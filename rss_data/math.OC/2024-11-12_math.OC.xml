<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 12 Nov 2024 05:00:44 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Assessing and Enhancing Graph Neural Networks for Combinatorial Optimization: Novel Approaches and Application in Maximum Independent Set Problems</title>
      <link>https://arxiv.org/abs/2411.05834</link>
      <description>arXiv:2411.05834v1 Announce Type: new 
Abstract: Combinatorial optimization (CO) problems are challenging as the computation time grows exponentially with the input. Graph Neural Networks (GNNs) show promise for researchers in solving CO problems. This study investigates the effectiveness of GNNs in solving the maximum independent set (MIS) problem, inspired by the intriguing findings of Schuetz et al., and aimed to enhance this solver. Despite the promise shown by GNNs, some researchers observed discrepancies when reproducing the findings, particularly compared to the greedy algorithm, for instance. We reproduced Schuetz' Quadratic Unconstrained Binary Optimization (QUBO) unsupervised approach and explored the possibility of combining it with a supervised learning approach for solving MIS problems. While the QUBO unsupervised approach did not guarantee maximal or optimal solutions, it provided a solid first guess for post-processing techniques like greedy decoding or tree-based methods. Moreover, our findings indicated that the supervised approach could further refine the QUBO unsupervised solver, as the learned model assigned meaningful probabilities for each node as initial node features, which could then be improved with the QUBO unsupervised approach. Thus, GNNs offer a valuable method for solving CO problems by integrating learned graph structures rather than relying solely on traditional heuristic functions. This research highlights the potential of GNNs to boost solver performance by leveraging ground truth during training and using optimization functions to learn structural graph information, marking a pioneering step towards improving prediction accuracy in a non-autoregressive manner.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05834v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Chenchuhui Hu</dc:creator>
    </item>
    <item>
      <title>Optimal Control of Microcephaly Under Vertical Transmission of Zika</title>
      <link>https://arxiv.org/abs/2411.05843</link>
      <description>arXiv:2411.05843v1 Announce Type: new 
Abstract: The Zika virus, known for its potential to induce neurological conditions such as microcephaly when transmitted vertically from infected mothers to infants, has sparked widespread concerns globally. Motivated by this, we propose an optimal control problem for the prevention of vertical Zika transmission. The novelty of this study lies in its consideration of time-dependent control functions, namely, insecticide spraying and personal protective measures taken to safeguard pregnant women from infected mosquitoes. New results provide a way to minimize the number of infected pregnant women through the implementation of control strategies while simultaneously reducing both the associated costs of control measures and the mosquito population, resulting in a decline in microcephaly cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05843v1</guid>
      <category>math.OC</category>
      <category>q-bio.PE</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.3390/axioms13110772</arxiv:DOI>
      <arxiv:journal_reference>Axioms 13 (2024), no. 11, Art. 772, 14pp</arxiv:journal_reference>
      <dc:creator>Dilara Yap{\i}\c{s}kan, Cristiana J. Silva, Delfim F. M. Torres</dc:creator>
    </item>
    <item>
      <title>Provably Faster Algorithms for Bilevel Optimization via Without-Replacement Sampling</title>
      <link>https://arxiv.org/abs/2411.05868</link>
      <description>arXiv:2411.05868v1 Announce Type: new 
Abstract: Bilevel Optimization has experienced significant advancements recently with the introduction of new efficient algorithms. Mirroring the success in single-level optimization, stochastic gradient-based algorithms are widely used in bilevel optimization. However, a common limitation in these algorithms is the presumption of independent sampling, which can lead to increased computational costs due to the complicated hyper-gradient formulation of bilevel problems. To address this challenge, we study the example-selection strategy for bilevel optimization in this work. More specifically, we introduce a without-replacement sampling based algorithm which achieves a faster convergence rate compared to its counterparts that rely on independent sampling. Beyond the standard bilevel optimization formulation, we extend our discussion to conditional bilevel optimization and also two special cases: minimax and compositional optimization. Finally, we validate our algorithms over both synthetic and real-world applications. Numerical results clearly showcase the superiority of our algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05868v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junyi Li, Heng Huang</dc:creator>
    </item>
    <item>
      <title>Stochastic Graphon Games with Memory</title>
      <link>https://arxiv.org/abs/2411.05896</link>
      <description>arXiv:2411.05896v1 Announce Type: new 
Abstract: We study finite-player dynamic stochastic games with heterogeneous interactions and non-Markovian linear-quadratic objective functionals. We derive the Nash equilibrium explicitly by converting the first-order conditions into a coupled system of stochastic Fredholm equations, which we solve in terms of operator resolvents. When the agents' interactions are modeled by a weighted graph, we formulate the corresponding non-Markovian continuum-agent game, where interactions are modeled by a graphon. We also derive the Nash equilibrium of the graphon game explicitly by first reducing the first-order conditions to an infinite-dimensional coupled system of stochastic Fredholm equations, then decoupling it using the spectral decomposition of the graphon operator, and finally solving it in terms of operator resolvents.
  Moreover, we show that the Nash equilibria of finite-player games on graphs converge to those of the graphon game as the number of agents increases. This holds both when a given graph sequence converges to the graphon in the cut norm and when the graph sequence is sampled from the graphon. We also bound the convergence rate, which depends on the cut norm in the former case and on the sampling method in the latter. Finally, we apply our results to various stochastic games with heterogeneous interactions, including systemic risk models with delays and stochastic network games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05896v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eyal Neuman, Sturmius Tuschmann</dc:creator>
    </item>
    <item>
      <title>A Passivity Analysis for Nonlinear Consensus on Balanced Digraphs</title>
      <link>https://arxiv.org/abs/2411.05933</link>
      <description>arXiv:2411.05933v1 Announce Type: new 
Abstract: This work deals with the output consensus problem for multiagent systems over balanced digraphs by passivity analysis. As the standard diffusive coupling structure only models the undirected interconnection, we propose a general approach capable of processing directed coupling and performing passivity analysis. To mitigate the complexity arising from the nonlinearity and directed interconnections, we reformulate the output consensus problem as a convergence analysis on a submanifold. We provide passivity analysis and establish a sufficient condition based on passivity for achieving output agreement in multi-agent systems over balanced digraphs. The results are supported by a numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05933v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Feng-Yu Yue, Daniel Zelazo</dc:creator>
    </item>
    <item>
      <title>Optimal drug application on stochastic cancer growth: an approach through path integral control</title>
      <link>https://arxiv.org/abs/2411.05968</link>
      <description>arXiv:2411.05968v1 Announce Type: new 
Abstract: We provide an overview of an optimal control problem within a stochastic model of tumor growth, which includes drug application. The model comprises two stochastic differential equations (SDE) representing the diffusion of nutrient and drug concentrations. To account for various uncertainties, stochastic terms are incorporated into the deterministic framework, capturing random disturbances. Control variables, informed by medical principles, are used to regulate drug and nutrient concentrations. In defining the optimal control problem, a stochastic cost function can be established, and a Feynman-type path integral control approach would lead to an optimal drug treatment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05968v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Noelymar Farinacci</dc:creator>
    </item>
    <item>
      <title>Movable Antennas in Wireless Systems: A Tool for Connectivity or a New Security Threat?</title>
      <link>https://arxiv.org/abs/2411.06028</link>
      <description>arXiv:2411.06028v1 Announce Type: new 
Abstract: The emergence of movable antenna (MA) technology has marked a significant advancement in the field of wireless communication research, paving the way for enhanced connectivity, improved signal quality, and adaptability across diverse environments. By allowing antennas to adjust positions dynamically within a finite area at transceivers, this technology enables more favourable channel conditions, optimizing performance across applications like mobile telecommunications and remote sensing. However, throughout history, the introduction of every new technology has presented opportunities for misuse by malicious individuals. Just as MAs can enhance connectivity, they may also be exploited for disruptive purposes such as jamming. In this paper, we examine the impact of an MA-enhanced jamming system equipped with $M$ antennas in a downlink multi-user communication scenario, where a base station (BS) with $N$ antennas transmits data to $K$ single-antenna users. Simulation results show that an adversary equipped with MAs reduce the system sum rate by $30\%$ more effectively than fixed-position antennas (FPAs). Additionally, MAs increase the outage probability by $25\%$ over FPAs, leading to a $20\%$ increase in the number of users experiencing outages. The highlighted risks posed by unauthorized use of this technology, underscore the urgent need for effective regulations and countermeasures to ensure its secure application.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06028v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Youssef Maghrebi, Mohamed Elhattab, Chadi Assi, Ali Ghrayeb</dc:creator>
    </item>
    <item>
      <title>Mean Field Control by Stochastic Koopman Operator via a Spectral Method</title>
      <link>https://arxiv.org/abs/2411.06180</link>
      <description>arXiv:2411.06180v1 Announce Type: new 
Abstract: Mean field control provides a robust framework for coordinating large-scale populations with complex interactions and has wide applications across diverse fields. However, the inherent nonlinearity and the presence of unknown system dynamics pose significant challenges for developing effective analytic or numerical solutions. There is a pressing need for data-driven methodologies to construct accurate models and facilitate efficient planning and control.
  To this end, we leverage Koopman operator theory to advance solution methods for mean field control problems. Our approach involves exploring stochastic Koopman operators using spectral analysis techniques. Through Koopman decomposition, we derive a linear model for mean field control problems in a data-driven fashion. Finally, we develop a model predictive control framework to achieve robust control and reduce the computational complexity for mean field control problems, thereby enhancing the efficacy and applicability of mean field control solutions in various domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06180v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuhan Zhao, Juntao Chen, Yingdong Lu, Quanyan Zhu</dc:creator>
    </item>
    <item>
      <title>PDE Models for Deep Neural Networks: Learning Theory, Calculus of Variations and Optimal Control</title>
      <link>https://arxiv.org/abs/2411.06290</link>
      <description>arXiv:2411.06290v1 Announce Type: new 
Abstract: We propose a partial differential-integral equation (PDE) framework for deep neural networks (DNNs) and their associated learning problem by taking the continuum limits of both network width and depth. The proposed model captures the complex interactions among hidden nodes, overcoming limitations of traditional discrete and ordinary differential equation (ODE)-based models. We explore the well-posedness of the forward propagation problem, analyze the existence and properties of minimizers for the learning task, and provide a detailed examination of necessary and sufficient conditions for the existence of critical points.
  Controllability and optimality conditions for the learning task with its associated PDE forward problem are established using variational calculus, the Pontryagin Maximum Principle, and the Hamilton-Jacobi-Bellman equation, framing the deep learning process as a PDE-constrained optimization problem. In this context, we prove the existence of viscosity solutions for the latter and we establish optimal feedback controls based on the value functional. This approach facilitates the development of new network architectures and numerical methods that improve upon traditional layer-by-layer gradient descent techniques by introducing forward-backward PDE discretization.
  The paper provides a mathematical foundation for connecting neural networks, PDE theory, variational analysis, and optimal control, partly building on and extending the results of \cite{liu2020selection}, where the main focus was the analysis of the forward evolution. By integrating these fields, we offer a robust framework that enhances deep learning models' stability, efficiency, and interpretability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06290v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Peter Markowich, Simone Portaro</dc:creator>
    </item>
    <item>
      <title>A Learned Proximal Alternating Minimization Algorithm and Its Induced Network for a Class of Two-block Nonconvex and Nonsmooth Optimization</title>
      <link>https://arxiv.org/abs/2411.06333</link>
      <description>arXiv:2411.06333v1 Announce Type: new 
Abstract: This work proposes a general learned proximal alternating minimization algorithm, LPAM, for solving learnable two-block nonsmooth and nonconvex optimization problems. We tackle the nonsmoothness by an appropriate smoothing technique with automatic diminishing smoothing effect. For smoothed nonconvex problems we modify the proximal alternating linearized minimization (PALM) scheme by incorporating the residual learning architecture, which has proven to be highly effective in deep network training, and employing the block coordinate decent (BCD) iterates as a safeguard for the convergence of the algorithm. We prove that there is a subsequence of the iterates generated by LPAM, which has at least one accumulation point and each accumulation point is a Clarke stationary point. Our method is widely applicable as one can employ various learning problems formulated as two-block optimizations, and is also easy to be extended for solving multi-block nonsmooth and nonconvex optimization problems. The network, whose architecture follows the LPAM exactly, namely LPAM-net, inherits the convergence properties of the algorithm to make the network interpretable. As an example application of LPAM-net, we present the numerical and theoretical results on the application of LPAM-net for joint multi-modal MRI reconstruction with significantly under-sampled k-space data. The experimental results indicate the proposed LPAM-net is parameter-efficient and has favourable performance in comparison with some state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06333v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yunmei Chen, Lezhi Liu, Lei Zhang</dc:creator>
    </item>
    <item>
      <title>A novel algorithm for optimizing bundle adjustment in image sequence alignment</title>
      <link>https://arxiv.org/abs/2411.06343</link>
      <description>arXiv:2411.06343v1 Announce Type: new 
Abstract: The Bundle Adjustment (BA) model is commonly optimized using a nonlinear least squares method, with the Levenberg-Marquardt (L-M) algorithm being a typical choice. However, despite the L-M algorithm's effectiveness, its sensitivity to initial conditions often results in slower convergence when applied to poorly conditioned datasets, motivating the exploration of alternative optimization strategies. This paper introduces a novel algorithm for optimizing the BA model in the context of image sequence alignment for cryo-electron tomography, utilizing optimal control theory to directly optimize general nonlinear functions. The proposed Optimal Control Algorithm (OCA) exhibits superior convergence rates and effectively mitigates the oscillatory behavior frequently observed in L-M algorithm. Extensive experiments on both synthetic and real-world datasets were conducted to evaluate the algorithm's performance. The results demonstrate that the OCA achieves faster convergence compared to the L-M algorithm. Moreover, the incorporation of a bisection-based update procedure significantly enhances the OCA's performance, particularly in poorly initialized datasets. These findings indicate that the OCA can substantially improve the efficiency of 3D reconstructions in cryo-electron tomography.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06343v1</guid>
      <category>math.OC</category>
      <category>cs.CV</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hailin Xu, Hongxia Wang, Huanshui Zhang</dc:creator>
    </item>
    <item>
      <title>Robust optimal stopping with regime switching</title>
      <link>https://arxiv.org/abs/2411.06522</link>
      <description>arXiv:2411.06522v1 Announce Type: new 
Abstract: In this paper, we study an optimal stopping problem in the presence of model uncertainty and regime switching. The max-min formulation for robust control and the dynamic programming approach are adopted to establish a general theoretical framework for such kind of problem. First, based on the dynamic programming principle, the value function of the optimal stopping problem is characterized as the unique viscosity solution to the associated Hamilton-Jacobi-Bellman equation. Then, the so-called smooth-fit principle for optimal stopping problems is proved in the current context, and a verification theorem consisting of a set of sufficient conditions for robust optimality is established. Moreover, when the Markov chain has a large state space and exhibits a two-time-scale structure, a singular perturbation approach is utilized to reduce the complexity involved and obtain an asymptotically optimal solution. Finally, an example of choosing the best time to sell a stock is provided, in which numerical experiments are reported to illustrate the implications of model uncertainty and regime switching.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06522v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siyu Lv, Zhen Wu, Jie Xiong, Xin Zhang</dc:creator>
    </item>
    <item>
      <title>Two Kinds of Learning Algorithms for Continuous-Time VWAP Targeting Execution</title>
      <link>https://arxiv.org/abs/2411.06645</link>
      <description>arXiv:2411.06645v1 Announce Type: new 
Abstract: The optimal execution problem has always been a continuously focused research issue, and many reinforcement learning (RL) algorithms have been studied. In this article, we consider the execution problem of targeting the volume weighted average price (VWAP) and propose a relaxed stochastic optimization problem with an entropy regularizer to encourage more exploration. We derive the explicit formula of the optimal policy, which is Gaussian distributed, with its mean value being the solution to the original problem. Extending the framework of continuous RL to processes with jumps, we provide some theoretical proofs for RL algorithms. First, minimizing the martingale loss function leads to the optimal parameter estimates in the mean-square sense, and the second algorithm is to use the martingale orthogonality condition. In addition to the RL algorithm, we also propose another learning algorithm: adaptive dynamic programming (ADP) algorithm, and verify the performance of both in two different environments across different random seeds. Convergence of all algorithms has been verified in different environments, and shows a larger advantage in the environment with stronger price impact. ADP is a good choice when the agent fully understands the environment and can estimate the parameters well. On the other hand, RL algorithms do not require any model assumptions or parameter estimation, and are able to learn directly from interactions with the environment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06645v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xingyu Zhou, Wenbin Chen, Mingyu Xu</dc:creator>
    </item>
    <item>
      <title>Manifold Quadratic Penalty Alternating Minimization for Sparse Principal Component Analysis</title>
      <link>https://arxiv.org/abs/2411.06654</link>
      <description>arXiv:2411.06654v1 Announce Type: new 
Abstract: Optimization on the Stiefel manifold or with orthogonality constraints is an important problem in many signal processing and data analysis applications such as Sparse Principal Component Analysis (SPCA). Algorithms such as the Riemannian proximal gradient algorithms addressing this problem usually involve an intricate subproblem requiring a semi-smooth Newton method hence, simple and effective operator splitting methods extended to the manifold setting such as the Alternating Direction Method of Multipliers (ADMM) have been proposed. However, another simple operator-splitting method, the Quadratic Penalty Alternating Minimization (QPAM) method which has been successful in image processing to our knowledge, has not yet been extended to the manifold setting. In this paper, we propose a manifold QPAM (MQPAM) which is very simple to implement. The iterative scheme of the MQPAM consists of a Riemannian Gradient Descent (RGD) subproblem and a subproblem in the form of a proximal operator which has a closed-form solution. Experiments on the SPCA problem show that our proposed MQPAM is at par with or better than several other algorithms in terms of sparsity and CPU time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06654v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tarmizi Adam</dc:creator>
    </item>
    <item>
      <title>Service Deployment in the On-Demand Economy: Employees, Contractors, or Both?</title>
      <link>https://arxiv.org/abs/2411.06793</link>
      <description>arXiv:2411.06793v1 Announce Type: new 
Abstract: The recent advancements in mobile/data technology have fostered a widespread adoption of on-demand or gig service platforms. The increasingly available data and independent contractors have enabled these platforms to design customized services and a cost-efficient workforce to effectively match demand and supply. In practice, a diverse landscape of the workforce has been observed: some rely solely on either employees or contractors, others use a blended workforce with both types of workers. In this paper, we consider a profit-maximizing service provider (SP) that decides to offer a single service or two differentiated services, along with the pricing and staffing of the workforce with employees and/or contractors, to price- and waiting-sensitive customers. Contractors independently determine whether or not to participate in the marketplace based on private reservation rates and per-service wage offered by the SP, while it controls the number of employees who receive per-hour wage. Under a single service, we show that the SP relies on either employees or contractors and identify sufficient and necessary conditions in which one workforce is better than the other. Under the optimal service deployment, we show that the SP offers either a single service relying solely on employees or contractors, or two differentiated services with a hybrid workforce depending on the service value and cost efficiencies of employees and contractors. Our analysis suggests that proliferating services with a blended workforce could improve the SP's profit significantly, and identifies conditions in which this value is significant. Our results provide an in-depth understanding and insightful guidance to on-demand platforms on the design of service differentiation and workforce models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06793v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Lijian Lu, Xin Weng, Li Xiao</dc:creator>
    </item>
    <item>
      <title>Vector-Valued Integer Optimal Control with TV Regularization: Optimality Conditions and Algorithmic Treatment</title>
      <link>https://arxiv.org/abs/2411.06856</link>
      <description>arXiv:2411.06856v1 Announce Type: new 
Abstract: We investigate a broad class of integer optimal control problems with vector-valued controls and switching regularization using a total variation functional involving the p-norm, which influences the structure of a solution. We derive optimality conditions of first and second order for the integer optimal control problem via a switching-point reformulation.
  For the numerical solution, we use a trust region method utilizing Bellman's optimality principle for the subproblems. We will show convergence properties of the method and highlight the algorithms efficacy on some benchmark examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06856v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Jonas Marko, Gerd Wachsmuth</dc:creator>
    </item>
    <item>
      <title>Distributed Graph Augmentation Protocols to Achieve Strong Connectivity in Multi-Agent Networks</title>
      <link>https://arxiv.org/abs/2411.06880</link>
      <description>arXiv:2411.06880v1 Announce Type: new 
Abstract: In multi-agent systems, strong connectivity of the communication network is often crucial for establishing consensus protocols, which underpin numerous applications in decision-making and distributed optimization. However, this connectivity requirement may not be inherently satisfied in geographically distributed settings. Consequently, we need to find the minimum number of communication links to add to make the communication network strongly connected. To date, such problems have been solvable only through centralized methods. This paper introduces a fully distributed algorithm that efficiently identifies an optimal set of edge additions to achieve strong connectivity, using only local information. The majority of the communication between agents is local (according to the digraph structure), with only a few steps requiring communication among non-neighboring agents to establish the necessary additional communication links. A comprehensive empirical analysis of the algorithm's performance on various random communication networks reveals its efficiency and scalability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06880v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guilherme Ramos, Diogo Po\c{c}as, S\'ergio Pequito</dc:creator>
    </item>
    <item>
      <title>Symmetrizable systems</title>
      <link>https://arxiv.org/abs/2411.06887</link>
      <description>arXiv:2411.06887v1 Announce Type: new 
Abstract: Transforming an asymmetric system into a symmetric system makes it possible to exploit the simplifying properties of symmetry in control problems. We define and characterize the family of symmetrizable systems. These systems can be transformed into symmetric systems by a linear transformation of their inputs and outputs. We show that a Khatri-Rao rank needs to be satisfied for a system to be symmetrizable. We conclude that linear systems are generically neither symmetric nor symmetrizable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06887v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hamed Taghavian, Jens Sj\"olund</dc:creator>
    </item>
    <item>
      <title>On the proximal point algorithm for strongly quasiconvex functions in Hadamard spaces</title>
      <link>https://arxiv.org/abs/2411.06910</link>
      <description>arXiv:2411.06910v1 Announce Type: new 
Abstract: We prove the convergence of the proximal point algorithm for finding the unique minimizer of a strongly quasiconvex function in general nonlinear Hadamard spaces, generalizing a recent result due to F. Lara. Our argument is rather elementary and brief and relies only on a few properties of strongly quasiconvex functions and their proximal operators which are established here for the first time over these nonlinear spaces. In particular, our convergence proof is fully effective and actually yields fast (ranging up to linear) rates of convergence for the iterates towards the solution and for the function values towards the minimum. These rates are novel even in the context of Euclidean spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06910v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicholas Pischke</dc:creator>
    </item>
    <item>
      <title>Effectively Leveraging Momentum Terms in Stochastic Line Search Frameworks for Fast Optimization of Finite-Sum Problems</title>
      <link>https://arxiv.org/abs/2411.07102</link>
      <description>arXiv:2411.07102v1 Announce Type: new 
Abstract: In this work, we address unconstrained finite-sum optimization problems, with particular focus on instances originating in large scale deep learning scenarios. Our main interest lies in the exploration of the relationship between recent line search approaches for stochastic optimization in the overparametrized regime and momentum directions. First, we point out that combining these two elements with computational benefits is not straightforward. To this aim, we propose a solution based on mini-batch persistency. We then introduce an algorithmic framework that exploits a mix of data persistency, conjugate-gradient type rules for the definition of the momentum parameter and stochastic line searches. The resulting algorithm is empirically shown to outperform other popular methods from the literature, obtaining state-of-the-art results in both convex and nonconvex large scale training problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07102v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Lapucci, Davide Pucci</dc:creator>
    </item>
    <item>
      <title>Zero-sum Dynkin games under common and independent Poisson constraints</title>
      <link>https://arxiv.org/abs/2411.07134</link>
      <description>arXiv:2411.07134v1 Announce Type: new 
Abstract: Zero-sum Dynkin games under the Poisson constraint have been studied widely in the recent literature. In such a game the players are only allowed to stop at the event times of a Poisson process. The constraint can be modelled in two different ways: either both players share the same Poisson process (the common constraint) or each player has her own Poisson process (the independent constraint). In the Markovian case where the payoff is given by a pair of functions of an underlying diffusion, we give sufficient conditions under which the solution of the game (the value function, and the optimal stopping sets for each player) under the common (respectively, independent) constraint is also the solution of the game under the independent (respectively, common) constraint. Roughly speaking, if the stopping sets of the maximiser and minimiser in the game under the common constraint are disjoint, then the solution to the game is the same under both the common and the independent constraint. However, the fact that the stopping sets are disjoint in the game under the independent constraint, is not sufficient to guarantee that the solution of the game under the independent constraint is also the solution under the common constraint.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07134v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Hobson, Gechun Liang, Edward Wang</dc:creator>
    </item>
    <item>
      <title>Semantic Information G Theory for Range Control with Tradeoff between Purposiveness and Efficiency</title>
      <link>https://arxiv.org/abs/2411.05789</link>
      <description>arXiv:2411.05789v1 Announce Type: cross 
Abstract: Recent advances in deep learning suggest that we need to maximize and minimize two different kinds of information simultaneously. The Information Max-Min (IMM) method has been used in deep learning, reinforcement learning, and maximum entropy control. Shannon's information rate-distortion function is the theoretical basis of Minimizing Mutual Information (MMI) and data compression, but it is not enough to solve the IMM problem. The author has proposed the semantic information G theory (i.e., Shannon-Lu theory), including the semantic information G measure and the information rate fidelity function R(G) (R is the MMI for the given G of semantic mutual information). The parameter solution of the R(G) function provides a general method to improve the information efficiency, G/R. This paper briefly introduces the semantic information G measure and the parametric solution of the R(G) function. Two examples reveal that the parametric solution can help us optimize range control with the tradeoff between purposiveness (i.e., semantic mutual information) and information efficiency. It seems that the R(G) function can serve as the theoretical basis of IMM methods, but we still need further research in combination with deep learning, reinforcement learning, and constraint control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05789v1</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chenguang Lu</dc:creator>
    </item>
    <item>
      <title>A Natural Primal-Dual Hybrid Gradient Method for Adversarial Neural Network Training on Solving Partial Differential Equations</title>
      <link>https://arxiv.org/abs/2411.06278</link>
      <description>arXiv:2411.06278v1 Announce Type: cross 
Abstract: We propose a scalable preconditioned primal-dual hybrid gradient algorithm for solving partial differential equations (PDEs). We multiply the PDE with a dual test function to obtain an inf-sup problem whose loss functional involves lower-order differential operators. The Primal-Dual Hybrid Gradient (PDHG) algorithm is then leveraged for this saddle point problem. By introducing suitable precondition operators to the proximal steps in the PDHG algorithm, we obtain an alternative natural gradient ascent-descent optimization scheme for updating the neural network parameters. We apply the Krylov subspace method (MINRES) to evaluate the natural gradients efficiently. Such treatment readily handles the inversion of precondition matrices via matrix-vector multiplication. A posterior convergence analysis is established for the time-continuous version of the proposed method. The algorithm is tested on various types of PDEs with dimensions ranging from $1$ to $50$, including linear and nonlinear elliptic equations, reaction-diffusion equations, and Monge-Amp\`ere equations stemming from the $L^2$ optimal transport problems. We compare the performance of the proposed method with several commonly used deep learning algorithms such as physics-informed neural networks (PINNs), the DeepRitz method, weak adversarial networks (WANs), etc, for solving PDEs using the Adam and L-BFGS optimizers. The numerical results suggest that the proposed method performs efficiently and robustly and converges more stably.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06278v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shu Liu, Stanley Osher, Wuchen Li</dc:creator>
    </item>
    <item>
      <title>Systematic design of compliant morphing structures: a phase-field approach</title>
      <link>https://arxiv.org/abs/2411.06289</link>
      <description>arXiv:2411.06289v1 Announce Type: cross 
Abstract: We investigate the systematic design of compliant morphing structures composed of materials reacting to an external stimulus. We add a perimeter penalty term to ensure existence of solutions. We propose a phase-field approximation of this sharp interface problem, prove its convergence as the regularization length approaches 0 and present an efficient numerical implementation. We illustrate the strengths of our approach through a series of numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06289v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jamal Shabani, Kaushik Bhattacharya, Blaise Bourdin</dc:creator>
    </item>
    <item>
      <title>An Energy-Based Self-Adaptive Learning Rate for Stochastic Gradient Descent: Enhancing Unconstrained Optimization with VAV method</title>
      <link>https://arxiv.org/abs/2411.06573</link>
      <description>arXiv:2411.06573v1 Announce Type: cross 
Abstract: Optimizing the learning rate remains a critical challenge in machine learning, essential for achieving model stability and efficient convergence. The Vector Auxiliary Variable (VAV) algorithm introduces a novel energy-based self-adjustable learning rate optimization method designed for unconstrained optimization problems. It incorporates an auxiliary variable $r$ to facilitate efficient energy approximation without backtracking while adhering to the unconditional energy dissipation law. Notably, VAV demonstrates superior stability with larger learning rates and achieves faster convergence in the early stage of the training process. Comparative analyses demonstrate that VAV outperforms Stochastic Gradient Descent (SGD) across various tasks. This paper also provides rigorous proof of the energy dissipation law and establishes the convergence of the algorithm under reasonable assumptions. Additionally, $r$ acts as an empirical lower bound of the training loss in practice, offering a novel scheduling approach that further enhances algorithm performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06573v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiahao Zhang, Christian Moya, Guang Lin</dc:creator>
    </item>
    <item>
      <title>On the optimal choice of the illumination function in photoacoustic tomography</title>
      <link>https://arxiv.org/abs/2411.06609</link>
      <description>arXiv:2411.06609v1 Announce Type: cross 
Abstract: This work studies the inverse problem of photoacoustic tomography (more precisely, the acoustic subproblem) as the identification of a space-dependent source parameter. The model consists of a wave equation involving a time-fractional damping term to account for power law frequency dependence of the attenuation, as relevant in ultrasonics. We solve the inverse problem in a Bayesian framework using a Maximum A Posteriori (MAP) estimate, and for this purpose derive an explicit expression for the adjoint operator. On top of this, we consider optimization of the choice of the laser excitation function, which is the time-dependent part of the source in this model, to enhance the reconstruction result. The method employs the $A$-optimality criterion for Bayesian optimal experimental design with Gaussian prior and Gaussian noise. To efficiently approximate the cost functional, we introduce an approximation scheme based on projection onto finite-dimensional subspaces. Finally, we present numerical results that illustrate the theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06609v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Phuoc-Truong Huynh, Barbara Kaltenbacher</dc:creator>
    </item>
    <item>
      <title>Learning a Single Neuron Robustly to Distributional Shifts and Adversarial Label Noise</title>
      <link>https://arxiv.org/abs/2411.06697</link>
      <description>arXiv:2411.06697v1 Announce Type: cross 
Abstract: We study the problem of learning a single neuron with respect to the $L_2^2$-loss in the presence of adversarial distribution shifts, where the labels can be arbitrary, and the goal is to find a ``best-fit'' function. More precisely, given training samples from a reference distribution $\mathcal{p}_0$, the goal is to approximate the vector $\mathbf{w}^*$ which minimizes the squared loss with respect to the worst-case distribution that is close in $\chi^2$-divergence to $\mathcal{p}_{0}$. We design a computationally efficient algorithm that recovers a vector $ \hat{\mathbf{w}}$ satisfying $\mathbb{E}_{\mathcal{p}^*} (\sigma(\hat{\mathbf{w}} \cdot \mathbf{x}) - y)^2 \leq C \, \mathbb{E}_{\mathcal{p}^*} (\sigma(\mathbf{w}^* \cdot \mathbf{x}) - y)^2 + \epsilon$, where $C&gt;1$ is a dimension-independent constant and $(\mathbf{w}^*, \mathcal{p}^*)$ is the witness attaining the min-max risk $\min_{\mathbf{w}~:~\|\mathbf{w}\| \leq W} \max_{\mathcal{p}} \mathbb{E}_{(\mathbf{x}, y) \sim \mathcal{p}} (\sigma(\mathbf{w} \cdot \mathbf{x}) - y)^2 - \nu \chi^2(\mathcal{p}, \mathcal{p}_0)$. Our algorithm follows a primal-dual framework and is designed by directly bounding the risk with respect to the original, nonconvex $L_2^2$ loss. From an optimization standpoint, our work opens new avenues for the design of primal-dual algorithms under structured nonconvexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06697v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shuyao Li, Sushrut Karmalkar, Ilias Diakonikolas, Jelena Diakonikolas</dc:creator>
    </item>
    <item>
      <title>Modeling and Detection of Critical Slowing Down in Epileptic Dynamics</title>
      <link>https://arxiv.org/abs/2411.06808</link>
      <description>arXiv:2411.06808v1 Announce Type: cross 
Abstract: Epilepsy is a common neurological disorder characterized by abrupt seizures. Although seizures may appear random, they are often preceded by early warning signs in neural signals, notably, critical slowing down, a phenomenon in which the system's recovery rate from perturbations declines when it approaches a critical point. Detecting these markers could enable preventive therapies. This paper introduces a multi-stable slow-fast system to capture critical slowing down in epileptic dynamics. We construct regions of attraction for stable states, shedding light on how dynamic bifurcations drive pathological oscillations. We derive the recovery rate after perturbations to formalize critical slowing down. A novel algorithm for detecting precursors to ictal transitions is presented, along with a proof-of-concept event-based feedback control strategy to prevent impending pathological oscillations. Numerical studies are conducted to validate our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06808v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yuzhen Qin, Marcel van Gerven</dc:creator>
    </item>
    <item>
      <title>Generalized Wasserstein Barycenters</title>
      <link>https://arxiv.org/abs/2411.06838</link>
      <description>arXiv:2411.06838v1 Announce Type: cross 
Abstract: We propose a generalization, where negative weights are allowed, of the Wasserstein barycenter of $n$ probability measures. The barycenter is found, as usual, as a minimum of a functional. In this paper, we prove existence of a minimizer for probability measures on a separable Hilbert space and uniqueness in the case of one positive coefficient and $n-1$ negative ones. In the one-dimensional case, we characterize the quantile function of the unique minimum as the orthogonal projection of the $L^2$-barycenter of the quantiles on the cone of nonincreasing functions in $L^2(0,1)$. Further, we provide a stability estimate in dimension one and a counterexample to uniqueness in $\mathbb{R}^2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06838v1</guid>
      <category>math.PR</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francesco Tornabene, Marco Veneroni, Giuseppe Savar\'e</dc:creator>
    </item>
    <item>
      <title>Randomized Forward Mode Gradient for Spiking Neural Networks in Scientific Machine Learning</title>
      <link>https://arxiv.org/abs/2411.07057</link>
      <description>arXiv:2411.07057v1 Announce Type: cross 
Abstract: Spiking neural networks (SNNs) represent a promising approach in machine learning, combining the hierarchical learning capabilities of deep neural networks with the energy efficiency of spike-based computations. Traditional end-to-end training of SNNs is often based on back-propagation, where weight updates are derived from gradients computed through the chain rule. However, this method encounters challenges due to its limited biological plausibility and inefficiencies on neuromorphic hardware. In this study, we introduce an alternative training approach for SNNs. Instead of using back-propagation, we leverage weight perturbation methods within a forward-mode gradient framework. Specifically, we perturb the weight matrix with a small noise term and estimate gradients by observing the changes in the network output. Experimental results on regression tasks, including solving various PDEs, show that our approach achieves competitive accuracy, suggesting its suitability for neuromorphic systems and potential hardware compatibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07057v1</guid>
      <category>cs.NE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruyin Wan, Qian Zhang, George Em Karniadakis</dc:creator>
    </item>
    <item>
      <title>General framework for online-to-nonconvex conversion: Schedule-free SGD is also effective for nonconvex optimization</title>
      <link>https://arxiv.org/abs/2411.07061</link>
      <description>arXiv:2411.07061v1 Announce Type: cross 
Abstract: This work investigates the effectiveness of schedule-free methods, developed by A. Defazio et al. (NeurIPS 2024), in nonconvex optimization settings, inspired by their remarkable empirical success in training neural networks. Specifically, we show that schedule-free SGD achieves optimal iteration complexity for nonsmooth, nonconvex optimization problems. Our proof begins with the development of a general framework for online-to-nonconvex conversion, which converts a given online learning algorithm into an optimization algorithm for nonconvex losses. Our general framework not only recovers existing conversions but also leads to two novel conversion schemes. Notably, one of these new conversions corresponds directly to schedule-free SGD, allowing us to establish its optimality. Additionally, our analysis provides valuable insights into the parameter choices for schedule-free SGD, addressing a theoretical gap that the convex theory cannot explain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07061v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kwangjun Ahn, Gagik Magakyan, Ashok Cutkosky</dc:creator>
    </item>
    <item>
      <title>Efficient Adaptive Optimization via Subset-Norm and Subspace-Momentum: Fast, Memory-Reduced Training with Convergence Guarantees</title>
      <link>https://arxiv.org/abs/2411.07120</link>
      <description>arXiv:2411.07120v1 Announce Type: cross 
Abstract: We introduce two complementary techniques for efficient adaptive optimization that reduce memory requirements while accelerating training of large-scale neural networks. The first technique, Subset-Norm adaptive step size, generalizes AdaGrad-Norm and AdaGrad(-Coordinate) by reducing the second moment term's memory footprint from $O(d)$ to $O(\sqrt{d})$ through step-size sharing, where $d$ is the model size. For non-convex smooth objectives under coordinate-wise sub-gaussian gradient noise, we prove a noise-adapted high-probability convergence guarantee showing improved dimensional dependence over existing methods. Our second technique, Subspace-Momentum, reduces the momentum state's memory footprint by operating in a low-dimensional subspace while applying standard SGD in the orthogonal complement. We establish high-probability convergence rates under similar relaxed assumptions. Empirical evaluation on LLaMA models from 60M to 1B parameters demonstrates the effectiveness of our methods, where combining subset-norm with subspace-momentum achieves Adam's validation perplexity in approximately half the training tokens (6.8B vs 13.1B) while using only 20% of the Adam's optimizer-states memory footprint and requiring minimal additional hyperparameter tuning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07120v1</guid>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thien Hang Nguyen, Huy Le Nguyen</dc:creator>
    </item>
    <item>
      <title>Conditional simulation via entropic optimal transport: Toward non-parametric estimation of conditional Brenier maps</title>
      <link>https://arxiv.org/abs/2411.07154</link>
      <description>arXiv:2411.07154v1 Announce Type: cross 
Abstract: Conditional simulation is a fundamental task in statistical modeling: Generate samples from the conditionals given finitely many data points from a joint distribution. One promising approach is to construct conditional Brenier maps, where the components of the map pushforward a reference distribution to conditionals of the target. While many estimators exist, few, if any, come with statistical or algorithmic guarantees. To this end, we propose a non-parametric estimator for conditional Brenier maps based on the computational scalability of \emph{entropic} optimal transport. Our estimator leverages a result of Carlier et al. (2010), which shows that optimal transport maps under a rescaled quadratic cost asymptotically converge to conditional Brenier maps; our estimator is precisely the entropic analogues of these converging maps. We provide heuristic justifications for choosing the scaling parameter in the cost as a function of the number of samples by fully characterizing the Gaussian setting. We conclude by comparing the performance of the estimator to other machine learning and non-parametric approaches on benchmark datasets and Bayesian inference problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07154v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ricardo Baptista, Aram-Alexandre Pooladian, Michael Brennan, Youssef Marzouk, Jonathan Niles-Weed</dc:creator>
    </item>
    <item>
      <title>Conic Reformulations for Kullback-Leibler Divergence Constrained Distributionally Robust Optimization and Applications</title>
      <link>https://arxiv.org/abs/2007.05966</link>
      <description>arXiv:2007.05966v2 Announce Type: replace 
Abstract: In this paper, we consider a distributionally robust optimization (DRO) model in which the ambiguity set is defined as the set of distributions whose Kullback-Leibler (KL) divergence to an empirical distribution is bounded. Utilizing the fact that KL divergence is an exponential cone representable function, we obtain the robust counterpart of the KL divergence constrained DRO problem as a dual exponential cone constrained program under mild assumptions on the underlying optimization problem. The resulting conic reformulation of the original optimization problem can be directly solved by a commercial conic programming solver. We specialize our generic formulation to two classical optimization problems, namely, the Newsvendor Problem and the Uncapacitated Facility Location Problem. Our computational study in an out-of-sample analysis shows that the solutions obtained via the DRO approach yield significantly better performance in terms of the dispersion of the cost realizations while the central tendency deteriorates only slightly compared to the solutions obtained by stochastic programming.</description>
      <guid isPermaLink="false">oai:arXiv.org:2007.05966v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.11121/ijocta.01.2021.001001</arxiv:DOI>
      <dc:creator>Burak Kocuk</dc:creator>
    </item>
    <item>
      <title>Unified Convergence Analysis for Adaptive Optimization with Moving Average Estimator</title>
      <link>https://arxiv.org/abs/2104.14840</link>
      <description>arXiv:2104.14840v5 Announce Type: replace 
Abstract: Although adaptive optimization algorithms have been successful in many applications, there are still some mysteries in terms of convergence analysis that have not been unraveled. This paper provides a novel non-convex analysis of adaptive optimization to uncover some of these mysteries. Our contributions are three-fold. First, we show that an increasing or large enough momentum parameter for the first-order moment used in practice is sufficient to ensure the convergence of adaptive algorithms whose adaptive scaling factors of the step size are bounded. Second, our analysis gives insights for practical implementations, e.g., increasing the momentum parameter in a stage-wise manner in accordance with stagewise decreasing step size would help improve the convergence. Third, the modular nature of our analysis allows its extension to solving other optimization problems, e.g., compositional, min-max and bilevel problems. As an interesting yet non-trivial use case, we present algorithms for solving non-convex min-max optimization and bilevel optimization that do not require using large batches of data to estimate gradients or double loops as the literature do. Our empirical studies corroborate our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2104.14840v5</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhishuai Guo, Yi Xu, Wotao Yin, Rong Jin, Tianbao Yang</dc:creator>
    </item>
    <item>
      <title>Optimizing Connected Components Graph Partitioning With Minimum Size Constraints Using Integer Programming and Spectral Clustering Techniques</title>
      <link>https://arxiv.org/abs/2202.11254</link>
      <description>arXiv:2202.11254v3 Announce Type: replace 
Abstract: In this work, a graph partitioning problem in a fixed number of connected components is considered. Given an undirected graph with costs on the edges, the problem consists of partitioning the set of nodes into a fixed number of subsets with minimum size, where each subset induces a connected subgraph with minimal edge cost. The problem naturally surges in applications where connectivity is essential, such as cluster detection in social networks, political districting, sports team realignment, and energy distribution. Mixed Integer Programming formulations together with a variety of valid inequalities are demonstrated and computationally tested. An assisted column generation approach by spectral clustering is also proposed for this problem with additional valid inequalities. Finally, the methods are tested for several simulated instances, and computational results are discussed. Overall, the proposed column generation technique enhanced by spectral clustering offers a promising approach to solve clustering and partitioning problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2202.11254v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1002/net.22257</arxiv:DOI>
      <dc:creator>Mishelle Cordero, Andr\'es Miniguano-Trujillo, Diego Recalde, Ramiro Torres, Polo Vaca</dc:creator>
    </item>
    <item>
      <title>Consensus-based Distributed Optimization for Multi-agent Systems over Multiplex Networks</title>
      <link>https://arxiv.org/abs/2304.01875</link>
      <description>arXiv:2304.01875v2 Announce Type: replace 
Abstract: Multilayer networks provide a more comprehensive framework for exploring real-world and engineering systems than traditional single-layer networks, consisting of multiple interacting networks. However, despite significant research in distributed optimization for single-layer networks, similar progress for multilayer systems is lacking. This paper proposes two algorithms for distributed optimization problems in multiplex networks using the supra-Laplacian matrix and its diffusion dynamics. The algorithms include a distributed saddle-point algorithm and its variation as a distributed gradient descent algorithm. By relating consensus and diffusion dynamics, we obtain the multiplex supra-Laplacian matrix. We extend the distributed gradient descent algorithm for multiplex networks using this matrix and analyze the convergence of both algorithms with several theoretical results. Numerical examples validate our proposed algorithms, and we explore the impact of interlayer diffusion on consensus time. We also present a coordinated dispatch for interdependent infrastructure networks (energy-gas) to demonstrate the application of the proposed framework to real engineering problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.01875v2</guid>
      <category>math.OC</category>
      <category>cond-mat.stat-mech</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>C. D. Rodr\'iguez-Camargo, A. F. Urquijo-Rodr\'iguez, E. A. Mojica-Nava</dc:creator>
    </item>
    <item>
      <title>Dynamic Pricing for Reusable Resources: The Power of Two Prices</title>
      <link>https://arxiv.org/abs/2308.13822</link>
      <description>arXiv:2308.13822v2 Announce Type: replace 
Abstract: Motivated by real-world applications such as rental and cloud computing services, we investigate pricing for reusable resources. We consider a system where a single resource with a fixed number of identical copies serves customers with heterogeneous willingness-to-pay (WTP), and the usage duration distribution is general. Optimal dynamic policies are computationally intractable when usage durations are not memoryless, so existing literature has focused on static pricing, which incurs a steady-state performance loss of ${O}(\sqrt{c})$ compared to optimality when supply and demand scale with $c$. We propose a class of dynamic "stock-dependent" policies that 1) are computationally tractable and 2) can attain a steady-state performance loss of $o(\sqrt{c})$. We give parametric bounds based on the local shape of the reward function at the optimal fluid admission probability and show that the performance loss of stock-dependent policies can be as low as ${O}((\log{c})^2)$. We characterize the tight performance loss for stock-dependent policies and show that they can in fact be achieved by a simple two-price policy that sets a higher price when the stock is below some threshold and a lower price otherwise. We extend our results to settings with multiple resources and multiple customer classes. Finally, we demonstrate this "minimally dynamic" class of two-price policies performs well numerically, even in non-asymptotic settings, suggesting that a little dynamicity can go a long way.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.13822v2</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Santiago R. Balseiro, Will Ma, Wenxin Zhang</dc:creator>
    </item>
    <item>
      <title>Learning Parametric Koopman Decompositions for Prediction and Control</title>
      <link>https://arxiv.org/abs/2310.01124</link>
      <description>arXiv:2310.01124v2 Announce Type: replace 
Abstract: We present an approach to construct approximate Koopman-type decompositions for dynamical systems depending on static or time-varying parameters. Our method simultaneously constructs an invariant subspace and a parametric family of projected Koopman operators acting on this subspace. We parametrize both the projected Koopman operator family and the dictionary that spans the invariant subspace by neural networks and jointly train them with trajectory data. We show theoretically the validity of our approach, and demonstrate via numerical experiments that it exhibits significant improvements over existing methods in solving prediction problems, especially those with large state or parameter dimensions, and those possessing strongly non-linear dynamics. Moreover, our method enables data-driven solution of optimal control problems involving non-linear dynamics, with interesting implications on controllability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.01124v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yue Guo, Milan Korda, Ioannis G. Kevrekidis, Qianxiao Li</dc:creator>
    </item>
    <item>
      <title>Accelerating optimization over the space of probability measures</title>
      <link>https://arxiv.org/abs/2310.04006</link>
      <description>arXiv:2310.04006v4 Announce Type: replace 
Abstract: The acceleration of gradient-based optimization methods is a subject of significant practical and theoretical importance, particularly within machine learning applications. While much attention has been directed towards optimizing within Euclidean space, the need to optimize over spaces of probability measures in machine learning motivates exploration of accelerated gradient methods in this context too. To this end, we introduce a Hamiltonian-flow approach analogous to momentum-based approaches in Euclidean space. We demonstrate that, in the continuous-time setting, algorithms based on this approach can achieve convergence rates of arbitrarily high order. We complement our findings with numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.04006v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shi Chen, Qin Li, Oliver Tse, Stephen J. Wright</dc:creator>
    </item>
    <item>
      <title>Smoothed Gradient Clipping and Error Feedback for Decentralized Optimization under Symmetric Heavy-Tailed Noise</title>
      <link>https://arxiv.org/abs/2310.16920</link>
      <description>arXiv:2310.16920v3 Announce Type: replace 
Abstract: Motivated by understanding and analysis of large-scale machine learning under heavy-tailed gradient noise, we study decentralized optimization with gradient clipping, i.e., in which certain clipping operators are applied to the gradients or gradient estimates computed from local nodes prior to further processing. While vanilla gradient clipping has proven effective in mitigating the impact of heavy-tailed gradient noise in non-distributed setups, it incurs bias that causes convergence issues in heterogeneous distributed settings. To address the inherent bias introduced by gradient clipping, we develop a smoothed clipping operator, and propose a decentralized gradient method equipped with an error feedback mechanism, i.e., the clipping operator is applied on the difference between some local gradient estimator and local stochastic gradient. We consider strongly convex and smooth local functions under symmetric heavy-tailed gradient noise that may not have finite moments of order greater than one. We show that the proposed decentralized gradient clipping method achieves a mean-square error (MSE) convergence rate of $O(1/t^\delta)$, $\delta \in (0, 2/5)$, where the exponent $\delta$ is independent of the existence of higher order gradient noise moments $\alpha &gt; 1$ and lower bounded by some constant dependent on condition number. To the best of our knowledge, this is the first MSE convergence result for decentralized gradient clipping under heavy-tailed noise without assuming bounded gradient. Numerical experiments validate our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.16920v3</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuhua Yu, Dusan Jakovetic, Soummya Kar</dc:creator>
    </item>
    <item>
      <title>Stochastic Optimization under Hidden Convexity</title>
      <link>https://arxiv.org/abs/2401.00108</link>
      <description>arXiv:2401.00108v2 Announce Type: replace 
Abstract: In this work, we consider constrained stochastic optimization problems under hidden convexity, i.e., those that admit a convex reformulation via non-linear (but invertible) map $c(\cdot)$. A number of non-convex problems ranging from optimal control, revenue and inventory management, to convex reinforcement learning all admit such a hidden convex structure. Unfortunately, in the majority of applications considered, the map $c(\cdot)$ is unavailable or implicit; therefore, directly solving the convex reformulation is not possible. On the other hand, the stochastic gradients with respect to the original variable are often easy to obtain. Motivated by these observations, we examine the basic projected stochastic (sub-) gradient methods for solving such problems under hidden convexity. We provide the first sample complexity guarantees for global convergence in smooth and non-smooth settings. Additionally, in the smooth setting, we improve our results to the last iterate convergence in terms of function value gap using the momentum variant of projected stochastic gradient descent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.00108v2</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ilyas Fatkhullin, Niao He, Yifan Hu</dc:creator>
    </item>
    <item>
      <title>Interpolatory Necessary Optimality Conditions for Reduced-order Modeling of Parametric Linear Time-invariant Systems</title>
      <link>https://arxiv.org/abs/2401.10047</link>
      <description>arXiv:2401.10047v2 Announce Type: replace 
Abstract: Interpolatory necessary optimality conditions for $\mathcal{H}_2$-optimal reduced-order modeling of non-parametric linear time-invariant (LTI) systems are known and well-investigated. In this work, using the general framework of $\mathcal{L}_2$-optimal reduced-order modeling of parametric stationary problems, we derive interpolatory $\mathcal{H}_2 \otimes \mathcal{L}_2$-optimality conditions for parametric LTI systems with a general pole-residue form. We then specialize this result to recover known conditions for systems with parameter-independent poles and develop new conditions for a certain class of systems with parameter-dependent poles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.10047v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.NA</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Petar Mlinari\'c, Peter Benner, Serkan Gugercin</dc:creator>
    </item>
    <item>
      <title>Mean uniformly stable function and its application to almost sure stability analysis of randomly switched time-varying systems</title>
      <link>https://arxiv.org/abs/2401.11655</link>
      <description>arXiv:2401.11655v2 Announce Type: replace 
Abstract: This paper investigates uniform almost sure stability of randomly switched time-varying systems. Mode-dependent indefinite multiple Lyapunov functions (iMLFs) are introduced to assess stability properties of diverse time-varying subsystems. To realize the stability conditions establishment based on iMLFs, we present a novel condition so-called mean uniformly stable function for time-varying parameters of iMLFs' derivatives. Our approach provides a random perspective, which makes iMLFs suits for random switched time-varying systems. Moreover, the MUSF condition revealed a fact that each time-varying subsystem staying mean bounded during its corresponding sojourn time interval is a precondition for whole system almost sure stable. The combination of iMLFs and MUSFs, to some extent, preforms a flexibility to accommodate stability analysis with unstable subsystems and stable but no-exponentially decay subystems. Numerical examples are provided to demonstrate the effectiveness and advantages of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.11655v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qian Liu, Yong He, Lin Jiang</dc:creator>
    </item>
    <item>
      <title>Hovering Flight in Flapping Insects and Hummingbirds: A Natural Real-Time and Stable Extremum Seeking Feedback System</title>
      <link>https://arxiv.org/abs/2402.04985</link>
      <description>arXiv:2402.04985v2 Announce Type: replace 
Abstract: In this paper, we show that the physical phenomenon of hovering flight can be comprehensively characterized and captured if considered and treated as an extremum seeking (ES) feedback system. Said novel characterization, while in early phases, strikes a great leap towards solving all the puzzle pieces of hovering flight that existed for decades in previous literature. Is hovering flight stable? If so, what is the control mechanism utilized by insects/hummingbirds to achieve stable hovering? If such a mechanism exists, does it fit the biological constraints that insects/hummingbirds have limited computational abilities? Does it fit the experimental biology narrative that insects/hummingbirds rely mainly on their sensation to stabilize hovering? Our ES characterization and analysis provide for the first time a simple, model-free, real-time, stable feedback system of hovering. Consistent with natural observations and biological experiments, hovering via ES is simply achievable by the natural oscillations of the wing angle and measuring (sensing) altitude or balance between the lift and weight. We provide simulation trials to demonstrate the effectiveness of our results on a hawkmoth, cranefly, bumblebee, dragonfly, hoverfly, and a hummingbird.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.04985v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmed A. Elgohary, Sameh A. Eisa</dc:creator>
    </item>
    <item>
      <title>Adaptive waveform inversion for transmitted wave data</title>
      <link>https://arxiv.org/abs/2402.17696</link>
      <description>arXiv:2402.17696v2 Announce Type: replace 
Abstract: Adaptive Waveform Inversion (AWI) applied to transient transmitted wave data can yield estimates of index of refraction (or wave velocity) similar to those obtained by travel time inversion. The AWI objective function measures normalized mean-square dispersion about zero time of a family of filters, one filter for each source-reeciver pair, designed to match predicted data to observed data. Provided that the data contain a single smooth wavefront, this function approaches the mean square traveltime error as data wavelength tends to zero. The scaling of each filter to have unit norm is responsible for the simple relation with travel time tomography. A similar approach, Matched Source Waveform Inversion (MSWI), does not normalize the filters and has a looser relation with mean-square travel time error. If substantial energy is spread amongst multiple arrivals, on the other hand, neither AWI nor MSWI objectives approximate the travel time mean square erorr, and attempts to minimize them by local (Newton-related) optimization are as likely to stagnate at models predicting erroneous travel times as is least-square Full Waveform Inversion (FWI). The matching filter at the heart of this approach must be ``pre-whitened'', that is, computed by solving a regularized least squares problem for filtered data misfit. In order for the relation to traveltime tomography to hold, and for the filtered data misfit to stay relatively small, the regularization weight must be coupled to data wavelength. These objective functions can also be used as penalty terms in a homotopy of objectives connecting AWI or MSWI with FWI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.17696v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>William W. Symes</dc:creator>
    </item>
    <item>
      <title>Managing Distributional Ambiguity in Stochastic Optimization through a Statistical Upper Bound Framework</title>
      <link>https://arxiv.org/abs/2403.08966</link>
      <description>arXiv:2403.08966v4 Announce Type: replace 
Abstract: Stochastic optimization is often hampered by distributional ambiguity, where critical probability distributions are poorly characterized or unknown. Addressing this challenge, we introduce a new framework that targets the minimization of a statistical upper bound for the expected value of uncertain objectives, facilitating more statistically robust decision-making. Central to our approach is the Average Percentile Upper Bound (APUB), a novel construct that simultaneously delivers a statistically rigorous upper bound for the population mean and a meaningful risk metric for the sample mean. The integration of APUB into stochastic optimization not only fortifies the process against distributional ambiguity but also reinforces key data-driven decision-making attributes, such as reliability, consistency, and comprehensibility. Notably, APUB-enriched optimization problems feature tractability, with particular advantages in two-stage stochastic optimization with random recourse. Empirical demonstrations on two-stage product mix and multi-product newsvendor benchmark problems reveal the benefit of the APUB optimization framework, in comparison with conventional techniques such as sample average approximation and distributionally robust optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08966v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shixin Liu, Jian Hu</dc:creator>
    </item>
    <item>
      <title>Stochastic Halpern iteration in normed spaces and applications to reinforcement learning</title>
      <link>https://arxiv.org/abs/2403.12338</link>
      <description>arXiv:2403.12338v3 Announce Type: replace 
Abstract: We analyze the oracle complexity of the stochastic Halpern iteration with variance reduction, where we aim to approximate fixed-points of nonexpansive and contractive operators in a normed finite-dimensional space. We show that if the underlying stochastic oracle is with uniformly bounded variance, our method exhibits an overall oracle complexity of $\tilde{O}(\varepsilon^{-5})$, improving recent rates established for the stochastic Krasnoselskii-Mann iteration. Also, we establish a lower bound of $\Omega(\varepsilon^{-3})$, which applies to a wide range of algorithms, including all averaged iterations even with minibatching. Using a suitable modification of our approach, we derive a $O(\varepsilon^{-2}(1-\gamma)^{-3})$ complexity bound in the case in which the operator is a $\gamma$-contraction. As an application, we propose new synchronous algorithms for average reward and discounted reward Markov decision processes. In particular, for the average reward, our method improves on the best-known sample complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12338v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mario Bravo, Juan Pablo Contreras</dc:creator>
    </item>
    <item>
      <title>A Gauss-Seidel method for solving multi-leader-multi-follower games</title>
      <link>https://arxiv.org/abs/2404.02605</link>
      <description>arXiv:2404.02605v2 Announce Type: replace 
Abstract: We design a computational approach to find equilibria in a class of Nash games possessing a hierarchical structure. By using tools from mixed-integer optimization and the characterization of variational equilibria in terms of the Karush-Kuhn-Tucker conditions, we propose a mixed-integer game formulation for solving this challenging class of problems. Besides providing an equivalent reformulation, we design a proximal Gauss--Seidel method with global convergence guarantees in case the game enjoys a potential structure. We finally corroborate the numerical performance of the algorithm on a novel instance of the ride-hail market problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02605v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Barbara Franci, Filippo Fabiani, Martin Schmidt, Mathias Staudigl</dc:creator>
    </item>
    <item>
      <title>Equitably allocating wildfire resilience investments for power grids: The curse of aggregation and vulnerability indices</title>
      <link>https://arxiv.org/abs/2404.11520</link>
      <description>arXiv:2404.11520v3 Announce Type: replace 
Abstract: Social vulnerability indices have increased traction for guiding infrastructure investment decisions to prioritize communities that need these investments most. One such plan is the Biden-Harris Justice40 initiative, which aims to guide equitable infrastructure investments by ensuring that disadvantaged communities defined by the Climate &amp; Economic Justice Screening Tool (CEJST) receive 40% of the total benefit realized by the investment. However, there is limited research on the practicality of applying vulnerability indices like the CEJST to real-world decision-making for policy outcomes. In this paper, we study this gap by examining the effectiveness of vulnerability indices in a case study focused on power shutoff and undergrounding decisions in wildfire-prone regions. Using a mixed-integer program and a high-fidelity synthetic transmission network in Texas, we model resource allocation policies inspired by Justice40 and evaluate their impact on reducing power outages and mitigating wildfire risk for vulnerable groups. Our analysis reveals that the Justice40 framework may fail to protect certain communities facing high wildfire risk. In our case study, we show that indigenous groups are particularly impacted. We posit that this outcome is likely due to information losses from data aggregation and the use of generalized vulnerability indices. Through the use of explicit group-level protections, we are able to bound the best possible outcome for population groups that are proportionally most affected.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11520v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Madeleine Pollack, Ryan Piansky, Swati Gupta, Alyssa Kody, Daniel Molzahn</dc:creator>
    </item>
    <item>
      <title>$\mathsf{QuITO}$ $\textsf{v.2}$: Trajectory Optimization with Uniform Error Guarantees under Path Constraints</title>
      <link>https://arxiv.org/abs/2404.13681</link>
      <description>arXiv:2404.13681v3 Announce Type: replace 
Abstract: This article introduces a new transcription, change point localization, and mesh refinement scheme for direct optimization-based solutions and for uniform approximation of optimal control trajectories associated with a class of nonlinear constrained optimal control problems (OCPs). The base transcription algorithm for which we establish the refinement algorithm is a direct multiple shooting technique -- $\mathsf{QuITO}$ $\textsf{v.2}$ (Quasi-Interpolation based Trajectory Optimization). The mesh refinement technique consists of two steps -- localization of certain irregular regions in an optimal control trajectory via wavelets, followed by a targeted $h$-refinement approach around such regions of irregularity. Theoretical approximation guarantees on uniform grids are presented for optimal controls with certain regularity properties, along with guarantees of localization of change points by wavelet transform. Numerical illustrations are provided for control profiles involving discontinuities to show the effectiveness of the localization and refinement strategy. We also announce, and make freely available, a new software package based on $\mathsf{QuITO}$ $\textsf{v.2}$ along with all its functionalities for completeness. The package is available at: https://github.com/chatterjee-d/QuITOv2.git.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13681v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siddhartha Ganguly, Rihan Aaron D'Silva, Debasish Chatterjee</dc:creator>
    </item>
    <item>
      <title>Greedy Learning to Optimize with Convergence Guarantees</title>
      <link>https://arxiv.org/abs/2406.00260</link>
      <description>arXiv:2406.00260v3 Announce Type: replace 
Abstract: Learning to optimize is an approach that leverages training data to accelerate the solution of optimization problems. Many approaches use unrolling to parametrize the update step and learn optimal parameters. Although L2O has shown empirical advantages over classical optimization algorithms, memory restrictions often greatly limit the unroll length and learned algorithms usually do not provide convergence guarantees. In contrast, we introduce a novel method employing a greedy strategy that learns iteration-specific parameters by minimizing the function value at the next iteration. This enables training over significantly more iterations while maintaining constant memory usage. We parameterize the update such that parameter learning corresponds to solving a convex optimization problem at each iteration. In particular, we explore preconditioned gradient descent with multiple parametrizations including a novel convolutional preconditioner. With our learned algorithm, convergence in the training set is proven even when the preconditioner is neither symmetric nor positive definite. Convergence on a class of unseen functions is also obtained, ensuring robust performance and generalization beyond the training data. We test our learned algorithms on two inverse problems, image deblurring and Computed Tomography, on which learned convolutional preconditioner demonstrates improved empirical performance over classical optimization algorithms such as Nesterov's Accelerated Gradient Method and the quasi-Newton method L-BFGS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00260v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrick Fahy, Mohammad Golbabaee, Matthias J. Ehrhardt</dc:creator>
    </item>
    <item>
      <title>Stochastic Newton Proximal Extragradient Method</title>
      <link>https://arxiv.org/abs/2406.01478</link>
      <description>arXiv:2406.01478v2 Announce Type: replace 
Abstract: Stochastic second-order methods achieve fast local convergence in strongly convex optimization by using noisy Hessian estimates to precondition the gradient. However, these methods typically reach superlinear convergence only when the stochastic Hessian noise diminishes, increasing per-iteration costs over time. Recent work in [arXiv:2204.09266] addressed this with a Hessian averaging scheme that achieves superlinear convergence without higher per-iteration costs. Nonetheless, the method has slow global convergence, requiring up to $\tilde{O}(\kappa^2)$ iterations to reach the superlinear rate of $\tilde{O}((1/t)^{t/2})$, where $\kappa$ is the problem's condition number. In this paper, we propose a novel stochastic Newton proximal extragradient method that improves these bounds, achieving a faster global linear rate and reaching the same fast superlinear rate in $\tilde{O}(\kappa)$ iterations. We accomplish this by extending the Hybrid Proximal Extragradient (HPE) framework, achieving fast global and local convergence rates for strongly convex functions with access to a noisy Hessian oracle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01478v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruichen Jiang, Micha{\l} Derezi\'nski, Aryan Mokhtari</dc:creator>
    </item>
    <item>
      <title>Adaptive and Optimal Second-order Optimistic Methods for Minimax Optimization</title>
      <link>https://arxiv.org/abs/2406.02016</link>
      <description>arXiv:2406.02016v2 Announce Type: replace 
Abstract: We propose adaptive, line search-free second-order methods with optimal rate of convergence for solving convex-concave min-max problems. By means of an adaptive step size, our algorithms feature a simple update rule that requires solving only one linear system per iteration, eliminating the need for line search or backtracking mechanisms. Specifically, we base our algorithms on the optimistic method and appropriately combine it with second-order information. Moreover, distinct from common adaptive schemes, we define the step size recursively as a function of the gradient norm and the prediction error in the optimistic update. We first analyze a variant where the step size requires knowledge of the Lipschitz constant of the Hessian. Under the additional assumption of Lipschitz continuous gradients, we further design a parameter-free version by tracking the Hessian Lipschitz constant locally and ensuring the iterates remain bounded. We also evaluate the practical performance of our algorithm by comparing it to existing second-order algorithms for minimax optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02016v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruichen Jiang, Ali Kavis, Qiujiang Jin, Sujay Sanghavi, Aryan Mokhtari</dc:creator>
    </item>
    <item>
      <title>Aubin Property and the Strong Regularity Are Equivalent for Nonlinear Second-Order Cone Programming</title>
      <link>https://arxiv.org/abs/2406.13798</link>
      <description>arXiv:2406.13798v2 Announce Type: replace 
Abstract: This paper solves a fundamental open problem in variational analysis on the equivalence between the Aubin property and the strong regularity for nonlinear second-order cone programming (SOCP) at a locally optimal solution. We achieve this by introducing a reduction approach to the Aubin property characterized by the Mordukhovich criterion and a lemma of alternative choices on cones to replace the S-lemma used in Outrata and Ram\'irez [SIAM J. Optim. 21 (2011) 789-823] and Opazo, Outrata, and Ram\'irez [SIAM J. Optim. 27 (2017) 2141-2151], where the same SOCP was considered under the strict complementarity condition except for possibly only one block of constraints. As a byproduct, we also offer a new approach to the well-known result of Dontchev and Rockafellar [SIAM J. Optim. 6 (1996) 1087-1105] on the equivalence of the two concepts in conventional nonlinear programming.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13798v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liang Chen, Ruoning Chen, Defeng Sun, Junyuan Zhu</dc:creator>
    </item>
    <item>
      <title>Real-time Hosting Capacity Assessment for Electric Vehicles: A Sequential Forecast-then-Optimize Method</title>
      <link>https://arxiv.org/abs/2408.11269</link>
      <description>arXiv:2408.11269v2 Announce Type: replace 
Abstract: Hosting capacity (HC) assessment for electric vehicles (EVs) is crucial for EV secure integration and reliable power system operation. Existing methods primarily focus on a long-term perspective (e.g., system planning), and consider the EV charging demands as scalar values, which introduces inaccuracies in real-time operations due to the inherently stochastic nature of EVs. In this regard, this paper proposes a real-time HC assessment method for EVs through a three-step process, involving real-time probabilistic forecasting, risk analysis and probabilistic optimization. Specifically, we conduct real-time probabilistic forecasting to capture the stochastic nature of EV charging demands across multiple charging stations by performing deterministic forecasting and fitting the distribution of forecasting errors. The deterministic forecasting is conducted using an adaptive spatio-temporal graph convolutional network (ASTGCN). ASTGCN leverages adaptive spatial feature extraction, attention-based temporal feature extraction, and second-order graph representation to improve the forecasting performance. Subsequently, based on the probabilistic forecasting of EV charging demands, we conduct real-time risk analysis and operational boundary identification by utilizing probabilistic power flow calculations to assess potential violations of secure operation constraints. Furthermore, we present the formulation of real-time HC of EVs considering expected satisfaction of stochastic EV charging demands, and propose an optimization model for real-time HC assessment of EVs. Numerical experiments on a real-world dataset demonstrate that the proposed ASTGCN model outperforms state-of-the-art forecasting models by achieving the lowest root mean square error of 0.0442, and the real-time HC is improved by 64% compared to long-term HC assessment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11269v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yingrui Zhuang, Lin Cheng, Ning Qi, Xinyi Wang, Yue Chen</dc:creator>
    </item>
    <item>
      <title>On Strong Quasiconvexity of Functions in Infinite Dimensions</title>
      <link>https://arxiv.org/abs/2409.17450</link>
      <description>arXiv:2409.17450v2 Announce Type: replace 
Abstract: In this paper, we explore the concept of $\sigma$-quasiconvexity for functions defined on normed vector spaces. This notion encompasses two important and well-established concepts: quasiconvexity and strong quasiconvexity. We start by analyzing certain operations on functions that preserve $\sigma$-quasiconvexity. Next, we present new results concerning the strong quasiconvexity of norm and Minkowski functions in infinite dimensions. Furthermore, we extend a recent result by F. Lara [16] on the supercoercive properties of strongly quasiconvex functions, with applications to the existence and uniqueness of minima, from finite dimensions to infinite dimensions. Finally, we address counterexamples related to strong quasiconvexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.17450v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nguyen Mau Nam, Jacob Sharkansky</dc:creator>
    </item>
    <item>
      <title>Global optimality conditions for sensor placement, with extensions to binary A-optimal experimental designs</title>
      <link>https://arxiv.org/abs/2410.16590</link>
      <description>arXiv:2410.16590v2 Announce Type: replace 
Abstract: We investigate optimality conditions for the sensor placement problem within optimal experimental design, wherein one must decide on the optimal manner in which a fixed number of sensors can be arranged over a large number of candidate locations. By a subgradient argument, we obtain sufficient and necessary conditions for global optimality of the relaxed problem, and demonstrate how one can take advantage of this optimality criterion to approximate optimal binary designs, i.e.~designs where no fractions of sensors are placed. To demonstrate our optimality criteria-based results, we derive a trace-free, efficient formulation of the gradient of the A-optimal objective for finite element-discretised function space settings, and study globally optimal designs for a Helmholtz-type source problem and extensions towards optimal binary designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16590v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian Aarset</dc:creator>
    </item>
    <item>
      <title>On the ReLU Lagrangian Cuts for Stochastic Mixed Integer Programming</title>
      <link>https://arxiv.org/abs/2411.01229</link>
      <description>arXiv:2411.01229v2 Announce Type: replace 
Abstract: We study stochastic mixed integer programs with both first-stage and recourse decisions involving mixed integer variables. A new family of Lagrangian cuts, termed ``ReLU Lagrangian cuts," is introduced by reformulating the nonanticipativity constraints using ReLU functions. These cuts can be integrated into scenario decomposition methods. We show that including ReLU Lagrangian cuts is sufficient to achieve optimality in the original stochastic mixed integer programs. Without solving the Lagrangian dual problems, we derive closed-form expressions for these cuts. Furthermore, to speed up the cut-generating procedures, we introduce linear programming-based methods to enhance the cut coefficients. Numerical studies demonstrate the effectiveness of the proposed cuts compared to existing cut families.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01229v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoyun Deng, Weijun Xie</dc:creator>
    </item>
    <item>
      <title>Forecasting Outside the Box: Application-Driven Optimal Pointwise Forecasts for Stochastic Optimization</title>
      <link>https://arxiv.org/abs/2411.03520</link>
      <description>arXiv:2411.03520v2 Announce Type: replace 
Abstract: The exponential growth in data availability in recent years has led to new formulations of data-driven optimization problems. One such formulation is that of stochastic optimization problems with contextual information, where the goal is to optimize the expected value of a certain function given some contextual information (also called features) that accompany the main data of interest. The contextual information then allows for a better estimation of the quantity of interest via machine learning methods, thereby leading to better solutions. Oftentimes, however, machine learning methods yield just a pointwise estimate instead of an entire distribution. In this paper we show that, when the problem to be solved is a class of two-stage stochastic programs (namely, those with fixed recourse matrix and fixed costs), under mild assumptions the problem can be solved with just one scenario. While such a scenario - which does not have be unique - is usually unknown, we present an integrated learning and optimization procedure that yields the best approximation of that scenario within the modeler's pre-specified set of parameterized forecast functions. Numerical results conducted with inventory problems from the literature (with synthetic data) as well as a bike-sharing problem with real data demonstrate that the proposed approach performs well when compared to benchmark methods from the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03520v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tito Homem-de-Mello, Juan Valencia, Felipe Lagos, Guido Lagos</dc:creator>
    </item>
    <item>
      <title>Solving Kernel Ridge Regression with Gradient Descent for a Non-Constant Kernel</title>
      <link>https://arxiv.org/abs/2311.01762</link>
      <description>arXiv:2311.01762v2 Announce Type: replace-cross 
Abstract: Kernel ridge regression, KRR, is a generalization of linear ridge regression that is non-linear in the data, but linear in the parameters. The solution can be obtained either as a closed-form solution, which includes solving a system of linear equations, or iteratively through gradient descent. Using the iterative approach opens up for changing the kernel during training, something that is investigated in this paper. We theoretically address the effects this has on model complexity and generalization. Based on our findings, we propose an update scheme for the bandwidth of translational-invariant kernels, where we let the bandwidth decrease to zero during training, thus circumventing the need for hyper-parameter selection. We demonstrate on real and synthetic data how decreasing the bandwidth during training outperforms using a constant bandwidth, selected by cross-validation and marginal likelihood maximization. We also show theoretically and empirically that using a decreasing bandwidth, we are able to achieve both zero training error in combination with good generalization, and a double descent behavior, phenomena that do not occur for KRR with constant bandwidth but are known to appear for neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.01762v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ME</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Oskar Allerbo</dc:creator>
    </item>
    <item>
      <title>Extreme Point Pursuit -- Part I: A Framework for Constant Modulus Optimization</title>
      <link>https://arxiv.org/abs/2403.06506</link>
      <description>arXiv:2403.06506v2 Announce Type: replace-cross 
Abstract: This study develops a framework for a class of constant modulus (CM) optimization problems, which covers binary constraints, discrete phase constraints, semi-orthogonal matrix constraints, non-negative semi-orthogonal matrix constraints, and several types of binary assignment constraints. Capitalizing on the basic principles of concave minimization and error bounds, we study a convex-constrained penalized formulation for general CM problems. The advantage of such formulation is that it allows us to leverage non-convex optimization techniques, such as the simple projected gradient method, to build algorithms. As the first part of this study, we explore the theory of this framework. We study conditions under which the formulation provides exact penalization results. We also examine computational aspects relating to the use of the projected gradient method for each type of CM constraint. Our study suggests that the proposed framework has a broad scope of applicability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06506v2</guid>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junbin Liu, Ya Liu, Wing-Kin Ma, Mingjie Shao, Anthony Man-Cho So</dc:creator>
    </item>
    <item>
      <title>Extreme Point Pursuit -- Part II: Further Error Bound Analysis and Applications</title>
      <link>https://arxiv.org/abs/2403.06513</link>
      <description>arXiv:2403.06513v2 Announce Type: replace-cross 
Abstract: In the first part of this study, a convex-constrained penalized formulation was studied for a class of constant modulus (CM) problems. In particular, the error bound techniques were shown to play a vital role in providing exact penalization results. In this second part of the study, we continue our error bound analysis for the cases of partial permutation matrices, size-constrained assignment matrices and non-negative semi-orthogonal matrices. We develop new error bounds and penalized formulations for these three cases, and the new formulations possess good structures for building computationally efficient algorithms. Moreover, we provide numerical results to demonstrate our framework in a variety of applications such as the densest k-subgraph problem, graph matching, size-constrained clustering, non-negative orthogonal matrix factorization and sparse fair principal component analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06513v2</guid>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junbin Liu, Ya Liu, Wing-Kin Ma, Mingjie Shao, Anthony Man-Cho So</dc:creator>
    </item>
    <item>
      <title>Decision making in stochastic extensive form I: Stochastic decision forests</title>
      <link>https://arxiv.org/abs/2404.12332</link>
      <description>arXiv:2404.12332v2 Announce Type: replace-cross 
Abstract: A general theory of stochastic decision forests is developed to bridge two concepts of information flow: decision trees and refined partitions on the one side, filtrations from probability theory on the other. Instead of the traditional "nature" agent, this framework uses a single lottery draw to select a tree of a given decision forest. Each "personal" agent receives dynamic updates from an own oracle on the lottery outcome and makes partition-refining choices adapted to this information. This theory addresses a key limitation of existing approaches in extensive form theory, which struggle to model continuous-time stochastic processes, such as Brownian motion, as outcomes of "nature" decision making. Additionally, a class of stochastic decision forests based on time-indexed action paths is constructed, encompassing a wide range of models from the literature and laying the groundwork for an approximation theory for stochastic differential games in extensive form.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12332v2</guid>
      <category>econ.TH</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>E. Emanuel Rapsch</dc:creator>
    </item>
    <item>
      <title>Fair Generalized Linear Mixed Models</title>
      <link>https://arxiv.org/abs/2405.09273</link>
      <description>arXiv:2405.09273v3 Announce Type: replace-cross 
Abstract: When using machine learning for automated prediction, it is important to account for fairness in the prediction. Fairness in machine learning aims to ensure that biases in the data and model inaccuracies do not lead to discriminatory decisions. E.g., predictions from fair machine learning models should not discriminate against sensitive variables such as sexual orientation and ethnicity. The training data often in obtained from social surveys. In social surveys, oftentimes the data collection process is a strata sampling, e.g. due to cost restrictions. In strata samples, the assumption of independence between the observation is not fulfilled. Hence, if the machine learning models do not account for the strata correlations, the results may be biased. Especially high is the bias in cases where the strata assignment is correlated to the variable of interest. We present in this paper an algorithm that can handle both problems simultaneously, and we demonstrate the impact of stratified sampling on the quality of fair machine learning predictions in a reproducible simulation study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09273v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jan Pablo Burgard, Jo\~ao Vitor Pamplona</dc:creator>
    </item>
    <item>
      <title>MDP Geometry, Normalization and Reward Balancing Solvers</title>
      <link>https://arxiv.org/abs/2407.06712</link>
      <description>arXiv:2407.06712v3 Announce Type: replace-cross 
Abstract: The Markov Decision Process (MDP) is a widely used mathematical model for sequential decision-making problems. In this paper, we present a new geometric interpretation of MDPs with a natural normalization procedure that allows us to adjust the value function at each state without altering the advantage of any action with respect to any policy. This procedure enables the development of a novel class of algorithms for solving MDPs that find optimal policies without explicitly computing policy values. The new algorithms we propose for different settings achieve and, in some cases, improve upon state-of-the-art sample complexity results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06712v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arsenii Mustafin, Aleksei Pakharev, Alex Olshevsky, Ioannis Ch. Paschalidis</dc:creator>
    </item>
    <item>
      <title>On the shifts of orbits and periodic orbits under perturbation and the change of Poincar\'e map Jacobian of periodic orbits</title>
      <link>https://arxiv.org/abs/2407.08079</link>
      <description>arXiv:2407.08079v5 Announce Type: replace-cross 
Abstract: Periodic orbits and cycles, respectively, play a significant role in discrete- and continuous-time dynamical systems (i.e. maps and flows). To succinctly describe their shifts when the system is applied perturbation, the notions of functional and functional derivative are borrowed from functional analysis to consider the whole system as an argument of the geometric representation of the periodic orbit or cycle. The shifts of an orbit/trajectory and periodic orbit/cycle are analyzed and concluded as formulae for maps/flows, respectively. The theory shall be beneficial for analyzing sensitivity to perturbations, and optimizing and controlling various systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08079v5</guid>
      <category>math.DS</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <category>nlin.CD</category>
      <category>physics.plasm-ph</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenyin Wei, Alexander Knieps, Yunfeng Liang</dc:creator>
    </item>
    <item>
      <title>GLinSAT: The General Linear Satisfiability Neural Network Layer By Accelerated Gradient Descent</title>
      <link>https://arxiv.org/abs/2409.17500</link>
      <description>arXiv:2409.17500v2 Announce Type: replace-cross 
Abstract: Ensuring that the outputs of neural networks satisfy specific constraints is crucial for applying neural networks to real-life decision-making problems. In this paper, we consider making a batch of neural network outputs satisfy bounded and general linear constraints. We first reformulate the neural network output projection problem as an entropy-regularized linear programming problem. We show that such a problem can be equivalently transformed into an unconstrained convex optimization problem with Lipschitz continuous gradient according to the duality theorem. Then, based on an accelerated gradient descent algorithm with numerical performance enhancement, we present our architecture, GLinSAT, to solve the problem. To the best of our knowledge, this is the first general linear satisfiability layer in which all the operations are differentiable and matrix-factorization-free. Despite the fact that we can explicitly perform backpropagation based on automatic differentiation mechanism, we also provide an alternative approach in GLinSAT to calculate the derivatives based on implicit differentiation of the optimality condition. Experimental results on constrained traveling salesman problems, partial graph matching with outliers, predictive portfolio allocation and power system unit commitment demonstrate the advantages of GLinSAT over existing satisfiability layers. Our implementation is available at \url{https://github.com/HunterTracer/GLinSAT}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.17500v2</guid>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hongtai Zeng, Chao Yang, Yanzhen Zhou, Cheng Yang, Qinglai Guo</dc:creator>
    </item>
    <item>
      <title>Is Pontryagin's Maximum Principle all you need? Solving optimal control problems with PMP-inspired neural networks</title>
      <link>https://arxiv.org/abs/2410.06277</link>
      <description>arXiv:2410.06277v2 Announce Type: replace-cross 
Abstract: Calculus of Variations is the mathematics of functional optimization, i.e., when the solutions are functions over a time interval. This is particularly important when the time interval is unknown like in minimum-time control problems, so that forward in time solutions are not possible. Calculus of Variations offers a robust framework for learning optimal control and inference. How can this framework be leveraged to design neural networks to solve challenges in control and inference? We propose the Pontryagin's Maximum Principle Neural Network (PMP-net) that is tailored to estimate control and inference solutions, in accordance with the necessary conditions outlined by Pontryagin's Maximum Principle. We assess PMP-net on two classic optimal control and inference problems: optimal linear filtering and minimum-time control. Our findings indicate that PMP-net can be effectively trained in an unsupervised manner to solve these problems without the need for ground-truth data, successfully deriving the classical "Kalman filter" and "bang-bang" control solution. This establishes a new approach for addressing general, possibly yet unsolved, optimal control problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06277v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kawisorn Kamtue, Jose M. F. Moura, Orathai Sangpetch</dc:creator>
    </item>
    <item>
      <title>How Does Critical Batch Size Scale in Pre-training?</title>
      <link>https://arxiv.org/abs/2410.21676</link>
      <description>arXiv:2410.21676v2 Announce Type: replace-cross 
Abstract: Training large-scale models under given resources requires careful design of parallelism strategies. In particular, the efficiency notion of critical batch size (CBS), concerning the compromise between time and compute, marks the threshold beyond which greater data parallelism leads to diminishing returns. To operationalize it, we propose a measure of CBS and pre-train a series of auto-regressive language models, ranging from 85 million to 1.2 billion parameters, on the C4 dataset. Through extensive hyper-parameter sweeps and careful control of factors such as batch size, momentum, and learning rate along with its scheduling, we systematically investigate the impact of scale on CBS. Then we fit scaling laws with respect to model and data sizes to decouple their effects. Overall, our results demonstrate that CBS scales primarily with data size rather than model size, a finding we justify theoretically through the analysis of infinite-width limits of neural networks and infinite-dimensional least squares regression. Of independent interest, we highlight the importance of common hyper-parameter choices and strategies for studying large-scale pre-training beyond fixed training durations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21676v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hanlin Zhang, Depen Morwani, Nikhil Vyas, Jingfeng Wu, Difan Zou, Udaya Ghai, Dean Foster, Sham Kakade</dc:creator>
    </item>
    <item>
      <title>IC/DC: Surpassing Heuristic Solvers in Combinatorial Optimization with Diffusion Models</title>
      <link>https://arxiv.org/abs/2411.00003</link>
      <description>arXiv:2411.00003v2 Announce Type: replace-cross 
Abstract: Recent advancements in learning-based combinatorial optimization (CO) methods have shown promising results in solving NP-hard problems without the need for expert-crafted heuristics. However, high performance of these approaches often rely on problem-specific human-expertise-based search after generating candidate solutions, limiting their applicability to commonly solved CO problems such as Travelling Salesman Problem (TSP). In this paper, we present IC/DC, a CO framework that operates without any supervision. IC/DC is specialized in addressing problems involving two distinct sets of items, and it does not need problem-specific search processes to generate valid solutions. IC/DC employs a novel architecture capable of capturing the intricate relationships between items, and thereby enabling effective optimization in challenging CO scenarios. We train our model in a self-supervised way to minimize the cost of the solution while adhering to the problem-specific constraints. IC/DC not only achieves state-of-the-art performance compared to previous learning methods, but also surpasses well-known solvers and heuristic approaches on Asymmetric Traveling Salesman Problem (ATSP).</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00003v2</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Seong-Hyun Hong, Hyun-Sung Kim, Zian Jang, Byung-Jun Lee</dc:creator>
    </item>
    <item>
      <title>Solving Hidden Monotone Variational Inequalities with Surrogate Losses</title>
      <link>https://arxiv.org/abs/2411.05228</link>
      <description>arXiv:2411.05228v2 Announce Type: replace-cross 
Abstract: Deep learning has proven to be effective in a wide variety of loss minimization problems. However, many applications of interest, like minimizing projected Bellman error and min-max optimization, cannot be modelled as minimizing a scalar loss function but instead correspond to solving a variational inequality (VI) problem. This difference in setting has caused many practical challenges as naive gradient-based approaches from supervised learning tend to diverge and cycle in the VI case. In this work, we propose a principled surrogate-based approach compatible with deep learning to solve VIs. We show that our surrogate-based approach has three main benefits: (1) under assumptions that are realistic in practice (when hidden monotone structure is present, interpolation, and sufficient optimization of the surrogates), it guarantees convergence, (2) it provides a unifying perspective of existing methods, and (3) is amenable to existing deep learning optimizers like ADAM. Experimentally, we demonstrate our surrogate-based approach is effective in min-max optimization and minimizing projected Bellman error. Furthermore, in the deep reinforcement learning case, we propose a novel variant of TD(0) which is more compute and sample efficient.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05228v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ryan D'Orazio, Danilo Vucetic, Zichu Liu, Junhyung Lyle Kim, Ioannis Mitliagkas, Gauthier Gidel</dc:creator>
    </item>
  </channel>
</rss>
