<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DL</link>
    <description>cs.DL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 27 Nov 2025 02:42:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>The external rhythm of an actor in science: New indicators for the science of science</title>
      <link>https://arxiv.org/abs/2511.20405</link>
      <description>arXiv:2511.20405v1 Announce Type: new 
Abstract: When calculating citation indicators, whether it is the total number of received citations or the average citations per paper, we always face the same problem. Namely, that papers published in different years have varying citation potential. Hence, strictly speaking, their citations cannot be compared. In a former study, we created a new indicator called the internal rhythm indicator of an actor. The internal rhythm indicator makes it possible to compare the citation performances among different publication years, but it is only valid within the actor based framework. In this study, we define, create, and explore the external rhythm of an actor, which is also a sequence of ratios of observed citations to expected citations. The essential difference between internal rhythm and external rhythm lies in the way they are created and hence in the point of view taken to study an actor. The former is created based on its own publication-citation matrix, while the latter is based on two publication-citation matrices. One is the same as the former. The other one is a publication-citation matrix of a collective, which includes the actor under study. The external rhythm of an actor is a citation-based indicator of research that can be used to compare not only the citation performance of an actor with that of the collective the actor is part of, but also to compare two or more actors within the same collective. We further propose a summary average of ratios indicator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.20405v1</guid>
      <category>cs.DL</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Liming Liang, Ronald Rousseau</dc:creator>
    </item>
    <item>
      <title>Studying Maps at Scale: A Digital Investigation of Cartography and the Evolution of Figuration</title>
      <link>https://arxiv.org/abs/2511.19538</link>
      <description>arXiv:2511.19538v1 Announce Type: cross 
Abstract: This thesis presents methods and datasets to investigate cartographic heritage on a large scale and from a cultural perspective. Heritage institutions worldwide have digitized more than one million maps, and automated techniques now enable large-scale recognition and extraction of map content. Yet these methods have engaged little with the history of cartography, or the view that maps are semantic-symbolic systems, and cultural objects reflecting political and epistemic expectations. This work leverages a diverse corpus of 771,561 map records and 99,715 digitized images aggregated from 38 digital catalogs. After normalization, the dataset includes 236,925 contributors and spans six centuries, from 1492 to 1948. These data make it possible to chart geographic structures and the global chronology of map publication. The spatial focus of cartography is analyzed in relation to political dynamics, evidencing links between Atlantic maritime charting, the triangular trade, and colonial expansion. Further results document the progression of national, domestic focus and the impact of military conflicts on publication volumes. The research introduces semantic segmentation techniques and object detection models for the generic recognition of land classes and cartographic signs, trained on annotated data and synthetic images. The analysis of land classes shows that maps are designed images whose framing and composition emphasize features through centering and semantic symmetries. The study of cartographic figuration encodes 63 M signs and 25 M fragments into a latent visual space, revealing figurative shifts such as the replacement of relief hachures by terrain contours and showing that signs tend to form locally consistent systems. Analyses of collaboration and diffusion highlight the role of legitimacy, larger actors, and major cities in the spread of figurative norms and semiotic cultures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19538v1</guid>
      <category>cs.CV</category>
      <category>cs.CL</category>
      <category>cs.DL</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.5075/epfl-thesis-11559</arxiv:DOI>
      <dc:creator>Remi Petitpierre</dc:creator>
    </item>
    <item>
      <title>How to Find Fantastic AI Papers: Self-Rankings as a Powerful Predictor of Scientific Impact Beyond Peer Review</title>
      <link>https://arxiv.org/abs/2510.02143</link>
      <description>arXiv:2510.02143v2 Announce Type: replace-cross 
Abstract: Peer review in academic research aims not only to ensure factual correctness but also to identify work of high scientific potential that can shape future research directions. This task is especially critical in fast-moving fields such as artificial intelligence (AI), yet it has become increasingly difficult given the rapid growth of submissions. In this paper, we investigate an underexplored measure for identifying high-impact research: authors' own rankings of their multiple submissions to the same AI conference. Grounded in game-theoretic reasoning, we hypothesize that self-rankings are informative because authors possess unique understanding of their work's conceptual depth and long-term promise. To test this hypothesis, we conducted a large-scale experiment at a leading AI conference, where 1,342 researchers self-ranked their 2,592 submissions by perceived quality. Tracking outcomes over more than a year, we found that papers ranked highest by their authors received twice as many citations as their lowest-ranked counterparts; self-rankings were especially effective at identifying highly cited papers (those with over 150 citations). Moreover, we showed that self-rankings outperformed peer review scores in predicting future citation counts. Our results remained robust after accounting for confounders such as preprint posting time and self-citations. Together, these findings demonstrate that authors' self-rankings provide a reliable and valuable complement to peer review for identifying and elevating high-impact research in AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02143v2</guid>
      <category>stat.AP</category>
      <category>cs.AI</category>
      <category>cs.DL</category>
      <category>cs.LG</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Buxin Su, Natalie Collina, Garrett Wen, Didong Li, Kyunghyun Cho, Jianqing Fan, Bingxin Zhao, Weijie Su</dc:creator>
    </item>
  </channel>
</rss>
