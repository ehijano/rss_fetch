<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 09 Aug 2024 04:00:29 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 09 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Quantitative Convergence of Quadratically Regularized Linear Programs</title>
      <link>https://arxiv.org/abs/2408.04088</link>
      <description>arXiv:2408.04088v1 Announce Type: new 
Abstract: Linear programs with quadratic regularization are attracting renewed interest due to their applications in optimal transport: unlike entropic regularization, the squared-norm penalty gives rise to sparse approximations of optimal transport couplings. It is well known that the solution of a quadratically regularized linear program over any polytope converges stationarily to the minimal-norm solution of the linear program when the regularization parameter tends to zero. However, that result is merely qualitative. Our main result quantifies the convergence by specifying the exact threshold for the regularization parameter, after which the regularized solution also solves the linear program. Moreover, we bound the suboptimality of the regularized solution before the threshold. These results are complemented by a convergence rate for the regime of large regularization. We apply our general results to the setting of optimal transport, where we shed light on how the threshold and suboptimality depend on the number of data points.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04088v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alberto Gonz\'alez-Sanz, Marcel Nutz</dc:creator>
    </item>
    <item>
      <title>Desensitized Optimal Guidance Using Adaptive Radau Collocation</title>
      <link>https://arxiv.org/abs/2408.04146</link>
      <description>arXiv:2408.04146v1 Announce Type: new 
Abstract: An optimal guidance method is developed that reduces sensitivity to parameters in the dynamic model. The method combines a previously developed method for guidance and control using adaptive Legendre-Gauss-Radau (LGR) collocation and a previously developed approach for desensitized optimal control. Guidance updates are performed such that the desensitized optimal control problem is re-solved on the remaining horizon at the start of each guidance cycle. The effectiveness of the method is demonstrated on a simple example using Monte Carlo simulation. It is found that the method reduces variations in the terminal state as compared to either desensitized optimal control without guidance updates or a previously developed method for optimal guidance and control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04146v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Katrina L. Winkler, Anil V. Rao</dc:creator>
    </item>
    <item>
      <title>Clustering and synchronization analysis of Networks of Bistable Systems</title>
      <link>https://arxiv.org/abs/2408.04202</link>
      <description>arXiv:2408.04202v1 Announce Type: new 
Abstract: This paper studies the dynamics of a network of diffusively-coupled bistable systems. Under mild conditions and without requiring smoothness of the vector field, we analyze the network dynamics and show that the solutions converge globally to the set of equilibria for generic monotone (but not necessarily strictly monotone) regulatory functions. Sufficient conditions for global state synchronization are provided. Finally, by adopting a piecewise linear approximation of the vector field, we determine the existence, location and stability of the equilibria as function of the coupling gain. The theoretical results are illustrated with numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04202v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gianluca Villani, Luca Scardovi</dc:creator>
    </item>
    <item>
      <title>Social optimum of finite mean field games: existence and uniqueness of equilibrium solutions in the finite horizon and stationary solutions in the infinite horizon</title>
      <link>https://arxiv.org/abs/2408.04291</link>
      <description>arXiv:2408.04291v1 Announce Type: new 
Abstract: In this paper, we consider the social optimal problem of discrete time finite state space mean field games (referred to as finite mean field games [1]). Unlike the individual optimization of their own cost function in competitive models, in the problem we consider, individuals aim to optimize the social cost by finding a fixed point of the state distribution to achieve equilibrium in the mean field game. We provide a sufficient condition for the existence and uniqueness of the individual optimal strategies used to minimize the social cost. According to the definition of social optimum and the derived properties of social optimal cost, the existence and uniqueness conditions of equilibrium solutions under initial-terminal value constraints in the finite horizon and the existence and uniqueness conditions of stable solutions in the infinite horizon are given. Finally, two examples that satisfy the conditions for the above solutions are provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04291v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zijia Niu, Sanjin Huang, Lu Ren, Wang Yao, Xiao Zhang</dc:creator>
    </item>
    <item>
      <title>Existence of Weak Pareto Efficient Solutions of a Vector Optimization Problem under a Closed Constraint Set</title>
      <link>https://arxiv.org/abs/2408.04352</link>
      <description>arXiv:2408.04352v1 Announce Type: new 
Abstract: In this paper, we investigate the nonemptiness of weak Pareto efficient solution set for a class of nonsmooth vector optimization problems on a nonempty closed constraint set without any boundedness and convexity assumptions. First, we obtain a new property concerning the nonemptiness of weak Pareto efficient solution sets for these vector optimization problems. Then, under the condition of weak section-boundedness from below, we establish relationships between the notions of properness, Palais-Smale, weak Palais-Smale and M-tameness conditions with respect to some index sets for the restriction of the vector mapping on the constraint set. Finally, we present some new necessary and sufficient conditions for the nonemptiness of the weak Pareto efficient solution set for a general class of nonsmooth vector optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04352v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Danyang Liu, Jun Li, Giandomenico Mastroeni</dc:creator>
    </item>
    <item>
      <title>Finite sample learning of moving targets</title>
      <link>https://arxiv.org/abs/2408.04406</link>
      <description>arXiv:2408.04406v1 Announce Type: new 
Abstract: We consider a moving target that we seek to learn from samples. Our results extend randomized techniques developed in control and optimization for a constant target to the case where the target is changing. We derive a novel bound on the number of samples that are required to construct a probably approximately correct (PAC) estimate of the target. Furthermore, when the moving target is a convex polytope, we provide a constructive method of generating the PAC estimate using a mixed integer linear program (MILP). The proposed method is demonstrated on an application to autonomous emergency braking.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04406v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikolaus Vertovec, Kostas Margellos, Maria Prandini</dc:creator>
    </item>
    <item>
      <title>Convergence Rates of Sums of Squares Hierarchies for Polynomial Optimization</title>
      <link>https://arxiv.org/abs/2408.04417</link>
      <description>arXiv:2408.04417v1 Announce Type: new 
Abstract: In this survey we consider polynomial optimization problems, asking to minimize a polynomial function over a compact semialgebraic set, defined by polynomial inequalities. This models a great variety of (in general, nonlinear nonconvex) optimization problems. Various hierarchies of (lower and upper) bounds have been introduced, having the remarkable property that they converge asymptotically to the global minimum. These bounds exploit algebraic representations of positive polynomials in terms of sums of squares and can be computed using semidefinite optimization. Our focus lies in the performance analysis of these hierarchies of bounds, namely, in how far the bounds are from the global minimum as the degrees of the sums of squares they involve tend to infinity. We present the main state-of-the-art results and offer a gentle introductory overview over the various techniques that have been recently developed to establish them, stemming from the theory of orthogonal polynomials, approximation theory, Fourier analysis, and more.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04417v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Monique Laurent, Lucas Slot</dc:creator>
    </item>
    <item>
      <title>Achieving Robust Data-driven Contextual Decision Making in a Data Augmentation Way</title>
      <link>https://arxiv.org/abs/2408.04469</link>
      <description>arXiv:2408.04469v1 Announce Type: new 
Abstract: This paper focuses on the contextual optimization problem where a decision is subject to some uncertain parameters and covariates that have some predictive power on those parameters are available before the decision is made. More specifically, we focus on solving the Wasserstein-distance-based distributionally robust optimization (DRO) model for the problem, which maximizes the worst-case expected objective over an uncertainty set including all distributions closed enough to a nominal distribution with respect to the Wasserstein distance. We develop a stochastic gradient descent algorithm based on the idea of data augmentation to solve the model efficiently. The algorithm iteratively a) does a bootstrapping sample from the nominal distribution; b) perturbs the adversarially and c) updates decisions. Accordingly, the computational time of the algorithm is only determined by the number of iterations and the complexity of computing the gradient of a single sample. Except for efficiently solving the model, the algorithm provide additional advantages that the proposed algorithm can cope with any nominal distributions and therefore is extendable to solve the problem in an online setting. We also prove that the algorithm converges to the optimal solution of the DRO model at a rate of a $O(1/\sqrt{T})$, where $T$ is the number of iterations of bootstrapping. Consequently, the performance guarantee of the algorithm is that of the DRO model plus $O(1/\sqrt{T})$. Through extensive numerical experiments, we demonstrate the superior performance of the proposed algorithm to several benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04469v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaoen Li, Maoqi Liu, Zhi-Hai Zhang</dc:creator>
    </item>
    <item>
      <title>Multi-Objective LQR with Linear Scalarization</title>
      <link>https://arxiv.org/abs/2408.04488</link>
      <description>arXiv:2408.04488v1 Announce Type: new 
Abstract: The framework of decision-making, modeled as a Markov Decision Process (MDP), typically assumes a single objective. However, most practical scenarios involve considering tradeoffs between multiple objectives. With that as the motivation, we consider the task of finding the Pareto front of achievable tradeoffs in the context of Linear Quadratic Regulator (LQR), a canonical example of a continuous, infinite horizon MDP. As our first contribution, we establish that the Pareto front for LQR is characterized by linear scalarization, wherein a linear combination of the objectives creates a single objective, and by varying the weight of the linear combination one achieves different possible tradeoffs. That is, each tradeoff point on the Pareto front of multi-objective LQR turns out to be a single objective LQR where the objective is a convex combination of the multiple objectives. Intellectually, our work provides an important example of linear scalarization being sufficient for a non-convex multi-objective problem. As our second contribution, we establish the smoothness of the Pareto front, showing that the optimal control to an $\epsilon$-perturbation to a scalarization parameter yields an $O(\epsilon)$-approximation to its objective performance. Together these results highlight a simple algorithm to approximate the continuous Pareto front by optimizing over a grid of scalarization parameters. Unlike other scalarization methods, each individual optimization problem retains the structure of a single objective LQR problem, making them computationally feasible. Lastly, we extend the results to consider certainty equivalence, where the unknown dynamics are replaced with estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04488v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ali Jadbabaie, Devavrat Shah, Sean R. Sinclair</dc:creator>
    </item>
    <item>
      <title>Discrete nonlinear functions: formulations and applications in retail revenue management</title>
      <link>https://arxiv.org/abs/2408.04562</link>
      <description>arXiv:2408.04562v1 Announce Type: new 
Abstract: This paper examines nonlinear optimization problems that incorporate discrete decisions. We introduce new improved formulation techniques that take advantage of the simplotope structure present in the domain of the binarization variables. Our technique identifies new polynomially solvable instances for price promotion problem initially studied by Cohen et al. (2021) and allows us to develop a linear programming (LP) formulation for inventory optimization problem under a choice model proposed by Boada-Collado and Martinez-de Albeniz (2020). The techniques we develop rely on ideal formulations for submodular and fractional compositions of discrete functions, improving prior formulations for bilinear products suggested by Adams and Henry (2012). Submodular compositions also generalize L natural functions over bounded domains and our construction provides new insights into Lovasz-extension based formulations for this class of problems while expanding the class of nonlinear discrete optimization problems amenable to linear programming based techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04562v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taotao He, Mohit Tawarmalani</dc:creator>
    </item>
    <item>
      <title>Adaptive Sampling Bi-Fidelity Stochastic Trust Region Method for Derivative-Free Stochastic Optimization</title>
      <link>https://arxiv.org/abs/2408.04625</link>
      <description>arXiv:2408.04625v1 Announce Type: new 
Abstract: Bi-fidelity stochastic optimization is increasingly favored for streamlining optimization processes by employing a cost-effective low-fidelity (LF) function, with the goal of optimizing a more expensive high-fidelity (HF) function. In this paper, we introduce ASTRO-BFDF, a new adaptive sampling trust region method specifically designed for solving unconstrained bi-fidelity stochastic derivative-free optimization problems. Within ASTRO-BFDF, the LF function serves two purposes: first, to identify better iterates for the HF function when a high correlation between them is indicated by the optimization process, and second, to reduce the variance of the HF function estimates by Bi-fidelity Monte Carlo (BFMC). In particular, the sample sizes are dynamically determined with the option of employing either crude Monte Carlo or BFMC, while balancing optimization error and sampling error. We demonstrate that the iterates generated by ASTRO-BFDF converge to the first-order stationary point almost surely. Additionally, we numerically demonstrate the superiority of our proposed algorithm by testing it on synthetic problems and simulation optimization problems with discrete event simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04625v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunsoo Ha, Juliane Mueller</dc:creator>
    </item>
    <item>
      <title>Minimal L2-Consistent Data-Transmission</title>
      <link>https://arxiv.org/abs/2408.04012</link>
      <description>arXiv:2408.04012v1 Announce Type: cross 
Abstract: In this work, we consider non-collocated sensors and actuators, and we address the problem of minimizing the number of sensor-to-actuator transmissions while ensuring that the L2 gain of the system remains under a threshold. By using causal factorization and system level synthesis, we reformulate this problem as a rank minimization problem over a convex set. When heuristics like nuclear norm minimization are used for rank minimization, the resulting matrix is only numerically low rank and must be truncated, which can lead to an infeasible solution. To address this issue, we introduce approximate causal factorization to control the factorization error and provide a bound on the degradation of the L2 gain in terms of the factorization error. The effectiveness of our method is demonstrated using a benchmark.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04012v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antoine Aspeel, Laurent Bako, Necmiye Ozay</dc:creator>
    </item>
    <item>
      <title>UpLIF: An Updatable Self-Tuning Learned Index Framework</title>
      <link>https://arxiv.org/abs/2408.04113</link>
      <description>arXiv:2408.04113v1 Announce Type: cross 
Abstract: The emergence of learned indexes has caused a paradigm shift in our perception of indexing by considering indexes as predictive models that estimate keys' positions within a data set, resulting in notable improvements in key search efficiency and index size reduction; however, a significant challenge inherent in learned index modeling is its constrained support for update operations, necessitated by the requirement for a fixed distribution of records. Previous studies have proposed various approaches to address this issue with the drawback of high overhead due to multiple model retraining. In this paper, we present UpLIF, an adaptive self-tuning learned index that adjusts the model to accommodate incoming updates, predicts the distribution of updates for performance improvement, and optimizes its index structure using reinforcement learning. We also introduce the concept of balanced model adjustment, which determines the model's inherent properties (i.e. bias and variance), enabling the integration of these factors into the existing index model without the need for retraining with new data. Our comprehensive experiments show that the system surpasses state-of-the-art indexing solutions (both traditional and ML-based), achieving an increase in throughput of up to 3.12 times with 1000 times less memory usage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04113v1</guid>
      <category>cs.DB</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alireza Heidari, Amirhossein Ahmadi, Wei Zhang</dc:creator>
    </item>
    <item>
      <title>Reducing Matroid Optimization to Basis Search</title>
      <link>https://arxiv.org/abs/2408.04118</link>
      <description>arXiv:2408.04118v1 Announce Type: cross 
Abstract: In combinatorial optimization, matroids provide one of the most elegant structures for algorithm design. This is perhaps best identified by the Edmonds-Rado theorem relating the success of the simple greedy algorithm to the anatomy of the optimal basis of a matroid [Edm71; Rad57]. As a response, much energy has been devoted to understanding a matroid's favorable computational properties. Yet surprisingly, not much is understood where parallel algorithm design is concerned. Specifically, while prior work has investigated the task of finding an arbitrary basis in parallel computing settings [KUW88], the more complex task of finding the optimal basis remains unexplored. We initiate this study by reexamining Bor\r{u}vka's minimum weight spanning tree algorithm in the language of matroid theory, identifying a new characterization of the optimal basis by way of a matroid's cocircuits as a result. Furthermore, we then combine such insights with special properties of binary matroids to reduce optimization in a binary matroid to the simpler task of search for an arbitrary basis, with only logarithmic asymptotic overhead. Consequentially, we are able to compose our reduction with a known basis search method of [KUW88] to obtain a novel algorithm for finding the optimal basis of a binary matroid with only sublinearly many adaptive rounds of queries to an independence oracle. To the authors' knowledge, this is the first parallel algorithm for matroid optimization to outperform the greedy algorithm in terms of adaptive complexity, for any class of matroid not represented by a graph.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04118v1</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <category>cs.DM</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert Streit, Vijay K. Garg</dc:creator>
    </item>
    <item>
      <title>Non-maximizing policies that fulfill multi-criterion aspirations in expectation</title>
      <link>https://arxiv.org/abs/2408.04385</link>
      <description>arXiv:2408.04385v1 Announce Type: cross 
Abstract: In dynamic programming and reinforcement learning, the policy for the sequential decision making of an agent in a stochastic environment is usually determined by expressing the goal as a scalar reward function and seeking a policy that maximizes the expected total reward. However, many goals that humans care about naturally concern multiple aspects of the world, and it may not be obvious how to condense those into a single reward function. Furthermore, maximization suffers from specification gaming, where the obtained policy achieves a high expected total reward in an unintended way, often taking extreme or nonsensical actions.
  Here we consider finite acyclic Markov Decision Processes with multiple distinct evaluation metrics, which do not necessarily represent quantities that the user wants to be maximized. We assume the task of the agent is to ensure that the vector of expected totals of the evaluation metrics falls into some given convex set, called the aspiration set. Our algorithm guarantees that this task is fulfilled by using simplices to approximate feasibility sets and propagate aspirations forward while ensuring they remain feasible. It has complexity linear in the number of possible state-action-successor triples and polynomial in the number of evaluation metrics. Moreover, the explicitly non-maximizing nature of the chosen policy and goals yields additional degrees of freedom, which can be used to apply heuristic safety criteria to the choice of actions. We discuss several such safety criteria that aim to steer the agent towards more conservative behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04385v1</guid>
      <category>cs.AI</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simon Dima, Simon Fischer, Jobst Heitzig, Joss Oliver</dc:creator>
    </item>
    <item>
      <title>A Note on the Bias and Kemeny's Constant in Markov Reward Processes with an Application to Markov Chain Perturbation</title>
      <link>https://arxiv.org/abs/2408.04454</link>
      <description>arXiv:2408.04454v1 Announce Type: cross 
Abstract: Given a unichain Markov reward process (MRP), we provide an explicit expression for the bias values in terms of mean first passage times. This result implies a generalization of known Markov chain perturbation bounds for the stationary distribution to the case where the perturbed chain is not irreducible. It further yields an improved perturbation bound in 1-norm. As a special case, Kemeny's constant can be interpreted as the translated bias in an MRP with constant reward 1, which offers an intuitive explanation why it is a constant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04454v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ronald Ortner</dc:creator>
    </item>
    <item>
      <title>Symmetric nonnegative functions, the tropical Vandermonde cell and superdominance of power sums</title>
      <link>https://arxiv.org/abs/2408.04616</link>
      <description>arXiv:2408.04616v1 Announce Type: cross 
Abstract: We study nonnegative and sums of squares symmetric (and even symmetric) functions of fixed degree. We can think of these as limit cones of symmetric nonnegative polynomials and symmetric sums of squares of fixed degree as the number of variables goes to infinity. We compare these cones, including finding explicit examples of nonnegative polynomials which are not sums of squares for any sufficiently large number of variables, and compute the tropicalizations of their dual cones in the even symmetric case. We find that the tropicalization of the dual cones is naturally understood in terms of the overlooked superdominance order on partitions. The power sum symmetric functions obey this same partial order (analogously to how term-normalized power sums obey the dominance order).</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04616v1</guid>
      <category>math.AG</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jose Acevedo, Grigoriy Blekherman, Sebastian Debus, Cordian Riener</dc:creator>
    </item>
    <item>
      <title>Collision Avoidance using Iterative Dynamic and Nonlinear Programming with Adaptive Grid Refinements</title>
      <link>https://arxiv.org/abs/2311.03148</link>
      <description>arXiv:2311.03148v3 Announce Type: replace 
Abstract: Nonlinear optimal control problems for trajectory planning with obstacle avoidance present several challenges. While general-purpose optimizers and dynamic programming methods struggle when adopted separately, their combination enabled by a penalty approach is capable of handling highly nonlinear systems while overcoming the curse of dimensionality. Nevertheless, using dynamic programming with a fixed state space discretization limits the set of reachable solutions, hindering convergence or requiring enormous memory resources for uniformly spaced grids. In this work we solve this issue by incorporating an adaptive refinement of the state space grid, splitting cells where needed to better capture the problem structure while requiring less discretization points overall. Numerical results on a space manipulator demonstrate the improved robustness and efficiency of the combined method with respect to the single components.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.03148v3</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.23919/ECC64448.2024.10591064</arxiv:DOI>
      <arxiv:journal_reference>2024 European Control Conference (ECC), Stockholm, Sweden, 2024, pp. 52-57</arxiv:journal_reference>
      <dc:creator>Rebecca Richter, Alberto De Marchi, Matthias Gerdts</dc:creator>
    </item>
    <item>
      <title>Suboptimality bounds for trace-bounded SDPs enable a faster and scalable low-rank SDP solver SDPLR+</title>
      <link>https://arxiv.org/abs/2406.10407</link>
      <description>arXiv:2406.10407v2 Announce Type: replace 
Abstract: Semidefinite programs (SDPs) and their solvers are powerful tools with many applications in machine learning and data science. Designing scalable SDP solvers is challenging because by standard the positive semidefinite decision variable is an $n \times n$ dense matrix, even though the input is often $n \times n$ sparse matrices. However, the information in the solution may not correspond to a full-rank dense matrix as shown by Barvinok and Pataki. Two decades ago, Burer and Monteiro developed an SDP solver $\texttt{SDPLR}$ that optimizes over a low-rank factorization instead of the full matrix. This greatly decreases the storage cost and works well for many problems. The original solver $\texttt{SDPLR}$ tracks only the primal infeasibility of the solution, limiting the technique's flexibility to produce moderate accuracy solutions. We use a suboptimality bound for trace-bounded SDP problems that enables us to track the progress better and perform early termination. We then develop $\texttt{SDPLR+}$, which starts the optimization with an extremely low-rank factorization and dynamically updates the rank based on the primal infeasibility and suboptimality. This further speeds up the computation and saves the storage cost. Numerical experiments on Max Cut, Minimum Bisection, Cut Norm, and Lov\'{a}sz Theta problems with many recent memory-efficient scalable SDP solvers demonstrate its scalability up to problems with million-by-million decision variables and it is often the fastest solver to a moderate accuracy of $10^{-2}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10407v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yufan Huang, David F. Gleich</dc:creator>
    </item>
    <item>
      <title>Finite-Sample Guarantees for Best-Response Learning Dynamics in Zero-Sum Matrix Games</title>
      <link>https://arxiv.org/abs/2407.20128</link>
      <description>arXiv:2407.20128v2 Announce Type: replace 
Abstract: We study best-response type learning dynamics for two player zero-sum matrix games. We consider two settings that are distinguished by the type of information that each player has about the game and their opponent's strategy. The first setting is the full information case, in which each player knows their own and the opponent's payoff matrices and observes the opponent's mixed strategy. The second setting is the minimal information case, where players do not observe the opponent's strategy and are not aware of either of the payoff matrices (instead they only observe their realized payoffs). For this setting, also known as the radically uncoupled case in the learning in games literature, we study a two-timescale learning dynamics that combine smoothed best-response type updates for strategy estimates with a TD-learning update to estimate a local payoff function. For these dynamics, without additional exploration, we provide polynomial-time finite-sample guarantees for convergence to an $\epsilon$-Nash equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20128v2</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fathima Zarin Faizal, Asuman Ozdaglar, Martin J. Wainwright</dc:creator>
    </item>
    <item>
      <title>On Approximating Volumes of Clipped Hypercubes</title>
      <link>https://arxiv.org/abs/2407.21365</link>
      <description>arXiv:2407.21365v2 Announce Type: replace 
Abstract: We give a method of sub-exponential complexity to approximate the volume of the intersection of the unit hypercube with two specific sets. Our method can be applied (without losing the sub-exponential complexity) to compute the volume of the hypercube intersected with a fixed number of sets, described by the equations of the form $\sum_{q=1}^n a_q(x_q) = b$, where $a_q : \mathbb{R} \to \mathbb{R}$ are polynomial functions and $b \in \mathbb{R}$. Note that the resulting sets are not necessarily convex. However, this type of equations describe, among others, half-spaces, balls and ellipsoids.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21365v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marius Costandin</dc:creator>
    </item>
    <item>
      <title>Capacity Planning in Stable Matching</title>
      <link>https://arxiv.org/abs/2110.00734</link>
      <description>arXiv:2110.00734v5 Announce Type: replace-cross 
Abstract: Motivated by the shortage of seats that the Chilean school choice system is facing, we introduce the problem of jointly increasing school capacities and finding a student-optimal assignment in the expanded market. Due to the theoretical and practical complexity of the problem, we provide a comprehensive set of tools to solve the problem, including different mathematical programming formulations, a cutting plane algorithm, and two heuristics that allow obtaining near-optimal solutions quickly. On the theoretical side, we show the correctness of our formulations, different properties of the objective and feasible region that facilitate computation, and also several properties of the underlying mechanism to find a student-optimal matching under capacity expansions. On the computational side, we use data from the Chilean school choice system to demonstrate the impact of our framework and derive insights that could help alleviate the problem. Our results show that each additional seat can benefit multiple students and that we can effectively target the assignment of previously unassigned students or improve the assignment of several students through improvement chains. Nevertheless, our results show that the marginal effect of each additional seat is decreasing and that simply adding seats is insufficient to ensure every student gets assigned to some school. Finally, we discuss several extensions of our framework, showcasing its flexibility to accommodate different needs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2110.00734v5</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Federico Bobbio, Margarida Carvalho, Andrea Lodi, Ignacio Rios, Alfredo Torrico</dc:creator>
    </item>
    <item>
      <title>Mitigating the Impact of Uncertain Wildfire Risk on Power Grids through Topology Control</title>
      <link>https://arxiv.org/abs/2303.07558</link>
      <description>arXiv:2303.07558v2 Announce Type: replace-cross 
Abstract: Wildfires pose a significant threat to the safe and reliable operations of the electric grid. To mitigate wildfire risk, system operators resort to public safety power shutoffs, or PSPS, that shed load for a subset of customers. As wildfire risk forecasts are stochastic, such decision-making may often be sub-optimal. This paper proposes a two-stage topology control problem that jointly minimizes generation and load-shedding costs in the face of uncertain fire risk. Compared to existing work, we include preand post-event topology control actions and consider scenarios where the wildfire risk is known with low and high confidence. The effectiveness of the proposed approach is demonstrated using a benchmark test system, artificially geo-located in Southern California, and using stochastic wildfire risk data that exists in the literature. Our work provides a crucial study of the comparative benefits of pre-event versus post-event control and the effects of wildfire risk accuracy on each control strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.07558v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuqi Zhou, Kaarthik Sundar, Deepjyoti Deka, Hao Zhu</dc:creator>
    </item>
    <item>
      <title>Optimization Dynamics of Equivariant and Augmented Neural Networks</title>
      <link>https://arxiv.org/abs/2303.13458</link>
      <description>arXiv:2303.13458v3 Announce Type: replace-cross 
Abstract: We investigate the optimization of neural networks on symmetric data, and compare the strategy of constraining the architecture to be equivariant to that of using data augmentation. Our analysis reveals that that the relative geometry of the admissible and the equivariant layers, respectively, plays a key role. Under natural assumptions on the data, network, loss, and group of symmetries, we show that compatibility of the spaces of admissible layers and equivariant layers, in the sense that the corresponding orthogonal projections commute, implies that the sets of equivariant stationary points are identical for the two strategies. If the linear layers of the network also are given a unitary parametrization, the set of equivariant layers is even invariant under the gradient flow for augmented models. Our analysis however also reveals that even in the latter situation, stationary points may be unstable for augmented training although they are stable for the manifestly equivariant models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.13458v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Oskar Nordenfors, Fredrik Ohlsson Axel Flinth</dc:creator>
    </item>
    <item>
      <title>Drift Control of High-Dimensional RBM: A Computational Method Based on Neural Networks</title>
      <link>https://arxiv.org/abs/2309.11651</link>
      <description>arXiv:2309.11651v4 Announce Type: replace-cross 
Abstract: Motivated by applications in queueing theory, we consider a stochastic control problem whose state space is the $d$-dimensional positive orthant. The controlled process $Z$ evolves as a reflected Brownian motion whose covariance matrix is exogenously specified, as are its directions of reflection from the orthant's boundary surfaces. A system manager chooses a drift vector $\theta(t)$ at each time $t$ based on the history of $Z$, and the cost rate at time $t$ depends on both $Z(t)$ and $\theta(t)$. In our initial problem formulation, the objective is to minimize expected discounted cost over an infinite planning horizon, after which we treat the corresponding ergodic control problem. Extending earlier work by Han et al. (Proceedings of the National Academy of Sciences, 2018, 8505-8510), we develop and illustrate a simulation-based computational method that relies heavily on deep neural network technology. For test problems studied thus far, our method is accurate to within a fraction of one percent, and is computationally feasible in dimensions up to at least $d=30$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.11651v4</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Baris Ata, J. Michael Harrison, Nian Si</dc:creator>
    </item>
    <item>
      <title>Halfway Escape Optimization: A Quantum-Inspired Solution for Complex Optimization Problems</title>
      <link>https://arxiv.org/abs/2405.02850</link>
      <description>arXiv:2405.02850v3 Announce Type: replace-cross 
Abstract: This paper first proposes the Halfway Escape Optimization (HEO) algorithm, a novel quantum-inspired metaheuristic designed to address complex optimization problems characterized by rugged landscapes and high-dimensionality with an efficient convergence rate. The study presents a comprehensive comparative evaluation of HEO's performance against established optimization algorithms, including Particle Swarm Optimization (PSO), Genetic Algorithm (GA), Artificial Fish Swarm Algorithm (AFSA), Grey Wolf Optimizer (GWO), and Quantum behaved Particle Swarm Optimization (QPSO). The primary analysis encompasses 14 benchmark functions with dimension 30, demonstrating HEO's effectiveness and adaptability in navigating complex optimization landscapes and providing valuable insights into its performance. The simple test of HEO in Traveling Salesman Problem (TSP), Pressure Vessel Design and Tubular Column Design infers its feasibility and potential weakness in real-time applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02850v3</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jiawen Li, Anwar PP Abdul Majeed, Pascal Lefevre</dc:creator>
    </item>
    <item>
      <title>The Road Less Scheduled</title>
      <link>https://arxiv.org/abs/2405.15682</link>
      <description>arXiv:2405.15682v3 Announce Type: replace-cross 
Abstract: Existing learning rate schedules that do not require specification of the optimization stopping step T are greatly out-performed by learning rate schedules that depend on T. We propose an approach that avoids the need for this stopping time by eschewing the use of schedules entirely, while exhibiting state-of-the-art performance compared to schedules across a wide family of problems ranging from convex problems to large-scale deep learning problems. Our Schedule-Free approach introduces no additional hyper-parameters over standard optimizers with momentum. Our method is a direct consequence of a new theory we develop that unifies scheduling and iterate averaging. An open source implementation of our method is available (https://github.com/facebookresearch/schedule_free).</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15682v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aaron Defazio, Xingyu Alice Yang, Harsh Mehta, Konstantin Mishchenko, Ahmed Khaled, Ashok Cutkosky</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning for Jump-Diffusions, with Financial Applications</title>
      <link>https://arxiv.org/abs/2405.16449</link>
      <description>arXiv:2405.16449v2 Announce Type: replace-cross 
Abstract: We study continuous-time reinforcement learning (RL) for stochastic control in which system dynamics are governed by jump-diffusion processes. We formulate an entropy-regularized exploratory control problem with stochastic policies to capture the exploration--exploitation balance essential for RL. Unlike the pure diffusion case initially studied by Wang et al. (2020), the derivation of the exploratory dynamics under jump-diffusions calls for a careful formulation of the jump part. Through a theoretical analysis, we find that one can simply use the same policy evaluation and $q$-learning algorithms in Jia and Zhou (2022a, 2023), originally developed for controlled diffusions, without needing to check a priori whether the underlying data come from a pure diffusion or a jump-diffusion. However, we show that the presence of jumps ought to affect parameterizations of actors and critics in general. We investigate as an application the mean--variance portfolio selection problem with stock price modelled as a jump-diffusion, and show that both RL algorithms and parameterizations are invariant with respect to jumps. Finally, we present a detailed study on applying the general theory to option hedging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16449v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuefeng Gao, Lingfei Li, Xun Yu Zhou</dc:creator>
    </item>
    <item>
      <title>Exploiting Structure in Quantum Relative Entropy Programs</title>
      <link>https://arxiv.org/abs/2407.00241</link>
      <description>arXiv:2407.00241v2 Announce Type: replace-cross 
Abstract: Quantum relative entropy programs are convex optimization problems which minimize a linear functional over an affine section of the epigraph of the quantum relative entropy function. Recently, the self-concordance of a natural barrier function was proved for this set. This has opened up the opportunity to use interior-point methods for nonsymmetric cone programs to solve these optimization problems. In this paper, we show how common structures arising from applications in quantum information theory can be exploited to improve the efficiency of solving quantum relative entropy programs using interior-point methods. First, we show that the natural barrier function for the epigraph of the quantum relative entropy composed with positive linear operators is optimally self-concordant, even when these linear operators map to singular matrices. Compared to modelling problems using the full quantum relative entropy cone, this allows us to remove redundant log determinant expressions from the barrier function and reduce the overall barrier parameter. Second, we show how certain slices of the quantum relative entropy cone exhibit useful properties which should be exploited whenever possible to perform certain key steps of interior-point methods more efficiently. We demonstrate how these methods can be applied to applications in quantum information theory, including quantifying quantum key rates, quantum rate-distortion functions, quantum channel capacities, and the ground state energy of Hamiltonians. Our numerical results show that these techniques improve computation times by up to several orders of magnitude, and allow previously intractable problems to be solved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00241v2</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kerry He, James Saunderson, Hamza Fawzi</dc:creator>
    </item>
  </channel>
</rss>
