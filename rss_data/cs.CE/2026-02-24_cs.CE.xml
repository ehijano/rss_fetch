<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 24 Feb 2026 05:00:20 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Universal Basic Income with Time-Decaying Currency: Structural Effects on Essential Labor and Long-Term Formation</title>
      <link>https://arxiv.org/abs/2602.18714</link>
      <description>arXiv:2602.18714v1 Announce Type: new 
Abstract: Time-decaying currencies have long been discussed in economic theory as a means to discourage hoarding and promote circulation. However, their modern digital implementation as a universal basic income (UBI) mechanism raises unresolved structural questions regarding labor participation and long-term social reproduction. In this study, we analyze a dual-currency model in which a time-decaying currency is distributed exclusively as UBI, while labor income and savings are denominated in a standard currency. Through agent-based simulations, we identify the acceptance ratio of the time-decaying currency for necessities as a critical design parameter. Our results show that essential labor does not necessarily collapse under such a system. Nevertheless, beyond a threshold acceptance ratio, delayed labor participation and weakened human capital formation emerge even in the absence of material deprivation. These findings suggest that time-decaying currency can stabilize short-term living conditions while distorting long-term formation incentives, depending on system design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.18714v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hitoshi Yamada</dc:creator>
    </item>
    <item>
      <title>Learning Adaptive Perturbation-Conditioned Contexts for Robust Transcriptional Response Prediction</title>
      <link>https://arxiv.org/abs/2602.18885</link>
      <description>arXiv:2602.18885v1 Announce Type: new 
Abstract: Predicting high-dimensional transcriptional responses to genetic perturbations is challenging due to severe experimental noise and sparse gene-level effects. Existing methods often suffer from mean collapse, where high correlation is achieved by predicting global average expression rather than perturbation-specific responses, leading to many false positives and limited biological interpretability. Recent approaches incorporate biological knowledge graphs into perturbation models, but these graphs are typically treated as dense and static, which can propagate noise and obscure true perturbation signals. We propose AdaPert, a perturbation-conditioned framework that addresses mean collapse by explicitly modeling sparsity and biological structure. AdaPert learns perturbation-specific subgraphs from biological knowledge graphs and applies adaptive learning to separate true signals from noise. Across multiple genetic perturbation benchmarks, AdaPert consistently outperforms existing baselines and achieves substantial improvements on DEG-aware evaluation metrics, indicating more accurate recovery of perturbation-specific transcriptional changes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.18885v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yinhua Piao, Hyomin Kim, Seonghwan Kim, Yunhak Oh, Junhyeok Jeon, Sang-Yeon Hwang, Jaechang Lim, Woo Youn Kim, Chanyoung Park, Sungsoo Ahn</dc:creator>
    </item>
    <item>
      <title>Dual-Kernel Adapter: Expanding Spatial Horizons for Data-Constrained Medical Image Analysis</title>
      <link>https://arxiv.org/abs/2602.18888</link>
      <description>arXiv:2602.18888v1 Announce Type: new 
Abstract: Adapters have become a widely adopted strategy for efficient fine-tuning of large pretrained models, particularly in resource-constrained settings. However, their performance under extreme data scarcity, common in medical imaging due to high annotation costs, privacy regulations, and fragmented datasets, remains underexplored. In this work, we present the first comprehensive study of adapter-based fine-tuning for large pretrained models in low-data medical imaging scenarios. We find that, contrary to their promise, conventional adapters can degrade performance under severe data constraints, performing even worse than simple linear probing when trained on less than 1% of the corresponding training data. Through systematic analysis, we identify a sharp reduction in Effective Receptive Field (ERF) as a key factor behind this degradation. Motivated by these findings, we propose the Dual-Kernel Adapter (DKA), a lightweight module that expands spatial context via large-kernel convolutions while preserving local detail with small-kernel counterparts. Extensive experiments across diverse classification and segmentation benchmarks show that DKA significantly outperforms existing adapter methods, establishing new leading results in both data-constrained and data-rich regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.18888v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziquan Zhu, Hanruo Zhu, Siyuan Lu, Xiang Li, Yanda Meng, Gaojie Jin, Lu Yin, Lijie Hu, Di Wang, Lu Liu, Tianjin Huang</dc:creator>
    </item>
    <item>
      <title>Evaluation and Benchmarking Suite for Financial Large Language Models and Agents</title>
      <link>https://arxiv.org/abs/2602.19073</link>
      <description>arXiv:2602.19073v1 Announce Type: new 
Abstract: Over the past three years, the financial services industry has witnessed Large Language Models (LLMs) and agents transitioning from the exploration stage to readiness and governance stages. Financial large language models (FinLLMs), such as open FinGPT and proprietary BloombergGPT , have great potential in financial applications, including retrieving real-time data, tutoring, analyzing sentiment of social media, analyzing SEC filings, and agentic trading. However, general-purpose LLMs and agents lack financial expertise and often struggle to handle complex financial reasoning. This paper presents an evaluation and benchmarking suite that covers the lifecycle of FinLLMs and FinAgents. This suite led by SecureFinAI Lab includes an evaluation pipeline and a governance framework collaborating with Linux Foundation and PyTorch Foundation, a FinLLM Leaderboard with HuggingFace, an AgentOps framework with Red Hat, and a documentation website with Rensselear Center of Open Source. Our collaborative development evolves through three stages: FinLLM Exploration (2023), FinLLM Readiness (2024), and FinAI Governance (2025). The proposed suite serves as an open platform that enables researchers and practitioners to perform both quantitative and qualitative analysis of different FinLLMs and FinAgents, fostering a more robust and reliable FinAI ecosystem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19073v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shengyuan Lin, Kaiwen He, Jaisal Patel, Qinchuan Zhang, Chris Ding, James Tang, Keyi Wang, Yupeng Cao, Yan Wang, Kairong Xiao, Vincent Caldeira, Matt White, Xiao-Yang Liu Yanglet</dc:creator>
    </item>
    <item>
      <title>Scale-PINN: Learning Efficient Physics-Informed Neural Networks Through Sequential Correction</title>
      <link>https://arxiv.org/abs/2602.19475</link>
      <description>arXiv:2602.19475v1 Announce Type: new 
Abstract: Physics-informed neural networks (PINNs) have emerged as a promising mesh-free paradigm for solving partial differential equations, yet adoption in science and engineering is limited by slow training and modest accuracy relative to modern numerical solvers. We introduce the Sequential Correction Algorithm for Learning Efficient PINN (Scale-PINN), a learning strategy that bridges modern physics-informed learning with numerical algorithms. Scale-PINN incorporates the iterative residual-correction principle, a cornerstone of numerical solvers, directly into the loss formulation, marking a paradigm shift in how PINN losses can be conceived and constructed. This integration enables Scale-PINN to achieve unprecedented convergence speed across PDE problems from different physics domain, including reducing training time on a challenging fluid-dynamics problem for state-of-the-art PINN from hours to sub-2 minutes while maintaining superior accuracy, and enabling application to representative problems in aerodynamics and urban science. By uniting the rigor of numerical methods with the flexibility of deep learning, Scale-PINN marks a significant leap toward the practical adoption of PINNs in science and engineering through scalable, physics-informed learning. Codes are available at https://github.com/chiuph/SCALE-PINN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19475v1</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pao-Hsiung Chiu, Jian Cheng Wong, Chin Chun Ooi, Chang Wei, Yuchen Fan, Yew-Soon Ong</dc:creator>
    </item>
    <item>
      <title>Pixel2Phys: Distilling Governing Laws from Visual Dynamics</title>
      <link>https://arxiv.org/abs/2602.19516</link>
      <description>arXiv:2602.19516v1 Announce Type: new 
Abstract: Discovering physical laws directly from high-dimensional visual data is a long-standing human pursuit but remains a formidable challenge for machines, representing a fundamental goal of scientific intelligence. This task is inherently difficult because physical knowledge is low-dimensional and structured, whereas raw video observations are high-dimensional and redundant, with most pixels carrying little or no physical meaning. Extracting concise, physically relevant variables from such noisy data remains a key obstacle. To address this, we propose Pixel2Phys, a collaborative multi-agent framework adaptable to any Multimodal Large Language Model (MLLM). It emulates human scientific reasoning by employing a structured workflow to extract formalized physical knowledge through iterative hypothesis generation, validation, and refinement. By repeatedly formulating, and refining candidate equations on high-dimensional data, it identifies the most concise representations that best capture the underlying physical evolution. This automated exploration mimics the iterative workflow of human scientists, enabling AI to reveal interpretable governing equations directly from raw observations. Across diverse simulated and real-world physics videos, Pixel2Phys discovers accurate, interpretable governing equations and maintaining stable long-term extrapolation where baselines rapidly diverge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19516v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruikun Li, Jun Yao, Yingfan Hua, Shixiang Tang, Biqing Qi, Bin Liu, Wanli Ouyang, Yan Lu</dc:creator>
    </item>
    <item>
      <title>Neural Markov chain Monte Carlo: Bayesian inversion via normalizing flows and variational autoencoders</title>
      <link>https://arxiv.org/abs/2602.19597</link>
      <description>arXiv:2602.19597v1 Announce Type: new 
Abstract: This paper introduces a Bayesian framework that combines Markov chain Monte Carlo (MCMC) sampling, dimensionality reduction, and neural density estimation to efficiently handle inverse problems that (i) must be solved multiple times, and (ii) are characterized by intractable or unavailable likelihood functions. The posterior probability distribution over quantities of interest is estimated via differential evolution Metropolis sampling, empowered by learnable mappings. First, a variational autoencoder performs probabilistic feature extraction from observational data. The resulting latent structure inherently quantifies uncertainty, capturing deviations between the actual data-generating process and the training data distribution. At each step of the MCMC random walk, the algorithm jointly samples from the data-informed latent distribution and the space of parameters to be inferred. These samples are fed into a neural likelihood estimator based on normalizing flows, specifically real-valued non-volume preserving transformations. The scaling and translation functions of the affine coupling layers are modeled by neural networks conditioned on the unknown parameters, allowing the representation of arbitrary observation likelihoods. The proposed methodology is validated on two case studies: (i) structural health monitoring of a railway bridge for damage detection, localization, and quantification, and (ii) estimation of the conductivity field in a steady-state Darcy's groundwater flow problem. The results demonstrate the efficiency of the inference strategy, while ensuring that model-reality mismatches do not yield overconfident, yet inaccurate, estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19597v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giacomo Bottacini, Matteo Torzoni, Andrea Manzoni</dc:creator>
    </item>
    <item>
      <title>Stress-constrained Topology Optimization for Metamaterial Microstructure Design</title>
      <link>https://arxiv.org/abs/2602.19662</link>
      <description>arXiv:2602.19662v1 Announce Type: new 
Abstract: Although stress-constrained topology optimization has been extensively studied in structural design, the development of optimization frameworks to enable the creation of metamaterials with optimal mechanical performance is still an open problem. This study incorporates local stress constraints into the topology optimization framework for metamaterial microstructure design, aiming to avoid the stress concentration in the optimized microstructure. For the efficient solution of multi-constraint topology optimization problems, the Augmented Lagrangian formulation is extended to address local minimization problems subjected to the combined action of local and global constraints. Additionally, as an extension of static load conditions, this study further investigates the design of metamaterial microstructures under cyclic loading. Finally, the effectiveness of the proposed approach is demonstrated through a series of two-dimensional and three-dimensional benchmark problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19662v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yanda Chen, Sebastian Rodriguez, Beatriz Moya, Francisco Chinesta</dc:creator>
    </item>
    <item>
      <title>GPU-Native Compressed Neighbor Lists with a Space-Filling-Curve Data Layout</title>
      <link>https://arxiv.org/abs/2602.19873</link>
      <description>arXiv:2602.19873v1 Announce Type: new 
Abstract: We have developed a compressed neighbor list for short-range particle-particle interaction based on a space- filling curve (SFC) memory layout and particle clusters. The neighbor list can be constructed efficiently on GPUs, supporting NVIDIA and AMD hardware, and has a memory footprint of only 4 bytes per particle to store approximately 200 neighbors. Compared to the highly-optimized domain-specific neighbor list implementation of GROMACS, a molecular dynamics code, it has a comparable cluster overhead and delivers similar performance in a neighborhood pass. Thanks to the SFC-based data layout and the support for varying interaction radii per particle, our neighbor list performs well for systems with high density contrasts, such as those encountered in many astrophysical and cosmological applications. Due to the close relation between SFCs and octrees, our neighbor list seamlessly integrates with octree-based domain decomposition and multipole-based methods for long-range gravitational or electrostatic interactions. To demonstrate the coupling between long- and short-range forces, we simulate an Evrard collapse, a standard test case for the coupling between hydrodynamical and gravitational forces, on up to 1024 GPUs, and compare our results to the analytical solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19873v1</guid>
      <category>cs.CE</category>
      <category>astro-ph.IM</category>
      <category>cs.DS</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Felix Thaler, Sebastian Keller</dc:creator>
    </item>
    <item>
      <title>Updating DMD Operators for Changes in Domain Properties</title>
      <link>https://arxiv.org/abs/2602.18441</link>
      <description>arXiv:2602.18441v1 Announce Type: cross 
Abstract: Fast and reliable surrogate models are critical for optimization, control and uncertainty analysis in geological carbon-storage projects, yet high-fidelity multiphase simulators remain too expensive. Dynamic Mode Decomposition (DMD) offers an attractive data-driven reduction framework, but its operators are trained for a single set of reservoir properties. When permeability or well location changes, conventional practice is to regenerate snapshots and retrain the surrogate, erasing most of the speed advantage. This work presents a lightweight alternative that updates an existing DMD or DMD-with-control model without incorporating new simulation data or retraining. Two complementary update strategies are introduced. For cases where permeability changes uniformly across the domain, the proposed updates adjust the models internal dynamics and control response to match the new flow timescale. When permeability varies in space, the approach modifies the spatial representation so that high-permeability zones are given greater influence on the models reduced basis. Numerical experiments demonstrate that the proposed updates recover plume migration and pressure build-up within three percent of a freshly trained surrogate yet execute hundreds of times faster than full retraining. These methods therefore enable real-time optimization and rapid what-if studies while preserving the physical fidelity demanded by carbon-storage workflows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.18441v1</guid>
      <category>physics.comp-ph</category>
      <category>cs.CE</category>
      <category>math.OC</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.13140/RG.2.2.21682.06083</arxiv:DOI>
      <dc:creator>Dimitrios Voulanas, Eduardo Gildin</dc:creator>
    </item>
    <item>
      <title>An Interpretable Data-Driven Model of the Flight Dynamics of Hawks</title>
      <link>https://arxiv.org/abs/2602.19196</link>
      <description>arXiv:2602.19196v1 Announce Type: cross 
Abstract: Despite significant analysis of bird flight, generative physics models for flight dynamics do not currently exist. Yet the underlying mechanisms responsible for various flight manoeuvres are important for understanding how agile flight can be accomplished. Even in a simple flight, multiple objectives are at play, complicating analysis of the overall flight mechanism. Using the data-driven method of dynamic mode decomposition (DMD) on motion capture recordings of hawks, we show that multiple behavioral states such as flapping, turning, landing, and gliding, can be modeled by simple and interpretable modal structures (i.e. the underlying wing-tail shape) which can be linearly combined to reproduce the experimental flight observations. Moreover, the DMD model can be used to extrapolate naturalistic flapping. Flight is highly individual, with differences in style across the hawks, but we find they share a common set of dynamic modes. The DMD model is a direct fit to data, unlike traditional models constructed from physics principles which can rarely be tested on real data and whose assumptions are typically invalid in real flight. The DMD approach gives a highly accurate reconstruction of the flight dynamics with only three parameters needed to characterize flapping, and a fourth to integrate turning manoeuvres. The DMD analysis further shows that the underlying mechanism of flight, much like simplest walking models, displays a parametric coupling between dominant modes suggesting efficiency for locomotion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19196v1</guid>
      <category>q-bio.QM</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>physics.flu-dyn</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lydia France, Karl Lapo, J. Nathan Kutz</dc:creator>
    </item>
    <item>
      <title>Classroom Final Exam: An Instructor-Tested Reasoning Benchmark</title>
      <link>https://arxiv.org/abs/2602.19517</link>
      <description>arXiv:2602.19517v1 Announce Type: cross 
Abstract: We introduce \CFE{} (\textbf{C}lassroom \textbf{F}inal \textbf{E}xam), a multimodal benchmark for evaluating the reasoning capabilities of large language models across more than 20 STEM domains. \CFE{} is curated from repeatedly used, authentic university homework and exam problems, together with reference solutions provided by course instructors. \CFE{} presents a significant challenge even for frontier models: the newly released Gemini-3.1-pro-preview achieves an overall accuracy of 59.69\%, while the second-best model, Gemini-3-flash-preview, reaches 55.46\%, leaving considerable room for improvement. Beyond leaderboard results, we perform a diagnostic analysis by decomposing reference solutions into reasoning flows. We find that although frontier models can often answer intermediate sub-questions correctly, they struggle to reliably derive and maintain correct intermediate states throughout multi-step solutions. We further observe that model-generated solutions typically have more reasoning steps than those provided by the instructor, indicating suboptimal step efficiency and a higher risk of error accumulation. The data and code are available at https://github.com/Analogy-AI/CFE_Bench.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19517v1</guid>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.CL</category>
      <category>cs.CV</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chongyang Gao, Diji Yang, Shuyan Zhou, Xichen Yan, Luchuan Song, Shuo Li, Kezhen Chen</dc:creator>
    </item>
    <item>
      <title>Metaorder modelling and identification from public data</title>
      <link>https://arxiv.org/abs/2602.19590</link>
      <description>arXiv:2602.19590v1 Announce Type: cross 
Abstract: Market-order flow in financial markets exhibits long-range correlations. This is a widely known stylised fact of financial markets. A popular hypothesis for this stylised fact comes from the Lillo-Mike-Farmer (LMF) order-splitting theory. However, quantitative tests of this theory have historically relied on proprietary datasets with trader identifiers, limiting reproducibility and cross-market validation. We show that the LMF theory can be validated using publicly available Johannesburg Stock Exchange (JSE) data by leveraging recently developed methods for reconstructing synthetic metaorders. We demonstrate the validation using 3 years of Transaction and Quote Data (TAQ) for the largest 100 stocks on the JSE when assuming that there are either N=50 or N=150 effective traders managing metaorders in the market.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19590v1</guid>
      <category>q-fin.TR</category>
      <category>cs.CE</category>
      <category>q-fin.ST</category>
      <category>stat.CO</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ezra Goliath, Tim Gebbie</dc:creator>
    </item>
    <item>
      <title>Textual semantics and machine learning methods for data product pricing</title>
      <link>https://arxiv.org/abs/2511.22185</link>
      <description>arXiv:2511.22185v2 Announce Type: replace 
Abstract: Reasonable pricing of data products enables data trading platforms to maximize revenue and foster the growth of the data trading market. The textual semantics of data products are vital for pricing and contain significant value that remains largely underexplored. Therefore, to investigate how textual features influence data product pricing, we employ five prevalent text representation techniques to encode the descriptive text of data products. And then, we employ six machine learning methods to predict data product prices, including linear regression, neural networks, decision trees, support vector machines, random forests, and XGBoost. Our empirical design consists of two tasks: a regression task that predicts the continuous price of data products, and a classification task that discretizes price into ordered categories. Furthermore, we conduct feature importance analysis by the mRMR feature selection method and SHAP-based interpretability techniques. Based on empirical data from the AWA Data Exchange, we find that for predicting continuous prices, Word2Vec text representations capturing semantic similarity yield superior performance. In contrast, for price-tier classification tasks, simpler representations that do not rely on semantic similarity, such as Bag-of-Words and TF-IDF, perform better. SHAP analysis reveals that semantic features related to healthcare and demographics tend to increase prices, whereas those associated with weather and environmental topics are linked to lower prices. This analytical framework significantly enhances the interpretability of pricing models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22185v2</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.4310/RME.260221154937</arxiv:DOI>
      <dc:creator>Ruize Gao, Feng Xiao, Jinpu Li, Shaoze Cui</dc:creator>
    </item>
    <item>
      <title>Robust Time Series Causal Discovery for Agent-Based Model Validation</title>
      <link>https://arxiv.org/abs/2410.19412</link>
      <description>arXiv:2410.19412v3 Announce Type: replace-cross 
Abstract: Agent-Based Model (ABM) validation is crucial as it helps ensuring the reliability of simulations, and causal discovery has become a powerful tool in this context. However, current causal discovery methods often face accuracy and robustness challenges when applied to complex and noisy time series data, which is typical in ABM scenarios. This study addresses these issues by proposing a Robust Cross-Validation (RCV) approach to enhance causal structure learning for ABM validation. We develop RCV-VarLiNGAM and RCV-PCMCI, novel extensions of two prominent causal discovery algorithms. These aim to reduce the impact of noise better and give more reliable causal relation results, even with high-dimensional, time-dependent data. The proposed approach is then integrated into an enhanced ABM validation framework, which is designed to handle diverse data and model structures.
  The approach is evaluated using synthetic datasets and a complex simulated fMRI dataset. The results demonstrate greater reliability in causal structure identification. The study examines how various characteristics of datasets affect the performance of established causal discovery methods. These characteristics include linearity, noise distribution, stationarity, and causal structure density. This analysis is then extended to the RCV method to see how it compares in these different situations. This examination helps confirm whether the results are consistent with existing literature and also reveals the strengths and weaknesses of the novel approaches.
  By tackling key methodological challenges, the study aims to enhance ABM validation with a more resilient valuation framework presented. These improvements increase the reliability of model-driven decision making processes in complex systems analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19412v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>econ.EM</category>
      <category>stat.CO</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gene Yu, Ce Guo, Wayne Luk</dc:creator>
    </item>
    <item>
      <title>Optimality in importance sampling: a gentle survey</title>
      <link>https://arxiv.org/abs/2502.07396</link>
      <description>arXiv:2502.07396v2 Announce Type: replace-cross 
Abstract: The performance of the Monte Carlo sampling methods relies on the crucial choice of a proposal density. The notion of optimality is fundamental to design suitable adaptive procedures of the proposal density within Monte Carlo schemes. This work is an exhaustive review around the concept of optimality in importance sampling. Several frameworks are described and analyzed, such as the marginal likelihood approximation for model selection, the use of multiple proposal densities, a sequence of tempered posteriors, and noisy scenarios including the applications to approximate Bayesian computation (ABC) and reinforcement learning, to name a few. Some theoretical and empirical comparisons are also provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07396v2</guid>
      <category>stat.CO</category>
      <category>cs.CE</category>
      <category>stat.ML</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fernando Llorente, Luca Martino</dc:creator>
    </item>
    <item>
      <title>Physics vs Distributions: Pareto Optimal Flow Matching with Physics Constraints</title>
      <link>https://arxiv.org/abs/2506.08604</link>
      <description>arXiv:2506.08604v4 Announce Type: replace-cross 
Abstract: Physics-constrained generative modeling aims to produce high-dimensional samples that are both physically consistent and distributionally accurate, a task that remains challenging due to often conflicting optimization objectives. Recent advances in flow matching and diffusion models have enabled efficient generative modeling, but integrating physical constraints often degrades generative fidelity or requires costly inference-time corrections. Our work is the first to recognize the trade-off between distributional and physical accuracy. Based on the insight of inherently conflicting objectives, we introduce Physics-Based Flow Matching (PBFM) a method that enforces physical constraints at training time using conflict-free gradient updates and unrolling to mitigate Jensen's gap. Our approach avoids manual loss balancing and enables simultaneous optimization of generative and physical objectives. As a consequence, physics constraints do not impede inference performance. We benchmark our method across three representative PDE benchmarks. PBFM achieves a Pareto-optimal trade-off, competitive inference speed, and generalizes to a wide range of physics-constrained generative tasks, providing a practical tool for scientific machine learning. Code and datasets available at https://github.com/tum-pbs/PBFM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08604v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giacomo Baldan, Qiang Liu, Alberto Guardone, Nils Thuerey</dc:creator>
    </item>
    <item>
      <title>Foundation and Large-Scale AI Models in Neuroscience: A Comprehensive Review</title>
      <link>https://arxiv.org/abs/2510.16658</link>
      <description>arXiv:2510.16658v2 Announce Type: replace-cross 
Abstract: The development of large-scale artificial intelligence (AI) models is influencing neuroscience research by enabling end-to-end learning from raw brain signals and neural data. In this paper, we review applications of large-scale AI models across five major neuroscience domains: neuroimaging and data processing, brain-computer interfaces and neural decoding, clinical decision support and translational frameworks, and disease-specific applications across neurological and psychiatric disorders. These models show potential to address major computational neuroscience challenges, including multimodal neural data integration, spatiotemporal pattern interpretation, and the development of translational frameworks for clinical research. Moreover, the interaction between neuroscience and AI has become increasingly reciprocal, as biologically informed architectural constraints are now incorporated to develop more interpretable and computationally efficient models. This review highlights both the promise of such technologies and critical implementation considerations, with particular emphasis on rigorous evaluation frameworks, effective integration of domain knowledge, prospective clinical validation, and comprehensive ethical guidelines. Finally, a systematic listing of critical neuroscience datasets used to develop and evaluate large-scale AI models across diverse research applications is provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16658v2</guid>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shihao Yang, Xiying Huang, Danilo Bernardo, Jun-En Ding, Andrew Michael, Jingmei Yang, Patrick Kwan, Ashish Raj, Feng Liu</dc:creator>
    </item>
    <item>
      <title>Graph Neural Network Assisted Genetic Algorithm for Structural Dynamic Response and Parameter Optimization</title>
      <link>https://arxiv.org/abs/2510.22839</link>
      <description>arXiv:2510.22839v3 Announce Type: replace-cross 
Abstract: The optimization of structural parameters, such as mass(m), stiffness(k), and damping coefficient(c), is critical for designing efficient, resilient, and stable structures. Conventional numerical approaches, including Finite Element Method (FEM) and Computational Fluid Dynamics (CFD) simulations, provide high-fidelity results but are computationally expensive for iterative optimization tasks, as each evaluation requires solving the governing equations for every parameter combination. This study proposes a hybrid data-driven framework that integrates a Graph Neural Network (GNN) surrogate model with a Genetic Algorithm (GA) optimizer to overcome these challenges. The GNN is trained to accurately learn the nonlinear mapping between structural parameters and dynamic displacement responses, enabling rapid predictions without repeatedly solving the system equations. A dataset of single-degree-of-freedom (SDOF) system responses is generated using the Newmark Beta method across diverse mass, stiffness, and damping configurations. The GA then searches for globally optimal parameter sets by minimizing predicted displacements and enhancing dynamic stability. Results demonstrate that the GNN and GA framework achieves strong convergence, robust generalization, and significantly reduced computational cost compared to conventional simulations. This approach highlights the effectiveness of combining machine learning surrogates with evolutionary optimization for automated and intelligent structural design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22839v3</guid>
      <category>cs.NE</category>
      <category>cs.CE</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sagnik Mukherjee, Indrajit Barua</dc:creator>
    </item>
    <item>
      <title>Buy versus Build an LLM: A Decision Framework for Governments</title>
      <link>https://arxiv.org/abs/2602.13033</link>
      <description>arXiv:2602.13033v2 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) represent a new frontier of digital infrastructure that can support a wide range of public-sector applications, from general purpose citizen services to specialized and sensitive state functions. When expanding AI access, governments face a set of strategic choices over whether to buy existing services, build domestic capabilities, or adopt hybrid approaches across different domains and use cases. These are critical decisions especially when leading model providers are often foreign corporations, and LLM outputs are increasingly treated as trusted inputs to public decision-making and public discourse. In practice, these decisions are not intended to mandate a single approach across all domains; instead, national AI strategies are typically pluralistic, with sovereign, commercial and open-source models coexisting to serve different purposes. Governments may rely on commercial models for non-sensitive or commodity tasks, while pursuing greater control for critical, high-risk or strategically important applications.
  This paper provides a strategic framework for making this decision by evaluating these options across dimensions including sovereignty, safety, cost, resource capability, cultural fit, and sustainability. Importantly, "building" does not imply that governments must act alone: domestic capabilities may be developed through public research institutions, universities, state-owned enterprises, joint ventures, or broader national ecosystems. By detailing the technical requirements and practical challenges of each pathway, this work aims to serve as a reference for policy-makers to determine whether a buy or build approach best aligns with their specific national needs and societal goals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13033v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.CL</category>
      <category>cs.SI</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiahao Lu, Ziwei Xu, William Tjhi, Junnan Li, Antoine Bosselut, Pang Wei Koh, Mohan Kankanhalli</dc:creator>
    </item>
    <item>
      <title>Refine Now, Query Fast: A Decoupled Refinement Paradigm for Implicit Neural Fields</title>
      <link>https://arxiv.org/abs/2602.15155</link>
      <description>arXiv:2602.15155v2 Announce Type: replace-cross 
Abstract: Implicit Neural Representations (INRs) have emerged as promising surrogates for large 3D scientific simulations due to their ability to continuously model spatial and conditional fields, yet they face a critical fidelity-speed dilemma: deep MLPs suffer from high inference cost, while efficient embedding-based models lack sufficient expressiveness. To resolve this, we propose the Decoupled Representation Refinement (DRR) architectural paradigm. DRR leverages a deep refiner network, alongside non-parametric transformations, in a one-time offline process to encode rich representations into a compact and efficient embedding structure. This approach decouples slow neural networks with high representational capacity from the fast inference path. We introduce DRR-Net, a simple network that validates this paradigm, and a novel data augmentation strategy, Variational Pairs (VP) for improving INRs under complex tasks like high-dimensional surrogate modeling. Experiments on several ensemble simulation datasets demonstrate that our approach achieves state-of-the-art fidelity, while being up to 27$\times$ faster at inference than high-fidelity baselines and remaining competitive with the fastest models. The DRR paradigm offers an effective strategy for building powerful and practical neural field surrogates and \rev{INRs in broader applications}, with a minimal compromise between speed and quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15155v2</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>cs.CV</category>
      <category>cs.GR</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tianyu Xiong, Skylar Wurster, Han-Wei Shen</dc:creator>
    </item>
  </channel>
</rss>
