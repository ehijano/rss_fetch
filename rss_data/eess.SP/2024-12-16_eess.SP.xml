<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 16 Dec 2024 05:00:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Online Adaptive Real-Time Beamforming Design for Dynamic Environments in Cell-Free Systems</title>
      <link>https://arxiv.org/abs/2412.09629</link>
      <description>arXiv:2412.09629v1 Announce Type: new 
Abstract: In this paper, we consider real-time beamforming design for dynamic wireless environments with varying channels and different numbers of access points (APs) and users in cell-free systems. Specifically, a sum-rate maximization optimization problem is formulated for the beamforming design in dynamic wireless environments of cell-free systems. To efficiently solve it, a high-generalization network (HGNet) is proposed to adapt to the changing numbers of APs and users. Then, a high-generalization beamforming module is also designed in HGNet to extract the valuable features for the varying channels, and we theoretically prove that such a high-generalization beamforming module is able to reduce the upper bound of the generalization error. Subsequently, by online adaptively updating about 3% of the parameters of HGNet, an online adaptive updating (OAU) algorithm is proposed to enable the online adaptive real-time beamforming design for improving the sum rate. Numerical results demonstrate that the proposed HGNet with OAU algorithm achieves a higher sum rate with a lower computational cost on the order of milliseconds, thus realizing the real-time beamforming design for dynamic wireless environments in cell-free systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09629v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guanghui Chen, Zheng Wang, Hongxin Lin, Pengguang Du, Yongming Huang</dc:creator>
    </item>
    <item>
      <title>A Novel Wavelet-base Algorithm for Reconstruction of the Time-Domain Impulse Response from Band-limited Scattering Parameters with Applications</title>
      <link>https://arxiv.org/abs/2412.09633</link>
      <description>arXiv:2412.09633v1 Announce Type: new 
Abstract: In this paper, we introduce a novel waveletbased algorithm for reconstructing time-domain impulse responses from band-limited scattering parameters (frequencydomain data) with a particular focus on ship hull applications. We establish the algorithm and demonstrate its convergence, as well as its efficiency for a class of functions that can be expanded as exponential functions. We provide simulation results to validate our numerical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09633v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shantia Yarahmadian, Maryam Rahmani, Michael Mazzola</dc:creator>
    </item>
    <item>
      <title>Importance Sampling With Stochastic Particle Flow and Diffusion Optimization</title>
      <link>https://arxiv.org/abs/2412.09778</link>
      <description>arXiv:2412.09778v1 Announce Type: new 
Abstract: Particle flow (PFL) is an effective method for overcoming particle degeneracy, the main limitation of particle filtering. In PFL, particles are migrated towards regions of high likelihood based on the solution of a partial differential equation. Recently proposed stochastic PFL introduces a diffusion term in the ordinary differential equation (ODE) that describes particle motion. This diffusion term reduces the stiffness of the ODE and makes it possible to perform PFL with a lower number of numerical integration steps compared to traditional deterministic PFL. In this work, we introduce a general approach to perform importance sampling (IS) based on stochastic PFL. Our method makes it possible to evaluate a "flow-induced" proposal probability density function (PDF) after the parameters of a Gaussian mixture model (GMM) have been migrated by stochastic PFL. Compared to conventional stochastic PFL, the resulting processing step is asymptotically optimal. Within our method, it is possible to optimize the diffusion matrix that describes the diffusion term of the ODE to improve the accuracy-computational complexity tradeoff. Our simulation results in a highly nonlinear 3-D source localization scenario showcase a reduced stiffness of the ODE and an improved estimating accuracy compared to state-of-the-art deterministic and stochastic PFL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09778v1</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenyu Zhang, Mohammad J. Khojasteh, Nikolay A. Atanasov, Florian Meyer</dc:creator>
    </item>
    <item>
      <title>AI and Deep Learning for THz Ultra-Massive MIMO: From Model-Driven Approaches to Foundation Models</title>
      <link>https://arxiv.org/abs/2412.09839</link>
      <description>arXiv:2412.09839v1 Announce Type: new 
Abstract: In this paper, we explore the potential of artificial intelligence (AI) to address the challenges posed by terahertz ultra-massive multiple-input multiple-output (THz UM-MIMO) systems. We begin by outlining the characteristics of THz UM-MIMO systems, and identify three primary challenges for the transceiver design: 'hard to compute', 'hard to model', and 'hard to measure'. We argue that AI can provide a promising solution to these challenges. We then propose two systematic research roadmaps for developing AI algorithms tailored for THz UM-MIMO systems. The first roadmap, called model-driven deep learning (DL), emphasizes the importance to leverage available domain knowledge and advocates for adopting AI only to enhance the bottleneck modules within an established signal processing or optimization framework. We discuss four essential steps to make it work, including algorithmic frameworks, basis algorithms, loss function design, and neural architecture design. Afterwards, we present a forward-looking vision through the second roadmap, i.e., physical layer foundation models. This approach seeks to unify the design of different transceiver modules by focusing on their common foundation, i.e., the wireless channel. We propose to train a single, compact foundation model to estimate the score function of wireless channels, which can serve as a versatile prior for designing a wide variety of transceiver modules. We will also guide the readers through four essential steps, including general frameworks, conditioning, site-specific adaptation, and the joint design of foundation models and model-driven DL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09839v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wentao Yu, Hengtao He, Shenghui Song, Jun Zhang, Linglong Dai, Lizhong Zheng, Khaled B. Letaief</dc:creator>
    </item>
    <item>
      <title>Deep Learning for Spectrum Prediction in Cognitive Radio Networks: State-of-the-Art, New Opportunities, and Challenges</title>
      <link>https://arxiv.org/abs/2412.09849</link>
      <description>arXiv:2412.09849v1 Announce Type: new 
Abstract: Spectrum prediction is considered to be a promising technology that enhances spectrum efficiency by assisting dynamic spectrum access (DSA) in cognitive radio networks (CRN). Nonetheless, the highly nonlinear nature of spectrum data across time, frequency, and space domains, coupled with the intricate spectrum usage patterns, poses challenges for accurate spectrum prediction. Deep learning (DL), recognized for its capacity to extract nonlinear features, has been applied to solve these challenges. This paper first shows the advantages of applying DL by comparing with traditional prediction methods. Then, the current state-of-the-art DL-based spectrum prediction techniques are reviewed and summarized in terms of intra-band and crossband prediction. Notably, this paper uses a real-world spectrum dataset to prove the advancements of DL-based methods. Then, this paper proposes a novel intra-band spatiotemporal spectrum prediction framework named ViTransLSTM. This framework integrates visual self-attention and long short-term memory to capture both local and global long-term spatiotemporal dependencies of spectrum usage patterns. Similarly, the effectiveness of the proposed framework is validated on the aforementioned real-world dataset. Finally, the paper presents new related challenges and potential opportunities for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09849v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guangliang Pan, David K. Y. Yau, Bo Zhou, Qihui Wu</dc:creator>
    </item>
    <item>
      <title>Data-Driven Quantification of Battery Degradation Modes via Critical Features from Charging</title>
      <link>https://arxiv.org/abs/2412.10044</link>
      <description>arXiv:2412.10044v1 Announce Type: new 
Abstract: Battery degradation modes influence the aging behavior of Li-ion batteries, leading to accelerated capacity loss and potential safety issues. Quantifying these aging mechanisms poses challenges for both online and offline diagnostics in charging station applications. Data-driven algorithms have emerged as effective tools for addressing state-of-health issues by learning hard-to-model electrochemical properties from data. This paper presents a data-driven method for quantifying battery degradation modes. Ninety-one statistical features are extracted from the incremental capacity curve derived from 1/3C charging data. These features are then screened based on dispersion, contribution, and correlation. Subsequently, machine learning models, including four baseline algorithms and a feedforward neural network, are used to estimate the degradation modes. Experimental validation indicates that the feedforward neural network outperforms the others, achieving a root mean square error of around 10\% across all three degradation modes (i.e., loss of lithium inventory, loss of active material on the positive electrode, and loss of active material on the negative electrode). The findings in this paper demonstrate the potential of machine learning for diagnosing battery degradation modes in charging station scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10044v1</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuanhao Cheng (Department of Mechanical Engineering, National University of Singapore), Hanyu Bai (Department of Mechanical Engineering, National University of Singapore), Yichen Liang (Department of Mechanical Engineering, National University of Singapore), Xiaofan Cui (Department of Electrical and Computer Engineering, University of California, Los Angeles), Weiren Jiang (Farasis Energy USA, Inc), Ziyou Song (Department of Mechanical Engineering, National University of Singapore)</dc:creator>
    </item>
    <item>
      <title>A model-based approach for transforming InSAR-derived vertical land motion from a local to a global reference frame</title>
      <link>https://arxiv.org/abs/2412.10282</link>
      <description>arXiv:2412.10282v1 Announce Type: new 
Abstract: Vertical land motion (VLM) observations obtained from Interferometric Synthetic Aperture Radar (InSAR) have transformed our understanding of crustal deformation processes over the past 3 decades. However, these observations are often related to a local reference frame, posing challenges for studies that require large-scale observations within a global reference frame, such as assessments of relative sea level rise and associated hazards. Here, we present a novel approach that enables transforming InSAR-derived VLM at any location worldwide to a global (e.g., International Terrestrial Reference Frame) reference frame without a direct need for GNSS (Global Navigation Satellite System) measurements. To this end, we employ a coarse resolution model of global VLM obtained by interpolating rates of all available GNSS stations over the global land areas. Our rationale is that the high-resolution InSAR-derived VLM data do not capture the long-wavelength signals present in the global VLM model. Therefore, we employ a set of 2D polynomial models to evaluate the difference between InSAR-derived VLM and the global model and then add it back to the InSAR-derived VLM. We examined the validity of our rationale using normalized power spectrum analysis and tested the effect of polynomial order on the accuracy of transformed VLM and the overall success of our approach using two datasets from Los Angeles and New York City. This approach improves the usability of InSAR-derived VLM in geophysical applications, including monitoring regional land subsidence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10282v1</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mahmoud Reshadati, Manoochehr Shirzaei</dc:creator>
    </item>
    <item>
      <title>Towards joint graph and sampling set selection from data</title>
      <link>https://arxiv.org/abs/2412.09753</link>
      <description>arXiv:2412.09753v1 Announce Type: cross 
Abstract: We explore the problem of sampling graph signals in scenarios where the graph structure is not predefined and must be inferred from data. In this scenario, existing approaches rely on a two-step process, where a graph is learned first, followed by sampling. More generally, graph learning and graph signal sampling have been studied as two independent problems in the literature. This work provides a foundational step towards jointly optimizing the graph structure and sampling set. Our main contribution, Vertex Importance Sampling (VIS), is to show that the sampling set can be effectively determined from the vertex importance (node weights) obtained from graph learning. We further propose Vertex Importance Sampling with Repulsion (VISR), a greedy algorithm where spatially -separated "important" nodes are selected to ensure better reconstruction. Empirical results on simulated data show that sampling using VIS and VISR leads to competitive reconstruction performance and lower complexity than the conventional two-step approach of graph learning followed by graph sampling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09753v1</guid>
      <category>cs.LG</category>
      <category>eess.IV</category>
      <category>eess.SP</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shashank N. Sridhara, Eduardo Pavez, Antonio Ortega</dc:creator>
    </item>
    <item>
      <title>Toward Foundation Model for Multivariate Wearable Sensing of Physiological Signals</title>
      <link>https://arxiv.org/abs/2412.09758</link>
      <description>arXiv:2412.09758v1 Announce Type: cross 
Abstract: Time-series foundation models have the ability to run inference, mainly forecasting, on any type of time series data, thanks to the informative representations comprising waveform features. Wearable sensing data, on the other hand, contain more variability in both patterns and frequency bands of interest and generally emphasize more on the ability to infer healthcare-related outcomes. The main challenge of crafting a foundation model for wearable sensing physiological signals is to learn generalizable representations that support efficient adaptation across heterogeneous sensing configurations and applications. In this work, we propose NormWear, a step toward such a foundation model, aiming to extract generalized and informative wearable sensing representations. NormWear has been pretrained on a large set of physiological signals, including PPG, ECG, EEG, GSR, and IMU, from various public resources. For a holistic assessment, we perform downstream evaluation on 11 public wearable sensing datasets, spanning 18 applications in the areas of mental health, body state inference, biomarker estimations, and disease risk evaluations. We demonstrate that NormWear achieves a better performance improvement over competitive baselines in general time series foundation modeling. In addition, leveraging a novel representation-alignment-match-based method, we align physiological signals embeddings with text embeddings. This alignment enables our proposed foundation model to perform zero-shot inference, allowing it to generalize to previously unseen wearable signal-based health applications. Finally, we perform nonlinear dynamic analysis on the waveform features extracted by the model at each intermediate layer. This analysis quantifies the model's internal processes, offering clear insights into its behavior and fostering greater trust in its inferences among end users.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09758v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yunfei Luo, Yuliang Chen, Asif Salekin, Tauhidur Rahman</dc:creator>
    </item>
    <item>
      <title>User Identity Protection in EEG-based Brain-Computer Interfaces</title>
      <link>https://arxiv.org/abs/2412.09854</link>
      <description>arXiv:2412.09854v1 Announce Type: cross 
Abstract: A brain-computer interface (BCI) establishes a direct communication pathway between the brain and an external device. Electroencephalogram (EEG) is the most popular input signal in BCIs, due to its convenience and low cost. Most research on EEG-based BCIs focuses on the accurate decoding of EEG signals; however, EEG signals also contain rich private information, e.g., user identity, emotion, and so on, which should be protected. This paper first exposes a serious privacy problem in EEG-based BCIs, i.e., the user identity in EEG data can be easily learned so that different sessions of EEG data from the same user can be associated together to more reliably mine private information. To address this issue, we further propose two approaches to convert the original EEG data into identity-unlearnable EEG data, i.e., removing the user identity information while maintaining the good performance on the primary BCI task. Experiments on seven EEG datasets from five different BCI paradigms showed that on average the generated identity-unlearnable EEG data can reduce the user identification accuracy from 70.01\% to at most 21.36\%, greatly facilitating user privacy protection in EEG-based BCIs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09854v1</guid>
      <category>cs.HC</category>
      <category>cs.CR</category>
      <category>eess.SP</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TNSRE.2023.3310883</arxiv:DOI>
      <arxiv:journal_reference>IEEE Trans. on Neural Systems and Rehabilitation Engineering, 31:3576-3586, 2023</arxiv:journal_reference>
      <dc:creator>L. Meng, X. Jiang, J. Huang, W. Li, H. Luo, D. Wu</dc:creator>
    </item>
    <item>
      <title>CSL-L2M: Controllable Song-Level Lyric-to-Melody Generation Based on Conditional Transformer with Fine-Grained Lyric and Musical Controls</title>
      <link>https://arxiv.org/abs/2412.09887</link>
      <description>arXiv:2412.09887v1 Announce Type: cross 
Abstract: Lyric-to-melody generation is a highly challenging task in the field of AI music generation. Due to the difficulty of learning strict yet weak correlations between lyrics and melodies, previous methods have suffered from weak controllability, low-quality and poorly structured generation. To address these challenges, we propose CSL-L2M, a controllable song-level lyric-to-melody generation method based on an in-attention Transformer decoder with fine-grained lyric and musical controls, which is able to generate full-song melodies matched with the given lyrics and user-specified musical attributes. Specifically, we first introduce REMI-Aligned, a novel music representation that incorporates strict syllable- and sentence-level alignments between lyrics and melodies, facilitating precise alignment modeling. Subsequently, sentence-level semantic lyric embeddings independently extracted from a sentence-wise Transformer encoder are combined with word-level part-of-speech embeddings and syllable-level tone embeddings as fine-grained controls to enhance the controllability of lyrics over melody generation. Then we introduce human-labeled musical tags, sentence-level statistical musical attributes, and learned musical features extracted from a pre-trained VQ-VAE as coarse-grained, fine-grained and high-fidelity controls, respectively, to the generation process, thereby enabling user control over melody generation. Finally, an in-attention Transformer decoder technique is leveraged to exert fine-grained control over the full-song melody generation with the aforementioned lyric and musical conditions. Experimental results demonstrate that our proposed CSL-L2M outperforms the state-of-the-art models, generating melodies with higher quality, better controllability and enhanced structure. Demos and source code are available at https://lichaiustc.github.io/CSL-L2M/.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09887v1</guid>
      <category>eess.AS</category>
      <category>cs.AI</category>
      <category>cs.SD</category>
      <category>eess.SP</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Li Chai, Donglin Wang</dc:creator>
    </item>
    <item>
      <title>You Can Wash Hands Better: Accurate Daily Handwashing Assessment with Smartwatches</title>
      <link>https://arxiv.org/abs/2112.06657</link>
      <description>arXiv:2112.06657v3 Announce Type: replace 
Abstract: Hand hygiene is among the most effective daily practices for preventing infectious diseases such as influenza, malaria, and skin infections. While professional guidelines emphasize proper handwashing to reduce the risk of viral infections, surveys reveal that adherence to these recommendations remains low. To address this gap, we propose UWash, a wearable solution leveraging smartwatches to evaluate handwashing procedures, aiming to raise awareness and cultivate high-quality handwashing habits. We frame the task of handwashing assessment as an action segmentation problem, similar to those in computer vision, and introduce a simple yet efficient two-stream UNet-like network to achieve this goal. Experiments involving 51 subjects demonstrate that UWash achieves 92.27% accuracy in handwashing gesture recognition, an error of &lt;0.5 seconds in onset/offset detection, and an error of &lt;5 points in gesture scoring under user-dependent settings. The system also performs robustly in user-independent and user-independent-location-independent evaluations. Remarkably, UWash maintains high performance in real-world tests, including evaluations with 10 random passersby at a hospital 9 months later and 10 passersby in an in-the-wild test conducted 2 years later. UWash is the first system to score handwashing quality based on gesture sequences, offering actionable guidance for improving daily hand hygiene. The code and dataset are publicly available at \url{https://github.com/aiotgroup/UWash}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2112.06657v3</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fei Wang, Xilei Wu, Tingting Zhang, Xin Wang, Pengcheng Wang, Han Ding, Jingang Shi, Jinsong Han, Dong Huang</dc:creator>
    </item>
    <item>
      <title>Design of stacked intelligent metasurfaces with reconfigurable amplitude and phase for multiuser downlink beamforming</title>
      <link>https://arxiv.org/abs/2408.16606</link>
      <description>arXiv:2408.16606v2 Announce Type: replace 
Abstract: A novel technology based on stacked intelligent metasurfaces (SIM) has recently emerged. This platform involves cascading multiple metasurfaces, each acting as a digitally programmable physical layer within a diffractive neural network. SIM enable the implementation of signal-processing transformations directly in the electromagnetic wave domain, eliminating the need for expensive, high-precision, and power-intensive digital platforms. However, existing studies employing SIM in wireless communication applications rely solely on nearly passive structures that control only the phase of the meta-atoms in each layer. In this study, we propose a SIM-aided downlink multiuser transmission scheme, where the SIM at the base station (BS) end is designed by combining nearly passive layers with phase-only reconfiguration capabilities and active layers integrated with amplifier chips to enable amplitude control. Our optimal design aims at maximizing the sum rate for the best group of users by jointly optimizing the transmit power allocation at the BS and the wave-based beamforming at the SIM. In addition to the standard sum-power constraint at the BS, our optimization framework includes two additional constraints: (i) a per-stream power preserving constraint to prevent propagation losses across the SIM, and (ii) an amplitude constraint to account for power limitations for each active layer. To further reduce the complexity of the optimal beamforming solution, we explore a simple yet suboptimal zero-forcing (ZF) beamforming design, where the wave-based transformation implemented by the SIM is selected to eliminate interference among user streams. Finally, extensive Monte Carlo simulations demonstrate that incorporating both nearly passive and active layers within the SIM significantly enhances capacity compared to previously reported phase-only coding SIM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16606v2</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Donatella Darsena, Francesco Verde, Ivan Iudice, Vincenzo Galdi</dc:creator>
    </item>
    <item>
      <title>Comparing Differentiable and Dynamic Ray Tracing: Introducing the Multipath Lifetime Map</title>
      <link>https://arxiv.org/abs/2410.14535</link>
      <description>arXiv:2410.14535v3 Announce Type: replace 
Abstract: With the increasing presence of dynamic scenarios, such as Vehicle-to-Vehicle communications, radio propagation modeling tools must adapt to the rapidly changing nature of the radio channel. Recently, both Differentiable and Dynamic Ray Tracing frameworks have emerged to address these challenges. However, there is often confusion about how these approaches differ and which one should be used in specific contexts. In this paper, we provide an overview of these two techniques and a comparative analysis against two state-of-the-art tools: 3DSCAT from UniBo and Sionna from NVIDIA. To provide a more precise characterization of the scope of these methods, we introduce a novel simulation-based metric, the Multipath Lifetime Map, which enables the evaluation of spatial and temporal coherence in radio channels only based on the geometrical description of the environment. Finally, our metrics are evaluated on a classic urban street canyon scenario, yielding similar results to those obtained from measurement campaigns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14535v3</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>J\'erome Eertmans, Enrico Maria Vittuci, Vittorio Degli-Esposti, Laurent Jacques, Claude Oestges</dc:creator>
    </item>
    <item>
      <title>On the Crucial Role of Initialization for Matrix Factorization</title>
      <link>https://arxiv.org/abs/2410.18965</link>
      <description>arXiv:2410.18965v3 Announce Type: replace-cross 
Abstract: This work revisits the classical low-rank matrix factorization problem and unveils the critical role of initialization in shaping convergence rates for such nonconvex and nonsmooth optimization. We introduce Nystrom initialization, which significantly improves the global convergence of Scaled Gradient Descent (ScaledGD) in both symmetric and asymmetric matrix factorization tasks. Specifically, we prove that ScaledGD with Nystrom initialization achieves quadratic convergence in cases where only linear rates were previously known. Furthermore, we extend this initialization to low-rank adapters (LoRA) commonly used for finetuning foundation models. Our approach, NoRA, i.e., LoRA with Nystrom initialization, demonstrates superior performance across various downstream tasks and model scales, from 1B to 7B parameters, in large language and diffusion models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18965v3</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Bingcong Li, Liang Zhang, Aryan Mokhtari, Niao He</dc:creator>
    </item>
    <item>
      <title>Distributed Computation Offloading for Energy Provision Minimization in WP-MEC Networks with Multiple HAPs</title>
      <link>https://arxiv.org/abs/2411.00397</link>
      <description>arXiv:2411.00397v2 Announce Type: replace-cross 
Abstract: This paper investigates a wireless powered mobile edge computing (WP-MEC) network with multiple hybrid access points (HAPs) in a dynamic environment, where wireless devices (WDs) harvest energy from radio frequency (RF) signals of HAPs, and then compute their computation data locally (i.e., local computing mode) or offload it to the chosen HAPs (i.e., edge computing mode). In order to pursue a green computing design, we formulate an optimization problem that minimizes the long-term energy provision of the WP-MEC network subject to the energy, computing delay and computation data demand constraints. The transmit power of HAPs, the duration of the wireless power transfer (WPT) phase, the offloading decisions of WDs, the time allocation for offloading and the CPU frequency for local computing are jointly optimized adapting to the time-varying generated computation data and wireless channels of WDs. To efficiently address the formulated non-convex mixed integer programming (MIP) problem in a distributed manner, we propose a Two-stage Multi-Agent deep reinforcement learning-based Distributed computation Offloading (TMADO) framework, which consists of a high-level agent and multiple low-level agents. The high-level agent residing in all HAPs optimizes the transmit power of HAPs and the duration of the WPT phase, while each low-level agent residing in each WD optimizes its offloading decision, time allocation for offloading and CPU frequency for local computing. Simulation results show the superiority of the proposed TMADO framework in terms of the energy provision minimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00397v2</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoying Liu, Anping Chen, Kechen Zheng, Kaikai Chi, Bin Yang, Tarik Taleb</dc:creator>
    </item>
  </channel>
</rss>
