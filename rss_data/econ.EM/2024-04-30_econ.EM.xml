<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 30 Apr 2024 04:03:47 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 30 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Survey Selection Correction using Nonrandom Followup with an Application to the Gender Entrepreneurship Gap</title>
      <link>https://arxiv.org/abs/2404.17693</link>
      <description>arXiv:2404.17693v1 Announce Type: new 
Abstract: Selection into samples undermines efforts to describe populations and to estimate relationships between variables. We develop a simple method for correcting for sample selection that explains differences in survey responses between early and late respondents with correlation between potential responses and preference for survey response. Our method relies on researchers observing the number of data collection attempts prior to each individual's survey response rather than covariates that affect response rates without affecting potential responses. Applying our method to a survey of entrepreneurial aspirations among undergraduates at University of Wisconsin-Madison, we find suggestive evidence that the entrepreneurial aspiration rate is larger among survey respondents than the population, as well as the male-female gender gap in the entrepreneurial aspiration rate, which we estimate as 21 percentage points in the sample and 19 percentage points in the population. Our results suggest that the male-female gap in entrepreneurial aspirations arises prior to direct exposure to the labor market.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17693v1</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Clint Harris, Jon Eckhardt, Brent Goldfarb</dc:creator>
    </item>
    <item>
      <title>Sequential monitoring for explosive volatility regimes</title>
      <link>https://arxiv.org/abs/2404.17885</link>
      <description>arXiv:2404.17885v1 Announce Type: new 
Abstract: In this paper, we develop two families of sequential monitoring procedure to (timely) detect changes in a GARCH(1,1) model. Whilst our methodologies can be applied for the general analysis of changepoints in GARCH(1,1) sequences, they are in particular designed to detect changes from stationarity to explosivity or vice versa, thus allowing to check for volatility bubbles. Our statistics can be applied irrespective of whether the historical sample is stationary or not, and indeed without prior knowledge of the regime of the observations before and after the break. In particular, we construct our detectors as the CUSUM process of the quasi-Fisher scores of the log likelihood function. In order to ensure timely detection, we then construct our boundary function (exceeding which would indicate a break) by including a weighting sequence which is designed to shorten the detection delay in the presence of a changepoint. We consider two types of weights: a lighter set of weights, which ensures timely detection in the presence of changes occurring early, but not too early after the end of the historical sample; and a heavier set of weights, called Renyi weights which is designed to ensure timely detection in the presence of changepoints occurring very early in the monitoring horizon. In both cases, we derive the limiting distribution of the detection delays, indicating the expected delay for each set of weights. Our theoretical results are validated via a comprehensive set of simulations, and an empirical application to daily returns of individual stocks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17885v1</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lajos Horvath, Lorenzo Trapani, Shixuan Wang</dc:creator>
    </item>
    <item>
      <title>Testing for Asymmetric Information in Insurance with Deep Learning</title>
      <link>https://arxiv.org/abs/2404.18207</link>
      <description>arXiv:2404.18207v1 Announce Type: new 
Abstract: The positive correlation test for asymmetric information developed by Chiappori and Salanie (2000) has been applied in many insurance markets. Most of the literature focuses on the special case of constant correlation; it also relies on restrictive parametric specifications for the choice of coverage and the occurrence of claims. We relax these restrictions by estimating conditional covariances and correlations using deep learning methods. We test the positive correlation property by using the intersection test of Chernozhukov, Lee, and Rosen (2013) and the "sorted groups" test of Chernozhukov, Demirer, Duflo, and Fernandez-Val (2023). Our results confirm earlier findings that the correlation between risk and coverage is small. Random forests and gradient boosting trees produce similar results to neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18207v1</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Serguei Maliar, Bernard Salanie</dc:creator>
    </item>
    <item>
      <title>Optimal Treatment Allocation under Constraints</title>
      <link>https://arxiv.org/abs/2404.18268</link>
      <description>arXiv:2404.18268v1 Announce Type: new 
Abstract: In optimal policy problems where treatment effects vary at the individual level, optimally allocating treatments to recipients is complex even when potential outcomes are known. We present an algorithm for multi-arm treatment allocation problems that is guaranteed to find the optimal allocation in strongly polynomial time, and which is able to handle arbitrary potential outcomes as well as constraints on treatment requirement and capacity. Further, starting from an arbitrary allocation, we show how to optimally re-allocate treatments in a Pareto-improving manner. To showcase our results, we use data from Danish nurse home visiting for infants. We estimate nurse specific treatment effects for children born 1959-1967 in Copenhagen, comparing nurses against each other. We exploit random assignment of newborn children to nurses within a district to obtain causal estimates of nurse-specific treatment effects using causal machine learning. Using these estimates, and treating the Danish nurse home visiting program as a case of an optimal treatment allocation problem (where a treatment is a nurse), we document room for significant productivity improvements by optimally re-allocating nurses to children. Our estimates suggest that optimal allocation of nurses to children could have improved average yearly earnings by USD 1,815 and length of education by around two months.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18268v1</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Torben S. D. Johansen</dc:creator>
    </item>
    <item>
      <title>Discordant Relaxations of Misspecified Models</title>
      <link>https://arxiv.org/abs/2012.11679</link>
      <description>arXiv:2012.11679v5 Announce Type: replace 
Abstract: In many set-identified models, it is difficult to obtain a tractable characterization of the identified set. Therefore, researchers often rely on non-sharp identification conditions, and empirical results are often based on an outer set of the identified set. This practice is often viewed as conservative yet valid because an outer set is always a superset of the identified set. However, this paper shows that when the model is refuted by the data, two sets of non-sharp identification conditions derived from the same model could lead to disjoint outer sets and conflicting empirical results. We provide a sufficient condition for the existence of such discordancy, which covers models characterized by conditional moment inequalities and the Artstein (1983) inequalities. We also derive sufficient conditions for the non-existence of discordant submodels, therefore providing a class of models for which constructing outer sets cannot lead to misleading interpretations. In the case of discordancy, we follow Masten and Poirier (2021) by developing a method to salvage misspecified models, but unlike them, we focus on discrete relaxations. We consider all minimum relaxations of a refuted model that restores data-consistency. We find that the union of the identified sets of these minimum relaxations is robust to detectable misspecifications and has an intuitive empirical interpretation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2012.11679v5</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lixiong Li, D\'esir\'e K\'edagni, Isma\"el Mourifi\'e</dc:creator>
    </item>
    <item>
      <title>Data Scaling Effect of Deep Learning in Financial Time Series Forecasting</title>
      <link>https://arxiv.org/abs/2309.02072</link>
      <description>arXiv:2309.02072v4 Announce Type: replace 
Abstract: For many years, researchers have been exploring the use of deep learning in the forecasting of financial time series. However, they have continued to rely on the conventional econometric approach for model optimization, optimizing the deep learning models on individual assets. In this paper, we use the stock volatility forecast as an example to illustrate global training - optimizes the deep learning model across a wide range of stocks - is both necessary and beneficial for any academic or industry practitioners who is interested in employing deep learning to forecast financial time series. Furthermore, a pre-trained foundation model for volatility forecast is introduced, capable of making accurate zero-shot forecasts for any stocks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.02072v4</guid>
      <category>econ.EM</category>
      <category>cs.AI</category>
      <category>q-fin.CP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Chen Liu, Minh-Ngoc Tran, Chao Wang, Richard Gerlach, Robert Kohn</dc:creator>
    </item>
    <item>
      <title>Sensitivity Analysis for Linear Estimators</title>
      <link>https://arxiv.org/abs/2309.06305</link>
      <description>arXiv:2309.06305v3 Announce Type: replace 
Abstract: We propose a novel sensitivity analysis framework for linear estimators with identification failures that can be viewed as seeing the wrong outcome distribution. Our approach measures the degree of identification failure through the change in measure between the observed distribution and a hypothetical target distribution that would identify the causal parameter of interest. The framework yields a sensitivity analysis that generalizes existing bounds for Average Potential Outcome (APO), Regression Discontinuity (RD), and instrumental variables (IV) exclusion failure designs. Our partial identification results extend results from the APO context to allow even unbounded likelihood ratios. Our proposed sensitivity analysis consistently estimates sharp bounds under plausible conditions and estimates valid bounds under mild conditions. We find that our method performs well in simulations even when targeting a discontinuous and nearly infinite bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.06305v3</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jacob Dorn, Luther Yap</dc:creator>
    </item>
    <item>
      <title>Efficiency of QMLE for dynamic panel data models with interactive effects</title>
      <link>https://arxiv.org/abs/2312.07881</link>
      <description>arXiv:2312.07881v2 Announce Type: replace 
Abstract: This paper derives the efficiency bound for estimating the parameters of dynamic panel data models in the presence of an increasing number of incidental parameters. We study the efficiency problem by formulating the dynamic panel as a simultaneous equations system, and show that the quasi-maximum likelihood estimator (QMLE) applied to the system achieves the efficiency bound. Comparison of QMLE with fixed effects estimators is made.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.07881v2</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jushan Bai</dc:creator>
    </item>
    <item>
      <title>Arellano-Bond LASSO Estimator for Dynamic Linear Panel Models</title>
      <link>https://arxiv.org/abs/2402.00584</link>
      <description>arXiv:2402.00584v3 Announce Type: replace 
Abstract: The Arellano-Bond estimator is a fundamental method for dynamic panel data models, widely used in practice. However, the estimator is severely biased when the data's time series dimension $T$ is long due to the large degree of overidentification. We show that weak dependence along the panel's time series dimension naturally implies approximate sparsity of the most informative moment conditions, motivating the following approach to remove the bias: First, apply LASSO to the cross-section data at each time period to construct most informative (and cross-fitted) instruments, using lagged values of suitable covariates. This step relies on approximate sparsity to select the most informative instruments. Second, apply a linear instrumental variable estimator after first differencing the dynamic structural equation using the constructed instruments. Under weak time series dependence, we show the new estimator is consistent and asymptotically normal under much weaker conditions on $T$'s growth than the Arellano-Bond estimator. Our theory covers models with high dimensional covariates, including multiple lags of the dependent variable, common in modern applications. We illustrate our approach by applying it to weekly county-level panel data from the United States to study opening K-12 schools and other mitigation policies' short and long-term effects on COVID-19's spread.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.00584v3</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Victor Chernozhukov, Iv\'an Fern\'andez-Val, Chen Huang, Weining Wang</dc:creator>
    </item>
  </channel>
</rss>
