<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 22 Apr 2025 04:01:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Access Probability Optimization in RACH: A Multi-Armed Bandits Approach</title>
      <link>https://arxiv.org/abs/2504.14085</link>
      <description>arXiv:2504.14085v1 Announce Type: new 
Abstract: The use of cellular networks for massive machine-type communications (mMTC) is an appealing solution due to the availability of the existing infrastructure. However, the massive number of user equipments (UEs) poses a significant challenge to the cellular network's random access channel (RACH) regarding congestion and overloading. To mitigate this problem, we first present a novel approach to model a two-priority RACH, which allows us to define access patterns that describe the random access behavior of UEs as observed by the base station (BS). A non-uniform preamble selection scheme is proposed, offering increased flexibility in resource allocation for different UE priority classes. Then, we formulate an allocation model that finds the optimal access probabilities to maximize the success rate of high-priority UEs while constraining low-priority UEs. Finally, we develop a reinforcement learning approach to solving the optimization problem using multi-armed bandits, which provides a near-optimal but scalable solution and does not require the BS to know the number of UEs in the network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14085v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ahmed O. Elmeligy, Ioannis Psaromiligkos, Au Minh</dc:creator>
    </item>
    <item>
      <title>6G WavesFM: A Foundation Model for Sensing, Communication, and Localization</title>
      <link>https://arxiv.org/abs/2504.14100</link>
      <description>arXiv:2504.14100v1 Announce Type: new 
Abstract: This paper introduces WavesFM, a novel Wireless Foundation Model (WFM) framework, capable of supporting a wide array of communication, sensing, and localization tasks. Our proposed architecture combines a shared Vision Transformer (ViT) backbone with task-specific multi-layer perceptron (MLP) heads and incorporates Low-Rank Adaptation (LoRA) for parameter-efficient fine-tuning. This design promotes full parameter sharing across tasks, significantly reducing the computational and memory footprint without sacrificing performance. The model processes both image-like wireless modalities, such as spectrograms and channel state information (CSI), and in-phase and quadrature (IQ) signals arranged as orthogonal frequency-division multiplexing (OFDM) resource grids. We demonstrate the strong generalization capabilities of WavesFM through extensive experiments on four downstream tasks: Fifth Generation New Radio (5G NR) positioning; multiple-input multiple-output OFDM (MIMO-OFDM) channel estimation; human activity sensing; and radio-frequency (RF) signal classification. Compared to supervised baselines trained individually, our approach achieves superior performance while sharing 80% of its parameters across tasks. Furthermore, we show that pretraining on domain-relevant data not only boosts performance but also accelerates convergence, reducing training time by up to 5x. These results demonstrate that our unified WFM can support diverse tasks and deliver significant gains in both performance and efficiency, highlighting the transformative potential of foundation models to drive AI-native paradigms in future sixth-generation (6G) networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14100v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmed Aboulfotouh, Elsayed Mohammed, Hatem Abou-Zeid</dc:creator>
    </item>
    <item>
      <title>An Artificial Intelligence Enabled Signature Estimation of Dual Wideband Systems in Ultra-Low Signal-to-Noise Ratio</title>
      <link>https://arxiv.org/abs/2504.14226</link>
      <description>arXiv:2504.14226v1 Announce Type: new 
Abstract: Millimeter-wave (mmWave) massive Multiple Input Multiple Output (MIMO) systems encounter both spatial wideband spreading and temporal wideband effects in the communication channels of individual users. Accurate estimation of a user's channel signature -- specifically, the direction of arrival and time of arrival -- is crucial for designing efficient beamforming transceivers, especially under noisy observations. In this work, we propose an Artificial Intelligence (AI)-enabled framework for estimating the channel signature of a user's location in mmWave massive MIMO systems. Our approach explicitly accounts for spatial wideband spreading, finite basis leakage effects, and significant unknown receiver noise. We demonstrate the effectiveness of a denoising convolutional neural network with residual learning for recovering channel responses, even when channel gains are of extremely low amplitude and embedded in ultra-high receiver noise environments. Notably, our method successfully recovers spatio-temporal diversity branches at signal-to-noise ratios as low as -20 dB. Furthermore, we introduce a local gravitation-based clustering algorithm to infer the number of physical propagation paths (unknown a priori) and to identify their respective support in the delay-angle domain of the denoised response. To complement our approach, we design tailored metrics for evaluating denoising and clustering performance within the context of wireless communications. We validate our framework through system-level simulations using Orthogonal Frequency Division Multiplexing (OFDM) with a Quadrature Phase Shift Keying (QPSK) modulation scheme over mmWave fading channels, highlighting the necessity and robustness of the proposed methods in ultra-low SNR scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14226v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chandrashekhar Rai, Debarati Sen</dc:creator>
    </item>
    <item>
      <title>A Real-time and Hardware Efficient Artfecat-free Spike Sorting Using Deep Spike Detection</title>
      <link>https://arxiv.org/abs/2504.14279</link>
      <description>arXiv:2504.14279v1 Announce Type: new 
Abstract: Spike sorting is a valuable tool in understanding brain regions. It assigns detected spike waveforms to their origins, helping to research the mechanism of the human brain and the development of implantable brain-machine interfaces (iBMIs). The presence of noise and artefacts will adversely affect the efficacy of spike sorting. This paper proposes a framework for low-cost and real-time implementation of deep spike detection, which consists of two one-dimensional (1-D) convolutional neural network (CNN) model for channel selection and artefact removal. The framework utilizes simulation and hardware layers, and it applies several low-power techniques to optimise the implementation cost of a 1-D CNN model. A compact CNN model with 210 bytes memory size is achieved using structured pruning, network projection and quantization in the simulation layer. The hardware layer also accommodates various techniques including a customized multiply-accumulate (MAC) engine, novel fused layers in the convolution pipeline and proposing flexible resource allocation for a power-efficient and low-delay design. The optimized 1-D CNN significantly decreases both computational complexity and model size, with only a minimal reduction in accuracy. Classification of 1-D CNN on the Cyclone V 5CSEMA5F31C6 FPGA evaluation platform is accomplished in just 16.8 microseconds at a frequency of 2.5 MHz. The FPGA prototype achieves an accuracy rate of 97.14% on a standard dataset and operates with a power consumption of 2.67mW from a supply voltage of 1.1 volts. An accuracy of 95.05% is achieved with a power of 5.6mW when deep spike detection is implemented using two optimized 1-D CNNs on an FPGA board.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14279v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaoyu Jiang, Tao Fang, Majid Zamani</dc:creator>
    </item>
    <item>
      <title>Exploiting Symmetric Non-Convexity for Multi-Objective Symbol-Level DFRC Signal Design</title>
      <link>https://arxiv.org/abs/2504.14281</link>
      <description>arXiv:2504.14281v1 Announce Type: new 
Abstract: Symbol-level precoding (SLP) is a promising solution for addressing the inherent interference problem in dual-functional radar-communication (DFRC) signal designs. This paper considers an SLP-DFRC signal design problem which optimizes the radar performance under communication performance constraints. We show that a common phase modulation applied to the transmit signals from an antenna array does not affect the performance of different radar sensing metrics, including beampattern similarity, signal-to-interference-plus-noise ratio (SINR), and Cram\'er-Rao lower bound (CRLB). We refer to this as symmetric-rotation invariance, upon which we develop low-complexity yet efficient DFRC signal design algorithms. More specifically, we propose a symmetric non-convexity (SNC)-based DFRC algorithm that relies on the non-convexity of the radar sensing metrics to identify a set of radar-only solutions. Based on these solutions, we further exploit the symmetry property of the radar sensing metrics to efficiently design the DFRC signal. We show that the proposed SNC-based algorithm is versatile in the sense that it can be applied to the DFRC signal optimization of all three sensing metrics mentioned above (beampattern, SINR, and CRLB). In addition, since the radar sensing metrics are independent of the communication channel and data symbols, the set of radar-only solutions can be constructed offline, thereby reducing the computational complexity. We also develop an accelerated SNC-based algorithm that further reduces the complexity. Finally, we numerically demonstrate the superiority of the proposed algorithms compared to existing methods in terms of sensing and communication performance as well as computational requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14281v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ly V. Nguyen, Rang Liu, Nhan Thanh Nguyen, Markku Juntti, Bj\"orn Ottersten, A. Lee Swindlehurst</dc:creator>
    </item>
    <item>
      <title>Iterative Polynomial Approximation Algorithms for Inverse Graph Filters</title>
      <link>https://arxiv.org/abs/2504.14341</link>
      <description>arXiv:2504.14341v1 Announce Type: new 
Abstract: Chebyshev interpolation polynomials exhibit the exponential approximation property to analytic functions on a cube. Based on the Chebyshev interpolation polynomial approximation, we propose
  iterative polynomial approximation algorithms to implement the inverse filter with a polynomial graph filter of commutative graph shifts in a distributed manner. The proposed algorithms exhibit exponential convergence properties, and they can be implemented on distributed networks in which agents are equipped with a data processing subsystem for limited data storage and computation power, and with a one-hop communication subsystem for direct data exchange only with their adjacent agents. Our simulations show that the proposed polynomial approximation algorithms may converge faster than the Chebyshev polynomial approximation algorithm
  and the conventional gradient descent algorithm
  do.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14341v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cheng Cheng, Qiyu Sun, Cong Zheng</dc:creator>
    </item>
    <item>
      <title>Beamforming Design and Association Scheme for Multi-RIS Multi-User mmWave Systems Through Graph Neural Networks</title>
      <link>https://arxiv.org/abs/2504.14464</link>
      <description>arXiv:2504.14464v1 Announce Type: new 
Abstract: Reconfigurable intelligent surface (RIS) is emerging as a promising technology for next-generation wireless communication networks, offering a variety of merits such as the ability to tailor the communication environment. Moreover, deploying multiple RISs helps mitigate severe signal blocking between the base station (BS) and users, providing a practical and efficient solution to enhance the service coverage. However, fully reaping the potential of a multi-RIS aided communication system requires solving a non-convex optimization problem. This challenge motivates the adoption of learning-based methods for determining the optimal policy. In this paper, we introduce a novel heterogeneous graph neural network (GNN) to effectively leverage the graph topology of a wireless communication environment. Specifically, we design an association scheme that selects a suitable RIS for each user. Then, we maximize the weighted sum rate (WSR) of all the users by iteratively optimizing the RIS association scheme, and beamforming designs until the considered heterogeneous GNN converges. Based on the proposed approach, each user is associated with the best RIS, which is shown to significantly improve the system capacity in multi-RIS multi-user millimeter wave (mmWave) communications. Specifically, simulation results demonstrate that the proposed heterogeneous GNN closely approaches the performance of the high-complexity alternating optimization (AO) algorithm in the considered multi-RIS aided communication system, and it outperforms other benchmark schemes. Moreover, the performance improvement achieved through the RIS association scheme is shown to be of the order of 30%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14464v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mengbing Liu, Chongwen Huang, Ahmed Alhammadi, Marco Di Renzo, Merouane Debbah, Chau Yuen</dc:creator>
    </item>
    <item>
      <title>Max-Min Fairness for Stacked Intelligent Metasurface-Assisted Multi-User MISO Systems</title>
      <link>https://arxiv.org/abs/2504.14584</link>
      <description>arXiv:2504.14584v1 Announce Type: new 
Abstract: Stacked intelligent metasurface (SIM) is an emerging technology that uses multiple reconfigurable surface layers to enable flexible wave-based beamforming. In this paper, we focus on an \ac{SIM}-assisted multi-user multiple-input single-output system, where it is essential to ensure that all users receive a fair and reliable service level. To this end, we develop two max-min fairness algorithms based on instantaneous channel state information (CSI) and statistical CSI. For the instantaneous CSI case, we propose an alternating optimization algorithm that jointly optimizes power allocation using geometric programming and wave-based beamforming coefficients using the gradient descent-ascent method. For the statistical CSI case, since deriving an exact expression for the average minimum achievable rate is analytically intractable, we derive a tight upper bound and thereby formulate a stochastic optimization problem. This problem is then solved, capitalizing on an alternating approach combining geometric programming and gradient descent algorithms, to obtain the optimal policies. Our numerical results show significant improvements in the minimum achievable rate compared to the benchmark schemes. In particular, for the instantaneous CSI scenario, the individual impact of the optimal wave-based beamforming is significantly higher than that of the power allocation strategy. Moreover, the proposed upper bound is shown to be tight in the low signal-to-noise ratio regime under the statistical CSI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14584v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nipuni Ginige, Prathapasinghe Dharmawansa, Arthur Sousa de Sena, Nurul Huda Mahmood, Nandana Rajatheva, Matti Latva-aho</dc:creator>
    </item>
    <item>
      <title>Markovian Continuity of the MMSE</title>
      <link>https://arxiv.org/abs/2504.14659</link>
      <description>arXiv:2504.14659v1 Announce Type: new 
Abstract: Minimum mean square error (MMSE) estimation is widely used in signal processing and related fields. While it is known to be non-continuous with respect to all standard notions of stochastic convergence, it remains robust in practical applications. In this work, we review the known counterexamples to the continuity of the MMSE. We observe that, in these counterexamples, the discontinuity arises from an element in the converging measurement sequence providing more information about the estimand than the limit of the measurement sequence. We argue that this behavior is uncharacteristic of real-world applications and introduce a new stochastic convergence notion, termed Markovian convergence, to address this issue. We prove that the MMSE is, in fact, continuous under this new notion. We supplement this result with semi-continuity and continuity guarantees of the MMSE in other settings and prove the continuity of the MMSE under linear estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14659v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Elad Domanovitz, Anatoly Khina</dc:creator>
    </item>
    <item>
      <title>Delay-Angle Information Spoofing for Channel State Information-Free Location-Privacy Enhancement</title>
      <link>https://arxiv.org/abs/2504.14780</link>
      <description>arXiv:2504.14780v1 Announce Type: new 
Abstract: In this paper, a delay-angle information spoofing (DAIS) strategy is proposed to enhance the location privacy at the physical layer. More precisely, the location-relevant delays and angles are artificially shifted without the aid of channel state information (CSI) at the transmitter, such that the location perceived by the eavesdropper is incorrect and distinct from the true one. By leveraging the intrinsic structure of the wireless channel, a precoder is designed to achieve DAIS while the legitimate localizer can remove the obfuscation via securely receiving a modest amount of information, i.e., the delay-angle shifts. A lower bound on eavesdropper's localization error is derived, revealing that location privacy is enhanced not only due to estimation error, but also by the geometric mismatch introduced by DAIS. Furthermore, the lower bound is explicitly expressed as a function of the delay-angle shifts, characterizing performance trends and providing the appropriate design of these shift parameters. The statistical hardness of maliciously inferring the delay-angle shifts by a single-antenna eavesdropper as well as the challenges for a multi-antenna eavesdropper are investigated to assess the robustness of the proposed DAIS strategy. Numerical results show that the proposed DAIS strategy results in more than 15 dB performance degradation for the eavesdropper as compared with that for the legitimate localizer at high signal-to-noise ratios, and provides more effective location-privacy enhancement than the prior art.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14780v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianxiu Li, Urbashi Mitra</dc:creator>
    </item>
    <item>
      <title>Aligning Beam with Imbalanced Multi-modality: A Generative Federated Learning Approach</title>
      <link>https://arxiv.org/abs/2504.14835</link>
      <description>arXiv:2504.14835v1 Announce Type: new 
Abstract: As vehicle intelligence advances, multi-modal sensing-aided communication emerges as a key enabler for reliable Vehicle-to-Everything (V2X) connectivity through precise environmental characterization. As centralized learning may suffer from data privacy, model heterogeneity and communication overhead issues, federated learning (FL) has been introduced to support V2X. However, the practical deployment of FL faces critical challenges: model performance degradation from label imbalance across vehicles and training instability induced by modality disparities in sensor-equipped agents. To overcome these limitations, we propose a generative FL approach for beam selection (GFL4BS). Our solution features two core innovations: 1) An adaptive zero-shot multi-modal generator coupled with spectral-regularized loss functions to enhance the expressiveness of synthetic data compensating for both label scarcity and missing modalities; 2) A hybrid training paradigm integrating feature fusion with decentralized optimization to ensure training resilience while minimizing communication costs. Experimental evaluations demonstrate significant improvements over baselines achieving 16.2% higher accuracy than the current state-of-the-art under severe label imbalance conditions while maintaining over 70% successful rate even when two agents lack both LiDAR and RGB camera inputs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14835v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiahui Liang, Miaowen Wen, Shuoyao Wang, Yuxuan Liang, Shijian Gao</dc:creator>
    </item>
    <item>
      <title>Radar Code Design for the Joint Optimization of Detection Performance and Measurement Accuracy in Track Maintenance</title>
      <link>https://arxiv.org/abs/2504.14885</link>
      <description>arXiv:2504.14885v1 Announce Type: new 
Abstract: This paper deals with the design of slow-time coded waveforms which jointly optimize the detection probability and the measurements accuracy for track maintenance in the presence of colored Gaussian interference. The output signal-to-interference-plus-noise ratio (SINR) and Cram\'er Rao bounds (CRBs) on time delay and Doppler shift are used as figures of merit to accomplish reliable detection as well as accurate measurements. The transmitted code is subject to radar power budget requirements and a similarity constraint. To tackle the resulting non-convex multi-objective optimization problem, a polynomial-time algorithm that integrates scalarization and tensor-based relaxation methods is developed. The corresponding relaxed multi-linear problems are solved by means of the maximum block improvement (MBI) framework, where the optimal solution at each iteration is obtained in closed form. Numeral results demonstrate the trade-off between the detection and the estimation performance, along with the acceptable Doppler robustness achieved by the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14885v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tao Fan, Augusto Aubry, Vincenzo Carotenuto, Antonio De Maio, Xianxiang Yu, Guolong Cui</dc:creator>
    </item>
    <item>
      <title>A Purely Data-Driven Adaptive Impedance Matching Method Robust to Parasitic Effects</title>
      <link>https://arxiv.org/abs/2504.14951</link>
      <description>arXiv:2504.14951v1 Announce Type: new 
Abstract: Adaptive impedance matching between antennas and radio frequency front-end (RFFE) power modules is essential for mobile communication systems. To address the matching performance degradation caused by parasitic effects in practical tunable matching networks (TMN), this paper proposes a purely data-driven adaptive impedance matching method that avoids trial-and-error physical adjustment. First, we propose the residual enhanced circuit behavior modeling network (RECBM-Net), a deep learning model that maps TMN operating states to their scattering parameters (S-parameters). Then, we formulate the matching process based on the trained surrogate model as a mathematical optimization problem. We employ two classic numerical methods with different online computational overhead, namely simulated annealing particle swarm optimization (SAPSO) and adaptive moment estimation with automatic differentiation (AD-Adam), to search for the matching solution. To further reduce the online inference overhead caused by repeated forward propagation through RECBM-Net, we train an inverse mapping solver network (IMS-Net) to directly predict the optimal solution. Simulation results show that RECBM-Net achieves exceptionally high modeling accuracy. While AD-Adam significantly reduces computational overhead compared to SAPSO, it sacrifices slight accuracy. IMS-Net offers the lowest online overhead while maintaining excellent matching accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14951v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wendong Cheng, Li Chen, Weidong Wang</dc:creator>
    </item>
    <item>
      <title>Blinding the Wiretapper: RIS-Enabled User Occultation in the ISAC Era</title>
      <link>https://arxiv.org/abs/2504.15033</link>
      <description>arXiv:2504.15033v1 Announce Type: new 
Abstract: An undesirable consequence of the foreseeable proliferation of sophisticated integrated sensing and communications (ISAC) technologies is the enabling of spoofing, by malicious agents, of situational information (such as proximity, direction or location) of legitimate users of wireless systems. In order to mitigate this threat, we present a novel ISAC scheme that, aided by a reconfigurable intelligent surface (RIS), enables the occultation of the positions of user equipment (UE) from wiretappers, while maintaining both sensing and desired communication performance between the UEs and a legitimate base station (BS). To that end, we first formulate an RIS phase-shift optimization problem that jointly maximizes the sum-rate performance of the UEs (communication objective), while minimizing the projection of the wiretapper's effective channel onto the legitimate channel (hiding objective), thereby disrupting the attempts by a wiretapper of localizing the UEs. Then, in order to efficiently solve the resulting non-convex joint optimization problem, a novel manifold optimization algorithm is derived, whose effectiveness is validated by numerical results, which demonstrate that the proposed approach preserves legitimate ISAC performance while significantly degrading the wiretapper's sensing capability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15033v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Getuar Rexhepi, Hyeon Seok Rou, Giuseppe Thadeu Freitas de Abreu, George C. Alexandropoulos</dc:creator>
    </item>
    <item>
      <title>The PHD/CPHD filter for Multiple Extended Target Tracking with Trajectory Set Theory and Explicit Shape Estimation</title>
      <link>https://arxiv.org/abs/2504.15040</link>
      <description>arXiv:2504.15040v1 Announce Type: new 
Abstract: In this paper, we propose two methods for tracking multiple extended targets or unresolved group targets with elliptical extent shape. These two methods are deduced from the famous Probability Hypothesis Density (PHD) filter and the Cardinality-PHD (CPHD) filter, respectively. In these two methods, Trajectory Set Theory (TST) is combined to establish the target trajectory estimates. Moreover, by employing a decoupled shape estimation model, the proposed methods can explicitly provide the shape estimation of the target, such as the orientation of the ellipse extension and the length of its two axes. We derived the closed Bayesian recursive of these two methods with stable trajectory generation and accurate extent estimation, resulting in the TPHD-E filter and the TCPHD-E filter. In addition, Gaussian mixture implementations of our methods are provided, which are further referred to as the GM-TPHD-E filter and the GM-TCPHD-E filters. We illustrate the ability of these methods through simulations and experiments with real data. These experiments demonstrate that the two proposed algorithms have advantages over existing algorithms in target shape estimation, as well as in the completeness and accuracy of target trajectory generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15040v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuanhao Cheng, Yunhe Cao, Tat-Soon Yeo, Fu Jie, Wei Zhang</dc:creator>
    </item>
    <item>
      <title>Bayesian Sensing for Time-Varying Channels in ISAC Systems</title>
      <link>https://arxiv.org/abs/2504.15042</link>
      <description>arXiv:2504.15042v1 Announce Type: new 
Abstract: Future mobile networks are projected to support integrated sensing and communications in high-speed communication scenarios. Nevertheless, large Doppler shifts induced by time-varying channels may cause severe inter-carrier interference (ICI). Frequency domain shows the potential of reducing ISAC complexity as compared with other domains. However, parameter mismatching issue still exists for such sensing. In this paper, we develop a novel sensing scheme based on sparse Bayesian framework, where the delay and Doppler estimation problem in time-varying channels is formulated as a 3D multiple measurement-sparse signal recovery (MM-SSR) problem. We then propose a novel two-layer variational Bayesian inference (VBI) method to decompose the 3D MM-SSR problem into two layers and estimate the Doppler in the first layer and the delay in the second layer alternatively. Subsequently, as is benefited from newly unveiled signal construction, a simplified two-stage multiple signal classification (MUSIC)-based VBI method is proposed, where the delay and the Doppler are estimated by MUSIC and VBI, respectively. Additionally, the Cram\'er-Rao bound (CRB) of the considered sensing parameters is derived to characterize the lower bound for the proposed estimators. Corroborated by extensive simulation results, our proposed method can achieve improved mean square error (MSE) than its conventional counterparts and is robust against the target number and target speed, thereby validating its wide applicability and advantages over prior arts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15042v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xueyang Wang, Kai Wu, J. Andrew Zhang, Shiqi Gong, Chengwen Xing</dc:creator>
    </item>
    <item>
      <title>Time-Series Analysis on Edge-AI Hardware for Healthcare Monitoring</title>
      <link>https://arxiv.org/abs/2504.15178</link>
      <description>arXiv:2504.15178v1 Announce Type: new 
Abstract: This project addresses the need for efficient, real-time analysis of biomedical signals such as electrocardiograms (ECG) and electroencephalograms (EEG) for continuous health monitoring. Traditional methods rely on long-duration data recording followed by offline analysis, which is power-intensive and delays responses to critical symptoms such as arrhythmia. To overcome these limitations, a time-domain ECG analysis model based on a novel dynamically-biased Long Short-Term Memory (DB-LSTM) neural network is proposed. This model supports simultaneous ECG forecasting and classification with high performance-achieving over 98% accuracy and a normalized mean square error below 1e-3 for forecasting, and over 97% accuracy with faster convergence and fewer training parameters for classification. To enable edge deployment, the model is hardware-optimized by quantizing weights to INT4 or INT3 formats, resulting in only a 2% and 6% drop in classification accuracy during training and inference, respectively, while maintaining full accuracy for forecasting. Extensive simulations using multiple ECG datasets confirm the model's robustness. Future work includes implementing the algorithm on FPGA and CMOS circuits for practical cardiac monitoring, as well as developing a digital hardware platform that supports flexible neural network configurations and on-chip online training for personalized healthcare applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15178v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jinhai Hu</dc:creator>
    </item>
    <item>
      <title>Joint Knowledge and Power Management for Secure Semantic Communication Networks</title>
      <link>https://arxiv.org/abs/2504.15260</link>
      <description>arXiv:2504.15260v1 Announce Type: new 
Abstract: Recently, semantic communication (SemCom) has shown its great superiorities in resource savings and information exchanges. However, while its unique background knowledge guarantees accurate semantic reasoning and recovery, semantic information security-related concerns are introduced at the same time. Since the potential eavesdroppers may have the same background knowledge to accurately decrypt the private semantic information transmitted between legal SemCom users, this makes the knowledge management in SemCom networks rather challenging in joint consideration with the power control. To this end, this paper focuses on jointly addressing three core issues of power allocation, knowledge base caching (KBC), and device-to-device (D2D) user pairing (DUP) in secure SemCom networks. We first develop a novel performance metric, namely semantic secrecy throughput (SST), to quantify the information security level that can be achieved at each pair of D2D SemCom users. Next, an SST maximization problem is formulated subject to secure SemCom-related delay and reliability constraints. Afterward, we propose a security-aware resource management solution using the Lagrange primal-dual method and a two-stage method. Simulation results demonstrate our proposed solution nearly doubles the SST performance and realizes less than half of the queuing delay performance compared to different benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15260v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuesong Liu, Yansong Liu, Haoyu Tang, Fangzhou Zhao, Le Xia, Yao Sun</dc:creator>
    </item>
    <item>
      <title>Wireless Silent Speech Interface Using Multi-Channel Textile EMG Sensors Integrated into Headphones</title>
      <link>https://arxiv.org/abs/2504.13921</link>
      <description>arXiv:2504.13921v1 Announce Type: cross 
Abstract: This paper presents a novel wireless silent speech interface (SSI) integrating multi-channel textile-based EMG electrodes into headphone earmuff for real-time, hands-free communication. Unlike conventional patch-based EMG systems, which require large-area electrodes on the face or neck, our approach ensures comfort, discretion, and wearability while maintaining robust silent speech decoding. The system utilizes four graphene/PEDOT:PSS-coated textile electrodes to capture speech-related neuromuscular activity, with signals processed via a compact ESP32-S3-based wireless readout module. To address the challenge of variable skin-electrode coupling, we propose a 1D SE-ResNet architecture incorporating squeeze-and-excitation (SE) blocks to dynamically adjust per-channel attention weights, enhancing robustness against motion-induced impedance variations. The proposed system achieves 96% accuracy on 10 commonly used voice-free control words, outperforming conventional single-channel and non-adaptive baselines. Experimental validation, including XAI-based attention analysis and t-SNE feature visualization, confirms the adaptive channel selection capability and effective feature extraction of the model. This work advances wearable EMG-based SSIs, demonstrating a scalable, low-power, and user-friendly platform for silent communication, assistive technologies, and human-computer interaction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.13921v1</guid>
      <category>cs.HC</category>
      <category>eess.SP</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chenyu Tang, Jos\'ee Mallah, Dominika Kazieczko, Wentian Yi, Tharun Reddy Kandukuri, Edoardo Occhipinti, Bhaskar Mishra, Sunita Mehta, Luigi G. Occhipinti</dc:creator>
    </item>
    <item>
      <title>Joint Channel Estimation and Signal Detection for MIMO-OFDM: A Novel Data-Aided Approach with Reduced Computational Overhead</title>
      <link>https://arxiv.org/abs/2504.14463</link>
      <description>arXiv:2504.14463v1 Announce Type: cross 
Abstract: The acquisition of channel state information (CSI) is essential in MIMO-OFDM communication systems. Data-aided enhanced receivers, by incorporating domain knowledge, effectively mitigate performance degradation caused by imperfect CSI, particularly in dynamic wireless environments. However, existing methodologies face notable challenges: they either refine channel estimates within MIMO subsystems separately, which proves ineffective due to deviations from assumptions regarding the time-varying nature of channels, or fully exploit the time-frequency characteristics but incur significantly high computational overhead due to dimensional concatenation. To address these issues, this study introduces a novel data-aided method aimed at reducing complexity, particularly suited for fast-fading scenarios in fifth-generation (5G) and beyond networks. We derive a general form of a data-aided linear minimum mean-square error (LMMSE)-based algorithm, optimized for iterative joint channel estimation and signal detection. Additionally, we propose a computationally efficient alternative to this algorithm, which achieves comparable performance with significantly reduced complexity. Empirical evaluations reveal that our proposed algorithms outperform several state-of-the-art approaches across various MIMO-OFDM configurations, pilot sequence lengths, and in the presence of time variability. Comparative analysis with basis expansion model-based iterative receivers highlights the superiority of our algorithms in achieving an effective trade-off between accuracy and computational complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14463v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinjie Li, Jing Zhang, Xingyu Zhou, Chao-Kai Wen, Shi Jin</dc:creator>
    </item>
    <item>
      <title>sEEG-based Encoding for Sentence Retrieval: A Contrastive Learning Approach to Brain-Language Alignment</title>
      <link>https://arxiv.org/abs/2504.14468</link>
      <description>arXiv:2504.14468v1 Announce Type: cross 
Abstract: Interpreting neural activity through meaningful latent representations remains a complex and evolving challenge at the intersection of neuroscience and artificial intelligence. We investigate the potential of multimodal foundation models to align invasive brain recordings with natural language. We present SSENSE, a contrastive learning framework that projects single-subject stereo-electroencephalography (sEEG) signals into the sentence embedding space of a frozen CLIP model, enabling sentence-level retrieval directly from brain activity. SSENSE trains a neural encoder on spectral representations of sEEG using InfoNCE loss, without fine-tuning the text encoder. We evaluate our method on time-aligned sEEG and spoken transcripts from a naturalistic movie-watching dataset. Despite limited data, SSENSE achieves promising results, demonstrating that general-purpose language representations can serve as effective priors for neural decoding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14468v1</guid>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yijun Liu</dc:creator>
    </item>
    <item>
      <title>Wireless Large AI Model: Shaping the AI-Native Future of 6G and Beyond</title>
      <link>https://arxiv.org/abs/2504.14653</link>
      <description>arXiv:2504.14653v1 Announce Type: cross 
Abstract: The emergence of sixth-generation and beyond communication systems is expected to fundamentally transform digital experiences through introducing unparalleled levels of intelligence, efficiency, and connectivity. A promising technology poised to enable this revolutionary vision is the wireless large AI model (WLAM), characterized by its exceptional capabilities in data processing, inference, and decision-making. In light of these remarkable capabilities, this paper provides a comprehensive survey of WLAM, elucidating its fundamental principles, diverse applications, critical challenges, and future research opportunities. We begin by introducing the background of WLAM and analyzing the key synergies with wireless networks, emphasizing the mutual benefits. Subsequently, we explore the foundational characteristics of WLAM, delving into their unique relevance in wireless environments. Then, the role of WLAM in optimizing wireless communication systems across various use cases and the reciprocal benefits are systematically investigated. Furthermore, we discuss the integration of WLAM with emerging technologies, highlighting their potential to enable transformative capabilities and breakthroughs in wireless communication. Finally, we thoroughly examine the high-level challenges hindering the practical implementation of WLAM and discuss pivotal future research directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14653v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fenghao Zhu, Xinquan Wang, Xinyi Li, Maojun Zhang, Yixuan Chen, Chongwen Huang, Zhaohui Yang, Xiaoming Chen, Zhaoyang Zhang, Richeng Jin, Yongming Huang, Wei Feng, Tingting Yang, Baoming Bai, Feifei Gao, Kun Yang, Yuanwen Liu, Sami Muhaidat, Chau Yuen, Kaibin Huang, Kai-Kit Wong, Dusit Niyato, M\'erouane Debbah</dc:creator>
    </item>
    <item>
      <title>Generative Semantic Communications: Principles and Practices</title>
      <link>https://arxiv.org/abs/2504.14947</link>
      <description>arXiv:2504.14947v1 Announce Type: cross 
Abstract: Semantic communication leverages artificial intelligence (AI) technologies to extract semantic information from data for efficient transmission, theraby significantly reducing communication cost. With the evolution towards artificial general intelligence (AGI), the increasing demands for AGI services pose new challenges to semantic communication. In response, we propose a new paradigm for AGI-driven communications, called generative semantic communication (GSC), which utilizes advanced AI technologies such as foundation models and generative models. We first describe the basic concept of GSC and its difference from existing semantic communications, and then introduce a general framework of GSC, followed by two case studies to verify the advantages of GSC in AGI-driven applications. Finally, open challenges and new research directions are discussed to stimulate this line of research and pave the way for practical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14947v1</guid>
      <category>cs.AI</category>
      <category>eess.IV</category>
      <category>eess.SP</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaojun Yuan, Haoming Ma, Yinuo Huang, Zhoufan Hua, Yong Zuo, Zhi Ding</dc:creator>
    </item>
    <item>
      <title>Frequency Comb-based Wavelength Division Multiplexing and Detection without Wavelength Demultiplexers</title>
      <link>https://arxiv.org/abs/2504.15012</link>
      <description>arXiv:2504.15012v1 Announce Type: cross 
Abstract: We demonstrate a wavelength division multiplexing (WDM) concept using demultiplexer-free frequency combs at both transmitter and receiver in a 4-wavelength 200-GHz-grid WDM system with flexible symbol rates, aiming to avoid the power-hungry wavelength control on demultiplexers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15012v1</guid>
      <category>physics.optics</category>
      <category>eess.SP</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Di Che, Zhongdi Peng, Mikael Mazur, Nicolas Fontaine</dc:creator>
    </item>
    <item>
      <title>Fast Data-driven Greedy Sensor Selection for Ridge Regression</title>
      <link>https://arxiv.org/abs/2402.10596</link>
      <description>arXiv:2402.10596v2 Announce Type: replace 
Abstract: We propose a data-driven sensor-selection algorithm for accurate estimation of the target variables from the selected measurements. The target variables are assumed to be estimated by a ridge-regression estimator which is trained based on the data. The proposed algorithm greedily selects sensors for minimizing the cost function of the estimator. Sensor selection which prevents overfitting of the resulting estimator can be realized by setting a positive regularization parameter. The greedy solution is computed in quite a short time by using some recurrent relations that we derive. The effectiveness of the proposed algorithm is verified for artificial datasets which are generated from linear systems and a real-wold dataset which are aimed for selection of pressure-sensor locations for estimating yaw angle of a ground vehicle. The demonstration for the datasets reveal that the proposed algorithm computes a sensor set resulting in more accurate estimation than existing data-drive selection algorithms in some conditions. Furthermore, it is confirmed that setting a positive regularization parameter in the proposed algorithm leads to accurate estimation when overfitting is problematic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.10596v2</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/JSEN.2025.3537702</arxiv:DOI>
      <arxiv:journal_reference>in IEEE Sensors Journal, vol. 25, no. 6, pp. 10030-10045, 2025</arxiv:journal_reference>
      <dc:creator>Yasuo Sasaki, Keigo Yamada, Takayuki Nagata, Yuji Saito, Taku Nonomura</dc:creator>
    </item>
    <item>
      <title>Analyzing Downlink Coverage in Clustered Low Earth Orbit Satellite Constellations: A Stochastic Geometry Approach</title>
      <link>https://arxiv.org/abs/2402.16307</link>
      <description>arXiv:2402.16307v3 Announce Type: replace 
Abstract: Satellite networks are emerging as vital solutions for global connectivity beyond 5G. As companies such as SpaceX, OneWeb, and Amazon are poised to launch a large number of satellites in low Earth orbit, the heightened inter-satellite interference caused by mega-constellations has become a significant concern. To address this challenge, recent works have introduced the concept of satellite cluster networks where multiple satellites in a cluster collaborate to enhance the network performance. In order to investigate the performance of these networks, we propose mathematical analyses by modeling the locations of satellites and users using Poisson point processes, building on the success of stochastic geometry-based analyses for satellite networks. In particular, we suggest the lower and upper bounds of the coverage probability as functions of the system parameters, including satellite density, satellite altitude, satellite cluster area, path loss exponent, and Nakagami parameter $m$. We validate the analytical expressions by comparing them with simulation results. Our analyses can be used to design reliable satellite cluster networks by effectively estimating the impact of system parameters on the coverage performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.16307v3</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Miyeon Lee, Sucheol Kim, Minje Kim, Dong-Hyun Jung, Junil Choi</dc:creator>
    </item>
    <item>
      <title>Accelerated Real-time Cine and Flow under In-magnet Staged Exercise</title>
      <link>https://arxiv.org/abs/2402.17877</link>
      <description>arXiv:2402.17877v3 Announce Type: replace 
Abstract: Background: Cardiovascular magnetic resonance imaging (CMR) is a well established imaging tool for diagnosing and managing cardiac conditions. The integration of exercise stress with CMR (ExCMR) can enhance its diagnostic capacity. Despite recent advances in CMR technology, quantitative ExCMR during exercise remains technically challenging due to motion artifacts and limited spatial and temporal resolution. Methods: This study investigated the feasibility of biventricular functional and hemodynamic assessment using real-time (RT) ExCMR during a staged exercise protocol in 24 healthy volunteers. We employed high acceleration rates and applied a coil reweighting technique to minimize motion blurring and artifacts. We further applied a beat-selection technique that identified beats from the endexpiratory phase to minimize the impact of respiration-induced through-plane motion on cardiac function quantification. Additionally, results from six patients were presented to demonstrate clinical feasibility. Results: Our findings indicated a consistent decrease in end-systolic volume and stable end-diastolic volume across exercise intensities, leading to increased stroke volume and ejection fraction. The selection of end-expiratory beats modestly enhanced the repeatability of cardiac function parameters, as shown by scan-rescan tests in nine volunteers. High scores from a blinded image quality assessment indicated that coil reweighting effectively minimized motion artifacts. Conclusions: This study demonstrated the feasibility of RT ExCMR with inmagnet exercise in healthy subjects and patients. Our results indicate that high acceleration rates, coil reweighting, and selection of respiratory phase-specific heartbeats enhance image quality and repeatability of quantitative RT ExCMR.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.17877v3</guid>
      <category>eess.SP</category>
      <category>eess.IV</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Preethi Chandrasekaran, Chong Chen, Yingmin Liu, Syed Murtaza Arshad, Christopher Crabtree, Matthew Tong, Yuchi Han, Rizwan Ahmad</dc:creator>
    </item>
    <item>
      <title>Spatial-Division ISAC: A Practical Waveform Design Strategy via Null-Space Superimposition</title>
      <link>https://arxiv.org/abs/2412.10541</link>
      <description>arXiv:2412.10541v2 Announce Type: replace 
Abstract: Integrated sensing and communications (ISAC) is a key enabler of new applications, such as precision agriculture, extended reality (XR), and digital twins, for 6G wireless systems. However, the implementation of ISAC technology is very challenging due to practical constraints such as high complexity. In this paper, we introduce a novel ISAC waveform design strategy, called the spatial-division ISAC (SD-ISAC) waveform, which simplifies the ISAC waveform design problem by decoupling it into separate communication and radar waveform design tasks. Specifically, the proposed strategy leverages the null-space of the communication channel to superimpose sensing signals onto communication signals without interference. This approach offers multiple benefits, including reduced complexity and the reuse of existing communication and radar waveforms. We then address the problem of optimizing the spatial and temporal properties of the proposed waveform. We develop a low-complexity beampattern matching algorithm, leveraging a majorization-minimization (MM) technique. Furthermore, we develop a range sidelobe suppression algorithm based on manifold optimization. We provide comprehensive discussions on the practical advantages and potential challenges of the proposed method, including null-space feedback. We evaluate the performance of the proposed waveform design algorithm through extensive simulations. Simulation results show that the proposed method can provide similar or even superior performance to existing ISAC algorithms while reducing computation time significantly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10541v2</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Byunghyun Lee, Hwanjin Kim, David J. Love, James V. Krogmeier</dc:creator>
    </item>
    <item>
      <title>Unsupervised Learning for AoD Estimation in MISO Downlink LoS Transmissions</title>
      <link>https://arxiv.org/abs/2503.12033</link>
      <description>arXiv:2503.12033v2 Announce Type: replace 
Abstract: With the emergence of simultaneous localization and communication (SLAC), it becomes more and more attractive to perform angle of departure (AoD) estimation at the receiving Internet of Thing (IoT) user end for improved positioning accuracy, flexibility and enhanced user privacy. To address challenges like a large number of real-time measurements required for latency-critical applications and enormous data collection for training deep learning models in conventional AoD estimation methods, we propose in this letter an unsupervised learning framework, which unifies training for both deterministic maximum likelihood (DML) and stochastic maximum likelihood (SML) based AoD estimation in multiple-input single-output (MISO) downlink (DL) wireless transmissions. Specifically, under the line-of-sight (LoS) assumption, we incorporate both the received signals and pilot-sequence information, as per its availability at the DL user, into the input of the deep learning model, and adopt a common neural network architecture compatible with input data in both DML and SML cases. Extensive numerical results validate that the proposed unsupervised learning based AoD estimation not only improves estimation accuracy, but also significantly reduces required number of observations, thereby reducing both estimation overhead and latency compared to various benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.12033v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiaying Li, Yuanwei Liu, Hong Xing</dc:creator>
    </item>
    <item>
      <title>Resource Allocation for RIS-Assisted CoMP-NOMA Networks using Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2504.00975</link>
      <description>arXiv:2504.00975v2 Announce Type: replace 
Abstract: This thesis delves into the forefront of wireless communication by exploring the synergistic integration of three transformative technologies: STAR-RIS, CoMP, and NOMA. Driven by the ever-increasing demand for higher data rates, improved spectral efficiency, and expanded coverage in the evolving landscape of 6G development, this research investigates the potential of these technologies to revolutionize future wireless networks.
  The thesis analyzes the performance gains achievable through strategic deployment of STAR-RIS, focusing on mitigating inter-cell interference, enhancing signal strength, and extending coverage to cell-edge users. Resource sharing strategies for STAR-RIS elements are explored, optimizing both transmission and reflection functionalities. Analytical frameworks are developed to quantify the benefits of STAR-RIS assisted CoMP-NOMA networks under realistic channel conditions, deriving key performance metrics such as ergodic rates and outage probabilities. Additionally, the research delves into energy-efficient design approaches for CoMP-NOMA networks incorporating RIS, proposing novel RIS configurations and optimization algorithms to achieve a balance between performance and energy consumption. Furthermore, the application of Deep Reinforcement Learning (DRL) techniques for intelligent and adaptive optimization in aerial RIS-assisted CoMP-NOMA networks is explored, aiming to maximize network sum rate while meeting user quality of service requirements. Through a comprehensive investigation of these technologies and their synergistic potential, this thesis contributes valuable insights into the future of wireless communication, paving the way for the development of more efficient, reliable, and sustainable networks capable of meeting the demands of our increasingly connected world.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.00975v2</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muhammad Umer, Muhammad Ahmed Mohsin, Huma Ghafoor, Syed Ali Hassan</dc:creator>
    </item>
    <item>
      <title>xApp Conflict Mitigation with Scheduler</title>
      <link>https://arxiv.org/abs/2504.06867</link>
      <description>arXiv:2504.06867v2 Announce Type: replace 
Abstract: Open RAN (O-RAN) fosters multi-vendor interoperability and data-driven control but simultaneously introduces the challenge of coordinating pre-trained xApps that may produce conflicting actions. Although O-RAN specifications mandate offline training and validation to prevent the deployment of untrained or inadequately tested models, operational conflicts can still arise under dynamic and context-dependent conditions.This work proposes a scheduler-based conflict mitigation framework to address these challenges without requiring training xApps together or further xApp re-training. By examining an indirect conflict involving power and resource block allocation xApps and employing an Advantage Actor-Critic (A2C) approach to train both xApps and the scheduler, we illustrate that a straightforward A2C-based scheduler improves performance relative to independently deployed xApps and conflicting cases. Notably, among all tested deployment scenarios (including individual xApp deployment, multiple conflicting xApps, and limited scheduler configurations), augmenting the system with baseline xApps and enabling the scheduler to select from a broader pool achieves the highest total transmission rate, thereby underscoring the importance of adaptive scheduling mechanisms. These findings highlight the context-dependent nature of conflicts in automated network management, as two xApps may conflict under certain conditions but coexist under others. Consequently, the ability to dynamically update and adapt the scheduler to accommodate diverse operational intents is vital for future network deployments. By offering dynamic scheduling without re-training xApps, this framework advances practical conflict resolution solutions while supporting real-world scalability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06867v2</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Idris Cinemre, Toktam Mahmoodi, Amirmohammad Farzaneh</dc:creator>
    </item>
    <item>
      <title>Fusing Bluetooth with Pedestrian Dead Reckoning: A Floor Plan-Assisted Positioning Approach</title>
      <link>https://arxiv.org/abs/2504.09905</link>
      <description>arXiv:2504.09905v2 Announce Type: replace 
Abstract: Floor plans can provide valuable prior information that helps enhance the accuracy of indoor positioning systems. However, existing research typically faces challenges in efficiently leveraging floor plan information and applying it to complex indoor layouts. To fully exploit information from floor plans for positioning, we propose a floor plan-assisted fusion positioning algorithm (FP-BP) using Bluetooth low energy (BLE) and pedestrian dead reckoning (PDR). In the considered system, a user holding a smartphone walks through a positioning area with BLE beacons installed on the ceiling, and can locate himself in real time. In particular, FP-BP consists of two phases. In the offline phase, FP-BP programmatically extracts map features from a stylized floor plan based on their binary masks, and constructs a mapping function to identify the corresponding map feature of any given position on the map. In the online phase, FP-BP continuously computes BLE positions and PDR results from BLE signals and smartphone sensors, where a novel grid-based maximum likelihood estimation (GML) algorithm is introduced to enhance BLE positioning. Then, a particle filter is used to fuse them and obtain an initial estimate. Finally, FP-BP performs post-position correction to obtain the final position based on its specific map feature. Experimental results show that FP-BP can achieve a real-time mean positioning accuracy of 1.19 m, representing an improvement of over 28% compared to existing floor plan-fused baseline algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09905v2</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenxuan Pan, Yang Yang, Mingzhe Chen, Dong Wei, Caili Guo, Shiwen Mao</dc:creator>
    </item>
    <item>
      <title>Traffic Congestion Prediction Using Machine Learning Techniques</title>
      <link>https://arxiv.org/abs/2206.10983</link>
      <description>arXiv:2206.10983v5 Announce Type: replace-cross 
Abstract: The prediction of traffic congestion can serve a crucial role in making future decisions. Although many studies have been conducted regarding congestion, most of these could not cover all the important factors (e.g., weather conditions). We proposed a prediction model for traffic congestion that can predict congestion based on day, time and several weather data (e.g., temperature, humidity). To evaluate our model, it has been tested against the traffic data of New Delhi. With this model, congestion of a road can be predicted one week ahead with an average RMSE of 1.12. Therefore, this model can be used to take preventive measure beforehand.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.10983v5</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rafed Muhammad Yasir, Moumita Asad, Naushin Nower, Mohammad Shoyaib</dc:creator>
    </item>
    <item>
      <title>LEO-based Positioning: Foundations, Signal Design, and Receiver Enhancements for 6G NTN</title>
      <link>https://arxiv.org/abs/2410.18301</link>
      <description>arXiv:2410.18301v2 Announce Type: replace-cross 
Abstract: The integration of non-terrestrial networks (NTN) into 5G new radio (NR) has opened up the possibility of developing a new positioning infrastructure using NR signals from Low-Earth Orbit (LEO) satellites. Compared to existing Global Navigation Satellite Systems (GNSS), LEO-based cellular positioning offers several advantages, such as a superior link budget, higher operating bandwidth, and large forthcoming constellations. Due to these factors, LEO-based positioning, navigation, and timing (PNT) is a potential enhancement for NTN in 6G cellular networks. However, extending the existing terrestrial cellular positioning methods to LEO-based NTN positioning requires key fundamental enhancements. These include creating broad positioning beams orthogonal to conventional communication beams, time-domain processing at the user equipment (UE) to resolve large delay and Doppler uncertainties, and efficiently accommodating positioning reference signals (PRS) from multiple satellites within the communication resource grid. In this paper, we present the first set of design insights by incorporating these enhancements and thoroughly evaluating LEO-based positioning, considering the constraints and capabilities of the NR-NTN physical layer. To evaluate the performance of LEO-based NTN positioning, we develop a comprehensive NR-compliant simulation framework, including LEO orbit simulation, transmission (Tx) and receiver (Rx) architectures, and a positioning engine incorporating the necessary enhancements. Our findings suggest that LEO-based NTN positioning could serve as a complementary infrastructure to GNSS and, with appropriate enhancements, may also offer a viable alternative.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18301v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Harish K. Dureppagari, Chiranjib Saha, Harikumar Krishnamurthy, Xiao Feng Wang, Alberto Rico-Alvari\~no, R. Michael Buehrer, Harpreet S. Dhillon</dc:creator>
    </item>
    <item>
      <title>PK-YOLO: Pretrained Knowledge Guided YOLO for Brain Tumor Detection in Multiplanar MRI Slices</title>
      <link>https://arxiv.org/abs/2410.21822</link>
      <description>arXiv:2410.21822v2 Announce Type: replace-cross 
Abstract: Brain tumor detection in multiplane Magnetic Resonance Imaging (MRI) slices is a challenging task due to the various appearances and relationships in the structure of the multiplane images. In this paper, we propose a new You Only Look Once (YOLO)-based detection model that incorporates Pretrained Knowledge (PK), called PK-YOLO, to improve the performance for brain tumor detection in multiplane MRI slices. To our best knowledge, PK-YOLO is the first pretrained knowledge guided YOLO-based object detector. The main components of the new method are a pretrained pure lightweight convolutional neural network-based backbone via sparse masked modeling, a YOLO architecture with the pretrained backbone, and a regression loss function for improving small object detection. The pretrained backbone allows for feature transferability of object queries on individual plane MRI slices into the model encoders, and the learned domain knowledge base can improve in-domain detection. The improved loss function can further boost detection performance on small-size brain tumors in multiplanar two-dimensional MRI slices. Experimental results show that the proposed PK-YOLO achieves competitive performance on the multiplanar MRI brain tumor detection datasets compared to state-of-the-art YOLO-like and DETR-like object detectors. The code is available at https://github.com/mkang315/PK-YOLO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21822v2</guid>
      <category>cs.CV</category>
      <category>eess.IV</category>
      <category>eess.SP</category>
      <category>stat.AP</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/WACV61041.2025.00367</arxiv:DOI>
      <arxiv:journal_reference>In WACV (2025) 3732--3741</arxiv:journal_reference>
      <dc:creator>Ming Kang, Fung Fung Ting, Rapha\"el C. -W. Phan, Chee-Ming Ting</dc:creator>
    </item>
    <item>
      <title>System-Level Experimental Evaluation of Reconfigurable Intelligent Surfaces for NextG Communication Systems</title>
      <link>https://arxiv.org/abs/2412.12969</link>
      <description>arXiv:2412.12969v2 Announce Type: replace-cross 
Abstract: Reconfigurable Intelligent Surfaces (RISs) are a promising technique for enhancing the performance of Next Generation (NextG) wireless communication systems in terms of both spectral and energy efficiency, as well as resource utilization. However, current RIS research has primarily focused on theoretical modeling and Physical (PHY) layer considerations only. Full protocol stack emulation and accurate modeling of the propagation characteristics of the wireless channel are necessary for studying the benefits introduced by RIS technology across various spectrum bands and use-cases. In this paper, we propose, for the first time: (i) accurate PHY layer RIS-enabled channel modeling through Geometry-Based Stochastic Models (GBSMs), leveraging the QUAsi Deterministic RadIo channel GenerAtor (QuaDRiGa) open-source statistical ray-tracer; (ii) optimized resource allocation with RISs by comprehensively studying energy efficiency and power control on different portions of the spectrum through a single-leader multiple-followers Stackelberg game theoretical approach; (iii) full-stack emulation and performance evaluation of RIS-assisted channels with SCOPE/srsRAN for Enhanced Mobile Broadband (eMBB) and Ultra Reliable and Low Latency Communications (URLLC) applications in the worlds largest emulator of wireless systems with hardware-in-the-loop, namely Colosseum. Our findings indicate (i) the significant power savings in terms of energy efficiency achieved with RIS-assisted topologies, especially in the millimeter wave (mmWave) band; and (ii) the benefits introduced for Sub-6 GHz band User Equipments (UEs), where the deployment of a relatively small RIS (e.g., in the order of 100 RIS elements) can result in decreased levels of latency for URLLC services in resource-constrained environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12969v2</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maria Tsampazi, Tommaso Melodia</dc:creator>
    </item>
    <item>
      <title>Driving Innovation in 6G Wireless Technologies: The OpenAirInterface Approach</title>
      <link>https://arxiv.org/abs/2412.13295</link>
      <description>arXiv:2412.13295v3 Announce Type: replace-cross 
Abstract: The development of 6G wireless technologies is rapidly advancing, with the 3rd Generation Partnership Project (3GPP) entering the pre-standardization phase and aiming to deliver the first specifications by 2028. This paper explores the OpenAirInterface (OAI) project, an open-source initiative that plays a crucial role in the evolution of 5G and future 6G networks. OAI provides a comprehensive implementation of 3GPP and O-RAN compliant networks, including Radio Access Network (RAN), Core Network (CN), and software-defined User Equipment (UE) components. This paper details the history and evolution of OAI, its licensing model, and the various projects under its umbrella, such as RAN, the CN, and the Operations, Administration and Maintenance (OAM) projects. It also highlights the development methodology, Continuous Integration/Continuous Delivery (CI/CD) processes, and end-to-end systems powered by OAI. Furthermore, the paper discusses the potential of OAI for 6G research, focusing on spectrum, reflective intelligent surfaces, and Artificial Intelligence (AI)/Machine Learning (ML) integration. The open-source approach of OAI is emphasized as essential for tackling the challenges of 6G, fostering community collaboration, and driving innovation in next-generation wireless technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13295v3</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Florian Kaltenberger, Tommaso Melodia, Irfan Ghauri, Michele Polese, Raymond Knopp, Tien Thinh Nguyen, Sakthivel Velumani, Davide Villa, Leonardo Bonati, Robert Schmidt, Sagar Arora, Mikel Irazabal, Navid Nikaein</dc:creator>
    </item>
    <item>
      <title>Hybrid Beamforming Design for RSMA-enabled Near-Field Integrated Sensing and Communications</title>
      <link>https://arxiv.org/abs/2412.17062</link>
      <description>arXiv:2412.17062v2 Announce Type: replace-cross 
Abstract: Integrated sensing and communication (ISAC) networks leverage extremely large antenna arrays and high frequencies. This inevitably extends the Rayleigh distance, making near-field (NF) spherical wave propagation dominant. This unlocks numerous spatial degrees of freedom, raising the challenge of optimizing them for communication and sensing tradeoffs. To this end, we propose a rate-splitting multiple access (RSMA)-based NF-ISAC transmit scheme utilizing hybrid analog-digital antennas. RSMA enhances interference management, while a variable number of dedicated sensing beams adds beamforming flexibility. The objective is to maximize the minimum communication rate while ensuring multi-target sensing performance by jointly optimizing receive filters, analog and digital beamformers, common rate allocation, and the sensing beam count. To address uncertainty in sensing beam allocation, a rank-zero solution reconstruction method demonstrates that dedicated sensing beams are unnecessary for NF multi-target detection. A penalty dual decomposition (PDD)-based double-loop algorithm is introduced, employing weighted minimum mean-squared error (WMMSE) and quadratic transforms to reformulate communication and sensing rates. Simulations reveal that the proposed scheme: 1) achieves performance comparable to fully digital beamforming with fewer RF chains, (2) maintains NF multi-target detection without compromising communication rates, and 3) significantly outperforms conventional multiple access schemes and far-field ISAC systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17062v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiasi Zhou, Chintha Tellambura, Geoffrey Ye Li</dc:creator>
    </item>
    <item>
      <title>Graph-Based Prediction Models for Data Debiasing</title>
      <link>https://arxiv.org/abs/2504.09348</link>
      <description>arXiv:2504.09348v2 Announce Type: replace-cross 
Abstract: Bias in data collection, arising from both under-reporting and over-reporting, poses significant challenges in critical applications such as healthcare and public safety. In this work, we introduce Graph-based Over- and Under-reporting Debiasing (GROUD), a novel graph-based optimization framework that debiases reported data by jointly estimating the true incident counts and the associated reporting bias probabilities. By modeling the bias as a smooth signal over a graph constructed from geophysical or feature-based similarities, our convex formulation not only ensures a unique solution but also comes with theoretical recovery guarantees under certain assumptions. We validate GROUD on both challenging simulated experiments and real-world datasets -- including Atlanta emergency calls and COVID-19 vaccine adverse event reports -- demonstrating its robustness and superior performance in accurately recovering debiased counts. This approach paves the way for more reliable downstream decision-making in systems affected by reporting irregularities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09348v2</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dongze Wu, Hanyang Jiang, Yao Xie</dc:creator>
    </item>
    <item>
      <title>SegOTA: Accelerating Over-the-Air Federated Learning with Segmented Transmission</title>
      <link>https://arxiv.org/abs/2504.09745</link>
      <description>arXiv:2504.09745v2 Announce Type: replace-cross 
Abstract: Federated learning (FL) with over-the-air computation efficiently utilizes the communication resources, but it can still experience significant latency when each device transmits a large number of model parameters to the server. This paper proposes the Segmented Over-The-Air (SegOTA) method for FL, which reduces latency by partitioning devices into groups and letting each group transmit only one segment of the model parameters in each communication round. Considering a multi-antenna server, we model the SegOTA transmission and reception process to establish an upper bound on the expected model learning optimality gap. We minimize this upper bound, by formulating the per-round online optimization of device grouping and joint transmit-receive beamforming, for which we derive efficient closed-form solutions. Simulation results show that our proposed SegOTA substantially outperforms the conventional full-model OTA approach and other common alternatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09745v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chong Zhang, Min Dong, Ben Liang, Ali Afana, Yahia Ahmed</dc:creator>
    </item>
  </channel>
</rss>
