<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 09 Jan 2026 05:00:28 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Generalized Adaptive Joint Learning Framework for High-Dimensional Time-Varying Models</title>
      <link>https://arxiv.org/abs/2601.04499</link>
      <description>arXiv:2601.04499v1 Announce Type: cross 
Abstract: In modern biomedical and econometric studies, longitudinal processes are often characterized by complex time-varying associations and abrupt regime shifts that are shared across correlated outcomes. Standard functional data analysis (FDA) methods, which prioritize smoothness, often fail to capture these dynamic structural features, particularly in high-dimensional settings. This article introduces Adaptive Joint Learning (AJL), a regularization framework designed to simultaneously perform functional variable selection and structural changepoint detection in multivariate time-varying coefficient models. We propose a convex optimization procedure that synergizes adaptive group-wise penalization with fused regularization, effectively borrowing strength across multiple outcomes to enhance estimation efficiency. We provide a rigorous theoretical analysis of the estimator in the ultra-high-dimensional regime (p &gt;&gt; n), establishing non-asymptotic error bounds and proving that AJL achieves the oracle property--performing as well as if the true active set and changepoint locations were known a priori. A key theoretical contribution is the explicit handling of approximation bias via undersmoothing conditions to ensure valid asymptotic inference. The proposed method is validated through comprehensive simulations and an application to Primary Biliary Cirrhosis (PBC) data. The analysis uncovers synchronized phase transitions in disease progression and identifies a parsimonious set of time-varying prognostic markers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.04499v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Baolin Chen, Mengfei Ran</dc:creator>
    </item>
    <item>
      <title>MDAS: A Diagnostic Approach to Assess the Quality of Data Splitting in Machine Learning</title>
      <link>https://arxiv.org/abs/2206.11721</link>
      <description>arXiv:2206.11721v2 Announce Type: replace 
Abstract: In the field of machine learning, model performance is usually assessed by randomly splitting data into training and test sets. Different random splits, however, can yield markedly different performance estimates, so a genuinely good model may be discarded or a poor one selected purely due to an unlucky partition. This motivates a principled way to diagnose the quality of a given data split. We propose a diagnostic framework based on a new discrepancy measure, the Mahalanobis Distribution Alignment Score (MDAS). MDAS is a symmetric dissimilarity measure between two multivariate samples, rather than a strict metric. MDAS captures both mean and covariance differences and is affine invariant. Building on this, we construct a Monte Carlo test that evaluates whether an observed split is statistically compatible with typical random splits, yielding an interpretable p-value for split quality. Using several real data sets, we study the relationship between MDAS and model robustness, including its association with the normalized Akaike information criterion. Finally, we apply MDAS to compare existing state-of-the-art deterministic data-splitting strategies with standard random splitting. The experimental results show that MDAS provides a simple, model-agnostic tool for auditing data splits and improving the reliability of empirical model evaluation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.11721v2</guid>
      <category>stat.CO</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Palash Ghosh, Bittu Karmakar, Eklavya Jain, J. Neeraja, Buddhananda Banerjee, Tanujit Chakraborty</dc:creator>
    </item>
    <item>
      <title>Closed-form approximations of the two-sample Pearson Bayes factor</title>
      <link>https://arxiv.org/abs/2310.11313</link>
      <description>arXiv:2310.11313v3 Announce Type: replace 
Abstract: In this paper, I present three closed-form approximations of the two-sample Pearson Bayes factor, a recently developed index of evidential value for data in two-group designs. The techniques rely on some classical asymptotic results about Gamma functions. These approximations permit simple closed-form calculation of the Pearson Bayes factor in cases where only minimal summary statistics are available (i.e., the t-score and degrees of freedom). Moreover, these approximations vastly outperform the classic BIC method for approximating Bayes factors from experimental designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.11313v3</guid>
      <category>stat.CO</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas J. Faulkenberry</dc:creator>
    </item>
    <item>
      <title>Demonstrating the power and flexibility of variational assumptions for amortized neural posterior estimation in environmental applications</title>
      <link>https://arxiv.org/abs/2404.10899</link>
      <description>arXiv:2404.10899v2 Announce Type: replace 
Abstract: Classic Bayesian methods with complex models are frequently infeasible due to an intractable likelihood. Simulation-based inference methods, such as Approximate Bayesian Computing (ABC), calculate posteriors without accessing a likelihood function by leveraging the fact that data can be quickly simulated from the model, but converge slowly and/or poorly in high-dimensional settings. In this paper, we propose a framework for Bayesian posterior estimation by mapping data to posteriors of parameters using a neural network trained on data simulated from the complex model. Posterior distributions of model parameters are efficiently obtained by feeding observed data into the trained neural network. We show theoretically that our posteriors converge to the true posteriors in Kullback-Leibler divergence. Our approach yields computationally efficient and theoretically justified uncertainty quantification, which is lacking in existing simulation-based neural network approaches. Comprehensive simulation studies highlight our method's robustness and accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10899v2</guid>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elliot Maceda, Emily C. Hector, Amanda Lenzi, Brian J. Reich</dc:creator>
    </item>
    <item>
      <title>FastRerandomize: Fast Rerandomization Using Accelerated Computing</title>
      <link>https://arxiv.org/abs/2501.07642</link>
      <description>arXiv:2501.07642v3 Announce Type: replace 
Abstract: We present fastrerandomize, an R package for fast, scalable rerandomization in experimental design. Rerandomization improves precision by discarding treatment assignments that fail a prespecified covariate-balance criterion, but existing implementations can become computationally prohibitive as the number of units or covariates grows. fastrerandomize introduces three complementary advances: (i) optional GPU/TPU acceleration to parallelize balance checks, (ii) memory-efficient key-only storage that avoids retaining full assignment matrices, and (iii) auto-vectorized, just-in-time compiled kernels for batched candidate generation and inference. This approach enables exact or Monte Carlo rerandomization at previously intractable scales, making it practical to adopt the tighter balance thresholds required in modern high-dimensional experiments while simultaneously quantifying the resulting gains in precision and power for a given covariate set. Our approach also supports randomization-based testing conditioned on acceptance. In controlled benchmarks, we observe order-of-magnitude speedups over baseline workflows, with larger gains as the sample size or dimensionality grows, translating into improved precision of causal estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07642v3</guid>
      <category>stat.CO</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rebecca Goldstein, Connor T. Jerzak, Aniket Kamat, Fucheng Warren Zhu</dc:creator>
    </item>
    <item>
      <title>Propagating Surrogate Uncertainty in Bayesian Inverse Problems</title>
      <link>https://arxiv.org/abs/2601.03532</link>
      <description>arXiv:2601.03532v2 Announce Type: replace-cross 
Abstract: Standard Bayesian inference schemes are infeasible for inverse problems with computationally expensive forward models. A common solution is to replace the model with a cheaper surrogate. To avoid overconfident conclusions, it is essential to acknowledge the surrogate approximation by propagating its uncertainty. At present, a variety of distinct uncertainty propagation methods have been suggested, with little understanding of how they vary. To fill this gap, we propose a mixture distribution termed the expected posterior (EP) as a general baseline for uncertainty-aware posterior approximation, justified by decision theoretic and modular Bayesian inference arguments. We then investigate the expected unnormalized posterior (EUP), a popular heuristic alternative, analyzing when it may deviate from the EP baseline. Our results show that this heuristic can break down when the surrogate uncertainty is highly non-uniform over the design space, as can be the case when the log-likelihood is emulated by a Gaussian process. Finally, we present the random kernel preconditioned Crank-Nicolson (RKpCN) algorithm, an approximate Markov chain Monte Carlo scheme that provides practical EP approximation in the challenging setting involving infinite-dimensional Gaussian process surrogates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03532v2</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrew Gerard Roberts, Michael Dietze, Jonathan H. Huggins</dc:creator>
    </item>
  </channel>
</rss>
