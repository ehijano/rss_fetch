<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 05 Mar 2025 03:01:48 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Fed-KAN: Federated Learning with Kolmogorov-Arnold Networks for Traffic Prediction</title>
      <link>https://arxiv.org/abs/2503.00154</link>
      <description>arXiv:2503.00154v1 Announce Type: new 
Abstract: Non-Terrestrial Networks (NTNs) are becoming a critical component of modern communication infrastructures, especially with the advent of Low Earth Orbit (LEO) satellite systems. Traditional centralized learning approaches face major challenges in such networks due to high latency, intermittent connectivity and limited bandwidth. Federated Learning (FL) is a promising alternative as it enables decentralized training while maintaining data privacy. However, existing FL models, such as Federated Learning with Multi-Layer Perceptrons (Fed-MLP), can struggle with high computational complexity and poor adaptability to dynamic NTN environments. This paper provides a detailed analysis for Federated Learning with Kolmogorov-Arnold Networks (Fed-KAN), its implementation and performance improvements over traditional FL models in NTN environments for traffic forecasting. The proposed Fed-KAN is a novel approach that utilises the functional approximation capabilities of KANs in a FL framework. We evaluate Fed-KAN compared to Fed-MLP on a traffic dataset of real satellite operator and show a significant reduction in training and test loss. Our results show that Fed-KAN can achieve a 77.39% reduction in average test loss compared to Fed-MLP, highlighting its improved performance and better generalization ability. At the end of the paper, we also discuss some potential applications of Fed-KAN within O-RAN and Fed-KAN usage for split functionalities in NTN architecture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00154v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Engin Zeydan, Cristian J. Vaca-Rubio, Luis Blanco, Roberto Pereira, Marius Caus, Kapal Dev</dc:creator>
    </item>
    <item>
      <title>QaSAL: QoS-aware State-Augmented Learnable Algorithms for Coexistence of 5G NR-U/Wi-Fi</title>
      <link>https://arxiv.org/abs/2503.00259</link>
      <description>arXiv:2503.00259v1 Announce Type: new 
Abstract: With the increasing demand for wireless connectivity, ensuring the efficient coexistence of multiple radio access technologies in shared unlicensed spectrum has become an important issue. This paper focuses on optimizing Medium Access Control (MAC) parameters to enhance the coexistence of 5G New Radio in Unlicensed Spectrum (NR-U) and Wi-Fi networks operating in unlicensed spectrum with multiple priority classes of traffic that may have varying quality-of-service (QoS) requirements. In this context, we tackle the coexistence parameter management problem by introducing a QoS-aware State-Augmented Learnable (QaSAL) framework, designed to improve network performance under various traffic conditions. Our approach augments the state representation with constraint information, enabling dynamic policy adjustments to enforce QoS requirements effectively. Simulation results validate the effectiveness of QaSAL in managing NR-U and Wi-Fi coexistence, demonstrating improved channel access fairness while satisfying a latency constraint for high-priority traffic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00259v1</guid>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Reza Fasihi, Brian L. Mark</dc:creator>
    </item>
    <item>
      <title>Uncoordinated Access to Serverless Computing in MEC Systems for IoT</title>
      <link>https://arxiv.org/abs/2503.00375</link>
      <description>arXiv:2503.00375v1 Announce Type: new 
Abstract: Edge computing is a promising solution to enable low-latency IoT applications, by shifting computation from remote data centers to local devices, less powerful but closer to the end user devices. However, this creates the challenge on how to best assign clients to edge nodes offering compute capabilities. So far, two antithetical architectures are proposed: centralized resource orchestration or distributed overlay. In this work we explore a third way, called uncoordinated access, which consists in letting every device exploring multiple opportunities, to opportunistically embrace the heterogeneity of network and load conditions towards diverse edge nodes. In particular, our contribution is intended for emerging serverless IoT applications, which do not have a state on the edge nodes executing tasks. We model the proposed system as a set of M/M/1 queues and show that it achieves a smaller jitter delay than single edge node allocation. Furthermore, we compare uncoordinated access with state-of-the-art centralized and distributed alternatives in testbed experiments under more realistic conditions. Based on the results, our proposed approach, which requires a tiny fraction of the complexity of the alternatives in both the device and network components, is very effective in using the network resources, while incurring only a small penalty in terms of increased compute load and high percentiles of delay.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00375v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.comnet.2020.107184</arxiv:DOI>
      <arxiv:journal_reference>Computer Networks, Volume 172, 2020, 107184, ISSN 1389-1286</arxiv:journal_reference>
      <dc:creator>Claudio Cicconetti, Marco Conti, Andrea Passarella</dc:creator>
    </item>
    <item>
      <title>LLMs are everywhere: Ubiquitous Utilization of AI Models through Air Computing</title>
      <link>https://arxiv.org/abs/2503.00767</link>
      <description>arXiv:2503.00767v1 Announce Type: new 
Abstract: We are witnessing a new era where problem-solving and cognitive tasks are being increasingly delegated to Large Language Models (LLMs) across diverse domains, ranging from code generation to holiday planning. This trend also creates a demand for the ubiquitous execution of LLM-powered applications in a wide variety of environments in which traditional terrestrial 2D networking infrastructures may prove insufficient. A promising solution in this context is to extend edge computing into a 3D setting to include aerial platforms organized in multiple layers, a paradigm we refer to as air computing, to augment local devices for running LLM and Generative AI (GenAI) applications. This approach alleviates the strain on existing infrastructure while enhancing service efficiency by offloading computational tasks to the corresponding air units such as UAVs. Furthermore, the coordinated deployment of various air units can significantly improve the Quality of Experience (QoE) by ensuring seamless, adaptive, and resilient task execution. In this study, we investigate the synergy between LLM-based applications and air computing, exploring their potential across various use cases. Additionally, we present a disaster response case study demonstrating how the collaborative utilization of LLMs and air computing can significantly improve outcomes in critical situations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00767v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Baris Yamansavascilar, Atay Ozgovde, Cem Ersoy</dc:creator>
    </item>
    <item>
      <title>Design, Implementation and Practical Evaluation of an Opportunistic Communications Protocol Based on Bluetooth Mesh and libp2p</title>
      <link>https://arxiv.org/abs/2503.00976</link>
      <description>arXiv:2503.00976v1 Announce Type: new 
Abstract: The increasing proliferation of Internet of Things (IoT) devices has created a growing need for more efficient communication networks, especially in areas where continuous connectivity is unstable or unavailable. Opportunistic networks have emerged as a possible solution in such scenarios, allowing for intermittent and decentralized data sharing. This article presents a novel communication protocol that uses Bluetooth 5 and the libp2p framework to enable decentralized and opportunistic communications among IoT devices. The protocol provides dynamic peer discovery and decentralized management, resulting in a more flexible and robust IoT network infrastructure. The performance of the proposed architecture was evaluated through experiments in both controlled and industrial scenarios, with a particular emphasis on latency and on the impact of the presence of obstacles. The obtained results show that the protocol has the ability to improve data transfer in environments with limited connectivity, making it adequate for both urban and rural areas, as well as for challenging environments such as shipyards. Moreover, the presented findings conclude that the protocol works well in situations with minimal signal obstruction and short distances, like homes, where average latency values of about 8 s have been achieved with no losses. Furthermore, the protocol can also be used in industrial scenarios, even when metal obstacles increase signal attenuation, and over long distances, where average latency values of about 8.5 s have been obtained together with packet losses of less than 5%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00976v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.3390/s25041190</arxiv:DOI>
      <dc:creator>\'Angel Niebla-Montero, Iv\'an Froiz-M\'iguez, Paula Fraga-Lamas, Tiago M. Fern\'andez-Caram\'es</dc:creator>
    </item>
    <item>
      <title>Comparative Analysis of Ray Tracing and Rayleigh Fading Models for Distributed MIMO Systems in Industrial Environments</title>
      <link>https://arxiv.org/abs/2503.01300</link>
      <description>arXiv:2503.01300v1 Announce Type: new 
Abstract: This paper presents a detailed analysis of coverage in a factory environment using realistic 3D map data to evaluate the benefits of Distributed MIMO (D-MIMO) over colocalized approach. Our study emphasizes the importance of network densification in enhancing D-MIMO performance, ensuring that User Equipment (UE) remains within range of multiple Access Points (APs). To assess MIMO capacity, we compare two propagation channel models: ray tracing and stochastic. While ray tracing provides accurate predictions by considering environmental details and consistent correlations within the MIMO response, stochastic models offer a more generalized and efficient approach. The analysis outlines the strengths and limitations of each model when applied to the simulation of the downlink (DL) and uplink (UL) single-user capacity in various D-MIMO deployment scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01300v1</guid>
      <category>cs.NI</category>
      <category>cs.ET</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>EUCAP 2025</arxiv:journal_reference>
      <dc:creator>Aymen Jaziri, David Demmer, Yoann Corre, Jean-Baptiste Dor\'e, Didier Le Ruyet, Hmaied Shaiek, Pascal Chevalier</dc:creator>
    </item>
    <item>
      <title>Measuring the Energy of Smartphone Communications in the Edge-Cloud Continuum: Approaches, Challenges, and a Case Study</title>
      <link>https://arxiv.org/abs/2503.01336</link>
      <description>arXiv:2503.01336v1 Announce Type: new 
Abstract: As computational resources are placed at different points in the edge-cloud continuum, not only the responsiveness on the client side is affected, but also the energy spent during communications. We summarize the main approaches used to estimate the energy consumption of smartphones and the main difficulties that are typically encountered. A case study then shows how such approaches can be put into practice. Results show that the edge is favorable in terms of energy consumption, compared to more remote locations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01336v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/MIC.2023.3279438</arxiv:DOI>
      <arxiv:journal_reference>IEEE Internet Computing, Volume 27, Issue 6, Nov.-Dec. 2023</arxiv:journal_reference>
      <dc:creator>Chiara Caiazza, Valerio Luconi, Alessio Vecchio</dc:creator>
    </item>
    <item>
      <title>Verifying QUIC implementations using Ivy</title>
      <link>https://arxiv.org/abs/2503.01374</link>
      <description>arXiv:2503.01374v1 Announce Type: new 
Abstract: QUIC is a new transport protocol combining the reliability and congestion control features of TCP with the security features of TLS. One of the main challenges with QUIC is to guarantee that any of its implementation follows the IETF specification. This challenge is particularly appealing as the specification is written in textual language, and hence may contain ambiguities. In a recent work, McMillan and Zuck proposed a formal representation of part of draft-18 of the IETF specification. They also showed that this representation made it possible to efficiently generate tests to stress four implementations of QUIC. Our first contribution is to complete and extend the formal representation from draft-18 to draft-29. Our second contribution is to test seven implementations of both QUIC client and server. Our last contribution is to show that our tool can highlight ambiguities in the QUIC specification, for which we suggest paths to corrections</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01374v1</guid>
      <category>cs.NI</category>
      <category>cs.SE</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3488660.3493803</arxiv:DOI>
      <dc:creator>Christophe Crochet, Tom Rousseaux, J-F Sambon, Maxime Piraux, Axel Legay</dc:creator>
    </item>
    <item>
      <title>An Empirical Smart Contracts Latency Analysis on Ethereum Blockchain for Trustworthy Inter-Provider Agreements</title>
      <link>https://arxiv.org/abs/2503.01397</link>
      <description>arXiv:2503.01397v1 Announce Type: new 
Abstract: As 6G networks evolve, inter-provider agreements become crucial for dynamic resource sharing and network slicing across multiple domains, requiring on-demand capacity provisioning while enabling trustworthy interaction among diverse operators. To address these challenges, we propose a blockchain-based Decentralized Application (DApp) on Ethereum that introduces four smart contracts, organized into a Preliminary Agreement Phase and an Enforcement Phase, and measures their gas usage, thereby establishing an open marketplace where service providers can list, lease, and enforce resource sharing. We present an empirical evaluation of how gas price, block size, and transaction count affect transaction processing time on the live Sepolia Ethereum testnet in a realistic setting, focusing on these distinct smart-contract phases with varying computational complexities. We first examine transaction latency as the number of users (batch size) increases, observing median latencies from 12.5 s to 23.9 s in the Preliminary Agreement Phase and 10.9 s to 24.7 s in the Enforcement Phase. Building on these initial measurements, we perform a comprehensive Kruskal-Wallis test (p &lt; 0.001) to compare latency distributions across quintiles of gas price, block size, and transaction count. The post-hoc analyses reveal that high-volume blocks overshadow fee variations when transaction logic is more complex (effect sizes up to 0.43), whereas gas price exerts a stronger influence when the computation is lighter (effect sizes up to 0.36). Overall, 86% of transactions finalize within 30 seconds, underscoring that while designing decentralized applications, there must be a balance between contract complexity and fee strategies. The implementation of this work is publicly accessible online.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01397v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Farhana Javed, Josep Mangues-Bafalluy</dc:creator>
    </item>
    <item>
      <title>m4: A Learned Flow-level Network Simulator</title>
      <link>https://arxiv.org/abs/2503.01770</link>
      <description>arXiv:2503.01770v1 Announce Type: new 
Abstract: Flow-level simulation is widely used to model large-scale data center networks due to its scalability. Unlike packet-level simulators that model individual packets, flow-level simulators abstract traffic as continuous flows with dynamically assigned transmission rates. While this abstraction enables orders-of-magnitude speedup, it is inaccurate by omitting critical packet-level effects such as queuing, congestion control, and retransmissions.
  We present m4, an accurate and scalable flow-level simulator that uses machine learning to learn the dynamics of the network of interest. At the core of m4 lies a novel ML architecture that decomposes state transition computations into distinct spatial and temporal components, each represented by a suitable neural network. To efficiently learn the underlying flow-level dynamics, m4 adds dense supervision signals by predicting intermediate network metrics such as remaining flow size and queue length during training. m4 achieves a speedup of up to 104$\times$ over packet-level simulation. Relative to a traditional flow-level simulation, m4 reduces per-flow estimation errors by 45.3% (mean) and 53.0% (p90). For closed-loop applications, m4 accurately predicts network throughput under various congestion control schemes and workloads.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01770v1</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <category>cs.PF</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chenning Li, Anton A. Zabreyko, Arash Nasr-Esfahany, Kevin Zhao, Prateesh Goyal, Mohammad Alizadeh, Thomas Anderson</dc:creator>
    </item>
    <item>
      <title>Data Taxonomy Towards the Applicability of the Digital Twin Conceptual Framework in Disaster Management</title>
      <link>https://arxiv.org/abs/2503.00076</link>
      <description>arXiv:2503.00076v1 Announce Type: cross 
Abstract: The Digital Twin (DT) offers a novel approach to the management of critical infrastructures, including energy, water, traffic, public health, and communication systems, which are indispensable for the functioning of modern societies. The increasing complexity and interconnectedness of these infrastructures necessitate the development of robust disaster response and management strategies. During crises and disasters, data source availability for critical infrastructure may be severely constrained due to physical damage to communication networks, power outages, overwhelmed systems, sensor failure or intentional disruptions, hampering the ability to effectively monitor, manage, and respond to emergencies. This research introduces a taxonomy and similarity function for comparing data sources based on their features and vulnerability to crisis events. This assessment enables the identification of similar, complementary, and alternative data sources and rapid adaptation when primary sources fail. The paper outlines a data source manager as an additional component for existing DT frameworks, specifically the data ingress and scenario mangement. A case study for traffic data sources in an urban scenario demonstrates the proposed methodology and its effectiveness. This approach enhances the robustness and adaptability of DTs in disaster management applications, contributing to improved decision-making and response capabilities in critical situations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00076v1</guid>
      <category>cs.CY</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Eva Brucherseifer, Marco Marquard, Martin Hellmann, Andrea Tundis</dc:creator>
    </item>
    <item>
      <title>CATS: A framework for Cooperative Autonomy Trust &amp; Security</title>
      <link>https://arxiv.org/abs/2503.00659</link>
      <description>arXiv:2503.00659v1 Announce Type: cross 
Abstract: With cooperative perception, autonomous vehicles can wirelessly share sensor data and representations to overcome sensor occlusions, improving situational awareness. Securing such data exchanges is crucial for connected autonomous vehicles. Existing, automated reputation-based approaches often suffer from a delay between detection and exclusion of misbehaving vehicles, while majority-based approaches have communication overheads that limits scalability. In this paper, we introduce CATS, a novel automated system that blends together the best traits of reputation-based and majority-based detection mechanisms to secure vehicle-to-everything (V2X) communications for cooperative perception, while preserving the privacy of cooperating vehicles. Our evaluation with city-scale simulations on realistic traffic data shows CATS's effectiveness in rapidly identifying and isolating misbehaving vehicles, with a low false negative rate and overheads, proving its suitability for real world deployments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00659v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Namo Asavisanu, Tina Khezresmaeilzadeh, Rohan Sequeira, Hang Qiu, Fawad Ahmad, Konstantinos Psounis, Ramesh Govindan</dc:creator>
    </item>
    <item>
      <title>Formally Discovering and Reproducing Network Protocols Vulnerabilities</title>
      <link>https://arxiv.org/abs/2503.01538</link>
      <description>arXiv:2503.01538v1 Announce Type: cross 
Abstract: The rapid evolution of cyber threats has increased the need for robust methods to discover vulnerabilities in increasingly complex and diverse network protocols. This paper introduces Network Attack-centric Compositional Testing (NACT), a novel methodology designed to discover new vulnerabilities in network protocols and create scenarios to reproduce these vulnerabilities through attacker models. NACT integrates composable attacker specifications, formal specification mutations, and randomized constraint-solving techniques to generate sophisticated attack scenarios and test cases. The methodology enables comprehensive testing of both single-protocol and multi-protocol interactions. Through case studies involving a custom minimalist protocol (MiniP) and five widely used QUIC implementations, NACT is shown to effectively identify, reproduce, and find new real-world vulnerabilities such as version negotiation abuse. Additionally, by comparing the current and older versions of these QUIC implementations, NACT demonstrates its ability to detect both persistent vulnerabilities and regressions. Finally, by supporting cross-protocol testing within a black-box testing framework, NACT provides a versatile approach to improve the security of network protocols.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01538v1</guid>
      <category>cs.CR</category>
      <category>cs.FL</category>
      <category>cs.NI</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-79007-2_22</arxiv:DOI>
      <dc:creator>Christophe Crochet, John Aoga, Axel Legay</dc:creator>
    </item>
    <item>
      <title>Application of the List Viterbi Algorithm for Satellite-based AIS Detection</title>
      <link>https://arxiv.org/abs/2503.01744</link>
      <description>arXiv:2503.01744v1 Announce Type: cross 
Abstract: Satellites receiving Automatic Identification System (AIS) packets in dense areas are particularly prone to AIS channel overload due to the extensive number of vessels. Thus a failure of detection might be caused by the collisions among AIS messages. To improve the detection capability, we propose to exploit the presence of the cyclic redundancy check (CRC) in AIS frames by using the parallel list Viterbi algorithm (PLVA) instead of the classical Viterbi algorithm (VA) often used for decoding AIS signals. The performance of combining the PLVA with AIS post processing including the CRC is studied with two detectors, one coherent and the other differential, in two channel models: a single-user AWGN channel and a more realistic multiple-access AIS channel. We also show the impact of the PLVA parameters on the success recovery rate. The simulation results show that the resulting procedure can significantly improve the packet error rate (PER) at the cost of a limited increase of the computational complexity. The proposed technique could be applied to improve the performance of interference cancellation receivers by significantly lowering the AIS decoding threshold.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01744v1</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Linda Kanaan, Karine Amis, Fr\'ed\'eric Guilloud, R\'emi Chauvat</dc:creator>
    </item>
    <item>
      <title>Large Language Model(LLM) assisted End-to-End Network Health Management based on Multi-Scale Semanticization</title>
      <link>https://arxiv.org/abs/2406.08305</link>
      <description>arXiv:2406.08305v2 Announce Type: replace 
Abstract: Network device and system health management is the foundation of modern network operations and maintenance. Traditional health management methods, relying on expert identification or simple rule-based algorithms, struggle to cope with the dynamic heterogeneous networks (DHNs) environment. Moreover, current state-of-the-art distributed anomaly detection methods, which utilize specific machine learning techniques, lack multi-scale adaptivity for heterogeneous device information, resulting in unsatisfactory diagnostic accuracy for DHNs. In this paper, we develop an LLM-assisted end-to-end intelligent network health management framework. The framework first proposes a Multi-Scale Semanticized Anomaly Detection Model (MSADM), incorporating semantic rule trees with an attention mechanism to address the multi-scale anomaly detection problem in DHNs. Secondly, a chain-of-thought-based large language model is embedded in downstream to adaptively analyze the fault detection results and produce an analysis report with detailed fault information and optimization strategies. Experimental results show that the accuracy of our proposed MSADM for heterogeneous network entity anomaly detection is as high as 91.31\%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08305v2</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fengxiao Tang, Xiaonan Wang, Xun Yuan, Linfeng Luo, Ming Zhao, Tianchi Huang, Nei Kato</dc:creator>
    </item>
    <item>
      <title>X5G: An Open, Programmable, Multi-vendor, End-to-end, Private 5G O-RAN Testbed with NVIDIA ARC and OpenAirInterface</title>
      <link>https://arxiv.org/abs/2406.15935</link>
      <description>arXiv:2406.15935v3 Announce Type: replace 
Abstract: As Fifth generation (5G) cellular systems transition to softwarized, programmable, and intelligent networks, it becomes fundamental to enable public and private 5G deployments that are (i) primarily based on software components while (ii) maintaining or exceeding the performance of traditional monolithic systems and (iii) enabling programmability through bespoke configurations and optimized deployments. This requires hardware acceleration to scale the Physical (PHY) layer performance, programmable elements in the Radio Access Network (RAN) and intelligent controllers at the edge, careful planning of the Radio Frequency (RF) environment, as well as end-to-end integration and testing. In this paper, we describe how we developed the programmable X5G testbed, addressing these challenges through the deployment of the first 8-node network based on the integration of NVIDIA Aerial RAN CoLab Over-the-Air (ARC-OTA), OpenAirInterface (OAI), and a near-real-time RAN Intelligent Controller (RIC). The Aerial Software Development Kit (SDK) provides the PHY layer, accelerated on Graphics Processing Unit (GPU), with the higher layers from the OAI open-source project interfaced with the PHY through the Small Cell Forum (SCF) Functional Application Platform Interface (FAPI). An E2 agent provides connectivity to the O-RAN Software Community (OSC) near-real-time RIC. We discuss software integration, network infrastructure, and a digital twin framework for RF planning. We then profile the performance with up to 4 Commercial Off-the-Shelf (COTS) smartphones for each base station with iPerf and video streaming applications, as well as up to 25 emulated User Equipments (UEs), measuring a cell rate higher than 1.65 Gbps in downlink and 143 Mbps in uplink.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15935v3</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Davide Villa, Imran Khan, Florian Kaltenberger, Nicholas Hedberg, R\'uben Soares da Silva, Stefano Maxenti, Leonardo Bonati, Anupa Kelkar, Chris Dick, Eduardo Baena, Josep M. Jornet, Tommaso Melodia, Michele Polese, Dimitrios Koutsonikolas</dc:creator>
    </item>
    <item>
      <title>Delay-Aware Robust Edge Network Hardening Under Decision-Dependent Uncertainty</title>
      <link>https://arxiv.org/abs/2407.06142</link>
      <description>arXiv:2407.06142v2 Announce Type: replace 
Abstract: Edge computing promises to offer low-latency and ubiquitous computation to numerous devices at the network edge. For delay-sensitive applications, link delays can have a direct impact on service quality. These delays can fluctuate drastically over time due to various factors such as network congestion, changing traffic conditions, cyberattacks, component failures, and natural disasters. Thus, it is crucial to efficiently harden the edge network to mitigate link delay variation as well as ensure a stable and improved user experience. To this end, we propose a novel robust model for optimal edge network hardening, considering the link delay uncertainty. Departing from the existing literature that treats uncertainties as exogenous, our model incorporates an endogenous uncertainty set to properly capture the impact of hardening and workload allocation decisions on link delays. However, the endogenous set introduces additional complexity to the problem due to the interdependence between decisions and uncertainties. We present two efficient methods to transform the problem into a solvable form. Extensive numerical results are shown to demonstrate the effectiveness of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06142v2</guid>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiaming Cheng, Duong Thuy Anh Nguyen, Ni Trieu, Duong Tung Nguyen</dc:creator>
    </item>
    <item>
      <title>Optimizing Integrated Terrestrial and Non-Terrestrial Networks Performance with Traffic-Aware Resource Management</title>
      <link>https://arxiv.org/abs/2410.06700</link>
      <description>arXiv:2410.06700v2 Announce Type: replace 
Abstract: To address an ever-increasing demand for ubiquitous high-speed connectivity, mobile network deployments are becoming increasingly dense. However, this densification has also led to a surge in overall energy consumption, making the process increasingly challenging. In recent years, non-terrestrial networks (NTNs) have been mainly endorsed as a potential solution to enhance coverage by complementing the coverage of the terrestrial network (TN) in areas with limited network deployment. However, their ability to reduce TN energy consumption, though often overlooked, remains a significant advantage. To this end, this paper introduces a novel radio resource management algorithm, BLASTER (Bandwidth SpLit, User ASsociation, and PowEr ContRol), which integrates bandwidth allocation, user equipment (UE) association, power control, and base station activation within an integrated terrestrial and non-terrestrial network (TN-NTN). This algorithm aims to optimize network resource allocation fairness and energy consumption dynamically, demonstrating new opportunities in deploying satellite networks in legacy cellular systems. Our study offers a comprehensive analysis of the integrated network model, emphasizing the effective balance between energy saving and Quality of Service (QoS), and proposing practical solutions to meet the fluctuating traffic demands of cellular networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06700v2</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Henri Alam, Antonio de Domenico, David L\'opez-P\'erez, Florian Kaltenberger</dc:creator>
    </item>
    <item>
      <title>Optimal Ground Station Selection for Low-Earth Orbiting Satellites</title>
      <link>https://arxiv.org/abs/2410.16282</link>
      <description>arXiv:2410.16282v2 Announce Type: replace 
Abstract: This paper presents a solution to the problem of optimal ground station selection for low-Earth orbiting (LEO) space missions that enables mission operators to precisely design their ground segment performance and costs. Space mission operators are increasingly turning to Ground-Station-as-a-Service (GSaaS) providers to supply the terrestrial communications segment to reduce costs and increase network size. However, this approach leads to a new challenge of selecting the optimal service providers and station locations for a given mission. We consider the problem of ground station selection as an optimization problem and present a general solution framework that allows mission designers to set their overall optimization objective and constrain key mission performance variables such as total data downlink, total mission cost, recurring operational cost, and maximum communications time-gap. We solve the problem using integer programming (IP). To address computational scaling challenges, we introduce a surrogate optimization approach where the optimal station selection is determined based on solving the problem over a reduced time domain. Two different IP formulations are evaluated using randomized selections of LEO satellites of varying constellation sizes. We consider the networks of the commercial GSaaS providers Atlas Space Operations, Amazon Web Services (AWS) Ground Station, Azure Orbital Ground Station, Kongsberg Satellite Services (KSAT), Leaf Space, and Viasat Real-Time Earth. We compare our results against standard operational practices of integrating with one or two primary ground station providers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16282v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Duncan Eddy, Michelle Ho, Mykel J. Kochenderfer</dc:creator>
    </item>
    <item>
      <title>Efficient Multi-user Offloading of Personalized Diffusion Models: A DRL-Convex Hybrid Solution</title>
      <link>https://arxiv.org/abs/2411.15781</link>
      <description>arXiv:2411.15781v2 Announce Type: replace 
Abstract: With the impressive generative capabilities of diffusion models, personalized content synthesis has emerged as the most highly anticipated. However, the large model sizes and iterative nature of inference make it difficult to deploy personalized diffusion models broadly on local devices with varying computational power. To this end, we propose a novel framework for efficient multi-user offloading of personalized diffusion models, given a variable number of users, diverse user computational capabilities, and fluctuating available computational resources on the edge server. To enhance computational efficiency and reduce storage burden on edge servers, we first propose a tailored multi-user hybrid inference manner, where the inference process for each user is split into two phases with an optimizable split point. The initial phase of inference is processed on a cluster-wide model using batching techniques, generating low-level semantic information corresponding to each user's prompt. Then, the users employ their own personalized model to add further details in the later inference phase. Given the constraints on edge server computational resources and users' preferences for low latency and high accuracy, we model the joint optimization of each user's offloading request handling and split point as an extension of the Generalized Quadratic Assignment Problem (GQAP). Our objective is to maximize a comprehensive metric that accounts for both latency and accuracy across all users. To tackle this NP-hard problem, we transform the GQAP into an adaptive decision sequence, model it as a Markov decision process, and develop a hybrid solution combining deep reinforcement learning with convex optimization techniques. Simulation results validate the effectiveness of our framework, demonstrating superior optimality and low complexity compared to traditional methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15781v2</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wanting Yang, Zehui Xiong, Song Guo, Shiwen Mao, Dong In Kim, Merouane Debbah</dc:creator>
    </item>
    <item>
      <title>Interference Management Strategies for HAPS-Enabled vHetNets in Urban Deployments</title>
      <link>https://arxiv.org/abs/2412.19865</link>
      <description>arXiv:2412.19865v2 Announce Type: replace 
Abstract: Next-generation wireless networks are evolving towards architectures that integrate terrestrial and non-terrestrial networks (NTN), unitedly known as vertical heterogeneous networks (vHetNets). This integration is vital to address the increasing demand for coverage, capacity, and new services in urban environments. Among NTN platforms, high altitude platform stations (HAPS) play a promising role in future vHetNets due to their strategic positioning in the stratosphere. In HAPS-enabled vHetNets, various tiers can operate within the same frequency band, creating a harmonized-spectrum integrated network. Although this harmonization significantly enhances spectral efficiency, it also introduces challenges, with interference being a primary concern. This paper investigates vHetNets comprising HAPS and terrestrial macro base stations (MBSs) operating in a shared spectrum, where interference becomes a critical issue. The unique constraints of HAPS-enabled vHetNets further complicate the interference management problem. To address these challenges, we explore various strategies to manage interference in HAPS-enabled vHetNets. Accordingly, we discuss centralized and distributed approaches that leverage tools based on mathematical optimization and artificial intelligence (AI) to solve interference management problems. Preliminary numerical evaluations indicate that distributed approaches achieve spectral efficiency comparable to the centralized algorithm, while requiring lower complexity and less reliance on global information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19865v2</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Afsoon Alidadi Shamsabadi, Animesh Yadav, Halim Yanikomeroglu</dc:creator>
    </item>
    <item>
      <title>Adaptive Rank Allocation for Federated Parameter-Efficient Fine-Tuning of Language Models</title>
      <link>https://arxiv.org/abs/2501.14406</link>
      <description>arXiv:2501.14406v2 Announce Type: replace-cross 
Abstract: Pre-trained Language Models (PLMs) have demonstrated their superiority and versatility in modern Natural Language Processing (NLP), effectively adapting to various downstream tasks through further fine-tuning. Federated Parameter-Efficient Fine-Tuning (FedPEFT) has emerged as a promising solution to address privacy and efficiency challenges in distributed training for PLMs on resource-constrained local devices. However, our measurements reveal two key limitations of FedPEFT: heterogeneous data across devices leads to significant performance degradation, and a fixed parameter configuration results in communication inefficiency. To overcome these limitations, we propose FedARA, a novel Adaptive Rank Allocation framework for federated parameter-efficient fine-tuning of language models. Specifically, FedARA employs truncated Singular Value Decomposition (SVD) adaptation to enhance similar feature representation across clients, significantly mitigating the adverse effects of data heterogeneity. Subsequently, it utilizes dynamic rank allocation to progressively identify critical ranks, effectively improving communication efficiency. Lastly, it leverages rank-based module pruning to automatically remove inactive modules, steadily reducing local computational cost and memory usage in each federated learning round. Extensive experiments show that FedARA consistently outperforms baselines by an average of 6.95% to 8.49% across various datasets and models under heterogeneous data while significantly improving communication efficiency by 2.40$ \times$. Moreover, experiments on various edge devices demonstrate substantial decreases in total training time and energy consumption by up to 48.90% and 46.95%, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14406v2</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fei Wu, Jia Hu, Geyong Min, Shiqiang Wang</dc:creator>
    </item>
    <item>
      <title>Grassroots Platforms with Atomic Transactions: Social Networks, Cryptocurrencies, and Democratic Federations</title>
      <link>https://arxiv.org/abs/2502.11299</link>
      <description>arXiv:2502.11299v2 Announce Type: replace-cross 
Abstract: Grassroots platforms aim to offer an egalitarian alternative to global platforms -- centralized/autocratic (Facebook etc.) and decentralized/plutocratic (Bitcoin etc.) alike. Key grassroots platforms include grassroots social networks, grassroots cryptocurrencies, and grassroots democratic federations. Previously, grassroots platforms were defined formally and proven grassroots using unary distributed transition systems, in which each transition is carried out by a single agent. However, grassroots platforms cater for a more abstract specification using transactions carried out atomically by multiple agents, something that cannot be expressed by unary transition systems. As a result, their original specifications and proofs were unnecessarily cumbersome and opaque.
  Here, we aim to provide a more suitable formal foundation for grassroots platforms. To do so, we enhance the notion of a distributed transition system to include atomic transactions and revisit the notion of grassroots platforms within this new foundation. We present crisp specifications of key grassroots platforms using atomic transactions: befriending and defriending for grassroots social networks, coin swaps for grassroots cryptocurrencies, and communities forming, joining, and leaving a federation for grassroots democratic federations. We prove a general theorem that a platform specified by atomic transactions that are so-called interactive is grassroots; show that the atomic transactions used to specify all three platforms are interactive; and conclude that the platforms thus specified are indeed grassroots. We thus provide a better mathematical foundation for grassroots platforms and a solid and clear starting point from which their implementation can commence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11299v2</guid>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <category>cs.SI</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ehud Shapiro</dc:creator>
    </item>
    <item>
      <title>MobileViM: A Light-weight and Dimension-independent Vision Mamba for 3D Medical Image Analysis</title>
      <link>https://arxiv.org/abs/2502.13524</link>
      <description>arXiv:2502.13524v2 Announce Type: replace-cross 
Abstract: Efficient evaluation of three-dimensional (3D) medical images is crucial for diagnostic and therapeutic practices in healthcare. Recent years have seen a substantial uptake in applying deep learning and computer vision to analyse and interpret medical images. Traditional approaches, such as convolutional neural networks (CNNs) and vision transformers (ViTs), face significant computational challenges, prompting the need for architectural advancements. Recent efforts have led to the introduction of novel architectures like the ``Mamba'' model as alternative solutions to traditional CNNs or ViTs. The Mamba model excels in the linear processing of one-dimensional data with low computational demands. However, Mamba's potential for 3D medical image analysis remains underexplored and could face significant computational challenges as the dimension increases. This manuscript presents MobileViM, a streamlined architecture for efficient segmentation of 3D medical images. In the MobileViM network, we invent a new dimension-independent mechanism and a dual-direction traversing approach to incorporate with a vision-Mamba-based framework. MobileViM also features a cross-scale bridging technique to improve efficiency and accuracy across various medical imaging modalities. With these enhancements, MobileViM achieves segmentation speeds exceeding 90 frames per second (FPS) on a single graphics processing unit (i.e., NVIDIA RTX 4090). This performance is over 24 FPS faster than the state-of-the-art deep learning models for processing 3D images with the same computational resources. In addition, experimental evaluations demonstrate that MobileViM delivers superior performance, with Dice similarity scores reaching 92.72%, 86.69%, 80.46%, and 77.43% for PENGWIN, BraTS2024, ATLAS, and Toothfairy2 datasets, respectively, which significantly surpasses existing models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13524v2</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Wei Dai, Steven Wang, Jun Liu</dc:creator>
    </item>
    <item>
      <title>Offload Rethinking by Cloud Assistance for Efficient Environmental Sound Recognition on LPWANs</title>
      <link>https://arxiv.org/abs/2502.15285</link>
      <description>arXiv:2502.15285v2 Announce Type: replace-cross 
Abstract: Learning-based environmental sound recognition has emerged as a crucial method for ultra-low-power environmental monitoring in biological research and city-scale sensing systems. These systems usually operate under limited resources and are often powered by harvested energy in remote areas. Recent efforts in on-device sound recognition suffer from low accuracy due to resource constraints, whereas cloud offloading strategies are hindered by high communication costs. In this work, we introduce ORCA, a novel resource-efficient cloud-assisted environmental sound recognition system on batteryless devices operating over the Low-Power Wide-Area Networks (LPWANs), targeting wide-area audio sensing applications. We propose a cloud assistance strategy that remedies the low accuracy of on-device inference while minimizing the communication costs for cloud offloading. By leveraging a self-attention-based cloud sub-spectral feature selection method to facilitate efficient on-device inference, ORCA resolves three key challenges for resource-constrained cloud offloading over LPWANs: 1) high communication costs and low data rates, 2) dynamic wireless channel conditions, and 3) unreliable offloading. We implement ORCA on an energy-harvesting batteryless microcontroller and evaluate it in a real world urban sound testbed. Our results show that ORCA outperforms state-of-the-art methods by up to $80 \times$ in energy savings and $220 \times$ in latency reduction while maintaining comparable accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15285v2</guid>
      <category>cs.SD</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <category>eess.AS</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Le Zhang, Quanling Zhao, Run Wang, Shirley Bian, Onat Gungor, Flavio Ponzina, Tajana Rosing</dc:creator>
    </item>
    <item>
      <title>Privacy-Aware Joint DNN Model Deployment and Partition Optimization for Delay-Efficient Collaborative Edge Inference</title>
      <link>https://arxiv.org/abs/2502.16091</link>
      <description>arXiv:2502.16091v2 Announce Type: replace-cross 
Abstract: Edge inference (EI) is a key solution to address the growing challenges of delayed response times, limited scalability, and privacy concerns in cloud-based Deep Neural Network (DNN) inference. However, deploying DNN models on resource-constrained edge devices faces more severe challenges, such as model storage limitations, dynamic service requests, and privacy risks. This paper proposes a novel framework for privacy-aware joint DNN model deployment and partition optimization to minimize long-term average inference delay under resource and privacy constraints. Specifically, the problem is formulated as a complex optimization problem considering model deployment, user-server association, and model partition strategies. To handle the NP-hardness and future uncertainties, a Lyapunov-based approach is introduced to transform the long-term optimization into a single-time-slot problem, ensuring system performance. Additionally, a coalition formation game model is proposed for edge server association, and a greedy-based algorithm is developed for model deployment within each coalition to efficiently solve the problem. Extensive simulations show that the proposed algorithms effectively reduce inference delay while satisfying privacy constraints, outperforming baseline approaches in various scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16091v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhipeng Cheng, Xiaoyu Xia, Hong Wang, Minghui Liwang, Ning Chen, Xuwei Fan, Xianbin Wang</dc:creator>
    </item>
  </channel>
</rss>
