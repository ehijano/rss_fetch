<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Feb 2026 05:01:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Metric space valued Fr{\'e}chet regression</title>
      <link>https://arxiv.org/abs/2602.05225</link>
      <description>arXiv:2602.05225v1 Announce Type: new 
Abstract: We consider the problem of estimating the Fr{\'e}chet and conditional Fr{\'e}chet mean from data taking values in separable metric spaces. Unlike Euclidean spaces, where well-established methods are available, there is no practical estimator that works universally for all metric spaces. Therefore, we introduce a computable estimator for the Fr{\'e}chet mean based on random quantization techniques and establish its universal consistency across any separable metric spaces. Additionally, we propose another estimator for the conditional Fr{\'e}chet mean, leveraging data-driven partitioning and quantization, and demonstrate its universal consistency when the output space is any Banach space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05225v1</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>L\'aszl\'o Gy\"orfi (DCSIT), Pierre Humbert (LaMME), Batiste Le Bars (MAGNET)</dc:creator>
    </item>
    <item>
      <title>An Asymptotic Law of the Iterated Logarithm for $\mathrm{KL}_{\inf}$</title>
      <link>https://arxiv.org/abs/2602.05259</link>
      <description>arXiv:2602.05259v1 Announce Type: new 
Abstract: The population $\mathrm{KL}_{\inf}$ is a fundamental quantity that appears in lower bounds for (asymptotically) optimal regret of pure-exploration stochastic bandit algorithms, and optimal stopping time of sequential tests. Motivated by this, an empirical $\mathrm{KL}_{\inf}$ statistic is frequently used in the design of (asymptotically) optimal bandit algorithms and sequential tests. While nonasymptotic concentration bounds for the empirical $\mathrm{KL}_{\inf}$ have been developed, their optimality in terms of constants and rates is questionable, and their generality is limited (usually to bounded observations). The fundamental limits of nonasymptotic concentration are often described by the asymptotic fluctuations of the statistics. With that motivation, this paper presents a tight (upper and lower) law of the iterated logarithm for empirical $\mathrm{KL}_{\inf}$ applying to extremely general (unbounded) data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05259v1</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ashwin Ram, Aaditya Ramdas</dc:creator>
    </item>
    <item>
      <title>Asymptotically optimal sequential change detection for bounded means</title>
      <link>https://arxiv.org/abs/2602.05272</link>
      <description>arXiv:2602.05272v1 Announce Type: new 
Abstract: We consider the problem of quickest changepoint detection under the Average Run Length (ARL) constraint where the pre-change and post-change laws lie in composite families $\mathscr{P}$ and $\mathscr{Q}$ respectively. In such a problem, a massive challenge is characterizing the best possible detection delay when the "hardest" pre-change law in $\mathscr{P}$ depends on the unknown post-change law $Q\in\mathscr{Q}$. And typical simple-hypothesis likelihood-ratio arguments for Page-CUSUM and Shiryaev-Roberts do not at all apply here. To that end, we derive a universal sharp lower bound in full generality for any ARL-calibrated changepoint detector in the low type-I error ($\gamma\to\infty$ regime) of the order $\log(\gamma)/\mathrm{KL}_{\mathrm{inf}}(Q,\mathscr{P})$. We show achievability of this universal lower bound by proving a tight matching upper bound (with the same sharp $\log\gamma$ constant) in the important bounded mean detection setting. In addition, for separated mean shifts, we also we derive a uniform minimax guarantee of this achievability over the alternatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05272v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ashwin Ram, Aaditya Ramdas</dc:creator>
    </item>
    <item>
      <title>Complexity reduction in online stochastic Newton methods with potential O(N d) total cost</title>
      <link>https://arxiv.org/abs/2602.05460</link>
      <description>arXiv:2602.05460v1 Announce Type: new 
Abstract: Optimizing smooth convex functions in stochastic settings, where only noisy estimates of gradients and Hessians are available, is a fundamental problem in optimization. While first-order methods possess a low per-iteration cost, their convergence is slow for ill-conditioned problems. Stochastic Newton methods utilize second-order information to correct for local curvature, but the O(d 3 ) per-iteration cost of computing and inverting a full Hessian, where d is the problem dimension, is prohibitive in high dimensions. This paper introduces an online mini-batch stochastic Newton algorithm. The method employs a random masking strategy that selects a subset of Hessian columns at each iteration, substantially reducing the per-step computational cost. This approach allows the algorithm, in the mini-batch setting, to achieve a total computational cost for a single pass over N data points of O(N d), which is comparable to first-order methods while retaining the advantages of second-order information. We establish the almost sure convergence and asymptotic efficiency of the resulting estimator. This property is obtained without requiring iterate averaging, which distinguishes this work from prior analyses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05460v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antoine Godichon-Baggioni (LPSM), Bruno Portier (LMI), Guillaume Sall\'e (LMI, LPSM)</dc:creator>
    </item>
    <item>
      <title>An invariant modification of the bilinear form test</title>
      <link>https://arxiv.org/abs/2602.05592</link>
      <description>arXiv:2602.05592v1 Announce Type: new 
Abstract: The invariance properties of certain likelihood-based asymptotic tests as well as their extensions for M-estimation, estimating functions and the generalized method of moments have been well studied. The simulation study reported in Crudu and Osorio [Econ. Lett. 187: 108885, 2020] shows that the bilinear form test is not invariant to one-to-one transformations of the parameter space. This paper provides a set of suitable conditions to establish the invariance property under reparametrization of the bilinear form test for linear or nonlinear hypotheses that arise in extremum estimation which leads to a simple modification of the test statistic. Evidence from a Monte Carlo simulation experiment suggests good performance of the proposed methodology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05592v1</guid>
      <category>math.ST</category>
      <category>econ.EM</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Angelo Garate, Felipe Osorio, Federico Crudu</dc:creator>
    </item>
    <item>
      <title>Finite-Particle Rates for Regularized Stein Variational Gradient Descent</title>
      <link>https://arxiv.org/abs/2602.05172</link>
      <description>arXiv:2602.05172v1 Announce Type: cross 
Abstract: We derive finite-particle rates for the regularized Stein variational gradient descent (R-SVGD) algorithm introduced by He et al. (2024) that corrects the constant-order bias of the SVGD by applying a resolvent-type preconditioner to the kernelized Wasserstein gradient. For the resulting interacting $N$-particle system, we establish explicit non-asymptotic bounds for time-averaged (annealed) empirical measures, illustrating convergence in the \emph{true} (non-kernelized) Fisher information and, under a $\mathrm{W}_1\mathrm{I}$ condition on the target, corresponding $\mathrm{W}_1$ convergence for a large class of smooth kernels. Our analysis covers both continuous- and discrete-time dynamics and yields principled tuning rules for the regularization parameter, step size, and averaging horizon that quantify the trade-off between approximating the Wasserstein gradient flow and controlling finite-particle estimation error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05172v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ye He, Krishnakumar Balasubramanian, Sayan Banerjee, Promit Ghosal</dc:creator>
    </item>
    <item>
      <title>Total Variation Rates for Riemannian Flow Matching</title>
      <link>https://arxiv.org/abs/2602.05174</link>
      <description>arXiv:2602.05174v1 Announce Type: cross 
Abstract: Riemannian flow matching (RFM) extends flow-based generative modeling to data supported on manifolds by learning a time-dependent tangent vector field whose flow-ODE transports a simple base distribution to the data law. We develop a nonasymptotic Total Variation (TV) convergence analysis for RFM samplers that use a learned vector field together with Euler discretization on manifolds. Our key technical ingredient is a differential inequality governing the evolution of TV between two manifold ODE flows, which expresses the time-derivative of TV through the divergence of the vector-field mismatch and the score of the reference flow; controlling these terms requires establishing new bounds that explicitly account for parallel transport and curvature. Under smoothness assumptions on the population flow-matching field and either uniform (compact manifolds) or mean-square (Hadamard manifolds) approximation guarantees for the learned field, we obtain explicit bounds of the form $\mathrm{TV}\le C_{\mathrm{Lip}}\,h + C_{\varepsilon}\,\varepsilon$ (with an additional higher-order $\varepsilon^2$ term on compact manifolds), cleanly separating numerical discretization and learning errors. Here, $h$ is the step-size and $\varepsilon$ is the target accuracy. Instantiations yield \emph{explicit} polynomial iteration complexities on the hypersphere $S^d$, and on the SPD$(n)$ manifolds under mild moment conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05174v1</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yunrui Guan, Krishnakumar Balasubramanian, Shiqian Ma</dc:creator>
    </item>
    <item>
      <title>A Flexible Modeling of Extremes in the Presence of Inliers</title>
      <link>https://arxiv.org/abs/2602.05351</link>
      <description>arXiv:2602.05351v1 Announce Type: cross 
Abstract: Many random phenomena, including life-testing and environmental data, show positive values and excess zeros, which pose modeling challenges. In life testing, immediate failures result in zero lifetimes, often due to defects or poor quality, especially in electronics and clinical trials. These failures, called inliers at zero, are difficult to model using standard approaches. The presence and proportion of inliers may influence the accuracy of extreme value analysis, bias parameter estimates, or even lead to severe events or extreme effects, such as drought or crop failure. In such scenarios, a key issue in extreme value analysis is determining a suitable threshold to capture tail behaviour accurately. Although some extreme value mixture models address threshold and tail estimation, they often inadequately handle inliers, resulting in suboptimal results. Bulk model misspecification can affect the threshold, extreme value estimates, and, in particular, the tail proportion. There is no unified framework for defining extreme value mixture models, especially the tail proportion. This paper proposes a flexible model that handles extremes, inliers, and the tail proportion. Parameters are estimated using maximum likelihood estimation. Compared the proposed model estimates with the classical mean excess plot, parameter stability plot, and Pickands plot estimates. Theoretical results are established, and the proposed model outperforms traditional methods in both simulation studies and real data analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05351v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shivshankar Nila, Ishapathik Das, N. Balakrishna</dc:creator>
    </item>
    <item>
      <title>Piecewise Deterministic Markov Processes for Bayesian Inference of PDE Coefficients</title>
      <link>https://arxiv.org/abs/2602.05559</link>
      <description>arXiv:2602.05559v1 Announce Type: cross 
Abstract: We develop a general framework for piecewise deterministic Markov process (PDMP) samplers that enables efficient Bayesian inference in non-linear inverse problems with expensive likelihoods. The key ingredient is a surrogate-assisted thinning scheme in which a surrogate model provides a proposal event rate and a robust correction mechanism enforces an upper bound on the true rate by dynamically adjusting an additive offset whenever violations are detected. This construction is agnostic to the choice of surrogate and PDMP, and we demonstrate it for the Zig-Zag sampler and the Bouncy particle sampler with constant, Laplace, and Gaussian process (GP) surrogates, including gradient-informed and adaptively refined GP variants. As a representative application, we consider Bayesian inference of a spatially varying Young's modulus in a one-dimensional linear elasticity problem. Across dimensions, PDMP samplers equipped with GP-based surrogates achieve substantially higher accuracy and effective sample size per forward model evaluation than Random Walk Metropolis algorithm and the No-U-Turn sampler. The Bouncy particle sampler exhibits the most favorable overall efficiency and scaling, illustrating the potential of the proposed PDMP framework beyond this particular setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05559v1</guid>
      <category>stat.CO</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leon Riccius, Iuri B. C. M. Rocha, Joris Bierkens, Hanne Kekkonen, Frans P. van der Meer</dc:creator>
    </item>
    <item>
      <title>Fast Rates for Nonstationary Weighted Risk Minimization</title>
      <link>https://arxiv.org/abs/2602.05742</link>
      <description>arXiv:2602.05742v1 Announce Type: cross 
Abstract: Weighted empirical risk minimization is a common approach to prediction under distribution drift. This article studies its out-of-sample prediction error under nonstationarity. We provide a general decomposition of the excess risk into a learning term and an error term associated with distribution drift, and prove oracle inequalities for the learning error under mixing conditions. The learning bound holds uniformly over arbitrary weight classes and accounts for the effective sample size induced by the weight vector, the complexity of the weight and hypothesis classes, and potential data dependence. We illustrate the applicability and sharpness of our results in (auto-) regression problems with linear models, basis approximations, and neural networks, recovering minimax-optimal rates (up to logarithmic factors) when specialized to unweighted and stationary settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05742v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tobias Brock, Thomas Nagler</dc:creator>
    </item>
    <item>
      <title>Wedge Sampling: Efficient Tensor Completion with Nearly-Linear Sample Complexity</title>
      <link>https://arxiv.org/abs/2602.05869</link>
      <description>arXiv:2602.05869v1 Announce Type: cross 
Abstract: We introduce Wedge Sampling, a new non-adaptive sampling scheme for low-rank tensor completion. We study recovery of an order-$k$ low-rank tensor of dimension $n \times \cdots \times n$ from a subset of its entries. Unlike the standard uniform entry model (i.e., i.i.d. samples from $[n]^k$), wedge sampling allocates observations to structured length-two patterns (wedges) in an associated bipartite sampling graph. By directly promoting these length-two connections, the sampling design strengthens the spectral signal that underlies efficient initialization, in regimes where uniform sampling is too sparse to generate enough informative correlations.
  Our main result shows that this change in sampling paradigm enables polynomial-time algorithms to achieve both weak and exact recovery with nearly linear sample complexity in $n$. The approach is also plug-and-play: wedge-sampling-based spectral initialization can be combined with existing refinement procedures (e.g., spectral or gradient-based methods) using only an additional $\tilde{O}(n)$ uniformly sampled entries, substantially improving over the $\tilde{O}(n^{k/2})$ sample complexity typically required under uniform entry sampling for efficient methods. Overall, our results suggest that the statistical-to-computational gap highlighted in Barak and Moitra (2022) is, to a large extent, a consequence of the uniform entry sampling model for tensor completion, and that alternative non-adaptive measurement designs that guarantee a strong initialization can overcome this barrier.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05869v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hengrui Luo, Anna Ma, Ludovic Stephan, Yizhe Zhu</dc:creator>
    </item>
    <item>
      <title>Optimism Stabilizes Thompson Sampling for Adaptive Inference</title>
      <link>https://arxiv.org/abs/2602.06014</link>
      <description>arXiv:2602.06014v1 Announce Type: cross 
Abstract: Thompson sampling (TS) is widely used for stochastic multi-armed bandits, yet its inferential properties under adaptive data collection are subtle. Classical asymptotic theory for sample means can fail because arm-specific sample sizes are random and coupled with the rewards through the action-selection rule. We study this phenomenon in the $K$-armed Gaussian bandit and identify \emph{optimism} as a key mechanism for restoring \emph{stability}, a sufficient condition for valid asymptotic inference requiring each arm's pull count to concentrate around a deterministic scale. First, we prove that variance-inflated TS \citep{halder2025stable} is stable for any $K \ge 2$, including the challenging regime where multiple arms are optimal. This resolves the open question raised by \citet{halder2025stable} through extending their results from the two-armed setting to the general $K$-armed setting. Second, we analyze an alternative optimistic modification that keeps the posterior variance unchanged but adds an explicit mean bonus to posterior mean, and establish the same stability conclusion. In summary, suitably implemented optimism stabilizes Thompson sampling and enables asymptotically valid inference in multi-armed bandits, while incurring only a mild additional regret cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06014v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shunxing Yan, Han Zhong</dc:creator>
    </item>
    <item>
      <title>Optimistic Estimation of Convergence in Markov Chains with the Average-Mixing Time</title>
      <link>https://arxiv.org/abs/2402.10506</link>
      <description>arXiv:2402.10506v4 Announce Type: replace 
Abstract: The convergence rate of a Markov chain to its stationary distribution is typically assessed using the concept of total variation mixing time. However, this worst-case measure often yields pessimistic estimates and is challenging to infer from observations. In this paper, we advocate for the use of the average-mixing time as a more optimistic and demonstrably easier-to-estimate alternative. We further illustrate its applicability across a range of settings, from two-point to countable spaces, and discuss some practical implications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.10506v4</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Geoffrey Wolfer, Pierre Alquier</dc:creator>
    </item>
    <item>
      <title>Testing hypotheses generated by constraints</title>
      <link>https://arxiv.org/abs/2504.02974</link>
      <description>arXiv:2504.02974v5 Announce Type: replace 
Abstract: E-variables are nonnegative random variables with expected value at most one under any distribution from a given null hypothesis. Every nonasymptotically valid test can be obtained by thresholding some e-variable. As such, e-variables arise naturally in applications in statistics and operations research, and a key open problem is to characterize their form. We provide a complete solution to this problem for hypotheses generated by constraints -- a broad and natural framework that encompasses many hypothesis classes occurring in practice. Our main result is an abstract representation theorem that describes all e-variables for any hypothesis defined by an arbitrary collection of measurable constraints. We instantiate this general theory for three important classes: hypotheses generated by finitely many constraints, one-sided sub-$\psi$ distributions (including sub-Gaussian distributions), and distributions constrained by group symmetries. In each case, we explicitly characterize all e-variables as well as all admissible e-variables. Numerous examples are treated, including constraints on moments, quantiles, and conditional value-at-risk (CVaR). Building on these, we prove existence and uniqueness of optimal e-variables under a large class of expected utility-based objective functions used for optimal decision making, in particular covering all criteria studied in the e-variable literature to date.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02974v5</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Larsson, Aaditya Ramdas, Johannes Ruf</dc:creator>
    </item>
    <item>
      <title>Asymptotic inference in a stationary quantum time series</title>
      <link>https://arxiv.org/abs/2512.01026</link>
      <description>arXiv:2512.01026v2 Announce Type: replace 
Abstract: We consider a statistical model of a n-mode quantum Gaussian state which is shift invariant and also gauge invariant. Such models can be considered analogs of classical Gaussian stationary time series, parametrized by their spectral density. Defining an appropriate quantum spectral density as the parameter, we establish that the quantum Gaussian time series model is asymptotically equivalent to a classical nonlinear regression model given as a collection of independent geometric random variables. The asymptotic equivalence is established in the sense of the quantum Le Cam distance between statistical models (experiments). The geometric regression model has a further classical approximation as a certain Gaussian white noise model with a transformed quantum spectral density as signal. In this sense, the result is a quantum analog of the asymptotic equivalence of classical spectral density estimation and Gaussian white noise, which is known for Gaussian stationary time series. In a forthcoming version of this preprint, we will also identify a quantum analog of the periodogram and provide optimal parametric and nonparametric estimates of the quantum spectral density.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01026v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Nussbaum, Arleta Szko{\l}a</dc:creator>
    </item>
    <item>
      <title>Minimax optimal differentially private synthetic data for smooth queries</title>
      <link>https://arxiv.org/abs/2602.01607</link>
      <description>arXiv:2602.01607v2 Announce Type: replace 
Abstract: Differentially private synthetic data enables the sharing and analysis of sensitive datasets while providing rigorous privacy guarantees for individual contributors. A central challenge is to achieve strong utility guarantees for meaningful downstream analysis. Many existing methods ensure uniform accuracy over broad query classes, such as all Lipschitz functions, but this level of generality often leads to suboptimal rates for statistics of practical interest. Since many common data analysis queries exhibit smoothness beyond what worst-case Lipschitz bounds capture, we ask whether exploiting this additional structure can yield improved utility.
  We study the problem of generating $(\varepsilon,\delta)$-differentially private synthetic data from a dataset of size $n$ supported on the hypercube $[-1,1]^d$, with utility guarantees uniformly for all smooth queries having bounded derivatives up to order $k$. We propose a polynomial-time algorithm that achieves a minimax error rate of $n^{-\min \{1, \frac{k}{d}\}}$, up to a $\log(n)$ factor. This characterization uncovers a phase transition at $k=d$. Our results generalize the Chebyshev moment matching framework of (Musco et al., 2025; Wang et al., 2016) and strictly improve the error rates for $k$-smooth queries established in (Wang et al., 2016). Moreover, we establish the first minimax lower bound for the utility of $(\varepsilon,\delta)$-differentially private synthetic data with respect to $k$-smooth queries, extending the Wasserstein lower bound for $\varepsilon$-differential privacy in (Boedihardjo et al., 2024).</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01607v2</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rundong Ding, Yiyun He, Yizhe Zhu</dc:creator>
    </item>
    <item>
      <title>Optimal neural network approximation of smooth compositional functions on sets with low intrinsic dimension</title>
      <link>https://arxiv.org/abs/2602.03539</link>
      <description>arXiv:2602.03539v2 Announce Type: replace 
Abstract: We study approximation and statistical learning properties of deep ReLU networks under structural assumptions that mitigate the curse of dimensionality. We prove minimax-optimal uniform approximation rates for $s$-H\"older smooth functions defined on sets with low Minkowski dimension using fully connected networks with flexible width and depth, improving existing results by logarithmic factors even in classical full-dimensional settings. A key technical ingredient is a new memorization result for deep ReLU networks that enables efficient point fitting with dense architectures. We further introduce a class of compositional models in which each component function is smooth and acts on a domain of low intrinsic dimension. This framework unifies two common assumptions in the statistical learning literature, structural constraints on the target function and low dimensionality of the covariates, within a single model. We show that deep networks can approximate such functions at rates determined by the most difficult function in the composition. As an application, we derive improved convergence rates for empirical risk minimization in nonparametric regression that adapt to smoothness, compositional structure, and intrinsic dimensionality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03539v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Nagler, Sophie Langer</dc:creator>
    </item>
    <item>
      <title>Bayes, E-values and Testing</title>
      <link>https://arxiv.org/abs/2602.04146</link>
      <description>arXiv:2602.04146v2 Announce Type: replace 
Abstract: This paper studies relationships between Kolmogorov complexity, Shannon entropy, Bayes factors, E-values, and exchangeability testing. The focus is on negative log marginal or predictive probabilities -- what I.J.~Good termed the ``weight of evidence'' -- as a common evidence statistic linking coding, prediction, and sequential testing. The paper reviews the relevant information-theoretic and martingale tools, and discusses exchangeability testing via conformal e-prediction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04146v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nick Polson, Vadim Sokolov, Daniel Zantedeschi</dc:creator>
    </item>
    <item>
      <title>Arcade Processes for Informed Martingale Interpolation</title>
      <link>https://arxiv.org/abs/2301.05936</link>
      <description>arXiv:2301.05936v3 Announce Type: replace-cross 
Abstract: Arcade processes are a class of continuous stochastic processes that interpolate in a strong sense, i.e., omega by omega, between zeros at fixed pre-specified times. Their additive randomisation allows one to match any finite sequence of target random variables, indexed by the given fixed dates, on the whole probability space. The randomised arcade processes (RAPs) can thus be interpreted as a generalisation of anticipative stochastic bridges. The filtrations generated by these processes are utilised to construct a class of martingales that interpolate between the given target random variables. These so-called filtered arcade martingales (FAMs) are almost-sure solutions to the martingale interpolation problem and reveal an underlying stochastic filtering structure. In the special case of conditionally Markov randomised arcade processes, the dynamics of FAMs are informed by Bayesian updating. The same ideas are applied to filtered arcade reverse-martingales, which are constructed in a similar fashion, using reverse-filtrations of RAPs, instead. Several explicit examples for RAPs and FAMs are provided and simulated. This paper concludes with an outlook on potential connections between FAMs and martingale optimal transport, and related applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.05936v3</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Georges Kassis, Andrea Macrina</dc:creator>
    </item>
    <item>
      <title>A Differential and Pointwise Control Approach to Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2404.15617</link>
      <description>arXiv:2404.15617v4 Announce Type: replace-cross 
Abstract: Reinforcement learning (RL) in continuous state-action spaces remains challenging in scientific computing due to poor sample efficiency and lack of pathwise physical consistency. We introduce Differential Reinforcement Learning (Differential RL), a novel framework that reformulates RL from a continuous-time control perspective via a differential dual formulation. This induces a Hamiltonian structure that embeds physics priors and ensures consistent trajectories without requiring explicit constraints. To implement Differential RL, we develop Differential Policy Optimization (dfPO), a pointwise, stage-wise algorithm that refines local movement operators along the trajectory for improved sample efficiency and dynamic alignment. We establish pointwise convergence guarantees, a property not available in standard RL, and derive a competitive theoretical regret bound of $\mathcal{O}(K^{5/6})$. Empirically, dfPO outperforms standard RL baselines on representative scientific computing tasks, including surface modeling, grid control, and molecular dynamics, under low-data and physics-constrained conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15617v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minh Nguyen, Chandrajit Bajaj</dc:creator>
    </item>
    <item>
      <title>On the Effectiveness of Classical Regression Methods for Optimal Switching Problems</title>
      <link>https://arxiv.org/abs/2506.15436</link>
      <description>arXiv:2506.15436v2 Announce Type: replace-cross 
Abstract: Simple regression methods provide robust, near-optimal solutions for optimal switching problems, including high-dimensional ones (up to 50). While the theory requires solving intractable PDE systems, the Longstaff-Schwartz algorithm with classical regression methods achieves excellent switching decisions without extensive hyperparameter tuning. Testing linear models (OLS, Ridge, LASSO), tree-based methods (random forests, gradient boosting), $k$-nearest neighbors, and feedforward neural networks on four benchmark problems, we find that several simple methods maintain stable performance across diverse problem characteristics, outperforming the neural networks we tested against. In our comparison, $k$-NN regression performs consistently well, and with minimal hyperparameter tuning. We establish concentration bounds for this regressor and show that PCA enables $k$-NN to scale to high dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15436v2</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Andersson, Benny Avelin, Marcus Olofsson</dc:creator>
    </item>
    <item>
      <title>A variational approach to dimension-free self-normalized concentration</title>
      <link>https://arxiv.org/abs/2508.06483</link>
      <description>arXiv:2508.06483v2 Announce Type: replace-cross 
Abstract: We study the self-normalized concentration of vector-valued stochastic processes. We focus on bounds for "sub-$\psi$" processes, a well-known and quite general class of process that encompasses a wide variety of well-known tail conditions (including sub-exponential, sub-Gaussian, sub-gamma, sub-Poisson, and several heavy-tailed settings without a moment generating function such as symmetric or bounded 2nd or 3rd moments). Our results recover and generalize the influential bound of de la Pe\~na et al. [20] (proved again in Abbasi-Yadkori et al. [2]) in the sub-Gaussian case. Further, we fill a gap in the literature between determinant-based bounds and more recent bounds based on condition numbers. As applications we prove a Bernstein inequality for random vectors satisfying a moment condition (a more general condition than boundedness), and also provide the first dimension-free self-normalized empirical Bernstein inequality. Our techniques are based on the variational (PAC-Bayes) approach to concentration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06483v2</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ben Chugg, Aaditya Ramdas</dc:creator>
    </item>
    <item>
      <title>Neural Networks Learn Generic Multi-Index Models Near Information-Theoretic Limit</title>
      <link>https://arxiv.org/abs/2511.15120</link>
      <description>arXiv:2511.15120v2 Announce Type: replace-cross 
Abstract: In deep learning, a central issue is to understand how neural networks efficiently learn high-dimensional features. To this end, we explore the gradient descent learning of a general Gaussian Multi-index model $f(\boldsymbol{x})=g(\boldsymbol{U}\boldsymbol{x})$ with hidden subspace $\boldsymbol{U}\in \mathbb{R}^{r\times d}$, which is the canonical setup to study representation learning. We prove that under generic non-degenerate assumptions on the link function, a standard two-layer neural network trained via layer-wise gradient descent can agnostically learn the target with $o_d(1)$ test error using $\widetilde{\mathcal{O}}(d)$ samples and $\widetilde{\mathcal{O}}(d^2)$ time. The sample and time complexity both align with the information-theoretic limit up to leading order and are therefore optimal. During the first stage of gradient descent learning, the proof proceeds via showing that the inner weights can perform a power-iteration process. This process implicitly mimics a spectral start for the whole span of the hidden subspace and eventually eliminates finite-sample noise and recovers this span. It surprisingly indicates that optimal results can only be achieved if the first layer is trained for more than $\mathcal{O}(1)$ steps. This work demonstrates the ability of neural networks to effectively learn hierarchical functions with respect to both sample and time efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15120v2</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bohan Zhang, Zihao Wang, Hengyu Fu, Jason D. Lee</dc:creator>
    </item>
    <item>
      <title>Sample Complexity of Composite Quantum Hypothesis Testing</title>
      <link>https://arxiv.org/abs/2601.08588</link>
      <description>arXiv:2601.08588v3 Announce Type: replace-cross 
Abstract: This paper investigates symmetric composite binary quantum hypothesis testing (QHT), where the goal is to determine which of two uncertainty sets contains an unknown quantum state. While asymptotic error exponents for this problem are well-studied, the finite-sample regime remains poorly understood. We bridge this gap by characterizing the sample complexity -- the minimum number of state copies required to achieve a target error level. Specifically, we derive lower bounds that generalize the sample complexity of simple QHT and introduce new upper bounds for various uncertainty sets, including of both finite and infinite cardinalities. Notably, our upper and lower bounds match up to universal constants, providing a tight characterization of the sample complexity. Finally, we extend our analysis to the differentially private setting, establishing the sample complexity for privacy-preserving composite QHT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08588v3</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jacob Paul Simpson, Efstratios Palias, Sharu Theresa Jose</dc:creator>
    </item>
  </channel>
</rss>
