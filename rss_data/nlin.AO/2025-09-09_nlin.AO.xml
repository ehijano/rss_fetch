<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>nlin.AO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/nlin.AO</link>
    <description>nlin.AO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/nlin.AO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 10 Sep 2025 01:35:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Recursive Hierarchical Networks and the Law of Functional Evolution: A Universal Framework for Complex Systems</title>
      <link>https://arxiv.org/abs/2509.05567</link>
      <description>arXiv:2509.05567v1 Announce Type: cross 
Abstract: Understanding and predicting the evolution of across complex systems remains a fundamental challenge due to the absence of unified and computationally testable frameworks. Here we propose the Recursive Hierarchical Network(RHN), conceptualizing evolution as recursive encapsulation along a trajectory of node $\to$ module $\to$ system $\to$ new node, governed by gradual accumulation and abrupt transition. Theoretically, we formalize and prove the law of functional evolution, revealing an irreversible progression from structure-dominated to regulation-dominated to intelligence-dominated stages. Empirically, we operationalize functional levels and align life, cosmic, informational, and social systems onto this scale. The resulting trajectories are strictly monotonic and exhibit strong cross-system similarity, with high pairwise cosine similarities and robust stage resonance. We locate current system states and project future transitions. RHN provides a mathematically rigorous, multi-scale framework for reconstructing and predicting system evolution, offering theoretical guidance for designing next-generation intelligent systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05567v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <category>nlin.AO</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hui Li, Yanxin Li</dc:creator>
    </item>
    <item>
      <title>Disentangling Interaction and Bias Effects in Opinion Dynamics of Large Language Models</title>
      <link>https://arxiv.org/abs/2509.06858</link>
      <description>arXiv:2509.06858v1 Announce Type: cross 
Abstract: Large Language Models are increasingly used to simulate human opinion dynamics, yet the effect of genuine interaction is often obscured by systematic biases. We present a Bayesian framework to disentangle and quantify three such biases: (i) a topic bias toward prior opinions in the training data; (ii) an agreement bias favoring agreement irrespective of the question; and (iii) an anchoring bias toward the initiating agent's stance. Applying this framework to multi-step dialogues reveals that opinion trajectories tend to quickly converge to a shared attractor, with the influence of the interaction fading over time, and the impact of biases differing between LLMs. In addition, we fine-tune an LLM on different sets of strongly opinionated statements (incl. misinformation) and demonstrate that the opinion attractor shifts correspondingly. Exposing stark differences between LLMs and providing quantitative tools to compare them to human subjects in the future, our approach highlights both chances and pitfalls in using LLMs as proxies for human behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.06858v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.AI</category>
      <category>nlin.AO</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vincent C. Brockers, David A. Ehrlich, Viola Priesemann</dc:creator>
    </item>
    <item>
      <title>Predicting Steady-State Behavior in Complex Networks with Graph Neural Networks</title>
      <link>https://arxiv.org/abs/2502.01693</link>
      <description>arXiv:2502.01693v3 Announce Type: replace-cross 
Abstract: In complex systems, information propagation can be defined as diffused or delocalized, weakly localized, and strongly localized. This study investigates the application of graph neural network models to learn the behavior of a linear dynamical system on networks. A graph convolution and attention-based neural network framework has been developed to identify the steady-state behavior of the linear dynamical system. We reveal that our trained model distinguishes the different states with high accuracy. Furthermore, we have evaluated model performance with real-world data. In addition, to understand the explainability of our model, we provide an analytical derivation for the forward and backward propagation of our framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01693v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>nlin.AO</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Priodyuti Pradhan, Amit Reza</dc:creator>
    </item>
    <item>
      <title>Self-organisation -- the underlying principle and a general model</title>
      <link>https://arxiv.org/abs/2508.01877</link>
      <description>arXiv:2508.01877v2 Announce Type: replace-cross 
Abstract: Recent observations of coordinated self-organisation (SO) of stress and structure in granular systems provide insight into the fundamental principle underlying this phenomenon. It is first argued here that SO emerges when a minute subset of configurations are significantly more stable than the rest and therefore survive the noise in the system much longer to be observed. This principle goes deeper than recently proposed energy considerations. Guided by this principle, a statistical mechanics model is formulated then for SO in these systems and its extension to three dimensions is outlined. The principle holds beyond granular systems and the model is extended next to describe emergence of SO in more general systems. The application of the model is illustrated for the specific example of laning. Parallels of the modelling approach to traditional statistical mechanics provide useful insight that should assist in modelling SO in other out-of-equilibrium systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01877v2</guid>
      <category>cond-mat.stat-mech</category>
      <category>nlin.AO</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Raphael Blumenfeld</dc:creator>
    </item>
  </channel>
</rss>
