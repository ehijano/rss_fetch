<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 21 May 2025 01:49:48 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>XiSort: Deterministic Sorting via IEEE-754 Total Ordering and Entropy Minimization</title>
      <link>https://arxiv.org/abs/2505.11927</link>
      <description>arXiv:2505.11927v1 Announce Type: new 
Abstract: We introduce XiSort, a deterministic and reproducible sorting algorithm for floating-point sequences based on IEEE-754 total ordering and entropy minimization. XiSort guarantees bit-for-bit stability across runs and platforms by resolving tie-breaking via information-theoretic and symbolic methods. The algorithm supports both in-memory and external (out-of-core) operation, offering consistent performance on large datasets. We formalize a curved variant of the sorting metric that integrates into the Alpay Algebra framework, treating XiSort as a recursive operator with provable convergence and symbolic idempotence. This model preserves state-space closure while minimizing local disorder, interpretable as symbolic entropy. Empirical benchmarks demonstrate that XiSort achieves competitive throughput (e.g., sorting 10^8 doubles in approximately 12 seconds in-memory, and 100 GB at around 100 MB/s on SSDs), with applications in scientific computing, high-frequency finance, and reproducible numerical workflows. The results position XiSort as a principled tool for stable data alignment, symbolic preprocessing, and cross-platform float ordering.
  Keywords: deterministic sorting, IEEE-754, entropy minimization, symbolic algebra, reproducibility, external memory, Alpay Algebra, data pipelines</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11927v1</guid>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>cs.NA</category>
      <category>math.IT</category>
      <category>math.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Faruk Alpay</dc:creator>
    </item>
    <item>
      <title>A Reduction-based Algorithm for the Clique Interdiction Problem</title>
      <link>https://arxiv.org/abs/2505.12022</link>
      <description>arXiv:2505.12022v2 Announce Type: new 
Abstract: The Clique Interdiction Problem (CIP) aims to minimize the size of the largest clique in a given graph by removing a given number of vertices. The CIP models a special Stackelberg game and has important applications in fields such as pandemic control and terrorist identification. However, the CIP is a bilevel graph optimization problem, making it very challenging to solve. Recently, data reduction techniques have been successfully applied in many (single-level) graph optimization problems like the vertex cover problem. Motivated by this, we investigate a set of novel reduction rules and design a reduction-based algorithm, RECIP, for practically solving the CIP. RECIP enjoys an effective preprocessing procedure that systematically reduces the input graph, making the problem much easier to solve. Extensive experiments on 124 large real-world networks demonstrate the superior performance of RECIP and validate the effectiveness of the proposed reduction rules.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12022v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenghao Zhu, Yi Zhou, Haoyu Jiang</dc:creator>
    </item>
    <item>
      <title>Logarithmic Approximations for Fair k-Set Selection</title>
      <link>https://arxiv.org/abs/2505.12123</link>
      <description>arXiv:2505.12123v1 Announce Type: new 
Abstract: We study the fair k-set selection problem where we aim to select $k$ sets from a given set system such that the (weighted) occurrence times that each element appears in these $k$ selected sets are balanced, i.e., the maximum (weighted) occurrence times are minimized. By observing that a set system can be formulated into a bipartite graph $G:=(L\cup R, E)$, our problem is equivalent to selecting $k$ vertices from $R$ such that the maximum total weight of selected neighbors of vertices in $L$ is minimized. The problem arises in a wide range of applications in various fields, such as machine learning, artificial intelligence, and operations research.
  We first prove that the problem is NP-hard even if the maximum degree $\Delta$ of the input bipartite graph is $3$, and the problem is in P when $\Delta=2$. We then show that the problem is also in P when the input set system forms a laminar family. Based on intuitive linear programming, we show that a dependent rounding algorithm achieves $O(\frac{\log n}{\log \log n})$-approximation on general bipartite graphs, and an independent rounding algorithm achieves $O(\log\Delta)$-approximation on bipartite graphs with a maximum degree $\Delta$. We demonstrate that our analysis is almost tight by providing a hard instance for this linear programming. Finally, we extend all our algorithms to the weighted case and prove that all approximations are preserved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12123v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shi Li, Chenyang Xu, Ruilong Zhang</dc:creator>
    </item>
    <item>
      <title>Fair Submodular Maximization over a Knapsack Constraint</title>
      <link>https://arxiv.org/abs/2505.12126</link>
      <description>arXiv:2505.12126v1 Announce Type: new 
Abstract: We consider fairness in submodular maximization subject to a knapsack constraint, a fundamental problem with various applications in economics, machine learning, and data mining. In the model, we are given a set of ground elements, each associated with a weight and a color, and a monotone submodular function defined over them. The goal is to maximize the submodular function while guaranteeing that the total weight does not exceed a specified budget (the knapsack constraint) and that the number of elements selected for each color falls within a designated range (the fairness constraint).
  While there exists some recent literature on this topic, the existence of a non-trivial approximation for the problem -- without relaxing either the knapsack or fairness constraints -- remains a challenging open question. This paper makes progress in this direction. We demonstrate that when the number of colors is constant, there exists a polynomial-time algorithm that achieves a constant approximation with high probability. Additionally, we show that if either the knapsack or fairness constraint is relaxed only to require expected satisfaction, a tight approximation ratio of $(1-1/e-\epsilon)$ can be obtained in expectation for any $\epsilon &gt;0$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12126v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Lijun Li, Chenyang Xu, Liuyi Yang, Ruilong Zhang</dc:creator>
    </item>
    <item>
      <title>ResidualSketch: Enhancing Layer Efficiency and Error Reduction in Hierarchical Heavy Hitter Detection with ResNet Innovations</title>
      <link>https://arxiv.org/abs/2505.12445</link>
      <description>arXiv:2505.12445v1 Announce Type: new 
Abstract: In network management, swiftly and accurately identifying traffic anomalies, including Distributed Denial-of-Service (DDoS) attacks and unexpected network disruptions, is essential for network stability and security. Key to this process is the detection of Hierarchical Heavy Hitters (HHH), which significantly aids in the management of high-speed IP traffic. This study introduces ResidualSketch, a novel algorithm for HHH detection in hierarchical traffic analysis. ResidualSketch distinguishes itself by incorporating Residual Blocks and Residual Connections at crucial layers within the IP hierarchy, thus mitigating the Gradual Error Diffusion (GED) phenomenon in previous methods and reducing memory overhead while maintaining low update latency. Through comprehensive experiments on various datasets, we demonstrate that ResidualSketch outperforms existing state-of-the-art solutions in terms of accuracy and update speed across multiple layers of the network hierarchy. All related codes of ResidualSketch are open-source at GitHub.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12445v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xilai Liu, Yuxuan Tian, Xiangyuan Wang, Yuhan Wu, Wenhao Wu, Tong Yang, Gaogang Xie</dc:creator>
    </item>
    <item>
      <title>Fast and Simple Densest Subgraph with Predictions</title>
      <link>https://arxiv.org/abs/2505.12600</link>
      <description>arXiv:2505.12600v1 Announce Type: new 
Abstract: We study the densest subgraph problem and its variants through the lens of learning-augmented algorithms. For this problem, the greedy algorithm by Charikar (APPROX 2000) provides a linear-time $ 1/2 $-approximation, while computing the exact solution typically requires solving a linear program or performing maximum flow computations.We show that given a partial solution, i.e., one produced by a machine learning classifier that captures at least a $ (1 - \epsilon) $-fraction of nodes in the optimal subgraph, it is possible to design an extremely simple linear-time algorithm that achieves a provable $ (1 - \epsilon) $-approximation. Our approach also naturally extends to the directed densest subgraph problem and several NP-hard variants.An experiment on the Twitch Ego Nets dataset shows that our learning-augmented algorithm outperforms Charikar's greedy algorithm and a baseline that directly returns the predicted densest subgraph without additional algorithmic processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12600v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thai Bui, Hoa T. Vu</dc:creator>
    </item>
    <item>
      <title>A Faster Parametric Search for the Integral Quickest Transshipment Problem</title>
      <link>https://arxiv.org/abs/2505.12975</link>
      <description>arXiv:2505.12975v1 Announce Type: new 
Abstract: Algorithms for computing fractional solutions to the quickest transshipment problem have been significantly improved since Hoppe and Tardos first solved the problem in strongly polynomial time. For integral solutions, runtime improvements are limited to general progress on submodular function minimization, which is an integral part of Hoppe and Tardos' algorithm. Yet, no structural improvements on their algorithm itself have been proposed. We replace two central subroutines in the algorithm with methods that require vastly fewer minimizations of submodular functions. This improves the state-of-the-art runtime from $ \tilde{O}(m^4 k^{15}) $ down to $ \tilde{O}(m^2 k^5 + m^4 k^2) $, where $ k $ is the number of terminals and $ m $ is the number of arcs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12975v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Mariia Anapolska, Dario van den Boom, Christina B\"using, Timo Gersing</dc:creator>
    </item>
    <item>
      <title>Fast RoPE Attention: Combining the Polynomial Method and Fast Fourier Transform</title>
      <link>https://arxiv.org/abs/2505.11892</link>
      <description>arXiv:2505.11892v1 Announce Type: cross 
Abstract: The transformer architecture has been widely applied to many machine learning tasks. A main bottleneck in the time to perform transformer computations is a task called attention computation. [Alman and Song, NeurIPS 2023] have shown that in the bounded entry regime, there is an almost linear time algorithm to approximate the attention computation. They also proved that the bounded entry assumption is necessary for a fast algorithm assuming the popular Strong Exponential Time Hypothesis.
  A new version of transformer which uses position embeddings has recently been very successful. At a high level, position embedding enables the model to capture the correlations between tokens while taking into account their position in the sequence. Perhaps the most popular and effective version is Rotary Position Embedding (RoPE), which was proposed by [Su, Lu, Pan, Murtadha, Wen, and Liu, Neurocomputing 2024].
  A main downside of RoPE is that it complicates the attention computation problem, so that previous techniques for designing almost linear time algorithms no longer seem to work. In this paper, we show how to overcome this issue, and give a new algorithm to compute the RoPE attention in almost linear time in the bounded entry regime. (Again, known lower bounds imply that bounded entries are necessary.) Our new algorithm combines two techniques in a novel way: the polynomial method, which was used in prior fast attention algorithms, and the Fast Fourier Transform.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11892v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Josh Alman, Zhao Song</dc:creator>
    </item>
    <item>
      <title>BOLT: Block-Orthonormal Lanczos for Trace estimation of matrix functions</title>
      <link>https://arxiv.org/abs/2505.12289</link>
      <description>arXiv:2505.12289v1 Announce Type: cross 
Abstract: Efficient matrix trace estimation is essential for scalable computation of log-determinants, matrix norms, and distributional divergences. In many large-scale applications, the matrices involved are too large to store or access in full, making even a single matrix-vector (mat-vec) product infeasible. Instead, one often has access only to small subblocks of the matrix or localized matrix-vector products on restricted index sets. Hutch++ achieves optimal convergence rate but relies on randomized SVD and assumes full mat-vec access, making it difficult to apply in these constrained settings. We propose the Block-Orthonormal Stochastic Lanczos Quadrature (BOLT), which matches Hutch++ accuracy with a simpler implementation based on orthonormal block probes and Lanczos iterations. BOLT builds on the Stochastic Lanczos Quadrature (SLQ) framework, which combines random probing with Krylov subspace methods to efficiently approximate traces of matrix functions, and performs better than Hutch++ in near flat-spectrum regimes. To address memory limitations and partial access constraints, we introduce Subblock SLQ, a variant of BOLT that operates only on small principal submatrices. As a result, this framework yields a proxy KL divergence estimator and an efficient method for computing the Wasserstein-2 distance between Gaussians - both compatible with low-memory and partial-access regimes. We provide theoretical guarantees and demonstrate strong empirical performance across a range of high-dimensional settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12289v1</guid>
      <category>math.NA</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kingsley Yeon, Promit Ghosal, Mihai Anitescu</dc:creator>
    </item>
    <item>
      <title>Nonlinear Laplacians: Tunable principal component analysis under directional prior information</title>
      <link>https://arxiv.org/abs/2505.12528</link>
      <description>arXiv:2505.12528v1 Announce Type: cross 
Abstract: We introduce a new family of algorithms for detecting and estimating a rank-one signal from a noisy observation under prior information about that signal's direction, focusing on examples where the signal is known to have entries biased to be positive. Given a matrix observation $\mathbf{Y}$, our algorithms construct a nonlinear Laplacian, another matrix of the form $\mathbf{Y} + \mathrm{diag}(\sigma(\mathbf{Y}\mathbf{1}))$ for a nonlinear $\sigma: \mathbb{R} \to \mathbb{R}$, and examine the top eigenvalue and eigenvector of this matrix. When $\mathbf{Y}$ is the (suitably normalized) adjacency matrix of a graph, our approach gives a class of algorithms that search for unusually dense subgraphs by computing a spectrum of the graph "deformed" by the degree profile $\mathbf{Y}\mathbf{1}$. We study the performance of such algorithms compared to direct spectral algorithms (the case $\sigma = 0$) on models of sparse principal component analysis with biased signals, including the Gaussian planted submatrix problem. For such models, we rigorously characterize the critical threshold strength of rank-one signal, as a function of the nonlinearity $\sigma$, at which an outlier eigenvalue appears in the spectrum of a nonlinear Laplacian. While identifying the $\sigma$ that minimizes this critical signal strength in closed form seems intractable, we explore three approaches to design $\sigma$ numerically: exhaustively searching over simple classes of $\sigma$, learning $\sigma$ from datasets of problem instances, and tuning $\sigma$ using black-box optimization of the critical signal strength. We find both theoretically and empirically that, if $\sigma$ is chosen appropriately, then nonlinear Laplacian spectral algorithms substantially outperform direct spectral algorithms, while avoiding the complexity of broader classes of algorithms like approximate message passing or general first order methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12528v1</guid>
      <category>stat.ML</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuxin Ma, Dmitriy Kunisky</dc:creator>
    </item>
    <item>
      <title>Private Statistical Estimation via Truncation</title>
      <link>https://arxiv.org/abs/2505.12541</link>
      <description>arXiv:2505.12541v1 Announce Type: cross 
Abstract: We introduce a novel framework for differentially private (DP) statistical estimation via data truncation, addressing a key challenge in DP estimation when the data support is unbounded. Traditional approaches rely on problem-specific sensitivity analysis, limiting their applicability. By leveraging techniques from truncated statistics, we develop computationally efficient DP estimators for exponential family distributions, including Gaussian mean and covariance estimation, achieving near-optimal sample complexity. Previous works on exponential families only consider bounded or one-dimensional families. Our approach mitigates sensitivity through truncation while carefully correcting for the introduced bias using maximum likelihood estimation and DP stochastic gradient descent. Along the way, we establish improved uniform convergence guarantees for the log-likelihood function of exponential families, which may be of independent interest. Our results provide a general blueprint for DP algorithm design via truncated statistics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12541v1</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>stat.ML</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Manolis Zampetakis, Felix Zhou</dc:creator>
    </item>
    <item>
      <title>More Efforts Towards Fixed-Parameter Approximability of Multiwinner Rules</title>
      <link>https://arxiv.org/abs/2505.12699</link>
      <description>arXiv:2505.12699v1 Announce Type: cross 
Abstract: Multiwinner Elections have emerged as a prominent area of research with numerous practical applications. We contribute to this area by designing parameterized approximation algorithms and also resolving an open question by Yang and Wang [AAMAS'18]. More formally, given a set of candidates, \mathcal{C}, a set of voters,\mathcal{V}, approving a subset of candidates (called approval set of a voter), and an integer $k$, we consider the problem of selecting a ``good'' committee using Thiele rules. This problem is computationally challenging for most Thiele rules with monotone submodular satisfaction functions, as there is no (1-\frac{1}{e}-\epsilon)\footnote{Here, $e$ denotes the base of the natural logarithm.}-approximation algorithm in f(k)(|\mathcal{C}| + |\mathcal{V}|)^{o(k)} time for any fixed $\epsilon &gt; 0$ and any computable function $f$, and no {\sf PTAS} even when the length of approval set is two. Skowron [WINE'16] designed an approximation scheme running in FPT time parameterized by the combined parameter, size of the approval set and $k$. In this paper, we consider a parameter $d+k$ (no $d$ voters approve the same set of $d$ candidates), where $d$ is upper bounded by the size of the approval set (thus, can be much smaller).
  With respect to this parameter, we design parameterized approximation schemes, a lossy polynomial-time preprocessing method, and show that an extra committee member suffices to achieve the desired score (i.e., $1$-additive approximation). Additionally, we resolve an open question by Yang and Wang~[AAMAS'18] regarding the fixed-parameter tractability of the problem under the PAV rule with the total score as the parameter, demonstrating that it admits an FPT algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12699v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sushmita Gupta, Pallavi Jain, Souvik Saha, Saket Saurabh, Anannya Upasana</dc:creator>
    </item>
    <item>
      <title>Counting Graphlets of Size $k$ under Local Differential Privacy</title>
      <link>https://arxiv.org/abs/2505.12954</link>
      <description>arXiv:2505.12954v1 Announce Type: cross 
Abstract: The problem of counting subgraphs or graphlets under local differential privacy is an important challenge that has attracted significant attention from researchers. However, much of the existing work focuses on small graphlets like triangles or $k$-stars. In this paper, we propose a non-interactive, locally differentially private algorithm capable of counting graphlets of any size $k$. When $n$ is the number of nodes in the input graph, we show that the expected $\ell_2$ error of our algorithm is $O(n^{k - 1})$. Additionally, we prove that there exists a class of input graphs and graphlets of size $k$ for which any non-interactive counting algorithm incurs an expected $\ell_2$ error of $\Omega(n^{k - 1})$, demonstrating the optimality of our result. Furthermore, we establish that for certain input graphs and graphlets, any locally differentially private algorithm must have an expected $\ell_2$ error of $\Omega(n^{k - 1.5})$. Our experimental results show that our algorithm is more accurate than the classical randomized response method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12954v1</guid>
      <category>cs.SI</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Vorapong Suppakitpaisarn, Donlapark Ponnoprat, Nicha Hirankarn, Quentin Hillebrand</dc:creator>
    </item>
    <item>
      <title>A $d^{1/2+o(1)}$ Monotonicity Tester for Boolean Functions on $d$-Dimensional Hypergrids</title>
      <link>https://arxiv.org/abs/2304.01416</link>
      <description>arXiv:2304.01416v2 Announce Type: replace 
Abstract: Monotonicity testing of Boolean functions on the hypergrid, $f:[n]^d \to \{0,1\}$, is a classic topic in property testing. Determining the non-adaptive complexity of this problem is an important open question. For arbitrary $n$, [Black-Chakrabarty-Seshadhri, SODA 2020] describe a tester with query complexity $\widetilde{O}(\varepsilon^{-4/3}d^{5/6})$. This complexity is independent of $n$, but has a suboptimal dependence on $d$. Recently, [Braverman-Khot-Kindler-Minzer, ITCS 2023] and [Black-Chakrabarty-Seshadhri, STOC 2023] describe $\widetilde{O}(\varepsilon^{-2} n^3\sqrt{d})$ and $\widetilde{O}(\varepsilon^{-2} n\sqrt{d})$-query testers, respectively. These testers have an almost optimal dependence on $d$, but a suboptimal polynomial dependence on $n$.
  In this paper, we describe a non-adaptive, one-sided monotonicity tester with query complexity $O(\varepsilon^{-2} d^{1/2 + o(1)})$, independent of $n$. Up to the $d^{o(1)}$-factors, our result resolves the non-adaptive complexity of monotonicity testing for Boolean functions on hypergrids. The independence of $n$ yields a non-adaptive, one-sided $O(\varepsilon^{-2} d^{1/2 + o(1)})$-query monotonicity tester for Boolean functions $f:\mathbb{R}^d \to \{0,1\}$ associated with an arbitrary product measure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.01416v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hadley Black, Deeparnab Chakrabarty, C. Seshadhri</dc:creator>
    </item>
    <item>
      <title>Predicting Memory Demands of BDD Operations using Maximum Graph Cuts (Extended Paper)</title>
      <link>https://arxiv.org/abs/2307.04488</link>
      <description>arXiv:2307.04488v3 Announce Type: replace 
Abstract: The BDD package Adiar manipulates Binary Decision Diagrams (BDDs) in external memory. This enables handling big BDDs, but the performance suffers when dealing with moderate-sized BDDs. This is mostly due to initializing expensive external memory data structures, even if their contents can fit entirely inside internal memory.
  The contents of these auxiliary data structures always correspond to a graph cut in an input or output BDD. Specifically, these cuts respect the levels of the BDD. We formalise the shape of these cuts and prove sound upper bounds on their maximum size for each BDD operation.
  We have implemented these upper bounds within Adiar. With these bounds, it can predict whether a faster internal memory variant of the auxiliary data structures can be used. In practice, this improves Adiar's running time across the board. Specifically for the moderate-sized BDDs, this results in an average reduction of the computation time by 86.1% (median of 89.7%). In some cases, the difference is even 99.9\%. When checking equivalence of hardware circuits from the EPFL Benchmark Suite, for one of the instances the time was decreased by 52 hours.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.04488v3</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-45332-8_4</arxiv:DOI>
      <arxiv:journal_reference>S{\o}lvsten, S.C., Van de Pol, J. (2023). Predicting Memory Demands of BDD Operations Using Maximum Graph Cuts. In: Automated Technology for Verification and Analysis. ATVA 2023. Lecture Notes in Computer Science, vol 14216. Springer</arxiv:journal_reference>
      <dc:creator>Steffan Christ S{\o}lvsten, Jaco van de Pol</dc:creator>
    </item>
    <item>
      <title>Diversity-aware clustering: Computational Complexity and Approximation Algorithms</title>
      <link>https://arxiv.org/abs/2401.05502</link>
      <description>arXiv:2401.05502v3 Announce Type: replace 
Abstract: In this work, we study diversity-aware clustering problems where the data points are associated with multiple attributes resulting in intersecting groups. A clustering solution needs to ensure that the number of chosen cluster centers from each group should be within the range defined by a lower and upper bound threshold for each group, while simultaneously minimizing the clustering objective, which can be either $k$-median, $k$-means or $k$-supplier. We study the computational complexity of the proposed problems, offering insights into their NP-hardness, polynomial-time inapproximability, and fixed-parameter intractability. We present parameterized approximation algorithms with approximation ratios $1+ \frac{2}{e} + \epsilon \approx 1.736$, $1+\frac{8}{e} + \epsilon \approx 3.943$, and $5$ for diversity-aware $k$-median, diversity-aware $k$-means and diversity-aware $k$-supplier, respectively. Assuming Gap-ETH, the approximation ratios are tight for the diversity-aware $k$-median and diversity-aware $k$-means problems. Our results imply the same approximation factors for their respective fair variants with disjoint groups -- fair $k$-median, fair $k$-means, and fair $k$-supplier -- with lower bound requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.05502v3</guid>
      <category>cs.DS</category>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Suhas Thejaswi, Ameet Gadekar, Bruno Ordozgoiti, Aristides Gionis</dc:creator>
    </item>
    <item>
      <title>Massively Parallel Algorithms for Approximate Shortest Paths</title>
      <link>https://arxiv.org/abs/2412.06952</link>
      <description>arXiv:2412.06952v2 Announce Type: replace 
Abstract: We present fast algorithms for approximate shortest paths in the massively parallel computation (MPC) model. We provide randomized algorithms that take $poly(\log{\log{n}})$ rounds in the near-linear memory MPC model. Our results are for unweighted undirected graphs with $n$ vertices and $m$ edges. Our first contribution is a $(1+\epsilon)$-approximation algorithm for Single-Source Shortest Paths (SSSP) that takes $poly(\log{\log{n}})$ rounds in the near-linear MPC model, where the memory per machine is $\tilde{O}(n)$ and the total memory is $\tilde{O}(mn^{\rho})$, where $\rho$ is a small constant. Our second contribution is a distance oracle that allows to approximate the distance between any pair of vertices. The distance oracle is constructed in $poly(\log{\log{n}})$ rounds and allows to query a $(1+\epsilon)(2k-1)$-approximate distance between any pair of vertices $u$ and $v$ in $O(1)$ additional rounds. The algorithm is for the near-linear memory MPC model with total memory of size $\tilde{O}((m+n^{1+\rho})n^{1/k})$, where $\rho$ is a small constant. While our algorithms are for the near-linear MPC model, in fact they only use one machine with $\tilde{O}(n)$ memory, where the rest of machines can have sublinear memory of size $O(n^{\gamma})$ for a small constant $\gamma &lt; 1$. All previous algorithms for approximate shortest paths in the near-linear MPC model either required $\Omega(\log{n})$ rounds or had an $\Omega(\log{n})$ approximation. Our approach is based on fast construction of near-additive emulators, limited-scale hopsets and limited-scale distance sketches that are tailored for the MPC model. While our end-results are for the near-linear MPC model, many of the tools we construct such as hopsets and emulators are constructed in the more restricted sublinear MPC model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06952v2</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s00446-025-00482-y</arxiv:DOI>
      <dc:creator>Michal Dory, Shaked Matar</dc:creator>
    </item>
    <item>
      <title>Highway Dimension: a Metric View</title>
      <link>https://arxiv.org/abs/2412.20490</link>
      <description>arXiv:2412.20490v2 Announce Type: replace 
Abstract: Realistic metric spaces (such as road/transportation networks) tend to be much more algorithmically tractable than general metrics. In an attempt to formalize this intuition, Abraham et al. (SODA 2010, JACM 2016) introduced the notion of highway dimension. A weighted graph $G$ has highway dimension $h$ if for every ball $B$ of radius $\approx 4r$ there is a hitting set of size $h$ hitting all the shortest paths of length $&gt;r$ in $B$. Unfortunately, this definition fails to incorporate some very natural metric spaces such as the grid graph, and the Euclidean plane.
  We relax the definition of highway dimension by demanding to hit only approximate shortest paths. In addition to generalizing the original definition, this new definition also incorporates all doubling spaces (in particular the grid graph and the Euclidean plane). We then construct a PTAS for TSP under this new definition (improving a QPTAS w.r.t. the original more restrictive definition of Feldmann et al. (SICOMP 2018)). Finally, we develop a basic metric toolkit for spaces with small highway dimension by constructing padded decompositions, sparse covers/partitions, and tree covers. An abundance of applications follow.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20490v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andreas Emil Feldmann, Arnold Filtser</dc:creator>
    </item>
    <item>
      <title>Zip-Tries: Simple Dynamic Data Structures for Strings</title>
      <link>https://arxiv.org/abs/2505.04953</link>
      <description>arXiv:2505.04953v2 Announce Type: replace 
Abstract: In this paper, we introduce zip-tries, which are simple, dynamic, memory-efficient data structures for strings. Zip-tries support search and update operations for $k$-length strings in $\mathcal{O}(k+\log n)$ time in the standard RAM model or in $\mathcal{O}(k/\alpha+\log n)$ time in the word RAM model, where $\alpha$ is the length of the longest string that can fit in a memory word, and $n$ is the number of strings in the trie. Importantly, we show how zip-tries can achieve this while only requiring $\mathcal{O}(\log{\log{n}} + \log{\log{\frac{k}{\alpha}}})$ bits of metadata per node w.h.p., which is an exponential improvement over previous results for long strings. Despite being considerably simpler and more memory efficient, we show how zip-tries perform competitively with state-of-the-art data structures on large datasets of long strings.
  Furthermore, we provide a simple, general framework for parallelizing string comparison operations in linked data structures, which we apply to zip-tries to obtain parallel zip-tries. Parallel zip-tries are able to achieve good search and update performance in parallel, performing such operations in $\mathcal{O}(\log{n})$ span. We also apply our techniques to an existing external-memory string data structure, the string B-tree, obtaining a parallel string B-tree which performs search operations using $\mathcal{O}(\log_B{n})$ I/O span and $\mathcal{O}(\frac{k}{\alpha B} + \log_B{n})$ I/O work in the parallel external memory (PEM) model. The parallel string B-tree can perform prefix searches using only $\mathcal{O}(\frac{\log{n}}{\log{\log{n}}})$ span under the practical PRAM model.
  For the case of long strings that share short common prefixes, we provide LCP-aware variants of all our algorithms that should be quite efficient in practice, which we justify empirically.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04953v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Eppstein (University of California, Irvine), Ofek Gila (University of California, Irvine), Michael T. Goodrich (University of California, Irvine), Ryuto Kitagawa (University of California, Irvine)</dc:creator>
    </item>
    <item>
      <title>Tensor Sketch: Fast and Scalable Polynomial Kernel Approximation</title>
      <link>https://arxiv.org/abs/2505.08146</link>
      <description>arXiv:2505.08146v2 Announce Type: replace 
Abstract: Approximation of non-linear kernels using random feature maps has become a powerful technique for scaling kernel methods to large datasets. We propose $\textit{Tensor Sketch}$, an efficient random feature map for approximating polynomial kernels. Given $n$ training samples in $\mathbb{R}^d$ Tensor Sketch computes low-dimensional embeddings in $\mathbb{R}^D$ in time $\mathcal{O}\left( n(d+D \log{D}) \right)$ making it well-suited for high-dimensional and large-scale settings. We provide theoretical guarantees on the approximation error, ensuring the fidelity of the resulting kernel function estimates. We also discuss extensions and highlight applications where Tensor Sketch serves as a central computational tool.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08146v2</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ninh Pham, Rasmus Pagh</dc:creator>
    </item>
    <item>
      <title>Improved Rank Aggregation under Fairness Constraint</title>
      <link>https://arxiv.org/abs/2505.10006</link>
      <description>arXiv:2505.10006v2 Announce Type: replace 
Abstract: Aggregating multiple input rankings into a consensus ranking is essential in various fields such as social choice theory, hiring, college admissions, web search, and databases. A major challenge is that the optimal consensus ranking might be biased against individual candidates or groups, especially those from marginalized communities. This concern has led to recent studies focusing on fairness in rank aggregation. The goal is to ensure that candidates from different groups are fairly represented in the top-$k$ positions of the aggregated ranking.
  We study this fair rank aggregation problem by considering the Kendall tau as the underlying metric. While we know of a polynomial-time approximation scheme (PTAS) for the classical rank aggregation problem, the corresponding fair variant only possesses a quite straightforward 3-approximation algorithm due to Wei et al., SIGMOD'22, and Chakraborty et al., NeurIPS'22, which finds closest fair ranking for each input ranking and then simply outputs the best one.
  In this paper, we first provide a novel algorithm that achieves $(2+\epsilon)$-approximation (for any $\epsilon &gt; 0$), significantly improving over the 3-approximation bound. Next, we provide a $2.881$-approximation fair rank aggregation algorithm that works irrespective of the fairness notion, given one can find a closest fair ranking, beating the 3-approximation bound. We complement our theoretical guarantee by performing extensive experiments on various real-world datasets to establish the effectiveness of our algorithm further by comparing it with the performance of state-of-the-art algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10006v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Diptarka Chakraborty, Himika Das, Sanjana Dey, Alvin Hong Yao Yan</dc:creator>
    </item>
    <item>
      <title>Simpler and Faster Directed Low-Diameter Decompositions</title>
      <link>https://arxiv.org/abs/2505.10244</link>
      <description>arXiv:2505.10244v2 Announce Type: replace 
Abstract: We present a simpler and faster algorithm for low-diameter decompositions on directed graphs, matching the $O(\log n\log\log n)$ loss factor from Bringmann, Fischer, Haeupler, and Latypov (ICALP 2025) and improving the running time to $O((m+n\log\log n)\log^2n)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10244v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jason Li</dc:creator>
    </item>
    <item>
      <title>Filling a triangulation of the 2-sphere</title>
      <link>https://arxiv.org/abs/2303.10773</link>
      <description>arXiv:2303.10773v3 Announce Type: replace-cross 
Abstract: Define the tet-volume of a triangulation of the 2-sphere to be the minimum number of tetrahedra in a 3-complex of which it is the boundary, and let $d(v)$ be the maximum tet-volume for $v$-vertex triangulations. In 1986 Sleator, Tarjan, and Thurston (STT) proved that $d(v) = 2v-10$ holds for large $v$, and conjectured that it holds for all $v \geq 13$. Their proof used hyperbolic polyhedra of large volume. They suggested using more general notions of volume instead. In work that was all but lost, Mathieu and Thurston used this approach to outline a combinatorial proof of the STT asymptotic result. Here we use a much simplified version of their approach to prove the full conjecture. This implies STT's weaker conjecture, proven by Pournin in 2014, characterizing the maximum rotation distance between trees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.10773v3</guid>
      <category>math.CO</category>
      <category>cs.DS</category>
      <category>math.GT</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peter Doyle, Matthew Ellison, Zili Wang</dc:creator>
    </item>
    <item>
      <title>Hot PATE: Private Aggregation of Distributions for Diverse Task</title>
      <link>https://arxiv.org/abs/2312.02132</link>
      <description>arXiv:2312.02132v3 Announce Type: replace-cross 
Abstract: The Private Aggregation of Teacher Ensembles (PATE) framework enables privacy-preserving machine learning by aggregating responses from disjoint subsets of sensitive data. Adaptations of PATE to tasks with inherent output diversity such as text generation face a core tension: preserving output diversity reduces teacher agreement, which in turn increases the noise required for differential privacy, degrading utility. Yet suppressing diversity is counterproductive, as modern large language models encapsulate knowledge in their output distributions.
  We propose Hot PATE, a variant tailored to settings where outputs are distributions. We formally define what it means to preserve diversity and introduce an efficient aggregation mechanism that transfers diversity to the randomized output without incurring additional privacy cost. Our method can be implemented with only API access to proprietary models and serves as a drop-in replacement for existing "cold" PATE aggregators. Empirically, Hot PATE achieves orders-of-magnitude improvement on in-context learning tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.02132v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Edith Cohen, Benjamin Cohen-Wang, Xin Lyu, Jelani Nelson, Tamas Sarlos, Uri Stemmer</dc:creator>
    </item>
    <item>
      <title>Quantum (Inspired) $D^2$-sampling with Applications</title>
      <link>https://arxiv.org/abs/2405.13351</link>
      <description>arXiv:2405.13351v2 Announce Type: replace-cross 
Abstract: $D^2$-sampling is a fundamental component of sampling-based clustering algorithms such as $k$-means++. Given a dataset $V \subset \mathbb{R}^d$ with $N$ points and a center set $C \subset \mathbb{R}^d$, $D^2$-sampling refers to picking a point from $V$ where the sampling probability of a point is proportional to its squared distance from the nearest center in $C$. Starting with empty $C$ and iteratively $D^2$-sampling and updating $C$ in $k$ rounds is precisely $k$-means++ seeding that runs in $O(Nkd)$ time and gives $O(\log{k})$-approximation in expectation for the $k$-means problem. We give a quantum algorithm for (approximate) $D^2$-sampling in the QRAM model that results in a quantum implementation of $k$-means++ that runs in time $\tilde{O}(\zeta^2 k^2)$. Here $\zeta$ is the aspect ratio (i.e., largest to smallest interpoint distance), and $\tilde{O}$ hides polylogarithmic factors in $N, d, k$. It can be shown through a robust approximation analysis of $k$-means++ that the quantum version preserves its $O(\log{k})$ approximation guarantee. Further, we show that our quantum algorithm for $D^2$-sampling can be 'dequantized' using the sample-query access model of Tang (PhD Thesis, Ewin Tang, University of Washington, 2023). This results in a fast quantum-inspired classical implementation of $k$-means++, which we call QI-$k$-means++, with a running time $O(Nd) + \tilde{O}(\zeta^2k^2d)$, where the $O(Nd)$ term is for setting up the sample-query access data structure. Experimental investigations show promising results for QI-$k$-means++ on large datasets with bounded aspect ratio. Finally, we use our quantum $D^2$-sampling with the known $ D^2$-sampling-based classical approximation scheme (i.e., $(1+\varepsilon)$-approximation for any given $\varepsilon&gt;0$) to obtain the first quantum approximation scheme for the $k$-means problem with polylogarithmic running time dependence on $N$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13351v2</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Poojan Shah, Ragesh Jaiswal</dc:creator>
    </item>
    <item>
      <title>Greedy Algorithm for Structured Bandits: A Sharp Characterization of Asymptotic Success / Failure</title>
      <link>https://arxiv.org/abs/2503.04010</link>
      <description>arXiv:2503.04010v2 Announce Type: replace-cross 
Abstract: We study the greedy (exploitation-only) algorithm in bandit problems with a known reward structure. We allow arbitrary finite reward structures, while prior work focused on a few specific ones. We fully characterize when the greedy algorithm asymptotically succeeds or fails, in the sense of sublinear vs. linear regret as a function of time. Our characterization identifies a partial identifiability property of the problem instance as the necessary and sufficient condition for the asymptotic success. Notably, once this property holds, the problem becomes easy -- any algorithm will succeed (in the same sense as above), provided it satisfies a mild non-degeneracy condition. Our characterization extends to contextual bandits and interactive decision-making with arbitrary feedback. Examples demonstrating broad applicability and extensions to infinite reward structures are provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04010v2</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aleksandrs Slivkins, Yunzong Xu, Shiliang Zuo</dc:creator>
    </item>
  </channel>
</rss>
