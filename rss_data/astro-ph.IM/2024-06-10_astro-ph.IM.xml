<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>astro-ph.IM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/astro-ph.IM</link>
    <description>astro-ph.IM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/astro-ph.IM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 11 Jun 2024 02:45:26 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 10 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>TIDMAD: Time Series Dataset for Discovering Dark Matter with AI Denoising</title>
      <link>https://arxiv.org/abs/2406.04378</link>
      <description>arXiv:2406.04378v1 Announce Type: new 
Abstract: Dark matter makes up approximately 85% of total matter in our universe, yet it has never been directly observed in any laboratory on Earth. The origin of dark matter is one of the most important questions in contemporary physics, and a convincing detection of dark matter would be a Nobel-Prize-level breakthrough in fundamental science. The ABRACADABRA experiment was specifically designed to search for dark matter. Although it has not yet made a discovery, ABRACADABRA has produced several dark matter search results widely endorsed by the physics community. The experiment generates ultra-long time-series data at a rate of 10 million samples per second, where the dark matter signal would manifest itself as a sinusoidal oscillation mode within the ultra-long time series. In this paper, we present the TIDMAD -- a comprehensive data release from the ABRACADABRA experiment including three key components: an ultra-long time series dataset divided into training, validation, and science subsets; a carefully-designed denoising score for direct model benchmarking; and a complete analysis framework which produces a community-standard dark matter search result suitable for publication as a physics paper. This data release enables core AI algorithms to extract the signal and produce real physics results thereby advancing fundamental science. The data downloading and associated analysis scripts are available at https://github.com/jessicafry/TIDMAD</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04378v1</guid>
      <category>astro-ph.IM</category>
      <category>cs.LG</category>
      <category>hep-ex</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>J. T. Fry, Aobo Li, Lindley Winslow, Xinyi Hope Fu, Zhenghao Fu, Kaliroe M. W. Pappas</dc:creator>
    </item>
    <item>
      <title>Streamlining and standardizing software citations with The Software Citation Station</title>
      <link>https://arxiv.org/abs/2406.04405</link>
      <description>arXiv:2406.04405v1 Announce Type: new 
Abstract: Software is crucial for the advancement of astronomy especially in the context of rapidly growing datasets that increasingly require algorithm and pipeline development to process the data and produce results. However, software has not always been consistently cited, despite its importance to strengthen support for software development. To encourage, streamline, and standardize the process of citing software in academic work such as publications we introduce 'The Software Citation Station': a publicly available website and tool to quickly find or add software citations</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04405v1</guid>
      <category>astro-ph.IM</category>
      <category>cs.DL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tom Wagg, Floor S. Broekgaarden</dc:creator>
    </item>
    <item>
      <title>Integration of Data Reduction and Near Real-Time Archiving into the Keck Observing Model</title>
      <link>https://arxiv.org/abs/2406.04510</link>
      <description>arXiv:2406.04510v1 Announce Type: new 
Abstract: The W. M. Keck Observatory is welcoming a new era where data reduction and archiving are tightly integrated into our observing model, under the auspices of the Observatory's Data Services Initiative (DSI) project. While previously the Keck Observatory Archive (KOA) archived minimally processed, raw science data the day after observing, Keck is transitioning to a model in which it archives both raw frames and reduced data in near real-time. These data will be made available to observers and collaborators immediately upon ingestion through a dedicated new interface that will support collaboration and sharing among teams, as well as stream data directly to personal computers without access to WMKO's internal networks. Both the raw and science-ready data products will be made publicly available upon the expiration of data protections.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04510v1</guid>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1117/12.2629551</arxiv:DOI>
      <arxiv:journal_reference>Proc. SPIE 12186, Observatory Operations: Strategies, Processes, and Systems IX, 121860H (25 August 2022)</arxiv:journal_reference>
      <dc:creator>Max Brodheim (W. M. Keck Observatory), John O'Meara (W. M. Keck Observatory), Jeffrey A. Mader (W. M. Keck Observatory), G. Bruce Berriman (Caltech/IPAC-NExScI), Matthew Brown (W. M. Keck Observatory), Lucas Furhman (W. M. Keck Observatory), Tyler Tucker (W. M. Keck Observatory), Christopher R. Gelino (Caltech/IPAC-NExScI), Meca S. Lynn (Caltech/IPAC-NExScI), Melanie A. Swain (Caltech/IPAC-NExScI)</dc:creator>
    </item>
    <item>
      <title>The Active Optics System on the Vera C. Rubin Observatory: Optimal Control of Degeneracy Among the Large Number of Degrees of Freedom</title>
      <link>https://arxiv.org/abs/2406.04656</link>
      <description>arXiv:2406.04656v1 Announce Type: new 
Abstract: The Vera C. Rubin Observatory is a unique facility for survey astronomy that will soon be commissioned and begin operations. Crucial to many of its scientific goals is the achievement of sustained high image quality, limited only by the seeing at the site. This will be maintained through an Active Optics System (AOS) that controls optical element misalignments and corrects mirror figure error to minimize aberrations caused by both thermal and gravitational distortions. However, the large number of adjustment degrees of freedom available on the Rubin Observatory introduces a range of degeneracies, including many that are \textit{noise-induced} due to imperfect measurement of the wavefront errors. We present a structured methodology for identifying these degeneracies through an analysis of image noise level. We also present a novel scaling strategy based on Truncated Singular Value Decomposition (TSVD) that mitigates the degeneracy, and optimally distributes the adjustment over the available degrees of freedom. Our approach ensures the attainment of optimal image quality, while avoiding excursions around the noise-induced subspace of degeneracies, marking a significant improvement over the previous techniques adopted for Rubin, which were based on an Optimal Integral Controller (OIC). This new approach is likely to also yield significant benefits for all telescopes that incorporate large numbers of degrees of freedom of adjustment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04656v1</guid>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guillem Megias Homar, Steven M. Kahn, Joshua M. Meyers, John Franklin Crenshaw, Sandrine J. Thomas</dc:creator>
    </item>
    <item>
      <title>Planar near-field measurements of specular and diffuse reflection of millimeter-wave absorbers</title>
      <link>https://arxiv.org/abs/2406.04664</link>
      <description>arXiv:2406.04664v1 Announce Type: new 
Abstract: Mitigating the far sidelobes of a wide field-of-view telescope is one of the critical issues for polarization observation of the cosmic microwave background. Since even small reflections of stray light at the millimeter-wave absorbers inside the telescope may create nonnegligible far sidelobes, we have developed a method to measure the reflectance of millimeter-wave absorbers, including diffuse reflections. By applying the planar near-field measurement method to the absorbers, we have enabled two-dimensional diffuse-reflection measurements, in addition to characterizing specular reflection. We have measured the reflectance of five samples (TK RAM Large and Small Tiles and Eccosorb AN-72, HR-10, and LS-22) at two angles of incidence in the frequency range from 70 GHz to 110 GHz. Compared with conventional horn-to-horn measurements, we obtained a consistent specular reflectance with a higher precision, less affected by standing waves. We have demonstrated that the angular response and diffuse-to-specular reflectance ratio differ among various materials. The measurements also imply that some absorbers may affect the polarization direction when reflecting the incident waves.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04664v1</guid>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fumiya Miura (Department of Physics and Engineering, Graduate School of Science and Engineering, Yokohama National University, Institute of Space and Astronautical Science), Hayato Takakura (Institute of Space and Astronautical Science), Yutaro Sekimoto (Institute of Space and Astronautical Science), Junji Inatani (Institute of Space and Astronautical Science), Frederick Matsuda (Institute of Space and Astronautical Science), Shugo Oguri (Institute of Space and Astronautical Science), Shogo Nakamura (Department of Physics and Engineering, Graduate School of Science and Engineering, Yokohama National University)</dc:creator>
    </item>
    <item>
      <title>Assessment of Gradient-Based Samplers in Standard Cosmological Likelihoods</title>
      <link>https://arxiv.org/abs/2406.04725</link>
      <description>arXiv:2406.04725v1 Announce Type: new 
Abstract: We assess the usefulness of gradient-based samplers, such as the No-U-Turn Sampler (NUTS), by comparison with traditional Metropolis-Hastings algorithms, in tomographic $3 \times 2$ point analyses. Specifically, we use the DES Year 1 data and a simulated future LSST-like survey as representative examples of these studies, containing a significant number of nuisance parameters (20 and 32, respectively) that affect the performance of rejection-based samplers. To do so, we implement a differentiable forward model using JAX-COSMO (Campagne et al. 2023), and we use it to derive parameter constraints from both datasets using the NUTS algorithm as implemented in {\S}4, and the Metropolis-Hastings algorithm as implemented in Cobaya (Lewis 2013). When quantified in terms of the number of effective number of samples taken per likelihood evaluation, we find a relative efficiency gain of $\mathcal{O}(10)$ in favour of NUTS. However, this efficiency is reduced to a factor $\sim 2$ when quantified in terms of computational time, since we find the cost of the gradient computation (needed by NUTS) relative to the likelihood to be $\sim 4.5$ times larger for both experiments. We validate these results making use of analytical multi-variate distributions (a multivariate Gaussian and a Rosenbrock distribution) with increasing dimensionality. Based on these results, we conclude that gradient-based samplers such as NUTS can be leveraged to sample high dimensional parameter spaces in Cosmology, although the efficiency improvement is relatively mild for moderate $(\mathcal{O}(50))$ dimension numbers, typical of tomographic large-scale structure analyses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04725v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Arrykrishna Mootoovaloo, Jaime Ruiz-Zapatero, Carlos Garc\'ia-Garc\'ia, David Alonso</dc:creator>
    </item>
    <item>
      <title>Pulsar Timing Arrays require hierarchical models</title>
      <link>https://arxiv.org/abs/2406.05081</link>
      <description>arXiv:2406.05081v1 Announce Type: new 
Abstract: Pulsar Timing Array projects have found evidence of a stochastic background of gravitational waves (GWB) using data from an ensemble of pulsars. In the literature, minimal assumptions are made about the signal and noise processes that affect data from these pulsars, such as pulsar spin noise. These assumptions are encoded as uninformative priors in Bayesian searches, though Frequentist approaches make similar assumptions. Uninformative priors are not suitable for (noise) properties of pulsars in an ensemble, and they bias estimates of model parameters such as gravitational-wave signal parameters. Both Frequentist and Bayesian searches are affected. In this letter, more appropriate priors are proposed in the language of Hierarchical Bayesian Modeling, where the properties of the ensemble of pulsars are jointly described with the properties of the individual components of the ensemble. Results by Pulsar Timing Array projects should be re-evaluated using Hierarchical Models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05081v1</guid>
      <category>astro-ph.IM</category>
      <category>gr-qc</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.3847/1538-4365/ad530f</arxiv:DOI>
      <dc:creator>Rutger van Haasteren</dc:creator>
    </item>
    <item>
      <title>Using gravitational wave early warning to pre-point neutron star mergers with Imaging Atmospheric Cherenkov telescopes</title>
      <link>https://arxiv.org/abs/2406.04387</link>
      <description>arXiv:2406.04387v1 Announce Type: cross 
Abstract: The LIGO-Virgo-KAGRA (LVK) collaboration has recently made it possible for early warning alerts to be sent out, potentially before the end of the gravitational wave (GW) emission from a neutron star binary. If we get such alerts in this (the fourth) or the next observing run they may arrive up to tens of seconds before the merger, which is comparable to the slewing times of the Large Size Telescopes (designed to observe very high energy gamma rays): it would be therefore possible to point to the source right before it starts emitting an electromagnetic signal. This new mode of observation would allow us to detect the TeV component of prompt emission, which is currently poorly constrained and understood. There are many technical challenges to overcome before this can be realized: improving the synergy between gravitational observatories and telescopes, reducing operational latencies and, from the gravitational wave side, providing more information, such as real-time updates on early warning candidates and the probability distribution of the inclination angle. Although we may need to wait a few years -- in the worst case scenario, until the next generation of GW detectors is built -- before the first detection of this kind is made, implementing these improvements is a necessity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04387v1</guid>
      <category>astro-ph.HE</category>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jacopo Tissino</dc:creator>
    </item>
    <item>
      <title>Constraining the selection corrected luminosity function and total pulse count for radio transients</title>
      <link>https://arxiv.org/abs/2406.04597</link>
      <description>arXiv:2406.04597v1 Announce Type: cross 
Abstract: Studying transient phenomena, such as individual pulses from pulsars, has garnered considerable attention in the era of astronomical big data. Of specific interest to this study are Rotating Radio Transients (RRATs), nulling, and intermittent pulsars. This study introduces a new algorithm named LuNfit, tailored to correct the selection biases originating from the telescope and detection pipelines. Ultimately LuNfit estimates the intrinsic luminosity distribution and nulling fraction of the single pulses emitted by pulsars. LuNfit relies on Bayesian nested sampling so that the parameter space can be fully explored. Bayesian nested sampling also provides the additional benefit of simplifying model comparisons through the Bayes ratio. The robustness of LuNfit is shown through simulations and applying LuNfit onto pulsars with known nulling fractions. LuNfit is then applied to three RRATs, J0012+5431, J1538+1523, and J2355+1523, extracting their intrinsic luminosity distribution and burst rates. We find that their nulling fraction is 0.4(2), 0.749(5) and 0.995(2) respectively. We further find that a log-normal distribution likely describes the single pulse luminosity distribution of J0012+5431 and J1538+1523, while the Bayes ratio for J2355+1523 slightly favors an exponential distribution. We show the conventional method of correcting selection effects by "scaling up" the missed fraction of radio transients can be unreliable when the mean luminosity of the source is faint relative to the telescope sensitivity. Finally, we discuss the limitations of the current implementation of LuNfit while also delving into potential enhancements that would enable LuNfit to be applied to sources with complex pulse morphologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04597v1</guid>
      <category>astro-ph.HE</category>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.3847/1538-4357/ad53c5</arxiv:DOI>
      <dc:creator>Fengqiu Adam Dong, Antonio Herrera-Martin, Ingrid Stairs, Radu V. Craiu, Kathryn Crowter, Gwendolyn M. Eadie, Emmanuel Fonseca, Deborah Good, James W. Mckee, Bradley W. Meyers, Aaron B. Pearlman, David C. Stenning</dc:creator>
    </item>
    <item>
      <title>Uncertainty-aware and Data-efficient Cosmological Emulation using Gaussian Processes and PCA</title>
      <link>https://arxiv.org/abs/2307.01138</link>
      <description>arXiv:2307.01138v2 Announce Type: replace-cross 
Abstract: Bayesian parameter inference is one of the key elements for model selection in cosmological research. However, the available inference tools require a large number of calls to simulation codes which can lead to high and sometimes even infeasible computational costs. In this work we propose a new way of emulating simulation codes for Bayesian parameter inference. In particular, this novel approach emphasizes the uncertainty-awareness of the emulator, which allows to state the emulation accuracy and ensures reliable performance. With a focus on data efficiency, we implement an active learning algorithm based on a combination of Gaussian Processes and Principal Component Analysis. We find that for an MCMC analysis of Planck and BAO data on the $\Lambda$CDM model (6 model and 21 nuisance parameters) we can reduce the number of simulation calls by a factor of $\sim$500 and save about $96\%$ of the computational costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.01138v2</guid>
      <category>astro-ph.CO</category>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sven G\"unther (RWTH Aachen U.)</dc:creator>
    </item>
    <item>
      <title>Calibrating gravitational-wave search algorithms with conformal prediction</title>
      <link>https://arxiv.org/abs/2402.19313</link>
      <description>arXiv:2402.19313v4 Announce Type: replace-cross 
Abstract: In astronomy, we frequently face the decision problem: does this data contain a signal? Typically, a statistical approach is used, which requires a threshold. The choice of threshold presents a common challenge in settings where signals and noise must be delineated, but their distributions overlap. Gravitational-wave astronomy, which has gone from the first discovery to catalogues of hundreds of events in less than a decade, presents a fascinating case study. For signals from colliding compact objects, the field has evolved from a frequentist to a Bayesian methodology. However, the issue of choosing a threshold and validating noise contamination in a catalogue persists. Confusion and debate often arise due to the misapplication of statistical concepts, the complicated nature of the detection statistics, and the inclusion of astrophysical background models. We introduce Conformal Prediction (CP), a framework developed in Machine Learning to provide distribution-free uncertainty quantification to point predictors. We show that CP can be viewed as an extension of the traditional statistical frameworks whereby thresholds are calibrated such that the uncertainty intervals are statistically rigorous and the error rate can be validated. Moreover, we discuss how CP offers a framework to optimally build a meta-pipeline combining the outputs from multiple independent searches. We introduce CP with a toy cosmic-ray detector, which captures the salient features of most astrophysical search problems and allows us to demonstrate the features of CP in a simple context. We then apply the approach to a recent gravitational-wave Mock Data Challenge using multiple search algorithms for compact binary coalescence signals in interferometric gravitational-wave data. Finally, we conclude with a discussion on the future potential of the method for gravitational-wave astronomy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.19313v4</guid>
      <category>gr-qc</category>
      <category>astro-ph.HE</category>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gregory Ashton, Nicolo Colombo, Ian Harry, Surabhi Sachdev</dc:creator>
    </item>
  </channel>
</rss>
