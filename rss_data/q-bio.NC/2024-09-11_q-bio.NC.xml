<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 11 Sep 2024 10:39:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>The Neuroscientific Basis of Flow: Learning Progress Guides Task Engagement and Cognitive Control</title>
      <link>https://arxiv.org/abs/2409.06592</link>
      <description>arXiv:2409.06592v1 Announce Type: new 
Abstract: People often strive for deep engagement in activities which is usually associated with feelings of flow: a state of full task absorption accompanied by a sense of control and fulfillment. The intrinsic factors driving such engagement and facilitating subjective feelings of flow remain unclear. Building on computational theories of intrinsic motivation, this study examines how learning progress predicts engagement and directs cognitive control. Results showed that task engagement, indicated by feelings of flow and distractibility, is a function of learning progress. Electroencephalography data further revealed that learning progress is associated with enhanced proactive preparation (e.g., reduced pre-stimulus contingent negativity variance and parietal alpha desynchronization) and improved feedback processing (e.g., increased P3b amplitude and parietal alpha desynchronization). The impact of learning progress on cognitive control is observed at the task-block and goal-episode levels, but not at the trial level. This suggests that learning progress shapes cognitive control over extended periods as progress accumulates. These findings highlight the critical role of learning progress in sustaining engagement and cognitive control in goal-directed behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06592v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hairong Lu, Dimitri van der Linden, Arnold B. Bakker</dc:creator>
    </item>
    <item>
      <title>Non-exchangeable networks of integrate-and-fire neurons: spatially-extended mean-field limit of the empirical measure</title>
      <link>https://arxiv.org/abs/2409.06325</link>
      <description>arXiv:2409.06325v1 Announce Type: cross 
Abstract: The dynamics of exchangeable or spatially-structured networks of $N$ interacting stochastic neurons can be described by deterministic population equations in the mean-field limit $N\to\infty$, when synaptic weights scale as $O(1/N)$. This asymptotic behavior has been proven in several works but a general question has remained unanswered: does the $O(1/N)$ scaling of synaptic weights, by itself, suffice to guarantee the convergence of network dynamics to a deterministic population equation, even when networks are not assumed to be exchangeable or spatially structured? In this work, we consider networks of stochastic integrate-and-fire neurons with arbitrary synaptic weights satisfying only a $O(1/N)$ scaling condition. Borrowing results from the theory of dense graph limits (graphons), we prove that, as $N\to\infty$, and up to the extraction of a subsequence, the empirical measure of the neurons' membrane potentials converges to the solution of a spatially-extended mean-field partial differential equation (PDE). Our proof requires analytical techniques that go beyond standard propagation of chaos methods. In particular, we introduce a weak metric that depends on the dense graph limit kernel and we show how the weak convergence of the initial data can be obtained by propagating the regularity of the limit kernel along the dual-backward equation associated with the spatially-extended mean-field PDE. Overall, this result invites us to re-interpret spatially-extended population equations as universal mean-field limits of networks of neurons with $O(1/N)$ synaptic weight scaling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06325v1</guid>
      <category>math.PR</category>
      <category>math.AP</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Pierre-Emmanuel Jabin, Valentin Schmutz, Datong Zhou</dc:creator>
    </item>
    <item>
      <title>The time is ripe to reverse engineer an entire nervous system: simulating behavior from neural interactions</title>
      <link>https://arxiv.org/abs/2308.06578</link>
      <description>arXiv:2308.06578v4 Announce Type: replace 
Abstract: Just like electrical engineers understand how microprocessors execute programs in terms of how transistor currents are affected by their inputs, neuroscientists want to understand behavior production in terms of how neuronal outputs are affected by their inputs and internal states. This dependency of neuronal outputs on inputs can be described by a state-dependent input-output (IO)-function. However, to reliably identify these IO-functions, we need to perturb each input and combination of inputs while observing all the outputs. Here, we argue that such completeness is possible in C. elegans; a complete description that goes all the way from the activity of every neuron to predict behavior. The established and growing toolkit of optophysiology can non-invasively capture and control every neuron's activity and scale to countless experiments. The information from many such experiments can be pooled while capturing the inter-individual variability because neuronal identity and function are largely conserved across individuals. Just like electrical engineers use transistor IO-functions to simulate program execution, we argue that neuronal IO-functions could be used to simulate the impressive breadth of brain states and behaviors of C. elegans.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.06578v4</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Gal Haspel (NJIT), Ben Baker (Colby College), Isabel Beets (KU Leuven), Edward S Boyden (MIT), Jeffrey Brown (MIT), George Church (Harvard University), Netta Cohen (University of Leeds), Daniel Colon-Ramos (Yale University), Eva Dyer (Georgia Institute of Technology), Christopher Fang-Yen (Ohio State University), Steven Flavell (MIT), Miriam B Goodman (Stanford University), Anne C Hart (Brown University), Eduardo J Izquierdo (Rose-Hulman Institute of Technology), Konstantinos Kagias (MIT), Shawn Lockery (University of Oregon), Yangning Lu (MIT), Adam Marblestone (Convergent Research), Jordan Matelsky (University of Pennsylvania), Brett Mensh (Optimize Science), Talmo D Pereira (Salk Institute), Hanspeter Pfister (Harvard University), Kanaka Rajan (Harvard Medical School), Horacio G Rotstein (NJIT), Monika Scholz (Max Planck Institute for Neurobiology of Behavior), Joshua W. Shaevitz (Princeton University), Eli Shlizerman (University of Washington), Quilee Simeon (MIT), Michael A Skuhersky (MIT), Vineet Tiruvadi (Hume AI), Vivek Venkatachalam (Northeastern University), Donglai Wei (Boston College), Brock Wester (Johns Hopkins APL), Guangyu Robert Yang (MIT), Eviatar Yemini (UMass), Manuel Zimmer (University of Vienna), Konrad P Kording (University of Pennsylvania)</dc:creator>
    </item>
    <item>
      <title>One-shot learning of paired association navigation with biologically plausible schemas</title>
      <link>https://arxiv.org/abs/2106.03580</link>
      <description>arXiv:2106.03580v4 Announce Type: replace-cross 
Abstract: Schemas are knowledge structures that can enable rapid learning. Rodent one-shot learning in a multiple paired association navigation task has been postulated to be schema-dependent. We still only poorly understand how schemas, conceptualized at Marr's computational level, are neurally implemented. Moreover, a biologically plausible computational model of the rodent learning has not been demonstrated. Accordingly, we here compose an agent from schemas with biologically plausible neural implementations. The agent gradually learns a metric representation of its environment using a path integration temporal difference error, allowing it to localize in any environment. Additionally, the agent contains an associative memory that can stably form numerous one-shot associations between sensory cues and goal coordinates, implemented with a feedforward layer or a reservoir of recurrently connected neurons whose plastic output weights are governed by a 4-factor reward-modulated Exploratory Hebbian (EH) rule. A third network performs vector subtraction between the agent's current and goal location to decide the direction of movement. We further show that schemas supplemented by an actor-critic allows the agent to succeed even if an obstacle prevents direct heading, and that temporal-difference learning of a working memory gating mechanism enables one-shot learning despite distractors. Our agent recapitulates learning behavior observed in experiments and provides testable predictions that can be probed in future experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2106.03580v4</guid>
      <category>cs.NE</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M Ganesh Kumar, Cheston Tan, Camilo Libedinsky, Shih-Cheng Yen, Andrew Yong-Yi Tan</dc:creator>
    </item>
    <item>
      <title>Multi-intention Inverse Q-learning for Interpretable Behavior Representation</title>
      <link>https://arxiv.org/abs/2311.13870</link>
      <description>arXiv:2311.13870v4 Announce Type: replace-cross 
Abstract: In advancing the understanding of natural decision-making processes, inverse reinforcement learning (IRL) methods have proven instrumental in reconstructing animal's intentions underlying complex behaviors. Given the recent development of a continuous-time multi-intention IRL framework, there has been persistent inquiry into inferring discrete time-varying rewards with IRL. To address this challenge, we introduce the class of hierarchical inverse Q-learning (HIQL) algorithms. Through an unsupervised learning process, HIQL divides expert trajectories into multiple intention segments, and solves the IRL problem independently for each. Applying HIQL to simulated experiments and several real animal behavior datasets, our approach outperforms current benchmarks in behavior prediction and produces interpretable reward functions. Our results suggest that the intention transition dynamics underlying complex decision-making behavior is better modeled by a step function instead of a smoothly varying function. This advancement holds promise for neuroscience and cognitive science, contributing to a deeper understanding of decision-making and uncovering underlying brain mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.13870v4</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Zhu, Brice De La Crompe, Gabriel Kalweit, Artur Schneider, Maria Kalweit, Ilka Diester, Joschka Boedecker</dc:creator>
    </item>
    <item>
      <title>Disentangling Hippocampal Shape Variations: A Study of Neurological Disorders Using Mesh Variational Autoencoder with Contrastive Learning</title>
      <link>https://arxiv.org/abs/2404.00785</link>
      <description>arXiv:2404.00785v2 Announce Type: replace-cross 
Abstract: This paper presents a comprehensive study focused on disentangling hippocampal shape variations from diffusion tensor imaging (DTI) datasets within the context of neurological disorders. Leveraging a Graph Variational Autoencoder (VAE) enhanced with Supervised Contrastive Learning, our approach aims to improve interpretability by disentangling two distinct latent variables corresponding to age and the presence of diseases. In our ablation study, we investigate a range of VAE architectures and contrastive loss functions, showcasing the enhanced disentanglement capabilities of our approach. This evaluation uses synthetic 3D torus mesh data and real 3D hippocampal mesh datasets derived from the DTI hippocampal dataset. Our supervised disentanglement model outperforms several state-of-the-art (SOTA) methods like attribute and guided VAEs in terms of disentanglement scores. Our model distinguishes between age groups and disease status in patients with Multiple Sclerosis (MS) using the hippocampus data. Our Graph VAE with Supervised Contrastive Learning shows the volume changes of the hippocampus of MS populations at different ages, and the result is consistent with the current neuroimaging literature. This research provides valuable insights into the relationship between neurological disorder and hippocampal shape changes in different age groups of MS populations using a Graph VAE with Supervised Contrastive loss.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00785v2</guid>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jakaria Rabbi, Johannes Kiechle, Christian Beaulieu, Nilanjan Ray, Dana Cobzas</dc:creator>
    </item>
  </channel>
</rss>
