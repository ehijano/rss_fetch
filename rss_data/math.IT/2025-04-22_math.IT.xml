<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.IT</link>
    <description>math.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 22 Apr 2025 09:36:44 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>On the Capacity of Insertion Channels for Small Insertion Probabilities</title>
      <link>https://arxiv.org/abs/2504.14035</link>
      <description>arXiv:2504.14035v1 Announce Type: new 
Abstract: Channels with synchronization errors, such as deletion and insertion errors, are crucial in DNA storage, data reconstruction, and other applications. These errors introduce memory to the channel, complicating its capacity analysis. This paper analyzes binary insertion channels for small insertion probabilities, identifying dominant terms in the capacity expansion and establishing capacity in this regime. Using Bernoulli(1/2) inputs for achievability and a converse based on the use of stationary and ergodic processes, we demonstrate that capacity closely aligns with achievable rates using independent and identically distributed (i.i.d.) inputs, differing only in higher-order terms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14035v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Busra Tegin, Tolga M Duman</dc:creator>
    </item>
    <item>
      <title>Transport alpha divergences</title>
      <link>https://arxiv.org/abs/2504.14084</link>
      <description>arXiv:2504.14084v1 Announce Type: new 
Abstract: We derive a class of divergences measuring the difference between probability density functions on a one-dimensional sample space. This divergence is a one-parameter variation of the Ito-Sauda divergence between quantile density functions. We prove that the proposed divergence is one-parameter variation of transport Kullback-Leibler divergence and Hessian distance of negative Boltzmann entropy with respect to Wasserstein-2 metric. From Taylor expansions, we also formulate the 3-symmetric tensor in Wasserstein space, which is given by an iterative Gamma three operators. The alpha-geodesic on Wasserstein space is also derived. From these properties, we name the proposed information measures transport alpha divergences. We provide several examples of transport alpha divergences for generative models in machine learning applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14084v1</guid>
      <category>cs.IT</category>
      <category>math-ph</category>
      <category>math.IT</category>
      <category>math.MP</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wuchen Li</dc:creator>
    </item>
    <item>
      <title>Channels with Input-Correlated Synchronization Errors</title>
      <link>https://arxiv.org/abs/2504.14087</link>
      <description>arXiv:2504.14087v1 Announce Type: new 
Abstract: "Independent and identically distributed" errors do not accurately capture the noisy behavior of real-world data storage and information transmission technologies. Motivated by this, we study channels with input-correlated synchronization errors, meaning that the distribution of synchronization errors (such as deletions and insertions) applied to the $i$-th input $x_i$ may depend on the whole input string $x$.
  We begin by identifying conditions on the input-correlated synchronization channel under which the channel's information capacity is achieved by a stationary ergodic input source and is equal to its coding capacity. These conditions capture a wide class of channels, including channels with correlated errors observed in DNA-based data storage systems and their multi-trace versions, and generalize prior work. To showcase the usefulness of the general capacity theorem above, we combine it with techniques of Pernice-Li-Wootters (ISIT 2022) and Brakensiek-Li-Spang (FOCS 2020) to obtain explicit capacity-achieving codes for multi-trace channels with runlength-dependent deletions, motivated by error patterns observed in DNA-based data storage systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14087v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roni Con, Jo\~ao Ribeiro</dc:creator>
    </item>
    <item>
      <title>Sparse Superposition Codes with Binomial Dictionary are Capacity-Achieving with Maximum Likelihood Decoding</title>
      <link>https://arxiv.org/abs/2504.14262</link>
      <description>arXiv:2504.14262v1 Announce Type: new 
Abstract: It is known that sparse superposition codes asymptotically achieve the channel capacity over the additive white Gaussian noise channel with both maximum likelihood decoding and efficient decoding (Joseph and Barron in 2012, 2014). Takeishi et al. (in 2014, 2019) demonstrated that these codes can also asymptotically achieve the channel capacity with maximum likelihood decoding when the dictionary is drawn from a Bernoulli distribution. In this paper, we extend these results by showing that the dictionary distribution can be naturally generalized to the binomial distribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14262v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yoshinari Takeishi, Jun'ichi Takeuchi</dc:creator>
    </item>
    <item>
      <title>DLW-CI: A Dynamic Likelihood-Weighted Cooperative Infotaxis Approach for Multi-Source Search in Urban Environments Using Consumer Drone Networks</title>
      <link>https://arxiv.org/abs/2504.14330</link>
      <description>arXiv:2504.14330v1 Announce Type: new 
Abstract: Consumer-grade drones equipped with low-cost sensors have emerged as a cornerstone of Autonomous Intelligent Systems (AISs) for environmental monitoring and hazardous substance detection in urban environments. However, existing research primarily addresses single-source search problems, overlooking the complexities of real-world urban scenarios where both the location and quantity of hazardous sources remain unknown. To address this issue, we propose the Dynamic Likelihood-Weighted Cooperative Infotaxis (DLW-CI) approach for consumer drone networks. Our approach enhances multi-drone collaboration in AISs by combining infotaxis (a cognitive search strategy) with optimized source term estimation and an innovative cooperative mechanism. Specifically, we introduce a novel source term estimation method that utilizes multiple parallel particle filters, with each filter dedicated to estimating the parameters of a potentially unknown source within the search scene. Furthermore, we develop a cooperative mechanism based on dynamic likelihood weights to prevent multiple drones from simultaneously estimating and searching for the same source, thus optimizing the energy efficiency and search coverage of the consumer AIS. Experimental results demonstrate that the DLW-CI approach significantly outperforms baseline methods regarding success rate, accuracy, and root mean square error, particularly in scenarios with relatively few sources, regardless of the presence of obstacles. Also, the effectiveness of the proposed approach is verified in a diffusion scenario generated by the computational fluid dynamics (CFD) model. Research findings indicate that our approach could improve source estimation accuracy and search efficiency by consumer drone-based AISs, making a valuable contribution to environmental safety monitoring applications within smart city infrastructure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14330v1</guid>
      <category>cs.IT</category>
      <category>cs.RO</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaoran Zhang, Yatai Ji, Yong Zhao, Chuan Ai, Bin Chen, Zhengqiu Zhu</dc:creator>
    </item>
    <item>
      <title>Algebraic Barriers to Halving Algorithmic Information Quantities in Correlated Strings</title>
      <link>https://arxiv.org/abs/2504.14408</link>
      <description>arXiv:2504.14408v1 Announce Type: new 
Abstract: We study the possibility of scaling down algorithmic information quantities in tuples of correlated strings. In particular, we address a question raised by Alexander Shen: whether, for any triple of strings \((a, b, c)\), there exists a string \(z\) such that each of the values of conditional Kolmogorov complexity \(C(a|z), C(b|z), C(c|z)\) is approximately half of the corresponding unconditional Kolmogorov complexity. We provide a negative answer to this question by constructing a triple \((a, b, c)\) for which no such string \(z\) exists. Our construction is based on combinatorial properties of incidences in finite projective planes and relies on recent bounds on point-line incidences over prime fields. As an application, we show that this impossibility implies lower bounds on the communication complexity of secret key agreement protocols in certain settings. These results reveal algebraic obstructions to efficient information exchange and highlight a separation in the information-theoretic behavior of projective planes over fields with and without proper subfields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14408v1</guid>
      <category>cs.IT</category>
      <category>cs.DM</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrei Romashchenko</dc:creator>
    </item>
    <item>
      <title>On the Redundancy of Function-Correcting Codes over Finite Fields</title>
      <link>https://arxiv.org/abs/2504.14410</link>
      <description>arXiv:2504.14410v1 Announce Type: new 
Abstract: Function-correcting codes (FCCs) are a class of codes introduced by Lenz et al. (2023) that protect specific function evaluations of a message against errors, imposing a less stringent distance requirement than classical error-correcting codes (ECCs) and thereby allowing for reduced redundancy. For FCCs over binary field, a lower bound on the optimal redundancy for function correction was established by Lenz et al., and we derive an upper bound that remains within a logarithmic factor of this lower bound. We extend this result by proving that the same lower bound holds for any q-ary finite field. Furthermore, we show that for sufficiently large fields, this bound is tight by proving it also serves as an upper bound. In addition, we construct an encoding scheme that achieves this optimal redundancy. Finally, motivated by these two extremal regimes, we conjecture that our bound continues to serve as a valid upper bound across all finite fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14410v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hoang Ly, Emina Soljanin</dc:creator>
    </item>
    <item>
      <title>Joint Channel Estimation and Signal Detection for MIMO-OFDM: A Novel Data-Aided Approach with Reduced Computational Overhead</title>
      <link>https://arxiv.org/abs/2504.14463</link>
      <description>arXiv:2504.14463v1 Announce Type: new 
Abstract: The acquisition of channel state information (CSI) is essential in MIMO-OFDM communication systems. Data-aided enhanced receivers, by incorporating domain knowledge, effectively mitigate performance degradation caused by imperfect CSI, particularly in dynamic wireless environments. However, existing methodologies face notable challenges: they either refine channel estimates within MIMO subsystems separately, which proves ineffective due to deviations from assumptions regarding the time-varying nature of channels, or fully exploit the time-frequency characteristics but incur significantly high computational overhead due to dimensional concatenation. To address these issues, this study introduces a novel data-aided method aimed at reducing complexity, particularly suited for fast-fading scenarios in fifth-generation (5G) and beyond networks. We derive a general form of a data-aided linear minimum mean-square error (LMMSE)-based algorithm, optimized for iterative joint channel estimation and signal detection. Additionally, we propose a computationally efficient alternative to this algorithm, which achieves comparable performance with significantly reduced complexity. Empirical evaluations reveal that our proposed algorithms outperform several state-of-the-art approaches across various MIMO-OFDM configurations, pilot sequence lengths, and in the presence of time variability. Comparative analysis with basis expansion model-based iterative receivers highlights the superiority of our algorithms in achieving an effective trade-off between accuracy and computational complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14463v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinjie Li, Jing Zhang, Xingyu Zhou, Chao-Kai Wen, Shi Jin</dc:creator>
    </item>
    <item>
      <title>Generalized Derangetropy Functionals for Modeling Cyclical Information Flow</title>
      <link>https://arxiv.org/abs/2504.14605</link>
      <description>arXiv:2504.14605v1 Announce Type: new 
Abstract: This paper introduces a framework for modeling cyclical and feedback-driven information flow through a generalized family of entropy-modulated transformations called derangetropy functionals. Unlike scalar and static entropy measures such as Shannon entropy, these functionals act directly on probability densities and provide a topographical representation of information structure across the support of the distribution. The framework captures periodic and self-referential aspects of information distribution and encodes them through functional operators governed by nonlinear differential equations. When applied recursively, these operators induce a spectral diffusion process governed by the heat equation, leading to convergence toward a Gaussian characteristic function. This convergence theorem provides a unified analytical foundation for describing the long-term dynamics of information under cyclic modulation. The proposed framework offers new tools for analyzing the temporal evolution of information in systems characterized by periodic structure, stochastic feedback, and delayed interaction, with applications in artificial neural networks, communication theory, and non-equilibrium statistical mechanics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14605v1</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Masoud Ataei, Xiaogang Wang</dc:creator>
    </item>
    <item>
      <title>Semantic HARQ for Intelligent Transportation Systems: Joint Source-Channel Coding-Powered Reliable Retransmissions</title>
      <link>https://arxiv.org/abs/2504.14615</link>
      <description>arXiv:2504.14615v1 Announce Type: new 
Abstract: The surge of data traffic in Intelligent Transportation Systems (ITS) places a significant challenge on limited wireless resources. Semantic communication, which transmits essential semantics of the raw data, offers a promising solution by reducing redundancy and improving spectrum efficiency. However, high vehicle mobility, dynamic channel conditions, and dense vehicular networks severely impact transmission reliability in ITS. To address these limitations, we integrate Hybrid Automatic Repeat reQuest (HARQ) with Joint Source-Channel Coding (JSCC) to provide reliable semantic communications for ITS. To counteract the adverse effects of time-varying fading channels and noise, we propose a generative signal reconstructor module supported by a local knowledge base, which employs a discriminator for channel error detection and a conditional generative network for error correction. We propose three innovative semantic HARQ (sem-HARQ) schemes, Type I sem-HARQ (sem-HARQ-I), sem-HARQ with weighted combining (sem-HARQ-WC), and sem-HARQ with synonymous combining (sem-HARQ-SC) to enable reliable JSCC-based semantic communications. At the transmitter, both sem-HARQ-I and sem-HARQ-WC retransmit the same semantic signals, while sem-HARQ-SC introduces redundant semantics across different HARQ rounds through synonymous mapping. At the receiver, sem-HARQ-I performs semantic decoding based solely on the currently received signal. In contrast, sem-HARQ-WC enhances reliability by fusing the current received semantic signal with prior erroneous signals at the feature or decision level, thereby exploiting semantic information from failed HARQ rounds. Similarly, sem-HARQ-SC employs feature-level combining, leveraging incremental semantic redundancy to merge semantic features from retransmissions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14615v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yongkang Li, Xu Wang, Zheng Shi, Yaru Fu</dc:creator>
    </item>
    <item>
      <title>Wireless Large AI Model: Shaping the AI-Native Future of 6G and Beyond</title>
      <link>https://arxiv.org/abs/2504.14653</link>
      <description>arXiv:2504.14653v1 Announce Type: new 
Abstract: The emergence of sixth-generation and beyond communication systems is expected to fundamentally transform digital experiences through introducing unparalleled levels of intelligence, efficiency, and connectivity. A promising technology poised to enable this revolutionary vision is the wireless large AI model (WLAM), characterized by its exceptional capabilities in data processing, inference, and decision-making. In light of these remarkable capabilities, this paper provides a comprehensive survey of WLAM, elucidating its fundamental principles, diverse applications, critical challenges, and future research opportunities. We begin by introducing the background of WLAM and analyzing the key synergies with wireless networks, emphasizing the mutual benefits. Subsequently, we explore the foundational characteristics of WLAM, delving into their unique relevance in wireless environments. Then, the role of WLAM in optimizing wireless communication systems across various use cases and the reciprocal benefits are systematically investigated. Furthermore, we discuss the integration of WLAM with emerging technologies, highlighting their potential to enable transformative capabilities and breakthroughs in wireless communication. Finally, we thoroughly examine the high-level challenges hindering the practical implementation of WLAM and discuss pivotal future research directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14653v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fenghao Zhu, Xinquan Wang, Xinyi Li, Maojun Zhang, Yixuan Chen, Chongwen Huang, Zhaohui Yang, Xiaoming Chen, Zhaoyang Zhang, Richeng Jin, Yongming Huang, Wei Feng, Tingting Yang, Baoming Bai, Feifei Gao, Kun Yang, Yuanwen Liu, Sami Muhaidat, Chau Yuen, Kaibin Huang, Kai-Kit Wong, Dusit Niyato, M\'erouane Debbah</dc:creator>
    </item>
    <item>
      <title>Binary cyclic codes from permutation polynomials over $\mathbb{F}_{2^m}$</title>
      <link>https://arxiv.org/abs/2504.14674</link>
      <description>arXiv:2504.14674v1 Announce Type: new 
Abstract: Binary cyclic codes having large dimensions and minimum distances close to the square-root bound are highly valuable in applications where high-rate transmission and robust error correction are both essential. They provide an optimal trade-off between these two factors, making them suitable for demanding communication and storage systems, post-quantum cryptography, radar and sonar systems, wireless sensor networks, and space communications. This paper aims to investigate cyclic codes by an efficient approach introduced by Ding \cite{SETA5} from several known classes of permutation monomials and trinomials over $\mathbb{F}_{2^m}$. We present several infinite families of binary cyclic codes of length $2^m-1$ with dimensions larger than $(2^m-1)/2$. By applying the Hartmann-Tzeng bound, some of the lower bounds on the minimum distances of these cyclic codes are relatively close to the square root bound. Moreover, we obtain a new infinite family of optimal binary cyclic codes with parameters $[2^m-1,2^m-2-3m,8]$, where $m\geq 5$ is odd, according to the sphere-packing bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14674v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mrinal Kanti Bose, Udaya Parampalli, Abhay Kumar Singh</dc:creator>
    </item>
    <item>
      <title>Reveal-or-Obscure: A Differentially Private Sampling Algorithm for Discrete Distributions</title>
      <link>https://arxiv.org/abs/2504.14696</link>
      <description>arXiv:2504.14696v1 Announce Type: new 
Abstract: We introduce a differentially private (DP) algorithm called reveal-or-obscure (ROO) to generate a single representative sample from a dataset of $n$ observations drawn i.i.d. from an unknown discrete distribution $P$. Unlike methods that add explicit noise to the estimated empirical distribution, ROO achieves $\epsilon$-differential privacy by randomly choosing whether to "reveal" or "obscure" the empirical distribution. While ROO is structurally identical to Algorithm 1 proposed by Cheu and Nayak (arXiv:2412.10512), we prove a strictly better bound on the sampling complexity than that established in Theorem 12 of (arXiv:2412.10512). To further improve the privacy-utility trade-off, we propose a novel generalized sampling algorithm called Data-Specific ROO (DS-ROO), where the probability of obscuring the empirical distribution of the dataset is chosen adaptively. We prove that DS-ROO satisfies $\epsilon$-DP, and provide empirical evidence that DS-ROO can achieve better utility under the same privacy budget of vanilla ROO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14696v1</guid>
      <category>cs.IT</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Naima Tasnim, Atefeh Gilani, Lalitha Sankar, Oliver Kosut</dc:creator>
    </item>
    <item>
      <title>Optimal Additive Noise Mechanisms for Differential Privacy</title>
      <link>https://arxiv.org/abs/2504.14730</link>
      <description>arXiv:2504.14730v1 Announce Type: new 
Abstract: We propose a unified optimization framework for designing continuous and discrete noise distributions that ensure differential privacy (DP) by minimizing R\'enyi DP, a variant of DP, under a cost constraint. R\'enyi DP has the advantage that by considering different values of the R\'enyi parameter $\alpha$, we can tailor our optimization for any number of compositions. To solve the optimization problem, we reduce it to a finite-dimensional convex formulation and perform preconditioned gradient descent. The resulting noise distributions are then compared to their Gaussian and Laplace counterparts. Numerical results demonstrate that our optimized distributions are consistently better, with significant improvements in $(\varepsilon, \delta)$-DP guarantees in the moderate composition regimes, compared to Gaussian and Laplace distributions with the same variance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14730v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Atefeh Gilani, Juan Felipe Gomez, Shahab Asoodeh, Flavio P. Calmon, Oliver Kosut, Lalitha Sankar</dc:creator>
    </item>
    <item>
      <title>Optimal Linear MAP Decoding of Convolutional Codes</title>
      <link>https://arxiv.org/abs/2504.14778</link>
      <description>arXiv:2504.14778v1 Announce Type: new 
Abstract: In this paper, we propose a linear representation of BCJR maximum a posteriori probability (MAP) decoding of a rate 1/2 convolutional code (CC), referred to as the linear MAP decoding (LMAP). We discover that the MAP forward and backward decoding can be implemented by the corresponding dual soft input and soft output (SISO) encoders using shift registers. The bidrectional MAP decoding output can be obtained by combining the contents of respective forward and backward dual encoders. Represented using simple shift-registers, LMAP decoder maps naturally to hardware registers and thus can be easily implemented. Simulation results demonstrate that the LMAP decoding achieves the same performance as the BCJR MAP decoding, but has a significantly reduced decoding delay. For the block length 64, the CC of the memory length 14 with LMAP decoding surpasses the random coding union (RCU) bound by approximately 0.5 dB at a BLER of $10^{-3}$, and closely approaches both the normal approximation (NA) and meta-converse (MC) bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14778v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yonghui Li, Chentao Yue, Branka Vucetic</dc:creator>
    </item>
    <item>
      <title>A Short Proof of Coding Theorems for Reed-Muller Codes</title>
      <link>https://arxiv.org/abs/2504.14842</link>
      <description>arXiv:2504.14842v1 Announce Type: new 
Abstract: In this paper, we present a short proof that ReedMuller (RM) codes are entropy-achieving as source coding for Bernoulli sources and capacity-achieving as channel coding for binary memoryless symmetric (BMS) channels, also known as memoryless binary-input output-symmetric (BIOS) channels, in terms of bit error rate (BER) under maximum-likelihood (ML) decoding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14842v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiao Ma</dc:creator>
    </item>
    <item>
      <title>Sum-Rate Maximization for NOMA-Assisted Pinching-Antenna Systems</title>
      <link>https://arxiv.org/abs/2504.15006</link>
      <description>arXiv:2504.15006v1 Announce Type: new 
Abstract: In this letter, we investigate a non-orthogonal multiple access (NOMA) assisted downlink pinching-antenna system. Leveraging the ability of pinching antennas to flexibly adjust users' wireless channel conditions, we formulate an optimization problem to maximize the sum rate by optimizing both the users' power allocation coefficients and the positions of pinching antennas. The optimal power allocation coefficients are obtained in closed-form by using the Karush-Kuhn-Tucker (KKT) conditions. The optimization problem of pinching antenna placements is more challenging than the power allocation problem, and is solved by a bisection-based search algorithm. In particular, the algorithm first optimizes the antenna placements to create favorable channel disparities between users, followed by fine-tuning the antenna positions to ensure the phase alignment for users, thus maximizing the sum rate. Simulation results demonstrate that, compared to conventional-antenna systems, pinching antennas can significantly enhance the sum rate in NOMA scenarios, and the proposed bisection-based search algorithm can achieve a sum rate nearly equivalent to that of an exhaustive search.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15006v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziwu Zhou, Zheng Yang, Gaojie Chen,  Zhiguo,  Ding</dc:creator>
    </item>
    <item>
      <title>Energy-Efficient Irregular RIS-aided UAV-Assisted Optimization: A Deep Reinforcement Learning Approach</title>
      <link>https://arxiv.org/abs/2504.15031</link>
      <description>arXiv:2504.15031v1 Announce Type: new 
Abstract: Reconfigurable intelligent surfaces (RISs) enhance unmanned aerial vehicles (UAV)-assisted communication by extending coverage, improving efficiency, and enabling adaptive beamforming. This paper investigates a multiple-input single-output system where a base station (BS) communicates with multiple single-antenna users through a UAV-assisted RIS, dynamically adapting to user mobility to maintain seamless connectivity. To extend UAV-RIS operational time, we propose a hybrid energy-harvesting resource allocation (HERA) strategy that leverages the irregular RIS ON/OFF capability while adapting to BS-RIS and RIS-user channels. The HERA strategy dynamically allocates resources by integrating non-linear radio frequency energy harvesting (EH) based on the time-switching (TS) approach and renewable energy as a complementary source. A non-convex mixed-integer nonlinear programming problem is formulated to maximize EH efficiency while satisfying quality-of-service, power, and energy constraints under channel state information and hardware impairments. The optimization jointly considers BS transmit power, RIS phase shifts, TS factor, and RIS element selection as decision variables. To solve this problem, we introduce the energy-efficient deep deterministic policy gradient (EE-DDPG) algorithm. This deep reinforcement learning (DRL)-based approach integrates action clipping and softmax-weighted Q-value estimation to mitigate estimation errors. Simulation results demonstrate that the proposed HERA method significantly improves EH efficiency, reaching up to 81.5\% and 73.2\% in single-user and multi-user scenarios, respectively, contributing to extended UAV operational time. Additionally, the proposed EE-DDPG model outperforms existing DRL algorithms while maintaining practical computational complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15031v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mahmoud M. Salim, Khaled M. Rabie, Ali H. Muqaibel</dc:creator>
    </item>
    <item>
      <title>Energy-Efficient UAV-Mounted RIS for IoT: A Hybrid Energy Harvesting and DRL Approach</title>
      <link>https://arxiv.org/abs/2504.15043</link>
      <description>arXiv:2504.15043v1 Announce Type: new 
Abstract: Many future Internet of Things (IoT) applications are expected to rely heavily on reconfigurable intelligent surface (RIS)-aided unmanned aerial vehicles (UAVs). However, the endurance of such systems is constrained by the limited onboard energy, where frequent recharging or battery replacements are required. This consequently disrupts continuous operation and may be impractical in disaster scenarios. To address this challenge, we explore a dual energy harvesting (EH) framework that integrates time-switching (TS), power-splitting (PS), and element-splitting (ES) EH protocols for radio frequency energy, along with solar energy as a renewable source. First, we present the proposed system architecture and EH operating protocols, introducing the proposed hybrid ES-TS-PS EH strategy to extend UAV-mounted RIS endurance. Next, we outline key application scenarios and the associated design challenges. After that, a deep reinforcement learning-based framework is introduced to maximize the EH efficiency by jointly optimizing UAV trajectory, RIS phase shifts, and EH strategies. The framework considers dual EH, hardware impairments, and channel state information imperfections to reflect real-world deployment conditions. The optimization problem is formulated as a Markov decision process and solved using an enhanced deep deterministic policy gradient algorithm, incorporating clipped double Q-learning and softmax-based Q-value estimation for improved stability and efficiency. The results demonstrate significant performance gains compared to the considered baseline approaches. Finally, possible challenges and open research directions are presented, highlighting the transformative potential of energy-efficient UAV-mounted RIS networks for IoT systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15043v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mahmoud M. Salim, Khaled M. Rabie, Ali H. Muqaibel</dc:creator>
    </item>
    <item>
      <title>Soft-Output from Covered Space Decoding of Product Codes</title>
      <link>https://arxiv.org/abs/2504.15204</link>
      <description>arXiv:2504.15204v1 Announce Type: new 
Abstract: In this work, we propose a new soft-in soft-out decoder called soft-output from covered space (SOCS) decoder. It estimates the a posteriori reliability based on the space explored by a list decoder, i.e., the set of vectors for which the list decoder knows whether they are codewords. This approach enables a more accurate calculation of the a posteriori reliability and results in gains of up to 0.25$\,$dB for turbo product decoding with SOCS decoding compared to Chase-Pyndiah decoding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15204v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tim Janz, Simon Oberm\"uller, Andreas Zunker, Stephan ten Brink</dc:creator>
    </item>
    <item>
      <title>Linear Complementary Pairs of Quasi-Cyclic and Quasi-Twisted Codes</title>
      <link>https://arxiv.org/abs/2504.15231</link>
      <description>arXiv:2504.15231v1 Announce Type: new 
Abstract: In this paper, we provide a polynomial characterization of linear complementary pairs of quasi-cyclic and quasi-twisted codes of index 2. We also give several examples of linear complementary pairs of quasi-cyclic and quasi-twisted codes with (almost) optimal security parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15231v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kanat Abdukhalikov, Duy Ho, San Ling, Gyanendra K. Verma</dc:creator>
    </item>
    <item>
      <title>Publicly Verifiable Secret Sharing: Generic Constructions and Lattice-Based Instantiations in the Standard Model</title>
      <link>https://arxiv.org/abs/2504.14381</link>
      <description>arXiv:2504.14381v1 Announce Type: cross 
Abstract: Publicly verifiable secret sharing (PVSS) allows a dealer to share a secret among a set of shareholders so that the secret can be reconstructed later from any set of qualified participants. In addition, any public verifier should be able to check the correctness of the sharing and reconstruction process. PVSS has been demonstrated to yield various applications, such as e-voting, distributed key generation, decentralized random number generation protocols, and multi-party computation. Although many concrete PVSS protocols have been proposed, their security is either proven in the random oracle model or relies on quantum-vulnerable assumptions such as factoring or discrete logarithm. In this work, we put forward a generic construction for PVSS that can be instantiated in the standard model under the Learning With Errors (LWE) assumption. Our instantiation provides the first post-quantum PVSS in the standard model, with a reasonable level of asymptotic efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14381v1</guid>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.NT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pham Nhat Minh, Khoa Nguyen, Willy Susilo, Khuong Nguyen-An</dc:creator>
    </item>
    <item>
      <title>Markovian Continuity of the MMSE</title>
      <link>https://arxiv.org/abs/2504.14659</link>
      <description>arXiv:2504.14659v1 Announce Type: cross 
Abstract: Minimum mean square error (MMSE) estimation is widely used in signal processing and related fields. While it is known to be non-continuous with respect to all standard notions of stochastic convergence, it remains robust in practical applications. In this work, we review the known counterexamples to the continuity of the MMSE. We observe that, in these counterexamples, the discontinuity arises from an element in the converging measurement sequence providing more information about the estimand than the limit of the measurement sequence. We argue that this behavior is uncharacteristic of real-world applications and introduce a new stochastic convergence notion, termed Markovian convergence, to address this issue. We prove that the MMSE is, in fact, continuous under this new notion. We supplement this result with semi-continuity and continuity guarantees of the MMSE in other settings and prove the continuity of the MMSE under linear estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14659v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Elad Domanovitz, Anatoly Khina</dc:creator>
    </item>
    <item>
      <title>Additive energy, uncertainty principle and signal recovery mechanisms</title>
      <link>https://arxiv.org/abs/2504.14702</link>
      <description>arXiv:2504.14702v1 Announce Type: cross 
Abstract: Given a signal $f:G\to\mathbb{C}$, where $G$ is a finite abelian group, under what reasonable assumptions can we guarantee the exact recovery of $f$ from a proper subset of its Fourier coefficients? In 1989, Donoho and Stark established a result \cite{DS89} using the classical uncertainty principle, which states that $|\text{supp}(f)|\cdot|\text{supp}(\hat{f})|\geq |G|$ for any nonzero signal $f$. Another result, first proven by Santose and Symes \cite{SS86}, was based on the Logan phenomenon \cite{L65}. In particular, the result showcases how the $L^1$ and $L^2$ minimizing signals with matching Fourier frequencies often recovers the original signal.
  The purpose of this paper is to relate these recovery mechanisms to additive energy, a combinatorial measure denoted and defined by $$\Lambda(A)=\left| \left\{ (x_1, x_2, x_3, x_4) \in A^4 \mid x_1 + x_2 = x_3 + x_4 \right\} \right|,$$ where $A\subset\mathbb{Z}_N^d$. In the first part of this paper, we use combinatorial techniques to establish an improved variety of the uncertainty principle in terms of additive energy. In a similar fashion as the Donoho-Stark argument, we use this principle to establish an often stronger recovery condition. In the latter half of the paper, we invoke these combinatorial methods to demonstrate two $L^p$ minimizing recovery results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14702v1</guid>
      <category>math.CA</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>K. Aldahleh, A. Iosevich, J. Iosevich, J. Jaimangal, A. Mayeli, S. Pack</dc:creator>
    </item>
    <item>
      <title>Extending the ElGamal Cryptosystem to the Third Group of Units of $\Z_{n}$</title>
      <link>https://arxiv.org/abs/2504.15202</link>
      <description>arXiv:2504.15202v1 Announce Type: cross 
Abstract: In this paper, we extend the ElGamal cryptosystem to the third group of units of the ring $\Z_{n}$, which we prove to be more secure than the previous extensions. We describe the arithmetic needed in the new setting. We also provide some numerical simulations that shows the security and efficiency of our proposed cryptosystem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15202v1</guid>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>math.GR</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <category>math.RA</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Jana Hamza, Mohammad EL Hindi, Seifeddine Kadri, Therrar Kadri, Yahya Awad</dc:creator>
    </item>
    <item>
      <title>LEO-based Positioning: Foundations, Signal Design, and Receiver Enhancements for 6G NTN</title>
      <link>https://arxiv.org/abs/2410.18301</link>
      <description>arXiv:2410.18301v2 Announce Type: replace 
Abstract: The integration of non-terrestrial networks (NTN) into 5G new radio (NR) has opened up the possibility of developing a new positioning infrastructure using NR signals from Low-Earth Orbit (LEO) satellites. Compared to existing Global Navigation Satellite Systems (GNSS), LEO-based cellular positioning offers several advantages, such as a superior link budget, higher operating bandwidth, and large forthcoming constellations. Due to these factors, LEO-based positioning, navigation, and timing (PNT) is a potential enhancement for NTN in 6G cellular networks. However, extending the existing terrestrial cellular positioning methods to LEO-based NTN positioning requires key fundamental enhancements. These include creating broad positioning beams orthogonal to conventional communication beams, time-domain processing at the user equipment (UE) to resolve large delay and Doppler uncertainties, and efficiently accommodating positioning reference signals (PRS) from multiple satellites within the communication resource grid. In this paper, we present the first set of design insights by incorporating these enhancements and thoroughly evaluating LEO-based positioning, considering the constraints and capabilities of the NR-NTN physical layer. To evaluate the performance of LEO-based NTN positioning, we develop a comprehensive NR-compliant simulation framework, including LEO orbit simulation, transmission (Tx) and receiver (Rx) architectures, and a positioning engine incorporating the necessary enhancements. Our findings suggest that LEO-based NTN positioning could serve as a complementary infrastructure to GNSS and, with appropriate enhancements, may also offer a viable alternative.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18301v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Harish K. Dureppagari, Chiranjib Saha, Harikumar Krishnamurthy, Xiao Feng Wang, Alberto Rico-Alvari\~no, R. Michael Buehrer, Harpreet S. Dhillon</dc:creator>
    </item>
    <item>
      <title>Run-Length-Limited ISI-Mitigation (RLIM) Coding for Molecular Communication</title>
      <link>https://arxiv.org/abs/2411.15955</link>
      <description>arXiv:2411.15955v2 Announce Type: replace 
Abstract: Inter-symbol interference (ISI) is a significant challenge in diffusion-based communication channels, where residual molecules from previous transmissions interfere with the current signal interval, leading to detection errors. We introduce a new infinite family of coding schemes, which we name RLIM, that require each 1-bit to be followed by at least i consecutive 0-bits, where i is any chosen positive integer. This enhances ISI mitigation and improves error correction capabilities compared to existing ISI-mitigating channel codes. Through extensive simulations, we demonstrate that the codebooks derived from the proposed RLIM scheme significantly reduce bit error rate compared to prominent coding methods. Simulation results also reveal that an important constraint in RLIM codes is redundant under zero-drift conditions, removal of which makes them equivalent to run-length-limited (RLL) codes. Notably, despite this equivalence, the proposed family of RLIM coding schemes retains a distinct power optimization constraint and employs a specialized error correction algorithm, preserving its unique character and advantages. Furthermore, in diffusion-based channels with time-varying drift, the previously redundant constraint becomes critical for ensuring robust detection, thus demonstrating the enhanced applicability of proposed RLIM codes for such channels as well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15955v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Melih \c{S}ahin, Ozgur B. Akan</dc:creator>
    </item>
    <item>
      <title>Decoding convolutional codes over finite rings. A linear dynamical systems approach</title>
      <link>https://arxiv.org/abs/2411.18316</link>
      <description>arXiv:2411.18316v2 Announce Type: replace 
Abstract: Observable convolutional codes defined over Zpr with the Predictable Degree Property admits minimal input state output representations that behaves well under restriction of scalars. We make use of this fact to present Rosenthal's decoding algorithm for these convolutional codes. When combined with the Greferath-Vellbinger algorithm and a modified version of the Torrecillas-Lobillo-Navarro algorithm, the decoding problem reduces to selecting two decoding algorithms for linear block codes over a field. Finally, we analyze both the theoretical and practical error-correction capabilities of the combined algorithm,</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18316v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>\'Angel Luis Mu\~noz Casta\~neda, Noem\'i Decastro-Garc\'ia, Miguel V. Carriegos</dc:creator>
    </item>
    <item>
      <title>Quantum Codes from Group Ring Codes</title>
      <link>https://arxiv.org/abs/2412.13616</link>
      <description>arXiv:2412.13616v2 Announce Type: replace 
Abstract: This article examines group ring codes over finite fields and finite groups. We also present a section on two-dimensional cyclic codes in the quotient ring $\mathbb{F}_q[x, y] / \langle x^{l} - 1, y^{m} - 1 \rangle$. These two-dimensional cyclic codes can be analyzed using the group ring $\mathbb{F}_q(C_{l} \times C_{m})$, where $C_{l}$ and $C_{m}$ represent cyclic groups of orders $l$ and $m$, respectively. The aim is to show that studying group ring codes provides a more compact approach compared to the quotient ring method. We further extend this group ring framework to study codes over other group structures, such as the dihedral group, direct products of cyclic and dihedral groups, direct products of two cyclic groups, and semidirect products of two groups. Additionally, we explore necessary and sufficient conditions for such group ring codes to be self-orthogonal under Euclidean, Hermitian, and symplectic inner products and propose a construction for quantum codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13616v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kanat Abdukhalikov (UAEU), Tushar Bag (LIP, QINFO), Daniel Panario</dc:creator>
    </item>
    <item>
      <title>Hybrid Beamforming Design for RSMA-enabled Near-Field Integrated Sensing and Communications</title>
      <link>https://arxiv.org/abs/2412.17062</link>
      <description>arXiv:2412.17062v2 Announce Type: replace 
Abstract: Integrated sensing and communication (ISAC) networks leverage extremely large antenna arrays and high frequencies. This inevitably extends the Rayleigh distance, making near-field (NF) spherical wave propagation dominant. This unlocks numerous spatial degrees of freedom, raising the challenge of optimizing them for communication and sensing tradeoffs. To this end, we propose a rate-splitting multiple access (RSMA)-based NF-ISAC transmit scheme utilizing hybrid analog-digital antennas. RSMA enhances interference management, while a variable number of dedicated sensing beams adds beamforming flexibility. The objective is to maximize the minimum communication rate while ensuring multi-target sensing performance by jointly optimizing receive filters, analog and digital beamformers, common rate allocation, and the sensing beam count. To address uncertainty in sensing beam allocation, a rank-zero solution reconstruction method demonstrates that dedicated sensing beams are unnecessary for NF multi-target detection. A penalty dual decomposition (PDD)-based double-loop algorithm is introduced, employing weighted minimum mean-squared error (WMMSE) and quadratic transforms to reformulate communication and sensing rates. Simulations reveal that the proposed scheme: 1) achieves performance comparable to fully digital beamforming with fewer RF chains, (2) maintains NF multi-target detection without compromising communication rates, and 3) significantly outperforms conventional multiple access schemes and far-field ISAC systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17062v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiasi Zhou, Chintha Tellambura, Geoffrey Ye Li</dc:creator>
    </item>
    <item>
      <title>On Achievable Rates Over Noisy Nanopore Channels</title>
      <link>https://arxiv.org/abs/2501.02917</link>
      <description>arXiv:2501.02917v4 Announce Type: replace 
Abstract: In this paper, we consider a recent channel model of a nanopore sequencer proposed by McBain, Viterbo, and Saunderson (2024), termed the \emph{noisy nanopore channel} (NNC). In essence, an NNC is a duplication channel with structured, Markov inputs, that is corrupted by memoryless noise. We first discuss a (tight) lower bound on the capacity of the NNC in the absence of random noise. Next, we present bounds on the channel capacity of general noisy nanopore channels, via simple information-theoretic inequalities. We then consider two interesting regimes of operation of an NNC: first, where the memory of the input process is large and the random noise introduces erasures, and second, where the rate of measurements of the electric current (also called the sampling rate) is high. For these regimes, we show that it is possible to achieve information rates close to the noise-free capacity, using simple encoding and decoding schemes. In particular, our decoder for the regime of high sampling rates makes use of a change-point detection procedure -- a subroutine of immediate relevance for practitioners.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02917v4</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>V. Arvind Rameshwar, Nir Weinberger</dc:creator>
    </item>
    <item>
      <title>Optimizing Sequencing Coverage Depth in DNA Storage: Insights From DNA Storage Data</title>
      <link>https://arxiv.org/abs/2501.06801</link>
      <description>arXiv:2501.06801v2 Announce Type: replace 
Abstract: DNA storage is now being considered as a new archival storage method for its durability and high information density, but still facing some challenges like high costs and low throughput. By reducing sequencing sample size for decoding digital data, minimizing DNA coverage depth helps lower both costs and system latency. Previous studies have mainly focused on minimizing coverage depth in uniform distribution channels under theoretical assumptions. In contrast, our work uses real DNA storage experimental data to extend this problem to log-normal distribution channels, a conclusion derived from our PCR and sequencing data analysis. In this framework, we investigate both noiseless and noisy channels. We first demonstrate a detailed positive correlation between MDS code rate and the expected minimum sequencing coverage depth. Moreover, we observe that the probability of successfully decoding all information in a single sequencing run decreases and then increases as code rate rises, when the sample size is optimized for complete decoding. Then we extend the lower bounds of the DNA coverage depth from uniform to log-normal noisy channels. The findings of this study provide valuable insights for the efficient execution of DNA storage experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.06801v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruiying Cao, Xin Chen</dc:creator>
    </item>
    <item>
      <title>Causal Emergence 2.0: Quantifying emergent complexity</title>
      <link>https://arxiv.org/abs/2503.13395</link>
      <description>arXiv:2503.13395v3 Announce Type: replace 
Abstract: Complex systems can be described at myriad different scales, and their causal workings often have multiscale structure (e.g., a computer can be described at the microscale of its hardware circuitry, the mesoscale of its machine code, and the macroscale of its operating system). While scientists study and model systems across the full hierarchy of their scales, from microphysics to macroeconomics, there is debate about what the macroscales of systems can possibly add beyond mere compression. To resolve this longstanding issue, here a new theory of emergence is introduced wherein the different scales of a system are treated like slices of a higher-dimensional object. The theory can distinguish which of these scales possess unique causal contributions, and which are not causally relevant. Constructed from an axiomatic notion of causation, the theory's application is demonstrated in coarse-grains of Markov chains. It identifies all cases of macroscale causation: instances where reduction to a microscale is possible, yet lossy about causation. Furthermore, the theory posits a causal apportioning schema that calculates the causal contribution of each scale, showing what each uniquely adds. Finally, it reveals a novel measure of emergent complexity: how widely distributed a system's causal workings are across its hierarchy of scales.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13395v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erik Hoel</dc:creator>
    </item>
    <item>
      <title>Bounds and Optimal Constructions of Generalized Merge-Convertible Codes for Code Conversion into LRCs</title>
      <link>https://arxiv.org/abs/2504.09580</link>
      <description>arXiv:2504.09580v2 Announce Type: replace 
Abstract: Error-correcting codes are essential for ensuring fault tolerance in modern distributed data storage systems. However, in practice, factors such as the failure rates of storage devices can vary significantly over time, resulting in changes to the optimal code parameters. To reduce storage cost while maintaining efficiency, Maturana and Rashmi introduced a theoretical framework known as code conversion, which enables dynamic adjustment of code parameters according to device performance. In this paper, we focus exclusively on the bounds and constructions of generalized merge-convertible codes. First, we establish a new lower bound on the access cost when the final code is an $(r,\delta)$-LRC. This bound unifies and generalizes all previously known bounds for merge conversion, where the initial and final codes are either LRCs or MDS codes. We then construct a family of access-optimal MDS convertible codes by leveraging subgroups of the automorphism group of a rational function field. It is worth noting that our construction is also per-symbol read access-optimal. Next, we further extend our MDS-based construction to design access-optimal convertible codes for the conversion between $(r,\delta)$-LRCs with parameters that have not been previously reported. Finally, using the parity-check matrix approach, we present a construction of access-optimal convertible codes that enable merge conversion from MDS codes to an $(r,\delta)$-LRC. To the best of our knowledge, this is the first explicit optimal construction of code conversion between MDS codes and LRCs. All of our constructions are performed over finite fields whose sizes grow linearly with the code length.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09580v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Haoming Shi, Weijun Fang, Yuan Gao</dc:creator>
    </item>
    <item>
      <title>SegOTA: Accelerating Over-the-Air Federated Learning with Segmented Transmission</title>
      <link>https://arxiv.org/abs/2504.09745</link>
      <description>arXiv:2504.09745v2 Announce Type: replace 
Abstract: Federated learning (FL) with over-the-air computation efficiently utilizes the communication resources, but it can still experience significant latency when each device transmits a large number of model parameters to the server. This paper proposes the Segmented Over-The-Air (SegOTA) method for FL, which reduces latency by partitioning devices into groups and letting each group transmit only one segment of the model parameters in each communication round. Considering a multi-antenna server, we model the SegOTA transmission and reception process to establish an upper bound on the expected model learning optimality gap. We minimize this upper bound, by formulating the per-round online optimization of device grouping and joint transmit-receive beamforming, for which we derive efficient closed-form solutions. Simulation results show that our proposed SegOTA substantially outperforms the conventional full-model OTA approach and other common alternatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09745v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chong Zhang, Min Dong, Ben Liang, Ali Afana, Yahia Ahmed</dc:creator>
    </item>
    <item>
      <title>Universal time-series forecasting with mixture predictors</title>
      <link>https://arxiv.org/abs/2010.00297</link>
      <description>arXiv:2010.00297v2 Announce Type: replace-cross 
Abstract: This book is devoted to the problem of sequential probability forecasting, that is, predicting the probabilities of the next outcome of a growing sequence of observations given the past. This problem is considered in a very general setting that unifies commonly used probabilistic and non-probabilistic settings, trying to make as few as possible assumptions on the mechanism generating the observations. A common form that arises in various formulations of this problem is that of mixture predictors, which are formed as a combination of a finite or infinite set of other predictors attempting to combine their predictive powers. The main subject of this book are such mixture predictors, and the main results demonstrate the universality of this method in a very general probabilistic setting, but also show some of its limitations. While the problems considered are motivated by practical applications, involving, for example, financial, biological or behavioural data, this motivation is left implicit and all the results exposed are theoretical.
  The book targets graduate students and researchers interested in the problem of sequential prediction, and, more generally, in theoretical analysis of problems in machine learning and non-parametric statistics, as well as mathematical and philosophical foundations of these fields.
  The material in this volume is presented in a way that presumes familiarity with basic concepts of probability and statistics, up to and including probability distributions over spaces of infinite sequences. Familiarity with the literature on learning or stochastic processes is not required.</description>
      <guid isPermaLink="false">oai:arXiv.org:2010.00297v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-030-54304-4</arxiv:DOI>
      <dc:creator>Daniil Ryabko</dc:creator>
    </item>
    <item>
      <title>Simple Worst-Case Optimal Adaptive Prefix-Free Coding</title>
      <link>https://arxiv.org/abs/2109.02997</link>
      <description>arXiv:2109.02997v4 Announce Type: replace-cross 
Abstract: We give a new and simple worst-case optimal algorithm for adaptive prefix-free coding that matches Gagie and Nekrich's bounds except for lower-order terms, and uses no data structures more complicated than a lookup table. Moreover, when Gagie and Nekrich's algorithm is modified for adaptive alphabetic prefix-free coding its decoding time slows down to $O (\log \log n)$ per character, but ours can be modified for this problem with no asymptotic slowdown. As far as we know, this gives the first algorithm for this alphabetic problem that is simultaneously worst-case optimal in terms of encoding and decoding time and of encoding length.</description>
      <guid isPermaLink="false">oai:arXiv.org:2109.02997v4</guid>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Travis Gagie</dc:creator>
    </item>
    <item>
      <title>Strong Converse Bounds for Compression of Mixed States</title>
      <link>https://arxiv.org/abs/2206.09415</link>
      <description>arXiv:2206.09415v2 Announce Type: replace-cross 
Abstract: In this paper, we study strong converse properties for both visible and blind compression of mixed states. The optimal rate of a visible compression scheme is obtained in terms of the entanglement of purification, whose additivity remains unknown so far. For a variation of extendible states, we prove that the entanglement of purification is additive and apply this to obtain a "pretty strong" converse bound for the blind and visible compression of such states. Namely, when the rate decreases below the optimal rate, the error exhibits a discontinuous jump from 0 to at least $\frac{1}{3\sqrt{2}}$.
  To deal with the visible case for general states, we define a new quantity $E_{\alpha,p}(A:R)_{\rho}$ for a bipartite state $\rho^{AR}$ and $\alpha \in (0,1)\cup (1,\infty)$ as the $\alpha$-R\'enyi generalization of the entanglement of purification $E_{p}(A:R)_{\rho}$. For $\alpha=1$, we define $E_{1,p}(A:R)_{\rho}:=E_{p}(A:R)_{\rho}$. We show that for any rate below the regularization $\lim_{\alpha \to 1^+}E_{\alpha,p}^{\infty}(A:R)_{\rho}:=\lim_{\alpha \to 1^+} \lim_{n \to \infty} \frac{E_{\alpha,p}(A^n:R^n)_{\rho^{\otimes n}}}{n}$ the fidelity for the visible compression exponentially converges to zero.
  Moreover, we consider blind compression of a general mixed-state source $\rho^{AR}$ shared between an encoder and an inaccessible reference system $R$. We obtain a strong converse bound for the compression of this source by assuming that the decoder is a super-unital channel. This immediately implies a strong converse for the blind compression of ensembles of mixed states, by assuming a super-unital decoder, as this is a special case of the general mixed-state source $\rho^{AR}$ where the reference system $R$ has a classical structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.09415v2</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zahra Baghali Khanian</dc:creator>
    </item>
    <item>
      <title>Interior Point Methods for Structured Quantum Relative Entropy Optimization Problems</title>
      <link>https://arxiv.org/abs/2407.00241</link>
      <description>arXiv:2407.00241v3 Announce Type: replace-cross 
Abstract: Quantum relative entropy optimization refers to a class of convex problems in which a linear functional is minimized over an affine section of the epigraph of the quantum relative entropy function. Recently, the self-concordance of a natural barrier function was proved for this set, and various implementations of interior-point methods have been made available to solve this class of optimization problems. In this paper, we show how common structures arising from applications in quantum information theory can be exploited to improve the efficiency of solving quantum relative entropy optimization problems using interior-point methods. First, we show that the natural barrier function for the epigraph of the quantum relative entropy composed with positive linear operators is self-concordant, even when these linear operators map to singular matrices. Compared to modelling problems using the full quantum relative entropy cone, this allows us to remove redundant log-determinant expressions from the barrier function and reduce the overall barrier parameter. Second, we show how certain slices of the quantum relative entropy cone exhibit useful properties which should be exploited whenever possible to perform certain key steps of interior-point methods more efficiently. We demonstrate how these methods can be applied to applications in quantum information theory, including quantifying quantum key rates, quantum rate-distortion functions, quantum channel capacities, and the ground state energy of Hamiltonians. Our numerical results show that these techniques improve computation times by up to several orders of magnitude, and allow previously intractable problems to be solved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00241v3</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kerry He, James Saunderson, Hamza Fawzi</dc:creator>
    </item>
    <item>
      <title>TinyML NLP Scheme for Semantic Wireless Sentiment Classification with Privacy Preservation</title>
      <link>https://arxiv.org/abs/2411.06291</link>
      <description>arXiv:2411.06291v3 Announce Type: replace-cross 
Abstract: Natural Language Processing (NLP) operations, such as semantic sentiment analysis and text synthesis, often raise privacy concerns and demand significant on-device computational resources. Centralized learning (CL) on the edge provides an energy-efficient alternative but requires collecting raw data, compromising user privacy. While federated learning (FL) enhances privacy, it imposes high computational energy demands on resource-constrained devices. This study provides insights into deploying privacy-preserving, energy-efficient NLP models on edge devices. We introduce semantic split learning (SL) as an energy-efficient, privacy-preserving tiny machine learning (TinyML) framework and compare it to FL and CL in the presence of Rayleigh fading and additive noise. Our results show that SL significantly reduces computational power and CO2 emissions while enhancing privacy, as evidenced by a fourfold increase in reconstruction error compared to FL and nearly eighteen times that of CL. In contrast, FL offers a balanced trade-off between privacy and efficiency. Our code is available for replication at our GitHub repository: https://github.com/AhmedRadwan02/TinyEco2AI-NLP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06291v3</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmed Y. Radwan, Mohammad Shehab, Mohamed-Slim Alouini</dc:creator>
    </item>
    <item>
      <title>Linearly Homomorphic Signature with Tight Security on Lattice</title>
      <link>https://arxiv.org/abs/2412.01641</link>
      <description>arXiv:2412.01641v4 Announce Type: replace-cross 
Abstract: At present, in lattice-based linearly homomorphic signature schemes, especially under the standard model, there are very few schemes with tight security. This paper constructs the first lattice-based linearly homomorphic signature scheme that achieves tight security against existential unforgeability under chosen-message attacks (EUF-CMA) in the standard model. Furthermore, among existing schemes, the scheme proposed in this paper also offers certain advantages in terms of public key size, signature length, and computational cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01641v4</guid>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Heng Guo, Kun Tian, Fengxia Liu, Zhiyong Zheng</dc:creator>
    </item>
    <item>
      <title>Efficient Algorithm for Sparse Fourier Transform of Generalized $q$-ary Functions</title>
      <link>https://arxiv.org/abs/2501.12365</link>
      <description>arXiv:2501.12365v2 Announce Type: replace-cross 
Abstract: Computing the Fourier transform of a $q$-ary function $f:\mathbb{Z}_{q}^n\rightarrow \mathbb{R}$, which maps $q$-ary sequences to real numbers, is an important problem in mathematics with wide-ranging applications in biology, signal processing, and machine learning. Previous studies have shown that, under the sparsity assumption, the Fourier transform can be computed efficiently using fast and sample-efficient algorithms. However, in most practical settings, the function is defined over a more general space -- the space of generalized $q$-ary sequences $\mathbb{Z}_{q_1} \times \mathbb{Z}_{q_2} \times \cdots \times \mathbb{Z}_{q_n}$ -- where each $\mathbb{Z}_{q_i}$ corresponds to integers modulo $q_i$. Herein, we develop GFast, a coding theoretic algorithm that computes the $S$-sparse Fourier transform of $f$ with a sample complexity of $O(Sn)$, computational complexity of $O(Sn \log N)$, and a failure probability that approaches zero as $N=\prod_{i=1}^n q_i \rightarrow \infty$ with $S = N^\delta$ for some $0 \leq \delta &lt; 1$. We show that a noise-robust version of GFast computes the transform with a sample complexity of $O(Sn^2)$ and computational complexity of $O(Sn^2 \log N)$ under the same high probability guarantees. Additionally, we demonstrate that GFast computes the sparse Fourier transform of generalized $q$-ary functions $8\times$ faster using $16\times$ fewer samples on synthetic experiments, and enables explaining real-world heart disease diagnosis and protein fitness models using up to $13\times$ fewer samples compared to existing Fourier algorithms applied to the most efficient parameterization of the models as $q$-ary functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12365v2</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Darin Tsui, Kunal Talreja, Amirali Aghazadeh</dc:creator>
    </item>
    <item>
      <title>Unsupervised Learning for AoD Estimation in MISO Downlink LoS Transmissions</title>
      <link>https://arxiv.org/abs/2503.12033</link>
      <description>arXiv:2503.12033v2 Announce Type: replace-cross 
Abstract: With the emergence of simultaneous localization and communication (SLAC), it becomes more and more attractive to perform angle of departure (AoD) estimation at the receiving Internet of Thing (IoT) user end for improved positioning accuracy, flexibility and enhanced user privacy. To address challenges like a large number of real-time measurements required for latency-critical applications and enormous data collection for training deep learning models in conventional AoD estimation methods, we propose in this letter an unsupervised learning framework, which unifies training for both deterministic maximum likelihood (DML) and stochastic maximum likelihood (SML) based AoD estimation in multiple-input single-output (MISO) downlink (DL) wireless transmissions. Specifically, under the line-of-sight (LoS) assumption, we incorporate both the received signals and pilot-sequence information, as per its availability at the DL user, into the input of the deep learning model, and adopt a common neural network architecture compatible with input data in both DML and SML cases. Extensive numerical results validate that the proposed unsupervised learning based AoD estimation not only improves estimation accuracy, but also significantly reduces required number of observations, thereby reducing both estimation overhead and latency compared to various benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.12033v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiaying Li, Yuanwei Liu, Hong Xing</dc:creator>
    </item>
    <item>
      <title>Understanding LLM Behaviors via Compression: Data Generation, Knowledge Acquisition and Scaling Laws</title>
      <link>https://arxiv.org/abs/2504.09597</link>
      <description>arXiv:2504.09597v3 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across numerous tasks, yet principled explanations for their underlying mechanisms and several phenomena, such as scaling laws, hallucinations, and related behaviors, remain elusive. In this work, we revisit the classical relationship between compression and prediction, grounded in Kolmogorov complexity and Shannon information theory, to provide deeper insights into LLM behaviors. By leveraging the Kolmogorov Structure Function and interpreting LLM compression as a two-part coding process, we offer a detailed view of how LLMs acquire and store information across increasing model and data scales -- from pervasive syntactic patterns to progressively rarer knowledge elements. Motivated by this theoretical perspective and natural assumptions inspired by Heap's and Zipf's laws, we introduce a simplified yet representative hierarchical data-generation framework called the Syntax-Knowledge model. Under the Bayesian setting, we show that prediction and compression within this model naturally lead to diverse learning and scaling behaviors of LLMs. In particular, our theoretical analysis offers intuitive and principled explanations for both data and model scaling laws, the dynamics of knowledge acquisition during training and fine-tuning, factual knowledge hallucinations in LLMs. The experimental results validate our theoretical predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09597v3</guid>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhixuan Pan, Shaowen Wang, Jian Li</dc:creator>
    </item>
    <item>
      <title>A Mathematical Framework of Semantic Communication based on Category Theory</title>
      <link>https://arxiv.org/abs/2504.11334</link>
      <description>arXiv:2504.11334v2 Announce Type: replace-cross 
Abstract: While semantic communication (SemCom) has recently demonstrated great potential to enhance transmission efficiency and reliability by leveraging machine learning (ML) and knowledge base (KB), there is a lack of mathematical modeling to rigorously characterize SemCom system and quantify the performance gain obtained from ML and KB. In this paper, we develop a mathematical framework for SemCom based on category theory, rigorously modeling the concepts of semantic entities and semantic probability space. Within this framework, we introduce the semantic entropy to quantify the uncertainty of semantic entities. We theoretically prove that semantic entropy can be effectively reduced by exploiting KBs, which capture semantic dependencies. Within the formulated semantic space, semantic entities can be combined according to the required semantic ambiguity, and the combined entities can be encoded based on semantic dependencies obtained from KB. Then, we derive semantic channel capacity modeling, which incorporates the mutual information obtained in KB to accurately measure the transmission efficiency of SemCom. Numerical simulations validate the effectiveness of the proposed framework, showing that SemCom with KB integration outperforms traditional communication in both entropy reduction and coding efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11334v2</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuheng Hua, Yao Sun, Kairong Ma, Dusit Niyato, Muhammad Ali Imran</dc:creator>
    </item>
  </channel>
</rss>
