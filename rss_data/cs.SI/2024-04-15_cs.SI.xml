<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 16 Apr 2024 04:01:06 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 16 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Beam Management in Low Earth Orbit Satellite Networks with Random Traffic Arrival and Time-varying Topology</title>
      <link>https://arxiv.org/abs/2404.08959</link>
      <description>arXiv:2404.08959v1 Announce Type: new 
Abstract: Low earth orbit (LEO) satellite communication networks have been considered as promising solutions to providing high data rate and seamless coverage, where satellite beam management plays a key role. However, due to the limitation of beam resource, dynamic network topology, beam spectrum reuse, time-varying traffic arrival and service continuity requirement, it is challenging to effectively allocate time-frequency resource of satellite beams to multiple cells. In this paper, aiming at reducing time-averaged beam revisit time and mitigate inter-satellite handover, a beam management problem is formulated for dynamic LEO satellite communication networks, under inter-cell interference and network stability constraints. Particularly, inter-cell interference constraints are further simplified into off-axis angle based constraints, which provide tractable rules for spectrum sharing between two beam cells. To deal with the long-term performance optimization, the primal problem is transformed into a series of single epoch problems by adopting Lyapunov optimization framework. Since the transformed problem is NP-hard, it is further divided into three subproblems, including serving beam allocation, beam service time allocation and serving satellite allocation. With the help of conflict graphs built with off-axis angle based constraints, serving beam allocation and beam service time allocation algorithms are developed to reduce beam revisit time and cell packet queue length. Then, we further develop a satellite-cell service relationship optimization algorithm to better adapt to dynamic network topology. Compared with baselines, numerical results show that our proposal can reduce average beam revisit time by 20.8% and keep strong network stability with similar inter-satellite handover frequency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08959v1</guid>
      <category>cs.SI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianfeng Zhu, Yaohua Sun, Mugen Peng</dc:creator>
    </item>
    <item>
      <title>Timing Advance Estimation in Low Earth Orbit Satellite Networks</title>
      <link>https://arxiv.org/abs/2404.08960</link>
      <description>arXiv:2404.08960v1 Announce Type: new 
Abstract: Low earth orbit (LEO) satellite communication based on 3GPP standard is seen as a promising solution to rolling out communication services in areas without terrestrial base stations. However, due to the fast movement of satellites and large beam footprint size, the existing 5G timing advance (TA) estimation mechanism cannot be directly applied when global navigation satellite system is unavailable. In this article, an enhanced TA estimation approach is proposed for LEO satellite communication networks. Specifically, a user-side time-frequency pre-compensation method is introduced at first, which leverages frequency offset measurement on synchronization signal blocks broadcasted by satellites in initial cell search phase. For the random access phase, the upper bound of inter-preamble interference incurred by partial-period cross-correlation operations is derived for a preamble format advised by 3GPP, and it is shown that the interference level is closely related to the square of the number of such operations. Inspired by this result, a cyclic prefix free preamble format is further designed, which features extended guard time, differential power allocation and flexible preamble structure. Numerical results show that our proposal can reduce the missed detection rate of preamble within a beam. Particularly, the missed detection rates of preamble under 32, 48, and 64 users are lower than 1% when SNR = -6 dB, which is a significant improvement compared to baselines. In addition, our proposal can limit the TA estimation error of the detected users to the time length of 25 time-domain sampling points when the subcarrier spacing is 30 kHz and operation frequency is 27 GHz.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08960v1</guid>
      <category>cs.SI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TVT.2023.3325328</arxiv:DOI>
      <dc:creator>Jianfeng Zhu, Yaohua Sun, Mugen Peng</dc:creator>
    </item>
    <item>
      <title>Beam Management in Low Earth Orbit Satellite Communication With Handover Frequency Control and Satellite-Terrestrial Spectrum Sharing</title>
      <link>https://arxiv.org/abs/2404.08967</link>
      <description>arXiv:2404.08967v1 Announce Type: new 
Abstract: To achieve ubiquitous wireless connectivity, low earth orbit (LEO) satellite networks have drawn much attention. However, effective beam management is challenging due to time-varying cell load, high dynamic network topology, and complex interference situations. In this paper, under inter-satellite handover frequency and satellite-terrestrial/inter-beam interference constraints, we formulate a practical beam management problem, aiming to maximize the long-term service satisfaction of cells. Particularly, Lyapunov framework is leveraged to equivalently transform the primal problem into multiple single epoch optimization problems, where virtual queue stability constraints replace inter-satellite handover frequency constraints. Since each single epoch problem is NP-hard, we further decompose it into three subproblems, including inter-satellite handover decision, beam hopping design and satellite-terrestrial spectrum sharing. First, a proactive inter-satellite handover mechanism is developed to balance handover frequency and satellite loads. Subsequently, a beam hopping design algorithm is presented based on conflict graphs to achieve interference mitigation among beams, and then a flexible satellite-terrestrial spectrum sharing algorithm is designed to satisfy the demands of beam cells and improve spectral efficiency. Simulation results show that our proposal significantly improves service satisfaction compared with baselines, where the average data queue length of beam cells is reduced by over 50% with affordable handover frequency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08967v1</guid>
      <category>cs.SI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yaohua Sun, Jianfeng Zhu, Mugen Peng</dc:creator>
    </item>
    <item>
      <title>Survey on Embedding Models for Knowledge Graph and its Applications</title>
      <link>https://arxiv.org/abs/2404.09167</link>
      <description>arXiv:2404.09167v1 Announce Type: new 
Abstract: Knowledge Graph (KG) is a graph based data structure to represent facts of the world where nodes represent real world entities or abstract concept and edges represent relation between the entities. Graph as representation for knowledge has several drawbacks like data sparsity, computational complexity and manual feature engineering. Knowledge Graph embedding tackles the drawback by representing entities and relation in low dimensional vector space by capturing the semantic relation between them. There are different KG embedding models. Here, we discuss translation based and neural network based embedding models which differ based on semantic property, scoring function and architecture they use. Further, we discuss application of KG in some domains that use deep learning models and leverage social media data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09167v1</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Manita Pote</dc:creator>
    </item>
    <item>
      <title>FewUser: Few-Shot Social User Geolocation via Contrastive Learning</title>
      <link>https://arxiv.org/abs/2404.08662</link>
      <description>arXiv:2404.08662v1 Announce Type: cross 
Abstract: To address the challenges of scarcity in geotagged data for social user geolocation, we propose FewUser, a novel framework for Few-shot social User geolocation. We incorporate a contrastive learning strategy between users and locations to improve geolocation performance with no or limited training data. FewUser features a user representation module that harnesses a pre-trained language model (PLM) and a user encoder to process and fuse diverse social media inputs effectively. To bridge the gap between PLM's knowledge and geographical data, we introduce a geographical prompting module with hard, soft, and semi-soft prompts, to enhance the encoding of location information. Contrastive learning is implemented through a contrastive loss and a matching loss, complemented by a hard negative mining strategy to refine the learning process. We construct two datasets TwiU and FliU, containing richer metadata than existing benchmarks, to evaluate FewUser and the extensive experiments demonstrate that FewUser significantly outperforms state-of-the-art methods in both zero-shot and various few-shot settings, achieving absolute improvements of 26.95\% and \textbf{41.62\%} on TwiU and FliU, respectively, with only one training sample per class. We further conduct a comprehensive analysis to investigate the impact of user representation on geolocation performance and the effectiveness of FewUser's components, offering valuable insights for future research in this area.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08662v1</guid>
      <category>cs.IR</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Menglin Li, Kwan Hui Lim</dc:creator>
    </item>
    <item>
      <title>Targeted aspect-based emotion analysis to detect opportunities and precaution in financial Twitter messages</title>
      <link>https://arxiv.org/abs/2404.08665</link>
      <description>arXiv:2404.08665v1 Announce Type: cross 
Abstract: Microblogging platforms, of which Twitter is a representative example, are valuable information sources for market screening and financial models. In them, users voluntarily provide relevant information, including educated knowledge on investments, reacting to the state of the stock markets in real-time and, often, influencing this state. We are interested in the user forecasts in financial, social media messages expressing opportunities and precautions about assets. We propose a novel Targeted Aspect-Based Emotion Analysis (TABEA) system that can individually discern the financial emotions (positive and negative forecasts) on the different stock market assets in the same tweet (instead of making an overall guess about that whole tweet). It is based on Natural Language Processing (NLP) techniques and Machine Learning streaming algorithms. The system comprises a constituency parsing module for parsing the tweets and splitting them into simpler declarative clauses; an offline data processing module to engineer textual, numerical and categorical features and analyse and select them based on their relevance; and a stream classification module to continuously process tweets on-the-fly. Experimental results on a labelled data set endorse our solution. It achieves over 90% precision for the target emotions, financial opportunity, and precaution on Twitter. To the best of our knowledge, no prior work in the literature has addressed this problem despite its practical interest in decision-making, and we are not aware of any previous NLP nor online Machine Learning approaches to TABEA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08665v1</guid>
      <category>cs.IR</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <category>q-fin.TR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.eswa.2023.119611</arxiv:DOI>
      <dc:creator>Silvia Garc\'ia-M\'endez, Francisco de Arriba-P\'erez, Ana Barros-Vila, Francisco J. Gonz\'alez-Casta\~no</dc:creator>
    </item>
    <item>
      <title>Misinformation Resilient Search Rankings with Webgraph-based Interventions</title>
      <link>https://arxiv.org/abs/2404.08869</link>
      <description>arXiv:2404.08869v1 Announce Type: cross 
Abstract: The proliferation of unreliable news domains on the internet has had wide-reaching negative impacts on society. We introduce and evaluate interventions aimed at reducing traffic to unreliable news domains from search engines while maintaining traffic to reliable domains. We build these interventions on the principles of fairness (penalize sites for what is in their control), generality (label/fact-check agnostic), targeted (increase the cost of adversarial behavior), and scalability (works at webscale). We refine our methods on small-scale webdata as a testbed and then generalize the interventions to a large-scale webgraph containing 93.9M domains and 1.6B edges. We demonstrate that our methods penalize unreliable domains far more than reliable domains in both settings and we explore multiple avenues to mitigate unintended effects on both the small-scale and large-scale webgraph experiments. These results indicate the potential of our approach to reduce the spread of misinformation and foster a more reliable online information ecosystem. This research contributes to the development of targeted strategies to enhance the trustworthiness and quality of search engine results, ultimately benefiting users and the broader digital community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08869v1</guid>
      <category>cs.IR</category>
      <category>cs.SI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peter Carragher, Evan M. Williams, Kathleen M. Carley</dc:creator>
    </item>
    <item>
      <title>A Multi-Modal Latent-Features based Service Recommendation System for the Social Internet of Things</title>
      <link>https://arxiv.org/abs/2306.01163</link>
      <description>arXiv:2306.01163v2 Announce Type: replace 
Abstract: The Social Internet of Things (SIoT), is revolutionizing how we interact with our everyday lives. By adding the social dimension to connecting devices, the SIoT has the potential to drastically change the way we interact with smart devices. This connected infrastructure allows for unprecedented levels of convenience, automation, and access to information, allowing us to do more with less effort. However, this revolutionary new technology also brings an eager need for service recommendation systems. As the SIoT grows in scope and complexity, it becomes increasingly important for businesses and individuals, and SIoT objects alike to have reliable sources for products, services, and information that are tailored to their specific needs. Few works have been proposed to provide service recommendations for SIoT environments. However, these efforts have been confined to only focusing on modeling user-item interactions using contextual information, devices' SIoT relationships, and correlation social groups but these schemes do not account for latent semantic item-item structures underlying the sparse multi-modal contents in SIoT environment. In this paper, we propose a latent-based SIoT recommendation system that learns item-item structures and aggregates multiple modalities to obtain latent item graphs which are then used in graph convolutions to inject high-order affinities into item representations. Experiments showed that the proposed recommendation system outperformed state-of-the-art SIoT recommendation methods and validated its efficacy at mining latent relationships from multi-modal features.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.01163v2</guid>
      <category>cs.SI</category>
      <category>cs.IR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TCSS.2024.3360518</arxiv:DOI>
      <dc:creator>Amar Khelloufi, Huansheng Ning, Abdenacer Naouri, Abdelkarim Ben Sada, Attia Qammar, Abdelkader Khalil, Sahraoui Dhelim, Lingfeng Mao</dc:creator>
    </item>
    <item>
      <title>Approximation Algorithms to Enhance Social Sharing of Fresh Point-of-Interest Information</title>
      <link>https://arxiv.org/abs/2308.13260</link>
      <description>arXiv:2308.13260v2 Announce Type: replace 
Abstract: In location-based social networks (LBSNs), such as Gowalla and Waze, users sense urban point-of-interest (PoI) information (e.g., restaurants' queue length and real-time traffic conditions) in the vicinity and share such information with friends in online social networks. Given each user's social connections and the severe lags in disseminating fresh PoI to all users, major LBSNs aim to enhance users' social PoI sharing by selecting $k$ out of $m$ users as hotspots and broadcasting their PoI information to the entire user community. This motivates us to study a new combinatorial optimization problem by integrating two urban sensing and online social networks. We prove that this problem is NP-hard and also renders existing approximation solutions not viable. Through analyzing the interplay effects between the sensing and social networks, we successfully transform the involved PoI-sharing process across two networks to matrix computations for deriving a closed-form objective, {\color{black}which we find holds desirable properties (e.g., submodularity and monotonicity).} This finding enables us to develop a polynomial-time algorithm that guarantees a ($1-\frac{m-2}{m}(\frac{k-1}{k})^k$) approximation of the optimum. Furthermore, we allow each selected user to move around and sense more PoI information to share. To this end, we propose an augmentation-adaptive algorithm, which benefits from a resource-augmented technique and achieves bounded approximation, ranging from $\frac{1}{k}(1-\frac{1}{e})$ to $1-\frac{1}{e}&gt; 0.632$ by adjusting our augmentation factors. Finally, our theoretical results are corroborated by our simulation findings using both synthetic and real-world datasets across different network topologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.13260v2</guid>
      <category>cs.SI</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Songhua Li, Lingjie Duan</dc:creator>
    </item>
    <item>
      <title>COVID-19 and income profile: How communities in the United States responded to mobility restrictions in the pandemic's early stages</title>
      <link>https://arxiv.org/abs/2007.02160</link>
      <description>arXiv:2007.02160v2 Announce Type: replace-cross 
Abstract: Mobility interventions in communities play a critical role in containing a pandemic at an early stage. The real-world practice of social distancing can enlighten policymakers and help them implement more efficient and effective control measures. A lack of such research using real-world observations initiates this article. We analyzed the social distancing performance of 66,149 census tracts from 3,142 counties in the United States with a specific focus on income profile. Six daily mobility metrics, including a social distancing index, stay-at-home percentage, miles traveled per person, trip rate, work trip rate, and non-work trip rate, were produced for each census tract using the location data from over 100 million anonymous devices on a monthly basis. Each mobility metric was further tabulated by three perspectives of social distancing performance: "best performance", "effort", and "consistency". We found that for all 18 indicators, high-income communities demonstrated better social distancing performance. Such disparities between communities of different income levels are presented in detail in this article. The comparisons across scenarios also raise other concerns for low-income communities, such as employment status, working conditions, and accessibility to basic needs. This article lays out a series of facts extracted from real-world data and offers compelling perspectives for future discussions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2007.02160v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1111/rsp3.12598</arxiv:DOI>
      <arxiv:journal_reference>Regional Science Policy &amp; Practice. 15(2023)541-559</arxiv:journal_reference>
      <dc:creator>Qianqian Sun, Weiyi Zhou, Aliakbar Kabiri, Aref Darzi, Songhua Hu, Hannah Younes, Lei Zhang</dc:creator>
    </item>
    <item>
      <title>Node Classification in Random Trees</title>
      <link>https://arxiv.org/abs/2311.12167</link>
      <description>arXiv:2311.12167v2 Announce Type: replace-cross 
Abstract: We propose a method for the classification of objects that are structured as random trees. Our aim is to model a distribution over the node label assignments in settings where the tree data structure is associated with node attributes (typically high dimensional embeddings). The tree topology is not predetermined and none of the label assignments are present during inference. Other methods that produce a distribution over node label assignment in trees (or more generally in graphs) either assume conditional independence of the label assignment, operate on a fixed graph topology, or require part of the node labels to be observed. Our method defines a Markov Network with the corresponding topology of the random tree and an associated Gibbs distribution. We parameterize the Gibbs distribution with a Graph Neural Network that operates on the random tree and the node embeddings. This allows us to estimate the likelihood of node assignments for a given random tree and use MCMC to sample from the distribution of node assignments.
  We evaluate our method on the tasks of node classification in trees on the Stanford Sentiment Treebank dataset. Our method outperforms the baselines on this dataset, demonstrating its effectiveness for modeling joint distributions of node labels in random trees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.12167v2</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wouter W. L. Nuijten, Vlado Menkovski</dc:creator>
    </item>
    <item>
      <title>Graph Neural Networks with Diverse Spectral Filtering</title>
      <link>https://arxiv.org/abs/2312.09041</link>
      <description>arXiv:2312.09041v2 Announce Type: replace-cross 
Abstract: Spectral Graph Neural Networks (GNNs) have achieved tremendous success in graph machine learning, with polynomial filters applied for graph convolutions, where all nodes share the identical filter weights to mine their local contexts. Despite the success, existing spectral GNNs usually fail to deal with complex networks (e.g., WWW) due to such homogeneous spectral filtering setting that ignores the regional heterogeneity as typically seen in real-world networks. To tackle this issue, we propose a novel diverse spectral filtering (DSF) framework, which automatically learns node-specific filter weights to exploit the varying local structure properly. Particularly, the diverse filter weights consist of two components -- A global one shared among all nodes, and a local one that varies along network edges to reflect node difference arising from distinct graph parts -- to balance between local and global information. As such, not only can the global graph characteristics be captured, but also the diverse local patterns can be mined with awareness of different node positions. Interestingly, we formulate a novel optimization problem to assist in learning diverse filters, which also enables us to enhance any spectral GNNs with our DSF framework. We showcase the proposed framework on three state-of-the-arts including GPR-GNN, BernNet, and JacobiConv. Extensive experiments over 10 benchmark datasets demonstrate that our framework can consistently boost model performance by up to 4.92% in node classification tasks, producing diverse filters with enhanced interpretability. Code is available at \url{https://github.com/jingweio/DSF}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.09041v2</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3543507.3583324</arxiv:DOI>
      <arxiv:journal_reference>Proceedings of the ACM Web Conference 2023</arxiv:journal_reference>
      <dc:creator>Jingwei Guo, Kaizhu Huang, Xinping Yi, Rui Zhang</dc:creator>
    </item>
    <item>
      <title>AceMap: Knowledge Discovery through Academic Graph</title>
      <link>https://arxiv.org/abs/2403.02576</link>
      <description>arXiv:2403.02576v2 Announce Type: replace-cross 
Abstract: The exponential growth of scientific literature requires effective management and extraction of valuable insights. While existing scientific search engines excel at delivering search results based on relational databases, they often neglect the analysis of collaborations between scientific entities and the evolution of ideas, as well as the in-depth analysis of content within scientific publications. The representation of heterogeneous graphs and the effective measurement, analysis, and mining of such graphs pose significant challenges. To address these challenges, we present AceMap, an academic system designed for knowledge discovery through academic graph. We present advanced database construction techniques to build the comprehensive AceMap database with large-scale academic entities that contain rich visual, textual, and numerical information. AceMap also employs innovative visualization, quantification, and analysis methods to explore associations and logical relationships among academic entities. AceMap introduces large-scale academic network visualization techniques centered on nebular graphs, providing a comprehensive view of academic networks from multiple perspectives. In addition, AceMap proposes a unified metric based on structural entropy to quantitatively measure the knowledge content of different academic entities. Moreover, AceMap provides advanced analysis capabilities, including tracing the evolution of academic ideas through citation relationships and concept co-occurrence, and generating concise summaries informed by this evolutionary process. In addition, AceMap uses machine reading methods to generate potential new ideas at the intersection of different fields. Exploring the integration of large language models and knowledge graphs is a promising direction for future research in idea evolution. Please visit \url{https://www.acemap.info} for further exploration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02576v2</guid>
      <category>cs.DL</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xinbing Wang, Luoyi Fu, Xiaoying Gan, Ying Wen, Guanjie Zheng, Jiaxin Ding, Liyao Xiang, Nanyang Ye, Meng Jin, Shiyu Liang, Bin Lu, Haiwen Wang, Yi Xu, Cheng Deng, Shao Zhang, Huquan Kang, Xingli Wang, Qi Li, Zhixin Guo, Jiexing Qi, Pan Liu, Yuyang Ren, Lyuwen Wu, Jungang Yang, Jianping Zhou, Chenghu Zhou</dc:creator>
    </item>
    <item>
      <title>Forward Learning of Graph Neural Networks</title>
      <link>https://arxiv.org/abs/2403.11004</link>
      <description>arXiv:2403.11004v2 Announce Type: replace-cross 
Abstract: Graph neural networks (GNNs) have achieved remarkable success across a wide range of applications, such as recommendation, drug discovery, and question answering. Behind the success of GNNs lies the backpropagation (BP) algorithm, which is the de facto standard for training deep neural networks (NNs). However, despite its effectiveness, BP imposes several constraints, which are not only biologically implausible, but also limit the scalability, parallelism, and flexibility in learning NNs. Examples of such constraints include storage of neural activities computed in the forward pass for use in the subsequent backward pass, and the dependence of parameter updates on non-local signals. To address these limitations, the forward-forward algorithm (FF) was recently proposed as an alternative to BP in the image classification domain, which trains NNs by performing two forward passes over positive and negative data. Inspired by this advance, we propose ForwardGNN in this work, a new forward learning procedure for GNNs, which avoids the constraints imposed by BP via an effective layer-wise local forward training. ForwardGNN extends the original FF to deal with graph data and GNNs, and makes it possible to operate without generating negative inputs (hence no longer forward-forward). Further, ForwardGNN enables each layer to learn from both the bottom-up and top-down signals without relying on the backpropagation of errors. Extensive experiments on real-world datasets show the effectiveness and generality of the proposed forward graph learning framework. We release our code at https://github.com/facebookresearch/forwardgnn.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11004v2</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Namyong Park, Xing Wang, Antoine Simoulin, Shuai Yang, Grey Yang, Ryan Rossi, Puja Trivedi, Nesreen Ahmed</dc:creator>
    </item>
    <item>
      <title>Predicting Mergers and Acquisitions: Temporal Dynamic Industry Networks</title>
      <link>https://arxiv.org/abs/2404.07298</link>
      <description>arXiv:2404.07298v2 Announce Type: replace-cross 
Abstract: M&amp;A activities are pivotal for market consolidation, enabling firms to augment market power through strategic complementarities. Existing research often overlooks the peer effect, the mutual influence of M&amp;A behaviors among firms, and fails to capture complex interdependencies within industry networks. Common approaches suffer from reliance on ad-hoc feature engineering, data truncation leading to significant information loss, reduced predictive accuracy, and challenges in real-world application. Additionally, the rarity of M&amp;A events necessitates data rebalancing in conventional models, introducing bias and undermining prediction reliability. We propose an innovative M&amp;A predictive model utilizing the Temporal Dynamic Industry Network (TDIN), leveraging temporal point processes and deep learning to adeptly capture industry-wide M&amp;A dynamics. This model facilitates accurate, detailed deal-level predictions without arbitrary data manipulation or rebalancing, demonstrated through superior evaluation results from M&amp;A cases between January 1997 and December 2020. Our approach marks a significant improvement over traditional models by providing detailed insights into M&amp;A activities and strategic recommendations for specific firms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07298v2</guid>
      <category>q-fin.ST</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <category>q-fin.GN</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Dayu Yang</dc:creator>
    </item>
  </channel>
</rss>
