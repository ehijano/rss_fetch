<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.TH</link>
    <description>econ.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 04 Dec 2024 02:55:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Extreme Points in Multi-Dimensional Screening</title>
      <link>https://arxiv.org/abs/2412.00649</link>
      <description>arXiv:2412.00649v1 Announce Type: new 
Abstract: This paper characterizes extreme points of the set of incentive-compatible mechanisms for screening problems with linear utility. Extreme points are exhaustive mechanisms, meaning their menus cannot be scaled and translated to make additional feasibility constraints binding. In problems with one-dimensional types, extreme points admit a tractable description with a tight upper bound on their menu size. In problems with multi-dimensional types, every exhaustive mechanism can be transformed into an extreme point by applying an arbitrarily small perturbation. For mechanisms with a finite menu, this perturbation displaces the menu items into general position. Generic exhaustive mechanisms are extreme points with an uncountable menu. Similar results hold in applications to delegation, veto bargaining, and monopoly problems, where we consider mechanisms that are unique maximizers for specific classes of objective functionals. The proofs involve a novel connection between menus of extreme points and indecomposable convex bodies, first studied by Gale (1954).</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00649v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Patrick Lahr, Axel Niemeyer</dc:creator>
    </item>
    <item>
      <title>A partial-state space model of unawareness</title>
      <link>https://arxiv.org/abs/2412.00897</link>
      <description>arXiv:2412.00897v1 Announce Type: new 
Abstract: We propose a model of unawareness that remains close to the paradigm of Aumann's model for knowledge [R. J. Aumann, International Journal of Game Theory 28 (1999) 263-300]: just as Aumann uses a correspondence on a state space to define an agent's knowledge operator on events, we use a correspondence on a state space to define an agent's awareness operator on events. This is made possible by three ideas. First, like the model of [A. Heifetz, M. Meier, and B. Schipper, Journal of Economic Theory 130 (2006) 78-94], ours is based on a space of partial specifications of the world, partially ordered by a relation of further specification or refinement, and the idea that agents may be aware of some coarser-grained specifications while unaware of some finer-grained specifications; however, our model is based on a different implementation of this idea, related to forcing in set theory. Second, we depart from a tradition in the literature, initiated by [S. Modica and A. Rustichini, Theory and Decision 37 (1994) 107-124] and adopted by Heifetz et al. and [J. Li, Journal of Economic Theory 144 (2009) 977-993], of taking awareness to be definable in terms of knowledge. Third, we show that the negative conclusion of a well-known impossibility theorem concerning unawareness in [Dekel, Lipman, and Rustichini, Econometrica 66 (1998) 159-173] can be escaped by a slight weakening of a key axiom. Together these points demonstrate that a correspondence on a partial-state space is sufficient to model unawareness of events. Indeed, we prove a representation theorem showing that any abstract Boolean algebra equipped with awareness, knowledge, and belief operators satisfying some plausible axioms is representable as the algebra of events arising from a partial-state space with awareness, knowledge, and belief correspondences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00897v1</guid>
      <category>econ.TH</category>
      <category>cs.LO</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wesley H. Holliday</dc:creator>
    </item>
    <item>
      <title>Tournaments with a Standard</title>
      <link>https://arxiv.org/abs/2412.01139</link>
      <description>arXiv:2412.01139v1 Announce Type: new 
Abstract: We study tournaments where winning a rank-dependent prize requires passing a minimum performance standard. We show that, for any prize allocation, the optimal standard is always at a mode of performance that is weakly higher than the global mode and identify a necessary and sufficient condition for it to be at the global mode. When the prize scheme can be designed as well, the winner-take-all prize scheme is optimal for noise distributions with an increasing failure rate; and awarding equal prizes to all qualifying agents is optimal for noise distributions with a decreasing failure rate. For distributions with monotone likelihood ratios -- log-concave and log-convex, respectively -- these pay schemes are also optimal in a larger class of anonymous, monotone contracts that may depend on cardinal performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01139v1</guid>
      <category>econ.TH</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mikhail Drugov, Dmitry Ryvkin, Jun Zhang</dc:creator>
    </item>
    <item>
      <title>Capacity Constraints in Principal-Agent Problems</title>
      <link>https://arxiv.org/abs/2412.01760</link>
      <description>arXiv:2412.01760v1 Announce Type: new 
Abstract: Adding a capacity constraint to a hidden-action principal-agent problem results in the same set of Pareto optimal contracts as the unconstrained problem where output is scaled down by a constant factor. This scaling factor is increasing in the agent's capacity to exert effort.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01760v1</guid>
      <category>econ.TH</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aubrey Clark</dc:creator>
    </item>
    <item>
      <title>The use of knowledge in open-ended systems</title>
      <link>https://arxiv.org/abs/2412.00011</link>
      <description>arXiv:2412.00011v1 Announce Type: cross 
Abstract: Economists model knowledge use and acquisition as a cause-and-effect calculus associating observations made by a decision-maker about their world with possible underlying causes. Knowledge models are well-established for static contexts, but not for contexts of innovative and unbounded change. We develop a representation of knowledge use and acquisition in open-ended evolutionary systems and demonstrate its primary results, including that observers embedded in open-ended evolutionary systems can agree to disagree and that their ability to theorize about their systems is fundamentally local and constrained to their frame of reference what we call frame relativity. The results of our framework formalize local knowledge use, the many-selves interpretation of reasoning through time, and motivate the emergence of nonlogical modes of reasoning like institutional and aesthetic codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00011v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <category>econ.TH</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abigail Devereaux, Roger Koppl</dc:creator>
    </item>
    <item>
      <title>Anticomonotonicity for Preference Axioms: The Natural Counterpart to Comonotonicity</title>
      <link>https://arxiv.org/abs/2307.08542</link>
      <description>arXiv:2307.08542v3 Announce Type: replace 
Abstract: Comonotonicity (``same variation'') of random variables minimizes hedging possibilities and has been widely used, e.g., in Gilboa and Schmeidler's ambiguity models. This paper investigates anticomonotonicity (``opposite variation''; abbreviated ``AC''), the natural counterpart to comonotonicity. It minimizes leveraging rather than hedging possibilities. Surprisingly, AC restrictions of several traditional axioms do not give new models. Instead, they strengthen the foundations of existing classical models: (a) linear functionals through Cauchy's equation; (b) Anscombe-Aumann expected utility; (c) as-if-risk-neutral pricing through no-arbitrage; (d) de Finetti's bookmaking foundation of Bayesianism using subjective probabilities; (e) risk aversion in Savage's subjective expected utility. In each case, our generalizations show where the critical tests of classical axioms lie: in the AC cases (maximal hedges). We next present examples where AC restrictions do essentially weaken existing axioms, and do provide new properties and new models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.08542v3</guid>
      <category>econ.TH</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giulio Principi, Peter P. Wakker, Ruodu Wang</dc:creator>
    </item>
    <item>
      <title>The Limits of Identification in Discrete Choice</title>
      <link>https://arxiv.org/abs/2403.13773</link>
      <description>arXiv:2403.13773v3 Announce Type: replace 
Abstract: This paper uncovers tight bounds on the number of preferences permissible in identified random utility models. We show that as the number of alternatives in a discrete choice model becomes large, the fraction of preferences admissible in an identified model rapidly tends to zero. We propose a novel sufficient condition ensuring identification, which is strictly weaker than some of those existing in the literature. While this sufficient condition reaches our upper bound, an example demonstrates that this condition is not necessary for identification. Using our new condition, we show that the classic ``Latin Square" example from social choice theory is identified from stochastic choice data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.13773v3</guid>
      <category>econ.TH</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Christopher P. Chambers, Christopher Turansick</dc:creator>
    </item>
    <item>
      <title>Fair Combinatorial Auction for Blockchain Trade Intents: Being Fair without Knowing What is Fair</title>
      <link>https://arxiv.org/abs/2408.12225</link>
      <description>arXiv:2408.12225v2 Announce Type: replace 
Abstract: Blockchain trade intent auctions currently intermediate approximately USD 5 billion monthly. Due to production complementarities, the auction is combinatorial: when multiple trade intents from different traders are auctioned off simultaneously, a bidder (here called solver) can generate additional efficiencies by winning a batch of multiple trade intents. However, sharing these additional efficiencies between traders is problematic: because of market frictions and fees (solvers' private information), the auctioneer does not know how much each trader would have received had its trade been auctioned off individually. We formalize this problem and study the most commonly used auction formats: batch auctions and multiple simultaneous auctions. We also propose a novel fair combinatorial auction that combines batch auction and multiple simultaneous auctions: solvers submit individual-trade bids and batched bids, but batched bids are considered only if they are better for all traders relative to the outcome of the simultaneous auctions constructed using the individual-trade bids. We find a trade-off between the fairness guarantees provided in equilibrium by the auction (i.e., the minimum each trader can expect to receive) and the expected value of the assets returned to the traders. Also, the amount that each trader receives in the equilibrium of the fair combinatorial auction may be higher or lower than what they receive in the equilibrium of the simultaneous auctions used as a benchmark for fairness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12225v2</guid>
      <category>econ.TH</category>
      <category>cs.DC</category>
      <category>cs.GT</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Andrea Canidio, Felix Henneke</dc:creator>
    </item>
    <item>
      <title>Equitable Core Imputations via a New Adaptation of The Primal-Dual Framework</title>
      <link>https://arxiv.org/abs/2402.11437</link>
      <description>arXiv:2402.11437v4 Announce Type: replace-cross 
Abstract: The classic paper of Shapley and Shubik \cite{Shapley1971assignment} characterized the core of the assignment game. We observe that a sub-coalition consisting of one player (or a set of players from the same side of the bipartition) can make zero profit, and therefore its profit under a core imputation can be an arbitrary amount. Hence an arbitrary core imputation makes {\em no fairness guarantee at the level of individual agents}. Can this deficiency be addressed by picking a ``good'' core imputation?
  To arrive at an appropriate solution concept, we give specific criteria for picking a special core imputation, and we undertake a detailed comparison of four solution concepts. Leximin and leximax core imputations come out as clear winners; we define these to be {\em equitable core imputations}. These imputations achieve ``fairness'' in different ways: whereas leximin tries to make poor agents more rich, leximax tries to make rich agents less rich.
  We give combinatorial strongly polynomial algorithms for computing these imputations via a novel adaptation of the classical primal-dual paradigm. The ``engine'' driving them involves insights into core imputations obtained via complementarity. It will not be surprising if our work leads to new uses of this powerful technique. Furthermore, we expect more work on computing the leximin and leximax core imputations of other natural games, in addition to the recent follow-up work \cite{Leximin-max}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.11437v4</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vijay V. Vazirani</dc:creator>
    </item>
  </channel>
</rss>
