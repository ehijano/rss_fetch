<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 19 Dec 2025 02:41:58 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Mixed-Integer Linear Programming Approximations for the Stochastic Knapsack</title>
      <link>https://arxiv.org/abs/2512.14912</link>
      <description>arXiv:2512.14912v1 Announce Type: new 
Abstract: We develop a novel mathematical programming approximation framework to tackle the stochastic knapsack problem. In this problem, the decision maker considers items for which either weights or values, or both, are random. The aim is to select a subset of these items to be included into their knapsack. We study both "static" and "dynamic" variants of this problem: in the static setting, the decision about which items should be included in the knapsack is taken at the outset, before any random item value or weight is revealed; in the dynamic setting, items are received sequentially, and the decision about a particular item is made by taking into account previously observed values and weights. The knapsack has a given capacity, and if the total realised weight exceeds this capacity then a penalty cost is incurred for each unit of excess capacity utilised. The goal is to maximise the expected net profit. We tackle the case of normally distributed item weights and we show that our approach extends seamlessly to the case in which item weights are correlated and follow a multivariate normal distribution. In addition, we show our approach represents an effective heuristic for the case in which item weights follow generic probability distributions. In an extensive computational study we demonstrate that our models are near-optimal and more scalable than other state-of-the-art approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14912v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roberto Rossi, Steven D. Prestwich, S. Armagan Tarim</dc:creator>
    </item>
    <item>
      <title>A Parameter-Free Stochastic LineseArch Method (SLAM) for Minimizing Expectation Residuals</title>
      <link>https://arxiv.org/abs/2512.14979</link>
      <description>arXiv:2512.14979v1 Announce Type: new 
Abstract: Most existing rate and complexity guarantees for stochastic gradient methods in $L$-smooth settings mandates that such sequences be non-adaptive, non-increasing, and upper bounded by $\tfrac{a}{L}$ for $a &gt; 0$. This requires knowledge of $L$ and may preclude larger steps. Motivated by these shortcomings, we present an Armijo-enabled stochastic linesearch framework with standard stochastic zeroth- and first-order oracles. The resulting steplength sequence is non-monotone and requires neither knowledge of $L$ nor any other problem parameters. We then prove that the expected stationarity residual diminishes at a rate of $\mathcal{O}(1/\sqrt{K})$, where $K$ denotes the iteration budget. Furthermore, the resulting iteration and sample complexities for computing an $\epsilon$-stationary point are $\mathcal{O}(\epsilon^{-2})$ and $\mathcal{O}\left(\epsilon^{-4}\right)$. The proposed method allows for a simple nonsmooth convex component in the objective, addressed through proximal gradient updates. Analogous guarantees are provided in the Polyak-Lojasiewicz (PL) setting and convex regimes. Preliminary numerical experiments are seen to be promising.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14979v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qi Wang, Uday V. Shanbhag, Yue Xie</dc:creator>
    </item>
    <item>
      <title>QUBO Formulations for MIP Symmetry Detection</title>
      <link>https://arxiv.org/abs/2512.15070</link>
      <description>arXiv:2512.15070v1 Announce Type: new 
Abstract: Formulation symmetry in mixed-integer programming (MIP) can hinder solver performance by inducing redundant search, but detecting such symmetries is also a significant computational challenge. This paper explores the potential for quantum computing to handle symmetry detection. Quantum is a promising alternative to classical compute, but this emerging technology has limited hardware capacity in terms of input problem size. This paper explores the use of Quadratic Unconstrained Binary Optimization (QUBO) models for symmetry detection, as QUBO is the canonical format for quantum optimization platforms. To help address the input size bottleneck, we develop full, reduced, and decomposed QUBO as well as QUBO-Plus formulations for MIP symmetry detection. Computational experiments on the MIPLIB 2017 benchmark are used to estimate the quantum computing resources needed for practical problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15070v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander While, Chen Chen</dc:creator>
    </item>
    <item>
      <title>Control of kinetic opinion dynamics in popularity-adaptive social networks</title>
      <link>https://arxiv.org/abs/2512.15165</link>
      <description>arXiv:2512.15165v1 Announce Type: new 
Abstract: This paper presents a mathematical model for opinion dynamics in popularity-adaptive social networks, where both opinion spreading and the evolution of social media contacts depend on agents' popularity and the prominence of their views. While previous approaches accounted for the influence of popularity on opinion dynamics, we introduce a novel feedback mechanism in which opinion affects the formation of contacts. Within a kinetic modeling framework, we describe the evolution of the coupled dynamics of opinions and network structure, incorporating a class of control laws in order to promote interactions with popular individuals and amplify dominant opinions. Such control strategies are introduced to influence both opinion formation and connectivity, representing interventions such as awareness campaigns or moderation policies. Numerical results show how control strategies can mitigate polarization, foster consensus, or guide opinion distributions in dynamically evolving networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15165v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giacomo Albi, Elisa Calzola, Matteo Piu</dc:creator>
    </item>
    <item>
      <title>Long-Run Average Reward Maximization of A Regulated Regime-Switching Diffusion Model</title>
      <link>https://arxiv.org/abs/2512.15167</link>
      <description>arXiv:2512.15167v1 Announce Type: new 
Abstract: This study considers an optimal reinsurance, investment, and dividend strategy control problem for insurance companies in a regulated Markov regime-switching environment, intending to maximize long-run average reward. Unlike existing single or dual strategy studies, an integrated control framework is established under solvency constraints, allowing investment and dividends only when the surplus process exceeds a minimum cash requirement level. To address the analytical difficulties associated with solving HJB equations and stationary distributions in high-dimensional state spaces under regime switching, we construct a numerical approximation scheme for the optimal strategy function based on Markov chains and neural networks. Furthermore, we establish the convergence of the corresponding sequence of surplus processes and rigorously prove that the associated optimal values converge to the true value function. Finally, we provide a numerical example based on the approximate dynamic programming method to demonstrate the feasibility of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15167v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lingjia Zeng, Manman Li</dc:creator>
    </item>
    <item>
      <title>Historical Information Accelerates Decentralized Optimization: A Proximal Bundle Method</title>
      <link>https://arxiv.org/abs/2512.15189</link>
      <description>arXiv:2512.15189v2 Announce Type: new 
Abstract: Historical information, such as past function values or gradients, has significant potential to enhance decentralized optimization methods for two key reasons: first, it provides richer information about the objective function, which also explains its established success in centralized optimization; second, unlike the second-order derivative or its alternatives, historical information has already been computed or communicated and requires no additional cost to acquire. Despite this potential, it remains underexploited. In this work, we employ a proximal bundle framework to incorporate the function values and gradients at historical iterates and adapt the framework to the proximal decentralized gradient descent method, resulting in a Decentralized Proximal Bundle Method (DPBM). To broaden its applicability, we further extend DPBM to the asynchronous and stochastic setting. We theoretically analysed the convergence of the proposed methods. Notably, both the asynchronous DPBM and its stochastic variant can converge with fixed step-sizes that are independent of delays, which is superior to the delay-dependent step-sizes required by most existing asynchronous optimization methods, as it is easier to determine and often leads to faster convergence. Numerical experiments on classification problems demonstrate that by using historical information, our methods yield faster convergence and stronger robustness in the step-sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15189v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhao Zhu, Yu-Ping Tian, Xuyang Wu</dc:creator>
    </item>
    <item>
      <title>A Regression-Based Prediction-Correction Method for Stochastic Time-Varying Optimization Problems</title>
      <link>https://arxiv.org/abs/2512.15205</link>
      <description>arXiv:2512.15205v1 Announce Type: new 
Abstract: In many real-world applications, optimization problems evolve continuously over time and are often subject to stochastic noise. We consider a stochastic time-varying optimization problem in which the objective function $f(x;t)$ changes continuously and only noisy gradient observations are available. In deterministic settings, the prediction-correction method that exploits the time derivative of the solution is effective for accurately tracking the solution trajectory. However, a straightforward extension to stochastic problems requires an estimate of $\nabla_{xt} f(x;t)$ and the computation of a Hessian inverse at each step--requirements that are difficult or costly in practice. To address these issues, we propose a prediction-correction algorithm that uses a regression-based prediction step: the prediction is formed as a linear combination of recent iterates, which can be computed efficiently without estimating $\nabla_{xt}f(x;t)$ or computing Hessian inversions. We prove a tracking-error bound for the proposed method under standard smoothness and stochastic assumptions. Numerical experiments show that the regression-based prediction improves tracking accuracy while reducing computational cost compared with existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15205v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tomoya Kamijima, Naoki Marumo, Akiko Takeda</dc:creator>
    </item>
    <item>
      <title>On Computing and Pricing of Adjustable Robust Chemical Process Designs</title>
      <link>https://arxiv.org/abs/2512.15318</link>
      <description>arXiv:2512.15318v1 Announce Type: new 
Abstract: Model-based process simulation can be used to derive designs and operating conditions of chemical processes that optimally balance multiple objectives, such as quality, costs, or environmental impacts. This work focuses on identifying designs that hedge against uncertainties in model parameters to ensure feasibility, taking the possibility to adjust operating conditions into account. An adaptive scheme is proposed to pinpoint the relevant scenarios in a discretized uncertainty space; these scenarios are then fed into a multi-objective adjustable robust optimization framework reducing the computational burden compared to the consideration of all potential scenarios. Furthermore, we propose a method to quantify the cost or price of robustness, i.e., the compromise which has to be made in comparison to the nominal design case in order to hedge against uncertainty. The conceptual findings are illustrated with an industrially relevant case study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15318v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jan Schwientek, Katrin Teichert, Jan Schr\"oder, Johannes H\"oller, Patrick Schwartz, Norbert Asprion, Pascal Sch\"afer, Martin Wlotzka, Michael Bortz</dc:creator>
    </item>
    <item>
      <title>Gaussian Process Dual MPC using Active Inference: An Autonomous Vehicle Usecase</title>
      <link>https://arxiv.org/abs/2512.15381</link>
      <description>arXiv:2512.15381v1 Announce Type: new 
Abstract: Designing controllers under uncertainty requires balancing the need to explore system dynamics with the requirement to maintain reliable control performance. Dual control addresses this challenge by selecting actions that both regulate the system and actively gather informative data. This paper investigates the use of the Active Inference framework, grounded in the Free Energy Principle, for developing a dual model-predictive controller (MPC). To identify and quantify uncertainty, we introduce an online sparse semi-parametric Gaussian Process model that combines the flexibility of nonparametric with the efficiency of parametric learning for real-time updates. By applying the expected free energy functional to this adaptive probabilistic model, we derive an MPC objective that incorporates an information-theoretic term, which captures uncertainty arising from both the learned model and measurement noise. This formulation leads to a stochastic optimal control problem for dual controller design, which is solved using a novel dynamic-programming-based method. Simulation results on a vehicle use case demonstrate that the proposed algorithm enhances autonomous driving control performance across different settings and scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15381v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mohammad Mahmoudi Filabadi, Guillaume Crevecoeur, Tom Lefebvre</dc:creator>
    </item>
    <item>
      <title>Asymptotic behaviour of stochastic inertial dynamics incorporating a Tikhonov regularization term</title>
      <link>https://arxiv.org/abs/2512.15392</link>
      <description>arXiv:2512.15392v1 Announce Type: new 
Abstract: In a separable Hilbert space, we study the minimization problem of a convex smooth function with Lipschitz continuous gradient whose evaluations are corrupted by random noise. To this end, we associate a stochastic inertial system that incorporates Tikhonov regularization with the optimization problem. We establish existence and uniqueness of a solution trajectory for this system. Then, we derive an upper bound on the expected value of an appropriate associated energy function given square-integrability of the diffusion $\sigma_X$ before focusing on the particular case where the parameter function multiplied by the Tikhonov term is given by $\frac{1}{t^r}$ for $0&lt;r&lt;2$. For this setting, we show a.s. convergence rates as well as convergence rates in expectation for the function values along the trajectory to an infimal value, the trajectory process to an optimal solution and its time derivative to zero under a stronger integrability condition on $\sigma_X$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15392v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chiara Schindler</dc:creator>
    </item>
    <item>
      <title>Robustness Measures for Stochastic Parallel Machine Scheduling and Train Unit Shunting</title>
      <link>https://arxiv.org/abs/2512.15471</link>
      <description>arXiv:2512.15471v1 Announce Type: new 
Abstract: In many real world scheduling problems, the processing times of tasks are subject to uncertainty. This makes it essential to design schedules that are robust and able to handle potential disruptions. Therefore, we investigate measures that give us information about the robustness of a schedule. Although many measures can be found in literature, there is no consensus on which measures are the best. We identify 14 robustness measures from the literature, as well as introduce 4 new ones. To find out which of these measures are best used for generating robust schedules, we perform an elaborate simulation study to investigate how well these robustness measures correlate with the stability of the objective function under disturbances (quality robustness) and with the stability of the schedule itself (solution robustness). We first consider the Stochastic Parallel Machine Scheduling Problem (SPMSP) with precedence constraints, which is a very general setting that is relevant for many practical situations. We then perform a second simulation study by taking the best performing measures from the first experiment, and using them for the Train Unit Shunting Problem with Service Scheduling (TUSPwSS). After establishing the correlation with quality and solution robustness, we included the measures as objective in a local search algorithm. We make a comparison between the theoretical setting of the SPMSP and the TUSPwSS, and identify a set of robustness measures that can be applied in many different settings. We show that we can achieve up to 90% decreases in delays compared to using no robustness measures. Lastly, we also identify properties that can be used to predict the effectiveness of such a robustness measure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15471v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Casper Loman, Loriana Pascual, Marjan van den Akker, Roel van den Broek, Han Hoogeveen</dc:creator>
    </item>
    <item>
      <title>Exact Learning of Linear Model Predictive Control Laws using Oblique Decision Trees with Linear Predictions</title>
      <link>https://arxiv.org/abs/2512.15568</link>
      <description>arXiv:2512.15568v1 Announce Type: new 
Abstract: Model Predictive Control (MPC) is a powerful strategy for constrained multivariable systems but faces computational challenges in real-time deployment due to its online optimization requirements. While explicit MPC and neural network approximations mitigate this burden, they suffer from scalability issues or lack interpretability, limiting their applicability in safety-critical systems. This work introduces a data-driven framework that directly learns the Linear MPC control law from sampled state-action pairs using Oblique Decision Trees with Linear Predictions (ODT-LP), achieving both computational efficiency and interpretability. By leveraging the piecewise affine structure of Linear MPC, we prove that the Linear MPC control law can be replicated by finite-depth ODT-LP models. We develop a gradient-based training algorithm using smooth approximations of tree routing functions to learn this structure from grid-sampled Linear MPC solutions, enabling end-to-end optimization. Input-to-state stability is established under bounded approximation errors, with explicit error decomposition into learning inaccuracies and sampling errors to inform model design. Numerical experiments demonstrate that ODT-LP controllers match MPC's closed-loop performance while reducing online evaluation time by orders of magnitude compared to MPC, explicit MPC, neural network, and random forest counterparts. The transparent tree structure enables formal verification of control logic, bridging the gap between computational efficiency and certifiable reliability for safety-critical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15568v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiayang Ren, Qiangqiang Mao, Tianwei Zhao, Yankai Cao</dc:creator>
    </item>
    <item>
      <title>Hybrid Set-Seeking Systems: Model-Free Feedback Optimization via Hybrid Inclusions</title>
      <link>https://arxiv.org/abs/2512.15678</link>
      <description>arXiv:2512.15678v1 Announce Type: new 
Abstract: This article aims to provide an accessible, tutorial-style introduction to hybrid extremum-seeking systems, which are model-free, feedback-optimization controllers that incorporate hybrid dynamics, meaning both continuous-time and discrete-time behaviors. Such systems arise when advanced control and optimization tools are needed to overcome the limitations of smooth feedback methods and to satisfy demanding transient and steady-state requirements in high-performance applications. They also appear when controllers must operate on plants that inherently exhibit hybrid behaviors, as is common in cyber-physical and autonomous systems that rely on digital sensing, computation, and actuation. To study hybrid extremum-seeking dynamics through control-theoretic methods, we first review the key concepts that support the development of perturbation theory for hybrid inclusions, forming the basis for averaging and singular perturbation analyses. We then show how these ideas apply to the design and evaluation of hybrid extremum-seeking algorithms for static and dynamic plants. Several examples are presented, including set-valued and switching algorithms under different switching regimes such as arbitrarily fast switching, dwell-time and average dwell-time constraints, and average activation time conditions. We also discuss state-based switching extremum seeking for obstacle-avoidance problems and gradient-Newton switching schemes. Additional topics include momentum-based and reset-type extremum seeking, intermittent updates, slowly varying parameters, hybrid filters, and safety-aware schemes that incorporate constraints. Across all these settings, we illustrate how perturbation-based methods traditionally used for extremum-seeking control naturally extend to hybrid systems when mild regularity assumptions are satisfied, and solutions are modeled on hybrid time domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15678v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jorge I. Poveda, Andrew R. Teel</dc:creator>
    </item>
    <item>
      <title>Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes</title>
      <link>https://arxiv.org/abs/2512.14991</link>
      <description>arXiv:2512.14991v1 Announce Type: cross 
Abstract: We study reinforcement learning for controlled diffusion processes with unbounded continuous state spaces, bounded continuous actions, and polynomially growing rewards: settings that arise naturally in finance, economics, and operations research. To overcome the challenges of continuous and high-dimensional domains, we introduce a model-based algorithm that adaptively partitions the joint state-action space. The algorithm maintains estimators of drift, volatility, and rewards within each partition, refining the discretization whenever estimation bias exceeds statistical confidence. This adaptive scheme balances exploration and approximation, enabling efficient learning in unbounded domains. Our analysis establishes regret bounds that depend on the problem horizon, state dimension, reward growth order, and a newly defined notion of zooming dimension tailored to unbounded diffusion processes. The bounds recover existing results for bounded settings as a special case, while extending theoretical guarantees to a broader class of diffusion-type problems. Finally, we validate the effectiveness of our approach through numerical experiments, including applications to high-dimensional problems such as multi-asset mean-variance portfolio selection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14991v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>q-fin.PM</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hanqing Jin, Renyuan Xu, Yanzhao Yang</dc:creator>
    </item>
    <item>
      <title>Intertemporal Hedging Demand under Epstein-Zin Preferences in a Multi-Asset Long-Run Risk Model: Evidence from Projected Pontryagin-Guided Deep Policy Optimization</title>
      <link>https://arxiv.org/abs/2512.15175</link>
      <description>arXiv:2512.15175v1 Announce Type: cross 
Abstract: I study intertemporal hedging demand in a continuous-time multi-asset long-run risk (LRR) model under Epstein--Zin (EZ) recursive preferences. The investor trades a risk-free asset and several risky assets whose drifts and volatilities depend on an Ornstein--Uhlenbeck type LRR factor. Preferences are described by EZ utility with risk aversion $R$, elasticity of intertemporal substitution $\psi$, and discount rate $\delta$, so that the standard time-additive CRRA case appears as a limiting benchmark.
  To handle the high-dimensional consumption--investment problem, I use a projected Pontryagin-guided deep policy optimization (P-PGDPO) scheme adapted to EZ preferences. The method starts from the continuous-time Hamiltonian implied by the Pontryagin maximum principle, represents the value and costate processes with neural networks, and updates the policy along the Hamiltonian gradient. Portfolio constraints and a lower bound on wealth are enforced by explicit projection operators rather than by adding ad hoc penalties.
  Three main findings emerge from numerical experiments in a five-asset LRR economy: \textbf{(1)} the P-PGDPO algorithm achieves stable convergence across multiple random seeds, validating its reliability for solving high-dimensional EZ problems; \textbf{(2)} wealth floors materially reduce hedging demand by limiting the investor's ability to exploit intertemporal risk-return tradeoffs; and \textbf{(3)} the learned hedging portfolios concentrate exposure in assets with high correlation to the LRR factor, confirming that EZ agents actively hedge long-run uncertainty rather than merely following myopic rules. Because EZ preferences nest time-additive CRRA in the limit $\psi \to 1/R$, I use CRRA as an explicit diagnostic benchmark and, when needed, a warm start to stabilize training in high dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15175v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Wonchan Cho</dc:creator>
    </item>
    <item>
      <title>A Clustering-Based Variable Ordering Framework for Relaxed Decision Diagrams for Maximum Weighted Independent Set Problem</title>
      <link>https://arxiv.org/abs/2512.15198</link>
      <description>arXiv:2512.15198v1 Announce Type: cross 
Abstract: Efficient exact algorithms for Discrete Optimization (DO) rely heavily on strong primal and dual bounds. Relaxed Decision Diagrams (DDs) provide a versatile mechanism for deriving such dual bounds by compactly over-approximating the solution space through node merging. However, the quality of these relaxed diagrams, i.e. the tightness of the resulting dual bounds, depends critically on the variable ordering and the merging decisions executed during compilation. While dynamic variable ordering heuristics effectively tighten bounds, they often incur computational overhead when evaluated globally across the entire variable set. To mitigate this trade-off, this work introduces a novel clustering-based framework for variable ordering. Instead of applying dynamic ordering heuristics to the full set of unfixed variables, we first partition variables into clusters. We then leverage this structural decomposition to guide the ordering process, significantly reducing the heuristic's search space. Within this framework, we investigate two distinct strategies: Cluster-to-Cluster, which processes clusters sequentially using problem-specific aggregate criteria (such as cumulative vertex weights in the Maximum Weighted Independent Set Problem (MWISP)), and Pick-and-Sort, which iteratively selects and sorts representative variables from each cluster to balance local diversity with heuristic guidance. Later on, developing some theoretical results on the growth of the size of DDs for MWISP we propose two different policies for setting the number of clusters within the proposed framework. We embed these strategies into a DD-based branch-and-bound algorithm and evaluate them on the MWISP. Across benchmark instances, the proposed methodology consistently reduces computational costs compared to standard dynamic variable ordering baseline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15198v1</guid>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohsen Nafar, Michael R\"omer, Lin Xie</dc:creator>
    </item>
    <item>
      <title>Explicit Solution to a government debt reduction problem: a stochastic control approach</title>
      <link>https://arxiv.org/abs/2512.15296</link>
      <description>arXiv:2512.15296v1 Announce Type: cross 
Abstract: We analyze the problem of optimal reduction of the debt-to-GDP ratio in a stochastic control setting. The debt-to-GDP dynamics are modeled through a stochastic differential equation in which fiscal policy simultaneously affects both debt accumulation and GDP growth. A key feature of the framework is the introduction of a cost functional that captures the disutility of fiscal surpluses and the perceived benefit of fiscal deficits, thus incorporating the macroeconomic trade-off between tighten and expansionary policies. By applying the Hamilton-Jacobi-Bellman approach, we provide explicit solutions in the case of linear GDP response to the fiscal policies. We rigorously analyze threshold-type fiscal strategies in the case of linear impact of the fiscal policy and provide closed-form solutions for the associated value function in relevant regimes. A sensitivity analysis is conducted by varying key model parameters, confirming the robustness of our theoretical findings. The application to debt reduction highlights how fiscal costs and benefits influence optimal interventions, offering valuable insights into sustainable public debt management under uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15296v1</guid>
      <category>econ.GN</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>q-fin.EC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Claudia Ceci, Luca Semerari</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning Methods for the Stochastic Optimal Control of an Industrial Power-to-Heat System</title>
      <link>https://arxiv.org/abs/2411.02211</link>
      <description>arXiv:2411.02211v3 Announce Type: replace 
Abstract: The optimal control of sustainable energy supply systems, including renewable energies and energy storage, takes a central role in the decarbonization of industrial systems. However, the use of fluctuating renewable energies leads to fluctuations in energy generation and requires a suitable control strategy for the complex systems in order to ensure energy supply. In this paper, we consider an electrified power-to-heat system which is designed to supply heat in form of superheated steam for industrial processes. The system consists of a high-temperature heat pump for heat supply, a wind turbine for power generation, a sensible thermal energy storage for storing excess heat and a steam generator for providing steam. If the system's energy demand cannot be covered by electricity from the wind turbine, additional electricity must be purchased from the power grid. For this system, we investigate the cost-optimal operation aiming to minimize the electricity cost from the grid by a suitable system control depending on the available wind power and the amount of stored thermal energy. This is a decision making problem under uncertainties about the future prices for electricity from the grid and the future generation of wind power. The resulting stochastic optimal control problem is treated as finite-horizon Markov decision process for a multi-dimensional controlled state process. We first consider the classical backward recursion technique for solving the associated dynamic programming equation for the value function and compute the optimal decision rule. Since that approach suffers from the curse of dimensionality we also apply reinforcement learning techniques, namely Q-learning, that are able to provide a good approximate solution to the optimization problem within reasonable time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02211v3</guid>
      <category>math.OC</category>
      <category>q-fin.CP</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eric Pilling, Martin B\"ahr, Ralf Wunderlich</dc:creator>
    </item>
    <item>
      <title>Deterministic Global Optimization of the Acquisition Function in Bayesian Optimization: To Do or Not To Do?</title>
      <link>https://arxiv.org/abs/2503.03625</link>
      <description>arXiv:2503.03625v2 Announce Type: replace 
Abstract: Bayesian Optimization (BO) with Gaussian Processes relies on optimizing an acquisition function to determine sampling. We investigate the advantages and disadvantages of using a deterministic global solver (MAiNGO) compared to conventional local and stochastic global solvers (L-BFGS-B and multi-start, respectively) for the optimization of the acquisition function. For CPU efficiency, we set a time limit for MAiNGO, taking the best point as optimal. We perform repeated numerical experiments, initially using the Muller-Brown potential as a benchmark function, utilizing the lower confidence bound acquisition function; we further validate our findings with three alternative benchmark functions. Statistical analysis reveals that when the acquisition function is more exploitative (as opposed to exploratory), BO with MAiNGO converges in fewer iterations than with the local solvers. However, when the dataset lacks diversity, or when the acquisition function is overly exploitative, BO with MAiNGO, compared to the local solvers, is more likely to converge to a local rather than a global ly near-optimal solution of the black-box function. L-BFGS-B and multi-start mitigate this risk in BO by introducing stochasticity in the selection of the next sampling point, which enhances the exploration of uncharted regions in the search space and reduces dependence on acquisition function hyperparameters. Ultimately, suboptimal optimization of poorly chosen acquisition functions may be preferable to their optimal solution. When the acquisition function is more exploratory, BO with MAiNGO, multi-start, and L-BFGS-B achieve comparable probabilities of convergence to a globally near-optimal solution (although BO with MAiNGO may require more iterations to converge under these conditions).</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03625v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anastasia Georgiou, Daniel Jungen, Luise Kaven, Verena Hunstig, Constantine Frangakis, Ioannis Kevrekidis, Alexander Mitsos</dc:creator>
    </item>
    <item>
      <title>Optimal mixed fleet and charging infrastructure planning to electrify demand responsive feeder services with target CO2 emission constraints</title>
      <link>https://arxiv.org/abs/2503.13085</link>
      <description>arXiv:2503.13085v2 Announce Type: replace 
Abstract: Electrifying demand-responsive transport systems need to plan the charging infrastructure carefully, considering the trade-offs of charging efficiency and charging infrastructure costs. Earlier studies assume a fully electrified fleet and overlook the planning issue in the transition period. This study addresses the joint fleet size and charging infrastructure planning for a demand-responsive feeder service under stochastic demand, given a user-defined targeted CO2 emission reduction policy. We propose a bi-level optimization model where the upper-level determines charging station configuration given stochastic demand patterns, whereas the lower-level solves a mixed fleet dial-a-ride routing problem under the CO2 emission and capacitated charging station constraints. An efficient deterministic annealing metaheuristic is proposed to solve the CO2-constrained mixed fleet routing problem. The performance of the algorithm is validated by a series of numerical test instances with up to 500 requests. We apply the model for a real-world case study in Bettembourg, Luxembourg, with different demand and customised CO2 reduction targets. The results show that the proposed method provides a flexible tool for joint charging infrastructure and fleet size planning under different levels of demand and CO2 emission reduction targets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13085v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.apenergy.2025.127216</arxiv:DOI>
      <dc:creator>Haruko Nakao, Tai-Yu Ma, Richard D. Connors, Francesco Viti</dc:creator>
    </item>
    <item>
      <title>Accelerated Decentralized Constraint-Coupled Optimization: A Dual$^2$ Approach</title>
      <link>https://arxiv.org/abs/2505.03719</link>
      <description>arXiv:2505.03719v3 Announce Type: replace 
Abstract: In this paper, we focus on a class of decentralized constraint-coupled optimization problem: $\min_{x_i \in \mathbb{R}^{d_i}, i \in \mathcal{I}; y \in \mathbb{R}^p}$ $\sum_{i=1}^n\left(f_i(x_i) + g_i(x_i)\right) + h(y) \ \text{s.t.} \ \sum_{i=1}^{n}A_ix_i = y$, over an undirected and connected network of $n$ agents. Here, $f_i$, $g_i$, and $A_i$ represent private information of agent $i \in \mathcal{I} = \{1, \cdots, n\}$, while $h$ is public for all agents. Building on a novel dual$^2$ approach, we develop two accelerated algorithms to solve this problem: the inexact Dual$^2$ Accelerated (iD2A) gradient method and the Multi-consensus inexact Dual$^2$ Accelerated (MiD2A) gradient method. We demonstrate that both iD2A and MiD2A can guarantee asymptotic convergence under a milder condition on $h$ compared to existing algorithms. Furthermore, under additional assumptions, we establish linear convergence rates and derive significantly lower communication and computational complexity bounds than those of existing algorithms. Several numerical experiments validate our theoretical analysis and demonstrate the practical superiority of the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03719v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingwang Li, Vincent Lau</dc:creator>
    </item>
    <item>
      <title>Null controllability of the 1D heat equation with interior inverse square potential</title>
      <link>https://arxiv.org/abs/2505.07302</link>
      <description>arXiv:2505.07302v2 Announce Type: replace 
Abstract: This paper aims to answer an open problem posed by Morancey in 2015 concerning the null controllability of the heat equation on (-1, 1) with an internal inverse square potential located at x = 0. For the range of singularity under study, after having introduced a suitable self-adjoint extension that enables to transmit information from one side of the singularity to another, we prove null-controllability in arbitrary small time, firstly with an internal control supported in an arbitrary measurable set of positive measure, secondly with a boundary control acting on one side of the boundary. Our proof is mainly based on a precise spectral study of the singular operator together with some recent refinements of the moment method of Fattorini and Russell. This notably requires to use some fine (and sometimes new) properties for Bessel functions and their zeros.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07302v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pierre Lissy (CERMICS), Tanguy Lourme</dc:creator>
    </item>
    <item>
      <title>Bregman proximal gradient method for linear optimization under entropic constraints</title>
      <link>https://arxiv.org/abs/2506.10849</link>
      <description>arXiv:2506.10849v3 Announce Type: replace 
Abstract: In this paper, we present an efficient algorithm for solving a linear optimization problem with entropic constraints, a class of problems that arises in game theory and information theory. Our analysis distinguishes between the cases of active and inactive constraints, addressing each using a Bregman proximal gradient method with entropic Legendre functions, for which we establish a convergence rate of $O(1/n)$ in objective values. For a specific cost structure, our framework provides a theoretical justification for the well-known Blahut-Arimoto algorithm and the uniqueness of the Lagrange multiplier associated with the entropic constraint. In the active constraint setting, we include a bisection procedure to approximate the strictly positive Lagrange multiplier. The efficiency of the proposed method is illustrated through comparisons with standard optimization solvers on a representative example from game theory, including extensions to higher-dimensional settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10849v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luis M. Brice\~no-Arias, Ma\"el Le Treust</dc:creator>
    </item>
    <item>
      <title>Relaxation and stability analysis of a third-order multiclass traffic flow model</title>
      <link>https://arxiv.org/abs/2507.04135</link>
      <description>arXiv:2507.04135v2 Announce Type: replace 
Abstract: Traffic flow modeling spans a wide range of mathematical approaches, from microscopic descriptions of individual vehicle dynamics to macroscopic models based on aggregate quantities. A fundamental challenge in macroscopic modeling lies in the closure relations, particularly in the specification of a traffic hesitation function in second-order models like Aw-Rascle-Zhang. In this work, we propose a third-order hyperbolic traffic model in which the hesitation evolves as a driver-dependent dynamic quantity. Starting from a microscopic formulation, we relax the standard assumption by introducing an evolution law for the hesitation. This extension allows to incorporate hysteresis effects, modeling the fact that drivers respond differently when accelerating or decelerating, even under identical local traffic conditions. Furthermore, various relaxation terms are introduced. These allow us to establish relations to the Aw-Rascle-Zhang model and other traffic flow models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04135v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.DS</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Stephan Gerster, Giuseppe Visconti</dc:creator>
    </item>
    <item>
      <title>Frank-Wolfe Algorithms for (L0, L1)-smooth functions</title>
      <link>https://arxiv.org/abs/2510.16468</link>
      <description>arXiv:2510.16468v2 Announce Type: replace 
Abstract: We propose a new version of the Frank-Wolfe method, called the (L0, L1)-Frank-Wolfe algorithm, developed for optimization problems with (L0, L1)-smooth objectives. We establish that this algorithm achieves superior theoretical convergence rates compared to the classical Frank-Wolfe method. In addition, we introduce a novel adaptive procedure, termed the Adaptive (L0, L1)-Frank-Wolfe algorithm, which dynamically adjusts the smoothness parameters to further improve performance and stability. Comprehensive numerical experiments confirm the theoretical results and demonstrate the clear practical advantages of both proposed algorithms over existing Frank-Wolfe variants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16468v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>A. A. Vyguzov, F. S. Stonyakin</dc:creator>
    </item>
    <item>
      <title>Equivalence of additive and parametric pinning control protocols for systems of weakly coupled oscillators</title>
      <link>https://arxiv.org/abs/2510.16766</link>
      <description>arXiv:2510.16766v3 Announce Type: replace 
Abstract: Controlling the behavior of nonlinear systems on networks is a paramount task in control theory, in particular the control of synchronization, given its vast applicability. In this work, we focus on pinning control and we examine two different approaches: the first, more common in engineering applications, where the control is implemented through an external input (additive pinning); the other, where the parameters of the pinned nodes are varied (parametric pinning). By means of the phase reduction technique, we show that the two pinning approaches are equivalent for weakly coupled systems exhibiting periodic oscillatory behaviors. Through numerical simulations, we validate the claim for a system of coupled Stuart--Landau oscillators. Our results pave the way for further applications of pinning control in real-world systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16766v3</guid>
      <category>math.OC</category>
      <category>nlin.AO</category>
      <category>nlin.PS</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Riccardo Muolo, Yuzuru Kato</dc:creator>
    </item>
    <item>
      <title>Exact output tracking for the one-dimensional heat equation and applications to the interpolation problem in Gevrey classes of order 2</title>
      <link>https://arxiv.org/abs/2511.07326</link>
      <description>arXiv:2511.07326v2 Announce Type: replace 
Abstract: This paper provides a complete characterization of the Dirichlet boundary outputs that can be exactly tracked in the one-dimensional heat equation with Neumann boundary control. The problem consists in describing the set of boundary traces generated by square-integrable controls over a finite or infinite time horizon. We show that these outputs form a precise functional space related to Gevrey regularity of order 2. In the infinite-time case, the trackable outputs are precisely those functions whose successive derivatives satisfy a weighted summability condition, which corresponds to specific Gevrey classes. For finite-time horizons, an additional compatibility condition involving the reachable space of the system provides a full characterization. The analysis relies on Fourier-Laplace transform, properties of Hardy spaces, the flatness method, and a new Plancherel-type theorem for Hilbert spaces of Gevrey functions. Beyond control theory, our results yield an optimal solution to the classical interpolation problem in Gevrey-$2$ classes, which improves results of Mitjagin on the optimal loss factor. The techniques developed here also extend to variants of the heat system with different boundary conditions or observation points.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07326v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lucas Davron, Pierre Lissy</dc:creator>
    </item>
    <item>
      <title>A Framework for Handling and Exploiting Symmetry in Benders' Decomposition</title>
      <link>https://arxiv.org/abs/2511.22251</link>
      <description>arXiv:2511.22251v2 Announce Type: replace 
Abstract: Benders' decomposition (BD) is a framework for solving optimization problems by removing some variables and modeling their contribution to the original problem via so-called Benders cuts. While many advanced optimization techniques can be applied in a BD framework, one central technique has not been applied systematically in BD: symmetry handling. The main reason for this is that Benders cuts are not known explicitly but only generated via a separation oracle.
  In this work, we close this gap by developing a theory of symmetry detection within the BD framework. To this end, we introduce a tailored family of graphs that capture the symmetry information of both the Benders master problem and the Benders oracles. Once symmetries of these graphs are known, which can be found by established techniques, classical symmetry handling approaches become available to accelerate BD. We complement these approaches by devising techniques for the separation and aggregation of symmetric Benders cuts by means of tailored separation routines and extended formulations. Both substantially reduce the number of executions of the separation oracles. In a numerical study, we show the effect of both symmetry handling and cut aggregation for bin packing and scheduling problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22251v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christopher Hojny, C\'edric Roy</dc:creator>
    </item>
    <item>
      <title>A Dual-Mode Framework for Mean-Field Systems: Model-Based $H_2/H_\infty$ Control with Jump Diffusions and Model-Free Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2512.01000</link>
      <description>arXiv:2512.01000v3 Announce Type: replace 
Abstract: Two approaches for solving the robust control of mean-field systems are investigated in this paper. For the stochastic $H_2/H_\infty$ control problem of continuous-time mean-field stochastic differential equations with Poisson jumps over a finite horizon, the continuous and jump diffusion terms in the system depend not only on the state but also on the control input, external disturbance, and mean-field components. The feasibility of the stochastic $H_2/H_\infty$ control problem is demonstrated to be equivalent to the solvability of four sets of cross-coupled generalized differential Riccati equations. Based on this conclusion, a model-based numerical method is presented. Furthermore, a data-driven, model-free, off-policy reinforcement learning approach is proposed, which can be employed to solve the $H_\infty$ control problem of the linear mean-field (x, u, v)-dependent systems. Two distinct methodologies for designing robust controllers for interacting particle systems are demonstrated in this paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01000v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huimin Han, Shaolin Ji, Weihai Zhang</dc:creator>
    </item>
    <item>
      <title>Stopping Rules for Stochastic Gradient Descent via Anytime-Valid Confidence Sequences</title>
      <link>https://arxiv.org/abs/2512.13123</link>
      <description>arXiv:2512.13123v2 Announce Type: replace 
Abstract: We study stopping rules for stochastic gradient descent (SGD) for convex optimization from the perspective of anytime-valid confidence sequences. Classical analyses of SGD provide convergence guarantees in expectation or at a fixed horizon, but offer no statistically valid way to assess, at an arbitrary time, how close the current iterate is to the optimum. We develop an anytime-valid, data-dependent upper confidence sequence for the weighted average suboptimality of projected SGD, constructed via nonnegative supermartingales and requiring no smoothness or strong convexity. This confidence sequence yields a simple stopping rule that is provably $\varepsilon$-optimal with probability at least $1-\alpha$ and is almost surely finite under standard stochastic approximation stepsizes. To the best of our knowledge, these are the first rigorous, time-uniform performance guarantees and finite-time $\varepsilon$-optimality certificates for projected SGD with general convex objectives, based solely on observable trajectory quantities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13123v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liviu Aolaritei, Michael I. Jordan</dc:creator>
    </item>
    <item>
      <title>A preconditioned second-order convex splitting algorithm with extrapolation</title>
      <link>https://arxiv.org/abs/2512.14468</link>
      <description>arXiv:2512.14468v3 Announce Type: replace 
Abstract: Nonconvex optimization problems are widespread in modern machine learning and data science. We introduce an extrapolation strategy into a class of preconditioned second-order convex splitting algorithms for nonconvex optimization problems. The proposed algorithms combine second-order backward differentiation formulas (BDF2) with an extrapolation method. Meanwhile, the implicit-explicit scheme simplifies the subproblem through a preconditioned process. As a result, our approach solves nonconvex problems efficiently without significant computational overhead. Theoretical analysis establishes global convergence of the algorithms using Kurdyka-\L ojasiewicz properties. Numerical experiments include a benchmark problem, the least squares problem with SCAD regularization, and an image segmentation problem. These results demonstrate that our algorithms are highly efficient, as they achieve reduced solution times and competitive performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14468v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xinhua Shen, Hongpeng Sun</dc:creator>
    </item>
    <item>
      <title>Reducing Recurrent Competitive Epidemics via Dynamic Resource Allocation</title>
      <link>https://arxiv.org/abs/2006.13395</link>
      <description>arXiv:2006.13395v2 Announce Type: replace-cross 
Abstract: Motivated by scenarios of epidemic competition, as well as how social contagions spread at the level of individuals, this work considers the competition between two conflicting node states that spread over a social graph according to a generic diffusion process. For this setting, we introduce the Generalized Largest Reduction in Infectious Edges (gLRIE), which is a dynamic resource allocation strategy that favors the preferred state against the other. Our analysis assumes a generic continuous-time SIS-like (Susceptible-Infectious-Susceptible) diffusion model that allows for: arbitrary node transition rate functions for nodes to change state, and competition between the healthy (positive) and infected (negative) states, which are both diffusive at the same time, yet mutually exclusive at each node. The strategy follows a minimum-risk-maximum-gain principle, and its features are particularly relevant for social contagion phenomena. In accordance with the LRIE strategy that we generalize, we show that in this context the gLRIE strategy remains a greedy solution for the minimization of the number of infected network nodes over time. Ultimately, simulations are employed to compare the proposed strategy with other existing alternatives, demonstrating that gLRIE exhibits superior performance across a spectrum of scenarios, including a realistic counter-contagion campaign in a small well-monitored community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2006.13395v2</guid>
      <category>cs.SI</category>
      <category>math.OC</category>
      <category>physics.soc-ph</category>
      <category>q-bio.PE</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Argyris Kalogeratos, Gaspard Abel, Stefano Sarao Mannelli</dc:creator>
    </item>
    <item>
      <title>Synthetic MTW conditions and their equivalence under mild regularity assumption on the cost function</title>
      <link>https://arxiv.org/abs/2010.14471</link>
      <description>arXiv:2010.14471v2 Announce Type: replace-cross 
Abstract: Loeper's condition in \cite{Loe09} and the quantitatively quasi-convex condition (QQconv) from \cite{GK15} are synthetic expressions of the analytic MTW condition from \cite{TW} since they only require $C^2$ differentiability of the cost function $c$. When the cost function $c$ is $C^4$, it is known that the two synthetic MTW conditions are equivalent to the analytic MTW condition. However, when the cost function has regularity weaker than $C^4$, it is not known that if the two synthetic MTW conditions are equivalent. In this paper, we show the equivalence of the synthetic MTW conditions when the cost function has only $C^2$ regularity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2010.14471v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Seonghyeon Jeong</dc:creator>
    </item>
    <item>
      <title>Online convex optimization for robust control of constrained dynamical systems</title>
      <link>https://arxiv.org/abs/2401.04487</link>
      <description>arXiv:2401.04487v3 Announce Type: replace-cross 
Abstract: This article investigates the problem of controlling linear time-invariant systems subject to time-varying and a priori unknown cost functions, state and input constraints, and exogenous disturbances. We combine the online convex optimization framework with tools from robust model predictive control to propose an algorithm that is able to guarantee robust constraint satisfaction. The performance of the closed loop emerging from application of our framework is studied in terms of its dynamic regret, which is proven to be bounded linearly by the variation of the cost functions and the magnitude of the disturbances. We corroborate our theoretical findings and illustrate implementational aspects of the proposed algorithm by a numerical case study on a tracking control problem of an autonomous vehicle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.04487v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TAC.2025.3641731</arxiv:DOI>
      <dc:creator>Marko Nonhoff, Emiliano Dall'Anese, Matthias A. M\"uller</dc:creator>
    </item>
    <item>
      <title>Worth Their Weight: Randomized and Regularized Block Kaczmarz Algorithms without Preprocessing</title>
      <link>https://arxiv.org/abs/2502.00882</link>
      <description>arXiv:2502.00882v3 Announce Type: replace-cross 
Abstract: Due to the ever growing amounts of data leveraged for machine learning and scientific computing, it is increasingly important to develop algorithms that sample only a small portion of the data at a time. In the case of linear least-squares, the randomized block Kaczmarz method (RBK) is an appealing example of such an algorithm, but its convergence is only understood under sampling distributions that require potentially prohibitively expensive preprocessing steps. To address this limitation, we analyze RBK when the data is sampled uniformly, showing that its iterates converge in a Monte Carlo sense to a $\textit{weighted}$ least-squares solution. Unfortunately, for general problems the bias of the weighted least-squares solution and the variance of the iterates can become arbitrarily large. We show that these quantities can be rigorously controlled by incorporating regularization into the RBK iterations, yielding the regularized algorithm ReBlocK. Numerical experiments including examples arising from natural gradient optimization demonstrate that ReBlocK can outperform both RBK and minibatch stochastic gradient descent for inconsistent problems with rapidly decaying singular values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00882v3</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gil Goldshlager, Jiang Hu, Lin Lin</dc:creator>
    </item>
    <item>
      <title>A Neural Surrogate-Enhanced Multi-Method Framework for Robust Wing Design Optimization</title>
      <link>https://arxiv.org/abs/2510.08582</link>
      <description>arXiv:2510.08582v2 Announce Type: replace-cross 
Abstract: This paper introduces a modular and scalable design optimization framework for the wing design process that enables faster early-phase design while ensuring aerodynamic stability. The pipeline starts with the generation of initial wing geometries and then proceeds to optimize the wing using several algorithms. Aerodynamic performance is assessed using a Vortex Lattice Method (VLM) applied to a carefully selected dataset of wing configurations. These results are employed to develop surrogate neural network models, which can predict lift and drag rapidly and accurately. The stability evaluation is implemented by setting the control surfaces and components to fixed positions in order to have realistic flight dynamics. The approach unifies and compares several optimization techniques, including Particle Swarm Optimization (PSO), Genetic Algorithms (GA), gradient-based MultiStart methods, Bayesian optimization, and Lipschitz optimization. Each method ensures constraint management via adaptive strategies and penalty functions, where the targets for lift and design feasibility are enforced. The progression of aerodynamic characteristics and geometries over the optimization iterations will be investigated in order to clarify each algorithm's convergence characteristics and performance efficiency. Our results show improvement in aerodynamic qualities and robust stability properties, offering a mechanism for wing design at speed and precision. In the interest of reproducibility and community development, the complete implementation is publicly available at Github.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08582v2</guid>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arash Fath Lipaei, Melika Sabzikari</dc:creator>
    </item>
    <item>
      <title>New Location Science Models with Applications to UAV-Based Disaster Relief</title>
      <link>https://arxiv.org/abs/2510.15229</link>
      <description>arXiv:2510.15229v2 Announce Type: replace-cross 
Abstract: Natural and human-made disasters can cause severe devastation and claim thousands of lives worldwide. Therefore, developing efficient methods for disaster response and management is a critical task for relief teams. One of the most essential components of effective response is the rapid collection of information about affected areas, damages, and victims. More data translates into better coordination, faster rescue operations, and ultimately, more lives saved. However, in some disasters, such as earthquakes, the communication infrastructure is often partially or completely destroyed, making it extremely difficult for victims to send distress signals and for rescue teams to locate and assist them in time. Unmanned Aerial Vehicles (UAVs) have emerged as valuable tools in such scenarios. In particular, a fleet of UAVs can be dispatched from a mobile station to the affected area to facilitate data collection and establish temporary communication networks. Nevertheless, real-world deployment of UAVs faces several challenges, with adverse weather conditions--especially wind--being among the most significant. To address this, we develop a novel mathematical framework to determine the optimal location of a mobile UAV station while explicitly accounting for the heterogeneity of the UAVs and the effect of wind. In particular, we generalize the Sylvester problem to introduce the Sylvester-Fermat-Torricelli (SFT) problem, which captures complex factors such as wind influence, UAV heterogeneity, and back-and-forth motion within a unified framework. The proposed framework enhances the practicality of UAV-based disaster response planning by accounting for real-world factors such as wind and UAV heterogeneity. Experimental results demonstrate that it can reduce wasted operational time by up to 84%, making post-disaster missions significantly more efficient and effective.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.15229v2</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sina Kazemdehbashi, Yanchao Liu, Boris S. Mordukhovich</dc:creator>
    </item>
    <item>
      <title>N2N: A Parallel Framework for Large-Scale MILP under Distributed Memory</title>
      <link>https://arxiv.org/abs/2511.18723</link>
      <description>arXiv:2511.18723v4 Announce Type: replace-cross 
Abstract: Parallelization has emerged as a promising approach for accelerating MILP solving. However, the complexity of the branch-and-bound (B&amp;B) framework and the numerous effective algorithm components in MILP solvers make it difficult to parallelize. In this study, a scalable parallel framework, N2N (a node-to-node framework that maps the B&amp;B nodes to distributed computing nodes), was proposed to solve large-scale problems in a distributed memory computing environment. Both deterministic and nondeterministic modes are supported, and the framework is designed to be easily integrated with existing solvers. Regarding the deterministic mode, a novel sliding-window-based algorithm was designed and implemented to ensure that tasks are generated and solved in a deterministic order. Moreover, several advanced techniques, such as the utilization of CP search and general primal heuristics, have been developed to fully utilize distributed computing resources and capabilities of base solvers. Adaptive solving and data communication optimization were also investigated. A popular open-source MILP solver, SCIP, was integrated into N2N as the base solver, yielding N2N-SCIP. Extensive computational experiments were conducted to evaluate the performance of N2N-SCIP compared to ParaSCIP, which is a state-of-the-art distributed parallel MILP solver under the UG framework. The nondeterministic N2N-SCIP achieves speedups of 22.52 and 12.71 with 1,000 MPI processes on the Kunpeng and x86 computing clusters, which is 1.98 and 2.08 times faster than ParaSCIP, respectively. In the deterministic mode, N2N-SCIP also shows significant performance improvements over ParaSCIP across different process numbers and computing clusters. To validate the generality of N2N, HiGHS, another open-source solver, was integrated into N2N. The related results are analyzed, and the requirements of N2N on base solvers are also concluded.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18723v4</guid>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Longfei Wang, Junyan Liu, Fan Zhang, Jiangwen Wei, Yuanhua Tang, Jie Sun, Xiaodong Luo</dc:creator>
    </item>
    <item>
      <title>A Theoretical Framework for Iteratively Enhanced Room-Temperature Single-Photon Detection</title>
      <link>https://arxiv.org/abs/2512.01328</link>
      <description>arXiv:2512.01328v3 Announce Type: replace-cross 
Abstract: High-performance photon detection is indispensable in a wide range of quantum-optical applications and is conventionally treated as a fixed device-level operation based on single-photon detectors (SPDs). However, state-of-the-art SPDs rely on superconducting materials, which impose severe technological demands and require challenging operational conditions such as cryogenic cooling, thereby hindering scalable implementation. Here, we propose the enhanced single-photon detector (ESPD) framework, a theoretical paradigm supported by numerical simulations, that reformulates single-photon detection as an iteratively enhanced process based on state preparation, controlled operations, projective measurements, and multi-copy analysis, and enables substantial performance improvement using exclusively room-temperature components. Numerical simulations indicate that, within a physically motivated parameter regime, the ESPD framework can upgrade a legacy SPD with a detection efficiency (DE) of about 59% and a dark count rate (DCR) of about $10^{-2}$ to effective performance metrics with DE exceeding 93% and DCR below $10^{-9}$, comparable to those of superconducting SPDs. As a consequence, the minimal tolerable channel transmission rate for quantum key distribution protocols can be reduced by several orders of magnitude. While its physical realization would require substantial experimental integration, the ESPD framework establishes a general system-level perspective on photon detection, highlighting the potential of iterative quantum processing for overcoming intrinsic detector limitations at room temperature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01328v3</guid>
      <category>quant-ph</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Shu</dc:creator>
    </item>
    <item>
      <title>AI-Assisted Game Management Decisions: A Fuzzy Logic Approach to Real-Time Soccer Substitutions</title>
      <link>https://arxiv.org/abs/2512.04480</link>
      <description>arXiv:2512.04480v4 Announce Type: replace-cross 
Abstract: In elite soccer, substitution decisions entail significant financial and sporting consequences yet remain heavily reliant on intuition or predictive models that merely mimic historical biases. This paper introduces a Fuzzy Logic based Decision Support System (DSS) designed for real time, prescriptive game management. Unlike traditional Machine Learning approaches that encounter a predictive ceiling by attempting to replicate human behavior, our system audits performance through an objective, rule based inference engine. We propose a methodological advancement by reformulating the PlayeRank metric into a Cumulative Mean with Role Aware Normalization, eliminating the play time exposure bias inherent in cumulative sum models to enable accurate intra match comparison. The system integrates this refined metric with physiological proxies (fatigue) and contextual variables (disciplinary risk modulated by tactical role) to calculate a dynamic Substitution Priority (P final). Validation via a case study of the 2018 FIFA World Cup match between Brazil and Belgium demonstrates the system's ecological validity: it not only aligned with expert consensus on executed substitutions (for example Gabriel Jesus) but, crucially, identified high risk scenarios ignored by human decision makers. Specifically, the model flagged the "FAGNER Paradox" - a maximum priority defensive risk - minutes before a critical yellow card, and detected the "Lukaku Paradox", where an isolated assist masked a severe drop in participation. These results confirm that Fuzzy Logic offers a transparent, explainable, and superior alternative to black box models for optimizing real time tactical decisions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04480v4</guid>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Pedro Passos</dc:creator>
    </item>
    <item>
      <title>Geometric properties of optimizers for the maximum gradient of the torsion function</title>
      <link>https://arxiv.org/abs/2512.09400</link>
      <description>arXiv:2512.09400v2 Announce Type: replace-cross 
Abstract: Consider $J(\Omega):= \|\nabla u_\Omega\|_\infty/\sqrt{|\Omega|} $ and $J_P(\Omega):= \|\nabla u_\Omega\|_\infty/P(\Omega) $, where $\Omega$ is a planar convex domain, $u_\Omega$ is the torsion function, $P(\Omega)$ is the perimeter of $\Omega$ and $|\Omega|$ its area. We prove that there exist planar convex domains that maximize the functionals $J$ and $J_P$, and any maximizer has a $C^1$ boundary that contains a line segment on which $|\nabla u_\Omega|$ attains its maximum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09400v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Krzysztof Burdzy, Ilias Ftouhi, Phanuel Mariano</dc:creator>
    </item>
  </channel>
</rss>
