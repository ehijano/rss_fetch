<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DB updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DB</link>
    <description>cs.DB updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DB" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 11 Oct 2024 02:24:42 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A large collection of bioinformatics question-query pairs over federated knowledge graphs: methodology and applications</title>
      <link>https://arxiv.org/abs/2410.06010</link>
      <description>arXiv:2410.06010v1 Announce Type: new 
Abstract: Background. In the last decades, several life science resources have structured data using the same framework and made these accessible using the same query language to facilitate interoperability. Knowledge graphs have seen increased adoption in bioinformatics due to their advantages for representing data in a generic graph format. For example, yummydata.org catalogs more than 60 knowledge graphs accessible through SPARQL, a technical query language. Although SPARQL allows powerful, expressive queries, even across physically distributed knowledge graphs, formulating such queries is a challenge for most users. Therefore, to guide users in retrieving the relevant data, many of these resources provide representative examples. These examples can also be an important source of information for machine learning, if a sufficiently large number of examples are provided and published in a common, machine-readable and standardized format across different resources.
  Findings. We introduce a large collection of human-written natural language questions and their corresponding SPARQL queries over federated bioinformatics knowledge graphs (KGs) collected for several years across different research groups at the SIB Swiss Institute of Bioinformatics. The collection comprises more than 1000 example questions and queries, including 65 federated queries. We propose a methodology to uniformly represent the examples with minimal metadata, based on existing standards. Furthermore, we introduce an extensive set of open-source applications, including query graph visualizations and smart query editors, easily reusable by KG maintainers who adopt the proposed methodology.
  Conclusions. We encourage the community to adopt and extend the proposed methodology, towards richer KG metadata and improved Semantic Web services.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06010v1</guid>
      <category>cs.DB</category>
      <category>cs.AI</category>
      <category>cs.IR</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jerven Bolleman, Vincent Emonet, Adrian Altenhoff, Amos Bairoch, Marie-Claude Blatter, Alan Bridge, Severine Duvaud, Elisabeth Gasteiger, Dmitry Kuznetsov, Sebastien Moretti, Pierre-Andre Michel, Anne Morgat, Marco Pagni, Nicole Redaschi, Monique Zahn-Zabal, Tarcisio Mendes de Farias, Ana Claudia Sima</dc:creator>
    </item>
    <item>
      <title>Large Language Model Enhanced Text-to-SQL Generation: A Survey</title>
      <link>https://arxiv.org/abs/2410.06011</link>
      <description>arXiv:2410.06011v1 Announce Type: new 
Abstract: Text-to-SQL translates natural language queries into Structured Query Language (SQL) commands, enabling users to interact with databases using natural language. Essentially, the text-to-SQL task is a text generation task, and its development is primarily dependent on changes in language models. Especially with the rapid development of Large Language Models (LLMs), the pattern of text-to-SQL has undergone significant changes. Existing survey work mainly focuses on rule-based and neural-based approaches, but it still lacks a survey of Text-to-SQL with LLMs. In this paper, we survey the large language model enhanced text-to-SQL generations, classifying them into prompt engineering, fine-tuning, pre-trained, and Agent groups according to training strategies. We also summarize datasets and evaluation metrics comprehensively. This survey could help people better understand the pattern, research status, and challenges of LLM-based text-to-SQL generations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06011v1</guid>
      <category>cs.DB</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xiaohu Zhu, Qian Li, Lizhen Cui, Yongkang Liu</dc:creator>
    </item>
    <item>
      <title>LLM-based SPARQL Query Generation from Natural Language over Federated Knowledge Graphs</title>
      <link>https://arxiv.org/abs/2410.06062</link>
      <description>arXiv:2410.06062v2 Announce Type: new 
Abstract: We introduce a Retrieval-Augmented Generation (RAG) system for translating user questions into accurate federated SPARQL queries over bioinformatics knowledge graphs (KGs) leveraging Large Language Models (LLMs). To enhance accuracy and reduce hallucinations in query generation, our system utilises metadata from the KGs, including query examples and schema information, and incorporates a validation step to correct generated queries. The system is available online at chat.expasy.org.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06062v2</guid>
      <category>cs.DB</category>
      <category>cs.AI</category>
      <category>cs.IR</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vincent Emonet, Jerven Bolleman, Severine Duvaud, Tarcisio Mendes de Farias, Ana Claudia Sima</dc:creator>
    </item>
    <item>
      <title>KOR-Bench: Benchmarking Language Models on Knowledge-Orthogonal Reasoning Tasks</title>
      <link>https://arxiv.org/abs/2410.06526</link>
      <description>arXiv:2410.06526v1 Announce Type: new 
Abstract: In this paper, we introduce Knowledge-Orthogonal Reasoning (KOR), which minimizes the impact of domain-specific knowledge for a more accurate evaluation of models' reasoning abilities in out-of-distribution scenarios. Based on this concept, we propose the Knowledge-Orthogonal Reasoning Benchmark (KOR-Bench), encompassing five task categories: Operation, Logic, Cipher, Puzzle, and Counterfactual. KOR-Bench emphasizes the effectiveness of models in applying new rule descriptions to solve novel rule-driven questions, revealing that top-performing models like Claude-3.5-Sonnet and GPT-4o only achieve 58.96% and 58.00% accuracy, respectively. We conduct thorough analyses to identify bottlenecks in the Cipher task using Stepwise Prompting, discovering that two rounds of Self-Correction yield optimal results. Complex Task Processing evaluates model performance across three integrated tasks, while we also explore the impact of Tricks on the Puzzle task and visualize rule-focused attention to enhance our understanding of model behavior. We aim for KOR-Bench to be a valuable resource for enhancing models' reasoning capabilities and fostering further research in this field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06526v1</guid>
      <category>cs.DB</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kaijing Ma, Xinrun Du, Yunran Wang, Haoran Zhang, Zhoufutu Wen, Xingwei Qu, Jian Yang, Jiaheng Liu, Minghao Liu, Xiang Yue, Wenhao Huang, Ge Zhang</dc:creator>
    </item>
    <item>
      <title>Natural Language Query Engine for Relational Databases using Generative AI</title>
      <link>https://arxiv.org/abs/2410.07144</link>
      <description>arXiv:2410.07144v1 Announce Type: new 
Abstract: The growing reliance on data-driven decision-making highlights the need for more intuitive ways to access and analyze information stored in relational databases. However, the requirement of SQL knowledge has long been a significant barrier for non-technical users. This article introduces an innovative solution that leverages Generative AI to bridge this gap, enabling users to query databases using natural language. Our approach automatically translates natural language queries into SQL, ensuring both syntactic and semantic correctness, while also generating clear, natural language responses from the retrieved data. By streamlining the interaction between users and databases, this method empowers individuals without technical expertise to engage with data directly and efficiently, democratizing access to valuable insights and enhancing productivity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07144v1</guid>
      <category>cs.DB</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SE</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Steve Tueno Fotso</dc:creator>
    </item>
    <item>
      <title>The OCON model: an old but gold solution for distributable supervised classification</title>
      <link>https://arxiv.org/abs/2410.05320</link>
      <description>arXiv:2410.05320v1 Announce Type: cross 
Abstract: This paper introduces to a structured application of the One-Class approach and the One-Class-One-Network model for supervised classification tasks, specifically addressing a vowel phonemes classification case study within the Automatic Speech Recognition research field. Through pseudo-Neural Architecture Search and Hyper-Parameters Tuning experiments conducted with an informed grid-search methodology, we achieve classification accuracy comparable to nowadays complex architectures (90.0 - 93.7%). Despite its simplicity, our model prioritizes generalization of language context and distributed applicability, supported by relevant statistical and performance metrics. The experiments code is openly available at our GitHub.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05320v1</guid>
      <category>eess.AS</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.DB</category>
      <category>cs.LG</category>
      <category>cs.SD</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Stefano Giacomelli, Marco Giordano, Claudia Rinaldi</dc:creator>
    </item>
    <item>
      <title>Exploring the Meaningfulness of Nearest Neighbor Search in High-Dimensional Space</title>
      <link>https://arxiv.org/abs/2410.05752</link>
      <description>arXiv:2410.05752v1 Announce Type: cross 
Abstract: Dense high dimensional vectors are becoming increasingly vital in fields such as computer vision, machine learning, and large language models (LLMs), serving as standard representations for multimodal data. Now the dimensionality of these vector can exceed several thousands easily. Despite the nearest neighbor search (NNS) over these dense high dimensional vectors have been widely used for retrieval augmented generation (RAG) and many other applications, the effectiveness of NNS in such a high-dimensional space remains uncertain, given the possible challenge caused by the "curse of dimensionality." To address above question, in this paper, we conduct extensive NNS studies with different distance functions, such as $L_1$ distance, $L_2$ distance and angular-distance, across diverse embedding datasets, of varied types, dimensionality and modality. Our aim is to investigate factors influencing the meaningfulness of NNS. Our experiments reveal that high-dimensional text embeddings exhibit increased resilience as dimensionality rises to higher levels when compared to random vectors. This resilience suggests that text embeddings are less affected to the "curse of dimensionality," resulting in more meaningful NNS outcomes for practical use. Additionally, the choice of distance function has minimal impact on the relevance of NNS. Our study shows the effectiveness of the embedding-based data representation method and can offer opportunity for further optimization of dense vector-related applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05752v1</guid>
      <category>cs.LG</category>
      <category>cs.DB</category>
      <category>cs.IR</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zhonghan Chen, Ruiyuan Zhang, Xi Zhao, Xiaojun Cheng, Xiaofang Zhou</dc:creator>
    </item>
    <item>
      <title>Bottom-up Anytime Discovery of Generalised Multimodal Graph Patterns for Knowledge Graphs</title>
      <link>https://arxiv.org/abs/2410.05839</link>
      <description>arXiv:2410.05839v1 Announce Type: cross 
Abstract: Vast amounts of heterogeneous knowledge are becoming publicly available in the form of knowledge graphs, often linking multiple sources of data that have never been together before, and thereby enabling scholars to answer many new research questions. It is often not known beforehand, however, which questions the data might have the answers to, potentially leaving many interesting and novel insights to remain undiscovered. To support scholars during this scientific workflow, we introduce an anytime algorithm for the bottom-up discovery of generalized multimodal graph patterns in knowledge graphs. Each pattern is a conjunction of binary statements with (data-) type variables, constants, and/or value patterns. Upon discovery, the patterns are converted to SPARQL queries and presented in an interactive facet browser together with metadata and provenance information, enabling scholars to explore, analyse, and share queries. We evaluate our method from a user perspective, with the help of domain experts in the humanities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05839v1</guid>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Xander Wilcke, Rick Mourits, Auke Rijpma, Richard Zijdeman</dc:creator>
    </item>
    <item>
      <title>DSparsE: Dynamic Sparse Embedding for Knowledge Graph Completion</title>
      <link>https://arxiv.org/abs/2410.07140</link>
      <description>arXiv:2410.07140v1 Announce Type: cross 
Abstract: Addressing the incompleteness problem in knowledge graph remains a significant challenge. Current knowledge graph completion methods have their limitations. For example, ComDensE is prone to overfitting and suffers from the degradation with the increase of network depth while InteractE has the limitations in feature interaction and interpretability. To this end, we propose a new method called dynamic sparse embedding (DSparsE) for knowledge graph completion. The proposed model embeds the input entity-relation pairs by a shallow encoder composed of a dynamic layer and a relation-aware layer. Subsequently, the concatenated output of the dynamic layer and relation-aware layer is passed through a projection layer and a deep decoder with residual connection structure. This model ensures the network robustness and maintains the capability of feature extraction. Furthermore, the conventional dense layers are replaced by randomly initialized sparse connection layers in the proposed method, which can mitigate the model overfitting. Finally, comprehensive experiments are conducted on the datasets of FB15k-237, WN18RR and YAGO3-10. It was demonstrated that the proposed method achieves the state-of-the-art performance in terms of Hits@1 compared to the existing baseline approaches. An ablation study is performed to examine the effects of the dynamic layer and relation-aware layer, where the combined model achieves the best performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07140v1</guid>
      <category>cs.IR</category>
      <category>cs.DB</category>
      <category>cs.GR</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chuhong Yang, Bin Li, Nan Wu</dc:creator>
    </item>
    <item>
      <title>On the Optimal Linear Contraction Order of Tree Tensor Networks, and Beyond</title>
      <link>https://arxiv.org/abs/2209.12332</link>
      <description>arXiv:2209.12332v5 Announce Type: replace-cross 
Abstract: The contraction cost of a tensor network depends on the contraction order. However, the optimal contraction ordering problem is known to be NP-hard. We show that the linear contraction ordering problem for tree tensor networks admits a polynomial-time algorithm, by drawing connections to database join ordering. The result relies on the adjacent sequence interchange property of the contraction cost, which enables a global decision of the contraction order based on local comparisons. Based on that, we specify a modified version of the IKKBZ database join ordering algorithm to find the optimal tree tensor network linear contraction order. Finally, we extend our algorithm as a heuristic to general contraction orders and arbitrary tensor network topologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.12332v5</guid>
      <category>quant-ph</category>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1137/23M161286X</arxiv:DOI>
      <arxiv:journal_reference>SIAM J. Sci. Comput. 46, B647-B668 (2024)</arxiv:journal_reference>
      <dc:creator>Mihail Stoian, Richard Milbradt, Christian B. Mendl</dc:creator>
    </item>
    <item>
      <title>Semantic Tree-Width and Path-Width of Conjunctive Regular Path Queries</title>
      <link>https://arxiv.org/abs/2212.01679</link>
      <description>arXiv:2212.01679v4 Announce Type: replace-cross 
Abstract: We show that the problem of whether a query is equivalent to a query of tree-width $k$ is decidable, for the class of Unions of Conjunctive Regular Path Queries with two-way navigation (UC2RPQs). A previous result by Barcel\'o, Romero, and Vardi [SIAM Journal on Computing, 2016] has shown decidability for the case $k=1$, and here we extend this result showing that decidability in fact holds for any arbitrary $k\geq 1$. The algorithm is in 2ExpSpace, but for the restricted but practically relevant case where all regular expressions of the query are of the form $a^*$ or $(a_1 + \dotsb + a_n)$ we show that the complexity of the problem drops to $\Pi^P_2$.
  We also investigate the related problem of approximating a UC2RPQ by queries of small tree-width. We exhibit an algorithm which, for any fixed number $k$, builds the maximal under-approximation of tree-width $k$ of a UC2RPQ. The maximal under-approximation of tree-width $k$ of a query $q$ is a query $q'$ of tree-width $k$ which is contained in $q$ in a maximal and unique way, that is, such that for every query $q"$ of tree-width $k$, if $q"$ is contained in $q$ then $q"$ is also contained in $q'$.
  Our approach is shown to be robust, in the sense that it allows also to test equivalence with queries of a given path-width, it also covers the previously known result for $k=1$, and it allows to test for equivalence of whether a (one-way) UCRPQ is equivalent to a UCRPQ of a given tree-width (or path-width).</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.01679v4</guid>
      <category>cs.LO</category>
      <category>cs.DB</category>
      <category>cs.FL</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Diego Figueira, R\'emi Morvan</dc:creator>
    </item>
    <item>
      <title>What-if Analysis for Business Users: Current Practices and Future Opportunities</title>
      <link>https://arxiv.org/abs/2212.13643</link>
      <description>arXiv:2212.13643v3 Announce Type: replace-cross 
Abstract: What-if analysis (WIA), crucial for making data-driven decisions, enables users to understand how changes in variables impact outcomes and explore alternative scenarios. However, existing WIA research focuses on supporting the workflows of data scientists or analysts, largely overlooking significant non-technical users, like business users. We conduct a two-part user study with 22 business users (marketing, sales, product, and operations managers). The first study examines existing WIA techniques employed, tools used, and challenges faced. Findings reveal that business users perform many WIA techniques independently using rudimentary tools due to various constraints. We implement representative WIA techniques identified previously in a visual analytics prototype to use as a probe to conduct a follow-up study evaluating business users' practical use of the techniques. These techniques improve decision-making efficiency and confidence while highlighting the need for better support in data preparation, risk assessment, and domain knowledge integration. Finally, we offer design recommendations to enhance future business analytics systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.13643v3</guid>
      <category>cs.HC</category>
      <category>cs.DB</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sneha Gathani, Zhicheng Liu, Peter J. Haas, \c{C}a\u{g}atay Demiralp</dc:creator>
    </item>
    <item>
      <title>FLASC: A Flare-Sensitive Clustering Algorithm</title>
      <link>https://arxiv.org/abs/2311.15887</link>
      <description>arXiv:2311.15887v2 Announce Type: replace-cross 
Abstract: Clustering algorithms are often used to find subpopulations in exploratory data analysis workflows. Not only the clusters themselves, but also their shape can represent meaningful subpopulations. In this paper, we present FLASC, an algorithm that detects branches within clusters to identify such subpopulations. FLASC builds upon HDBSCAN*, a state-of-the-art density-based clustering algorithm, and detects branches in a post-processing step that describes within-cluster connectivity. Two variants of the algorithm are presented, which trade computational cost for noise robustness. We show that both variants scale similarly to HDBSCAN* in terms of computational cost and provide stable outputs using synthetic data sets, resulting in an efficient flare-sensitive clustering algorithm. In addition, we demonstrate the benefit of branch-detection on two real-world data sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.15887v2</guid>
      <category>cs.LG</category>
      <category>cs.DB</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>D. M. Bot, J. Peeters, J. Liesenborgs, J. Aerts</dc:creator>
    </item>
    <item>
      <title>Evaluating the Generalization Ability of Spatiotemporal Model in Urban Scenario</title>
      <link>https://arxiv.org/abs/2410.04740</link>
      <description>arXiv:2410.04740v2 Announce Type: replace-cross 
Abstract: Spatiotemporal neural networks have shown great promise in urban scenarios by effectively capturing temporal and spatial correlations. However, urban environments are constantly evolving, and current model evaluations are often limited to traffic scenarios and use data mainly collected only a few weeks after training period to evaluate model performance. The generalization ability of these models remains largely unexplored. To address this, we propose a Spatiotemporal Out-of-Distribution (ST-OOD) benchmark, which comprises six urban scenario: bike-sharing, 311 services, pedestrian counts, traffic speed, traffic flow, ride-hailing demand, and bike-sharing, each with in-distribution (same year) and out-of-distribution (next years) settings. We extensively evaluate state-of-the-art spatiotemporal models and find that their performance degrades significantly in out-of-distribution settings, with most models performing even worse than a simple Multi-Layer Perceptron (MLP). Our findings suggest that current leading methods tend to over-rely on parameters to overfit training data, which may lead to good performance on in-distribution data but often results in poor generalization. We also investigated whether dropout could mitigate the negative effects of overfitting. Our results showed that a slight dropout rate could significantly improve generalization performance on most datasets, with minimal impact on in-distribution performance. However, balancing in-distribution and out-of-distribution performance remains a challenging problem. We hope that the proposed benchmark will encourage further research on this critical issue.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04740v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.DB</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongjun Wang, Jiyuan Chen, Tong Pan, Zheng Dong, Lingyu Zhang, Renhe Jiang, Xuan Song</dc:creator>
    </item>
  </channel>
</rss>
