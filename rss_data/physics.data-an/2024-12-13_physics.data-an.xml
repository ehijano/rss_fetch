<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 13 Dec 2024 05:39:45 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Markov-type state models to describe non-Markovian dynamics</title>
      <link>https://arxiv.org/abs/2412.08660</link>
      <description>arXiv:2412.08660v1 Announce Type: cross 
Abstract: When clustering molecular dynamics (MD) trajectories into a few metastable conformational states, the Markov state models (MSMs) assumption of timescale separation between fast intrastate fluctuations and rarely occurring interstate transitions is often not valid. Hence, the naive estimation of the macrostate transition matrix via simply counting transitions between the states leads to significantly too short implied timescales and thus to too fast population decays. In this work, we discuss advanced approaches to estimate the transition matrix. Assuming that Markovianity is at least given at the microstate level, we consider the Laplace-transform based method by Hummer and Szabo, as well as a direct microstate-to-macrostate projection, which by design yields correct macrostate population dynamics. Alternatively, we study the recently proposed quasi-MSM ansatz of Huang and coworkers to solve a generalized master equations, as well as a hybrid method that employs MD at short times and MSM at long times. Adopting a one-dimensional toy model and an all-atom folding trajectory of HP35, we discuss the virtues and shortcomings of the various approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08660v1</guid>
      <category>cond-mat.soft</category>
      <category>physics.bio-ph</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sofia Sartore, Franziska Teichmann, Gerhard Stock</dc:creator>
    </item>
    <item>
      <title>GeoConformal prediction: a model-agnostic framework of measuring the uncertainty of spatial prediction</title>
      <link>https://arxiv.org/abs/2412.08661</link>
      <description>arXiv:2412.08661v1 Announce Type: cross 
Abstract: Spatial prediction is a fundamental task in geography. In recent years, with advances in geospatial artificial intelligence (GeoAI), numerous models have been developed to improve the accuracy of geographic variable predictions. Beyond achieving higher accuracy, it is equally important to obtain predictions with uncertainty measures to enhance model credibility and support responsible spatial prediction. Although geostatistic methods like Kriging offer some level of uncertainty assessment, such as Kriging variance, these measurements are not always accurate and lack general applicability to other spatial models. To address this issue, we propose a model-agnostic uncertainty assessment method called GeoConformal Prediction, which incorporates geographical weighting into conformal prediction. We applied it to two classic spatial prediction cases, spatial regression and spatial interpolation, to evaluate its reliability. First, in the spatial regression case, we used XGBoost to predict housing prices, followed by GeoConformal to calculate uncertainty. Our results show that GeoConformal achieved a coverage rate of 93.67%, while Bootstrap methods only reached a maximum coverage of 68.33% after 2000 runs. Next, we applied GeoConformal to spatial interpolation models. We found that the uncertainty obtained from GeoConformal aligned closely with the variance in Kriging. Finally, using GeoConformal, we analyzed the sources of uncertainty in spatial prediction. We found that explicitly including local features in AI models can significantly reduce prediction uncertainty, especially in areas with strong local dependence. Our findings suggest that GeoConformal holds potential not only for geographic knowledge discovery but also for guiding the design of future GeoAI models, paving the way for more reliable and interpretable spatial prediction frameworks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08661v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <category>stat.AP</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiayin Lou, Peng Luo, Liqiu Meng</dc:creator>
    </item>
    <item>
      <title>Efficient Gravitational Wave Parameter Estimation via Knowledge Distillation: A ResNet1D-IAF Approach</title>
      <link>https://arxiv.org/abs/2412.08672</link>
      <description>arXiv:2412.08672v1 Announce Type: cross 
Abstract: With the rapid development of gravitational wave astronomy, the increasing number of detected events necessitates efficient methods for parameter estimation and model updates. This study presents a novel approach using knowledge distillation techniques to enhance computational efficiency in gravitational wave analysis. We develop a framework combining ResNet1D and Inverse Autoregressive Flow (IAF) architectures, where knowledge from a complex teacher model is transferred to a lighter student model. Our experimental results show that the student model achieves a validation loss of 3.70 with optimal configuration (40,100,0.75), compared to the teacher model's 4.09, while reducing the number of parameters by 43\%. The Jensen-Shannon divergence between teacher and student models remains below 0.0001 across network layers, indicating successful knowledge transfer. By optimizing ResNet layers (7-16) and hidden features (70-120), we achieve a 35\% reduction in inference time while maintaining parameter estimation accuracy. This work demonstrates significant improvements in computational efficiency for gravitational wave data analysis, providing valuable insights for real-time event processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08672v1</guid>
      <category>gr-qc</category>
      <category>astro-ph.IM</category>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xihua Zhu, Yiqian Yang, Fan Zhang</dc:creator>
    </item>
    <item>
      <title>Exact joint distributions of three global characteristic times for Brownian motion</title>
      <link>https://arxiv.org/abs/2412.09244</link>
      <description>arXiv:2412.09244v1 Announce Type: cross 
Abstract: We consider three global chracteristic times for a one-dimensional Brownian motion $x(\tau)$ in the interval $\tau\in [0,t]$: the occupation time $t_{\rm o}$ denoting the cumulative time where $x(\tau)&gt;0$, the time $t_{\rm m}$ at which the process achieves its global maximum in $[0,t]$ and the last-passage time $t_l$ through the origin before $t$. All three random variables have the same marginal distribution given by L\'evy's arcsine law. We compute exactly the pairwise joint distributions of these three times and show that they are quite different from each other. The joint distributions display rather rich and nontrivial correlations between these times. Our analytical results are verified by numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09244v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>physics.data-an</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander K. Hartmann, Satya N. Majumdar</dc:creator>
    </item>
    <item>
      <title>Evolving Alignment via Asymmetric Self-Play</title>
      <link>https://arxiv.org/abs/2411.00062</link>
      <description>arXiv:2411.00062v2 Announce Type: replace-cross 
Abstract: Current RLHF frameworks for aligning large language models (LLMs) typically assume a fixed prompt distribution, which is sub-optimal and limits the scalability of alignment and generalizability of models. To address this, we introduce a general open-ended RLHF framework that casts alignment as an asymmetric game between two players: (i) a creator that generates increasingly informative prompt distributions using reward signals, and (ii) a solver that learns to produce more preferred responses on prompts produced by the creator. This framework of Evolving Alignment via Asymmetric Self-Play (eva), results in a simple and efficient approach that can utilize any existing RLHF algorithm for scalable alignment. eva outperforms state-of-the-art methods on widely-used benchmarks, without the need of any additional human crafted prompts. Specifically, eva improves the win rate of Gemma-2-9B-it on Arena-Hard from 51.6% to 60.1% with DPO, from 55.7% to 58.9% with SPPO, from 52.3% to 60.7% with SimPO, and from 54.8% to 60.3% with ORPO, surpassing its 27B version and matching claude-3-opus. This improvement is persistent even when new human crafted prompts are introduced. Finally, we show eva is effective and robust under various ablation settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00062v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>physics.data-an</category>
      <category>stat.ML</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziyu Ye, Rishabh Agarwal, Tianqi Liu, Rishabh Joshi, Sarmishta Velury, Quoc V. Le, Qijun Tan, Yuan Liu</dc:creator>
    </item>
  </channel>
</rss>
