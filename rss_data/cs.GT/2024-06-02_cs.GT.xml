<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 03 Jun 2024 04:00:26 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 03 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Dynamics and Contracts for an Agent with Misspecified Beliefs</title>
      <link>https://arxiv.org/abs/2405.20423</link>
      <description>arXiv:2405.20423v1 Announce Type: new 
Abstract: We study a single-agent contracting environment where the agent has misspecified beliefs about the outcome distributions for each chosen action. First, we show that for a myopic Bayesian learning agent with only two possible actions, the empirical frequency of the chosen actions converges to a Berk-Nash equilibrium. However, through a constructed example, we illustrate that this convergence in action frequencies fails when the agent has three or more actions. Furthermore, with multiple actions, even computing an $\varepsilon$-Berk-Nash equilibrium requires at least quasi-polynomial time under the Exponential Time Hypothesis (ETH) for the PPAD-class. This finding poses a significant challenge to the existence of simple learning dynamics that converge in action frequencies. Motivated by this challenge, we focus on the contract design problems for an agent with misspecified beliefs and two possible actions. We show that the revenue-optimal contract, under a Berk-Nash equilibrium, can be computed in polynomial time. Perhaps surprisingly, we show that even a minor degree of misspecification can result in a significant reduction in optimal revenue.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20423v1</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yingkai Li, Argyris Oikonomou</dc:creator>
    </item>
    <item>
      <title>Quality of Non-Convergent Best Response Processes in Multi-Agent Systems through Sink Equilibrium</title>
      <link>https://arxiv.org/abs/2405.20426</link>
      <description>arXiv:2405.20426v1 Announce Type: new 
Abstract: Examining the behavior of multi-agent systems is vitally important to many emerging distributed applications - game theory has emerged as a powerful tool set in which to do so. The main approach of game-theoretic techniques is to model agents as players in a game, and predict the emergent behavior through the relevant Nash equilibrium. The virtue from this viewpoint is that by assuming that self-interested decision-making processes lead to Nash equilibrium, system behavior can then be captured by Nash equilibrium without studying the decision-making processes explicitly. This approach has seen success in a wide variety of domains, such as sensor coverage, traffic networks, auctions, and network coordination. However, in many other problem settings, Nash equilibrium are not necessarily guaranteed to exist or emerge from self-interested processes. Thus the main focus of the paper is on the study of sink equilibrium, which are defined as the attractors of these decision-making processes. By classifying system outcomes through a global objective function, we can analyze the resulting approximation guarantees that sink equilibrium have for a given game. Our main result is an approximation guarantee on the sink equilibrium through defining an introduced metric of misalignment, which captures how uniform agents are in their self-interested decision making. Overall, sink equilibrium are naturally occurring in many multi-agent contexts, and we display our results on their quality with respect to two practical problem settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20426v1</guid>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rohit Konda, Rahul Chandan, Jason Marden</dc:creator>
    </item>
    <item>
      <title>Optimizing Contracts in Principal-Agent Team Production</title>
      <link>https://arxiv.org/abs/2405.20631</link>
      <description>arXiv:2405.20631v1 Announce Type: new 
Abstract: I study a principal-agent team production model. The principal hires a team of agents to participate in a common production task. The exact effort of each agent is unobservable and unverifiable, but the total production outcome (e.g. the total revenue) can be observed. The principal incentivizes the agents to exert effort through contracts. Specifically, the principal promises that each agent receives a pre-specified amount of share of the total production output. The principal is interested in finding the optimal profit-sharing rule that maximizes her own utility. I identify a condition under which the principal's optimization problem can be reformulated as solving a family of convex programs, thereby showing the optimal contract can be found efficiently.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20631v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shiliang Zuo</dc:creator>
    </item>
    <item>
      <title>Reachability and Safety Games under TSO Semantics (Extended Version)</title>
      <link>https://arxiv.org/abs/2405.20804</link>
      <description>arXiv:2405.20804v1 Announce Type: new 
Abstract: We consider games played on the transtion graph of concurrent programs running under the TotalStore Order (TSO) weak memory model. Games are frequently used to model the interaction between a system and its environment, in this case between the concurrent processes and the nondeterminisitic TSO buffer updates. The game is played by two players, who alternatinglymake a move: Theprocess playercan execute any enabled instruction of the processes, while theupdate playertakes care of updating the messages in the buffers that are between each process andthe shared memory. We show that the reachability and safety problem of this game reduce to theanalysis of single-process (non-concurrent) programs. In particular, they exhibit only finite-statebehaviour. Because of this, we introduce different notions offairness, which force the two players tobehave in a more realistic way. Both the reachability and safety problem then become undecidable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20804v1</guid>
      <category>cs.GT</category>
      <category>cs.LO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stephan Spengler</dc:creator>
    </item>
    <item>
      <title>Paying to Do Better: Games with Payments between Learning Agents</title>
      <link>https://arxiv.org/abs/2405.20880</link>
      <description>arXiv:2405.20880v1 Announce Type: new 
Abstract: In repeated games, such as auctions, players typically use learning algorithms to choose their actions. The use of such autonomous learning agents has become widespread on online platforms. In this paper, we explore the impact of players incorporating monetary transfers into their agents' algorithms, aiming to incentivize behavior in their favor. Our focus is on understanding when players have incentives to make use of monetary transfers, how these payments affect learning dynamics, and what the implications are for welfare and its distribution among the players. We propose a simple game-theoretic model to capture such scenarios. Our results on general games show that in a broad class of games, players benefit from letting their learning agents make payments to other learners during the game dynamics, and that in many cases, this kind of behavior improves welfare for all players. Our results on first- and second-price auctions show that in equilibria of the ``payment policy game,'' the agents' dynamics can reach strong collusive outcomes with low revenue for the auctioneer. These results highlight a challenge for mechanism design in systems where automated learning agents can benefit from interacting with their peers outside the boundaries of the mechanism.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20880v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>econ.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yoav Kolumbus, Joe Halpern, \'Eva Tardos</dc:creator>
    </item>
    <item>
      <title>Likelihood Equilibria in the Ising Game</title>
      <link>https://arxiv.org/abs/2405.21010</link>
      <description>arXiv:2405.21010v1 Announce Type: new 
Abstract: A description of static equilibria in the noisy binary choice (Ising) game on complete and random graphs resulting from maximisation of the likelihood of system configurations is presented. An equivalence of such likelihood equilibria to the competitive Bayes-Nash quantal response expectation equilibria in the special case of consistent agents expectations is established. It is shown that the same likelihood equilibria are obtained by considering the system's partition function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.21010v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrey Leonidov</dc:creator>
    </item>
    <item>
      <title>Fusion-PSRO: Nash Policy Fusion for Policy Space Response Oracles</title>
      <link>https://arxiv.org/abs/2405.21027</link>
      <description>arXiv:2405.21027v1 Announce Type: new 
Abstract: For solving zero-sum games involving non-transitivity, a common approach is to maintain population policies to approximate the Nash Equilibrium (NE). Previous research has shown that the Policy Space Response Oracle (PSRO) is an effective multi-agent reinforcement learning framework for these games. However, repeatedly training new policies from scratch to approximate the Best Response (BR) to opponents' mixed policies at each iteration is inefficient and costly. While some PSRO methods initialize a new BR policy by inheriting from past BR policies, this approach limits the exploration of new policies, especially against challenging opponents.To address this issue, we propose Fusion-PSRO, which uses model fusion to initialize the policy for better approximation to BR. With Top-k probabilities from NE, we select high-quality base policies and fuse them into a new BR policy through model averaging. This approach allows the initialized policy to incorporate multiple expert policies, making it easier to handle difficult opponents compared to inheriting or initializing from scratch. Additionally, our method only modifies the policy initialization, enabling its application to nearly all PSRO variants without additional training overhead.Our experiments with non-transitive matrix games, Leduc poker, and the more complex Liars Dice demonstrate that Fusion-PSRO enhances the performance of nearly all PSRO variants, achieving lower exploitability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.21027v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiesong Lian, Yucong Huang, Mingzhi Wang, Chengdong Ma, Yixue Hao, Ying Wen, Yaodong Yang</dc:creator>
    </item>
    <item>
      <title>No-Regret Learning for Fair Multi-Agent Social Welfare Optimization</title>
      <link>https://arxiv.org/abs/2405.20678</link>
      <description>arXiv:2405.20678v1 Announce Type: cross 
Abstract: We consider the problem of online multi-agent Nash social welfare (NSW) maximization. While previous works of Hossain et al. [2021], Jones et al. [2023] study similar problems in stochastic multi-agent multi-armed bandits and show that $\sqrt{T}$-regret is possible after $T$ rounds, their fairness measure is the product of all agents' rewards, instead of their NSW (that is, their geometric mean). Given the fundamental role of NSW in the fairness literature, it is more than natural to ask whether no-regret fair learning with NSW as the objective is possible. In this work, we provide a complete answer to this question in various settings. Specifically, in stochastic $N$-agent $K$-armed bandits, we develop an algorithm with $\widetilde{\mathcal{O}}\left(K^{\frac{2}{N}}T^{\frac{N-1}{N}}\right)$ regret and prove that the dependence on $T$ is tight, making it a sharp contrast to the $\sqrt{T}$-regret bounds of Hossain et al. [2021], Jones et al. [2023]. We then consider a more challenging version of the problem with adversarial rewards. Somewhat surprisingly, despite NSW being a concave function, we prove that no algorithm can achieve sublinear regret. To circumvent such negative results, we further consider a setting with full-information feedback and design two algorithms with $\sqrt{T}$-regret: the first one has no dependence on $N$ at all and is applicable to not just NSW but a broad class of welfare functions, while the second one has better dependence on $K$ and is preferable when $N$ is small. Finally, we also show that logarithmic regret is possible whenever there exists one agent who is indifferent about different arms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20678v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mengxiao Zhang, Ramiro Deo-Campo Vuong, Haipeng Luo</dc:creator>
    </item>
    <item>
      <title>Matrix Rationalization via Partial Orders</title>
      <link>https://arxiv.org/abs/2405.20976</link>
      <description>arXiv:2405.20976v1 Announce Type: cross 
Abstract: A preference matrix $M$ has an entry for each pair of candidates in an election whose value $p_{ij}$ represents the proportion of voters that prefer candidate $i$ over candidate $j$. The matrix is rationalizable if it is consistent with a set of voters whose preferences are total orders. A celebrated open problem asks for a concise characterization of rationalizable preference matrices. In this paper, we generalize this matrix rationalizability question and study when a preference matrix is consistent with a set of voters whose preferences are partial orders of width $\alpha$. The width (the maximum cardinality of an antichain) of the partial order is a natural measure of the rationality of a voter; indeed, a partial order of width $1$ is a total order. Our primary focus concerns the rationality number, the minimum width required to rationalize a preference matrix. We present two main results. The first concerns the class of half-integral preference matrices, where we show the key parameter required in evaluating the rationality number is the chromatic number of the undirected unanimity graph associated with the preference matrix $M$. The second concerns the class of integral preference matrices, where we show the key parameter now is the dichromatic number of the directed voting graph associated with $M$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20976v1</guid>
      <category>cs.DM</category>
      <category>cs.GT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Agnes Totschnig, Rohit Vasishta, Adrian Vetta</dc:creator>
    </item>
    <item>
      <title>Stochastic Online Fisher Markets: Static Pricing Limits and Adaptive Enhancements</title>
      <link>https://arxiv.org/abs/2205.00825</link>
      <description>arXiv:2205.00825v4 Announce Type: replace 
Abstract: Fisher markets are one of the most fundamental models for resource allocation. However, the problem of computing equilibrium prices in Fisher markets typically relies on complete knowledge of users' budgets and utility functions and requires transactions to happen in a static market where all users are present simultaneously. Motivated by these practical considerations, we study an online variant of Fisher markets, wherein users with privately known utility and budget parameters, drawn i.i.d. from a distribution, arrive sequentially. In this setting, we first study the limitations of static pricing algorithms, which set uniform prices for all users, along two performance metrics: (i) regret, i.e., the optimality gap in the objective of the Eisenberg-Gale program between an online algorithm and an oracle with complete information, and (ii) capacity violations, i.e., the over-consumption of goods relative to their capacities. Given the limitations of static pricing, we design adaptive posted-pricing algorithms, one with knowledge of the distribution of users' budget and utility parameters and another that adjusts prices solely based on past observations of user consumption, i.e., revealed preference feedback, with improved performance guarantees. Finally, we present numerical experiments to compare our revealed preference algorithm's performance to several benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.00825v4</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Devansh Jalota, Yinyu Ye</dc:creator>
    </item>
  </channel>
</rss>
