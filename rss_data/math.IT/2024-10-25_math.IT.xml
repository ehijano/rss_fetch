<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.IT</link>
    <description>math.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 25 Oct 2024 04:03:34 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>LEO-based Positioning: Foundations, Signal Design, and Receiver Enhancements for 6G NTN</title>
      <link>https://arxiv.org/abs/2410.18301</link>
      <description>arXiv:2410.18301v1 Announce Type: new 
Abstract: The integration of non-terrestrial networks (NTN) into 5G new radio (NR) has opened up the possibility of developing a new positioning infrastructure using NR signals from Low-Earth Orbit (LEO) satellites. LEO-based cellular positioning offers several advantages, such as a superior link budget, higher operating bandwidth, and large forthcoming constellations. Due to these factors, LEO-based positioning, navigation, and timing (PNT) is a potential enhancement for NTN in 6G cellular networks. However, extending the existing terrestrial cellular positioning methods to LEO-based NTN positioning requires considering key fundamental enhancements. These include creating broad positioning beams orthogonal to conventional communication beams, time-domain processing at the user equipment (UE) to resolve large delay and Doppler uncertainties, and efficiently accommodating positioning reference signals (PRS) from multiple satellites within the communication resource grid. In this paper, we present the first set of design insights by incorporating these enhancements and thoroughly evaluating LEO-based positioning, considering the constraints and capabilities of the NR-NTN physical layer. To evaluate the performance of LEO-based NTN positioning, we develop a comprehensive NR-compliant simulation framework, including LEO orbit simulation, transmission (Tx) and receiver (Rx) architectures, and a positioning engine incorporating the necessary enhancements. Our findings suggest that LEO-based NTN positioning could serve as a complementary infrastructure to existing Global Navigation Satellite Systems (GNSS) and, with appropriate enhancements, may also offer a viable alternative.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18301v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Harish K. Dureppagari, Chiranjib Saha, Harikumar Krishnamurthy, Xiao Feng Wang, Alberto Rico-Alvari\~no, R. Michael Buehrer, Harpreet S. Dhillon</dc:creator>
    </item>
    <item>
      <title>On maximal almost balanced non-overlapping codes and non-overlapping codes with restricted run-lengths</title>
      <link>https://arxiv.org/abs/2410.18458</link>
      <description>arXiv:2410.18458v1 Announce Type: new 
Abstract: This paper concerns non-overlapping codes, block codes motivated by synchronisation and DNA-based storage applications. Most existing constructions of these codes do not account for the restrictions posed by the physical properties of communication channels. If undesired sequences are not avoided, the system using the encoding may start behaving incorrectly. Hence, we aim to characterise all non-overlapping codes satisfying two additional constraints. For the first constraint, where approximately half of the letters in each word are positive, we derive necessary and sufficient conditions for the code's non-expandability and improve known bounds on its maximum size. We also determine exact values for the maximum sizes of polarity-balanced non-overlapping codes having small block and alphabet sizes. For the other constraint, where long sequences of consecutive equal symbols lead to undesired behaviour, we derive bounds and constructions of constrained non-overlapping codes. Moreover, we provide constructions of non-overlapping codes that satisfy both constraints and analyse the sizes of the obtained codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18458v1</guid>
      <category>cs.IT</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lidija Stanovnik, Miha Mo\v{s}kon, Miha Mraz</dc:creator>
    </item>
    <item>
      <title>Achieving Distributed MIMO Performance with Repeater-Assisted Cellular Massive MIMO</title>
      <link>https://arxiv.org/abs/2406.00142</link>
      <description>arXiv:2406.00142v2 Announce Type: cross 
Abstract: In what ways could cellular massive MIMO be improved? This technology has already been shown to bring huge performance gains. However, coverage holes and difficulties to transmit multiple streams to multi-antenna users because of insufficient channel rank remain issues. Distributed MIMO, also known as cell-free massive MIMO, might be the ultimate solution. However, while being a powerful technology, it is expensive to install backhaul, and it is a difficult problem to achieve accurate phase alignment for coherent multiuser beamforming on downlink. Another option is reflective intelligent surfaces -- but they have large form factors and require a lot of training and control overhead, and probably, in practice, some form of active filtering to make them sufficiently band-selective.
  We propose a new approach to densification of cellular systems, envisioning repeater-assisted cellular massive MIMO, where a large numbers of physically small and cheap wireless repeaters are deployed. They receive and retransmit signals instantaneously, appearing as ordinary scatterers in the channel but with amplification. We elaborate on the requirements of such repeaters, show that the performance of these systems could potentially approach that of distributed MIMO, and outline future research directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00142v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sara Willhammar, Hiroki Iimori, Joao Vieira, Lars Sundstr\"om, Fredrik Tufvesson, Erik G. Larsson</dc:creator>
    </item>
    <item>
      <title>Reconstruction with prior support information and non-Gaussian constraints</title>
      <link>https://arxiv.org/abs/2410.18116</link>
      <description>arXiv:2410.18116v1 Announce Type: cross 
Abstract: In this study, we introduce a novel model, termed the Weighted Basis Pursuit Dequantization ($\omega$-BPDQ$_p$), which incorporates prior support information by assigning weights on the $\ell_1$ norm in the $\ell_1$ minimization process and replaces the $\ell_2$ norm with the $\ell_p$ norm in the constraint. This adjustment addresses cases where noise deviates from a Gaussian distribution, such as quantized errors, which are common in practice. We demonstrate that Restricted Isometry Property (RIP$_{p,q}$) and Weighted Robust Null Space Property ($\omega$-RNSP$_{p,q}$) ensure stable and robust reconstruction within $\omega$-BPDQ$_p$, with the added observation that standard Gaussian random matrices satisfy these properties with high probability. Moreover, we establish a relationship between RIP$_{p,q}$ and $\omega$-RNSP$_{p,q}$ that RIP$_{p,q}$ implies $\omega$-RNSP$_{p,q}$. Additionally, numerical experiments confirm that the incorporation of weights and the non-Gaussian constraint results in improved reconstruction quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18116v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.CA</category>
      <category>math.IT</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaotong Liu, Yiyu Liang</dc:creator>
    </item>
    <item>
      <title>Multi-Draft Speculative Sampling: Canonical Architectures and Theoretical Limits</title>
      <link>https://arxiv.org/abs/2410.18234</link>
      <description>arXiv:2410.18234v1 Announce Type: cross 
Abstract: We consider multi-draft speculative sampling, where the proposal sequences are sampled independently from different draft models. At each step, a token-level draft selection scheme takes a list of valid tokens as input and produces an output token whose distribution matches that of the target model. Previous works have demonstrated that the optimal scheme (which maximizes the probability of accepting one of the input tokens) can be cast as a solution to a linear program. In this work we show that the optimal scheme can be decomposed into a two-step solution: in the first step an importance sampling (IS) type scheme is used to select one intermediate token; in the second step (single-draft) speculative sampling is applied to generate the output token. For the case of two identical draft models we further 1) establish a necessary and sufficient condition on the distributions of the target and draft models for the acceptance probability to equal one and 2) provide an explicit expression for the optimal acceptance probability. Our theoretical analysis also motives a new class of token-level selection scheme based on weighted importance sampling. Our experimental results demonstrate consistent improvements in the achievable block efficiency and token rates over baseline schemes in a number of scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18234v1</guid>
      <category>cs.CL</category>
      <category>cs.DC</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ashish Khisti, M. Reza Ebrahimi, Hassan Dbouk, Arash Behboodi, Roland Memisevic, Christos Louizos</dc:creator>
    </item>
    <item>
      <title>Refining Ky Fan's majorization relation with linear programming</title>
      <link>https://arxiv.org/abs/2410.18254</link>
      <description>arXiv:2410.18254v1 Announce Type: cross 
Abstract: A separable version of Ky Fan's majorization relation is proven for a sum of two operators that are each a tensor product of two positive semi-definite operators. In order to prove it, upper bounds are established for the relevant largest eigenvalue sums in terms of the optimal values of certain linear programs. The objective function of these linear programs is the dual of the direct sum of the spectra of the summands. The feasible sets are bounded polyhedra determined by positive numbers, called alignment terms, that quantify the overlaps between pairs of largest eigenvalue spaces of the summands. By appealing to geometric considerations, tight upper bounds are established on the alignment terms of tensor products of positive semi-definite operators. As an application, the spin alignment conjecture in quantum information theory is affirmatively resolved to the 2-letter level. Consequently, the coherent information of platypus channels is additive to the 2-letter level.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18254v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.RA</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad A. Alhejji</dc:creator>
    </item>
    <item>
      <title>Sliding DFT-based Signal Recovery for Modulo ADC with 1-bit Folding Information</title>
      <link>https://arxiv.org/abs/2410.18757</link>
      <description>arXiv:2410.18757v1 Announce Type: cross 
Abstract: The modulo analog-to-digital converter (ADC) is a promising solution to resolve the limited dynamic range (DR) issue of conventional ADCs. However, a modulo ADC requires an unfolding scheme to correct the nonlinear distortion introduced by the modulo operation. This paper presents a sliding discrete Fourier Transform (DFT)-based method for fast signal reconstruction given the modulo ADC output sequence and a 1-bit folding information sequence. In contrast to existing DFT-based signal recovery techniques for modulo ADCs, our proposed sliding DFT method reduces the required observation time and minimizes the spectral leakage effects via proper choice of window function parameters. A mean squared error (MSE) performance guarantee is established for the proposed signal recovery algorithm. More precisely, we derive sufficient conditions for the oversampling factor ($\mathrm{OF}$) and the number of quantization bits ($b$) to obtain a specific MSE performance. Our numerical results demonstrate that modulo ADCs equipped with our proposed recovery method can outperform conventional ADCs without modulo for $\mathrm{OF} \geq 4$ and $b \geq 4$. The impact of spectral leakage on the MSE performance of the proposed sliding DFT recovery method is also quantified.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18757v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Neil Irwin Bernardo</dc:creator>
    </item>
    <item>
      <title>Approximate Message Passing with Rigorous Guarantees for Pooled Data and Quantitative Group Testing</title>
      <link>https://arxiv.org/abs/2309.15507</link>
      <description>arXiv:2309.15507v4 Announce Type: replace 
Abstract: In the pooled data problem, the goal is to identify the categories associated with a large collection of items via a sequence of pooled tests. Each pooled test reveals the number of items of each category within the pool. We study an approximate message passing (AMP) algorithm for estimating the categories and rigorously characterize its performance, in both the noiseless and noisy settings. For the noiseless setting, we show that the AMP algorithm is equivalent to one recently proposed by El Alaoui et al. Our results provide a rigorous version of their performance guarantees, previously obtained via non-rigorous techniques. For the case of pooled data with two categories, known as quantitative group testing (QGT), we use the AMP guarantees to compute precise limiting values of the false positive rate and the false negative rate. Though the pooled data problem and QGT are both instances of estimation in a linear model, existing AMP theory cannot be directly applied since the design matrices are binary valued. The key technical ingredient in our analysis is a rigorous asymptotic characterization of AMP for generalized linear models defined via generalized white noise design matrices. This result, established using a recent universality result of Wang et al., is of independent interest. Our theoretical results are validated by numerical simulations. For comparison, we propose estimators based on convex relaxation and iterative thresholding, without providing theoretical guarantees. The simulations indicate that AMP consistently outperforms these estimators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.15507v4</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1137/23M1604928</arxiv:DOI>
      <arxiv:journal_reference>SIAM Journal on Mathematics of Data Science, vol. 6, no. 4, pp. 1027-1054, 2024</arxiv:journal_reference>
      <dc:creator>Nelvin Tan, Pablo Pascual Cobo, Jonathan Scarlett, Ramji Venkataramanan</dc:creator>
    </item>
    <item>
      <title>Sequential Outlier Hypothesis Testing under Universality Constraints</title>
      <link>https://arxiv.org/abs/2404.14221</link>
      <description>arXiv:2404.14221v3 Announce Type: replace 
Abstract: We revisit sequential outlier hypothesis testing and derive bounds on achievable exponents when both the nominal and anomalous distributions are \emph{unknown}. The task of outlier hypothesis testing is to identify the set of outliers that are generated from an anomalous distribution among all observed sequences where the rest majority are generated from a nominal distribution. In the sequential setting, one obtains a sample from each sequence per unit time until a reliable decision could be made. For the case with exactly one outlier, our exponent bounds on are tight, providing exact large deviations characterization of sequential tests and strengthening a previous result of Li, Nitinawarat and Veeravalli (2017). In particular, the average sample size of our sequential test is bounded universally under any pair of nominal and anomalous distributions and our sequential test achieves larger Bayesian exponent than the fixed-length test, which could not be guaranteed by the sequential test of Li, Nitinawarat and Veeravalli (2017). For the case with at most one outlier, we propose a threshold-based test that has bounded expected stopping time under mild conditions and we bound the error exponents under each non-null and the null hypotheses. Our sequential test resolves the error exponents tradeoff for the fixed-length test of Zhou, Wei and Hero (TIT 2022). Finally, with a further step towards practical applications, we generalize our results to the cases of multiple outliers and show that there is a penalty in the error exponents when the number of outliers is unknown.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14221v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jun Diao, Lin Zhou</dc:creator>
    </item>
    <item>
      <title>A Unified View of Group Fairness Tradeoffs Using Partial Information Decomposition</title>
      <link>https://arxiv.org/abs/2406.04562</link>
      <description>arXiv:2406.04562v2 Announce Type: replace 
Abstract: This paper introduces a novel information-theoretic perspective on the relationship between prominent group fairness notions in machine learning, namely statistical parity, equalized odds, and predictive parity. It is well known that simultaneous satisfiability of these three fairness notions is usually impossible, motivating practitioners to resort to approximate fairness solutions rather than stringent satisfiability of these definitions. However, a comprehensive analysis of their interrelations, particularly when they are not exactly satisfied, remains largely unexplored. Our main contribution lies in elucidating an exact relationship between these three measures of (un)fairness by leveraging a body of work in information theory called partial information decomposition (PID). In this work, we leverage PID to identify the granular regions where these three measures of (un)fairness overlap and where they disagree with each other leading to potential tradeoffs. We also include numerical simulations to complement our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04562v2</guid>
      <category>cs.IT</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/ISIT57864.2024.10619698</arxiv:DOI>
      <dc:creator>Faisal Hamman, Sanghamitra Dutta</dc:creator>
    </item>
    <item>
      <title>Striking a New Chord: Neural Networks in Music Information Dynamics</title>
      <link>https://arxiv.org/abs/2410.17989</link>
      <description>arXiv:2410.17989v2 Announce Type: replace 
Abstract: Initiating a quest to unravel the complexities of musical aesthetics through the lens of information dynamics, our study delves into the realm of musical sequence modeling, drawing a parallel between the sequential structured nature of music and natural language.
  Despite the prevalence of neural network models in MIR, the modeling of symbolic music events as applied to music cognition and music neuroscience has largely relied on statistical models. In this "proof of concept" paper we posit the superiority of neural network models over statistical models for predicting musical events. Specifically, we compare LSTM, Transformer, and GPT models against a widely-used markov model to predict a chord event following a sequence of chords.
  Utilizing chord sequences from the McGill Billboard dataset, we trained each model to predict the next chord from a given sequence of chords. We found that neural models significantly outperformed statistical ones in our study. Specifically, the LSTM with attention model led with an accuracy of 0.329, followed by Transformer models at 0.321, GPT at 0.301, and standard LSTM at 0.191. Variable Order Markov and Markov trailed behind with accuracies of 0.277 and 0.140, respectively. Encouraged by these results, we extended our investigation to multidimensional modeling, employing a many-to-one LSTM, LSTM with attention, Transformer, and GPT predictors. These models were trained on both chord and melody lines as two-dimensional data using the CoCoPops Billboard dataset, achieving an accuracy of 0.083, 0.312, 0.271, and 0.120, respectively, in predicting the next chord.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17989v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Farshad Jafari, Claire Arthur</dc:creator>
    </item>
    <item>
      <title>The Representation Jensen-Shannon Divergence</title>
      <link>https://arxiv.org/abs/2305.16446</link>
      <description>arXiv:2305.16446v4 Announce Type: replace-cross 
Abstract: Quantifying the difference between probability distributions is crucial in machine learning. However, estimating statistical divergences from empirical samples is challenging due to unknown underlying distributions. This work proposes the representation Jensen-Shannon divergence (RJSD), a novel measure inspired by the traditional Jensen-Shannon divergence. Our approach embeds data into a reproducing kernel Hilbert space (RKHS), representing distributions through uncentered covariance operators. We then compute the Jensen-Shannon divergence between these operators, thereby establishing a proper divergence measure between probability distributions in the input space. We provide estimators based on kernel matrices and empirical covariance matrices using Fourier features. Theoretical analysis reveals that RJSD is a lower bound on the Jensen-Shannon divergence, enabling variational estimation. Additionally, we show that RJSD is a higher-order extension of the maximum mean discrepancy (MMD), providing a more sensitive measure of distributional differences. Our experimental results demonstrate RJSD's superiority in two-sample testing, distribution shift detection, and unsupervised domain adaptation, outperforming state-of-the-art techniques. RJSD's versatility and effectiveness make it a promising tool for machine learning research and applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.16446v4</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jhoan K. Hoyos-Osorio, Luis G. Sanchez-Giraldo</dc:creator>
    </item>
    <item>
      <title>Equivalence of the Empirical Risk Minimization to Regularization on the Family of f-Divergences</title>
      <link>https://arxiv.org/abs/2402.00501</link>
      <description>arXiv:2402.00501v2 Announce Type: replace-cross 
Abstract: The solution to empirical risk minimization with $f$-divergence regularization (ERM-$f$DR) is presented under mild conditions on $f$. Under such conditions, the optimal measure is shown to be unique. Examples of the solution for particular choices of the function $f$ are presented. Previously known solutions to common regularization choices are obtained by leveraging the flexibility of the family of $f$-divergences. These include the unique solutions to empirical risk minimization with relative entropy regularization (Type-I and Type-II). The analysis of the solution unveils the following properties of $f$-divergences when used in the ERM-$f$DR problem: $i\bigl)$ $f$-divergence regularization forces the support of the solution to coincide with the support of the reference measure, which introduces a strong inductive bias that dominates the evidence provided by the training data; and $ii\bigl)$ any $f$-divergence regularization is equivalent to a different $f$-divergence regularization with an appropriate transformation of the empirical risk function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.00501v2</guid>
      <category>stat.ML</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francisco Daunas, I\~naki Esnaola, Samir M. Perlaza, H. Vincent Poor</dc:creator>
    </item>
  </channel>
</rss>
