<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 16 Oct 2025 04:00:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A faster algorithm for efficient longest common substring calculation for non-parametric entropy estimation in sequential data</title>
      <link>https://arxiv.org/abs/2510.13330</link>
      <description>arXiv:2510.13330v1 Announce Type: new 
Abstract: Non-parametric entropy estimation on sequential data is a fundamental tool in signal processing, capturing information flow within or between processes to measure predictability, redundancy, or similarity. Methods based on longest common substrings (LCS) provide a non-parametric estimate of typical set size but are often inefficient, limiting use on real-world data. We introduce LCSFinder, a new algorithm that improves the worst-case performance of LCS calculations from cubic to log-linear time. Although built on standard algorithmic constructs - including sorted suffix arrays and persistent binary search trees - the details require care to provide the matches required for entropy estimation on dynamically growing sequences. We demonstrate that LCSFinder achieves dramatic speedups over existing implementations on real and simulated data, enabling entropy estimation at scales previously infeasible in practical signal processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13330v1</guid>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bridget Smart, Max Ward, Matthew Roughan</dc:creator>
    </item>
    <item>
      <title>Tight Parameterized (In)tractability of Layered Crossing Minimization: Subexponential Algorithms and Kernelization</title>
      <link>https://arxiv.org/abs/2510.13335</link>
      <description>arXiv:2510.13335v1 Announce Type: new 
Abstract: The starting point of our work is a decade-old open question concerning the subexponential parameterized complexity of \textsc{2-Layer Crossing Minimization}. In this problem, the input is an $n$-vertex graph $G$ whose vertices are partitioned into two independent sets $V_1$ and $V_2$, and a non-negative integer $k$. The question is whether $G$ admits a 2-layered drawing with at most $k$ crossings, where each $V_i$ lies on a distinct line parallel to the $x$-axis, and all edges are straight lines. We resolve this open question by giving the first subexponential fixed-parameter algorithm for this problem, running in time $2^{O(\sqrt{k}\log k)} + n \cdot k^{O(1)}$.
  We then ask whether the subexponential phenomenon extends beyond two layers. In the general $h$-Layer Crossing Minimization problem, the vertex set is partitioned into $h$ independent sets $V_1, \ldots, V_h$, and the goal is to decide whether an $h$-layered drawing with at most $k$ crossings exists. We present a subexponential FPT algorithm for three layers with running time $2^{O(k^{2/3}\log k)} + n \cdot k^{O(1)}$ for $h = 3$ layers. In contrast, we show that for all $h \ge 5$, no algorithm with running time $2^{o(k/\log k)} \cdot n^{O(1)}$ exists unless the Exponential-Time Hypothesis fails.
  Finally, we address polynomial kernelization. While a polynomial kernel was already known for $h=2$, we design a new polynomial kernel for $h=3$. These kernels are essential ingredients in our subexponential algorithms. Finally, we rule out polynomial kernels for all $h \ge 4$ unless the polynomial hierarchy collapses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13335v1</guid>
      <category>cs.DS</category>
      <category>cs.CG</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fedor V. Fomin, Petr A. Golovach, Tanmay Inamdar, Saket Saurabh, Meirav Zehavi</dc:creator>
    </item>
    <item>
      <title>Chromatic correlation clustering via cluster LP</title>
      <link>https://arxiv.org/abs/2510.13446</link>
      <description>arXiv:2510.13446v1 Announce Type: new 
Abstract: Correlation Clustering is a fundamental clustering problem, and there has been a line of work on improving the approximation ratio for this problem in recent years. A key algorithmic component in these works is the cluster LP. Chromatic Correlation Clustering is an interesting generalization that has also been intensively studied. In light of success of the cluster LP in Correlation Clustering, it would be an interesting question whether the cluster LP can be used in Chromatic Correlation Clustering. We answer this question with affirmatives by presenting a $(2+\varepsilon)$-approximation algorithm for Chromatic Correlation Clustering using a chromatic cluster LP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13446v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Fateme Abbasi, Hyung-Chan An, Jaros{\l}aw Byrka, Changyeol Lee, Yongho Shin</dc:creator>
    </item>
    <item>
      <title>Distributed Reductions for the Maximum Weight Independent Set Problem</title>
      <link>https://arxiv.org/abs/2510.13306</link>
      <description>arXiv:2510.13306v1 Announce Type: cross 
Abstract: Finding maximum-weight independent sets in graphs is an important NP-hard optimization problem. Given a vertex-weighted graph $G$, the task is to find a subset of pairwise non-adjacent vertices of $G$ with maximum weight. Most recently published practical exact algorithms and heuristics for this problem use a variety of data-reduction rules to compute (near-)optimal solutions. Applying these rules results in an equivalent instance of reduced size. An optimal solution to the reduced instance can be easily used to construct an optimal solution for the original input.
  In this work, we present the first distributed-memory parallel reduction algorithms for this problem, targeting graphs beyond the scale of previous sequential approaches. Furthermore, we propose the first distributed reduce-and-greedy and reduce-and-peel algorithms for finding a maximum weight independent set heuristically.
  In our practical evaluation, our experiments on up to $1024$ processors demonstrate good scalability of our distributed reduce algorithms while maintaining good reduction impact. Our asynchronous reduce-and-peel approach achieves an average speedup of $33\times$ over a sequential state-of-the-art reduce-and-peel approach on 36 real-world graphs with a solution quality close to the sequential algorithm. Our reduce-and-greedy algorithms even achieve average speedups of up to $50\times$ at the cost of a lower solution quality. Moreover, our distributed approach allows us to consider graphs with more than one billion vertices and 17 billion edges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13306v1</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jannick Borowitz, Ernestine Gro{\ss}mann, Mattthias Schimek</dc:creator>
    </item>
    <item>
      <title>Online Metric Matching: Beyond the Worst Case</title>
      <link>https://arxiv.org/abs/2407.14785</link>
      <description>arXiv:2407.14785v3 Announce Type: replace 
Abstract: We study the online metric matching problem. There are $m$ servers and $n$ requests located in a metric space, where all servers are available upfront and requests arrive one at a time. Upon the arrival of a new request, it needs to be immediately and irrevocably matched to an available server, resulting in a cost of their distance. The objective is to minimize the total matching cost.
  When servers are adversarial and requests are independently drawn from a known distribution, we reduce the problem to a more tractable setting where servers and requests are all independently drawn from the same distribution. Applying our reduction, for $[0, 1]^d$ with various choices of distributions, we achieve improved competitive ratios and nearly optimal regret in both balanced and unbalanced markets. In particular, we give $O(1)$-competitive algorithms for $d \geq 3$ in both balanced and unbalanced markets with smooth distributions. Our algorithms improve on the $O((\log \log \log n)^2)$ competitive ratio of Gupta et al. (ICALP'19) for balanced markets in various regimes, and provide the first positive results for unbalanced markets. Moreover, when servers and requests are all adversarial, and a prediction of request locations is provided, we present a general framework for transforming an arbitrary algorithm that does not use predictions into an algorithm that leverages predictions. The transformation applies the given algorithm in a black-box manner, and the performance of the resulting algorithm degrades smoothly as the prediction accuracy deteriorates while preserving the worst-case guarantee.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14785v3</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mingwei Yang, Sophie H. Yu</dc:creator>
    </item>
    <item>
      <title>Bounded indegree $k$-forests problem and a faster algorithm for directed graph augmentation</title>
      <link>https://arxiv.org/abs/2409.14881</link>
      <description>arXiv:2409.14881v2 Announce Type: replace 
Abstract: We consider two problems for a directed graph $G$, which we show to be closely related. The first one is to find $k$ edge-disjoint forests in $G$ of maximal size such that the indegree of each vertex in these forests is at most $k$. We describe a min-max characterization for this problem and show that it can be solved in $O(k \delta m \log n)$ time, where $(n,m)$ is the size of $G$ and $\delta$ is the difference between $k$ and the edge connectivity of the graph. The second problem is the directed edge-connectivity augmentation problem, which has been extensively studied before: find a smallest set of directed edges whose addition to the graph makes it strongly $k$-connected. We improve the complexity for this problem from $O(k \delta (m+\delta n)\log n)$ [Gabow, STOC 1994] to $O(k \delta m \log n)$, by exploiting our solution for the first problem. A similar approach with the same complexity also works for the undirected version of the problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14881v2</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pavel Arkhipov, Vladimir Kolmogorov</dc:creator>
    </item>
    <item>
      <title>Faster algorithms for packing forests in graphs and related problems</title>
      <link>https://arxiv.org/abs/2409.20314</link>
      <description>arXiv:2409.20314v2 Announce Type: replace 
Abstract: We consider several problems related to packing forests in graphs. The first one is to find $k$ edge-disjoint forests in a directed graph $G$ of maximal size such that the indegree of each vertex in these forests is at most $k$. We describe a min-max characterization for this problem and show that it can be solved in almost linear time for fixed $k$, extending the algorithm of [Gabow, 1995]. Specifically, the complexity is $O(k \delta m \log n)$, where $n, m$ are the number of vertices and edges in $G$ respectively, and $\delta = \max\{1, k - k_G\}$, where $k_G$ is the edge connectivity of the graph. Using our solution to this problem, we improve complexities for two existing applications:
  (1) $k$-forest problem: find $k$ forests in an undirected graph $G$ maximizing the number of edges in their union. We show how to solve this problem in $O(k^3 \min\{kn, m\} \log^2 n + k \cdot{\rm MAXFLOW}(m, m) \log n)$ time, breaking the $O_k(n^{3/2})$ complexity barrier of previously known approaches.
  (2) Directed edge-connectivity augmentation problem: find a smallest set of directed edges whose addition to the given directed graph makes it strongly $k$-connected. We improve the deterministic complexity for this problem from $O(k \delta (m+\delta n)\log n)$ [Gabow, STOC 1994] to $O(k \delta m \log n)$. A similar approach with the same complexity also works for the undirected version of the problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.20314v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pavel Arkhipov, Vladimir Kolmogorov</dc:creator>
    </item>
    <item>
      <title>3SUM in Preprocessed Universes: Faster and Simpler</title>
      <link>https://arxiv.org/abs/2410.16784</link>
      <description>arXiv:2410.16784v3 Announce Type: replace 
Abstract: We revisit the 3SUM problem in the \emph{preprocessed universes} setting. We present an algorithm that, given three sets $A$, $B$, $C$ of $n$ integers, preprocesses them in quadratic time, so that given any subsets $A' \subseteq A$, $B' \subseteq B$, $C' \subseteq C$, it can decide if there exist $a \in A'$, $b \in B'$, $c \in C'$ with $a+b=c$ in time $O(n^{1.5} \log n)$.
  In contrast to both the first subquadratic $\tilde{O}(n^{13/7})$-time algorithm by Chan and Lewenstein (STOC 2015) and the current fastest $\tilde{O}(n^{11/6})$-time algorithm by Chan, Vassilevska Williams, and Xu (STOC 2023), which are based on the Balog--Szemer\'edi--Gowers theorem from additive combinatorics, our algorithm uses only standard 3SUM-related techniques, namely FFT and linear hashing modulo a prime. It is therefore not only faster but also simpler.
  Just as the two previous algorithms, ours not only decides if there is a single 3SUM solution but it actually determines for each $c \in C'$ if there is a solution containing it. We also modify the algorithm to still work in the scenario where the set $C$ is unknown at the time of preprocessing. Finally, even though the simplest version of our algorithm is randomized, we show how to make it deterministic losing only polylogarithmic factors in the running time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16784v3</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.46298/theoretics.25.24</arxiv:DOI>
      <arxiv:journal_reference>TheoretiCS, Volume 4 (2025), Article 24, 1-12</arxiv:journal_reference>
      <dc:creator>Shashwat Kasliwal, Adam Polak, Pratyush Sharma</dc:creator>
    </item>
    <item>
      <title>Graph modification of bounded size to minor-closed classes as fast as vertex deletion</title>
      <link>https://arxiv.org/abs/2504.16803</link>
      <description>arXiv:2504.16803v2 Announce Type: replace 
Abstract: A replacement action is a function $\mathcal{L}$ that maps each graph $H$ to a collection of graphs of size at most $|V(H)|$. Given a graph class $\mathcal{H}$, we consider a general family of graph modification problems, called $\mathcal{L}$-Replacement to $\mathcal{H}$, where the input is a graph $G$ and the question is whether it is possible to replace some induced subgraph $H_1$ of $G$ on at most $k$ vertices by a graph $H_2$ in $\mathcal{L}(H_1)$ so that the resulting graph belongs to $\mathcal{H}$. $\mathcal{L}$-Replacement to $\mathcal{H}$ can simulate many graph modification problems including vertex deletion, edge deletion/addition/edition/contraction, vertex identification, subgraph complementation, independent set deletion, (induced) matching deletion/contraction, etc. We present two algorithms. The first one solves $\mathcal{L}$-Replacement to $\mathcal{H}$ in time $2^{{\rm poly}(k)}\cdot |V(G)|^2$ for every minor-closed graph class $\mathcal{H}$, where {\rm poly} is a polynomial whose degree depends on $\mathcal{H}$, under a mild technical condition on $\mathcal{L}$. This generalizes the results of Morelle, Sau, Stamoulis, and Thilikos [ICALP 2020, ICALP 2023] for the particular case of Vertex Deletion to $\mathcal{H}$ within the same running time. Our second algorithm is an improvement of the first one when $\mathcal{H}$ is the class of graphs embeddable in a surface of Euler genus at most $g$ and runs in time $2^{\mathcal{O}(k^{9})}\cdot |V(G)|^2$, where the $\mathcal{O}(\cdot)$ notation depends on $g$. To the best of our knowledge, these are the first parameterized algorithms with a reasonable parametric dependence for such a general family of graph modification problems to minor-closed classes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16803v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Laure Morelle, Ignasi Sau, Dimitrios M. Thilikos</dc:creator>
    </item>
    <item>
      <title>PHast -- Perfect Hashing made fast</title>
      <link>https://arxiv.org/abs/2504.17918</link>
      <description>arXiv:2504.17918v5 Announce Type: replace 
Abstract: Perfect hash functions give unique "names" to arbitrary keys requiring only a few bits per key. This is an essential building block in applications like static hash tables, databases, or bioinformatics. This paper introduces the PHast approach that combines the fastest available queries, very fast construction, and good space consumption (below 2 bits per key). PHast improves bucket-placement which first hashes each key k to a bucket, and then looks for the bucket seed s such that a placement function maps pairs (s,k) in a collision-free way. PHast can use small-range hash functions with linear mapping, fixed-width encoding of seeds, and parallel construction. This is achieved using small overlapping slices of allowed values and bumping to handle unsuccessful seed assignment. A variant we called PHast+ uses additive placement, which enables bit-parallel seed searching, speeding up the construction by an order of magnitude.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17918v5</guid>
      <category>cs.DS</category>
      <category>cs.DB</category>
      <category>cs.PF</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Piotr Beling, Peter Sanders</dc:creator>
    </item>
    <item>
      <title>Explicit Min-wise Hash Families with Optimal Size</title>
      <link>https://arxiv.org/abs/2510.10431</link>
      <description>arXiv:2510.10431v2 Announce Type: replace 
Abstract: We study explicit constructions of min-wise hash families and their extension to $k$-min-wise hash families. Informally, a min-wise hash family guarantees that for any fixed subset $X\subseteq[N]$, every element in $X$ has an equal chance to have the smallest value among all elements in $X$; a $k$-min-wise hash family guarantees this for every subset of size $k$ in $X$. Min-wise hash is widely used in many areas of computer science such as sketching, web page detection, and $\ell_0$ sampling.
  The classical works by Indyk and P\u{a}tra\c{s}cu and Thorup have shown $\Theta(\log(1/\delta))$-wise independent families give min-wise hash of multiplicative (relative) error $\delta$, resulting in a construction with $\Theta(\log(1/\delta)\log N)$ random bits. Based on a reduction from pseudorandom generators for combinatorial rectangles by Saks, Srinivasan, Zhou and Zuckerman, Gopalan and Yehudayoff improved the number of bits to $O(\log N\log\log N)$ for polynomially small errors $\delta$. However, no construction with $O(\log N)$ bits (polynomial size family) and sub-constant error was known before.
  In this work, we continue and extend the study of constructing ($k$-)min-wise hash families from pseudorandomness for combinatorial rectangles and read-once branching programs. Our main result gives the first explicit min-wise hash families that use an optimal (up to constant) number of random bits and achieve a sub-constant (in fact, almost polynomially small) error, specifically, an explicit family of $k$-min-wise hash with $O(k\log N)$ bits and $2^{-O(\log N/\log\log N)}$ error. This improves all previous results for any $k=\log^{O(1)}N$ under $O(k \log N)$ bits. Our main techniques involve several new ideas to adapt the classical Nisan-Zuckerman pseudorandom generator to fool min-wise hashing with a multiplicative error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.10431v2</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xue Chen, Shengtang Huang, Xin Li</dc:creator>
    </item>
    <item>
      <title>EFX Allocations and Orientations on Bipartite Multi-graphs: A Complete Picture</title>
      <link>https://arxiv.org/abs/2410.17002</link>
      <description>arXiv:2410.17002v3 Announce Type: replace-cross 
Abstract: We consider the fundamental problem of fairly allocating a set of indivisible items among agents having valuations that are represented by a multi-graph -- here, agents appear as vertices and items as edges between them and each vertex (agent) only values the set of its incident edges (items). The goal is to find a fair, i.e., envy-free up to any item (EFX) allocation. This model has recently been introduced by Christodoulou et al. (EC-23) where they show that EFX allocations always exist on simple graphs for monotone valuations, i.e., where any two agents can share at most one edge (item). A natural question arises as to what happens when we go beyond simple graphs and study various classes of multi-graphs?
  We answer the above question affirmatively for the valuation class of bipartite multi-graphs and multi-cycles. The main contribution of this work is to establish the existence of EFX allocations on bipartite multi-graphs for monotone valuations and on multi-cycles for MMS-feasible valuations. We also present pseudo-polynomial time algorithms to compute EFX allocations for the above settings. Furthermore, we show that for bipartite multi-graphs with cancelable valuations, EFX allocations can be computed in polynomial time. We thus widen the spectrum where EFX allocations are guaranteed to exist.
  Next, we study EFX orientations (allocations where every item is assigned to one of its two endpoint agents) and provide a complete characterization of their existence on bipartite multi-graphs in terms of two key parameters: (i) the number of edges shared between any two agents and (ii) the diameter of the graph. Finally, we prove that it is NP-complete to determine whether a given fair division instance on a bipartite multi-graph admits an EFX orientation, even with a constant number of agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17002v3</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mahyar Afshinmehr, Alireza Danaei, Mehrafarin Kazemi, Kurt Mehlhorn, Nidhi Rathi</dc:creator>
    </item>
    <item>
      <title>On the Limits of Language Generation: Trade-Offs Between Hallucination and Mode Collapse</title>
      <link>https://arxiv.org/abs/2411.09642</link>
      <description>arXiv:2411.09642v3 Announce Type: replace-cross 
Abstract: Specifying all desirable properties of a language model is challenging, but certain requirements seem essential. Given samples from an unknown language, the trained model should produce valid strings not seen in training and be expressive enough to capture the language's full richness. Otherwise, outputting invalid strings constitutes "hallucination," and failing to capture the full range leads to "mode collapse." We ask if a language model can meet both requirements.
  We investigate this within a statistical language generation setting building on Gold and Angluin. Here, the model receives random samples from a distribution over an unknown language K, which belongs to a possibly infinite collection of languages. The goal is to generate unseen strings from K. We say the model generates from K with consistency and breadth if, as training size increases, its output converges to all unseen strings in K.
  Kleinberg and Mullainathan [KM24] asked if consistency and breadth in language generation are possible. We answer this negatively: for a large class of language models, including next-token prediction models, this is impossible for most collections of candidate languages. This contrasts with [KM24]'s result, showing consistent generation without breadth is possible for any countable collection of languages. Our finding highlights that generation with breadth fundamentally differs from generation without breadth.
  As a byproduct, we establish near-tight bounds on the number of samples needed for generation with or without breadth.
  Finally, our results offer hope: consistent generation with breadth is achievable for any countable collection of languages when negative examples (strings outside K) are available alongside positive ones. This suggests that post-training feedback, which encodes negative examples, can be crucial in reducing hallucinations while limiting mode collapse.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09642v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.DS</category>
      <category>stat.ML</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alkis Kalavasis, Anay Mehrotra, Grigoris Velegkas</dc:creator>
    </item>
    <item>
      <title>k-SUM Hardness Implies Treewidth-SETH</title>
      <link>https://arxiv.org/abs/2510.08185</link>
      <description>arXiv:2510.08185v2 Announce Type: replace-cross 
Abstract: We show that if k-SUM is hard, in the sense that the standard algorithm is essentially optimal, then a variant of the SETH called the Primal Treewidth SETH is true. Formally: if there is an $\varepsilon&gt;0$ and an algorithm which solves SAT in time $(2-\varepsilon)^{tw}|\phi|^{O(1)}$, where $tw$ is the width of a given tree decomposition of the primal graph of the input, then there exists a randomized algorithm which solves k-SUM in time $n^{(1-\delta)\frac{k}{2}}$ for some $\delta&gt;0$ and all sufficiently large $k$. We also establish an analogous result for the k-XOR problem, where integer addition is replaced by component-wise addition modulo $2$.
  As an application of our reduction we are able to revisit tight lower bounds on the complexity of several fundamental problems parameterized by treewidth (Independent Set, Max Cut, $k$-Coloring). Our results imply that these bounds, which were initially shown under the SETH, also hold if one assumes the k-SUM or k-XOR Hypotheses, arguably increasing our confidence in their validity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08185v2</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Lampis</dc:creator>
    </item>
  </channel>
</rss>
