<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.OT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.OT</link>
    <description>stat.OT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.OT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 20 Mar 2025 04:00:30 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Resolving Jeffreys-Lindley Paradox</title>
      <link>https://arxiv.org/abs/2503.14650</link>
      <description>arXiv:2503.14650v1 Announce Type: new 
Abstract: Jeffreys-Lindley paradox is a case where frequentist and Bayesian hypothesis testing methodologies contradict with each other. This has caused confusion among data analysts for selecting a methodology for their statistical inference tasks. Though the paradox goes back to mid 1930's so far there hasn't been a satisfactory resolution given for it. In this paper we show that it arises mainly due to the simple fact that, in the frequentist approach, the difference between the hypothesized parameter value and the observed estimate of the parameter is assessed in terms of the standard error of the estimate, no matter what the actual numerical difference is and how small the standard error is, whereas in the Bayesian methodology it has no effect due to the definition of the Bayes factor in the context, even though such an assessment is present. In fact, the paradox is an instance of conflict between statistical and practical significance and a result of using a sharp null hypothesis to approximate an acceptable small range of values for the parameter. Occurrence of type-I error that is allowed in frequentist methodology plays important role in the paradox. Therefore, the paradox is not a conflict between two inference methodologies but an instance of not agreeing their conclusions</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14650v1</guid>
      <category>stat.OT</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Priyantha Wijayatunga</dc:creator>
    </item>
    <item>
      <title>Bayesian hierarchical non-stationary hybrid modeling for threshold estimation in peak over threshold approach</title>
      <link>https://arxiv.org/abs/2503.14839</link>
      <description>arXiv:2503.14839v1 Announce Type: new 
Abstract: Extreme value theory (EVT) has been utilized to estimate crash risk from traffic conflicts with the peak over threshold approach. However, it's challenging to determine a suitable threshold to distinguish extreme conflicts in an objective way. The subjective and arbitrary selection of the threshold in the peak over threshold approach can result in biased estimation outcomes. This study proposes a Bayesian hierarchical hybrid modeling (BHHM) framework for the threshold estimation in the peak over threshold approach. Specifically, BHHM is based on a piecewise function to model the general conflicts with specific distribution while model the extreme conflicts with generalized Pareto distribution (GPD). The Bayesian hierarchical structure is used to combine traffic conflicts from different sites, incorporating covariates and site-specific unobserved heterogeneity. Five non-stationary BHHM models, including Normal-GPD, Cauchy-GPD, Logistic-GPD, Gamma-GPD, and Lognormal-GPD models, were developed and compared. Traditional graphical diagnostic and quantile regression approaches were also used for comparison. Traffic conflicts collected from three signalized intersections in the city of Surrey, British Columbia were used for the study. The results show that the proposed BHHM approach could estimate the threshold parameter objectively. The Lognormal-GPD model is superior to the other four BHHM models in terms of crash estimation accuracy and model fit. The crash estimates using the threshold determined by the BHHM outperform those estimated based on the graphical diagnostic and quantile regression approaches, indicating the superiority of the proposed threshold determination approach. The findings of this study contribute to enhancing the existing EVT methods for providing a threshold determination approach as well as producing reliable crash estimations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14839v1</guid>
      <category>stat.OT</category>
      <category>stat.AP</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Quansheng Yue, Yanyong Guo, Tarek Sayed, Lai Zheng, Hao Lyu, Pan Liu</dc:creator>
    </item>
    <item>
      <title>The information mismatch, and how to fix it</title>
      <link>https://arxiv.org/abs/2503.15382</link>
      <description>arXiv:2503.15382v1 Announce Type: new 
Abstract: We live in unprecedented times in terms of our ability to use evidence to inform medical care. For example, we can perform data-driven post-test probability calculations. However, there is work to do. In current studies, sensitivity and specificity, which play a key role in post-test probability calculations, are defined as unadjusted for patient covariates. In light of this, there have been multiple recommendations that sensitivity and specificity be adjusted for covariates. However, there is less work on the downstream clinical impact of unadjusted sensitivity and specificity. We discuss this here. We argue that unadjusted sensitivity and specificity can lead to a post-test probability that contains an ``information mismatch.'' We write the equations behind such an information mismatch and discuss the steps that can be taken to fix it.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15382v1</guid>
      <category>stat.OT</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samuel J. Weisenthal, Amit K. Chowdhry</dc:creator>
    </item>
  </channel>
</rss>
