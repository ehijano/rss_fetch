<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 10 Jun 2025 02:41:46 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Remarks on multi-period martingale optimal transport</title>
      <link>https://arxiv.org/abs/2506.05505</link>
      <description>arXiv:2506.05505v1 Announce Type: new 
Abstract: We study the structural properties of multi-period martingale optimal transport (MOT). We develop new tools to address these problems, and use them to prove several uniqueness and structural results on three-period martingale optimal transport. More precisely, we establish lemmas on how and when two-period martingale couplings may be glued together to obtain multi-period martingales and which among these glueings are optimal for particular MOT problems. We use these optimality results to study limits of solutions under convergence of the cost function and obtain a corresponding linearization of the optimal cost. We go on to establish a complete characterization of limiting solutions in a three-period problem as the interaction between two of the variables vanishes. Under additional assumptions, we show uniqueness of the solution and a structural result which yields the solution essentially explicitly. For the full three-period problem, we also obtain several structural and uniqueness results under a variety of different assumptions on the marginals and cost function.
  We illustrate our results with a real world application, providing approximate model independent upper and lower bounds for options depending on Amazon stock prices at three different times. We compare these bounds to prices computed using certain models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05505v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brendan Pass, Joshua Hiew</dc:creator>
    </item>
    <item>
      <title>Partially-Supervised Neural Network Model For Quadratic Multiparametric Programming</title>
      <link>https://arxiv.org/abs/2506.05567</link>
      <description>arXiv:2506.05567v1 Announce Type: new 
Abstract: Neural Networks (NN) with ReLU activation functions are used to model multiparametric quadratic optimization problems (mp-QP) in diverse engineering applications. Researchers have suggested leveraging the piecewise affine property of deep NN models to solve mp-QP with linear constraints, which also exhibit piecewise affine behaviour. However, traditional deep NN applications to mp-QP fall short of providing optimal and feasible predictions, even when trained on large datasets. This study proposes a partially-supervised NN (PSNN) architecture that directly represents the mathematical structure of the global solution function. In contrast to generic NN training approaches, the proposed PSNN method derives a large proportion of model weights directly from the mathematical properties of the optimization problem, producing more accurate solutions despite significantly smaller training data sets. Many energy management problems are formulated as QP, so we apply the proposed approach to energy systems (specifically DC optimal power flow) to demonstrate proof of concept. Model performance in terms of solution accuracy and speed of predictions was compared against a commercial solver and a generic Deep NN model based on classical training. Results show KKT sufficient conditions for PSNN consistently outperform generic NN architectures with classical training using far less data, including when tested on extreme, out-of-training distribution test data. Given its speed advantages over traditional solvers, the PSNN model can quickly produce optimal and feasible solutions within a second for millions of input parameters sampled from a distribution of stochastic demands and renewable generator dispatches, which can be used for simulations and long term planning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05567v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fuat Can Beylunioglu, Mehrdad Pirnia, P. Robert Duimering</dc:creator>
    </item>
    <item>
      <title>Stochastic maximum principle for optimal control problem of non exchangeable mean field systems</title>
      <link>https://arxiv.org/abs/2506.05595</link>
      <description>arXiv:2506.05595v1 Announce Type: new 
Abstract: We study the Pontryagin maximum principle by deriving necessary and sufficient conditions for a class of optimal control problems arising in non exchangeable mean field systems, where agents interact through heterogeneous and asymmetric couplings. Our analysis leads to a collection of forward-backward stochastic differential equations (FBSDE) of non exchangeable mean field type. Under suitable assumptions, we establish the solvability of this system. As an illustration, we consider the linear-quadratic case, where the optimal control is characterized by an infinite dimensional system of Riccati equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05595v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Idris Kharroubi, Samy Mekkaoui, Huy\^en Pham</dc:creator>
    </item>
    <item>
      <title>Simulating Fokker-Planck equations via mean field control of score-based normalizing flows</title>
      <link>https://arxiv.org/abs/2506.05723</link>
      <description>arXiv:2506.05723v1 Announce Type: new 
Abstract: The Fokker-Planck (FP) equation governs the evolution of densities for stochastic dynamics of physical systems, such as the Langevin dynamics and the Lorenz system. This work simulates FP equations through a mean field control (MFC) problem. We first formulate the FP equation as a continuity equation, where the velocity field consists of the drift function and the score function, i.e., the gradient of the logarithm of the density function. Next, we design a MFC problem that matches the velocity fields in a continuity equation with the ones in the FP equation. The score functions along deterministic trajectories are computed efficiently through the score-based normalizing flow, which only rely on the derivatives of the parameterized velocity fields. A convergence analysis is conducted for our algorithm on the FP equation of Ornstein-Uhlenbeck processes. Numerical results, including Langevin dynamics, underdamped Langevin dynamics, and various chaotic systems, validate the effectiveness of our proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05723v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mo Zhou, Stanley Osher, Wuchen Li</dc:creator>
    </item>
    <item>
      <title>Asymmetric Perturbation in Solving Bilinear Saddle-Point Optimization</title>
      <link>https://arxiv.org/abs/2506.05747</link>
      <description>arXiv:2506.05747v1 Announce Type: new 
Abstract: This paper proposes an asymmetric perturbation technique for solving saddle-point optimization problems, commonly arising in min-max problems, game theory, and constrained optimization. Perturbing payoffs or values are known to be effective in stabilizing learning dynamics and finding an exact solution or equilibrium. However, it requires careful adjustment of the perturbation magnitude; otherwise, learning dynamics converge to only an equilibrium. We establish an impossibility result that it almost never reaches an exact equilibrium as long as both players' payoff functions are perturbed. To overcome this, we introduce an asymmetric perturbation approach, where only one player's payoff function is perturbed. This ensures convergence to an equilibrium without requiring parameter adjustments, provided the perturbation strength parameter is sufficiently low. Furthermore, we empirically demonstrate fast convergence toward equilibria in both normal-form and extensive-form games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05747v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kenshi Abe, Mitsuki Sakamoto, Kaito Ariu, Atsushi Iwasaki</dc:creator>
    </item>
    <item>
      <title>Optimized projection-free algorithms for online learning: construction and worst-case analysis</title>
      <link>https://arxiv.org/abs/2506.05855</link>
      <description>arXiv:2506.05855v1 Announce Type: new 
Abstract: This work studies and develop projection-free algorithms for online learning with linear optimization oracles (a.k.a. Frank-Wolfe) for handling the constraint set. More precisely, this work (i) provides an improved (optimized) variant of an online Frank-Wolfe algorithm along with its conceptually simple potential-based proof, and (ii) shows how to leverage semidefinite programming to jointly design and analyze online Frank-Wolfe-type algorithms numerically in a variety of settings-that include the design of the variant (i). Based on the semidefinite technique, we conclude with strong numerical evidence suggesting that no pure online Frank-Wolfe algorithm within our model class can have a regret guarantee better than O(T^3/4) (T is the time horizon) without additional assumptions, that the current algorithms do not have optimal constants, that the algorithm benefits from similar anytime properties O(t^3/4) not requiring to know T in advance, and that multiple linear optimization rounds do not generally help to obtain better regret bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05855v1</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julien Weibel (SIERRA), Pierre Gaillard (Thoth), Wouter M. Koolen (CWI), Adrien Taylor (SIERRA)</dc:creator>
    </item>
    <item>
      <title>Policy Optimization for Continuous-time Linear-Quadratic Graphon Mean Field Games</title>
      <link>https://arxiv.org/abs/2506.05894</link>
      <description>arXiv:2506.05894v1 Announce Type: new 
Abstract: Multi-agent reinforcement learning, despite its popularity and empirical success, faces significant scalability challenges in large-population dynamic games. Graphon mean field games (GMFGs) offer a principled framework for approximating such games while capturing heterogeneity among players. In this paper, we propose and analyze a policy optimization framework for continuous-time, finite-horizon linear-quadratic GMFGs. Exploiting the structural properties of GMFGs, we design an efficient policy parameterization in which each player's policy is represented as an affine function of their private state, with a shared slope function and player-specific intercepts. We develop a bilevel optimization algorithm that alternates between policy gradient updates for best-response computation under a fixed population distribution, and distribution updates using the resulting policies. We prove linear convergence of the policy gradient steps to best-response policies and establish global convergence of the overall algorithm to the Nash equilibrium. The analysis relies on novel landscape characterizations over infinite-dimensional policy spaces. Numerical experiments demonstrate the convergence and robustness of the proposed algorithm under varying graphon structures, noise levels, and action frequencies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05894v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philipp Plank, Yufei Zhang</dc:creator>
    </item>
    <item>
      <title>A Proximal Variable Smoothing for Minimization of Nonlinearly Composite Nonsmooth Function -- Maxmin Dispersion and MIMO Applications</title>
      <link>https://arxiv.org/abs/2506.05974</link>
      <description>arXiv:2506.05974v1 Announce Type: new 
Abstract: We propose a proximal variable smoothing algorithm for a nonsmooth optimization problem whose cost function is the sum of three functions including a weakly convex composite function. The proposed algorithm has a single-loop structure inspired by a proximal gradient-type method. More precisely, the proposed algorithm consists of two steps: (i) a gradient descent of a time-varying smoothed surrogate function designed partially with the Moreau envelope of the weakly convex function; (ii) an application of the proximity operator of the remaining function not covered by the smoothed surrogate function. We also present a convergence analysis of the proposed algorithm by exploiting a novel asymptotic approximation of a gradient mapping-type stationarity measure. Numerical experiments demonstrate the effectiveness of the proposed algorithm in two scenarios: (i) maxmin dispersion problem and (ii) multiple-input-multiple-output (MIMO) signal detection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05974v1</guid>
      <category>math.OC</category>
      <category>eess.SP</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keita Kume, Isao Yamada</dc:creator>
    </item>
    <item>
      <title>Convergence of linear programming hierarchies for Gibbs states of spin systems</title>
      <link>https://arxiv.org/abs/2506.06125</link>
      <description>arXiv:2506.06125v1 Announce Type: new 
Abstract: We consider the problem of computing expectation values of local functions under the Gibbs distribution of a spin system. In particular, we study two families of linear programming hierarchies for this problem. The first hierarchy imposes local spin flip equalities and has been considered in the bootstrap literature in high energy physics. For this hierarchy, we prove fast convergence under a spatial mixing (decay of correlations) condition. This condition is satisfied for example above the critical temperature for Ising models on a $d$-dimensional grid. The second hierarchy is based on a Markov chain having the Gibbs state as a fixed point and has been studied in the optimization literature and more recently in the bootstrap literature. For this hierarchy, we prove fast convergence provided the Markov chain mixes rapidly. Both hierarchies lead to an $\varepsilon$-approximation for local expectation values using a linear program of size quasi-polynomial in $n/\varepsilon$, where $n$ is the total number of sites, provided the interactions can be embedded in a $d$-dimensional grid with constant $d$. Compared to standard Monte Carlo methods, an advantage of this approach is that it always (i.e., for any system) outputs rigorous upper and lower bounds on the expectation value of interest, without needing an a priori analysis of the convergence speed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06125v1</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hamza Fawzi, Omar Fawzi</dc:creator>
    </item>
    <item>
      <title>Acceleration via silver step-size on Riemannian manifolds with applications to Wasserstein space</title>
      <link>https://arxiv.org/abs/2506.06160</link>
      <description>arXiv:2506.06160v1 Announce Type: new 
Abstract: There is extensive literature on accelerating first-order optimization methods in a Euclidean setting. Under which conditions such acceleration is feasible in Riemannian optimization problems is an active area of research. Motivated by the recent success of varying step-size methods in the Euclidean setting, we undertake a study of such algorithms in the Riemannian setting. We show that varying step-size acceleration can be achieved in non-negatively curved Riemannian manifolds under geodesic smoothness and generalized geodesic convexity, a new notion of convexity that we introduce to aid our analysis. As a core application, we show that our method provides the first theoretically guaranteed accelerated optimization method in Wasserstein spaces. In addition, we numerically validate our method's applicability to other problems, such as optimization problems on the sphere.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06160v1</guid>
      <category>math.OC</category>
      <category>math.DG</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiyoung Park, Abhishek Roy, Jonathan W. Siegel, Anirban Bhattacharya</dc:creator>
    </item>
    <item>
      <title>PDHCG: A Scalable First-Order Method for Large-Scale Competitive Market Equilibrium Computation</title>
      <link>https://arxiv.org/abs/2506.06258</link>
      <description>arXiv:2506.06258v1 Announce Type: new 
Abstract: Large-scale competitive market equilibrium problems arise in a wide range of important applications, including economic decision-making and intelligent manufacturing. Traditional solution methods, such as interior-point algorithms and certain projection-based approaches, often fail to scale effectively to large problem instances. In this paper, we propose an efficient computational framework that integrates the primal-dual hybrid conjugate gradient (PDHCG) algorithm with GPU-based parallel computing to solve large-scale Fisher market equilibrium problems. By exploiting the underlying mathematical structure of the problem, we establish a theoretical guarantee of linear convergence for the proposed algorithm. Furthermore, the proposed framework can be extended to solve large-scale Arrow-Debreu market equilibrium problems through a fixed-point iteration scheme. Extensive numerical experiments conducted on GPU platforms demonstrate substantial improvements in computational efficiency, significantly expanding the practical solvable scale and applicability of market equilibrium models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06258v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huikang Liu, Yicheng Huang, Hongpei Li, Dongdong Ge, Yinyu Ye</dc:creator>
    </item>
    <item>
      <title>Zeroth-Order Optimization Finds Flat Minima</title>
      <link>https://arxiv.org/abs/2506.05454</link>
      <description>arXiv:2506.05454v1 Announce Type: cross 
Abstract: Zeroth-order methods are extensively used in machine learning applications where gradients are infeasible or expensive to compute, such as black-box attacks, reinforcement learning, and language model fine-tuning. Existing optimization theory focuses on convergence to an arbitrary stationary point, but less is known on the implicit regularization that provides a fine-grained characterization on which particular solutions are finally reached. We show that zeroth-order optimization with the standard two-point estimator favors solutions with small trace of Hessian, which is widely used in previous work to distinguish between sharp and flat minima. We further provide convergence rates of zeroth-order optimization to approximate flat minima for convex and sufficiently smooth functions, where flat minima are defined as the minimizers that achieve the smallest trace of Hessian among all optimal solutions. Experiments on binary classification tasks with convex losses and language model fine-tuning support our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05454v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liang Zhang, Bingcong Li, Kiran Koshy Thekumparampil, Sewoong Oh, Michael Muehlebach, Niao He</dc:creator>
    </item>
    <item>
      <title>Exploiting Similarity for Computation and Communication-Efficient Decentralized Optimization</title>
      <link>https://arxiv.org/abs/2506.05791</link>
      <description>arXiv:2506.05791v1 Announce Type: cross 
Abstract: Reducing communication complexity is critical for efficient decentralized optimization. The proximal decentralized optimization (PDO) framework is particularly appealing, as methods within this framework can exploit functional similarity among nodes to reduce communication rounds. Specifically, when local functions at different nodes are similar, these methods achieve faster convergence with fewer communication steps. However, existing PDO methods often require highly accurate solutions to subproblems associated with the proximal operator, resulting in significant computational overhead. In this work, we propose the Stabilized Proximal Decentralized Optimization (SPDO) method, which achieves state-of-the-art communication and computational complexities within the PDO framework. Additionally, we refine the analysis of existing PDO methods by relaxing subproblem accuracy requirements and leveraging average functional similarity. Experimental results demonstrate that SPDO significantly outperforms existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05791v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuki Takezawa, Xiaowen Jiang, Anton Rodomanov, Sebastian U. Stich</dc:creator>
    </item>
    <item>
      <title>Enhanced Trust Region Sequential Convex Optimization for Multi-Drone Thermal Screening Trajectory Planning in Urban Environments</title>
      <link>https://arxiv.org/abs/2506.06012</link>
      <description>arXiv:2506.06012v1 Announce Type: cross 
Abstract: The rapid detection of abnormal body temperatures in urban populations is essential for managing public health risks, especially during outbreaks of infectious diseases. Multi-drone thermal screening systems offer promising solutions for fast, large-scale, and non-intrusive human temperature monitoring. However, trajectory planning for multiple drones in complex urban environments poses significant challenges, including collision avoidance, coverage efficiency, and constrained flight environments. In this study, we propose an enhanced trust region sequential convex optimization (TR-SCO) algorithm for optimal trajectory planning of multiple drones performing thermal screening tasks. Our improved algorithm integrates a refined convex optimization formulation within a trust region framework, effectively balancing trajectory smoothness, obstacle avoidance, altitude constraints, and maximum screening coverage. Simulation results demonstrate that our approach significantly improves trajectory optimality and computational efficiency compared to conventional convex optimization methods. This research provides critical insights and practical contributions toward deploying efficient multi-drone systems for real-time thermal screening in urban areas. For reader who are interested in our research, we release our source code at https://github.com/Cherry0302/Enhanced-TR-SCO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06012v1</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaiyuan Chen, Zhengjie Hu, Shaolin Zhang, Yuanqing Xia, Wannian Liang, Shuo Wang</dc:creator>
    </item>
    <item>
      <title>Some remarks on stochastic converse Lyapunov theorems</title>
      <link>https://arxiv.org/abs/2506.06053</link>
      <description>arXiv:2506.06053v1 Announce Type: cross 
Abstract: In this brief note, we investigate some constructions of Lyapunov functions for stochastic discrete-time stabilizable dynamical systems, in other words, controlled Markov chains. The main question here is whether a Lyapunov function in some statistical sense exists if the respective controlled Markov chain admits a stabilizing policy. We demonstrate some constructions extending on the classical results for deterministic systems. Some limitations of the constructed Lyapunov functions for stabilization are discussed, particularly for stabilization in mean. Although results for deterministic systems are well known, the stochastic case was addressed in less detail, which the current paper remarks on. A distinguishable feature of this work is the study of stabilizers that possess computationally tractable convergence certificates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06053v1</guid>
      <category>math.DS</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pavel Osinenko, Grigory Yaremenko</dc:creator>
    </item>
    <item>
      <title>Similarity Matching Networks: Hebbian Learning and Convergence Over Multiple Time Scales</title>
      <link>https://arxiv.org/abs/2506.06134</link>
      <description>arXiv:2506.06134v1 Announce Type: cross 
Abstract: A recent breakthrough in biologically-plausible normative frameworks for dimensionality reduction is based upon the similarity matching cost function and the low-rank matrix approximation problem. Despite clear biological interpretation, successful application in several domains, and experimental validation, a formal complete convergence analysis remains elusive. Building on this framework, we consider and analyze a continuous-time neural network, the \emph{similarity matching network}, for principal subspace projection. Derived from a min-max-min objective, this biologically-plausible network consists of three coupled dynamics evolving at different time scales: neural dynamics, lateral synaptic dynamics, and feedforward synaptic dynamics at the fast, intermediate, and slow time scales, respectively. The feedforward and lateral synaptic dynamics consist of Hebbian and anti-Hebbian learning rules, respectively. By leveraging a multilevel optimization framework, we prove convergence of the dynamics in the offline setting. Specifically, at the first level (fast time scale), we show strong convexity of the cost function and global exponential convergence of the corresponding gradient-flow dynamics. At the second level (intermediate time scale), we prove strong concavity of the cost function and exponential convergence of the corresponding gradient-flow dynamics within the space of positive definite matrices. At the third and final level (slow time scale), we study a non-convex and non-smooth cost function, provide explicit expressions for its global minima, and prove almost sure convergence of the corresponding gradient-flow dynamics to the global minima. These results rely on two empirically motivated conjectures that are supported by thorough numerical experiments. Finally, we validate the effectiveness of our approach via a numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06134v1</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Veronica Centorrino, Francesco Bullo, Giovanni Russo</dc:creator>
    </item>
    <item>
      <title>Tightening Quadratic Convex Relaxations for the AC Optimal Transmission Switching Problem</title>
      <link>https://arxiv.org/abs/2212.12097</link>
      <description>arXiv:2212.12097v3 Announce Type: replace 
Abstract: The Alternating Current Optimal Transmission Switching (ACOTS) problem incorporates line switching decisions into the AC Optimal Power Flow (ACOPF) framework, offering well-known benefits in reducing operational costs and enhancing system reliability. ACOTS optimization models contain discrete variables and nonlinear, non-convex constraints, which make it difficult to solve. In this work, we develop strengthened quadratic convex (QC) relaxations for ACOTS, where we tighten the relaxation with several new valid inequalities, including a novel kind of on/off cycle-based polynomial constraints by taking advantage of the network structure. We linearize the sum of on/off trilinear terms in the relaxation using extreme-point representation, demonstrating theoretical tightness, and efficiently incorporate on/off cycle-based polynomial constraints through disjunctive programming-based cutting planes. Combined with an optimization-based bound tightening algorithm, this results in the tightest QC-based ACOTS relaxation to date. We additionally propose a novel maximum spanning tree-based heuristic to improve the computational performance by fixing certain lines to be switched on. Our extensive numerical experiments on medium-scale PGLib instances show significant improvements on relaxation bounds, while tests on large-scale instances with up to 2,312 buses demonstrate substantial performance gains. To our knowledge, this is the first ACOTS relaxation-based approach to demonstrate near-optimal switching solutions on realistic large-scale power grid instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.12097v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1287/ijoc.2023.0236</arxiv:DOI>
      <dc:creator>Cheng Guo, Harsha Nagarajan, Merve Bodur</dc:creator>
    </item>
    <item>
      <title>A Fisher-Rao gradient flow for entropy-regularised Markov decision processes in Polish spaces</title>
      <link>https://arxiv.org/abs/2310.02951</link>
      <description>arXiv:2310.02951v3 Announce Type: replace 
Abstract: We study the global convergence of a Fisher-Rao policy gradient flow for infinite-horizon entropy-regularised Markov decision processes with Polish state and action space. The flow is a continuous-time analogue of a policy mirror descent method. We establish the global well-posedness of the gradient flow and demonstrate its exponential convergence to the optimal policy. Moreover, we prove the flow is stable with respect to gradient evaluation, offering insights into the performance of a natural policy gradient flow with log-linear policy parameterisation. To overcome challenges stemming from the lack of the convexity of the objective function and the discontinuity arising from the entropy regulariser, we leverage the performance difference lemma and the duality relationship between the gradient and mirror descent flows. Our analysis provides a theoretical foundation for developing various discrete policy gradient algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.02951v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bekzhan Kerimkulov, James-Michael Leahy, David Siska, Lukasz Szpruch, Yufei Zhang</dc:creator>
    </item>
    <item>
      <title>A Positive Semidefinite Safe Approximation of Multivariate Distributionally Robust Constraints Determined by Simple Functions</title>
      <link>https://arxiv.org/abs/2310.05612</link>
      <description>arXiv:2310.05612v2 Announce Type: replace 
Abstract: Single-level reformulations of (non-convex) distributionally robust optimization (DRO) problems are often intractable, as they contain semiinfinite dual constraints. Based on such a semiinfinite reformulation, we present a safe approximation, that allows for the computation of feasible solutions for DROs that depend on nonconvex multivariate simple functions. Moreover, the approximation allows to address ambiguity sets that can incorporate information on moments as well as confidence sets. The typical strong assumptions on the structure of the underlying constraints, such as convexity in the decisions or concavity in the uncertainty found in the literature were, at least in part, recently overcome in [9]. We start from the duality-based reformulation approach in [9] that can be applied for DRO constraints based on simple functions that are univariate in the uncertainty parameters. We significantly extend their approach to multivariate simple functions which leads to a considerably wider applicability of the proposed reformulation approach. In order to achieve algorithmic tractability, the presented safe approximation is then realized by a discretized counterpart for the semiinfinite dual constraints. The approximation leads to a computationally tractable mixed-integer positive semidefinite problem for which state-of-the-art software implementations are readily available. The tractable safe approximation provides sufficient conditions for distributional robustness of the original problem, i.e., obtained solutions are provably robust.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.05612v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>J. Dienstbier, F. Liers, J. Rolfes</dc:creator>
    </item>
    <item>
      <title>Accelerating Level-Value Adjustment for the Polyak Stepsize</title>
      <link>https://arxiv.org/abs/2311.18255</link>
      <description>arXiv:2311.18255v3 Announce Type: replace 
Abstract: The Polyak stepsize has been widely used in subgradient methods for non-smooth convex optimization. However, calculating the stepsize requires the optimal value, which is generally unknown. Therefore, dynamic estimations of the optimal value are usually needed. In this paper, to guarantee convergence, a series of level values is constructed to estimate the optimal value successively. This is achieved by developing a decision-guided procedure that involves solving a novel, easy-to-solve linear constraint satisfaction problem referred to as the ``Polyak Stepsize Violation Detector'' (PSVD). Once a violation is detected, the level value is recalculated. We rigorously establish the convergence for both the level values and the objective function values. Furthermore, with our level adjustment approach, calculating an approximate subgradient in each iteration is sufficient for convergence. A series of empirical tests of convex optimization problems with diverse characteristics demonstrates the practical advantages of our approach over existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.18255v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anbang Liu, Mikhail A. Bragin, Xi Chen, Xiaohong Guan</dc:creator>
    </item>
    <item>
      <title>Robust Control Lyapunov-Value Functions for Nonlinear Disturbed Systems</title>
      <link>https://arxiv.org/abs/2403.03455</link>
      <description>arXiv:2403.03455v2 Announce Type: replace 
Abstract: Control Lyapunov Functions (CLFs) have been extensively used in the control community. A well-known drawback is the absence of a systematic way to construct CLFs for general nonlinear systems, and the problem can become more complex with input or state constraints. Our preliminary work on constructing Control Lyapunov Value Functions (CLVFs) using Hamilton-Jacobi (HJ) reachability analysis provides a method for finding a non-smooth CLF. In this paper, we extend our work on CLVFs to systems with bounded disturbance and define the Robust CLVF (R-CLVF). The R-CLVF naturally inherits all properties of the CLVF; i.e., it first identifies the "smallest robust control invariant set (SRCIS)" and stabilizes the system to it with a user-specified exponential rate. The region from which the exponential rate can be met is called the "region of exponential stabilizability (ROES)." We provide clearer definitions of the SRCIS and more rigorous proofs of several important theorems. Since the computation of the R-CLVF suffers from the "curse of dimensionality," we also provide two techniques (warmstart and system decomposition) that solve it, along with necessary proofs. Three numerical examples are provided, validating our definition of SRCIS, illustrating the trade-off between a faster decay rate and a smaller ROES, and demonstrating the efficiency of computation using warmstart and decomposition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03455v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zheng Gong, Sylvia Herbert</dc:creator>
    </item>
    <item>
      <title>Variance-Reduced Fast Krasnoselkii-Mann Methods for Finite-Sum Root-Finding Problems</title>
      <link>https://arxiv.org/abs/2406.02413</link>
      <description>arXiv:2406.02413v3 Announce Type: replace 
Abstract: We propose a new class of fast Krasnoselkii--Mann methods with variance reduction to solve a finite-sum co-coercive equation $Gx = 0$. Our algorithm is single-loop and leverages a new family of unbiased variance-reduced estimators specifically designed for a wider class of root-finding algorithms. Our method achieves both $\mathcal{O}(1/k^2)$ and $o(1/k^2)$ last-iterate convergence rates in terms of $\mathbb{E}[\| Gx^k\|^2]$, where $k$ is the iteration counter and $\mathbb{E}[\cdot]$ is the total expectation. We also establish almost sure $o(1/k^2)$ convergence rates and the almost sure convergence of iterates $\{x^k\}$ to a solution of $Gx=0$. We instantiate our framework for two prominent estimators: SVRG and SAGA. By an appropriate choice of parameters, both variants attain an oracle complexity of $\mathcal{O}(n + n^{2/3}\epsilon^{-1})$ to reach an $\epsilon$-solution, where $n$ represents the number of summands in the finite-sum operator $G$. Furthermore, under $\sigma$-strong quasi-monotonicity, our method achieves a linear convergence rate and an oracle complexity of $\mathcal{O}(n+ \max\{n, n^{2/3}\kappa\} \log(\frac{1}{\epsilon}))$, where $\kappa := L/\sigma$. We extend our approach to solve a class of finite-sum inclusions (possibly nonmonotone), demonstrating that our schemes retain the same theoretical guarantees as in the equation setting. Finally, numerical experiments validate our algorithms and demonstrate their promising performance compared to state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02413v3</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Quoc Tran-Dinh</dc:creator>
    </item>
    <item>
      <title>Provable Complexity Improvement of AdaGrad over SGD: Upper and Lower Bounds in Stochastic Non-Convex Optimization</title>
      <link>https://arxiv.org/abs/2406.04592</link>
      <description>arXiv:2406.04592v3 Announce Type: replace 
Abstract: Adaptive gradient methods, such as AdaGrad, are among the most successful optimization algorithms for neural network training. While these methods are known to achieve better dimensional dependence than stochastic gradient descent (SGD) for stochastic convex optimization under favorable geometry, the theoretical justification for their success in stochastic non-convex optimization remains elusive. In fact, under standard assumptions of Lipschitz gradients and bounded noise variance, it is known that SGD is worst-case optimal in terms of finding a near-stationary point with respect to the $l_2$-norm, making further improvements impossible. Motivated by this limitation, we introduce refined assumptions on the smoothness structure of the objective and the gradient noise variance, which better suit the coordinate-wise nature of adaptive gradient methods. Moreover, we adopt the $l_1$-norm of the gradient as the stationarity measure, as opposed to the standard $l_2$-norm, to align with the coordinate-wise analysis and obtain tighter convergence guarantees for AdaGrad. Under these new assumptions and the $l_1$-norm stationarity measure, we establish an upper bound on the convergence rate of AdaGrad and a corresponding lower bound for SGD. In particular, we identify non-convex settings in which the iteration complexity of AdaGrad is favorable over SGD and show that, for certain configurations of problem parameters, it outperforms SGD by a factor of $d$, where $d$ is the problem dimension. To the best of our knowledge, this is the first result to demonstrate a provable gain of adaptive gradient methods over SGD in a non-convex setting. We also present supporting lower bounds, including one specific to AdaGrad and one applicable to general deterministic first-order methods, showing that our upper bound for AdaGrad is tight and unimprovable up to a logarithmic factor under certain conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04592v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruichen Jiang, Devyani Maladkar, Aryan Mokhtari</dc:creator>
    </item>
    <item>
      <title>Tracking controllability for finite-dimensional linear systems</title>
      <link>https://arxiv.org/abs/2407.18641</link>
      <description>arXiv:2407.18641v2 Announce Type: replace 
Abstract: In this work, we present a functional analytic framework for tracking controllability in finite-dimensional linear systems. By leveraging the Hilbert Uniqueness Method (HUM) and duality principles, we rigorously characterize tracking controllability through a non-standard observability inequality for the adjoint system. This enables the synthesis of minimum-norm tracking controls while revealing novel regularity requirements that depend intricately on system structure and the projection operator. Our approach generalizes classical concepts, embedding them in an energy-minimization context that extends functional output controllability and invertibility. Explicit control constructions in the scalar case illustrate these principles, and numerical experiments validate the approach for both smooth and non-smooth targets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18641v2</guid>
      <category>math.OC</category>
      <category>math.CA</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebasti\'an Zamorano, Enrique Zuazua</dc:creator>
    </item>
    <item>
      <title>How long is long enough? Finite-horizon approximation of energy storage scheduling problems</title>
      <link>https://arxiv.org/abs/2411.17463</link>
      <description>arXiv:2411.17463v2 Announce Type: replace 
Abstract: Energy storage scheduling problems, where a storage is operated to maximize its profit in response to a price signal, are essentially infinite-horizon optimization problems as storage systems operate continuously, without a foreseen end to their operation. Such problems can be solved to optimality with a rolling-horizon approach, provided that the planning horizon over which the problem is solved is long enough. Such a horizon is termed a forecast horizon. However, the length of the planning horizon is usually chosen arbitrarily for such applications. We introduce an easy-to-check condition that confirms whether a planning horizon is a forecast horizon, and which can be used to derive a bound on suboptimality when it is not the case. By way of an example, we demonstrate that the existence of forecast horizons is not guaranteed for this problem. We also derive a lower bound on the length of the minimum forecast horizon. We show how the condition introduced can be used as part of an algorithm to determine the minimum forecast horizon of the problem, which ensures the determination of optimal solutions at the lowest computational and forecasting costs. Finally, we provide insights into the implications of different planning horizons for a range of storage system characteristics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17463v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>El\'ea Prat, Richard M. Lusby, Juan Miguel Morales, Salvador Pineda, Pierre Pinson</dc:creator>
    </item>
    <item>
      <title>A Riemannian Optimization Perspective of the Gauss-Newton Method for Feedforward Neural Networks</title>
      <link>https://arxiv.org/abs/2412.14031</link>
      <description>arXiv:2412.14031v4 Announce Type: replace 
Abstract: We analyze the convergence of Gauss-Newton dynamics for training neural networks with smooth activation functions. In the underparameterized regime, the Gauss-Newton gradient flow induces a Riemannian gradient flow on a low-dimensional, smooth, embedded submanifold of the Euclidean output space. Using tools from Riemannian optimization, we prove \emph{last-iterate} convergence of the Riemannian gradient flow to the optimal in-class predictor at an \emph{exponential rate} that is independent of the conditioning of the Gram matrix, \emph{without} requiring explicit regularization. We further characterize the critical impacts of the neural network scaling factor and the initialization on the convergence behavior. In the overparameterized regime, we show that the Levenberg-Marquardt dynamics with an appropriately chosen damping schedule yields fast convergence rate despite potentially ill-conditioned neural tangent kernel matrices, analogous to the underparameterized regime. These findings demonstrate the potential of Gauss-Newton methods for efficiently optimizing neural networks in the near-initialization regime, particularly in ill-conditioned problems where kernel and Gram matrices have small singular values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14031v4</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>stat.ML</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Semih Cayci</dc:creator>
    </item>
    <item>
      <title>Numerical Approximation of Delay Differential Equations via Operator Splitting in Fractional Domains</title>
      <link>https://arxiv.org/abs/2502.05483</link>
      <description>arXiv:2502.05483v5 Announce Type: replace 
Abstract: This paper develops a rigorous framework for the numerical approximation of both autonomous and non-autonomous delay differential equations (DDEs), with a focus on the implicit Euler method and sequential operator splitting.
  To overcome the difficulty that the delay operator does not generate an analytic semigroup in the standard space \( L^1[\tau, 0] \), we embed the problem into the interpolation space \( \left(L^1[\tau, 0], W^{1,1}_0[\tau, 0]\right)_{\theta, 1} \) for \( 0 &lt; \theta &lt; 1 \), where the differential operator becomes sectorial. This allows the full operator \( L = A + B \) to generate an analytic semigroup \( T_L(t) \), enabling the use of semigroup theory to derive sharp error estimates.
  We prove that the implicit Euler method achieves a global error of order \( \mathcal{O}(h) \), while the Lie--Trotter splitting method yields an error of order \( \mathcal{O}(h^{2\theta - 1}) \) in the interpolation norm. These theoretical rates are confirmed by numerical experiments, including comparisons with exact solutions obtained via semi-analytical Fourier-based methods in the non-autonomous setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05483v5</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hideki Kawahara</dc:creator>
    </item>
    <item>
      <title>A new perspective on Willems' fundamental lemma: Universality of persistently exciting inputs</title>
      <link>https://arxiv.org/abs/2503.12489</link>
      <description>arXiv:2503.12489v2 Announce Type: replace 
Abstract: In this letter, we provide new insight into Willems et al.'s fundamental lemma by studying the concept of universal inputs. An input is called universal if, when applied to any controllable system, it leads to input-output data that parametrizes all finite trajectories of the system. By the fundamental lemma, inputs that are persistently exciting of sufficiently high order are universal. The main contribution of this work is to prove the converse. Therefore, universality and persistency of excitation are equivalent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.12489v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/LCSYS.2025.3576276</arxiv:DOI>
      <dc:creator>Amir Shakouri, Henk J. van Waarde, M. Kanat Camlibel</dc:creator>
    </item>
    <item>
      <title>Variance-Reduced Fast Operator Splitting Methods for Stochastic Generalized Equations</title>
      <link>https://arxiv.org/abs/2504.13046</link>
      <description>arXiv:2504.13046v2 Announce Type: replace 
Abstract: We develop two classes of variance-reduced fast operator splitting methods to approximate solutions of both finite-sum and stochastic generalized equations. Our approach integrates recent advances in accelerated fixed-point methods, co-hypomonotonicity, and variance reduction. First, we introduce a class of variance-reduced estimators and establish their variance-reduction bounds. This class covers both unbiased and biased instances and comprises common estimators as special cases, including SVRG, SAGA, SARAH, and Hybrid-SGD. Next, we design a novel accelerated variance-reduced forward-backward splitting (FBS) algorithm using these estimators to solve finite-sum and stochastic generalized equations. Our method achieves both $\mathcal{O}(1/k^2)$ and $o(1/k^2)$ convergence rates on the expected squared norm $\mathbb{E}[ \| G_{\lambda}x^k\|^2]$ of the FBS residual $G_{\lambda}$, where $k$ is the iteration counter. Additionally, we establish, for the first time, almost sure convergence rates and almost sure convergence of iterates to a solution in stochastic accelerated methods. Unlike existing stochastic fixed-point algorithms, our methods accommodate co-hypomonotone operators, which potentially include nonmonotone problems arising from recent applications. We further specify our method to derive an appropriate variant for each stochastic estimator -- SVRG, SAGA, SARAH, and Hybrid-SGD -- demonstrating that they achieve the best-known complexity for each without relying on enhancement techniques. Alternatively, we propose an accelerated variance-reduced backward-forward splitting (BFS) method, which attains similar convergence rates and oracle complexity as our FBS method. Finally, we validate our results through several numerical experiments and compare their performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.13046v2</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Quoc Tran-Dinh</dc:creator>
    </item>
    <item>
      <title>Optimal control of convective Brinkman-Forchheimer equations: Dynamic programming equation and Viscosity solutions</title>
      <link>https://arxiv.org/abs/2505.07095</link>
      <description>arXiv:2505.07095v2 Announce Type: replace 
Abstract: It has been pointed out in the work [F. Gozzi et.al., \emph{Arch. Ration. Mech. Anal.} {163}(4) (2002), 295--327] that the existence and uniqueness of viscosity solutions to the first-order Hamilton-Jacobi-Bellman equation (HJBE) associated with the three-dimensional Navier-Stokes equations (NSE) have not been resolved due to the lack of global solvability and continuous dependence results. However, by adding a damping term to NSE, the so-called \emph{damped Navier-Stokes equations} fulfills the requirement of existence and uniqueness of global strong solutions. In this work, we address this issue in the context of the following two- and three-dimensional convective Brinkman-Forchheimer (CBF) equations (damped NSE) in $\mathbb{T}^d,\ d\in\{2,3\}$:
  \begin{align*}
  \frac{\partial\boldsymbol{u}}{\partial t}-\mu \Delta\boldsymbol{u}+(\boldsymbol{u}\cdot\nabla)\boldsymbol{u}+\alpha\boldsymbol{u}+\beta|\boldsymbol{u}|^{r-1}\boldsymbol{u}+\nabla p=\boldsymbol{f}, \ \nabla\cdot\boldsymbol{u}=0,
  \end{align*}
  where $\mu,\alpha,\beta&gt;0$, $r\in[1,\infty)$. We first prove the existence of a viscosity solution to the infinite-dimensional HJBE in the supercritical regime. For spatial dimension $d=2$, we consider the nonlinearity exponent $r\in(3,\infty)$, while for $d=3$, due to some technical difficulty, we focus on $r\in(3,5]$. In the case $r=3$, we require the condition $2\beta\mu\geq 1$ for both $d=2$ and $d=3$. Next, we derive a comparison principle for the HJB equation covering the ranges $r\in(3,\infty)$ and $r=3$ with $2\beta\mu\geq 1$ in $d\in\{2,3\}$. It ensures the uniqueness of the viscosity solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07095v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sagar Gautam, Manil T. Mohan</dc:creator>
    </item>
    <item>
      <title>Convergence rates of regularized quasi-Newton methods without strong convexity</title>
      <link>https://arxiv.org/abs/2506.00521</link>
      <description>arXiv:2506.00521v3 Announce Type: replace 
Abstract: In this paper, we study convergence rates of the cubic regularized proximal quasi-Newton method (\csr) for solving non-smooth additive composite problems that satisfy the so-called Kurdyka-\L ojasiewicz (K\L ) property with respect to some desingularization function $\phi$ rather than strong convexity. After a number of iterations $k_0$, Cubic SR1 PQN exhibits non-asymptotic explicit super-linear convergence rates for any $k\geq k_0$. In particular, when $\phi(t)=ct^{1/2}$, Cubic SR1 PQN has a convergence rate of order $\left(\frac{C}{(k-k_0)^{1/2}}\right)^{(k-k_0)/2}$, where $k$ is the number of iterations and $C&gt;0$ is a constant. For the special case, i.e. functions which satisfy \L ojasiewicz inequality, the rate becomes global and non-asymptotic. This work presents, for the first time, non-asymptotic explicit convergence rates of regularized (proximal) SR1 quasi-Newton methods applied to non-convex non-smooth problems with K\L\ property. Actually, the rates are novel even in the smooth non-convex case. Notably, we achieve this without employing line search or trust region strategies, without assuming the Dennis-Mor\'e condition, without any assumptions on quasi-Newton metrics and without assuming strong convexity. Furthermore, for convex problems, we focus on a more tractable gradient regularized quasi-Newton method (Grad SR1 PQN) which can achieve results similar to those obtained with cubic regularization. We also demonstrate, for the first time, the non-asymptotic super-linear convergence rate of Grad SR1 PQN for solving convex problems with the help of the \L ojasiewicz inequality instead of strong convexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00521v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shida Wang, Jalal Fadili, Peter Ochs</dc:creator>
    </item>
    <item>
      <title>Computable Bounds on Convergence of Markov Chains in Wasserstein Distance via Contractive Drift</title>
      <link>https://arxiv.org/abs/2308.10341</link>
      <description>arXiv:2308.10341v2 Announce Type: replace-cross 
Abstract: We introduce a unified framework to estimate the convergence of Markov chains to equilibrium in Wasserstein distance. The framework can provide convergence bounds with rates ranging from polynomial to exponential, all derived from a contractive drift condition that integrates not only contraction and drift but also coupling and metric design. The resulting bounds are computable, as they contain simple constants, one-step transition expectations, but no equilibrium-related quantities. We introduce the large M technique and the boundary removal technique to enhance the applicability of the framework, which is further enhanced by deep learning in Qu, Blanchet and Glynn (2024). We apply the framework to non-contractive or even expansive Markov chains arising from queueing theory, stochastic optimization, and Markov chain Monte Carlo.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.10341v2</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanlin Qu, Jose Blanchet, Peter Glynn</dc:creator>
    </item>
    <item>
      <title>Non-convex matrix sensing: Breaking the quadratic rank barrier in the sample complexity</title>
      <link>https://arxiv.org/abs/2408.13276</link>
      <description>arXiv:2408.13276v3 Announce Type: replace-cross 
Abstract: For the problem of reconstructing a low-rank matrix from a few linear measurements, two classes of algorithms have been widely studied in the literature: convex approaches based on nuclear norm minimization, and non-convex approaches that use factorized gradient descent. Under certain statistical model assumptions, it is known that nuclear norm minimization recovers the ground truth as soon as the number of samples scales linearly with the number of degrees of freedom of the ground truth. In contrast, while non-convex approaches are computationally less expensive, existing recovery guarantees assume that the number of samples scales at least quadratically with the rank $r$ of the ground-truth matrix. In this paper, we close this gap by showing that the non-convex approaches can be as efficient as nuclear norm minimization in terms of sample complexity. Namely, we consider the problem of reconstructing a positive semidefinite matrix from a few Gaussian measurements. We show that factorized gradient descent with spectral initialization converges to the ground truth with a linear rate as soon as the number of samples scales with $ \Omega (rd\kappa^2)$, where $d$ is the dimension, and $\kappa$ is the condition number of the ground truth matrix. This improves the previous rank-dependence in the sample complexity of non-convex matrix factorization from quadratic to linear. Our proof relies on a probabilistic decoupling argument, where we show that the gradient descent iterates are only weakly dependent on the individual entries of the measurement matrices. We expect that our proof technique is of independent interest for other non-convex problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13276v3</guid>
      <category>stat.ML</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dominik St\"oger, Yizhe Zhu</dc:creator>
    </item>
    <item>
      <title>Sketched Equivariant Imaging Regularization and Deep Internal Learning for Inverse Problems</title>
      <link>https://arxiv.org/abs/2411.05771</link>
      <description>arXiv:2411.05771v4 Announce Type: replace-cross 
Abstract: Equivariant Imaging (EI) regularization has become the de-facto technique for unsupervised training of deep imaging networks, without any need of ground-truth data. Observing that the EI-based unsupervised training paradigm currently has significant computational redundancy leading to inefficiency in high-dimensional applications, we propose a sketched EI regularization which leverages the randomized sketching techniques for acceleration. We apply our sketched EI regularization to develop an accelerated deep internal learning framework, which can be efficiently applied for test-time network adaptation. Additionally, for network adaptation tasks, we propose a parameter-efficient approach to accelerate both EI and Sketched-EI via optimizing only the normalization layers. Our numerical study on X-ray CT and multicoil magnetic resonance image reconstruction tasks demonstrate that our approach can achieve significant computational acceleration over standard EI counterpart in single-input setting and network adaptation at test time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05771v4</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guixian Xu, Jinglai Li, Junqi Tang</dc:creator>
    </item>
    <item>
      <title>Subspace correction methods for semicoercive and nearly semicoercive convex optimization with applications to nonlinear PDEs</title>
      <link>https://arxiv.org/abs/2412.17318</link>
      <description>arXiv:2412.17318v2 Announce Type: replace-cross 
Abstract: We present new convergence analyses for subspace correction methods for semicoercive and nearly semicoercive convex optimization problems, generalizing the theory of singular and nearly singular linear problems to the nonlinear domain. Our results demonstrate that the elegant theoretical framework developed for singular and nearly singular linear problems can be extended to semicoercive and nearly semicoercive convex optimization problems. For semicoercive problems, we show that the convergence rate can be estimated in terms of a seminorm stable decomposition over the subspaces and the kernel of the problem, aligning with the theory for singular linear problems. For nearly semicoercive problems, we establish a parameter-independent convergence rate, assuming the kernel of the semicoercive part can be decomposed into a sum of local kernels, which aligns with the theory for nearly singular problems. To demonstrate the applicability of our results, we provide convergence analyses of two-level additive Schwarz methods for solving a nonlinear Neumann boundary value problem and its perturbation within the proposed abstract framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17318v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Young-Ju Lee, Jongho Park</dc:creator>
    </item>
    <item>
      <title>Training Deep Learning Models with Norm-Constrained LMOs</title>
      <link>https://arxiv.org/abs/2502.07529</link>
      <description>arXiv:2502.07529v2 Announce Type: replace-cross 
Abstract: In this work, we study optimization methods that leverage the linear minimization oracle (LMO) over a norm-ball. We propose a new stochastic family of algorithms that uses the LMO to adapt to the geometry of the problem and, perhaps surprisingly, show that they can be applied to unconstrained problems. The resulting update rule unifies several existing optimization methods under a single framework. Furthermore, we propose an explicit choice of norm for deep architectures, which, as a side benefit, leads to the transferability of hyperparameters across model sizes. Experimentally, we demonstrate significant speedups on nanoGPT training using our algorithm, Scion, without any reliance on Adam. The proposed method is memory-efficient, requiring only one set of model weights and one set of gradients, which can be stored in half-precision. The code is available at https://github.com/LIONS-EPFL/scion .</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07529v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas Pethick, Wanyun Xie, Kimon Antonakopoulos, Zhenyu Zhu, Antonio Silveti-Falls, Volkan Cevher</dc:creator>
    </item>
    <item>
      <title>Scalable First-order Method for Certifying Optimal k-Sparse GLMs</title>
      <link>https://arxiv.org/abs/2502.09502</link>
      <description>arXiv:2502.09502v2 Announce Type: replace-cross 
Abstract: This paper investigates the problem of certifying optimality for sparse generalized linear models (GLMs), where sparsity is enforced through an $\ell_0$ cardinality constraint. While branch-and-bound (BnB) frameworks can certify optimality by pruning nodes using dual bounds, existing methods for computing these bounds are either computationally intensive or exhibit slow convergence, limiting their scalability to large-scale problems. To address this challenge, we propose a first-order proximal gradient algorithm designed to solve the perspective relaxation of the problem within a BnB framework. Specifically, we formulate the relaxed problem as a composite optimization problem and demonstrate that the proximal operator of the non-smooth component can be computed exactly in log-linear time complexity, eliminating the need to solve a computationally expensive second-order cone program. Furthermore, we introduce a simple restart strategy that enhances convergence speed while maintaining low per-iteration complexity. Extensive experiments on synthetic and real-world datasets show that our approach significantly accelerates dual bound computations and is highly effective in providing optimality certificates for large-scale problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09502v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiachang Liu, Soroosh Shafiee, Andrea Lodi</dc:creator>
    </item>
    <item>
      <title>BARK: A Fully Bayesian Tree Kernel for Black-box Optimization</title>
      <link>https://arxiv.org/abs/2503.05574</link>
      <description>arXiv:2503.05574v2 Announce Type: replace-cross 
Abstract: We perform Bayesian optimization using a Gaussian process perspective on Bayesian Additive Regression Trees (BART). Our BART Kernel (BARK) uses tree agreement to define a posterior over piecewise-constant functions, and we explore the space of tree kernels using a Markov chain Monte Carlo approach. Where BART only samples functions, the resulting BARK model obtains samples of Gaussian processes defining distributions over functions, which allow us to build acquisition functions for Bayesian optimization. Our tree-based approach enables global optimization over the surrogate, even for mixed-feature spaces. Moreover, where many previous tree-based kernels provide uncertainty quantification over function values, our sampling scheme captures uncertainty over the tree structure itself. Our experiments show the strong performance of BARK on both synthetic and applied benchmarks, due to the combination of our fully Bayesian surrogate and the optimization procedure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05574v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Toby Boyne, Jose Pablo Folch, Robert M Lee, Behrang Shafei, Ruth Misener</dc:creator>
    </item>
    <item>
      <title>Aging-aware Energy Management for Residential Multi-Carrier Energy Systems</title>
      <link>https://arxiv.org/abs/2503.16139</link>
      <description>arXiv:2503.16139v2 Announce Type: replace-cross 
Abstract: In the context of building electrification, the operation of distributed energy resources integrating multiple energy carriers (electricity, heat, mobility) poses a significant challenge due to the nonlinear device dynamics, uncertainty, and computational issues. As such, energy management systems seek to decide set points for the primary control layer in the best way possible. The objective is to minimize and balance operative costs (energy bills or asset degradation) with user requirements (mobility, heating, etc.). This paper presents a novel aging-aware day-ahead algorithm for electrified buildings. The proposed energy management algorithm incorporates physics-based battery aging models to enhance the operational performance, making explicit the trade-off between grid cost and battery degradation. The proposed day-ahead algorithm can either cut-down on grid costs or extend battery lifetime (electric vehicle or static packs). Moreover, it exploits the differences between cathode chemistries improving grid costs by 25\% when using LFP cells, with respect to NMC cells. Finally the performance using aged batteries is also enhanced, with respect to the benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16139v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dar\'io Slaifstein (Delft University of Technology), Gautham Ram Chandra Mouli (Delft University of Technology), Laura Ramirez-Elizondo (Delft University of Technology), Pavol Bauer (Delft University of Technology)</dc:creator>
    </item>
  </channel>
</rss>
