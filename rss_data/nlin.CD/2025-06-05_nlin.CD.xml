<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>nlin.CD updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/nlin.CD</link>
    <description>nlin.CD updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/nlin.CD" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Jun 2025 01:46:45 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Low-EFFourth: A computational framework for generating and studying multilevel model ensembles in low-dimensional systems</title>
      <link>https://arxiv.org/abs/2506.03313</link>
      <description>arXiv:2506.03313v1 Announce Type: cross 
Abstract: This paper introduces Low-EFFourth (LEF4), a MATLAB-based computational framework designed for generating and studying multilevel model ensembles in continuous dynamical systems. Initially developed to address questions in climate modelling, LEF4 can also be used in other disciplines such as epidemiology, economics, and engineering, with minimal modifications to the code. The framework provides an efficient and flexible approach for investigating uncertainties arising from initial conditions, model parameters, numerical methods, and model formulation. This preprint serves as a formal reference for the LEF4 codebase and provides a concise technical and conceptual overview of its purpose, structure, applications and development pipeline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03313v1</guid>
      <category>physics.geo-ph</category>
      <category>nlin.CD</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francisco de Melo Vir\'issimo</dc:creator>
    </item>
    <item>
      <title>Thermodynamics and Statistical Equilibrium of Large-Scale Hydroelastic Wave Turbulence</title>
      <link>https://arxiv.org/abs/2506.03353</link>
      <description>arXiv:2506.03353v1 Announce Type: cross 
Abstract: Understanding how statistical equilibrium can occur in out-of-equilibrium systems is of paramount interest, as it would enable the use of statistical mechanics tools to these systems. Here, we report the first experimental evidence of statistical equilibrium of the large scales of hydroelastic turbulent waves driven by small-scale random forcing. The wave field statistics at scales larger than the forcing scale, resolved in space and time, align well with the predictions of Rayleigh-Jeans equilibrium spectra over more than a decade. We measure zero net energy flux in this regime, as expected. We also determine the effective temperature, entropy, and heat capacity of this nonequilibrium system, demonstrating that classical thermodynamic concepts apply to describe large scales in statistical equilibrium of turbulent systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03353v1</guid>
      <category>physics.flu-dyn</category>
      <category>cond-mat.stat-mech</category>
      <category>nlin.CD</category>
      <category>physics.ao-ph</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Marlone Vernet, Eric Falcon</dc:creator>
    </item>
    <item>
      <title>Temporal horizons in forecasting: a performance-learnability trade-off</title>
      <link>https://arxiv.org/abs/2506.03889</link>
      <description>arXiv:2506.03889v1 Announce Type: cross 
Abstract: When training autoregressive models for dynamical systems, a critical question arises: how far into the future should the model be trained to predict? Too short a horizon may miss long-term trends, while too long a horizon can impede convergence due to accumulating prediction errors. In this work, we formalize this trade-off by analyzing how the geometry of the loss landscape depends on the training horizon. We prove that for chaotic systems, the loss landscape's roughness grows exponentially with the training horizon, while for limit cycles, it grows linearly, making long-horizon training inherently challenging. However, we also show that models trained on long horizons generalize well to short-term forecasts, whereas those trained on short horizons suffer exponentially (resp. linearly) worse long-term predictions in chaotic (resp. periodic) systems. We validate our theory through numerical experiments and discuss practical implications for selecting training horizons. Our results provide a principled foundation for hyperparameter optimization in autoregressive forecasting models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03889v1</guid>
      <category>cs.LG</category>
      <category>nlin.CD</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pau Vilimelis Aceituno, Jack William Miller, Noah Marti, Youssef Farag, Victor Boussange</dc:creator>
    </item>
  </channel>
</rss>
