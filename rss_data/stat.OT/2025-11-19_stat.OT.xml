<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.OT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.OT</link>
    <description>stat.OT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.OT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 19 Nov 2025 05:09:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Making Evidence Actionable in Adaptive Learning</title>
      <link>https://arxiv.org/abs/2511.14052</link>
      <description>arXiv:2511.14052v1 Announce Type: cross 
Abstract: Adaptive learning often diagnoses precisely yet intervenes weakly, yielding help that is mistimed or misaligned. This study presents evidence supporting an instructor-governed feedback loop that converts concept-level assessment evidence into vetted micro-interventions. The adaptive learning algorithm contains three safeguards: adequacy as a hard guarantee of gap closure, attention as a budgeted constraint for time and redundancy, and diversity as protection against overfitting to a single resource. We formalize intervention assignment as a binary integer program with constraints for coverage, time, difficulty windows informed by ability estimates, prerequisites encoded by a concept matrix, and anti-redundancy enforced through diversity. Greedy selection serves low-richness and tight-latency regimes, gradient-based relaxation serves rich repositories, and a hybrid method transitions along a richness-latency frontier. In simulation and in an introductory physics deployment with one thousand two hundred four students, both solvers achieved full skill coverage for essentially all learners within bounded watch time. The gradient-based method reduced redundant coverage by approximately twelve percentage points relative to greedy and harmonized difficulty across slates, while greedy delivered comparable adequacy with lower computational cost in scarce settings. Slack variables localized missing content and supported targeted curation, sustaining sufficiency across subgroups. The result is a tractable and auditable controller that closes the diagnostic-pedagogical loop and delivers equitable, load-aware personalization at classroom scale.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14052v1</guid>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>stat.AP</category>
      <category>stat.OT</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amirreza Mehrabi, Jason W. Morphew, Breejha Quezada, N. Sanjay Rebello</dc:creator>
    </item>
    <item>
      <title>PLS-SEM-power: A Shiny App and R package for Computing Required Sample Size and Minimum Detectable Effect Size in PLS-SEMs</title>
      <link>https://arxiv.org/abs/2511.14546</link>
      <description>arXiv:2511.14546v1 Announce Type: cross 
Abstract: Despite its evanescent nature, statistical power is crucial for planning Partial Least Squares Structural Equation Modelling (PLS-SEM) studies. This brief paper introduces PLS-SEM-power, a Shiny Application and R package that implements the inverse square root method by Kock and Hadaya (2018) to calculate both the minimum required sample size (a priori analysis) and the Minimum Detectable Effect Size (MDES, sensitivity analysis), given a chosen significance level (alpha level) at 80% power (1 - beta). The application provides an intuitive user interface, facilitating reproducible and easily accessible analyses in diverse research contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14546v1</guid>
      <category>stat.ME</category>
      <category>stat.OT</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Alessandro Ansani, Elena Rinallo</dc:creator>
    </item>
    <item>
      <title>A System Dynamics Approach to Evaluating Sludge Management Strategies in Vinasse Treatment: Cost-Benefit Analysis and Scenario Assessment</title>
      <link>https://arxiv.org/abs/2511.14607</link>
      <description>arXiv:2511.14607v1 Announce Type: cross 
Abstract: In the Chilean local alcohol industry (pisco indus- try), for one liter of alcohol produced 10-15 liters of vinasse as the main wastewater of the process. To comply with industrial waste regulations, vinasse must be stored, which enables evaporation, leaving behind a residual sludge. However, treating vinasse remains an environmental and industrial challenge, having a high nutrient concentration and acidity that can degrade soil quality and harm surrounding vegetation. While previous studies have modeled sludge generation and transport in urban water systems, research on industrial wastewater, such as the alcohol industry, remains limited, affecting the search for opportunities to improve the treatment process.. This paper proposes a System Dynamics Model (SDM) to assess the costs associated with three management strategies: natural drying of vinasse, relocation to an alternative site, and implementation of a coagulation- flocculation treatment to accelerate sludge production. This paper makes two contributions. First, we describe a pioneer SDM applicable to sludge management, which includes variables such as sludge transport, coagulant quantity, and ambient temperature to make hypothetical scenarios that affect the treatment processes of vinasse. Second, we present the expected results of the associated costs of the scenarios proposed in the model, helping decision-makers to manage vinasse. The model is calibrated with historical data provided by a company in the North of Chile, helping to improve the decision-making for vinasse treatment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14607v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>stat.OT</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Agustin Olivares, Paul Leger, Rodrigo Poblete</dc:creator>
    </item>
    <item>
      <title>MajinBook: An open catalogue of digital world literature with likes</title>
      <link>https://arxiv.org/abs/2511.11412</link>
      <description>arXiv:2511.11412v2 Announce Type: replace-cross 
Abstract: This data paper introduces MajinBook, an open catalogue designed to facilitate the use of shadow libraries--such as Library Genesis and Z-Library--for computational social science and cultural analytics. By linking metadata from these vast, crowd-sourced archives with structured bibliographic data from Goodreads, we create a high-precision corpus of over 539,000 references to English-language books spanning three centuries, enriched with first publication dates, genres, and popularity metrics like ratings and reviews. Our methodology prioritizes natively digital EPUB files to ensure machine-readable quality, while addressing biases in traditional corpora like HathiTrust, and includes secondary datasets for French, German, and Spanish. We evaluate the linkage strategy for accuracy, release all underlying data openly, and discuss the project's legal permissibility under EU and US frameworks for text and data mining in research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11412v2</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>stat.OT</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antoine Mazi\`eres, Thierry Poibeau</dc:creator>
    </item>
    <item>
      <title>CBDC Stress Test in a Dual-Currency Setting</title>
      <link>https://arxiv.org/abs/2511.13384</link>
      <description>arXiv:2511.13384v2 Announce Type: replace-cross 
Abstract: This study explores the potential impact of introducing a Central Bank Digital Currency (CBDC) on financial stability in an emerging dual-currency economy (Romania), where the domestic currency (RON) coexists with the euro. It develops an integrated analytical framework combining econometrics, machine learning, and behavioural modelling. CBDC adoption probabilities are estimated using XGBoost and logistic regression models trained on behavioural and macro-financial indicators rather than survey data. Liquidity stress simulations assess how banks would respond to deposit withdrawals resulting from CBDC adoption, while VAR, MSVAR, and SVAR models capture the macro-financial transmission of liquidity shocks into credit contraction and changes in monetary conditions. The findings indicate that CBDC uptake (co-circulating Digital RON and Digital EUR) would be moderate at issuance, amounting to around EUR 1 billion, primarily driven by digital readiness and trust in the central bank. The study concludes that a non-remunerated, capped CBDC, designed primarily as a means of payment rather than a store of value, can be introduced without compromising financial stability. In dual currency economies, differentiated holding limits for domestic and foreign digital currencies (e.g., Digital RON versus Digital Euro) are crucial to prevent uncontrolled euroisation and preserve monetary sovereignty. A prudent design with moderate caps, non remuneration, and macroprudential coordination can transform CBDC into a digital liquidity buffer and a complementary monetary policy instrument that enhances resilience and inclusion rather than destabilising the financial system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13384v2</guid>
      <category>q-fin.GN</category>
      <category>q-fin.CP</category>
      <category>q-fin.ST</category>
      <category>stat.OT</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Catalin Dumitrescu</dc:creator>
    </item>
  </channel>
</rss>
