<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 05 Nov 2025 05:01:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Grammar of Data Analysis</title>
      <link>https://arxiv.org/abs/2511.02156</link>
      <description>arXiv:2511.02156v1 Announce Type: new 
Abstract: This paper outlines a grammar of data analysis, as distinct from grammars of data manipulation, in which the primitives are metrics and dimensions. We describe a Python implementation of this grammar called Meterstick, which is agnostic to the underlying data source, which may be a DataFrame or a SQL database.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02156v1</guid>
      <category>stat.CO</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xunmo Yang, Taylor Pospisil, Omkar Muralidharan, Dennis L. Sun</dc:creator>
    </item>
    <item>
      <title>Efficient Solvers for SLOPE in R, Python, Julia, and C++</title>
      <link>https://arxiv.org/abs/2511.02430</link>
      <description>arXiv:2511.02430v1 Announce Type: new 
Abstract: We present a suite of packages in R, Python, Julia, and C++ that efficiently solve the Sorted L-One Penalized Estimation (SLOPE) problem. The packages feature a highly efficient hybrid coordinate descent algorithm that fits generalized linear models (GLMs) and supports a variety of loss functions, including Gaussian, binomial, Poisson, and multinomial logistic regression. Our implementation is designed to be fast, memory-efficient, and flexible. The packages support a variety of data structures (dense, sparse, and out-of-memory matrices) and are designed to efficiently fit the full SLOPE path as well as handle cross-validation of SLOPE models, including the relaxed SLOPE. We present examples of how to use the packages and benchmarks that demonstrate the performance of the packages on both real and simulated data and show that our packages outperform existing implementations of SLOPE in terms of speed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02430v1</guid>
      <category>stat.CO</category>
      <category>cs.MS</category>
      <category>cs.SE</category>
      <category>stat.ML</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johan Larsson, Malgorzata Bogdan, Krystyna Grzesiak, Mathurin Massias, Jonas Wallin</dc:creator>
    </item>
    <item>
      <title>Non Asymptotic Mixing Time Analysis of Non-Reversible Markov Chains</title>
      <link>https://arxiv.org/abs/2511.02265</link>
      <description>arXiv:2511.02265v1 Announce Type: cross 
Abstract: We introduce a unified operator-theoretic framework for analyzing mixing times of finite-state ergodic Markov chains that applies to both reversible and non-reversible dynamics. The central object in our analysis is the projected transition operator $PU_{\perp 1}$, where $P$ is the transition kernel and $U_{\perp 1}$ is orthogonal projection onto mean-zero subspace in $\ell^{2}(\pi)$, where $\pi$ is the stationary distribution. We show that explicitly computable matrix norms of $(PU_{\perp 1})^k$ gives non-asymptotic mixing times/distance to stationarity, and bound autocorrelations at lag $k$. We establish, for the first time, submultiplicativity of pointwise chi-squared divergence in the general non-reversible case. We provide for all times $\chi^{2}(k)$ bounds based on the spectrum of $PU_{\perp 1}$, i.e., magnitude of its distinct non-zero eigenvalues, discrepancy between their algebraic and geometric multiplicities, condition number of a similarity transform, and constant coming from smallest atom of stationary distribution(all scientifically computable). Furthermore, for diagonalizable $PU_{\perp 1}$, we provide explict constants satisfying hypocoercivity phenomenon for discrete time Markov Chains. Our framework enables direct computation of convergence bounds for challenging non-reversible chains, including momentum-based samplers for V-shaped distributions. We provide the sharpest known bounds for non-reversible walk on triangle. Our results combined with simple regression reveals a fundamental insight into momentum samplers: although for uniform distributions, $n\log{n}$ iterations suffice for $\chi^{2}$ mixing, for V-shaped distributions they remain diffusive as $n^{1.969}\log{n^{1.956}}$ iterations are sufficient. The framework shows that for ergodic chains relaxation times $\tau_{rel}=\|\sum_{k=0}^{\infty}P^{k}U_{\perp 1}\|_{\ell^{2}(\pi)}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02265v1</guid>
      <category>math.PR</category>
      <category>stat.CO</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Muhammad Abdullah Naeem</dc:creator>
    </item>
    <item>
      <title>A Stable Lasso</title>
      <link>https://arxiv.org/abs/2511.02306</link>
      <description>arXiv:2511.02306v1 Announce Type: cross 
Abstract: The Lasso has been widely used as a method for variable selection, valued for its simplicity and empirical performance. However, Lasso's selection stability deteriorates in the presence of correlated predictors. Several approaches have been developed to mitigate this limitation. In this paper, we provide a brief review of existing approaches, highlighting their limitations. We then propose a simple technique to improve the selection stability of Lasso by integrating a weighting scheme into the Lasso penalty function, where the weights are defined as an increasing function of a correlation-adjusted ranking that reflects the predictive power of predictors. Empirical evaluations on both simulated and real-world datasets demonstrate the efficacy of the proposed method. Additional numerical results demonstrate the effectiveness of the proposed approach in stabilizing other regularization-based selection methods, indicating its potential as a general-purpose solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02306v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mahdi Nouraie, Houying Zhu, Samuel Muller</dc:creator>
    </item>
    <item>
      <title>Reducing normalizing flow complexity for MCMC preconditioning</title>
      <link>https://arxiv.org/abs/2511.02345</link>
      <description>arXiv:2511.02345v1 Announce Type: cross 
Abstract: Preconditioning is a key component of MCMC algorithms that improves sampling efficiency by facilitating exploration of geometrically complex target distributions through an invertible map. While linear preconditioners are often sufficient for moderately complex target distributions, recent work has explored nonlinear preconditioning with invertible neural networks as components of normalizing flows (NFs). However, empirical and theoretical studies show that overparameterized NF preconditioners can degrade sampling efficiency and fit quality. Moreover, existing NF-based approaches do not adapt their architectures to the target distribution. Related work outside of MCMC similarly finds that suitably parameterized NFs can achieve comparable or superior performance with substantially less training time or data. We propose a factorized preconditioning architecture that reduces NF complexity by combining a linear component with a conditional NF, improving adaptability to target geometry. The linear preconditioner is applied to dimensions that are approximately Gaussian, as estimated from warmup samples, while the conditional NF models more complex dimensions. Our method yields significantly better tail samples on two complex synthetic distributions and consistently better performance on a sparse logistic regression posterior across varying likelihood and prior strengths. It also achieves higher effective sample sizes on hierarchical Bayesian model posteriors with weak likelihoods and strong funnel geometries. This approach is particularly relevant for hierarchical Bayesian model analyses with limited data and could inform current theoretical and software strides in neural MCMC design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02345v1</guid>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Nabergoj, Erik \v{S}trumbelj</dc:creator>
    </item>
    <item>
      <title>A new class of Markov random fields enabling lightweight sampling</title>
      <link>https://arxiv.org/abs/2511.02373</link>
      <description>arXiv:2511.02373v1 Announce Type: cross 
Abstract: This work addresses the problem of efficient sampling of Markov random fields (MRF). The sampling of Potts or Ising MRF is most often based on Gibbs sampling, and is thus computationally expensive. We consider in this work how to circumvent this bottleneck through a link with Gaussian Markov Random fields. The latter can be sampled in several cost-effective ways, and we introduce a mapping from real-valued GMRF to discrete-valued MRF. The resulting new class of MRF benefits from a few theoretical properties that validate the new model. Numerical results show the drastic performance gain in terms of computational efficiency, as we sample at least 35x faster than Gibbs sampling using at least 37x less energy, all the while exhibiting empirical properties close to classical MRFs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02373v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>stat.CO</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jean-Baptiste Courbot, Hugo Gangloff, Bruno Colicchio</dc:creator>
    </item>
    <item>
      <title>Identification of Separable OTUs for Multinomial Classification in Compositional Data Analysis</title>
      <link>https://arxiv.org/abs/2511.02509</link>
      <description>arXiv:2511.02509v1 Announce Type: cross 
Abstract: High-throughput sequencing has transformed microbiome research, but it also produces inherently compositional data that challenge standard statistical and machine learning methods. In this work, we propose a multinomial classification framework for compositional microbiome data based on penalized log-ratio regression and pairwise separability screening. The method quantifies the discriminative ability of each OTU through the area under the receiver operating characteristic curve ($AUC$) for all pairwise log-ratios and aggregates these values into a global separability index $S_k$, yielding interpretable rankings of taxa together with confidence intervals. We illustrate the approach by reanalyzing the Baxter colorectal adenoma dataset and comparing our results with Greenacre's ordination-based analysis using Correspondence Analysis and Canonical Correspondence Analysis. Our models consistently recover a core subset of taxa previously identified as discriminant, thereby corroborating Greenacre's main findings, while also revealing additional OTUs that become important once demographic covariates are taken into account. In particular, adjustment for age, gender, and diabetes medication improves the precision of the separation index and highlights new, potentially relevant taxa, suggesting that part of the original signal may have been influenced by confounding. Overall, the integration of log-ratio modeling, covariate adjustment, and uncertainty estimation provides a robust and interpretable framework for OTU selection in compositional microbiome data. The proposed method complements existing ordination-based approaches by adding a probabilistic and inferential perspective, strengthening the identification of biologically meaningful microbial signatures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02509v1</guid>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>R. Alberich, N. A. Cruz, R. Fern\'andez, I. Garc\'ia Mosquera, A. Mir, F. Rosell\'o</dc:creator>
    </item>
    <item>
      <title>Bayesian copula-based spatial random effects models for inference with complex spatial data</title>
      <link>https://arxiv.org/abs/2511.02551</link>
      <description>arXiv:2511.02551v1 Announce Type: cross 
Abstract: In this article, we develop fully Bayesian, copula-based, spatial-statistical models for large, noisy, incomplete, and non-Gaussian spatial data. Our approach includes novel constructions of copulas that accommodate a spatial-random-effects structure, enabling low-rank representations and computationally efficient Bayesian inference. The spatial copula is used in a latent process model of the Bayesian hierarchical spatial-statistical model, and, conditional on the latent copula-based spatial process, the data model handles measurement errors and missing data. Our simulation studies show that a fully Bayesian approach delivers accurate and fast inference for both parameter estimation and spatial-process prediction, outperforming several benchmark methods, including fixed rank kriging (FRK). The new class of copula-based models is used to map atmospheric methane in the Bowen Basin, Queensland, Australia, from Sentinel 5P satellite data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02551v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alan Pearse, David Gunawan, Noel Cressie</dc:creator>
    </item>
    <item>
      <title>Extended Kalman Filtering on Stiefel Manifolds</title>
      <link>https://arxiv.org/abs/2511.02682</link>
      <description>arXiv:2511.02682v1 Announce Type: cross 
Abstract: A generalisation of the extended Kalman filter for Stiefel manifold-valued measurements is presented. We provide simulations on the 2-sphere and the space of orthogonal 4-by-2 matrices which show significant improvement of the Extended Kalman Filter compared to only relying on raw measurements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02682v1</guid>
      <category>stat.AP</category>
      <category>math.DG</category>
      <category>stat.CO</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jordi-Llu\'is Figueras, Aron Persson, Lauri Viitasaari</dc:creator>
    </item>
  </channel>
</rss>
