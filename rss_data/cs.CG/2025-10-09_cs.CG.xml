<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CG updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CG</link>
    <description>cs.CG updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CG" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 10 Oct 2025 01:56:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>All Polyhedral Manifolds are Connected by a 2-Step Refolding</title>
      <link>https://arxiv.org/abs/2412.02174</link>
      <description>arXiv:2412.02174v2 Announce Type: replace 
Abstract: We prove that, for any two polyhedral manifolds $\mathcal P,\mathcal Q$, there is a polyhedral manifold $\mathcal I$ such that $\mathcal P,\mathcal I$ share a common unfolding and $\mathcal I,\mathcal Q$ share a common unfolding. In other words, we can unfold $\mathcal P$, refold (glue) that unfolding into $\mathcal I$, unfold $\mathcal I$, and then refold into $\mathcal Q$. Furthermore, if $\mathcal P,\mathcal Q$ have no boundary and can be embedded in 3D (without self-intersection), then so does $\mathcal I$. These results generalize to $n$ given manifolds $\mathcal P_1,\mathcal P_2, \dots, \mathcal P_n$; they all have a common unfolding with the same intermediate manifold $\mathcal I$. Allowing more than two unfold/refold steps, we obtain stronger results for two special cases: for doubly covered convex planar polygons, we achieve that all intermediate polyhedra are planar; and for tree-shaped polycubes, we achieve that all intermediate polyhedra are tree-shaped polycubes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02174v2</guid>
      <category>cs.CG</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lily Chung, Erik D. Demaine, Jenny Diomidova, Tonan Kamata, Jayson Lynch, Ryuhei Uehara, Hanyu Alice Zhang</dc:creator>
    </item>
    <item>
      <title>Sliding Squares in Parallel</title>
      <link>https://arxiv.org/abs/2412.05523</link>
      <description>arXiv:2412.05523v2 Announce Type: replace 
Abstract: We consider algorithmic problems motivated by modular robotic reconfiguration in the sliding square model, in which we are given $n$ square-shaped modules in a (labeled or unlabeled) start configuration and need to find a schedule of sliding moves to transform it into a desired goal configuration, maintaining connectivity of the configuration at all times. Recent work has aimed at minimizing the total number of moves, resulting in fully sequential schedules that perform reconfiguration in $\mathcal{O}(nP)$ moves for arrangements of bounding box perimeter size $P$, or a number of moves linear in the sum of module coordinates in the start and target arrangements.
  We extend the model to leverage the possibility of parallel motion, thereby reducing worst-case makespans by a factor linear in $n$. Our work presents tight results both in terms of complexity and algorithms: We show that deciding the existence of a single parallel reconfiguration step that solves an instance is NP-complete for unlabeled modules, but can be solved efficiently in the labeled setting. Nevertheless, deciding whether a labeled instance can be solved in two parallel steps is NP-complete. Finally, we describe an algorithm to perform in-place reconfiguration in worst-case optimal $\mathcal{O}(P)$ parallel steps for the unlabeled setting. This algorithm has a straight-forward extension to the labeled setting with slight relaxations to either the reconfiguration time or space constraint.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05523v2</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hugo A. Akitaya, S\'andor P. Fekete, Peter Kramer, Saba Molaei, Christian Rieck, Frederick Stock, Tobias Wallner</dc:creator>
    </item>
    <item>
      <title>Train-Free Segmentation in MRI with Cubical Persistent Homology</title>
      <link>https://arxiv.org/abs/2401.01160</link>
      <description>arXiv:2401.01160v2 Announce Type: replace-cross 
Abstract: We present a new general framework for segmentation of MRI scans based on Topological Data Analysis (TDA), offering several advantages over traditional machine learning approaches. The pipeline proceeds in three steps, first identifying the whole object to segment via automatic thresholding, then detecting a distinctive subset whose topology is known in advance, and finally deducing the various components of the segmentation. Unlike most prior TDA uses in medical image segmentation, which are typically embedded within deep networks, our approach is a standalone method tailored to MRI. A key ingredient is the localization of representative cycles from the persistence diagram, which enables interpretable mappings from topological features to anatomical components. In particular, the method offers the ability to perform segmentation without the need for large annotated datasets. Its modular design makes it adaptable to a wide range of data segmentation challenges. We validate the framework on three applications: glioblastoma segmentation in brain MRI, where a sphere is to be detected; myocardium in cardiac MRI, forming a cylinder; and cortical plate detection in fetal brain MRI, whose 2D slices are circles. We compare our method with established supervised and unsupervised baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.01160v2</guid>
      <category>eess.IV</category>
      <category>cs.CG</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anton Fran\c{c}ois, Rapha\"el Tinarrage</dc:creator>
    </item>
    <item>
      <title>AMBER: Adaptive Mesh Generation by Iterative Mesh Resolution Prediction</title>
      <link>https://arxiv.org/abs/2505.23663</link>
      <description>arXiv:2505.23663v2 Announce Type: replace-cross 
Abstract: The cost and accuracy of simulating complex physical systems using the Finite Element Method (FEM) scales with the resolution of the underlying mesh. Adaptive meshes improve computational efficiency by refining resolution in critical regions, but typically require task-specific heuristics or cumbersome manual design by a human expert. We propose Adaptive Meshing By Expert Reconstruction (AMBER), a supervised learning approach to mesh adaptation. Starting from a coarse mesh, AMBER iteratively predicts the sizing field, i.e., a function mapping from the geometry to the local element size of the target mesh, and uses this prediction to produce a new intermediate mesh using an out-of-the-box mesh generator. This process is enabled through a hierarchical graph neural network, and relies on data augmentation by automatically projecting expert labels onto AMBER-generated data during training. We evaluate AMBER on 2D and 3D datasets, including classical physics problems, mechanical components, and real-world industrial designs with human expert meshes. AMBER generalizes to unseen geometries and consistently outperforms multiple recent baselines, including ones using Graph and Convolutional Neural Networks, and Reinforcement Learning-based approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23663v2</guid>
      <category>cs.LG</category>
      <category>cs.CG</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Niklas Freymuth, Tobias W\"urth, Nicolas Schreiber, Balazs Gyenes, Andreas Boltres, Johannes Mitsch, Aleksandar Taranovic, Tai Hoang, Philipp Dahlinger, Philipp Becker, Luise K\"arger, Gerhard Neumann</dc:creator>
    </item>
  </channel>
</rss>
