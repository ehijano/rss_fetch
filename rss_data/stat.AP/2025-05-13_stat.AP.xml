<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 14 May 2025 01:39:44 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>An Early Warning Model for Forced Displacement</title>
      <link>https://arxiv.org/abs/2505.06249</link>
      <description>arXiv:2505.06249v1 Announce Type: new 
Abstract: Monitoring tools for anticipatory action are increasingly gaining traction to improve the efficiency and timeliness of humanitarian responses. Whilst predictive models can now forecast conflicts with high accuracy, translating these predictions into potential forced displacement movements remains challenging because it is often unclear which precise events will trigger significant population movements. This paper presents a novel monitoring approach for refugee and asylum seeker flows that addresses this challenge. Using gradient boosting classification, we combine conflict forecasts with a comprehensive set of economic, political, and demographic variables to assess two distinct risks at the country of origin: the likelihood of significant displacement flows and the probability of sudden increases in these flows. The model generates country-specific monthly risk indices for these two events with prediction horizons of one, three, and six months. Our analysis shows high accuracy in predicting significant displacement flows and good accuracy in forecasting sudden increases in displacement--the latter being inherently more difficult to predict, given the complexity of displacement triggers. We achieve these results by including predictive factors beyond conflict, thereby demonstrating that forced displacement risks can be assessed through an integrated analysis of multiple country-level indicators. Whilst these risk indices provide valuable quantitative support for humanitarian planning, they should always be understood as decision-support tools within a broader analytical framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06249v1</guid>
      <category>stat.AP</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Geraldine Henningsen</dc:creator>
    </item>
    <item>
      <title>Prediction of Delirium Risk in Mild Cognitive Impairment Using Time-Series data, Machine Learning and Comorbidity Patterns -- A Retrospective Study</title>
      <link>https://arxiv.org/abs/2505.06264</link>
      <description>arXiv:2505.06264v1 Announce Type: new 
Abstract: Delirium represents a significant clinical concern characterized by high morbidity and mortality rates, particularly in patients with mild cognitive impairment (MCI). This study investigates the associated risk factors for delirium by analyzing the comorbidity patterns relevant to MCI and developing a longitudinal predictive model leveraging machine learning methodologies. A retrospective analysis utilizing the MIMIC-IV v2.2 database was performed to evaluate comorbid conditions, survival probabilities, and predictive modeling outcomes. The examination of comorbidity patterns identified distinct risk profiles for the MCI population. Kaplan-Meier survival analysis demonstrated that individuals with MCI exhibit markedly reduced survival probabilities when developing delirium compared to their non-MCI counterparts, underscoring the heightened vulnerability within this cohort. For predictive modeling, a Long Short-Term Memory (LSTM) ML network was implemented utilizing time-series data, demographic variables, Charlson Comorbidity Index (CCI) scores, and an array of comorbid conditions. The model demonstrated robust predictive capabilities with an AUROC of 0.93 and an AUPRC of 0.92. This study underscores the critical role of comorbidities in evaluating delirium risk and highlights the efficacy of time-series predictive modeling in pinpointing patients at elevated risk for delirium development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06264v1</guid>
      <category>stat.AP</category>
      <category>cs.AI</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Santhakumar Ramamoorthy, Priya Rani, James Mahon, Glenn Mathews, Shaun Cloherty, Mahdi Babaei</dc:creator>
    </item>
    <item>
      <title>Adaptive Bayesian Very Short-Term Wind Power Forecasting Based on the Generalised Logit Transformation</title>
      <link>https://arxiv.org/abs/2505.06310</link>
      <description>arXiv:2505.06310v1 Announce Type: new 
Abstract: Wind power plays an increasingly significant role in achieving the 2050 Net Zero Strategy. Despite its rapid growth, its inherent variability presents challenges in forecasting. Accurately forecasting wind power generation is one key demand for the stable and controllable integration of renewable energy into existing grid operations. This paper proposes an adaptive method for very short-term forecasting that combines the generalised logit transformation with a Bayesian approach. The generalised logit transformation processes double-bounded wind power data to an unbounded domain, facilitating the application of Bayesian methods. A novel adaptive mechanism for updating the transformation shape parameter is introduced to leverage Bayesian updates by recovering a small sample of representative data. Four adaptive forecasting methods are investigated, evaluating their advantages and limitations through an extensive case study of over 100 wind farms ranging four years in the UK. The methods are evaluated using the Continuous Ranked Probability Score and we propose the use of functional reliability diagrams to assess calibration. Results indicate that the proposed Bayesian method with adaptive shape parameter updating outperforms benchmarks, yielding consistent improvements in CRPS and forecast reliability. The method effectively addresses uncertainty, ensuring robust and accurate probabilistic forecasting which is essential for grid integration and decision-making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06310v1</guid>
      <category>stat.AP</category>
      <category>cs.LG</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Tao Shen, Jethro Browell, Daniela Castro-Camilo</dc:creator>
    </item>
    <item>
      <title>Data Envelopment Analysis based on robust and closest targets</title>
      <link>https://arxiv.org/abs/2505.06487</link>
      <description>arXiv:2505.06487v1 Announce Type: new 
Abstract: As business environments grow increasingly volatile and unpredictable, the selection of benchmarking targets in data envelopment analysis should account for their ability to withstand risks, yet this aspect has not received sufficient attention. We propose a kind of robust benchmarking target defined by the intersection of the maximum number of full-dimensional efficient facets, each embedding a unique marginal substitution relationship. These targets can serve as robust projections for firms lacking prior risk information because they encompass the maximum number of marginal substitution relationships. This enables firms to adjust their outputs through these relationships, maximizing the likelihood of achieving globally optimal revenue. Furthermore, we put forward a novel well-defined efficiency measure based on robust and closest targets. Finally, we demonstrate the application of the proposed measure, using a dataset comprising 38 universities from China's 985 Project.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06487v1</guid>
      <category>stat.AP</category>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xiuquan Huang, Xi Wang, Tao Zhang, Xiaocang Xu</dc:creator>
    </item>
    <item>
      <title>Causal mediation analysis with one or multiple mediators: a comparative study</title>
      <link>https://arxiv.org/abs/2505.07323</link>
      <description>arXiv:2505.07323v1 Announce Type: new 
Abstract: Mediation analysis breaks down the causal effect of a treatment on an outcome into an indirect effect, acting through a third group of variables called mediators, and a direct effect, operating through other mechanisms. Mediation analysis is hard because confounders between treatment, mediators, and outcome blur effect estimates in observational studies. Many estimators have been proposed to adjust on those confounders and provide accurate causal estimates. We consider parametric and non-parametric implementations of classical estimators and provide a thorough evaluation for the estimation of the direct and indirect effects in the context of causal mediation analysis for binary, continuous, and multi-dimensional mediators. We assess several approaches in a comprehensive benchmark on simulated data.  Our results show that advanced statistical approaches such as the multiply robust and the double machine learning estimators achieve good performances in most of the simulated settings and on real data. As an example of application, we propose a thorough analysis of factors known to influence cognitive functions to assess if the mechanism involves modifications in brain morphology using the UK Biobank brain imaging cohort. This analysis shows that for several physiological factors, such as hypertension and obesity, a substantial part of the effect is mediated by changes in the brain structure. This work provides guidance to the practitioner from the formulation of a valid causal mediation problem, including the verification of the identification assumptions, to the choice of an adequate estimator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07323v1</guid>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Judith Ab\'ecassis (SODA, IP Paris), Houssam Zenati (MIND), Sami Bouma\"iza (SODA), Julie Josse (PREMEDICAL), Bertrand Thirion (MIND)</dc:creator>
    </item>
    <item>
      <title>A Value of Information-based assessment of strain-based thickness loss monitoring in ship hull structures</title>
      <link>https://arxiv.org/abs/2505.07427</link>
      <description>arXiv:2505.07427v1 Announce Type: new 
Abstract: Recent advances in Structural Health Monitoring (SHM) have attracted industry interest, yet real-world applications, such as in ship structures remain scarce. Despite SHM's potential to optimise maintenance, its adoption in ships is limited due to the lack of clearly quantifiable benefits for hull maintenance. This study employs a Bayesian pre-posterior decision analysis to quantify the value of information (VoI) from SHM systems monitoring corrosion-induced thickness loss (CITL) in ship hulls, in a first-of-its-kind analysis for ship structures. We define decision-making consequence cost functions based on exceedance probabilities relative to a target CITL threshold, which can be set by the decision-maker. This introduces a practical aspect to our framework, that enables implicitly modelling the decision-maker's risk perception. We apply this framework to a large-scale, high-fidelity numerical model of a commercial vessel and examine the relative benefits of different CITL monitoring strategies, including strain-based SHM and traditional on-site inspections.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07427v1</guid>
      <category>stat.AP</category>
      <category>cs.CE</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nicholas E. Silionis, Konstantinos N. Anyfantis</dc:creator>
    </item>
    <item>
      <title>Modelling higher education dropouts using sparse and interpretable post-clustering logistic regression</title>
      <link>https://arxiv.org/abs/2505.07582</link>
      <description>arXiv:2505.07582v1 Announce Type: new 
Abstract: Higher education dropout constitutes a critical challenge for tertiary education systems worldwide. While machine learning techniques can achieve high predictive accuracy on selected datasets, their adoption by policymakers remains limited and unsatisfactory, particularly when the objective is the unsupervised identification and characterization of student subgroups at elevated risk of dropout. The model introduced in this paper is a specialized form of logistic regression, specifically adapted to the context of university dropout analysis. Logistic regression continues to serve as a foundational tool among reliable statistical models, primarily due to the ease with which its parameters can be interpreted in terms of odds ratios. Our approach significantly extends this framework by incorporating heterogeneity within the student population. This is achieved through the application of a preliminary clustering algorithm that identifies latent subgroups, each characterized by distinct dropout propensities, which are then modeled via cluster-specific effects. We provide a detailed interpretation of the model parameters within this extended framework and enhance interpretability by imposing sparsity through a tailored variant of the LASSO algorithm. To demonstrate the practical applicability of the proposed methodology, we present an extensive case study based on the Italian university system, in which all the developed tools are systematically applied</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07582v1</guid>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea Nigri, Massimo Bilancia, Barbara Cafarelli, Samuele Magro</dc:creator>
    </item>
    <item>
      <title>An investigation of air pollution-induced temperature sensitivity and susceptibility to heat-related hospitalization in the Medicare population</title>
      <link>https://arxiv.org/abs/2505.07662</link>
      <description>arXiv:2505.07662v1 Announce Type: new 
Abstract: Background: With rising temperatures and an aging US population, understanding how to prevent heat-related illness among older Americans will be an increasingly critical objective. Despite biological plausibility, no study to date has investigated how exposure to fine particulate matter air pollution (PM$_{2.5}$) may contribute to risk of heat-related hospitalization.
  Methods: We identified Medicare fee-for-service beneficiaries who experienced a heat-related hospitalization between 2008 and 2016. Using a case-crossover design and fitting Bayesian conditional logistic regression models, we characterized the association between heat-related hospitalization and temperature and PM$_{2.5}$ exposures. We estimated the relative excess risk due to interaction (RERI) to quantify the additive-scale interaction of simultaneous exposure to heat and PM$_{2.5}$.
  Results: We observed 112,969 heat-related hospitalizations. Fixing PM$_{2.5}$ at the case day median, increasing temperature from its case day median to the 95th percentile was associated with an odds ratio of 1.045 (95% CI: 1.026, 1.063). Fixing temperature at the case day median and increasing PM$_{2.5}$ from its median to the 95th percentile was associated with an odds ratio of 1.014 (95% CI: 0.993, 1.037). We estimated the RERI associated with simultaneous median-to-95th percentile increases in temperature and PM$_{2.5}$ to be 0.032 (0.007, 0.057).
  Conclusion: Using nationwide Medicare claims and a self-matched study design, we found evidence supporting synergism between temperature and PM$_{2.5}$ exposures on the risk of heat-related hospitalization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07662v1</guid>
      <category>stat.AP</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lauren Mock, Rachel C. Nethery, Poonam Gandhi, Ashwaghosha Parthasarathi, Melanie Rua, David Robinson, Soko Setoguchi, Kevin Josey</dc:creator>
    </item>
    <item>
      <title>Assessing the Impact of External and Internal Factors on Emergency Department Overcrowding</title>
      <link>https://arxiv.org/abs/2505.06238</link>
      <description>arXiv:2505.06238v1 Announce Type: cross 
Abstract: Study Objective: To analyze the factors influencing Emergency Department (ED) overcrowding by examining the impacts of operational, environmental, and external variables, including weather conditions and football games.
  Methods: This study integrates ED tracking and hospital census data from a southeastern U.S. academic medical center (2019-2023) with data from external sources, including weather, football events, and federal holidays. The dependent variable is the hourly waiting count in the ED. Seven regression models were developed to assess the effects of different predictors such as weather conditions, hospital census, federal holidays, and football games across different timestamps.
  Results: Some weather conditions significantly increased ED crowding in the Baseline Model, while federal holidays and weekends consistently reduced waiting counts. Boarding count positively correlated with ED crowding when they are concurrent, but earlier boarding count (3-6 hours before) showed significant negative associations, reducing subsequent waiting counts. Hospital census exhibited a negative association in the Baseline Model but shifted to a positive effect in other models, reflecting its time-dependent influence on ED operations. Football games 12 hours before significantly increased waiting counts, while games 12 and 24 hours after had no significant effects.
  Conclusion: This study highlights the importance of incorporating both operational and non-operational factors (e.g., weather) to understand ED patient flow. Identifying robust predictors such as weather, federal holidays, boarding count, and hospital census can inform dynamic resource allocation strategies to mitigate ED overcrowding effectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06238v1</guid>
      <category>cs.CY</category>
      <category>stat.AP</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abdulaziz Ahmed, Khalid Y Aram, Mohammed Alzeen, Orhun Vural, James Booth, Brittany F. Lindsey, Bunyamin Ozaydin</dc:creator>
    </item>
    <item>
      <title>United States Road Accident Prediction using Random Forest Predictor</title>
      <link>https://arxiv.org/abs/2505.06246</link>
      <description>arXiv:2505.06246v1 Announce Type: cross 
Abstract: Road accidents significantly threaten public safety and require in-depth analysis for effective prevention and mitigation strategies. This paper focuses on predicting accidents through the examination of a comprehensive traffic dataset covering 49 states in the United States. The dataset integrates information from diverse sources, including transportation departments, law enforcement, and traffic sensors. This paper specifically emphasizes predicting the number of accidents, utilizing advanced machine learning models such as regression analysis and time series analysis. The inclusion of various factors, ranging from environmental conditions to human behavior and infrastructure, ensures a holistic understanding of the dynamics influencing road safety. Temporal and spatial analysis further allows for the identification of trends, seasonal variations, and high-risk areas. The implications of this research extend to proactive decision-making for policymakers and transportation authorities. By providing accurate predictions and quantifiable insights into expected accident rates under different conditions, the paper aims to empower authorities to allocate resources efficiently and implement targeted interventions. The goal is to contribute to the development of informed policies and interventions that enhance road safety, creating a safer environment for all road users. Keywords: Machine Learning, Random Forest, Accident Prediction, AutoML, LSTM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06246v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>IEEE Access (2023)</arxiv:journal_reference>
      <dc:creator>Dominic Parosh Yamarthi, Haripriya Raman, Shamsad Parvin</dc:creator>
    </item>
    <item>
      <title>Modeling supply chain compliance response strategies based on AI synthetic data with structural path regression: A Simulation Study of EU 2027 Mandatory Labor Regulations</title>
      <link>https://arxiv.org/abs/2505.06261</link>
      <description>arXiv:2505.06261v1 Announce Type: cross 
Abstract: In the context of the new mandatory labor compliance in the European Union (EU), which will be implemented in 2027, supply chain enterprises face stringent working hour management requirements and compliance risks. In order to scientifically predict the enterprises' coping behaviors and performance outcomes under the policy impact, this paper constructs a methodological framework that integrates the AI synthetic data generation mechanism and structural path regression modeling to simulate the enterprises' strategic transition paths under the new regulations. In terms of research methodology, this paper adopts high-quality simulation data generated based on Monte Carlo mechanism and NIST synthetic data standards to construct a structural path analysis model that includes multiple linear regression, logistic regression, mediation effect and moderating effect. The variable system covers 14 indicators such as enterprise working hours, compliance investment, response speed, automation level, policy dependence, etc. The variable set with explanatory power is screened out through exploratory data analysis (EDA) and VIF multicollinearity elimination. The findings show that compliance investment has a significant positive impact on firm survival and its effect is transmitted through the mediating path of the level of intelligence; meanwhile, firms' dependence on the EU market significantly moderates the strength of this mediating effect. It is concluded that AI synthetic data combined with structural path modeling provides an effective tool for high-intensity regulatory simulation, which can provide a quantitative basis for corporate strategic response, policy design and AI-assisted decision-making in the pre-prediction stage lacking real scenario data. Keywords: AI synthetic data, structural path regression modeling, compliance response strategy, EU 2027 mandatory labor regulation</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06261v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>stat.AP</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei Meng</dc:creator>
    </item>
    <item>
      <title>Borrowing strength between unaligned binary time-series via Bayesian nonparametric rescaling of Unified Skewed Normal priors</title>
      <link>https://arxiv.org/abs/2505.06491</link>
      <description>arXiv:2505.06491v1 Announce Type: cross 
Abstract: We define a Bayesian semi-parametric model to effectively conduct inference with unaligned longitudinal binary data. The proposed strategy is motivated by data from the Human Epilepsy Project (HEP), which collects seizure occurrence data for epilepsy patients, together with relevant covariates. The model is designed to flexibly accommodate the particular challenges that arise with such data. First, epilepsy data require models that can allow for extensive heterogeneity, across both patients and time. With this regard, state space models offer a flexible, yet still analytically amenable class of models. Nevertheless, seizure time-series might share similar behavioral patterns, such as local prolonged periods of elevated seizure presence, which we refer to as "clumping". Such similarities can be used to share strength across patients and define subgroups. However, due to the lack of alignment, straightforward hierarchical modeling of latent state space parameters is not practicable. To overcome this constraint, we construct a strategy that preserves the flexibility of individual trajectories while also exploiting similarities across individuals to borrow information through a nonparametric prior. On the one hand, heterogeneity is ensured by (almost) subject-specific state-space submodels. On the other, borrowing of information is obtained by introducing a Pitman-Yor prior on group-specific probabilities for patterns of clinical interest. We design a posterior sampling strategy that leverages recent developments of binary state space models using the Unified Skewed Normal family (SUN). The model, which allows the sharing of information across individuals with similar disease traits over time, can more generally be adapted to any setting characterized by unaligned binary longitudinal data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06491v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Beatrice Cantoni, Giovanni Poli, Elizabeth Juarez-Colunga, Peter M\"uller</dc:creator>
    </item>
    <item>
      <title>The Malaysian Election Corpus (MECo): Federal and State-Level Election Results from 1955 to 2025</title>
      <link>https://arxiv.org/abs/2505.06564</link>
      <description>arXiv:2505.06564v1 Announce Type: cross 
Abstract: Empirical research and public knowledge on Malaysia's elections have long been constrained by a lack of high-quality open data, particularly in the absence of a Freedom of Information framework. We introduce the Malaysian Election Corpus (MECo; ElectionData.MY), an open-access panel database covering all federal and state general elections from 1955 to the present, as well as by-elections from 2008 onward. MECo includes candidate- and constituency-level results for nearly 10,000 contests across seven decades, standardised with unique identifiers for candidates, parties, and constituencies. The database also provides summary statistics on electorate size, voter turnout, rejected votes, and unreturned ballots. This is the most well-curated publicly available data on Malaysian elections, and will unlock new opportunities for research, data journalism, and civic engagement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06564v1</guid>
      <category>cs.CY</category>
      <category>stat.AP</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Thevesh Thevananthan</dc:creator>
    </item>
    <item>
      <title>Exploring Monetary Policy Shocks with Large-Scale Bayesian VARs</title>
      <link>https://arxiv.org/abs/2505.06649</link>
      <description>arXiv:2505.06649v1 Announce Type: cross 
Abstract: I introduce a high-dimensional Bayesian vector autoregressive (BVAR) framework designed to estimate the effects of conventional monetary policy shocks. The model captures structural shocks as latent factors, enabling computationally efficient estimation in high-dimensional settings through a straightforward Gibbs sampler. By incorporating time variation in the effects of monetary policy while maintaining tractability, the methodology offers a flexible and scalable approach to empirical macroeconomic analysis using BVARs, well-suited to handle data irregularities observed in recent times. Applied to the U.S. economy, I identify monetary shocks using a combination of high-frequency surprises and sign restrictions, yielding results that are robust across a wide range of specification choices. The findings indicate that the Federal Reserve's influence on disaggregated consumer prices fluctuated significantly during the 2022-24 high-inflation period, shedding new light on the evolving dynamics of monetary policy transmission.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06649v1</guid>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dimitris Korobilis</dc:creator>
    </item>
    <item>
      <title>FCPCA: Fuzzy clustering of high-dimensional time series based on common principal component analysis</title>
      <link>https://arxiv.org/abs/2505.07276</link>
      <description>arXiv:2505.07276v1 Announce Type: cross 
Abstract: Clustering multivariate time series data is a crucial task in many domains, as it enables the identification of meaningful patterns and groups in time-evolving data. Traditional approaches, such as crisp clustering, rely on the assumption that clusters are sufficiently separated with little overlap. However, real-world data often defy this assumption, exhibiting overlapping distributions or overlapping clouds of points and blurred boundaries between clusters. Fuzzy clustering offers a compelling alternative by allowing partial membership in multiple clusters, making it well-suited for these ambiguous scenarios. Despite its advantages, current fuzzy clustering methods primarily focus on univariate time series, and for multivariate cases, even datasets of moderate dimensionality become computationally prohibitive. This challenge is further exacerbated when dealing with time series of varying lengths, leaving a clear gap in addressing the complexities of modern datasets. This work introduces a novel fuzzy clustering approach based on common principal component analysis to address the aforementioned shortcomings. Our method has the advantage of efficiently handling high-dimensional multivariate time series by reducing dimensionality while preserving critical temporal features. Extensive numerical results show that our proposed clustering method outperforms several existing approaches in the literature. An interesting application involving brain signals from different drivers recorded from a simulated driving experiment illustrates the potential of the approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07276v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ziling Ma, \'Angel L\'opez-Oriona, Hernando Ombao, Ying Sun</dc:creator>
    </item>
    <item>
      <title>Learning Penalty for Optimal Partitioning via Automatic Feature Extraction</title>
      <link>https://arxiv.org/abs/2505.07413</link>
      <description>arXiv:2505.07413v1 Announce Type: cross 
Abstract: Changepoint detection identifies significant shifts in data sequences, making it important in areas like finance, genetics, and healthcare. The Optimal Partitioning algorithms efficiently detect these changes, using a penalty parameter to limit the changepoints number. Determining the appropriate value for this penalty can be challenging. Traditionally, this process involved manually extracting statistical features, such as sequence length or variance to make the prediction. This study proposes a novel approach that uses recurrent neural networks to learn this penalty directly from raw sequences by automatically extracting features. Experiments conducted on 20 benchmark genomic datasets show that this novel method surpasses traditional methods in partitioning accuracy in most cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07413v1</guid>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tung L Nguyen, Toby Hocking</dc:creator>
    </item>
    <item>
      <title>Separable models for dynamic signed networks</title>
      <link>https://arxiv.org/abs/2505.07669</link>
      <description>arXiv:2505.07669v1 Announce Type: cross 
Abstract: Signed networks capture the polarity of relationships between nodes, providing valuable insights into complex systems where both supportive and antagonistic interactions play a critical role in shaping the network's dynamics. We propose a separable temporal generative framework based on multi-layer exponential random graph models, characterised by the assumption of conditional independence between the sign and interaction effects. This structure preserves the flexibly and explanatory power inherent in the binary network specification while adhering to consistent balance theory assumptions. Using a fully probabilistic Bayesian paradigm, we infer the doubly intractable posterior distribution of model parameters via an adaptive Metropolis-Hastings approximate exchange algorithm. We illustrate the interpretability of our model by analysing signed relations among U.S. Senators during Ronald Reagan's second term (1985-1989). Specifically, we aim to understand whether these relations are consistent and balanced or reflect patterns of supportive or antagonistic alliances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07669v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alberto Caimo, Isabella Gollini</dc:creator>
    </item>
    <item>
      <title>Moderation effects and elasticities in compositional regression with a total. Application to Bayesian spatiotemporal modelling of all-cause mortality from environmental stressors</title>
      <link>https://arxiv.org/abs/2505.07800</link>
      <description>arXiv:2505.07800v1 Announce Type: cross 
Abstract: Compositional regression models with a real-valued response variable can generally be specified as log-contrast models subject to a zero-sum constraint on the model coefficients. This formulation emphasises the relative information conveyed in the composition, while the overall total is regarded irrelevant. In this work, such a setting is extended to account not only for total effects, formally defined in a so-called T-space, but also for moderation or interaction effects. This is applied in the context of complex spatiotemporal data modelling, through an adaptation of the integrated nested Laplace approximation (INLA) method within a Bayesian estimation framework. Particular emphasis is placed on the interpretation of model coefficients and results, both on the original scale of the response variable and in terms of elasticities.
  The methodology is demonstrated through a detailed case study investigating the relationship between all-cause mortality and the interaction between extreme temperatures, air pollution composition, and total air pollution in Catalonia, Spain, during the summer of 2022. The results indicate that extreme temperatures are associated with an increased risk of mortality four days after exposure. Additionally, exposure to total air pollution, especially to NO2, is linked to elevated mortality risk regardless of temperature. In contrast, particulate matter is associated to increased mortality only when exposure occurs on days of extreme heat.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07800v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Germ\`a Coenders (Research Group on Statistics, Econometrics and Health, Centro de Investigaci\'on Biom\'edica en Red de Epidemiolog\'ia y Salud P\'ublica, Instituto de Salud Carlos III), Javier Palarea-Albaladejo (Dept. of Computer Science, Applied Mathematics and Statistics. University of Girona), Marc Saez (Research Group on Statistics, Econometrics and Health, Centro de Investigaci\'on Biom\'edica en Red de Epidemiolog\'ia y Salud P\'ublica, Instituto de Salud Carlos III), Maria A. Barcel\'o (Research Group on Statistics, Econometrics and Health, Centro de Investigaci\'on Biom\'edica en Red de Epidemiolog\'ia y Salud P\'ublica, Instituto de Salud Carlos III)</dc:creator>
    </item>
    <item>
      <title>Integrated Bayesian non-parametric spatial modeling for cross-sample identification of spatially variable genes</title>
      <link>https://arxiv.org/abs/2504.09654</link>
      <description>arXiv:2504.09654v2 Announce Type: replace 
Abstract: Spatial transcriptomics has revolutionized tissue analysis by simultaneously mapping gene expression, spatial topography, and histological context across consecutive tissue sections, enabling systematic investigation of spatial heterogeneity. The detection of spatially variable (SV) genes, which are molecular signatures with position-dependent expression, provides critical insights into disease mechanisms spanning oncology, neurology, and cardiovascular research. Current methodologies, however, confront dual constraints: predominant reliance on predefined spatial pattern templates restricts detection of novel complex spatial architectures, and inconsistent sample selection strategies compromise analytical stability and biological interpretability. To overcome these challenges, we propose a novel Bayesian hierarchical framework incorporating non-parametric spatial modeling and across-sample integration. It takes advantage of the non-parametric technique and develops an adaptive spatial process accommodating complex pattern discovery while maintaining biological interpretability. A novel cross-sample bi-level shrinkage prior is further introduced for robust multi-sample SV gene detection, facilitating more effective information fusion. An efficient variational inference is developed for posterior inference ensuring computational scalability. Comprehensive simulations demonstrate the improved performance of our proposed method over existing analytical frameworks, and its application to DLPFC data reveals interpretable SV genes whose spatial patterns delineate neuroanatomically relevant clusters and gradients, advancing brain transcriptomics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09654v2</guid>
      <category>stat.AP</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Meng Zhou, Shuangge Ma, Mengyun Wu</dc:creator>
    </item>
    <item>
      <title>Local linear smoothing for regression surfaces on the simplex using Dirichlet kernels</title>
      <link>https://arxiv.org/abs/2408.07209</link>
      <description>arXiv:2408.07209v4 Announce Type: replace-cross 
Abstract: This paper introduces a local linear smoother for regression surfaces on the simplex. The estimator solves a least-squares regression problem weighted by a locally adaptive Dirichlet kernel, ensuring good boundary properties. Asymptotic results for the bias, variance, mean squared error, and mean integrated squared error are derived, generalizing the univariate results of Chen [Ann. Inst. Statist. Math., 54(2) (2002), pp. 312-323]. A simulation study shows that the proposed local linear estimator with Dirichlet kernel outperforms its only direct competitor in the literature, the Nadaraya-Watson estimator with Dirichlet kernel due to Bouzebda, Nezzal and Elhattab [AIMS Math., 9(9) (2024), pp. 26195-26282].</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07209v4</guid>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian Genest, Fr\'ed\'eric Ouimet</dc:creator>
    </item>
    <item>
      <title>AI-Assisted Decision-Making for Clinical Assessment of Auto-Segmented Contour Quality</title>
      <link>https://arxiv.org/abs/2505.00308</link>
      <description>arXiv:2505.00308v2 Announce Type: replace-cross 
Abstract: Purpose: This study presents a Deep Learning (DL)-based quality assessment (QA) approach for evaluating auto-generated contours (auto-contours) in radiotherapy, with emphasis on Online Adaptive Radiotherapy (OART). Leveraging Bayesian Ordinal Classification (BOC) and calibrated uncertainty thresholds, the method enables confident QA predictions without relying on ground truth contours or extensive manual labeling. Methods: We developed a BOC model to classify auto-contour quality and quantify prediction uncertainty. A calibration step was used to optimize uncertainty thresholds that meet clinical accuracy needs. The method was validated under three data scenarios: no manual labels, limited labels, and extensive labels. For rectum contours in prostate cancer, we applied geometric surrogate labels when manual labels were absent, transfer learning when limited, and direct supervision when ample labels were available. Results: The BOC model delivered robust performance across all scenarios. Fine-tuning with just 30 manual labels and calibrating with 34 subjects yielded over 90% accuracy on test data. Using the calibrated threshold, over 93% of the auto-contours' qualities were accurately predicted in over 98% of cases, reducing unnecessary manual reviews and highlighting cases needing correction. Conclusion: The proposed QA model enhances contouring efficiency in OART by reducing manual workload and enabling fast, informed clinical decisions. Through uncertainty quantification, it ensures safer, more reliable radiotherapy workflows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00308v2</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>stat.AP</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Biling Wang, Austen Maniscalco, Ti Bai, Siqiu Wang, Michael Dohopolski, Mu-Han Lin, Chenyang Shen, Dan Nguyen, Junzhou Huang, Steve Jiang, Xinlei Wang</dc:creator>
    </item>
  </channel>
</rss>
