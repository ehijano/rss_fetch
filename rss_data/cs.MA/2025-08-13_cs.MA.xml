<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.MA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.MA</link>
    <description>cs.MA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.MA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 14 Aug 2025 04:02:39 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Cowpox: Towards the Immunity of VLM-based Multi-Agent Systems</title>
      <link>https://arxiv.org/abs/2508.09230</link>
      <description>arXiv:2508.09230v1 Announce Type: new 
Abstract: Vision Language Model (VLM)-based agents are stateful, autonomous entities capable of perceiving and interacting with their environments through vision and language. Multi-agent systems comprise specialized agents who collaborate to solve a (complex) task. A core security property is robustness, stating that the system should maintain its integrity under adversarial attacks. However, the design of existing multi-agent systems lacks the robustness consideration, as a successful exploit against one agent can spread and infect other agents to undermine the entire system's assurance. To address this, we propose a new defense approach, Cowpox, to provably enhance the robustness of multi-agent systems. It incorporates a distributed mechanism, which improves the recovery rate of agents by limiting the expected number of infections to other agents. The core idea is to generate and distribute a special cure sample that immunizes an agent against the attack before exposure and helps recover the already infected agents. We demonstrate the effectiveness of Cowpox empirically and provide theoretical robustness guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09230v1</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yutong Wu, Jie Zhang, Yiming Li, Chao Zhang, Qing Guo, Nils Lukas, Tianwei Zhang</dc:creator>
    </item>
    <item>
      <title>Emergence of Hierarchies in Multi-Agent Self-Organizing Systems Pursuing a Joint Objective</title>
      <link>https://arxiv.org/abs/2508.09541</link>
      <description>arXiv:2508.09541v1 Announce Type: new 
Abstract: Multi-agent self-organizing systems (MASOS) exhibit key characteristics including scalability, adaptability, flexibility, and robustness, which have contributed to their extensive application across various fields. However, the self-organizing nature of MASOS also introduces elements of unpredictability in their emergent behaviors. This paper focuses on the emergence of dependency hierarchies during task execution, aiming to understand how such hierarchies arise from agents' collective pursuit of the joint objective, how they evolve dynamically, and what factors govern their development. To investigate this phenomenon, multi-agent reinforcement learning (MARL) is employed to train MASOS for a collaborative box-pushing task. By calculating the gradients of each agent's actions in relation to the states of other agents, the inter-agent dependencies are quantified, and the emergence of hierarchies is analyzed through the aggregation of these dependencies. Our results demonstrate that hierarchies emerge dynamically as agents work towards a joint objective, with these hierarchies evolving in response to changing task requirements. Notably, these dependency hierarchies emerge organically in response to the shared objective, rather than being a consequence of pre-configured rules or parameters that can be fine-tuned to achieve specific results. Furthermore, the emergence of hierarchies is influenced by the task environment and network initialization conditions. Additionally, hierarchies in MASOS emerge from the dynamic interplay between agents' "Talent" and "Effort" within the "Environment." "Talent" determines an agent's initial influence on collective decision-making, while continuous "Effort" within the "Environment" enables agents to shift their roles and positions within the system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09541v1</guid>
      <category>cs.MA</category>
      <category>cs.LG</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gang Chen, Guoxin Wang, Anton van Beek, Zhenjun Ming, Yan Yan</dc:creator>
    </item>
    <item>
      <title>Extending the OWASP Multi-Agentic System Threat Modeling Guide: Insights from Multi-Agent Security Research</title>
      <link>https://arxiv.org/abs/2508.09815</link>
      <description>arXiv:2508.09815v1 Announce Type: new 
Abstract: We propose an extension to the OWASP Multi-Agentic System (MAS) Threat Modeling Guide, translating recent anticipatory research in multi-agent security (MASEC) into practical guidance for addressing challenges unique to large language model (LLM)-driven multi-agent architectures. Although OWASP's existing taxonomy covers many attack vectors, our analysis identifies gaps in modeling failures, including, but not limited to: reasoning collapse across planner-executor chains, metric overfitting, unsafe delegation escalation, emergent covert coordination, and heterogeneous multi-agent exploits. We introduce additional threat classes and scenarios grounded in practical MAS deployments, highlighting risks from benign goal drift, cross-agent hallucination propagation, affective prompt framing, and multi-agent backdoors. We also outline evaluation strategies, including robustness testing, coordination assessment, safety enforcement, and emergent behavior monitoring, to ensure complete coverage. This work complements the framework of OWASP by expanding its applicability to increasingly complex, autonomous, and adaptive multi-agent systems, with the goal of improving security posture and resilience in real world deployments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09815v1</guid>
      <category>cs.MA</category>
      <category>cs.CR</category>
      <category>cs.SE</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Klaudia Krawiecka, Christian Schroeder de Witt</dc:creator>
    </item>
    <item>
      <title>The 2R-Conjecture for the Hegselmann--Krause Model: A Proof in Expectation and New Directions</title>
      <link>https://arxiv.org/abs/2508.08299</link>
      <description>arXiv:2508.08299v1 Announce Type: cross 
Abstract: Hegselmann--Krause models are localized, distributed averaging dynamics on spatial data. A key aspect of these dynamics is that they lead to cluster formation, which has important applications in geographic information systems, dynamic clustering algorithms, opinion dynamics, and social networks. For these models, the key questions are whether a fixed point exists and, if so, characterizing it. In this work, we establish new results towards the "2R-Conjecture" for the Hegselmann--Krause model, for which no meaningful progress, or even any precise statement, has been made since its introduction in 2007. This conjecture relates to the structure of the fixed point when there are a large number of agents per unit space. We provide, among other results, a proof in expectation and a statement of a stronger result that is supported by simulation. The key methodological contribution is to consider the dynamics as an infinite-dimensional problem on the space of point processes, rather than on finitely many points. This enables us to leverage stationarity, shift invariance, and certain other symmetries to obtain the results. These techniques do not have finite-dimensional analogs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08299v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.MA</category>
      <category>math.PR</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Partha S. Dey, S. Rasoul Etesami, Aditya S. Gopalan</dc:creator>
    </item>
    <item>
      <title>Agentic TinyML for Intent-aware Handover in 6G Wireless Networks</title>
      <link>https://arxiv.org/abs/2508.09147</link>
      <description>arXiv:2508.09147v1 Announce Type: cross 
Abstract: As 6G networks evolve into increasingly AI-driven, user-centric ecosystems, traditional reactive handover mechanisms demonstrate limitations, especially in mobile edge computing and autonomous agent-based service scenarios. This manuscript introduces WAAN, a cross-layer framework that enables intent-aware and proactive handovers by embedding lightweight TinyML agents as autonomous, negotiation-capable entities across heterogeneous edge nodes that contribute to intent propagation and network adaptation. To ensure continuity across mobility-induced disruptions, WAAN incorporates semi-stable rendezvous points that serve as coordination anchors for context transfer and state preservation. The framework's operational capabilities are demonstrated through a multimodal environmental control case study, highlighting its effectiveness in maintaining user experience under mobility. Finally, the article discusses key challenges and future opportunities associated with the deployment and evolution of WAAN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09147v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alaa Saleh, Roberto Morabito, Sasu Tarkoma, Anders Lindgren, Susanna Pirttikangas, Lauri Lov\'en</dc:creator>
    </item>
    <item>
      <title>Physiological Signal-Driven QoE Optimization for Wireless Virtual Reality Transmission</title>
      <link>https://arxiv.org/abs/2508.09151</link>
      <description>arXiv:2508.09151v1 Announce Type: cross 
Abstract: Abrupt resolution changes in virtual reality (VR) streaming can significantly impair the quality-of-experience (QoE) of users, particularly during transitions from high to low resolutions. Existing QoE models and transmission schemes inadequately address the perceptual impact of these shifts. To bridge this gap, this article proposes, for the first time, an innovative physiological signal-driven QoE modeling and optimization framework that fully leverages users' electroencephalogram (EEG), electrocardiogram (ECG), and skin activity signals. This framework precisely captures the temporal dynamics of physiological responses and resolution changes in VR streaming, enabling accurate quantification of resolution upgrades' benefits and downgrades' impacts. Integrated the proposed QoE framework into the radio access network (RAN) via a deep reinforcement learning (DRL) framework, adaptive transmission strategies have been implemented to allocate radio resources dynamically, which mitigates short-term channel fluctuations and adjusts frame resolution in response to channel variations caused by user mobility. By prioritizing long-term resolution while minimizing abrupt transitions, the proposed solution achieves an 88.7\% improvement in resolution and an 81.0\% reduction in handover over the baseline. Experimental results demonstrate the effectiveness of this physiological signal-driven strategy, underscoring the promise of edge AI in immersive media services.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09151v1</guid>
      <category>cs.NI</category>
      <category>cs.MA</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chang Wu, Yuang Chen, Yiyuan Chen, Fengqian Guo, Xiaowei Qin, Hancheng Lu</dc:creator>
    </item>
    <item>
      <title>Constrained Black-Box Attacks Against Multi-Agent Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2508.09275</link>
      <description>arXiv:2508.09275v1 Announce Type: cross 
Abstract: Collaborative multi-agent reinforcement learning (c-MARL) has rapidly evolved, offering state-of-the-art algorithms for real-world applications, including sensitive domains. However, a key challenge to its widespread adoption is the lack of a thorough investigation into its vulnerabilities to adversarial attacks. Existing work predominantly focuses on training-time attacks or unrealistic scenarios, such as access to policy weights or the ability to train surrogate policies. In this paper, we investigate new vulnerabilities under more realistic and constrained conditions, assuming an adversary can only collect and perturb the observations of deployed agents. We also consider scenarios where the adversary has no access at all. We propose simple yet highly effective algorithms for generating adversarial perturbations designed to misalign how victim agents perceive their environment. Our approach is empirically validated on three benchmarks and 22 environments, demonstrating its effectiveness across diverse algorithms and environments. Furthermore, we show that our algorithm is sample-efficient, requiring only 1,000 samples compared to the millions needed by previous methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09275v1</guid>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amine Andam, Jamal Bentahar, Mustapha Hedabou</dc:creator>
    </item>
    <item>
      <title>Online Safety under Multiple Constraints and Input Bounds using gatekeeper: Theory and Applications</title>
      <link>https://arxiv.org/abs/2508.09963</link>
      <description>arXiv:2508.09963v1 Announce Type: cross 
Abstract: This letter presents an approach to guarantee online safety of a cyber-physical system under multiple state and input constraints. Our proposed framework, called gatekeeper, recursively guarantees the existence of an infinite-horizon trajectory that satisfies all constraints and system dynamics. Such trajectory is constructed using a backup controller, which we define formally in this paper. gatekeeper relies on a small number of verifiable assumptions, and is computationally efficient since it requires optimization over a single scalar variable. We make two primary contributions in this letter. (A) First, we develop the theory of gatekeeper: we derive a sub-optimality bound relative to a full nonlinear trajectory optimization problem, and show how this can be used in runtime to validate performance. This also informs the design of the backup controllers and sets. (B) Second, we demonstrate in detail an application of gatekeeper for multi-agent formation flight, where each Dubins agent must avoid multiple obstacles and weapons engagement zones, both of which are nonlinear, nonconvex constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09963v1</guid>
      <category>eess.SY</category>
      <category>cs.MA</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Devansh R. Agrawal, Dimitra Panagou</dc:creator>
    </item>
    <item>
      <title>Game-Theoretic Multiagent Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2011.00583</link>
      <description>arXiv:2011.00583v5 Announce Type: replace 
Abstract: Tremendous advances have been made in multiagent reinforcement learning (MARL). MARL corresponds to the learning problem in a multiagent system in which multiple agents learn simultaneously. It is an interdisciplinary field of study with a long history that includes game theory, machine learning, stochastic control, psychology, and optimization. Despite great successes in MARL, there is a lack of a self-contained overview of the literature that covers game-theoretic foundations of modern MARL methods and summarizes the recent advances. The majority of existing surveys are outdated and do not fully cover the recent developments since 2010. In this work, we provide a monograph on MARL that covers both the fundamentals and the latest developments on the research frontier. The goal of this monograph is to provide a self-contained assessment of the current state-of-the-art MARL techniques from a game-theoretic perspective. We expect this work to serve as a stepping stone for both new researchers who are about to enter this fast-growing field and experts in the field who want to obtain a panoramic view and identify new directions based on recent advances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2011.00583v5</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yaodong Yang, Chengdong Ma, Zihan Ding, Stephen McAleer, Chi Jin, Jun Wang, Tuomas Sandholm</dc:creator>
    </item>
    <item>
      <title>ABIDES-Economist: Agent-Based Simulator of Economic Systems with Learning Agents</title>
      <link>https://arxiv.org/abs/2402.09563</link>
      <description>arXiv:2402.09563v2 Announce Type: replace 
Abstract: We present ABIDES-Economist, an agent-based simulator for economic systems that includes heterogeneous households, firms, a central bank, and a government. Agent behavior can be defined using domain-specific behavioral rules or learned through reinforcement learning by specifying their objectives. We integrate reinforcement learning capabilities for all agents using the OpenAI Gym environment framework for the multi-agent system. To enhance the realism of our model, we base agent parameters and action spaces on economic literature and real U.S. economic data. To tackle the challenges of calibrating heterogeneous agent-based economic models, we conduct a comprehensive survey of stylized facts related to both microeconomic and macroeconomic time series data. We then validate ABIDES-Economist by demonstrating its ability to generate simulated data that aligns with the relevant stylized facts for the economic scenario under consideration, following the learning of all agent behaviors via reinforcement learning. Specifically, we train our economic agents' policies under two broad configurations. The first configuration demonstrates that the learned economic agents produce system data consistent with macroeconomic and microeconomic stylized facts. The second configuration illustrates the utility of the validated simulation platform in designing regulatory policies for the central bank and government. These policies outperform standard rule-based approaches from the literature, which often overlook agent heterogeneity, shocks, and agent adaptability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.09563v2</guid>
      <category>cs.MA</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kshama Dwarakanath, Tucker Balch, Svitlana Vyetrenko</dc:creator>
    </item>
    <item>
      <title>Inertial Coordination Games</title>
      <link>https://arxiv.org/abs/2409.08145</link>
      <description>arXiv:2409.08145v3 Announce Type: replace-cross 
Abstract: We analyze inertial coordination games: dynamic coordination games with an endogenously changing state that depends on (i) a persistent fundamental players privately learn about over time; and (ii) past play. The speed of learning determines long-run equilibrium dynamics: the risk-dominant action is played in the limit if and only if learning is slow such that posterior precisions grow sub-quadratically. This generalizes results from static global games and endows them with a learning foundation. Conversely, when learning is fast such that posterior precisions grow super-quadratically, shocks can propagate and generate self-fulfilling spirals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08145v3</guid>
      <category>econ.TH</category>
      <category>cs.MA</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew Koh, Ricky Li, Kei Uzui</dc:creator>
    </item>
    <item>
      <title>Finite-Time Global Optimality Convergence in Deep Neural Actor-Critic Methods for Decentralized Multi-Agent Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2505.18433</link>
      <description>arXiv:2505.18433v2 Announce Type: replace-cross 
Abstract: Actor-critic methods for decentralized multi-agent reinforcement learning (MARL) facilitate collaborative optimal decision making without centralized coordination, thus enabling a wide range of applications in practice. To date, however, most theoretical convergence studies for existing actor-critic decentralized MARL methods are limited to the guarantee of a stationary solution under the linear function approximation. This leaves a significant gap between the highly successful use of deep neural actor-critic for decentralized MARL in practice and the current theoretical understanding. To bridge this gap, in this paper, we make the first attempt to develop a deep neural actor-critic method for decentralized MARL, where both the actor and critic components are inherently non-linear. We show that our proposed method enjoys a global optimality guarantee with a finite-time convergence rate of O(1/T), where T is the total iteration times. This marks the first global convergence result for deep neural actor-critic methods in the MARL literature. We also conduct extensive numerical experiments, which verify our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18433v2</guid>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhiyao Zhang, Myeung Suk Oh, FNU Hairi, Ziyue Luo, Alvaro Velasquez, Jia Liu</dc:creator>
    </item>
    <item>
      <title>Memp: Exploring Agent Procedural Memory</title>
      <link>https://arxiv.org/abs/2508.06433</link>
      <description>arXiv:2508.06433v2 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) based agents excel at diverse tasks, yet they suffer from brittle procedural memory that is manually engineered or entangled in static parameters. In this work, we investigate strategies to endow agents with a learnable, updatable, and lifelong procedural memory. We propose Memp that distills past agent trajectories into both fine-grained, step-by-step instructions and higher-level, script-like abstractions, and explore the impact of different strategies for Build, Retrieval, and Update of procedural memory. Coupled with a dynamic regimen that continuously updates, corrects, and deprecates its contents, this repository evolves in lockstep with new experience. Empirical evaluation on TravelPlanner and ALFWorld shows that as the memory repository is refined, agents achieve steadily higher success rates and greater efficiency on analogous tasks. Moreover, procedural memory built from a stronger model retains its value: migrating the procedural memory to a weaker model yields substantial performance gains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06433v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Runnan Fang, Yuan Liang, Xiaobin Wang, Jialong Wu, Shuofei Qiao, Pengjun Xie, Fei Huang, Huajun Chen, Ningyu Zhang</dc:creator>
    </item>
    <item>
      <title>miRKatAI: An Integrated Database and Multi-agent AI system for microRNA Research</title>
      <link>https://arxiv.org/abs/2508.08331</link>
      <description>arXiv:2508.08331v2 Announce Type: replace-cross 
Abstract: MicroRNAs (miRs) are robust regulators of gene expression, implicated in most biological processes. microRNAs predominantly downregulate the expression of genes post-transcriptionally and each miR is predicted to target several hundred genes. The accurate identification and annotation of miR-mRNA target interactions is central to understanding miRs function and their therapeutic potential. However, computational target prediction is challenging due to imperfect complementarity of miRs with their targets and the growing volume and heterogeneity of experimental data present challenges in accessing, integrating, and analysing miR-target interaction information across biological contexts. This creates a need for integrated resources and intelligent query tools.
  We present the miRKat Suite, comprising miRKatDB, a comprehensive, curated database of predicted and validated miR-target interactions and associated annotations, and miRKatAI, a multi-agent system powered by large language models (LLMs) and LangGraph. miRKatDB integrates data from multiple publicly available sources, providing a comprehensive foundation for miR studies, including miR target genes and changes in levels of tissue expression previously reported. miRKatAI offers a natural language interface for complex querying of miRKatDB, facilitates grounded information retrieval from established sources in the field, and supports basic data visualisation. The miRKat Suite aims to accelerate miR research by streamlining data access, enhancing exploratory analysis, and supporting hypothesis generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08331v2</guid>
      <category>q-bio.GN</category>
      <category>cs.MA</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karen Guerrero-Vazquez, Jacopo Umberto Verga, Pilib O Broin, Eva Szegezdi, Katarzyna Goljanek-Whysall</dc:creator>
    </item>
    <item>
      <title>A Minimal Model for Emergent Collective Behaviors in Autonomous Robotic Multi-Agent Systems</title>
      <link>https://arxiv.org/abs/2508.08473</link>
      <description>arXiv:2508.08473v2 Announce Type: replace-cross 
Abstract: Collective behaviors such as swarming and flocking emerge from simple, decentralized interactions in biological systems. Existing models, such as Vicsek and Cucker-Smale, lack collision avoidance, whereas the Olfati-Saber model imposes rigid formations, limiting their applicability in swarm robotics. To address these limitations, this paper proposes a minimal yet expressive model that governs agent dynamics using relative positions, velocities, and local density, modulated by two tunable parameters: the spatial offset and kinetic offset. The model achieves spatially flexible, collision-free behaviors that reflect naturalistic group dynamics. Furthermore, we extend the framework to cognitive autonomous systems, enabling energy-aware phase transitions between swarming and flocking through adaptive control parameter tuning. This cognitively inspired approach offers a robust foundation for real-world applications in multi-robot systems, particularly autonomous aerial swarms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08473v2</guid>
      <category>cs.RO</category>
      <category>cs.MA</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TCDS.2025.3598690</arxiv:DOI>
      <dc:creator>Hossein B. Jond</dc:creator>
    </item>
  </channel>
</rss>
