<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 10 Jul 2024 01:37:35 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 09 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Beating Grover search for low-energy estimation and state preparation</title>
      <link>https://arxiv.org/abs/2407.03073</link>
      <description>arXiv:2407.03073v1 Announce Type: cross 
Abstract: Estimating ground state energies of many-body Hamiltonians is a central task in many areas of quantum physics. In this work, we give quantum algorithms which, given any $k$-body Hamiltonian $H$, compute an estimate for the ground state energy and prepare a quantum state achieving said energy, respectively. Specifically, for any $\varepsilon&gt;0$, our algorithms return, with high probability, an estimate of the ground state energy of $H$ within additive error $\varepsilon M$, or a quantum state with the corresponding energy. Here, $M$ is the total strength of all interaction terms, which in general is extensive in the system size. Our approach makes no assumptions about the geometry or spatial locality of interaction terms of the input Hamiltonian and thus handles even long-range or all-to-all interactions, such as in quantum chemistry, where lattice-based techniques break down. In this fully general setting, the runtime of our algorithms scales as $2^{cn/2}$ for $c&lt;1$, yielding the first quantum algorithms for low-energy estimation breaking the natural bound based on Grover search. The core of our approach is remarkably simple, and relies on showing that any $k$-body Hamiltonian has a low-energy subspace of exponential dimension.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03073v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Harry Buhrman, Sevag Gharibian, Zeph Landau, Fran\c{c}ois Le Gall, Norbert Schuch, Suguru Tamaki</dc:creator>
    </item>
    <item>
      <title>The Reachability Problem for Neural-Network Control Systems</title>
      <link>https://arxiv.org/abs/2407.04988</link>
      <description>arXiv:2407.04988v1 Announce Type: cross 
Abstract: A control system consists of a plant component and a controller which periodically computes a control input for the plant. We consider systems where the controller is implemented by a feedforward neural network with ReLU activations. The reachability problem asks, given a set of initial states, whether a set of target states can be reached. We show that this problem is undecidable even for trivial plants and fixed-depth neural networks with three inputs and outputs. We also show that the problem becomes semi-decidable when the plant as well as the input and target sets are given by automata over infinite words.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04988v1</guid>
      <category>cs.LG</category>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>AISoLA 2023</arxiv:journal_reference>
      <dc:creator>Christian Schilling, Martin Zimmermann</dc:creator>
    </item>
    <item>
      <title>Computational Complexity-Constrained Spectral Efficiency Analysis for 6G Waveforms</title>
      <link>https://arxiv.org/abs/2407.05805</link>
      <description>arXiv:2407.05805v1 Announce Type: cross 
Abstract: In this work, we present a tutorial on how to account for the computational time complexity overhead of signal processing in the spectral efficiency (SE) analysis of wireless waveforms. Our methodology is particularly relevant in scenarios where achieving higher SE entails a penalty in complexity, a common trade-off present in 6G candidate waveforms. We consider that SE derives from the data rate, which is impacted by time-dependent overheads. Thus, neglecting the computational complexity overhead in the SE analysis grants an unfair advantage to more computationally complex waveforms, as they require larger computational resources to meet a signal processing runtime below the symbol period. We demonstrate our points with two case studies. In the first, we refer to IEEE 802.11a-compliant baseband processors from the literature to show that their runtime significantly impacts the SE perceived by upper layers. In the second case study, we show that waveforms considered less efficient in terms of SE can outperform their more computationally expensive counterparts if provided with equivalent high-performance computational resources. Based on these cases, we believe our tutorial can address the comparative SE analysis of waveforms that operate under different computational resource constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05805v1</guid>
      <category>eess.SP</category>
      <category>cs.CC</category>
      <category>cs.PF</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Saulo Queiroz, Jo\~ao P. Vilela, Benjamin Koon Kei Ng, Chan-Tong Lam, Edmundo Monteiro</dc:creator>
    </item>
    <item>
      <title>Tight Quantum Depth Lower Bound for Solving Systems of Linear Equations</title>
      <link>https://arxiv.org/abs/2407.06012</link>
      <description>arXiv:2407.06012v1 Announce Type: cross 
Abstract: Since Harrow, Hassidim, and Lloyd (2009) showed that a system of linear equations with $N$ variables and condition number $\kappa$ can be solved on a quantum computer in $\operatorname{poly}(\log(N), \kappa)$ time, exponentially faster than any classical algorithms, its improvements and applications have been extensively investigated. The state-of-the-art quantum algorithm for this problem is due to Costa, An, Sanders, Su, Babbush, and Berry (2022), with optimal query complexity $\Theta(\kappa)$. An important question left is whether parallelism can bring further optimization. In this paper, we study the limitation of parallel quantum computing on this problem. We show that any quantum algorithm for solving systems of linear equations with time complexity $\operatorname{poly}(\log(N), \kappa)$ has a lower bound of $\Omega(\kappa)$ on the depth of queries, which is tight up to a constant factor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06012v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/PhysRevA.110.012422</arxiv:DOI>
      <arxiv:journal_reference>Physical Review A, 110(1): 012422, 2024</arxiv:journal_reference>
      <dc:creator>Qisheng Wang, Zhicheng Zhang</dc:creator>
    </item>
    <item>
      <title>The Low-Degree Hardness of Finding Large Independent Sets in Sparse Random Hypergraphs</title>
      <link>https://arxiv.org/abs/2404.03842</link>
      <description>arXiv:2404.03842v2 Announce Type: replace 
Abstract: We study the algorithmic task of finding large independent sets in Erdos-Renyi $r$-uniform hypergraphs on $n$ vertices having average degree $d$. Krivelevich and Sudakov showed that the maximum independent set has density $\left(\frac{r\log d}{(r-1)d}\right)^{1/(r-1)}$. We show that the class of low-degree polynomial algorithms can find independent sets of density $\left(\frac{\log d}{(r-1)d}\right)^{1/(r-1)}$ but no larger. This extends and generalizes earlier results of Gamarnik and Sudan, Rahman and Virag, and Wein on graphs, and answers a question of Bal and Bennett. We conjecture that this statistical-computational gap holds for this problem.
  Additionally, we explore the universality of this gap by examining $r$-partite hypergraphs. A hypergraph $H=(V,E)$ is $r$-partite if there is a partition $V=V_1\cup\cdots\cup V_r$ such that each edge contains exactly one vertex from each set $V_i$. We consider the problem of finding large balanced independent sets (independent sets containing the same number of vertices in each partition) in random $r$-partite hypergraphs with $n$ vertices in each partition and average degree $d$. We prove that the maximum balanced independent set has density $\left(\frac{r\log d}{(r-1)d}\right)^{1/(r-1)}$ asymptotically. Furthermore, we prove an analogous low-degree computational threshold of $\left(\frac{\log d}{(r-1)d}\right)^{1/(r-1)}$. Our results recover and generalize recent work of Perkins and the second author on bipartite graphs.
  While the graph case has been extensively studied, this work is the first to consider statistical-computational gaps of optimization problems on random hypergraphs. Our results suggest that these gaps persist for larger uniformities as well as across many models. A somewhat surprising aspect of the gap for balanced independent sets is that the algorithm achieving the lower bound is a simple degree-1 polynomial.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03842v2</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abhishek Dhawan, Yuzhou Wang</dc:creator>
    </item>
    <item>
      <title>Partitioning Problems with Splittings and Interval Targets</title>
      <link>https://arxiv.org/abs/2204.11753</link>
      <description>arXiv:2204.11753v4 Announce Type: replace-cross 
Abstract: The $n$-way number partitioning problem is a classic problem in combinatorial optimization, with applications to diverse settings such as fair allocation and machine scheduling. All these problems are NP-hard, but various approximation algorithms are known. We consider three closely related kinds of approximations.
  The first two variants optimize the partition such that: in the first variant some fixed number $s$ of items can be \emph{split} between two or more bins and in the second variant we allow at most a fixed number $t$ of \emph{splittings}. The third variant is a decision problem: the largest bin sum must be within a pre-specified interval, parameterized by a fixed rational number $u$ times the largest item size.
  When the number of bins $n$ is unbounded, we show that every variant is strongly {\sf NP}-complete. When the number of bins $n$ is fixed, the running time depends on the fixed parameters $s,t,u$. For each variant, we give a complete picture of its running time.
  For $n=2$, the running time is easy to identify. Our main results consider any fixed integer $n \geq 3$. Using a two-way polynomial-time reduction between the first and the third variant, we show that $n$-way number-partitioning with $s$ split items can be solved in polynomial time if $s \geq n-2$, and it is {\sf NP}-complete otherwise. Also, $n$-way number-partitioning with $t$ splittings can be solved in polynomial time if $t \geq n-1$, and it is {\sf NP}-complete otherwise. Finally, we show that the third variant can be solved in polynomial time if $u \geq (n-2)/n$, and it is {\sf NP}-complete otherwise. Our positive results for the optimization problems consider both min-max and max-min versions.
  Using the same reduction, and we provide a fully polynomial-time approximation scheme for the case where the number of split items is lower than $n-2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2204.11753v4</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samuel Bismuth, Vladislav Makarov, Erel Segal-Halevi, Dana Shapira</dc:creator>
    </item>
    <item>
      <title>Quantum Multiplier Based on Exponent Adder</title>
      <link>https://arxiv.org/abs/2309.10204</link>
      <description>arXiv:2309.10204v3 Announce Type: replace-cross 
Abstract: Quantum multiplication is a fundamental operation in quantum computing. It is important to have a quantum multiplier with low complexity. In this paper, we propose the Quantum Multiplier Based on Exponent Adder (QMbead), a new approach that requires just $\log_2(n)$ qubits to multiply two $n$-bit integer numbers, in addition to $O(n)$ ancillary qubits used for quantum state preparation. The QMbead uses a so-called exponent encoding to respectively represent two multiplicands as two superposition states which are prepared by a quantum state preparation method, then employs a quantum adder to obtain the sum of these two superposition states, and subsequently measures the outputs of the quantum adder to calculate the product of the multiplicands. Different quantum adders can be used in the QMbead. The circuit depth and time complexity of the QMbead, using a logarithmic-depth quantum carry lookahead adder (QCLA) as adder, are $O(\log n)$ and $O(n \log n)$, respectively. The gate complexity of the QMbead is $O(n)$. The circuit depth and gate complexity of the QMbead is better than existing quantum multipliers such as the quantum Karatsuba multiplier and the QFT based multiplier. The time complexity of the QMbead is identical to that of the fastest classical multiplication algorithm, Harvey-Hoeven algorithm. Interestingly, the QMbead maintains an advantage over the Harvey-Hoeven algorithm, given that the latter is only suitable for excessively large numbers, whereas the QMbead is valid for both small and large numbers. The multiplicand can be either an integer or a decimal number. The QMbead has been implemented on quantum simulators to compute products with a bit length of up to 273 bits using only 17 qubits, excluding the ancillary qubits used for quantum state preparation. This establishes QMbead as an efficient solution for multiplying large integer or decimal numbers with many bits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.10204v3</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.CR</category>
      <category>math.QA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junpeng Zhan</dc:creator>
    </item>
  </channel>
</rss>
