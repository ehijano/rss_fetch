<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 17 Dec 2025 02:37:55 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>VeBPF Many-Core Architecture for Network Functions in FPGA-based SmartNICs and IoT</title>
      <link>https://arxiv.org/abs/2512.12778</link>
      <description>arXiv:2512.12778v1 Announce Type: new 
Abstract: FPGA-based SmartNICs and IoT devices integrating soft-processors for network function execution have emerged to address the limited hardware reconfigurability of DPUs and MCUs. However, existing FPGA-based solutions lack a highly configurable many-core architecture specialized for network packet processing. This work presents VeBPF many-core architecture, a resource-optimized and highly configurable many-core architecture composed of custom VeBPF (Verilog eBPF) CPU cores designed for FPGA-based packet processing. The VeBPF cores are eBPF ISA compliant and implemented in Verilog HDL for seamless integration with existing FPGA IP blocks and subsystems.
  The proposed many-core architecture enables parallel execution of multiple eBPF rules across multiple VeBPF cores, achieving low-latency packet processing. The architecture is fully parameterizable, allowing the number of VeBPF cores and eBPF rules to scale according to application requirements and available FPGA resources. eBPF rules can be dynamically updated at run time without requiring FPGA reconfiguration, enabling flexible and adaptive network processing.
  The design incorporates hardware and computer architecture optimizations that support deployment across a wide range of platforms, from low-end FPGA-based IoT devices to high-end FPGA-based SmartNICs. In addition, we present automated testing and simulation frameworks developed using open-source tools such as Python and Cocotb. The VeBPF cores, many-core architecture, control software libraries, and simulation infrastructure are released as open source to support further research in FPGA-based many-core systems, eBPF acceleration, SmartNICs, IoT, and network security.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.12778v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/HPEC62836.2024.10938505</arxiv:DOI>
      <dc:creator>Zaid Tahir, Ahmed Sanaullah, Sahan Bandara, Ulrich Drepper, Martin Herbordt</dc:creator>
    </item>
    <item>
      <title>OptiWing3D: A Diverse Dataset of Optimized Wing Designs</title>
      <link>https://arxiv.org/abs/2512.12867</link>
      <description>arXiv:2512.12867v1 Announce Type: new 
Abstract: OptiWing3D is the first publicly available dataset of high-fidelity shape optimized 3D wing geometries. Existing aerodynamics datasets are either limited to 2D simulations, lack optimization, or derive diversity solely from perturbations to a single baseline design, constraining their application as benchmarks to inverse design approaches and in the study of design diversity. The OptiWing3D dataset addresses these gaps, consisting of 1552 simulations resulting in 776 wing designs initialized from distinct extruded airfoil cross-sections. Additionally, a majority of the optimized wings in the dataset are paired to 2D counterparts optimized under identical conditions, creating the first multi-fidelity aerodynamic shape optimization dataset. Moreover, this structure allows for a direct comparison between 2D and 3D aerodynamic simulations. It is observed that 3D optimized designs diverge most prominently from the 2D-optimized designs near the wingtip, where three-dimensional effects are strongest, a finding made possible by the paired nature of the dataset. Finally, we demonstrate a constraint-aware conditional latent diffusion model capable of generating optimized wings from flow conditions, establishing a baseline for future inverse design approaches. The dataset, containing wing geometries and surface pressure distributions is publicly released to advance research in data-driven aerodynamic design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.12867v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cashen Diniz, Mark D. Fuge</dc:creator>
    </item>
    <item>
      <title>ERA-IT: Aligning Semantic Models with Revealed Economic Preference for Real-Time and Explainable Patent Valuation</title>
      <link>https://arxiv.org/abs/2512.12869</link>
      <description>arXiv:2512.12869v1 Announce Type: new 
Abstract: Valuing intangible assets under uncertainty remains a critical challenge in the strategic management of technological innovation due to the information asymmetry inherent in high-dimensional technical specifications. Traditional bibliometric indicators, such as citation counts, fail to address this friction in a timely manner due to the systemic latency inherent in data accumulation. To bridge this gap, this study proposes the Economic Reasoning Alignment via Instruction Tuning (ERA-IT) framework. We theoretically conceptualize patent renewal history as a revealed economic preference and leverage it as an objective supervisory signal to align the generative reasoning of Large Language Models (LLMs) with market realities, a process we term Eco-Semantic Alignment. Using a randomly sampled dataset of 10,000 European Patent Office patents across diverse technological domains, we trained the model not only to predict value tiers but also to reverse-engineer the Economic Chain-of-Thought from unstructured text. Empirical results demonstrate that ERA-IT significantly outperforms both conventional econometric models and zero-shot LLMs in predictive accuracy. More importantly, by generating explicit, logically grounded rationales for valuation, the framework serves as a transparent cognitive scaffold for decision-makers, reducing the opacity of black-box AI in high-stakes intellectual property management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.12869v1</guid>
      <category>cs.CE</category>
      <category>cs.CL</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yoo Yongmin, Kim Seungwoo, Liu Jingjiang</dc:creator>
    </item>
    <item>
      <title>On the impact of geometric variance on the performance of formed parts: A probabilistic approach on the example of airbag pressure bins</title>
      <link>https://arxiv.org/abs/2512.13302</link>
      <description>arXiv:2512.13302v1 Announce Type: new 
Abstract: Scatter in properties resulting from manufacturing is a great challenge in lightweight design, requiring consideration of not only the average mechanical performance but also the variance which is done e.g., by conservative safety factors. One contributor to this variance is the inherent geometric variability in the formed part. To isolate and quantify this effect, we present a probabilistic numerical study, aiming to assess the impact of geometric variance on the resulting part performance. By modelling geometric deviations stochastically, we aim to establish a correlation between the variance in geometry with the resulting variance in performance. The study is done on the example of an airbag pressure bin, where a better understanding of this correlation is crucial, as it allows for the design of a lighter part without changing the manufacturing process. Instead, we aim to implement more targeted and effective quality assurance, informed by the performance impact of geometric deviations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13302v1</guid>
      <category>cs.CE</category>
      <category>physics.app-ph</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Lukas Schnelle, Niklas Fehlemann, Ali O. M. Kilicsoy, Niklas Bechler, Marcos A. Valdebenito, Yannis P. Korkolis, Matthias G. R. Faes, Sebastian M\"unstermann, Kai-Uwe Schr\"oder</dc:creator>
    </item>
    <item>
      <title>Hot H\'em: S\`ai G\`on Gi\~ua C\'ai N\'ong H\^ong C\`ong B\`ang -- Saigon in Unequal Heat</title>
      <link>https://arxiv.org/abs/2512.11896</link>
      <description>arXiv:2512.11896v1 Announce Type: cross 
Abstract: Pedestrian heat exposure is a critical health risk in dense tropical cities, yet standard routing algorithms often ignore micro-scale thermal variation. Hot H\'em is a GeoAI workflow that estimates and operationalizes pedestrian heat exposure in H\^o Ch\'i Minh City (HCMC), Vi\d{e}t Nam, colloquially known as S\`ai G\`on. This spatial data science pipeline combines Google Street View (GSV) imagery, semantic image segmentation, and remote sensing. Two XGBoost models are trained to predict land surface temperature (LST) using a GSV training dataset in selected administrative wards, known as ph\u{o}ng, and are deployed in a patchwork manner across all OSMnx-derived pedestrian network nodes to enable heat-aware routing. This is a model that, when deployed, can provide a foundation for pinpointing where and further understanding why certain city corridors may experience disproportionately higher temperatures at an infrastructural scale.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11896v1</guid>
      <category>cs.CV</category>
      <category>cs.CE</category>
      <category>cs.CY</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tessa Vu</dc:creator>
    </item>
    <item>
      <title>The Agentic Regulator: Risks for AI in Finance and a Proposed Agent-based Framework for Governance</title>
      <link>https://arxiv.org/abs/2512.11933</link>
      <description>arXiv:2512.11933v1 Announce Type: cross 
Abstract: Generative and agentic artificial intelligence is entering financial markets faster than existing governance can adapt. Current model-risk frameworks assume static, well-specified algorithms and one-time validations; large language models and multi-agent trading systems violate those assumptions by learning continuously, exchanging latent signals, and exhibiting emergent behavior. Drawing on complex adaptive systems theory, we model these technologies as decentralized ensembles whose risks propagate along multiple time-scales. We then propose a modular governance architecture. The framework decomposes oversight into four layers of "regulatory blocks": (i) self-regulation modules embedded beside each model, (ii) firm-level governance blocks that aggregate local telemetry and enforce policy, (iii) regulator-hosted agents that monitor sector-wide indicators for collusive or destabilizing patterns, and (iv) independent audit blocks that supply third-party assurance. Eight design strategies enable the blocks to evolve as fast as the models they police. A case study on emergent spoofing in multi-agent trading shows how the layered controls quarantine harmful behavior in real time while preserving innovation. The architecture remains compatible with today's model-risk rules yet closes critical observability and control gaps, providing a practical path toward resilient, adaptive AI governance in financial systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11933v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.MA</category>
      <category>q-fin.GN</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eren Kurshan, Tucker Balch, David Byrd</dc:creator>
    </item>
    <item>
      <title>EXFormer: A Multi-Scale Trend-Aware Transformer with Dynamic Variable Selection for Foreign Exchange Returns Prediction</title>
      <link>https://arxiv.org/abs/2512.12727</link>
      <description>arXiv:2512.12727v1 Announce Type: cross 
Abstract: Accurately forecasting daily exchange rate returns represents a longstanding challenge in international finance, as the exchange rate returns are driven by a multitude of correlated market factors and exhibit high-frequency fluctuations. This paper proposes EXFormer, a novel Transformer-based architecture specifically designed for forecasting the daily exchange rate returns. We introduce a multi-scale trend-aware self-attention mechanism that employs parallel convolutional branches with differing receptive fields to align observations on the basis of local slopes, preserving long-range dependencies while remaining sensitive to regime shifts. A dynamic variable selector assigns time-varying importance weights to 28 exogenous covariates related to exchange rate returns, providing pre-hoc interpretability. An embedded squeeze-and-excitation block recalibrates channel responses to emphasize informative features and depress noise in the forecasting. Using the daily data for EUR/USD, USD/JPY, and GBP/USD, we conduct out-of-sample evaluations across five different sliding windows. EXFormer consistently outperforms the random walk and other baselines, improving directional accuracy by a statistically significant margin of up to 8.5--22.8%. In nearly one year of trading backtests, the model converts these gains into cumulative returns of 18%, 25%, and 18% for the three pairs, with Sharpe ratios exceeding 1.8. When conservative transaction costs and slippage are accounted for, EXFormer retains cumulative returns of 7%, 19%, and 9%, while other baselines achieve negative. The robustness checks further confirm the model's superiority under high-volatility and bear-market regimes. EXFormer furnishes both economically valuable forecasts and transparent, time-varying insights into the drivers of exchange rate dynamics for international investors, corporations, and central bank practitioners.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.12727v1</guid>
      <category>q-fin.CP</category>
      <category>cs.CE</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dinggao Liu, Robert \'Slepaczuk, Zhenpeng Tang</dc:creator>
    </item>
    <item>
      <title>Investigating Data Pruning for Pretraining Biological Foundation Models at Scale</title>
      <link>https://arxiv.org/abs/2512.12932</link>
      <description>arXiv:2512.12932v1 Announce Type: cross 
Abstract: Biological foundation models (BioFMs), pretrained on large-scale biological sequences, have recently shown strong potential in providing meaningful representations for diverse downstream bioinformatics tasks. However, such models often rely on millions to billions of training sequences and billions of parameters, resulting in prohibitive computational costs and significant barriers to reproducibility and accessibility, particularly for academic labs. To address these challenges, we investigate the feasibility of data pruning for BioFM pretraining and propose a post-hoc influence-guided data pruning framework tailored to biological domains. Our approach introduces a subset-based self-influence formulation that enables efficient estimation of sample importance at low computational cost, and builds upon it two simple yet effective selection strategies, namely Top-k Influence (Top I) and Coverage-Centric Influence (CCI). We empirically validate our method on two representative BioFMs, RNA-FM and ESM-C. For RNA, our framework consistently outperforms random selection baselines under an extreme pruning rate of over 99 percent, demonstrating its effectiveness. Furthermore, we show the generalizability of our framework on protein-related tasks using ESM-C. In particular, our coreset even outperforms random subsets that are ten times larger in both RNA and protein settings, revealing substantial redundancy in biological sequence datasets. These findings underscore the potential of influence-guided data pruning to substantially reduce the computational cost of BioFM pretraining, paving the way for more efficient, accessible, and sustainable biological AI research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.12932v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yifan Wu, Jiyue Jiang, Xichen Ye, Yiqi Wang, Chang Zhou, Yitao Xu, Jiayang Chen, He Hu, Weizhong Zhang, Cheng Jin, Jiao Yuan, Yu Li</dc:creator>
    </item>
    <item>
      <title>On the Complementarity of Shared Electric Mobility and Renewable Energy Communities</title>
      <link>https://arxiv.org/abs/2512.13099</link>
      <description>arXiv:2512.13099v1 Announce Type: cross 
Abstract: Driven by the ongoing energy transition, shared mobility service providers are emerging actors in electrical power systems which aim to shift combustion-based mobility to electric paradigm. In the meantime, Energy Communities are deployed to enhance the local usage of distributed renewable production. As both ators share the same goal of satisfying the demand at the lowest cost, they could take advantage of their complementarity and coordinate their decisions to enhance each other operation. This paper presents an original Mixed-Integer Second Order Cone Programming long-term Electric Vehicle fleet planning optimization problem that integrates the coordination with a Renewable Energy Community and Vehicle-to-Grid capability. This model is used to assess the economic, energy, and grid performances of their collaboration in a 21 buses low-voltage distribution network. Key results show that, both actors coordination can help reducing the yearly cost up to 11.3 % compared to their stand-alone situation and that it may reduce the stress on the substation transformer by 46 % through the activation of the inherent EVs flexibility when subject to peak penalties from the grid operator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13099v1</guid>
      <category>eess.SY</category>
      <category>cs.CE</category>
      <category>cs.SY</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julien Allard, No\'e Diffels, Fran\c{c}ois Vall\'ee, Bertrand Corn\'elusse, Zacharie De Gr\`eve</dc:creator>
    </item>
    <item>
      <title>Finch: Benchmarking Finance &amp; Accounting across Spreadsheet-Centric Enterprise Workflows</title>
      <link>https://arxiv.org/abs/2512.13168</link>
      <description>arXiv:2512.13168v1 Announce Type: cross 
Abstract: We introduce a finance &amp; accounting benchmark (Finch) for evaluating AI agents on real-world, enterprise-grade professional workflows -- interleaving data entry, structuring, formatting, web search, cross-file retrieval, calculation, modeling, validation, translation, visualization, and reporting. Finch is sourced from authentic enterprise workspaces at Enron (15,000 spreadsheets and 500,000 emails from 150 employees) and other financial institutions, preserving in-the-wild messiness across multimodal artifacts (text, tables, formulas, charts, code, and images) and spanning diverse domains such as budgeting, trading, and asset management.
  We propose a workflow construction process that combines LLM-assisted discovery with expert annotation: (1) LLM-assisted, expert-verified derivation of workflows from real-world email threads and version histories of spreadsheet files, and (2) meticulous expert annotation for workflows, requiring over 700 hours of domain-expert effort. This yields 172 composite workflows with 384 tasks, involving 1,710 spreadsheets with 27 million cells, along with PDFs and other artifacts, capturing the intrinsically messy, long-horizon, knowledge-intensive, and collaborative nature of real-world enterprise work.
  We conduct both human and automated evaluations of frontier AI systems including GPT 5.1, Claude Sonnet 4.5, Gemini 3 Pro, Grok 4, and Qwen 3 Max, and GPT 5.1 Pro spends 48 hours in total yet passes only 38.4% of workflows, while Claude Sonnet 4.5 passes just 25.0%. Comprehensive case studies further surface the challenges that real-world enterprise workflows pose for AI agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13168v1</guid>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.IR</category>
      <category>cs.MA</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haoyu Dong, Pengkun Zhang, Yan Gao, Xuanyu Dong, Yilin Cheng, Mingzhe Lu, Adina Yakefu, Shuxin Zheng</dc:creator>
    </item>
    <item>
      <title>Preconditioning Techniques for Hybridizable Discontinuous Galerkin Discretizations on GPU Architectures</title>
      <link>https://arxiv.org/abs/2512.13619</link>
      <description>arXiv:2512.13619v1 Announce Type: cross 
Abstract: We present scalable iterative solvers and preconditioning strategies for Hybridizable Discontinuous Galerkin (HDG) discretizations of partial differential equations (PDEs) on graphics processing units (GPUs). The HDG method is implemented using GPU-tailored algorithms in which local element degrees of freedom are eliminated in parallel, and the globally condensed system is assembled directly on the device using dense-block operations. The global matrix is stored in a block format that reflects the natural HDG structure, enabling all iterative solver kernels to be executed with strided batched dense matrix-vector multiplications. This implementation avoids sparse data structures, increases arithmetic intensity, and sustains high memory throughput across a range of meshes and polynomial orders. The nonlinear solver combines Newton's method with preconditioned GMRES, integrating scalable preconditioners such as block-Jacobi, additive Schwarz domain decomposition, and polynomial smoothers. All preconditioners are implemented in batched form with architecture-aware optimizations--including dense linear algebra kernels, memory-coalesced vector operations, and shared-memory acceleration--to minimize memory traffic and maximize parallel occupancy. Comprehensive studies are conducted for a variety of PDEs (including Poisson equation, Burgers equation, linear and nonlinear elasticity, Euler equations, Navier-Stokes equations, and Reynolds-Averaged Navier-Stokes equations) using structured and unstructured meshes with different element types and polynomial orders on both NVIDIA and AMD GPU architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13619v1</guid>
      <category>math.NA</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew Welter, Ngoc Cuong Nguyen</dc:creator>
    </item>
    <item>
      <title>Human Mobility Reimagined: Digital Twin Intelligence for Adaptive Campus Course Timetabling</title>
      <link>https://arxiv.org/abs/2503.06109</link>
      <description>arXiv:2503.06109v2 Announce Type: replace 
Abstract: Daily operations in large campuses depend on how efficiently people \emph{move} through space and time. In this sense, course timetables are more than administrative schedules: they act as mobility policies that orchestrate thousands of trajectories, shaping travel burden, congestion, accessibility, and the reliability of back-to-back transitions. Designing timetables that are both feasible and mobility-friendly is challenging because hard constraints including capacity, conflicts, feasibility must be satisfied alongside soft constraints including preferences, satisfaction, coordination, all under dynamic conditions such as real-time disruptions and evolving demand. Traditional static optimization methods often struggle to capture these human mobility impacts and to adapt when campus conditions change. This paper reconceptualizes course timetabling as a recommendation-based task and leverages the Texas A\&amp;M Campus Digital Twin as a dynamic data platform to evaluate mobility consequences at scale. We propose an iterative framework that integrates collaborative and content-based filtering with feedback-driven refinement to generate ranked sets of adaptive timetable recommendations. A mobility-aware composite scoring function combining classroom occupancy, travel distance, travel time, and vertical transitions systematically balances resource efficiency with human-centered movement costs. Extensive experiments using real-world data from Texas A\&amp;M University show that the proposed approach reduces mobility friction and travel inefficiencies, improves classroom utilization, and enhances overall user satisfaction. By coupling recommendation-oriented decision-making with digital twin intelligence, this study provides a robust and scalable blueprint for mobility-centered campus planning and resource allocation, with potential extensions to broader urban systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06109v2</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Keshu Wu, Xinyue Ye, Suphanut Jamonnak, Xin Feng</dc:creator>
    </item>
    <item>
      <title>Integrated Prediction and Multi-period Portfolio Optimization</title>
      <link>https://arxiv.org/abs/2512.11273</link>
      <description>arXiv:2512.11273v2 Announce Type: replace 
Abstract: Multi-period portfolio optimization is important for real portfolio management, as it accounts for transaction costs, path-dependent risks, and the intertemporal structure of trading decisions that single-period models cannot capture. Classical methods usually follow a two-stage framework: machine learning algorithms are employed to produce forecasts that closely fit the realized returns, and the predicted values are then used in a downstream portfolio optimization problem to determine the asset weights. This separation leads to a fundamental misalignment between predictions and decision outcomes, while also ignoring the impact of transaction costs. To bridge this gap, recent studies have proposed the idea of end-to-end learning, integrating the two stages into a single pipeline. This paper introduces IPMO (Integrated Prediction and Multi-period Portfolio Optimization), a model for multi-period mean-variance portfolio optimization with turnover penalties. The predictor generates multi-period return forecasts that parameterize a differentiable convex optimization layer, which in turn drives learning via portfolio performance. For scalability, we introduce a mirror-descent fixed-point (MDFP) differentiation scheme that avoids factorizing the Karush-Kuhn-Tucker (KKT) systems, which thus yields stable implicit gradients and nearly scale-insensitive runtime as the decision horizon grows. In experiments with real market data and two representative time-series prediction models, the IPMO method consistently outperforms the two-stage benchmarks in risk-adjusted performance net of transaction costs and achieves more coherent allocation paths. Our results show that integrating machine learning prediction with optimization in the multi-period setting improves financial outcomes and remains computationally tractable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11273v2</guid>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuxuan Linghu, Zhiyuan Liu, Qi Deng</dc:creator>
    </item>
    <item>
      <title>OmniScientist: Toward a Co-evolving Ecosystem of Human and AI Scientists</title>
      <link>https://arxiv.org/abs/2511.16931</link>
      <description>arXiv:2511.16931v2 Announce Type: replace-cross 
Abstract: With the rapid development of Large Language Models (LLMs), AI agents have demonstrated increasing proficiency in scientific tasks, ranging from hypothesis generation and experimental design to manuscript writing. Such agent systems are commonly referred to as "AI Scientists." However, existing AI Scientists predominantly formulate scientific discovery as a standalone search or optimization problem, overlooking the fact that scientific research is inherently a social and collaborative endeavor. Real-world science relies on a complex scientific infrastructure composed of collaborative mechanisms, contribution attribution, peer review, and structured scientific knowledge networks. Due to the lack of modeling for these critical dimensions, current systems struggle to establish a genuine research ecosystem or interact deeply with the human scientific community. To bridge this gap, we introduce OmniScientist, a framework that explicitly encodes the underlying mechanisms of human research into the AI scientific workflow. OmniScientist not only achieves end-to-end automation across data foundation, literature review, research ideation, experiment automation, scientific writing, and peer review, but also provides comprehensive infrastructural support by simulating the human scientific system, comprising: (1) a structured knowledge system built upon citation networks and conceptual correlations; (2) a collaborative research protocol (OSP), which enables seamless multi-agent collaboration and human researcher participation; and (3) an open evaluation platform (ScienceArena) based on blind pairwise user voting and Elo rankings. This infrastructure empowers agents to not only comprehend and leverage human knowledge systems but also to collaborate and co-evolve, fostering a sustainable and scalable innovation ecosystem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16931v2</guid>
      <category>cs.CY</category>
      <category>cs.CE</category>
      <category>cs.CL</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenyang Shao, Dehao Huang, Yu Li, Keyu Zhao, Weiquan Lin, Yining Zhang, Qingbin Zeng, Zhiyu Chen, Tianxing Li, Yifei Huang, Taozhong Wu, Xinyang Liu, Ruotong Zhao, Mengsheng Zhao, Jiaoyang Li, Xuhua Zhang, Yue Wang, Yuanyi Zhen, Fengli Xu, Yong Li, Tie-Yan Liu</dc:creator>
    </item>
    <item>
      <title>AI-Assisted Game Management Decisions: A Fuzzy Logic Approach to Real-Time Soccer Substitutions</title>
      <link>https://arxiv.org/abs/2512.04480</link>
      <description>arXiv:2512.04480v3 Announce Type: replace-cross 
Abstract: In elite soccer, substitution decisions entail significant financial and sporting consequences yet remain heavily reliant on intuition or predictive models that merely mimic historical biases. This paper introduces a Fuzzy Logic based Decision Support System (DSS) designed for real time, prescriptive game management. Unlike traditional Machine Learning approaches that encounter a predictive ceiling by attempting to replicate human behavior, our system audits performance through an objective, rule based inference engine. We propose a methodological advancement by reformulating the PlayeRank metric into a Cumulative Mean with Role Aware Normalization, eliminating the play time exposure bias inherent in cumulative sum models to enable accurate intra match comparison. The system integrates this refined metric with physiological proxies (fatigue) and contextual variables (disciplinary risk modulated by tactical role) to calculate a dynamic Substitution Priority (P final). Validation via a case study of the 2018 FIFA World Cup match between Brazil and Belgium demonstrates the system's ecological validity: it not only aligned with expert consensus on executed substitutions (for example Gabriel Jesus) but, crucially, identified high risk scenarios ignored by human decision makers. Specifically, the model flagged the "FAGNER Paradox" - a maximum priority defensive risk - minutes before a critical yellow card, and detected the "Lukaku Paradox", where an isolated assist masked a severe drop in participation. These results confirm that Fuzzy Logic offers a transparent, explainable, and superior alternative to black box models for optimizing real time tactical decisions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04480v3</guid>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Pedro Passos</dc:creator>
    </item>
  </channel>
</rss>
