<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 05 May 2025 04:00:29 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Quantum Measurement, Entanglement and the Warping Mechanism of Human Perception</title>
      <link>https://arxiv.org/abs/2505.00777</link>
      <description>arXiv:2505.00777v1 Announce Type: new 
Abstract: We prove that the quantum measurement process contains the same warping mechanism that occurs in categorical perception, a phenomenon ubiquitous in human perception. This warping causes stimuli belonging to the same category to be perceived as more similar, while stimuli belonging to different categories are perceived as more different. As a result of a detailed study of the quantum measurement using the Bloch representation, we identify the natural metric for pure states, namely the Fubini Study metric, and the natural metric for density states, namely the trace class metric. The warping mechanism of categorical perception is then manifested, when the distances between pure states, playing the role of stimuli for the quantum measurement, are warped into the distances between density states, playing the role of percepts for quantum measurement. We work out the example of a two-dimensional quantum model, a qubit, with 'light' and 'dark' as the two eigenstates, and show how the typical contraction and dilation warping of human perception manifest themselves in this example of the quantum measurement model of light and dark.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00777v1</guid>
      <category>q-bio.NC</category>
      <category>quant-ph</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Diederik Aerts, Jonito Aerts Argu\"elles, Sandro Sozzo</dc:creator>
    </item>
    <item>
      <title>Low-dimensional representation of brain networks for seizure risk forecasting</title>
      <link>https://arxiv.org/abs/2505.00856</link>
      <description>arXiv:2505.00856v1 Announce Type: new 
Abstract: Identifying preictal states -- periods during which seizures are more likely to occur -- remains a central challenge in clinical computational neuroscience. In this study, we introduce a novel framework that embeds functional brain connectivity networks, derived from intracranial EEG (iEEG) recordings, into a low-dimensional Euclidean space. This compact representation captures essential topological features of brain dynamics and facilitates the detection of subtle connectivity changes preceding seizures. Using standard machine learning techniques, we define a dimensionless biomarker, $\mathcal{B}$, that discriminates between interictal (seizure-free) and preictal (within 24 hours of seizure) network states. Our method focuses on connectivity patterns among a subset of informative iEEG electrodes, enabling robust classification of brain states across time. We validate our approach using a leave-one-out cross-validation scheme and a pseudo-prospective forecasting strategy, assessing performance with metrics such as F1-score and balanced accuracy. Results show that low-dimensional Euclidean embeddings of iEEG connectivity yield interpretable and predictive markers of preictal activity, offering promising implications for real-time seizure forecasting and individualized therapeutic interventions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00856v1</guid>
      <category>q-bio.NC</category>
      <category>physics.data-an</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Steven Rico-Aparicio, Martin Guillemaud, Alice Longhena, Vincent Navarro, Louis Cousyn, Mario Chavez</dc:creator>
    </item>
    <item>
      <title>Models of attractor dynamics in the brain</title>
      <link>https://arxiv.org/abs/2505.01098</link>
      <description>arXiv:2505.01098v1 Announce Type: new 
Abstract: Attractor dynamics are a fundamental computational motif in neural circuits, supporting diverse cognitive functions through stable, self-sustaining patterns of neural activity. In these lecture notes, we review four key examples that demonstrate how autoassociative neural network models can elucidate the computational mechanisms underlying attractor-based information processing in biological neural systems performing cognitive functions. Drawing on empirical evidence, we explore hippocampal spatial representations, visual classification in the inferotemporal cortex, perceptual adaptation and priming, and working-memory biases shaped by sensory history. Across these domains, attractor network models reveal common computational principles and provide analytical insights into how experience shapes neural activity and behavior. Our synthesis underscores the value of attractor models as powerful tools for probing the neural basis of cognition and behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01098v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tala Fakhoury, Elia Turner, Sushrut Thorat, Athena Akrami</dc:creator>
    </item>
    <item>
      <title>A flexible Bayesian non-parametric mixture model reveals multiple dependencies of swap errors in visual working memory</title>
      <link>https://arxiv.org/abs/2505.01178</link>
      <description>arXiv:2505.01178v1 Announce Type: new 
Abstract: Human behavioural data in psychophysics has been used to elucidate the underlying mechanisms of many cognitive processes, such as attention, sensorimotor integration, and perceptual decision making. Visual working memory has particularly benefited from this approach: analyses of VWM errors have proven crucial for understanding VWM capacity and coding schemes, in turn constraining neural models of both. One poorly understood class of VWM errors are swap errors, whereby participants recall an uncued item from memory. Swap errors could arise from erroneous memory encoding, noisy storage, or errors at retrieval time - previous research has mostly implicated the latter two. However, these studies made strong a priori assumptions on the detailed mechanisms and/or parametric form of errors contributed by these sources. Here, we pursue a data-driven approach instead, introducing a Bayesian non-parametric mixture model of swap errors (BNS) which provides a flexible descriptive model of swapping behaviour, such that swaps are allowed to depend on both the probed and reported features of every stimulus item. We fit BNS to the trial-by-trial behaviour of human participants and show that it recapitulates the strong dependence of swaps on cue similarity in multiple datasets. Critically, BNS reveals that this dependence coexists with a non-monotonic modulation in the report feature dimension for a random dot motion direction-cued, location-reported dataset. The form of the modulation inferred by BNS opens new questions about the importance of memory encoding in causing swap errors in VWM, a distinct source to the previously suggested binding and cueing errors. Our analyses, combining qualitative comparisons of the highly interpretable BNS parameter structure with rigorous quantitative model comparison and recovery methods, show that previous interpretations of swap errors may have been incomplete.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01178v1</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Puria Radmard, Paul M. Bays, M\'at\'e Lengyel</dc:creator>
    </item>
    <item>
      <title>YARE-GAN: Yet Another Resting State EEG-GAN</title>
      <link>https://arxiv.org/abs/2503.02636</link>
      <description>arXiv:2503.02636v2 Announce Type: replace 
Abstract: In this study, we implement a Wasserstein GAN with Gradient Penalty (WGAN-GP) to generate multi-channel resting-state EEG data and assess the quality of the synthesized signals through both visual and feature-based evaluations. Our results indicate that the model effectively captures the statistical and spectral characteristics of real EEG data, although challenges remain in replicating high-frequency oscillations in the frontal region. Additionally, we demonstrate that the Critic's learned representations can be reused for gender classification task, achieving an out-of-sample accuracy, significantly better than a shuffled-label baseline and a model trained directly on EEG data. These findings suggest that generative models can serve not only as EEG data generators but also as unsupervised feature extractors, reducing the need for manual feature engineering. This study highlights the potential of GAN-based unsupervised learning for EEG analysis, suggesting avenues for more data-efficient deep learning applications in neuroscience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02636v2</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Yeganeh Farahzadi, Morteza Ansarinia, Zoltan Kekecs</dc:creator>
    </item>
  </channel>
</rss>
