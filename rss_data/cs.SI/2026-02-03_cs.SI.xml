<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 03 Feb 2026 05:00:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Profit Maximization in Closed Social Networks</title>
      <link>https://arxiv.org/abs/2602.01232</link>
      <description>arXiv:2602.01232v1 Announce Type: new 
Abstract: Diffusion of information, innovation, and ideas is an important phenomenon in social networks. Information propagates through the network and reaches from one person to the next. In many settings, it is meaningful to restrict diffusion so that each node can spread information to only a limited number of its neighbors rather than to all of them. Such social networks are called closed social networks. In recent years, social media platforms have emerged as an effective medium for commercial entities, where the objective is to maximize profit. In this paper, we study the Profit Maximization in Closed Social Networks (PMCSN) problem in the context of viral marketing. The input to the problem is a closed social network and two positive integers $\ell$ and $B$. The problem asks to select seed nodes within a given budget $B$; during the diffusion process, each node is restricted to choose at most $\ell$ outgoing links for information diffusion; and the objective is to maximize the profit earned by the seed set. The PMCSN problem generalizes the Influence Maximization problem, which is NP-hard. We propose two solution approaches for PMCSN: a sampling-based approximate solution and a marginal-gain-based heuristic solution. We analyze the sample complexity, running time, and space requirements of the proposed approaches. We conduct experiments on real-world, publicly available social network datasets. The results show that the seed sets and diffusion links chosen by our methods yield higher profit than baseline methods. The implementation and data are available at \texttt{https://github.com/PoonamSharma-PY/ClosedNetwork}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01232v1</guid>
      <category>cs.SI</category>
      <category>cs.DS</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Poonam Sharma, Suman Banerjee</dc:creator>
    </item>
    <item>
      <title>DeepPM: A Deep Learning-based Profit Maximization Approach in Social Networks</title>
      <link>https://arxiv.org/abs/2602.01351</link>
      <description>arXiv:2602.01351v1 Announce Type: new 
Abstract: The problem of Profit Maximization asks to choose a limited number of influential users from a given social network such that the initial activation of these users maximizes the profit earned at the end of the diffusion process. This problem has a direct impact on viral marketing in social networks. Over the past decade, several traditional methodologies (i.e., non-learning-based, which include approximate solution, heuristic solution, etc.) have been developed, and many of them produce promising results. All these methods require the information diffusion model as input. However, it may not be realistic to consider any particular diffusion model as real-world diffusion scenarios will be much more complex and need not follow the rules for any particular diffusion model. In this paper, we propose a deep learning-based framework to solve the profit maximization problem. Our model makes a latent representation of the seed sets and is able to learn the diversified information diffusion pattern. We also design a noble objective function that can be optimized effectively using the proposed learning-based approach. The proposed model has been evaluated with the real-world datasets, and the results are reported. We compare the effectiveness of the proposed approach with many existing methods and observe that the seed set chosen by the proposed learning-based approach leads to more profit compared to existing methods. The whole implementation and the simulation code is available at: https://github.com/PoonamSharma-PY/DeepPM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01351v1</guid>
      <category>cs.SI</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Poonam Sharma, Suman Banerjee</dc:creator>
    </item>
    <item>
      <title>DREAMS: A Social Exchange Theory-Informed Modeling of Misinformation Engagement on Social Media</title>
      <link>https://arxiv.org/abs/2602.01567</link>
      <description>arXiv:2602.01567v1 Announce Type: new 
Abstract: Social media engagement prediction is a central challenge in computational social science, particularly for understanding how users interact with misinformation. Existing approaches often treat engagement as a homogeneous time-series signal, overlooking the heterogeneous social mechanisms and platform designs that shape how misinformation spreads. In this work, we ask: ``Can neural architectures discover social exchange principles from behavioral data alone?'' We introduce \textsc{Dreams} (\underline{D}isentangled \underline{R}epresentations and \underline{E}pisodic \underline{A}daptive \underline{M}odeling for \underline{S}ocial media misinformation engagements), a social exchange theory-guided framework that models misinformation engagement as a dynamic process of social exchange. Rather than treating engagement as a static outcome, \textsc{Dreams} models it as a sequence-to-sequence adaptation problem, where each action reflects an evolving negotiation between user effort and social reward conditioned by platform context. It integrates adaptive mechanisms to learn how emotional and contextual signals propagate through time and across platforms. On a cross-platform dataset spanning $7$ platforms and 2.37M posts collected between 2021 and 2025, \textsc{Dreams} achieves state-of-the-art performance in predicting misinformation engagements, reaching a mean absolute percentage error of $19.25$\%. This is a $43.6$\% improvement over the strongest baseline. Beyond predictive gains, the model reveals consistent cross-platform patterns that align with social exchange principles, suggesting that integrating behavioral theory can enhance empirical modeling of online misinformation engagement. The source code is available at: https://github.com/ltian678/DREAMS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01567v1</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3774904.3792681</arxiv:DOI>
      <dc:creator>Lin Tian, Marian-Andrei Rizoiu</dc:creator>
    </item>
    <item>
      <title>Cross-Domain Fake News Detection on Unseen Domains via LLM-Based Domain-Aware User Modeling</title>
      <link>https://arxiv.org/abs/2602.01726</link>
      <description>arXiv:2602.01726v1 Announce Type: new 
Abstract: Cross-domain fake news detection (CD-FND) transfers knowledge from a source domain to a target domain and is crucial for real-world fake news mitigation. This task becomes particularly important yet more challenging when the target domain is previously unseen (e.g., the COVID-19 outbreak or the Russia-Ukraine war). However, existing CD-FND methods overlook such scenarios and consequently suffer from the following two key limitations: (1) insufficient modeling of high-level semantics in news and user engagements; and (2) scarcity of labeled data in unseen domains. Targeting these limitations, we find that large language models (LLMs) offer strong potential for CD-FND on unseen domains, yet their effective use remains non-trivial. Nevertheless, two key challenges arise: (1) how to capture high-level semantics from both news content and user engagements using LLMs; and (2) how to make LLM-generated features more reliable and transferable for CD-FND on unseen domains. To tackle these challenges, we propose DAUD, a novel LLM-Based Domain-Aware framework for fake news detection on Unseen Domains. DAUD employs LLMs to extract high-level semantics from news content. It models users' single- and cross-domain engagements to generate domain-aware behavioral representations. In addition, DAUD captures the relations between original data-driven features and LLM-derived features of news, users, and user engagements. This allows it to extract more reliable domain-shared representations that improve knowledge transfer to unseen domains. Extensive experiments on real-world datasets demonstrate that DAUD outperforms state-of-the-art baselines in both general and unseen-domain CD-FND settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01726v1</guid>
      <category>cs.SI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xuankai Yang, Yan Wang, Jiajie Zhu, Pengfei Ding, Hongyang Liu, Xiuzhen Zhang, Huan Liu</dc:creator>
    </item>
    <item>
      <title>Twinning Complex Networked Systems: Data-Driven Calibration of the mABCD Synthetic Graph Generator</title>
      <link>https://arxiv.org/abs/2602.02044</link>
      <description>arXiv:2602.02044v1 Announce Type: new 
Abstract: The increasing availability of relational data has contributed to a growing reliance on network-based representations of complex systems. Over time, these models have evolved to capture more nuanced properties, such as the heterogeneity of relationships, leading to the concept of multilayer networks. However, the analysis and evaluation of methods for these structures is often hindered by the limited availability of large-scale empirical data. As a result, graph generators are commonly used as a workaround, albeit at the cost of introducing systematic biases. In this paper, we address the inverse-generator problem by inferring the configuration parameters of a multilayer network generator, mABCD, from a real-world system. Our goal is to identify parameter settings that enable the generator to produce synthetic networks that act as digital twins of the original structure. We propose a method for estimating matching configurations and for quantifying the associated error. Our results demonstrate that this task is non-trivial, as strong interdependencies between configuration parameters weaken independent estimation and instead favour a joint-prediction approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02044v1</guid>
      <category>cs.SI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Piotr Br\'odka, Micha{\l} Czuba, Bogumi{\l} Kami\'nski, {\L}ukasz Krai\'nski, Katarzyna Musial, Pawe{\l} Pra{\l}at, Mateusz Stolarski</dc:creator>
    </item>
    <item>
      <title>Fairness-Sensitive PageRank Approximation</title>
      <link>https://arxiv.org/abs/2602.02329</link>
      <description>arXiv:2602.02329v1 Announce Type: new 
Abstract: Real-world social networks have structural inequalities, including the majority and minorities, and fairness-agnostic centrality measures often amplify these inequalities by disproportionately favoring majority nodes. Fairness-Sensitive PageRank aims to balance algorithmic influence across structurally and demographically diverse groups while preserving the link-based relevance of classical PageRank. However, existing formulations require solving constrained matrix inversions that scale poorly with network size. In this work, we develop an efficient mean-field approximation for Fairness-Sensitive PageRank (FSPR) that enforces group-level fairness through an estimated teleportation (jump) vector, thereby avoiding the costly matrix inversion and iterative optimization. We derive a closed-form approximation of FSPR using the in-degree and group label of nodes, along with the global group proportion. We further analyze intra-class fluctuations by deriving expressions for the variance of approximated FSPR scores. Empirical results on real-world networks demonstrate that the proposed approximation efficiently estimates the FSPR while reducing runtime by an order of magnitude, enabling fairness-constrained ranking at scale.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02329v1</guid>
      <category>cs.SI</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mukesh Kumar, Gaurav Dixit, Akrati Saxena</dc:creator>
    </item>
    <item>
      <title>Front-Loaded or Balanced? The Mechanism through Which Review Order Affects Overall Ratings in Premium Service Settings</title>
      <link>https://arxiv.org/abs/2602.00008</link>
      <description>arXiv:2602.00008v1 Announce Type: cross 
Abstract: In the increasingly prevalent landscape of high-quality service contexts, whether consumer evaluation interfaces adopt a rating-first or review-first sequence has become a critical factor shaping rating authenticity and feedback quality. While prior research has primarily examined review content and sentiment, systematic investigation into how evaluation order influences rating outcomes remains limited. Through exploratory analyses, we find that Letterboxd -- which employs a review-first, rating-after mechanism -- exhibits a more centralized rating distribution with fewer extreme scores, whereas Yelp -- which adopts a rating-first, review-after mechanism -- shows a pronounced bimodal distribution with more polarized ratings. Three controlled experiments further demonstrate that in high-quality service contexts, a rating-first (vs. review-first) interface significantly elevates consumers' overall ratings. Mechanism analyses indicate that cognitive effort and affective heuristics serve as dual pathways: a rating-first (vs. review-first) sequence reduces cognitive effort and heightens affective heuristics, thereby increasing rating scores. Moreover, service quality moderates this process. When service quality is low, the rating-first (vs. review-first) sequence instead leads to lower ratings. This research reveals the psychological mechanisms through which evaluation order affects consumer ratings via cognitive and affective pathways. It extends theoretical understanding of online rating formation and offers practical implications for optimizing platform interface design to enhance rating authenticity and credibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00008v1</guid>
      <category>cs.IR</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.SI</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>He Wang, Ziyu Zhou, Hanxiang Liu</dc:creator>
    </item>
    <item>
      <title>Detecting AI-Generated Content in Academic Peer Reviews</title>
      <link>https://arxiv.org/abs/2602.00319</link>
      <description>arXiv:2602.00319v1 Announce Type: cross 
Abstract: The growing availability of large language models (LLMs) has raised questions about their role in academic peer review. This study examines the temporal emergence of AI-generated content in peer reviews by applying a detection model trained on historical reviews to later review cycles at International Conference on Learning Representations (ICLR) and Nature Communications (NC). We observe minimal detection of AI-generated content before 2022, followed by a substantial increase through 2025, with approximately 20% of ICLR reviews and 12% of Nature Communications reviews classified as AI-generated in 2025. The most pronounced growth of AI-generated reviews in NC occurs between the third and fourth quarter of 2024. Together, these findings provide suggestive evidence of a rapidly increasing presence of AI-assisted content in peer review and highlight the need for further study of its implications for scholarly evaluation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00319v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siyuan Shen, Kai Wang</dc:creator>
    </item>
    <item>
      <title>Leaves of preferential attachment trees</title>
      <link>https://arxiv.org/abs/2602.01021</link>
      <description>arXiv:2602.01021v1 Announce Type: cross 
Abstract: We provide a local probabilistic description of the limiting statistics of large preferential attachment trees in terms of the ordinary degree (number of neighbors) but augmented with information on leafdegree (number of neighbors that are leaves). The full description is the joint degree-leafdegree distribution $n_{k,\ell}$, which we derive from its associated multivariate generating function. From $n_{k,\ell}$ we obtain the leafdegree distribution, $m_{\ell}$, as well as the fraction of vertices that are protected (nonleaves with leafdegree zero) as a function of degree, $n_{k,0}$, among numerous other results. We also examine fluctuations and concentration of joint degree-leafdegree empirical counts $N_{k,\ell}$. Although our main findings pertain to the preferential attachment tree, the approach we present is highly generalizable and can characterize numerous existing models, in addition to facilitating the development of tractable new models. We further demonstrate the approach by analyzing $n_{k,\ell}$ in two other models: the random recursive tree, and a redirection-based model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01021v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Harrison Hartle, P. L. Krapivsky</dc:creator>
    </item>
    <item>
      <title>The Verification Crisis: Expert Perceptions of GenAI Disinformation and the Case for Reproducible Provenance</title>
      <link>https://arxiv.org/abs/2602.02100</link>
      <description>arXiv:2602.02100v1 Announce Type: cross 
Abstract: The growth of Generative Artificial Intelligence (GenAI) has shifted disinformation production from manual fabrication to automated, large-scale manipulation. This article presents findings from the first wave of a longitudinal expert perception survey (N=21) involving AI researchers, policymakers, and disinformation specialists. It examines the perceived severity of multimodal threats -- text, image, audio, and video -- and evaluates current mitigation strategies.
  Results indicate that while deepfake video presents immediate "shock" value, large-scale text generation poses a systemic risk of "epistemic fragmentation" and "synthetic consensus," particularly in the political domain. The survey reveals skepticism about technical detection tools, with experts favoring provenance standards and regulatory frameworks despite implementation barriers.
  GenAI disinformation research requires reproducible methods. The current challenge is measurement: without standardized benchmarks and reproducibility checklists, tracking or countering synthetic media remains difficult. We propose treating information integrity as an infrastructure with rigor in data provenance and methodological reproducibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02100v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3774905.3795484</arxiv:DOI>
      <dc:creator>Alexander Loth, Martin Kappes, Marc-Oliver Pahl</dc:creator>
    </item>
    <item>
      <title>Multilayer Horizontal Visibility Graphs for Multivariate Time Series Analysis</title>
      <link>https://arxiv.org/abs/2301.02333</link>
      <description>arXiv:2301.02333v2 Announce Type: replace 
Abstract: Multivariate time series analysis is a vital but challenging task, with multidisciplinary applicability, tackling the characterization of multiple interconnected variables over time and their dependencies. Traditional methodologies often adapt univariate approaches or rely on assumptions specific to certain domains or problems, presenting limitations. A recent promising alternative is to map multivariate time series into high-level network structures such as multiplex networks, with past work relying on connecting successive time series components with interconnections between contemporary timestamps.
  In this work, we first define a novel cross-horizontal visibility mapping between lagged timestamps of different time series and then introduce the concept of multilayer horizontal visibility graphs. This allows describing cross-dimension dependencies via inter-layer edges, leveraging the entire structure of multilayer networks. To this end, a novel parameter-free topological measure is proposed and common measures are extended for the multilayer setting. Our approach is general and applicable to any kind of multivariate time series data.
  We provide an extensive experimental evaluation with both synthetic and real-world datasets. We first explore the proposed methodology and the data properties highlighted by each measure, showing that inter-layer edges based on cross-horizontal visibility preserve more information than previous mappings, while also complementing the information captured by commonly used intra-layer edges. We then illustrate the applicability and validity of our approach in multivariate time series mining tasks, showcasing its potential for enhanced data analysis and insights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.02333v2</guid>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vanessa Freitas Silva, Maria Eduarda Silva, Pedro Ribeiro, Fernando Silva</dc:creator>
    </item>
    <item>
      <title>On Densest $k$-Subgraph Mining and Diagonal Loading: Optimization Landscape and Finite-Step Exact Convergence Analysis</title>
      <link>https://arxiv.org/abs/2410.07388</link>
      <description>arXiv:2410.07388v4 Announce Type: replace 
Abstract: The Densest $k$-Subgraph (D$k$S) is a fundamental combinatorial problem known for its theoretical hardness and breadth of applications. Recently, Lu et al. (AAAI 2025) introduced a penalty-based non-convex relaxation that achieves promising empirical performance; however, a rigorous theoretical understanding of its success remains unclear. In this work, we bridge this gap by providing a comprehensive theoretical analysis. We first establish the tightness of the relaxation, ensuring that the global maximum values of the original combinatorial problem and the relaxed problem coincide. Then we reveal the benign geometry of the optimization landscape by proving a strict dichotomy of stationary points: all integral stationary points are local maximizers, whereas all non-integral stationary points are strict saddles with explicit positive curvature. We propose a saddle-escaping Frank--Wolfe algorithm and prove that it achieves exact convergence to an integral local maximizer in a finite number of steps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07388v4</guid>
      <category>cs.SI</category>
      <category>cs.DS</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qiheng Lu, Nicholas D. Sidiropoulos, Aritra Konar</dc:creator>
    </item>
    <item>
      <title>Scalable Signed Exponential Random Graph Models under Local Dependence</title>
      <link>https://arxiv.org/abs/2507.07660</link>
      <description>arXiv:2507.07660v4 Announce Type: replace 
Abstract: Traditional network analysis focuses on binary edges, while real-world relationships are more nuanced, encompassing cooperation, neutrality, and conflict. The rise of negative edges in social media discussions spurred interest in analyzing signed interactions, especially in polarized debates. However, the vast data generated by digital networks presents challenges for traditional methods like Stochastic Block Models (SBM) and Exponential Family Random Graph Models (ERGM), particularly due to the homogeneity assumption and global dependence, which become increasingly unrealistic as network size grows. To address this, we propose a novel method that combines the strengths of SBM and ERGM while mitigating their weaknesses by incorporating local dependence based on nonoverlapping blocks. Our approach involves a two-step process: First, decomposing the network into sub-networks using SBM approximation, and, second, estimating parameters using ERGM methods. We validate our method on large synthetic networks and apply it to a signed Wikipedia network of thousands of editors. Through the use of local dependence, we find patterns consistent with structural balance theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07660v4</guid>
      <category>cs.SI</category>
      <category>stat.CO</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Marc Schalberger, Cornelius Fritz</dc:creator>
    </item>
    <item>
      <title>Limited Improvement of Connectivity in Scale-Free Networks by Increasing the Power-Law Exponent</title>
      <link>https://arxiv.org/abs/2509.17652</link>
      <description>arXiv:2509.17652v3 Announce Type: replace 
Abstract: It has been well-known that many real networks are scale-free (SF) but extremely vulnerable against attacks. We investigate the robustness of connectivity and the lengths of the shortest loops in randomized SF networks with realistic exponents $2.0 &lt; \gamma \leq 4.0$. We show that smaller variance of degree distributions leads to stronger robustness and longer average length of the shortest loops, which means the existing of large holes. These results will provide important insights toward enhancing the robustness by changing degree distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.17652v3</guid>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yingzhou Mou, Yukio Hayashi</dc:creator>
    </item>
    <item>
      <title>From Birdwatch to Community Notes, from Twitter to X: four years of community-based content moderation</title>
      <link>https://arxiv.org/abs/2510.09585</link>
      <description>arXiv:2510.09585v3 Announce Type: replace 
Abstract: Community Notes (formerly known as Birdwatch) is the first large-scale crowdsourced content moderation initiative that was launched by X (formerly known as Twitter) in January 2021. As the Community Notes model gains momentum across other social media platforms, there is a growing need to assess its underlying dynamics and effectiveness. This resource paper provides (a) a systematic review of the literature on Community Notes, and (b) a major curated dataset and accompanying source code to support future research on Community Notes. We parsed Notes and Ratings data from the first four years of the program and conducted language detection across all Notes. Focusing on English-language Notes, we extracted embedded URLs and identified discussion topics in each Note. Additionally, we constructed monthly interaction networks among the Contributors. Together with the literature review, these resources offer a robust foundation for advancing research on the Community Notes system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09585v3</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saeedeh Mohammadi, Narges Chinichian, Hannah Doyal, Kristina Skutilova, Hao Cui, Michele d'Errico, Siobhan Grayson, Taha Yasseri</dc:creator>
    </item>
    <item>
      <title>A Community-Aware Framework for Influence Maximization with Explicit Accounting for Inter-Community Influence</title>
      <link>https://arxiv.org/abs/2512.23973</link>
      <description>arXiv:2512.23973v2 Announce Type: replace 
Abstract: Influence Maximization (IM) seeks to identify a small set of seed nodes in a social network to maximize expected information spread under a diffusion model. While community-based approaches improve scalability by exploiting modular structure, they typically assume independence between communities, overlooking inter-community influence$\unicode{x2014}$a limitation that reduces effectiveness in real-world networks. We introduce Community-IM++, a scalable framework that explicitly models cross-community diffusion through a principled heuristic based on community-based diffusion degree (CDD) and a progressive budgeting strategy. The algorithm partitions the network, computes CDD to prioritize bridging nodes, and allocates seeds adaptively across communities using lazy evaluation to minimize redundant computations. Experiments on large real-world social networks under different edge weight models show that Community-IM++ achieves near-greedy influence spread at up to 100 times lower runtime, while outperforming Community-IM and degree heuristics across budgets and structural conditions. These results demonstrate the practicality of Community-IM++ for large-scale applications such as viral marketing, misinformation control, and public health campaigns, where efficiency and cross-community reach are critical.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23973v2</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Eliot W. Robson, Abhishek K. Umrawal</dc:creator>
    </item>
    <item>
      <title>A Blue Start: A large-scale pairwise and higher-order social network dataset</title>
      <link>https://arxiv.org/abs/2505.11608</link>
      <description>arXiv:2505.11608v2 Announce Type: replace-cross 
Abstract: Large-scale networks have been instrumental in shaping how we think about social systems, and have undergirded many foundational results in mathematical epidemiology, computational social science, and biology. However, many of the social systems through which diseases spread, information disseminates, and individuals interact are inherently mediated through groups, known as higher-order interactions. A gap exists between higher-order models of group formation and spreading processes and the data necessary to validate these mechanisms. Similarly, few datasets bridge the gap between pairwise and higher-order network data. The Bluesky social media platform is an ideal laboratory for observing social ties at scale through its open API. Not only does Bluesky contain pairwise following relationships, but it also contains higher-order social ties known as "starter packs" which are user-curated lists designed to promote social network growth. We introduce "A Blue Start", a large-scale network dataset comprising 39.7M user accounts, 2.4B pairwise following relationships, and 365.8K groups representing starter packs. This dataset will be an essential resource for the study of higher-order networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11608v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alyssa Smith, Ilya Amburg, Sagar Kumar, Brooke Foucault Welles, Nicholas W. Landry</dc:creator>
    </item>
    <item>
      <title>HIF: The hypergraph interchange format for higher-order networks</title>
      <link>https://arxiv.org/abs/2507.11520</link>
      <description>arXiv:2507.11520v2 Announce Type: replace-cross 
Abstract: Many empirical systems contain complex interactions of arbitrary size, representing, for example, chemical reactions, social groups, co-authorship relationships, and ecological dependencies. These interactions are known as higher-order interactions and the collection of these interactions comprise a higher-order network, or hypergraph. Hypergraphs have established themselves as a popular and versatile mathematical representation of such systems and a number of software packages written in various programming languages have been designed to analyze these networks. However, the ecosystem of higher-order network analysis software is fragmented due to specialization of each software's programming interface and compatible data representations. To enable seamless data exchange between higher-order network analysis software packages, we introduce the Hypergraph Interchange Format (HIF), a standardized format for storing higher-order network data. HIF supports multiple types of higher-order networks, including undirected hypergraphs, directed hypergraphs, and abstract simplicial complexes, while actively exploring extensions to represent multiplex hypergraphs, temporal hypergraphs, and ordered hypergraphs. To accommodate the wide variety of metadata used in different contexts, HIF also includes support for attributes associated with nodes, edges, and incidences. This initiative is a collaborative effort involving authors, maintainers, and contributors from prominent hypergraph software packages. This project introduces a JSON schema with corresponding documentation and unit tests, example HIF-compliant datasets, and tutorials demonstrating the use of HIF with several popular higher-order network analysis software packages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11520v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1017/nws.2025.10018</arxiv:DOI>
      <arxiv:journal_reference>Net Sci 13 (2025) e21</arxiv:journal_reference>
      <dc:creator>Mart\'in Coll, Cliff A. Joslyn, Nicholas W. Landry, Quintino Francesco Lotito, Audun Myers, Joshua Pickard, Brenda Praggastis, Przemys{\l}aw Szufel</dc:creator>
    </item>
    <item>
      <title>How Similar Are Grokipedia and Wikipedia? A Multi-Dimensional Textual and Structural Comparison</title>
      <link>https://arxiv.org/abs/2510.26899</link>
      <description>arXiv:2510.26899v4 Announce Type: replace-cross 
Abstract: The launch of Grokipedia, an AI-generated encyclopedia developed by Elon Musk's xAI, was presented as a response to perceived ideological and structural biases in Wikipedia, aiming to produce "truthful" entries using the Grok large language model. Yet whether an AI-driven alternative can escape the biases and limitations of human-edited platforms remains unclear. This study conducts a large-scale computational comparison of 17,790 matched article pairs from the 20,000 most-edited English Wikipedia pages. Using metrics spanning lexical richness, readability, reference density, structural features, and semantic similarity, we assess how closely the two platforms align in form and substance. We find that Grokipedia articles are substantially longer and contain significantly fewer references per word. Moreover, Grokipedia's content divides into two distinct groups: one that remains semantically and stylistically aligned with Wikipedia, and another that diverges sharply. Among the dissimilar articles, we observe a systematic rightward shift in the political bias of cited sources, concentrated primarily in entries related to politics, history, and religion. More broadly, the findings indicate that AI-generated encyclopedic content departs from established editorial norms, favoring narrative expansion over citation-based verification, raising questions about transparency, provenance, and the governance of knowledge in automated information systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26899v4</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Taha Yasseri, Saeedeh Mohammadi</dc:creator>
    </item>
    <item>
      <title>When Large Language Models Do Not Work: Online Incivility Prediction through Graph Neural Networks</title>
      <link>https://arxiv.org/abs/2512.07684</link>
      <description>arXiv:2512.07684v2 Announce Type: replace-cross 
Abstract: Online incivility has emerged as a widespread and persistent problem in digital communities, imposing substantial social and psychological burdens on users. Although many platforms attempt to curb incivility through moderation and automated detection, the performance of existing approaches often remains limited in both accuracy and efficiency. To address this challenge, we propose a Graph Neural Network (GNN) framework for detecting three types of uncivil behavior (i.e., toxicity, aggression, and personal attacks) within the English Wikipedia community. Our model represents each user comment as a node, with textual similarity between comments defining the edges, allowing the network to jointly learn from both linguistic content and relational structures among comments. We also introduce a dynamically adjusted attention mechanism that adaptively balances nodal and topological features during information aggregation. Empirical evaluations demonstrate that our proposed architecture outperforms 12 state-of-the-art Large Language Models (LLMs) across multiple metrics while requiring significantly lower inference cost. These findings highlight the crucial role of structural context in detecting online incivility and address the limitations of text-only LLM paradigms in behavioral prediction. All datasets and comparative outputs will be publicly available in our repository to support further research and reproducibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07684v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zihan Chen, Lanyu Yu</dc:creator>
    </item>
    <item>
      <title>The R&amp;D Productivity Puzzle: Innovation Networks with Heterogeneous Firms</title>
      <link>https://arxiv.org/abs/2512.23337</link>
      <description>arXiv:2512.23337v3 Announce Type: replace-cross 
Abstract: We introduce heterogeneous R&amp;D productivities into an endogenous R&amp;D network formation model, generalizing the framework of Goyal and Moraga-Gonz\'alez (2001). Heterogeneous productivities endogenously create asymmetric gains from collaboration: less productive firms benefit disproportionately from links, while more productive firms exert greater R&amp;D effort and incur higher costs. When productivity gaps are sufficiently large, more productive firms experience lower profits from collaborating with less productive partners. As a result, the complete network -- stable under homogeneity -- becomes unstable, and the positive assortative (PA) network, in which firms cluster by R&amp;D productivity, emerges as pairwise stable. Using simulations, we show that the clustered structure delivers higher welfare than the complete network; nevertheless, welfare under this formation follows an inverted U-shape as the fraction of high-productivity firms increases, reflecting crowding-out effects at high fractions. Altogether, we uncover an R&amp;D productivity puzzle: economies with higher average R&amp;D productivity may exhibit lower welfare through (i) the formation of alternative stable networks, or (ii) a crowding-out effect of high-productivity firms. Our findings show that productivity gaps shape the organization of innovation by altering equilibrium R&amp;D alliances and effort. Productivity-enhancing policies must therefore account for these endogenous responses, as they may reverse intended welfare gains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23337v3</guid>
      <category>econ.GN</category>
      <category>cs.SI</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M. Sadra Heydari, Zafer Kanik, Santiago Montoya-Bland\'on</dc:creator>
    </item>
    <item>
      <title>A Scalable Inter-edge Correlation Modeling in CopulaGNN for Link Sign Prediction</title>
      <link>https://arxiv.org/abs/2601.19175</link>
      <description>arXiv:2601.19175v3 Announce Type: replace-cross 
Abstract: Link sign prediction on a signed graph is a task to determine whether the relationship represented by an edge is positive or negative. Since the presence of negative edges violates the graph homophily assumption that adjacent nodes are similar, regular graph methods have not been applicable without auxiliary structures to handle them. We aim to directly model the latent statistical dependency among edges with the Gaussian copula and its corresponding correlation matrix, extending CopulaGNN (Ma et al., 2021). However, a naive modeling of edge-edge relations is computationally intractable even for a graph with moderate scale. To address this, we propose to 1) represent the correlation matrix as a Gramian of edge embeddings, significantly reducing the number of parameters, and 2) reformulate the conditional probability distribution to dramatically reduce the inference cost. We theoretically verify scalability of our method by proving its linear convergence. Also, our extensive experiments demonstrate that it achieves significantly faster convergence than baselines, maintaining competitive prediction performance to the state-of-the-art models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19175v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IR</category>
      <category>cs.SI</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jinkyu Sung, Myunggeum Jee, Joonseok Lee</dc:creator>
    </item>
  </channel>
</rss>
