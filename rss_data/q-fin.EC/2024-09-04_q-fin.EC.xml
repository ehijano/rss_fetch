<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.EC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.EC</link>
    <description>q-fin.EC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.EC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 04 Sep 2024 04:14:33 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Analysis of driving factors for carbon emissions in China based on ARIMA-BP model</title>
      <link>https://arxiv.org/abs/2409.00039</link>
      <description>arXiv:2409.00039v1 Announce Type: new 
Abstract: China accounts for one-third of the world's total carbon emissions. How to reach the peak of carbon emissions by 2030 and achieve carbon neutrality by 2060 to ensure the effective realization of the "dual-carbon" target is an important policy orientation at present. Based on the provincial panel data of ARIMA-BP model, this paper shows that the effect of energy consumption intensity effect is the main factor driving the growth of carbon emissions, per capita GDP and energy consumption structure effect are the main factors to inhibit carbon emissions, and the effect of industrial structure and population size effect is relatively small. Based on the research conclusion, the policy suggestions are put forward from the aspects of energy structure, industrial structure, new quality productivity and digital economy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00039v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <category>stat.AP</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sanglin Zhao, Hao Deng, Bingkun Yuan</dc:creator>
    </item>
    <item>
      <title>Nasdaq-100 Companies' Hiring Insights: A Topic-based Classification Approach to the Labor Market</title>
      <link>https://arxiv.org/abs/2409.00658</link>
      <description>arXiv:2409.00658v1 Announce Type: new 
Abstract: The emergence of new and disruptive technologies makes the economy and labor market more unstable. To overcome this kind of uncertainty and to make the labor market more comprehensible, we must employ labor market intelligence techniques, which are predominantly based on data analysis. Companies use job posting sites to advertise their job vacancies, known as online job vacancies (OJVs). LinkedIn is one of the most utilized websites for matching the supply and demand sides of the labor market; companies post their job vacancies on their job pages, and LinkedIn recommends these jobs to job seekers who are likely to be interested. However, with the vast number of online job vacancies, it becomes challenging to discern overarching trends in the labor market. In this paper, we propose a data mining-based approach for job classification in the modern online labor market. We employed structural topic modeling as our methodology and used the NASDAQ-100 indexed companies' online job vacancies on LinkedIn as the input data. We discover that among all 13 job categories, Marketing, Branding, and Sales; Software Engineering; Hardware Engineering; Industrial Engineering; and Project Management are the most frequently posted job classifications. This study aims to provide a clearer understanding of job market trends, enabling stakeholders to make informed decisions in a rapidly evolving employment landscape.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00658v1</guid>
      <category>econ.GN</category>
      <category>cs.AI</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seyed Mohammad Ali Jafari, Ehsan Chitsaz</dc:creator>
    </item>
    <item>
      <title>Stochastic Monotonicity and Random Utility Models: The Good and The Ugly</title>
      <link>https://arxiv.org/abs/2409.00704</link>
      <description>arXiv:2409.00704v1 Announce Type: new 
Abstract: When it comes to structural estimation of risk preferences from data on choices, random utility models have long been one of the standard research tools in economics. A recent literature has challenged these models, pointing out some concerning monotonicity and, thus, identification problems. In this paper, we take a second look and point out that some of the criticism - while extremely valid - may have gone too far, demanding monotonicity of choice probabilities in decisions where it is not so clear whether it should be imposed. We introduce a new class of random utility models based on carefully constructed generalized risk premia which always satisfy our relaxed monotonicity criteria. Moreover, we show that some of the models used in applied research like the certainty-equivalent-based random utility model for CARA utility actually lie in this class of monotonic stochastic choice models. We conclude that not all random utility models are bad.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00704v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <category>stat.ME</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Henk Keffert, Nikolaus Schweizer</dc:creator>
    </item>
    <item>
      <title>Does ESG Consistently Promote the Corporate Financial Performance? A Study of the Global Cruise Industry</title>
      <link>https://arxiv.org/abs/2409.00758</link>
      <description>arXiv:2409.00758v1 Announce Type: new 
Abstract: The analysis of determinants of a company's financial performance has aroused significant attention, particularly, the environmental, social, and governance (ESG) has been the research focus in recent years. In addition to increasing revenue, the cruise industry has actively embraced the initiative of "green shipping". This study investigates the relationship between ESG and corporate financial performance (CFP) in the global cruise sector. This paper utilizes the sample data from the world's largest cruise companies over 2012-2023, to examine the ESG-CFP relationship by a regression model. The results indicate that ESG practices in cruise companies negatively influence CFP, which is further impacted by financial constraints. Furthermore, the heterogeneity analysis suggests that the high time interest earned (TIE) ratios and low total annual greenhouse gas (GHG) emissions worsen the adverse impacts of ESG on CFP. These findings contribute to the theoretical research on ESG and provide practical guidance for cruise industry operators and investors in their decision-making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00758v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuechen Wu</dc:creator>
    </item>
    <item>
      <title>Not All Oil Price Shocks Are Alike. A Replication of Kilian (American Economic Review, 2009)</title>
      <link>https://arxiv.org/abs/2409.00769</link>
      <description>arXiv:2409.00769v1 Announce Type: new 
Abstract: The price of oil can rise because of a disruption to supply or an increase in demand. The nature of the price change determines the dynamic effects. As Kilian (2009) put it: "not all oil price shocks are alike." Using the latest available data, we extend Kilian's (2009) analysis using the R ecosystem and provide more evidence for Kilian's (2009) conclusions. Inference based on unknown conditional heteroskedasticity strengthens the conclusions. With the updated shocks, we assess how a local economy responds to the global oil market, an application that is relevant to policymakers concerned with the transition away from fossil fuels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00769v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rich Ryan, Nyakundi Michieka</dc:creator>
    </item>
    <item>
      <title>An essay on the history of DSGE models</title>
      <link>https://arxiv.org/abs/2409.00812</link>
      <description>arXiv:2409.00812v1 Announce Type: new 
Abstract: Dynamic Stochastic General Equilibrium (DSGE) models, which are nowadays a crucial element of the set of quantitative tools that policy-makers have, did not emerge spontaneously. They rely on previously established ideas in Economics and relatively recent advancements in Mathematics. I aim to provide a comprehensive coverage of their history, starting from the pioneering Neoclassical general equilibrium theories and eventually reaching the New Neoclassical Synthesis (NNS). I thoroughly present the mathematical tools involved in formulating a DSGE model. I claim that this history has a mixed nature rather than an absolutist or relativist one, that the NNS may have emerged due to the complementary nature of New Classical and New Keynesian theories, and that the recent adoption and development of DSGE models by central banks from different countries has entailed a departure from the goal of building a universally valid theory that Economics has always had. The latter means that DSGE modeling has landed not without loss of generality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00812v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Genaro Mart\'in Damiani</dc:creator>
    </item>
    <item>
      <title>Global Public Sentiment on Decentralized Finance: A Spatiotemporal Analysis of Geo-tagged Tweets from 150 Countries</title>
      <link>https://arxiv.org/abs/2409.00843</link>
      <description>arXiv:2409.00843v1 Announce Type: new 
Abstract: In the digital era, blockchain technology, cryptocurrencies, and non-fungible tokens (NFTs) have transformed financial and decentralized systems. However, existing research often neglects the spatiotemporal variations in public sentiment toward these technologies, limiting macro-level insights into their global impact. This study leverages Twitter data to explore public attention and sentiment across 150 countries, analyzing over 150 million geotagged tweets from 2012 to 2022. Sentiment scores were derived using a BERT-based multilingual sentiment model trained on 7.4 billion tweets. The analysis integrates global cryptocurrency regulations and economic indicators from the World Development Indicators database. Results reveal significant global sentiment variations influenced by economic factors, with more developed nations engaging more in discussions, while less developed countries show higher sentiment levels. Geographically weighted regression indicates that GDP-tweet engagement correlation intensifies following Bitcoin price surges. Topic modeling shows that countries within similar economic clusters share discussion trends, while different clusters focus on distinct topics. This study highlights global disparities in sentiment toward decentralized finance, shaped by economic and regional factors, with implications for poverty alleviation, cryptocurrency crime, and sustainable development. The dataset and code are publicly available on GitHub.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00843v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuqi Chen, Yifan Li, Kyrie Zhixuan Zhou, Xiaokang Fu, Lingbo Liu, Shuming Bao, Daniel Sui, Luyao Zhang</dc:creator>
    </item>
    <item>
      <title>Price effects and pass-through of a VAT increase on restaurants in Germany: causal evidence for the first months and a mega sports event</title>
      <link>https://arxiv.org/abs/2409.01180</link>
      <description>arXiv:2409.01180v1 Announce Type: new 
Abstract: This paper analyses the price effects and tax pass-through of a VAT increase from 7% to 19% on restaurant services in Germany as of January 1, 2024. The Synthetic Control Method (SCM) is used to identify the causal effects of this reform using prices of goods and services unaffected by the tax change as a counterfactual for restaurant prices. Immediately in January, 31% of the tax increase was passed on to consumer prices. Pass-through increased to 58% in the following six months, which corresponds to a causal consumer price increase of about 6.5%. The presumed increase in demand for gastronomy services due to hosting the UEFA Euro 2024 tournament did not alter the path of price adjustments compared to previous months.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01180v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthias Firgo</dc:creator>
    </item>
    <item>
      <title>Estimating Heterogenous Treatment Effects for Survival Data with Doubly Doubly Robust Estimator</title>
      <link>https://arxiv.org/abs/2409.01412</link>
      <description>arXiv:2409.01412v1 Announce Type: new 
Abstract: In this paper, we introduce a doubly doubly robust estimator for the average and heterogeneous treatment effect for left-truncated-right-censored (LTRC) survival data. In causal inference for survival functions in LTRC survival data, two missing data issues are noteworthy: one is the missing data of counterfactuals for causal inference, and the other is the missing data due to truncation and censoring. Based on previous research on non-parametric deep learning estimation in survival analysis, this paper proposes an algorithm to obtain an efficient estimate of the average and heterogeneous causal effect. We simulate the data and compare our methods with the marginal hazard ratio estimation, the naive plug-in estimation, and the doubly robust causal with Cox Proportional Hazard estimation and illustrate the advantages and disadvantages of the model application.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01412v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <category>stat.AP</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Guanghui Pan</dc:creator>
    </item>
    <item>
      <title>Shrouded Sin Taxes</title>
      <link>https://arxiv.org/abs/2409.01493</link>
      <description>arXiv:2409.01493v1 Announce Type: new 
Abstract: Strategic shrouding of taxes by profit-maximizing firms can impair the effectiveness of corrective taxes. This paper explores tax shrouding and its consequences after the introduction of a digital sin tax designed to discourage harmful overconsumption of online sports betting in Germany. In response to the tax reform, most firms strategically shroud the tax, i.e., exclude tax surcharges from posted prices. Using an extensive novel panel data set on online betting odds, I causally estimate the effect of the tax on consumer betting prices. Consumers bear, on average, 76% of the tax burden. There is considerable and long-lasting heterogeneity in effects conditional on shrouding practices. Firms that shroud taxes can pass 90% of the tax onto consumers, while the pass-through rate is 16% for firms that directly post tax-inclusive prices. To understand the results' underlying mechanisms and policy implications, I propose an optimal corrective taxation model where oligopolistic firms compete on base prices and can shroud additive taxes. Tax shrouding is only attainable in equilibrium if (some) consumers underreact to shrouded attributes. According to the theoretical predictions, the empirically identified heterogeneity suggests that strategic tax shrouding significantly attenuates the positive corrective welfare effects of the tax. The results prompt regulating shrouding practices in the context of corrective taxation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01493v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johannes Kasinger</dc:creator>
    </item>
    <item>
      <title>Reinterpreting economic complexity in multiple dimensions</title>
      <link>https://arxiv.org/abs/2409.01830</link>
      <description>arXiv:2409.01830v1 Announce Type: new 
Abstract: We build on the interpretation of the Economic Complexity method as Correspondence Analysis (CA), and propose that the Canonical form of CA (CCA), which originated in the ecology literature, can be used to calculate multi-dimensional economic complexity. The traditional (CA) way of calculating economic complexity includes no "external" information such as countries' development characteristics to facilitate interpretation of "complexity". This has led to a wide range of fairly ad hoc interpretations of economic complexity on the basis of ex-post correlation to a long list of other variables. By the ex-ante inclusion of a number of country variables in the construction of the complexity indicators, CCA enables better interpretation, also in the case of multi-dimensional indicators. The analysis is further facilitated by another element of the ecologists' toolbox, the so-called biplots, which are CCA-based graph embeddings that represent a lower-dimensional product-space in which products and countries are positioned together, in mutual correspondence to each other. We show that in this way, CCA provides a richer account of development in many of its aspects, especially economic growth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01830v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>\"Onder Nomaler, Bart Verspagen</dc:creator>
    </item>
    <item>
      <title>Inventor Mobility After the Fall of the Berlin Wall</title>
      <link>https://arxiv.org/abs/2409.01861</link>
      <description>arXiv:2409.01861v1 Announce Type: new 
Abstract: This study examines the inter-organizational and spatial mobility patterns of East German inventors following the fall of the Berlin Wall. Existing research often overlooks the role of informal institutions in the mobility decisions of inventors, particularly regarding access to and transfer of knowledge. To address this gap, we investigate the unique circumstances surrounding the dissolution of the German Democratic Republic, which caused a significant shock to establishment closures and prompted many inventors to change their jobs and locations. Our sample comprises over 25,000 East German inventors, whose patenting careers in reunified Germany post-1990 are traced using a novel disambiguation and matching procedure. Our findings reveal that East German inventors in technological fields where access to Western knowledge was facilitated by industrial espionage were more likely to pursue inter-organizational mobility and continue their inventive activities in reunified Germany. Additionally, inventors from communities with strong political support for the ruling socialist party encountered difficulties in sourcing knowledge through weak ties, resulting in a lower likelihood of continuing to patent. However, those who overcame these obstacles and continued to produce inventions were more likely to relocate to West Germany, leaving their original social contexts behind.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01861v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul H\"unermund, Ann Hipp</dc:creator>
    </item>
    <item>
      <title>Evaluating the Impact of Multiple DER Aggregators on Wholesale Energy Markets: A Hybrid Mean Field Approach</title>
      <link>https://arxiv.org/abs/2409.00107</link>
      <description>arXiv:2409.00107v1 Announce Type: cross 
Abstract: The integration of distributed energy resources (DERs) into wholesale energy markets can greatly enhance grid flexibility, improve market efficiency, and contribute to a more sustainable energy future. As DERs -- such as solar PV panels and energy storage -- proliferate, effective mechanisms are needed to ensure that small prosumers can participate meaningfully in these markets. We study a wholesale market model featuring multiple DER aggregators, each controlling a portfolio of DER resources and bidding into the market on behalf of the DER asset owners. The key of our approach lies in recognizing the repeated nature of market interactions the ability of participants to learn and adapt over time. Specifically, Aggregators repeatedly interact with each other and with other suppliers in the wholesale market, collectively shaping wholesale electricity prices (aka the locational marginal prices (LMPs)). We model this multi-agent interaction using a mean-field game (MFG), which uses market information -- reflecting the average behavior of market participants -- to enable each aggregator to predict long-term LMP trends and make informed decisions. For each aggregator, because they control the DERs within their portfolio under certain contract structures, we employ a mean-field control (MFC) approach (as opposed to a MFG) to learn an optimal policy that maximizes the total rewards of the DERs under their management. We also propose a reinforcement learning (RL)-based method to help each agent learn optimal strategies within the MFG framework, enhancing their ability to adapt to market conditions and uncertainties. Numerical simulations show that LMPs quickly reach a steady state in the hybrid mean-field approach. Furthermore, our results demonstrate that the combination of energy storage and mean-field learning significantly reduces price volatility compared to scenarios without storage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00107v1</guid>
      <category>eess.SY</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>econ.GN</category>
      <category>math.OC</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jun He, Andrew L. Liu</dc:creator>
    </item>
    <item>
      <title>Can AI Replace Human Subjects? A Large-Scale Replication of Psychological Experiments with LLMs</title>
      <link>https://arxiv.org/abs/2409.00128</link>
      <description>arXiv:2409.00128v1 Announce Type: cross 
Abstract: Artificial Intelligence (AI) is increasingly being integrated into scientific research, particularly in the social sciences, where understanding human behavior is critical. Large Language Models (LLMs) like GPT-4 have shown promise in replicating human-like responses in various psychological experiments. However, the extent to which LLMs can effectively replace human subjects across diverse experimental contexts remains unclear. Here, we conduct a large-scale study replicating 154 psychological experiments from top social science journals with 618 main effects and 138 interaction effects using GPT-4 as a simulated participant. We find that GPT-4 successfully replicates 76.0 percent of main effects and 47.0 percent of interaction effects observed in the original studies, closely mirroring human responses in both direction and significance. However, only 19.44 percent of GPT-4's replicated confidence intervals contain the original effect sizes, with the majority of replicated effect sizes exceeding the 95 percent confidence interval of the original studies. Additionally, there is a 71.6 percent rate of unexpected significant results where the original studies reported null findings, suggesting potential overestimation or false positives. Our results demonstrate the potential of LLMs as powerful tools in psychological research but also emphasize the need for caution in interpreting AI-driven findings. While LLMs can complement human studies, they cannot yet fully replace the nuanced insights provided by human subjects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00128v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ziyan Cui, Ning Li, Huaikang Zhou</dc:creator>
    </item>
    <item>
      <title>Credit Scores: Performance and Equity</title>
      <link>https://arxiv.org/abs/2409.00296</link>
      <description>arXiv:2409.00296v1 Announce Type: cross 
Abstract: Credit scores are critical for allocating consumer debt in the United States, yet little evidence is available on their performance. We benchmark a widely used credit score against a machine learning model of consumer default and find significant misclassification of borrowers, especially those with low scores. Our model improves predictive accuracy for young, low-income, and minority groups due to its superior performance with low quality data, resulting in a gain in standing for these populations. Our findings suggest that improving credit scoring performance could lead to more equitable access to credit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00296v1</guid>
      <category>q-fin.RM</category>
      <category>cs.LG</category>
      <category>econ.GN</category>
      <category>q-fin.CP</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefania Albanesi, Domonkos F. Vamossy</dc:creator>
    </item>
    <item>
      <title>From Friendship Networks to Classroom Dynamics: Leveraging Neural Networks, Instrumental Variable and Genetic Algorithms for Optimal Educational Outcomes</title>
      <link>https://arxiv.org/abs/2404.02497</link>
      <description>arXiv:2404.02497v4 Announce Type: replace 
Abstract: This study uses data from the China Educational Panel Survey (CEPS) to design a classroom assignment policy that maximizes peer effects. Our approach comprises three steps: firstly, we develop a friendship formation discrete choice model and estimate it with an interpretable neural network architecture, PeerNN, generating an adjacency-probability matrix $\Omega$ that reflects friendship formation probabilities. Secondly, we incorporate $\Omega$ into a linear-in-means model to estimate peer effects. The peer effect parameter, $\beta$, has a different interpretation from the conventional linear-in-means model and opens up a strategic scope of mean-maximizing classroom assignment policy. By exploiting the conditional random classroom assignment in many Chinese middle schools, we construct a valid instrument to address the endogeneity issue induced by $\Omega$ and consistently estimate $\beta$. Lastly, utilizing the estimates of $\Omega$ and $\beta$, we employ a genetic algorithm (GA) to search for the mean-maximizing class assignment policy. Though the result is much more efficient (i.e. more positive average peer effect) than random classroom assignment (i.e. the current practice in most Chinese middle schools), GA policy is highly inequitable: a small number of students are predicted to experience severely negative peer effects. To balance students' academic performance with educational equity, we propose a fairness metric and penalize classroom assignment that generates large variances in peer effects. The modified method is called algorithmically fair genetic algorithm (AFGA). AFGA policy is less efficient but much more equitable. We allow user-defined parameters for AFGA such that the school principals can adjust the trade-off between efficiency and equity according to their preferences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02497v4</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lei Bill Wang, Om Prakash Bedant, Zhenbang Jiao, Haoran Wang</dc:creator>
    </item>
    <item>
      <title>Conceiving Naturally After IVF: the effect of assisted reproduction on obstetric interventions and child health at birth</title>
      <link>https://arxiv.org/abs/2405.00234</link>
      <description>arXiv:2405.00234v2 Announce Type: replace 
Abstract: A growing share of the world's population is being born via assisted reproductive technology (ART), including in-vitro fertilisation (IVF). However, two concerns persist. First, ART pregnancies correlate with predictors of poor outcomes at birth--and it is unclear whether this relationship is causal. Second, the emotional and financial costs associated with ART-use might exacerbate defensive medical behaviour, where physicians intervene more than necessary to reduce the risk of adverse medical outcomes and litigation. We address the challenge of identifying the pure effect of ART-use on both maternal and infant outcomes at birth by leveraging exogenous variation in the success of ART cycles. We compare the obstetric outcomes for ART-conceived births with those of spontaneously-conceived births after a failed ART treatment. Moreover, we flexibly adjust for key confounders using double machine learning. We do this using clinical registry ART data and administrative maternal and infant data from New South Wales (NSW) between 2009-2017. We find that ART slightly decreases the risk of obstetric interventions, lowering the risk of a caesarean section and increasing the rate of spontaneous labour (+3.5 p.p.). Moreover, we find that ART has a statistically and clinically insignificant effect on infant health outcomes.
  Keywords: Fertility, Assisted reproduction, IVF, Caesarean Section, Obstetric, Infertility. JEL classification: I10, I12, I19.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00234v2</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Fabio I. Martinenghi, Xian Zhang, Luk Rombauts, Georgina M. Chambers</dc:creator>
    </item>
    <item>
      <title>GPT has become financially literate: Insights from financial literacy tests of GPT and a preliminary test of how people use it as a source of advice</title>
      <link>https://arxiv.org/abs/2309.00649</link>
      <description>arXiv:2309.00649v2 Announce Type: replace-cross 
Abstract: We assess the ability of GPT -- a large language model -- to serve as a financial robo-advisor for the masses, by using a financial literacy test. Davinci and ChatGPT based on GPT-3.5 score 66% and 65% on the financial literacy test, respectively, compared to a baseline of 33%. However, ChatGPT based on GPT-4 achieves a near-perfect 99% score, pointing to financial literacy becoming an emergent ability of state-of-the-art models. We use the Judge-Advisor System and a savings dilemma to illustrate how researchers might assess advice-utilization from large language models. We also present a number of directions for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.00649v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.frl.2023.104333</arxiv:DOI>
      <arxiv:journal_reference>Finance Research Letters, 2023, 58, 104333</arxiv:journal_reference>
      <dc:creator>Pawe{\l} Niszczota, Sami Abbas</dc:creator>
    </item>
    <item>
      <title>A General Framework for Optimizing and Learning Nash Equilibrium</title>
      <link>https://arxiv.org/abs/2408.16260</link>
      <description>arXiv:2408.16260v2 Announce Type: replace-cross 
Abstract: One key in real-life Nash equilibrium applications is to calibrate players' cost functions. To leverage the approximation ability of neural networks, we proposed a general framework for optimizing and learning Nash equilibrium using neural networks to estimate players' cost functions. Depending on the availability of data, we propose two approaches (a) the two-stage approach: we need the data pair of players' strategy and relevant function value to first learn the players' cost functions by monotonic neural networks or graph neural networks, and then solve the Nash equilibrium with the learned neural networks; (b) the joint approach: we use the data of partial true observation of the equilibrium and contextual information (e.g., weather) to optimize and learn Nash equilibrium simultaneously. The problem is formulated as an optimization problem with equilibrium constraints and solved using a modified Backpropagation Algorithm. The proposed methods are validated in numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16260v2</guid>
      <category>cs.GT</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Di Zhang, Wei Gu, Qing Jin</dc:creator>
    </item>
  </channel>
</rss>
