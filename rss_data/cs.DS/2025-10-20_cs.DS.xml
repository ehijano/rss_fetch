<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 20 Oct 2025 04:00:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 20 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Revoke vs. Restart in Unweighted Throughput Scheduling</title>
      <link>https://arxiv.org/abs/2510.15318</link>
      <description>arXiv:2510.15318v1 Announce Type: new 
Abstract: We study the unweighted throughput scheduling problem on a single machine in the preemption-revoke model, where a running job may be aborted at any time, but all progress is permanently lost and the job cannot be restarted. Each job $J_i=(r_i,p_i,s_i)$ is defined by a release time $r_i$, a processing time $p_i$, and a slack $s_i$, and must start no later than $r_i+s_i$ to be feasible. We prove that no deterministic online algorithm can achieve a constant competitive ratio. The lower bound is established via an adversarial construction: starting from a three-job instance where $\textsf{ALG}$ completes at most one job while $\textsf{OPT}$ completes all three, we iteratively nest such constructions. By induction, for every $k\ge 3$, there exists an instance where $\textsf{ALG}$ completes at most one job, while $\textsf{OPT}$ completes at least $k$ jobs. Thus, the competitive ratio can be forced to $1/k$, and hence made arbitrarily close to zero. Our result stands in sharp contrast to the preemption-restart model, where Hoogeveen, Potts, and Woeginger (2000) gave a deterministic $1/2$-competitive algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.15318v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 20 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Changdao He</dc:creator>
    </item>
    <item>
      <title>Temporal Graph Reconfiguration for Always-Connected Graphs</title>
      <link>https://arxiv.org/abs/2510.15593</link>
      <description>arXiv:2510.15593v1 Announce Type: new 
Abstract: Network redesign problems ask to modify the edges of a given graph to satisfy some properties. In temporal graphs, where edges are only active at certain times, we are sometimes only allowed to modify when the edges are going to be active. In practice, we might not even be able to perform all of the necessary modifications at once; changes must be applied step-by-step while the network is still in operation, meaning that the network must continue to satisfy some properties. To initiate a study in this area, we introduce the temporal graph reconfiguration problem. As a starting point, we consider the Layered Connectivity Reconfiguration problem in which every snapshot of the temporal graph must remain connected throughout the reconfiguration. We provide insights into how bridges can be reconfigured into non-bridges based on their reachability partitions, which lets us identify any edge as either changeable or unchangeable. From this we construct a polynomial-time algorithm that gives a valid reconfiguration sequence of length at most 2M^2 (where M is the number of temporal edges), or determines that reconfiguration is not possible. We also show that minimizing the length of the reconfiguration sequence is NP-hard via a reduction from vertex cover.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.15593v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 20 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paul Sievers, George Skretas, Georg Tennigkeit</dc:creator>
    </item>
    <item>
      <title>Online Correlation Clustering: Simultaneously Optimizing All $\ell_p$-norms</title>
      <link>https://arxiv.org/abs/2510.15076</link>
      <description>arXiv:2510.15076v1 Announce Type: cross 
Abstract: The $\ell_p$-norm objectives for correlation clustering present a fundamental trade-off between minimizing total disagreements (the $\ell_1$-norm) and ensuring fairness to individual nodes (the $\ell_\infty$-norm). Surprisingly, in the offline setting it is possible to simultaneously approximate all $\ell_p$-norms with a single clustering. Can this powerful guarantee be achieved in an online setting? This paper provides the first affirmative answer. We present a single algorithm for the online-with-a-sample (AOS) model that, given a small constant fraction of the input as a sample, produces one clustering that is simultaneously $O(\log^4 n)$-competitive for all $\ell_p$-norms with high probability, $O(\log n)$-competitive for the $\ell_\infty$-norm with high probability, and $O(1)$-competitive for the $\ell_1$-norm in expectation. This work successfully translates the offline "all-norms" guarantee to the online world.
  Our setting is motivated by a new hardness result that demonstrates a fundamental separation between these objectives in the standard random-order (RO) online model. Namely, while the $\ell_1$-norm is trivially $O(1)$-approximable in the RO model, we prove that any algorithm in the RO model for the fairness-promoting $\ell_\infty$-norm must have a competitive ratio of at least $\Omega(n^{1/3})$. This highlights the necessity of a different beyond-worst-case model. We complement our algorithm with lower bounds, showing our competitive ratios for the $\ell_1$- and $\ell_\infty$- norms are nearly tight in the AOS model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.15076v1</guid>
      <category>cs.LG</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Mon, 20 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sami Davies, Benjamin Moseley, Heather Newman</dc:creator>
    </item>
    <item>
      <title>PLS-complete problems with lexicographic cost functions: Max-$k$-SAT and Abelian Permutation Orbit Minimization</title>
      <link>https://arxiv.org/abs/2510.15712</link>
      <description>arXiv:2510.15712v1 Announce Type: cross 
Abstract: How hard is it to find a local optimum? If we are given a graph and want to find a locally maximal cut--meaning that the number of edges in the cut cannot be improved by moving a single vertex from one side to the other--then just iterating improving steps finds a local maximum since the size of the cut can increase at most $|E|$ times. If, on the other hand, the edges are weighted, this problem becomes hard for the class PLS (Polynomial Local Search)[16].
  We are interested in optimization problems with lexicographic costs. For Max-Cut this would mean that the edges $e_1,\dots, e_m$ have costs $c(e_i) = 2^{m-i}$. For such a cost function, it is easy to see that finding a global Max-Cut is easy. In contrast, we show that it is PLS-complete to find an assignment for a 4-CNF formula that is locally maximal (when the clauses have lexicographic weights); and also for a 3-CNF when we relax the notion of local by allowing to switch two variables at a time.
  We use these results to answer a question in Scheder and Tantow[15], who showed that finding a lexicographic local minimum of a string $s \in \{0,1\}^n$ under the action of a list of given permutations $\pi_1, \dots, \pi_k \in S_{n}$ is PLS-complete. They ask whether the problem stays PLS-complete when the $\pi_1,\dots,\pi_k$ commute, i.e., generate an Abelian subgroup $G$ of $S_n$. In this work, we show that it does, and in fact stays PLS-complete even (1) when every element in $G$ has order two and also (2) when $G$ is cyclic, i.e., all $\pi_1,\dots,\pi_k$ are powers of a single permutations $\pi$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.15712v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Mon, 20 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dominik Scheder, Johannes Tantow</dc:creator>
    </item>
    <item>
      <title>Quantum Worst-Case to Average-Case Reduction for Matrix-Vector Multiplication</title>
      <link>https://arxiv.org/abs/2510.15721</link>
      <description>arXiv:2510.15721v1 Announce Type: cross 
Abstract: Worst-case to average-case reductions are a cornerstone of complexity theory, providing a bridge between worst-case hardness and average-case computational difficulty. While recent works have demonstrated such reductions for fundamental problems using deep tools from ad- ditive combinatorics, these approaches often suffer from substantial complexity and suboptimal overheads. In this work, we focus on the quantum setting, and provide a new reduction for the Matrix-Vector Multiplication problem that is more efficient, and conceptually simpler than previous constructions. By adapting hardness self-amplification techniques to the quantum do- main, we obtain a quantum worst-case to average-case reduction with improved dependence on the success probability, laying the groundwork for broader applications in quantum fine-grained complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.15721v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Mon, 20 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Divesh Aggarwal, Dexter Kwan</dc:creator>
    </item>
    <item>
      <title>A Simple Geometric Proof of the Optimality of the Sequential Probability Ratio Test for Symmetric Bernoulli Hypotheses</title>
      <link>https://arxiv.org/abs/2510.15790</link>
      <description>arXiv:2510.15790v1 Announce Type: cross 
Abstract: This paper revisits the classical problem of determining the bias of a weighted coin, where the bias is known to be either $p = 1/2 + \varepsilon$ or $p = 1/2 - \varepsilon$, while minimizing the expected number of coin tosses and the error probability. The optimal strategy for this problem is given by Wald's Sequential Probability Ratio Test (SPRT), which compares the log-likelihood ratio against fixed thresholds to determine a stopping time. Classical proofs of this result typically rely on analytical, continuous, and non-constructive arguments. In this paper, we present a discrete, self-contained proof of the optimality of the SPRT for this problem. We model the problem as a biased random walk on the two-dimensional (heads, tails) integer lattice, and model strategies as marked stopping times on this lattice. Our proof takes a straightforward greedy approach, showing how any arbitrary strategy may be transformed into the optimal, parallel-line "difference policy" corresponding to the SPRT, via a sequence of local perturbations that improve a Bayes risk objective.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.15790v1</guid>
      <category>math.ST</category>
      <category>cs.DS</category>
      <category>stat.TH</category>
      <pubDate>Mon, 20 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chirag Pabbaraju, Gregory Valiant, Rishi Verma</dc:creator>
    </item>
    <item>
      <title>Online busy time scheduling with flexible jobs</title>
      <link>https://arxiv.org/abs/2405.08595</link>
      <description>arXiv:2405.08595v2 Announce Type: replace 
Abstract: We consider the online busy time scheduling problem motivated by energy and cost minimization in cloud computing systems. The input is a set of jobs $J=\{1,\dots,n\}$ where each job $j\in J$ has a release time $r_j$, deadline $d_j$, and processing time $p_j$. $m$ homogeneous machines are given with a parallelism parameter $g\geq 1$, which is the maximal number of jobs that can be processed simultaneously on a machine. A machine is called \emph{busy} when at least one job is being processed. The objective is to find a feasible schedule for all jobs such that the sum of busy times over all machines is minimized. We consider the online setting, where a job $j\in J$ is revealed at its release time $r_j$.
  We show multiple algorithms in different problem variants that have a tight competitive ratio. For the busy time scheduling problem, uniform processing time jobs, and where the parallelism is unbounded ($g=\infty$), we show a $2$-competitive algorithm and an online adversary that shows that the algorithm is tight. For the setting where jobs have arbitrary processing time, agreeable deadlines, and the parallelism is unbounded, we show a different tight $2$-competitive algorithm. For machines with bounded parallelism, we show lower bounds on the competitive ratio of any online algorithm when $g$ is small. Furthermore, we improve the setting with arbitrary jobs where the algorithm is allowed lookahead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.08595v2</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 20 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Susanne Albers, G. Wessel van der Heijden</dc:creator>
    </item>
    <item>
      <title>Online Matroid Embeddings</title>
      <link>https://arxiv.org/abs/2407.10316</link>
      <description>arXiv:2407.10316v2 Announce Type: replace 
Abstract: We introduce the notion of an online matroid embedding, which is an algorithm for mapping an unknown matroid that is revealed in an online fashion to a larger-but-known matroid. We establish the existence of such an embedding for binary matroids, and use it to relate variants of the binary matroid secretary problem to each other, showing that seemingly simpler problems are in fact equivalent to seemingly harder ones (up to constant-factors). Specifically, we show this to be the case for the version of the matroid secretary problem in which the matroid is not known in advance, and where it is known in advance. We also show that the version with known matroid structure, is equivalent to the problem where weights are not fully adversarial but drawn from a known pairwise-independent distribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10316v2</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Mon, 20 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andr\'es Cristi, Paul D\"utting, Robert Kleinberg, Renato Paes Leme, Neel Patel</dc:creator>
    </item>
    <item>
      <title>Cartesian Forest Matching</title>
      <link>https://arxiv.org/abs/2506.02704</link>
      <description>arXiv:2506.02704v2 Announce Type: replace 
Abstract: In this paper, we introduce the notion of Cartesian Forest, which generalizes Cartesian Trees, in order to deal with partially ordered sequences. We show that algorithms that solve both exact and approximate Cartesian Tree Matching can be adapted to solve Cartesian Forest Matching in average linear time. We adapt the notion of Cartesian Tree Signature to Cartesian Forests and show how filters can be used to experimentally improve the algorithm for the exact matching. We also show a one to one correspondence between Cartesian Forests and Schr\"oder Trees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02704v2</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 20 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bastien Auvray, Julien David, Richard Groult, Thierry Lecroq</dc:creator>
    </item>
    <item>
      <title>Vizing's Theorem in Deterministic Almost-Linear Time</title>
      <link>https://arxiv.org/abs/2510.12619</link>
      <description>arXiv:2510.12619v2 Announce Type: replace 
Abstract: Vizing's theorem states that any $n$-vertex $m$-edge graph of maximum degree $\Delta$ can be edge colored using at most $\Delta + 1$ different colors. Vizing's original proof is easily translated into a deterministic $O(mn)$ time algorithm. This deterministic time bound was subsequently improved to $\tilde O(m \sqrt n)$ time, independently by [Arjomandi, 1982] and by [Gabow et al., 1985].
  A series of recent papers improved the time bound of $\tilde O(m\sqrt{n})$ using randomization, culminating in the randomized near-linear time $(\Delta+1)$-coloring algorithm by [Assadi, Behnezhad, Bhattacharya, Costa, Solomon, and Zhang, 2025]. At the heart of all of these recent improvements, there is some form of a sublinear time algorithm. Unfortunately, sublinear time algorithms as a whole almost always require randomization. This raises a natural question: can the deterministic time complexity of the problem be reduced below the $\tilde O(m\sqrt{n})$ barrier?
  In this paper, we answer this question in the affirmative. We present a deterministic almost-linear time $(\Delta+1)$-coloring algorithm, namely, an algorithm running in $m \cdot 2^{O(\sqrt{\log \Delta})} \cdot \log n = m^{1+o(1)}$ time. Our main technical contribution is to entirely forego sublinear time algorithms. We do so by presenting a new deterministic color-type sparsification approach that runs in almost-linear (instead of sublinear) time, but can be used to color a much larger set of edges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12619v2</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 20 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sepehr Assadi, Soheil Behnezhad, Sayan Bhattacharya, Mart\'in Costa, Shay Solomon, Tianyi Zhang</dc:creator>
    </item>
    <item>
      <title>The Limits of Interval-Regulated Price Discrimination</title>
      <link>https://arxiv.org/abs/2406.06023</link>
      <description>arXiv:2406.06023v2 Announce Type: replace-cross 
Abstract: In this paper, we study third-degree price discrimination in a model first presented by Bergemann, Brooks, and Morris [2015]. Since such price discrimination might create market segments with vastly different posted prices, we consider regulating these prices, specifically, by restricting them to lie within an interval. Given a price interval, we consider segmentations of the market where a seller, who is oblivious to the existence of such regulation, still posts prices within the price interval. We show the following surprising result: For any market and price interval where such segmentation is feasible, there is always a different segmentation that optimally transfers all excess surplus to the consumers. In addition, we characterize the entire space of buyer and seller surplus that is achievable by such segmentation, including maximizing seller surplus, and simultaneously minimizing buyer and seller surplus. A key technical challenge is that the classical segmentation method of Bergemann, Brooks, and Morris [2015] fails under price constraints. To address this, we develop three intuitive but fundamentally distinct segmentation constructions, each tailored to a different surplus objective. These constructions maintain different invariants, reflect different economic intuitions, and collectively form the core of our regulated surplus characterization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06023v2</guid>
      <category>econ.TH</category>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Mon, 20 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kamesh Munagala, Yiheng Shen, Renzhe Xu</dc:creator>
    </item>
    <item>
      <title>Non-unitary enhanced transfer efficiency in quantum walk search on complex networks</title>
      <link>https://arxiv.org/abs/2503.01762</link>
      <description>arXiv:2503.01762v3 Announce Type: replace-cross 
Abstract: The task of finding an element in an unstructured database is known as spatial search and can be expressed as a quantum walk evolution on a graph. In this article, we modify the usual search problem by adding an extra trapping vertex to the graph, which is only connected to the target element. We study the transfer efficiency of the walker to a trapping site, using the search problem as a case study. Thus, our model offers no computational advantage for the search problem, but focuses on information transport in an open environment with a search Hamiltonian. The walker evolution is a mix between classical and quantum walk search dynamics. The balance between unitary and non-unitary dynamics is tuned with a parameter, and we numerically show that depending on the graph topology and the connectivity of the target element, this hybrid approach can outperform a purely classical or quantum evolution for reaching the trapping site. We show that this behavior is only observed in the presence of an extra trapping site, and that depending on the topology and a tunable parameter controlling the strength of the oracle, a hybrid regime composed of 90% coherent dynamics can lead to either the highest or worst transfer efficiency to the trapping site. We also relate the performance of an hybrid regime to the entropy's decay rate. As the introduction of non-unitary operations may be considered as noise, we interpret this phenomena as a noisy-assisted quantum evolution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01762v3</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <pubDate>Mon, 20 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ugo Nzongani, Andrea Simonetto, Giuseppe Di Molfetta</dc:creator>
    </item>
    <item>
      <title>Changing Base Without Losing Pace: A GPU-Efficient Alternative to MatMul in DNNs</title>
      <link>https://arxiv.org/abs/2503.12211</link>
      <description>arXiv:2503.12211v2 Announce Type: replace-cross 
Abstract: Modern AI relies on huge matrix multiplications (MatMuls), whose computation poses a scalability problem for inference and training. We propose an alternative, GPU native bilinear operator to MatMuls in neural networks, which offers a three-way tradeoff between: speed, accuracy and parameter count. In particular, this operator requires substantially fewer FLOPs to evaluate ($\ll n^3$), yet increases the parameter count compared to MatMul ($\gg n^2$). We call this operator Strassen-Tile (STL). The key idea behind STL is a local learnable change-of-basis, applied on tiles of the weight and activation matrices, followed by an element-wise product between the tiles, implemented simultaneously via MatMul. The key technical question we study is how to optimize the change-of-basis of a given layer, which is a highly non-convex problem. We show that theory-backed initializations (inspired by fast matrix and polynomial multiplication) lead to substantially better accuracy than random SGD initialization. This phenomenon motivates further algorithmic study of STL optimization in DNNs. Our experiments demonstrate that STL can approximate 4x4 MatMul of tiles while reducing FLOPs by a factor of 2.66, and can improve Imagenet-1K accuracy of SoTA T2T-ViT-7 (4.3M parameters) while lowering FLOPs. Even with non-CUDA optimized PyTorch code, STL achieves wall-clock speedups in the compute-bound regime. These results, together with its theoretical grounds, suggest STL as a promising building block for scalable and cost-efficient AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.12211v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <pubDate>Mon, 20 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nir Ailon, Akhiad Bercovich, Omri Weinstein</dc:creator>
    </item>
    <item>
      <title>Deriving the Gradients of Some Popular Optimal Transport Algorithms</title>
      <link>https://arxiv.org/abs/2504.08722</link>
      <description>arXiv:2504.08722v2 Announce Type: replace-cross 
Abstract: In this note, I review entropy-regularized Monge-Kantorovich problem in Optimal Transport, and derive the gradients of several popular algorithms popular in Computational Optimal Transport, including the Sinkhorn algorithms, Wasserstein Barycenter algorithms, and the Wasserstein Dictionary Learning algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08722v2</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Mon, 20 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Fangzhou Xie</dc:creator>
    </item>
    <item>
      <title>Parameterized Complexity of s-Club Cluster Edge Deletion: When Is the Diameter Bound Necessary?</title>
      <link>https://arxiv.org/abs/2510.07065</link>
      <description>arXiv:2510.07065v2 Announce Type: replace-cross 
Abstract: We study when the diameter bound s is essential for the tractability of the s-Club Cluster Edge Deletion problem. Given a graph G = (V, E) and integers k and s, the goal is to delete at most k edges so that every connected component of the resulting graph has diameter at most s. This problem generalizes Cluster Edge Deletion (s = 1) and captures distance-bounded clustering tasks.
  Montecchiani et al. (Information and Computation, 2023) proved that the problem is fixed-parameter tractable when parameterized by s + tw(G) and asked whether dependence on s is necessary. We answer negatively by showing W[1]-hardness when parameterized by pathwidth (and hence by treewidth), proving that s cannot in general be dropped. On the positive side, we show FPT algorithms parameterized by treedepth, neighborhood diversity, or cluster vertex deletion number, extending results of Italiano et al. (Algorithmica, 2023) and Komusiewicz and Uhlmann (SOFSEM, 2011). We also show that no polynomial kernel exists when parameterized by vertex cover number, even for s = 2.
  Classically, the problem is NP-hard on split graphs for s = 2, complementing the polynomial case s = 1. We give an FPT bicriteria approximation scheme running in f(k, 1/epsilon) * n^{O(1)} that outputs a set of at most k deletions whose components have diameter at most (1 + epsilon)s. Finally, we introduce a directed generalization, s-Club Cluster Arc Deletion, extending the undirected case to reachability distances, and show it is W[1]-hard in parameter k even on directed acyclic graphs (DAGs).</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.07065v2</guid>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Mon, 20 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ajinkya Gaikwad</dc:creator>
    </item>
    <item>
      <title>An efficient algorithm for $\mathcal{F}$-subgraph-free Edge Deletion on graphs having a product structure</title>
      <link>https://arxiv.org/abs/2510.14674</link>
      <description>arXiv:2510.14674v2 Announce Type: replace-cross 
Abstract: Given a family $\mathcal{F}$ of graphs, a graph is \emph{$\mathcal{F}$-subgraph-free} if it has no subgraph isomorphic to a member of $\mathcal{F}$. We present a fixed-parameter linear-time algorithm that decides whether a planar graph can be made $\mathcal{F}$-subgraph-free by deleting at most $k$ vertices or $k$ edges, where the parameters are $k$, $\lvert \mathcal{F} \rvert$, and the maximum number of vertices in a member of $\mathcal{F}$. The running time of our algorithm is double-exponential in the parameters, which is faster than the algorithm obtained by applying the first-order model checking result for graphs of bounded twin-width.
  To obtain this result, we develop a unified framework for designing algorithms for this problem on graphs with a ``product structure.'' Using this framework, we also design algorithms for other graph classes that generalize planar graphs. Specifically, the problem admits a fixed-parameter linear time algorithm on disk graphs of bounded local radius, and a fixed-parameter almost-linear time algorithm on graphs of bounded genus.
  Finally, we show that our result gives a tight fixed-parameter algorithm in the following sense: Even when $\mathcal{F}$ consists of a single graph $F$ and the input is restricted to planar graphs, it is unlikely to drop any parameters $k$ and $\lvert V(F) \rvert$ while preserving fixed-parameter tractability, unless the Exponential-Time Hypothesis fails.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14674v2</guid>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Mon, 20 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shinwoo An, Seonghyuk Im, Seokbeom Kim, Myounghwan Lee</dc:creator>
    </item>
  </channel>
</rss>
