<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 27 Aug 2024 04:00:43 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 27 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Beyond Winning Strategies: Admissible and Admissible Winning Strategies for Quantitative Reachability Games</title>
      <link>https://arxiv.org/abs/2408.13369</link>
      <description>arXiv:2408.13369v1 Announce Type: new 
Abstract: Classical reactive synthesis approaches aim to synthesize a reactive system that always satisfies a given specifications. These approaches often reduce to playing a two-player zero-sum game where the goal is to synthesize a winning strategy. However, in many pragmatic domains, such as robotics, a winning strategy does not always exist, yet it is desirable for the system to make an effort to satisfy its requirements instead of "giving up". To this end, this paper investigates the notion of admissible strategies, which formalize "doing-your-best", in quantitative reachability games. We show that, unlike the qualitative case, quantitative admissible strategies are history-dependent even for finite payoff functions, making synthesis a challenging task. In addition, we prove that admissible strategies always exist but may produce undesirable optimistic behaviors. To mitigate this, we propose admissible winning strategies, which enforce the best possible outcome while being admissible. We show that both strategies always exist but are not memoryless. We provide necessary and sufficient conditions for the existence of both strategies and propose synthesis algorithms. Finally, we illustrate the strategies on gridworld and robot manipulator domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13369v1</guid>
      <category>cs.GT</category>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <category>cs.RO</category>
      <pubDate>Tue, 27 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Karan Muvvala, Qi Heng Ho, Morteza Lahijanian</dc:creator>
    </item>
    <item>
      <title>Temporal Elections: Welfare, Strategyproofness, and Proportionality</title>
      <link>https://arxiv.org/abs/2408.13637</link>
      <description>arXiv:2408.13637v1 Announce Type: new 
Abstract: We investigate a model of sequential decision-making where a single alternative is chosen at each round. We focus on two objectives-utilitarian welfare (Util) and egalitarian welfare (Egal)-and consider the computational complexity of the associated maximization problems, as well as their compatibility with strategyproofness and proportionality. We observe that maximizing Util is easy, but the corresponding decision problem for Egal is NP-complete even in restricted cases. We complement this hardness result for Egal with parameterized complexity analysis and an approximation algorithm. Additionally, we show that, while a mechanism that outputs a Util outcome is strategyproof, all deterministic mechanisms for computing Egal outcomes fail a very weak variant of strategyproofness, called non-obvious manipulability (NOM). However, we show that when agents have non-empty approval sets at each timestep, choosing an Egal-maximizing outcome while breaking ties lexicographically satisfies NOM. Regarding proportionality, we prove that a proportional (PROP) outcome can be computed efficiently, but finding an outcome that maximizes Util while guaranteeing PROP is NP-hard. We also derive upper and lower bounds on the price of proportionality with respect to Util and Egal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13637v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <pubDate>Tue, 27 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Edith Elkind, Tzeh Yuan Neoh, Nicholas Teh</dc:creator>
    </item>
    <item>
      <title>How to guide a present-biased agent through prescribed tasks?</title>
      <link>https://arxiv.org/abs/2408.13675</link>
      <description>arXiv:2408.13675v1 Announce Type: new 
Abstract: The present bias is a well-documented behavioral trait that significantly influences human decision-making, with present-biased agents often prioritizing immediate rewards over long-term benefits, leading to suboptimal outcomes in various real-world scenarios. Kleinberg and Oren (2014) proposed a popular graph-theoretical model of inconsistent planning to capture the behavior of present-biased agents. In this model, a multi-step project is represented by a weighted directed acyclic task graph, where the agent traverses the graph based on present-biased preferences.
  We use the model of Kleinberg and Oren to address the principal-agent problem, where a principal, fully aware of the agent's present bias, aims to modify an existing project by adding or deleting tasks. The challenge is to create a modified project that satisfies two somewhat contradictory conditions. On one hand, the present-biased agent should select specific tasks deemed important by the principal. On the other hand, if the anticipated costs in the modified project become too high for the agent, there is a risk of the agent abandoning the entire project, which is not in the principal's interest.
  To tackle this issue, we leverage the tools of parameterized complexity to investigate whether the principal's strategy can be efficiently identified. We provide algorithms and complexity bounds for this problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13675v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 27 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tatiana Belova, Yuriy Dementiev, Fedor V. Fomin, Petr A. Golovach, Artur Ignatiev</dc:creator>
    </item>
    <item>
      <title>Informativeness and Trust in Bayesian Persuasion</title>
      <link>https://arxiv.org/abs/2408.13822</link>
      <description>arXiv:2408.13822v1 Announce Type: new 
Abstract: A persuasion policy successfully persuades an agent to pick a particular action only if the information is designed in a manner that convinces the agent that it is in their best interest to pick that action. Thus, it is natural to ask, what makes the agent trust the persuader's suggestion? We study a Bayesian persuasion interaction between a sender and a receiver where the sender has access to private information and the receiver attempts to recover this information from messages sent by the sender. The sender crafts these messages in an attempt to maximize its utility which depends on the source symbol and the symbol recovered by the receiver. Our goal is to characterize the \textit{Stackelberg game value}, and the amount of true information revealed by the sender during persuasion. We find that the SGV is given by the optimal value of a \textit{linear program} on probability distributions constrained by certain \textit{trust constraints}. These constraints encode that any signal in a persuasion strategy must contain more truth than untruth and thus impose a fundamental bound on the extent of obfuscation a sender can perform. We define \textit{informativeness} of the sender as the minimum expected number of symbols truthfully revealed by the sender in any accumulation point of a sequence of $\varepsilon$-equilibrium persuasion strategies, and show that it is given by another linear program. Informativeness is a fundamental bound on the amount of information the sender must reveal to persuade a receiver. Closed form expressions for the SGV and the informativeness are presented for structured utility functions. This work generalizes our previous work where the sender and the receiver were constrained to play only deterministic strategies and a similar notion of informativeness was characterized. Comparisons between the previous and current notions are discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13822v1</guid>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>econ.TH</category>
      <category>eess.SY</category>
      <pubDate>Tue, 27 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Reema Deori, Ankur A. Kulkarni</dc:creator>
    </item>
    <item>
      <title>An NP-hard generalization of Nim</title>
      <link>https://arxiv.org/abs/2408.13834</link>
      <description>arXiv:2408.13834v1 Announce Type: new 
Abstract: A new combinatorial game is given. It generalizes both Substraction and Nim. It is proved the computation of Nash equilibrium points in this new game is NP-hard.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13834v1</guid>
      <category>cs.GT</category>
      <category>math.CO</category>
      <pubDate>Tue, 27 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chunlei Liu</dc:creator>
    </item>
    <item>
      <title>ReLExS: Reinforcement Learning Explanations for Stackelberg No-Regret Learners</title>
      <link>https://arxiv.org/abs/2408.14086</link>
      <description>arXiv:2408.14086v1 Announce Type: new 
Abstract: With the constraint of a no regret follower, will the players in a two-player Stackelberg game still reach Stackelberg equilibrium? We first show when the follower strategy is either reward-average or transform-reward-average, the two players can always get the Stackelberg Equilibrium. Then, we extend that the players can achieve the Stackelberg equilibrium in the two-player game under the no regret constraint. Also, we show a strict upper bound of the follower's utility difference between with and without no regret constraint. Moreover, in constant-sum two-player Stackelberg games with non-regret action sequences, we ensure the total optimal utility of the game remains also bounded.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14086v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Tue, 27 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiangge Huang, Jingyuan Li, Jiaqing Xie</dc:creator>
    </item>
    <item>
      <title>Analysis of the ICML 2023 Ranking Data: Can Authors' Opinions of Their Own Papers Assist Peer Review in Machine Learning?</title>
      <link>https://arxiv.org/abs/2408.13430</link>
      <description>arXiv:2408.13430v1 Announce Type: cross 
Abstract: We conducted an experiment during the review process of the 2023 International Conference on Machine Learning (ICML) that requested authors with multiple submissions to rank their own papers based on perceived quality. We received 1,342 rankings, each from a distinct author, pertaining to 2,592 submissions. In this paper, we present an empirical analysis of how author-provided rankings could be leveraged to improve peer review processes at machine learning conferences. We focus on the Isotonic Mechanism, which calibrates raw review scores using author-provided rankings. Our analysis demonstrates that the ranking-calibrated scores outperform raw scores in estimating the ground truth ``expected review scores'' in both squared and absolute error metrics. Moreover, we propose several cautious, low-risk approaches to using the Isotonic Mechanism and author-provided rankings in peer review processes, including assisting senior area chairs' oversight of area chairs' recommendations, supporting the selection of paper awards, and guiding the recruitment of emergency reviewers. We conclude the paper by addressing the study's limitations and proposing future research directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13430v1</guid>
      <category>stat.AP</category>
      <category>cs.DL</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 27 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Buxin Su, Jiayao Zhang, Natalie Collina, Yuling Yan, Didong Li, Kyunghyun Cho, Jianqing Fan, Aaron Roth, Weijie J. Su</dc:creator>
    </item>
    <item>
      <title>Incentives in Social Decision Schemes with Pairwise Comparison Preferences</title>
      <link>https://arxiv.org/abs/2204.12436</link>
      <description>arXiv:2204.12436v3 Announce Type: replace 
Abstract: Social decision schemes (SDSs) map the ordinal preferences of individual voters over multiple alternatives to a probability distribution over the alternatives. In order to study the axiomatic properties of SDSs, we lift preferences over alternatives to preferences over lotteries using the natural -- but little understood -- pairwise comparison (PC) preference extension. This extension postulates that one lottery is preferred to another if the former is more likely to return a preferred outcome. We settle three open questions raised by Brandt (2017): (i) there is no Condorcet-consistent SDS that satisfies PC-strategyproofness; (ii) there is no anonymous and neutral SDS that satisfies PC-efficiency and PC-strategyproofness; and (iii) there is no anonymous and neutral SDS that satisfies PC-efficiency and strict PC-participation. All three impossibilities require $m\geq 4$ alternatives and turn into possibilities when $m\leq 3$. We furthermore settle an open problem raised by Aziz et al. (2015) by showing that no path of PC-improvements originating from an inefficient lottery may lead to a PC-efficient lottery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2204.12436v3</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Tue, 27 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.geb.2023.08.009</arxiv:DOI>
      <arxiv:journal_reference>Games and Economic Behavior, 142:266-291 (2023)</arxiv:journal_reference>
      <dc:creator>Felix Brandt, Patrick Lederer, Warut Suksompong</dc:creator>
    </item>
    <item>
      <title>Minimally Modifying a Markov Game to Achieve Any Nash Equilibrium and Value</title>
      <link>https://arxiv.org/abs/2311.00582</link>
      <description>arXiv:2311.00582v5 Announce Type: replace 
Abstract: We study the game modification problem, where a benevolent game designer or a malevolent adversary modifies the reward function of a zero-sum Markov game so that a target deterministic or stochastic policy profile becomes the unique Markov perfect Nash equilibrium and has a value within a target range, in a way that minimizes the modification cost. We characterize the set of policy profiles that can be installed as the unique equilibrium of a game and establish sufficient and necessary conditions for successful installation. We propose an efficient algorithm that solves a convex optimization problem with linear constraints and then performs random perturbation to obtain a modification plan with a near-optimal cost. The code for our algorithm is available at https://github.com/YoungWu559/game-modification .</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.00582v5</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <pubDate>Tue, 27 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Young Wu, Jeremy McMahan, Yiding Chen, Yudong Chen, Xiaojin Zhu, Qiaomin Xie</dc:creator>
    </item>
    <item>
      <title>Keeping the Harmony Between Neighbors: Local Fairness in Graph Fair Division</title>
      <link>https://arxiv.org/abs/2401.14825</link>
      <description>arXiv:2401.14825v2 Announce Type: replace 
Abstract: We study the problem of allocating indivisible resources under the connectivity constraints of a graph $G$. This model, initially introduced by Bouveret et al. (published in IJCAI, 2017), effectively encompasses a diverse array of scenarios characterized by spatial or temporal limitations, including the division of land plots and the allocation of time plots. In this paper, we introduce a novel fairness concept that integrates local comparisons within the social network formed by a connected allocation of the item graph. Our particular focus is to achieve pairwise-maximin fair share (PMMS) among the "neighbors" within this network. For any underlying graph structure, we show that a connected allocation that maximizes Nash welfare guarantees a $(1/2)$-PMMS fairness. Moreover, for two agents, we establish that a $(3/4)$-PMMS allocation can be efficiently computed. Additionally, we demonstrate that for three agents and the items aligned on a path, a PMMS allocation is always attainable and can be computed in polynomial time. Lastly, when agents have identical additive utilities, we present a pseudo-polynomial-time algorithm for a $(3/4)$-PMMS allocation, irrespective of the underlying graph $G$. Furthermore, we provide a polynomial-time algorithm for obtaining a PMMS allocation when $G$ is a tree.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.14825v2</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>cs.MA</category>
      <pubDate>Tue, 27 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Halvard Hummel, Ayumi Igarashi</dc:creator>
    </item>
    <item>
      <title>Optimal AoI-based Block Propagation and Incentive Mechanism for Blockchain Networks in Web 3.0</title>
      <link>https://arxiv.org/abs/2403.12807</link>
      <description>arXiv:2403.12807v2 Announce Type: replace 
Abstract: Web 3.0 is regarded as a revolutionary paradigm that enables users to securely manage data without a centralized authority. Blockchains, which enable data to be managed in a decentralized and transparent manner, are key technologies for achieving Web 3.0 goals. However, Web 3.0 based on blockchains is still in its infancy, such as ensuring block freshness and optimizing block propagation for improving blockchain performance. In this paper, we develop a freshness-aware block propagation optimization framework for Web 3.0. We first propose a novel metric called Age of Block Information (AoBI) based on the concept of age of information to quantify block freshness. AoBI measures the time elapsed from the freshest transaction generation to the completion of block consensus. To make block propagation optimization tractable, we classify miners into five different states and propose a block propagation model for public blockchains inspired by epidemic models. Moreover, considering that the miners are bounded rational, we propose an incentive mechanism based on the evolutionary game for block propagation to improve block propagation efficiency. Numerical results demonstrate that compared with other block propagation mechanisms in public blockchains, the proposed scheme has a higher block forwarding probability, which improves block propagation efficiency and decreases the minimum value of average AoBI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12807v2</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 27 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinbo Wen, Jiawen Kang, Zehui Xiong, Hongyang Du, Zhaohui Yang, Dusit Niyato, Meng Shen, Yutao Jiao, Yang Zhang</dc:creator>
    </item>
    <item>
      <title>On the equivalence between the minimax theorem and strong duality of conic linear programming</title>
      <link>https://arxiv.org/abs/2302.03066</link>
      <description>arXiv:2302.03066v4 Announce Type: replace-cross 
Abstract: We prove the almost equivalence between two-player zero-sum games and conic linear programming problems in reflexive Banach spaces. The previous fundamental results of von Neumann, Dantzig, Adler, and von Stengel on the equivalence between linear programming and finite games with strategy sets defined over $\mathbb{R}^n$, are therefore extended to more general strategy spaces. More specifically, we show that for every two-player zero-sum game with a bilinear payoff function of the form $u(x,y)=\langle y,Ax\rangle$, for some linear operator $A$, and strategy sets that represent bases of convex cones, the minimax theorem holds, and its game value and Nash equilibria can be computed by solving a primal-dual pair of conic linear problems. Conversely, the minimax theorem for the same class of games "almost always" implies strong duality of conic linear programming. The main results are applied to a number of infinite zero-sum games, whose classes include those of semi-infinite, semidefinite, time-continuous, quantum, polynomial, and homogeneous separable games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.03066v4</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <pubDate>Tue, 27 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikos Dimou</dc:creator>
    </item>
    <item>
      <title>Performative Prediction with Neural Networks</title>
      <link>https://arxiv.org/abs/2304.06879</link>
      <description>arXiv:2304.06879v2 Announce Type: replace-cross 
Abstract: Performative prediction is a framework for learning models that influence the data they intend to predict. We focus on finding classifiers that are performatively stable, i.e. optimal for the data distribution they induce. Standard convergence results for finding a performatively stable classifier with the method of repeated risk minimization assume that the data distribution is Lipschitz continuous to the model's parameters. Under this assumption, the loss must be strongly convex and smooth in these parameters; otherwise, the method will diverge for some problems. In this work, we instead assume that the data distribution is Lipschitz continuous with respect to the model's predictions, a more natural assumption for performative systems. As a result, we are able to significantly relax the assumptions on the loss function. In particular, we do not need to assume convexity with respect to the model's parameters. As an illustration, we introduce a resampling procedure that models realistic distribution shifts and show that it satisfies our assumptions. We support our theory by showing that one can learn performatively stable classifiers with neural networks making predictions about real data that shift according to our proposed procedure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.06879v2</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <pubDate>Tue, 27 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mehrnaz Mofakhami, Ioannis Mitliagkas, Gauthier Gidel</dc:creator>
    </item>
    <item>
      <title>Multi-Interval Energy-Reserve Co-Optimization with SoC-Dependent Bids from Battery Storage</title>
      <link>https://arxiv.org/abs/2401.15525</link>
      <description>arXiv:2401.15525v2 Announce Type: replace-cross 
Abstract: We consider the problem of co-optimized energy-reserve market clearing with state-of-charge (SoC) dependent bids from battery storage participants. While SoC-dependent bids capture storage's degradation and opportunity costs, such bids result in a non-convex optimization in the market clearing process. More challenging is the regulation reserve capacity clearing, where the SoC-dependent cost is uncertain as it depends on the unknown regulation trajectories ex-post of the market clearing. Addressing the nonconvexity and uncertainty in a multi-interval co-optimized real-time energy-reserve market, we introduce a simple restriction on the SoC-dependent bids along with a robust optimization formulation, transforming the non-convex market clearing under uncertainty into a standard convex piece-wise linear program and making it possible for large-scale storage integration. Under reasonable assumptions, we show that SoC-dependent bids yield higher profit for storage participants than that from SoC-independent bids. Numerical simulations demonstrate a 28%-150% profit increase of the proposed SoC-dependent bids compared with the SoC-independent counterpart.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.15525v2</guid>
      <category>eess.SY</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <pubDate>Tue, 27 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cong Chen, Siying Li, Lang Tong</dc:creator>
    </item>
  </channel>
</rss>
