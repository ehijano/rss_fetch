<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 31 Dec 2024 03:19:47 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Flex-PE: Flexible and SIMD Multi-Precision Processing Element for AI Workloads</title>
      <link>https://arxiv.org/abs/2412.11702</link>
      <description>arXiv:2412.11702v1 Announce Type: cross 
Abstract: The rapid adaptation of data driven AI models, such as deep learning inference, training, Vision Transformers (ViTs), and other HPC applications, drives a strong need for runtime precision configurable different non linear activation functions (AF) hardware support. Existing solutions support diverse precision or runtime AF reconfigurability but fail to address both simultaneously. This work proposes a flexible and SIMD multiprecision processing element (FlexPE), which supports diverse runtime configurable AFs, including sigmoid, tanh, ReLU and softmax, and MAC operation. The proposed design achieves an improved throughput of up to 16X FxP4, 8X FxP8, 4X FxP16 and 1X FxP32 in pipeline mode with 100% time multiplexed hardware. This work proposes an area efficient multiprecision iterative mode in the SIMD systolic arrays for edge AI use cases. The design delivers superior performance with up to 62X and 371X reductions in DMA reads for input feature maps and weight filters in VGG16, with an energy efficiency of 8.42 GOPS / W within the accuracy loss of 2%. The proposed architecture supports emerging 4-bit computations for DL inference while enhancing throughput in FxP8/16 modes for transformers and other HPC applications. The proposed approach enables future energy-efficient AI accelerators in edge and cloud environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11702v1</guid>
      <category>cs.AR</category>
      <category>cs.CV</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>eess.IV</category>
      <pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mukul Lokhande, Gopal Raut, Santosh Kumar Vishvakarma</dc:creator>
    </item>
    <item>
      <title>High order schemes for solving partial differential equations on a quantum computer</title>
      <link>https://arxiv.org/abs/2412.19232</link>
      <description>arXiv:2412.19232v1 Announce Type: cross 
Abstract: We explore the utilization of higher-order discretization techniques in optimizing the gate count needed for quantum computer based solutions of partial differential equations. To accomplish this, we present an efficient approach for decomposing $d$-band diagonal matrices into Pauli strings that are grouped into mutually commuting sets.
  Using numerical simulations of the one-dimensional wave equation, we show that higher-order methods can reduce the number of qubits necessary for discretization, similar to the classical case, although they do not decrease the number of Trotter steps needed to preserve solution accuracy. This result has important consequences for the practical application of quantum algorithms based on Hamiltonian evolution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19232v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Boris Arseniev, Dmitry Guskov, Richik Sengupta, Igor Zacharov</dc:creator>
    </item>
    <item>
      <title>The Internet of Value: Integrating Blockchain and Lightning Network Micropayments for Knowledge Markets</title>
      <link>https://arxiv.org/abs/2412.19384</link>
      <description>arXiv:2412.19384v1 Announce Type: cross 
Abstract: Q&amp;A websites rely on user-generated responses, with incentives such as reputation scores or monetary rewards often offered. While some users may find it intrinsically rewarding to assist others, studies indicate that payment can improve the quality and speed of answers. However, traditional payment processors impose minimum thresholds that many Q&amp;A inquiries fall below. The introduction of Bitcoin enabled direct digital value transfer, yet frequent micropayments remain challenging. Recent advancements like the Lightning Network now allow frictionless micropayments by reducing costs and minimising reliance on intermediaries. This development fosters an "Internet of Value," where transferring even small amounts of money is as simple as sharing data. This study investigates integrating Lightning Network-based micropayment strategies into Q&amp;A platforms, aiming to create a knowledge market free of minimum payment barriers. A survey was conducted to address the gap below the $2 payment level identified in prior research. Responses confirmed that incentives for asking and answering weaken as payments decrease. Findings reveal even minimal payments, such as {\pounds}0.01, significantly encourage higher quality and effort in responses. The study recommends micropayment incentives for service-oriented applications, particularly Q&amp;A platforms. By leveraging the Lightning Network to remove barriers, a more open marketplace can emerge, improving engagement and outcomes. Further research is needed to confirm if users follow through on reported intentions when spending funds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19384v1</guid>
      <category>cs.CY</category>
      <category>cs.CE</category>
      <category>cs.ET</category>
      <pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ellis Solaiman, Jorge Robins</dc:creator>
    </item>
    <item>
      <title>Adrenaline: Adaptive Rendering Optimization System for Scalable Cloud Gaming</title>
      <link>https://arxiv.org/abs/2412.19446</link>
      <description>arXiv:2412.19446v1 Announce Type: cross 
Abstract: Cloud gaming requires a low-latency network connection, making it a prime candidate for being hosted at the network edge. However, an edge server is provisioned with a fixed compute capacity, causing an issue for multi-user service and resulting in users having to wait before they can play when the server is occupied. In this work, we present a new insight that when a user's network condition results in use of lossy compression, the end-to-end visual quality more degrades for frames of high rendering quality, wasting the server's computing resources. We leverage this observation to build Adrenaline, a new system which adaptively optimizes the game rendering qualities by considering the user-side visual quality and server-side rendering cost. The rendering quality optimization of Adrenaline is done via a scoring mechanism quantifying the effectiveness of server resource usage on the user-side gaming quality. Our open-sourced implementation of Adrenaline demonstrates easy integration with modern game engines. In our evaluations, Adrenaline achieves up to 24% higher service quality and 2x more users served with the same resource footprint compared to other baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19446v1</guid>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.GR</category>
      <category>cs.MM</category>
      <pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jin Heo, Ketan Bhardwaj, Ada Gavrilovska</dc:creator>
    </item>
    <item>
      <title>A Mathematical Framework for the Problem of Security for Cognition in Neurotechnology</title>
      <link>https://arxiv.org/abs/2403.07945</link>
      <description>arXiv:2403.07945v3 Announce Type: replace-cross 
Abstract: The rapid advancement in neurotechnology in recent years has created an emerging critical intersection between neurotechnology and security. Implantable devices, non-invasive monitoring, and non-invasive therapies all carry with them the prospect of violating the privacy and autonomy of individuals' cognition. A growing number of scientists and physicians have made calls to address this issue, but applied efforts have been relatively limited. A major barrier hampering scientific and engineering efforts to address these security issues is the lack of a clear means of describing and analyzing relevant problems. In this paper we develop Cognitive Neurosecurity, a mathematical framework which enables such description and analysis by drawing on methods and results from multiple fields. We demonstrate certain statistical properties which have significant implications for Cognitive Neurosecurity, and then present descriptions of the algorithmic problems faced by attackers attempting to violate privacy and autonomy, and defenders attempting to obstruct such attempts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07945v3</guid>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bryce Allen Bagley, Claudia K Petritsch</dc:creator>
    </item>
    <item>
      <title>Comparative Study of Quantum Transpilers: Evaluating the Performance of qiskit-braket-provider, qBraid-SDK, and Pytket Extensions</title>
      <link>https://arxiv.org/abs/2406.06836</link>
      <description>arXiv:2406.06836v2 Announce Type: replace-cross 
Abstract: In this study, we present a comprehensive evaluation of popular SDK-to-SDK quantum transpilers (that is transpilers that takes a quantum circuit from an initial SDK and output a quantum circuit in another SDK), focusing on critical metrics such as correctness, failure rate, and transpilation time. To ensure unbiased evaluation and accommodate diverse quantum computing scenarios, we developed two dedicated tools: RandomQC, for generating random quantum circuits across various types (pure random, VQE-like, and SDK-specific circuits), and Benchmarq, to streamline the benchmarking process. Using these tools, we benchmarked prominent quantum transpilers as of February 2024. Our results highlight the superior performance of the qiskit-braket-provider, a specialized transpiler from Qiskit to Braket, achieving a remarkably low failure rate of 0.2\%. The qBraid-SDK, offering generalized transpilation across multiple SDKs, demonstrated robust but slower performance. The pytket extensions, while fast, faced limitations with complex circuits due to their one-to-one transpilation approach. In particular, the exceptional performance of the qiskit-bracket-provider stems not only from its specialization but also from its architecture, which combines one-to-one transpilation with gate decomposition for unsupported gates, enhancing both speed and capability. This study aims to provide practical guidelines to users of SDK-to-SDK quantum transpilers and guidance to developers for improving the design and development of future tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06836v2</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohamed Messaoud Louamri, Nacer eddine Belaloui, Abdellah Tounsi, Mohamed Taha Rouabah</dc:creator>
    </item>
    <item>
      <title>GenDFIR: Advancing Cyber Incident Timeline Analysis Through Retrieval Augmented Generation and Large Language Models</title>
      <link>https://arxiv.org/abs/2409.02572</link>
      <description>arXiv:2409.02572v4 Announce Type: replace-cross 
Abstract: Cyber timeline analysis, or forensic timeline analysis, is crucial in Digital Forensics and Incident Response (DFIR). It examines artefacts and events particularly timestamps and metadata to detect anomalies, establish correlations, and reconstruct incident timelines. Traditional methods rely on structured artefacts, such as logs and filesystem metadata, using specialised tools for evidence identification and feature extraction. This paper introduces GenDFIR, a framework leveraging large language models (LLMs), specifically Llama 3.1 8B in zero shot mode, integrated with a Retrieval-Augmented Generation (RAG) agent. Incident data is preprocessed into a structured knowledge base, enabling the RAG agent to retrieve relevant events based on user prompts. The LLM interprets this context, offering semantic enrichment. Tested on synthetic data in a controlled environment, results demonstrate GenDFIR's reliability and robustness, showcasing LLMs potential to automate timeline analysis and advance threat detection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02572v4</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fatma Yasmine Loumachi, Mohamed Chahine Ghanem, Mohamed Amine Ferrag</dc:creator>
    </item>
    <item>
      <title>Quantum Computing for Automotive Applications</title>
      <link>https://arxiv.org/abs/2409.14183</link>
      <description>arXiv:2409.14183v2 Announce Type: replace-cross 
Abstract: Quantum computing could impact various industries, with the automotive industry with many computational challenges, from optimizing supply chains and manufacturing to vehicle engineering, being particularly promising. This chapter investigates state-of-the-art quantum algorithms to enhance efficiency, accuracy, and scalability across the automotive value chain. We explore recent advances in quantum optimization, machine learning, and numerical and chemistry simulations, highlighting their potential and limitations. We identify and discuss key challenges in near-term and fault-tolerant algorithms and their practical use in industrial applications. While quantum algorithms show potential in many application domains, current noisy intermediate-scale quantum hardware limits scale and, thus, business benefits. In the long term, fault-tolerant systems promise theoretical speedups; however, they also require further progress in hardware and software (e.\,g., related to error correction and data loading). We expect that with this progress, significant practical benefits will emerge eventually.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14183v2</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carlos A. Riofr\'io, Johannes Klepsch, Jernej Rudi Fin\v{z}gar, Florian Kiwit, Leonhard H\"olscher, Marvin Erdmann, Lukas M\"uller, Chandan Kumar, Youssef Achari Berrada, Andre Luckow</dc:creator>
    </item>
    <item>
      <title>Pilot-Quantum: A Quantum-HPC Middleware for Resource, Workload and Task Management</title>
      <link>https://arxiv.org/abs/2412.18519</link>
      <description>arXiv:2412.18519v2 Announce Type: replace-cross 
Abstract: As quantum hardware continues to scale, managing the heterogeneity of resources and applications -- spanning diverse quantum and classical hardware and software frameworks -- becomes increasingly critical. Pilot-Quantum addresses these challenges as a middleware designed to provide unified application-level management of resources and workloads across hybrid quantum-classical environments. It is built on a rigorous analysis of existing quantum middleware systems and application execution patterns. It implements the Pilot Abstraction conceptual model, originally developed for HPC, to manage resources, workloads, and tasks. It is designed for quantum applications that rely on task parallelism, including: (i) Hybrid algorithms, such as variational approaches, and (ii) Circuit cutting systems, used to partition and execute large quantum circuits. Pilot-Quantum facilitates seamless integration of quantum processing units (QPUs), classical CPUs, and GPUs, while supporting high-level programming frameworks like Qiskit and Pennylane. This enables users to design and execute hybrid workflows across diverse computing resources efficiently. The capabilities of Pilot-Quantum are demonstrated through mini-applications -- simplified yet representative kernels focusing on critical performance bottlenecks. We present several mini-apps, including circuit execution across hardware and simulator platforms (e.g., IBM's Eagle QPU), distributed state vector simulation, circuit cutting, and quantum machine learning workflows, demonstrating significant scale (e.g., a 41-qubit simulation on 256 GPUs) and speedups (e.g., 15x for QML, 3.5x for circuit cutting).</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18519v2</guid>
      <category>quant-ph</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pradeep Mantha, Florian J. Kiwit, Nishant Saurabh, Shantenu Jha, Andre Luckow</dc:creator>
    </item>
  </channel>
</rss>
