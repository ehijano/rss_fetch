<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>nlin.CD updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/nlin.CD</link>
    <description>nlin.CD updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/nlin.CD" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 12 Mar 2025 04:01:31 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Effects of inertia on the asynchronous state of a disordered Kuramoto model</title>
      <link>https://arxiv.org/abs/2503.08572</link>
      <description>arXiv:2503.08572v1 Announce Type: new 
Abstract: We investigate the role of inertia in the asynchronous state of a disordered Kuramoto model. We extend an iterative simulation scheme to the case of the Kuramoto model with inertia in order to determine the self-consistent fluctuation statistics, specifically, the power spectra of network noise and single oscillators. Comparison with network simulations demonstrates that this works well whenever the system is in an asynchronous state. We also find an unexpected effect when varying the degree of inertia: the correlation time of the oscillators becomes minimal at an intermediate mass of the oscillators; correspondingly, the power spectra appear flatter and thus more similar to white noise around the same value of mass. We also find a similar effect for the Lyapunov spectra of the oscillators when the mass is varied.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08572v1</guid>
      <category>nlin.CD</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>stat.CO</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yagmur Kati, Ralf Toenjes, Benjamin Lindner</dc:creator>
    </item>
    <item>
      <title>Bypassing eigenstate thermalization with experimentally accessible quantum dynamics</title>
      <link>https://arxiv.org/abs/2503.07729</link>
      <description>arXiv:2503.07729v1 Announce Type: cross 
Abstract: Eigenstate thermalization has played a prominent role as a determiner of the validity of quantum statistical mechanics since von Neumann's early works on quantum ergodicity. However, its connection to the dynamical process of quantum thermalization relies sensitively on nondegeneracy properties of the energy spectrum, as well as detailed features of individual eigenstates that are effective only over correspondingly large timescales, rendering it generically inaccessible given practical timescales and finite experimental resources. Here, we introduce the notion of energy-band thermalization to address these limitations, which coarse-grains over energy level spacings with a finite energy resolution. We show that energy-band thermalization implies the thermalization of an observable in almost all physical states over accessible timescales without relying on microscopic properties of the energy eigenvalues or eigenstates, and conversely, can be efficiently accessed in experiments via the dynamics of a single initial state (for a given observable) with only polynomially many resources in the system size. This allows us to directly determine thermalization, including in the presence of conserved charges, from this state: Most strikingly, if an observable thermalizes in this initial state over a finite range of times, then it must thermalize in almost all physical initial states over all longer timescales. As applications, we derive a finite-time Mazur-Suzuki inequality for quantum transport with approximately conserved charges, and establish the thermalization of local observables over finite timescales in almost all accessible states in (generally inhomogeneous) dual-unitary quantum circuits. We also propose measurement protocols for general many-qubit systems. This work initiates a rigorous treatment of quantum thermalization in terms of experimentally accessible quantities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07729v1</guid>
      <category>quant-ph</category>
      <category>cond-mat.stat-mech</category>
      <category>hep-th</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>nlin.CD</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amit Vikram</dc:creator>
    </item>
    <item>
      <title>Freezing chaos without synaptic plasticity</title>
      <link>https://arxiv.org/abs/2503.08069</link>
      <description>arXiv:2503.08069v1 Announce Type: cross 
Abstract: Chaos is ubiquitous in high-dimensional neural dynamics. A strong chaotic fluctuation may be harmful to information processing. A traditional way to mitigate this issue is to introduce Hebbian plasticity, which can stabilize the dynamics. Here, we introduce another distinct way without synaptic plasticity. An Onsager reaction term due to the feedback of the neuron itself is added to the vanilla recurrent dynamics, making the driving force a gradient form. The original unstable fixed points supporting the chaotic fluctuation can then be approached by further decreasing the kinetic energy of the dynamics. We show that this freezing effect also holds in more biologically realistic networks, such as those composed of excitatory and inhibitory neurons. The gradient dynamics are also useful for computational tasks such as recalling or predicting external time-dependent stimuli.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08069v1</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.NE</category>
      <category>nlin.CD</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Weizhong Huang, Haiping Huang</dc:creator>
    </item>
    <item>
      <title>Nonlinear optimals and their role in sustaining turbulence in channel flow</title>
      <link>https://arxiv.org/abs/2503.08283</link>
      <description>arXiv:2503.08283v1 Announce Type: cross 
Abstract: We investigate the energy transfer from the mean profile to velocity fluctuations in channel flow by calculating nonlinear optimal disturbances,i.e. the initial condition of a given finite energy that achieves the highest possible energy growth during a given fixed time horizon. It is found that for a large range of time horizons and initial disturbance energies, the nonlinear optimal exhibits streak spacing and amplitude consistent with DNS at least at Re_tau = 180, which suggests that they isolate the relevant physical mechanisms that sustain turbulence. Moreover, the time horizon necessary for a nonlinear disturbance to outperform a linear optimal is consistent with previous DNS-based estimates using eddy turnover time, which offers a new perspective on how some turbulent time scales are determined.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08283v1</guid>
      <category>physics.flu-dyn</category>
      <category>cs.CE</category>
      <category>math.OC</category>
      <category>nlin.CD</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Dario Klingenberg, Rich R. Kerswell</dc:creator>
    </item>
    <item>
      <title>Inductively coupled Josephson junctions: a platform for rich neuromorphic dynamics</title>
      <link>https://arxiv.org/abs/2501.03385</link>
      <description>arXiv:2501.03385v3 Announce Type: replace 
Abstract: Josephson junctions (JJs) are by nature neuromorphic hardware devices capable of mimicking excitability and spiking dynamics. When coupled together or combined with other superconducting elements, they can emulate additional behaviors found in biological neurons. From a technological point of view, JJ-based neuromorphic systems are particularly appealing since they present THz-speed processing and they operate with near-zero power dissipation. In this work we study a system of inductively coupled JJs and focus on the nonlinear dynamical aspects of its neurocomputational properties. In particular, we report on spiking behavior related to a saddle-node off invariant cycle bifurcation and excitability type 2, synchronization, first spike latency effects, and multistability. Special emphasis is placed on the bursting dynamics the system is capable of reproducing, and a new underlying mechanism is proposed beyond the approach followed in prior works.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03385v3</guid>
      <category>nlin.CD</category>
      <category>cond-mat.supr-con</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>G. Baxevanis, J. Hizanidis</dc:creator>
    </item>
    <item>
      <title>Machine Learning for Predicting Chaotic Systems</title>
      <link>https://arxiv.org/abs/2407.20158</link>
      <description>arXiv:2407.20158v3 Announce Type: replace-cross 
Abstract: Predicting chaotic dynamical systems is critical in many scientific fields, such as weather forecasting, but challenging due to the characteristic sensitive dependence on initial conditions. Traditional modeling approaches require extensive domain knowledge, often leading to a shift towards data-driven methods using machine learning. However, existing research provides inconclusive results on which machine learning methods are best suited for predicting chaotic systems. In this paper, we compare different lightweight and heavyweight machine learning architectures using extensive existing benchmark databases, as well as a newly introduced database that allows for uncertainty quantification in the benchmark results. In addition to state-of-the-art methods from the literature, we also present new advantageous variants of established methods. Hyperparameter tuning is adjusted based on computational cost, with more tuning allocated to less costly methods. Furthermore, we introduce the cumulative maximum error, a novel metric that combines desirable properties of traditional metrics and is tailored for chaotic systems. Our results show that well-tuned simple methods, as well as untuned baseline methods, often outperform state-of-the-art deep learning models, but their performance can vary significantly with different experimental setups. These findings highlight the importance of aligning prediction methods with data characteristics and caution against the indiscriminate use of overly complex models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20158v3</guid>
      <category>cs.LG</category>
      <category>nlin.CD</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christof Sch\"otz, Alistair White, Maximilian Gelbrecht, Niklas Boers</dc:creator>
    </item>
  </channel>
</rss>
