<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 13 May 2025 09:32:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>RAAC panels can suddenly collapse before any warning of corrosion-induced surface cracking</title>
      <link>https://arxiv.org/abs/2505.06294</link>
      <description>arXiv:2505.06294v1 Announce Type: new 
Abstract: The collapse of reinforced autoclaved aerated concrete (RAAC) panels has attracted considerable public and academic interest. As detailed experimental data are not yet available and replicating the natural corrosion process requires years or decades, computational modelling is essential to understand under which conditions corrosion remains concealed. The very high porosity of RAAC is widely suspected to be a major contributing factor. However, current corrosion-induced cracking models are known to struggle with capturing the role of concrete porosity. To remedy this critical deficiency, we propose to enrich corrosion-induced cracking modelling with the analytical solution of reactive transport equations governing the precipitation of rust and a porosity-dependent description of diffusivity. With this, the corrosion concealment in RAAC panels is studied computationally for the first time, revealing that RAAC panels can suddenly collapse before any warning of corrosion-induced surface cracking and allowing to map the conditions most likely to result in sudden collapse.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06294v1</guid>
      <category>cs.CE</category>
      <category>cond-mat.mtrl-sci</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>E. Korec, P. Grassl, M. Jirasek, H. S. Wong, E. Mart\'inez-Pa\~neda</dc:creator>
    </item>
    <item>
      <title>A New DAPO Algorithm for Stock Trading</title>
      <link>https://arxiv.org/abs/2505.06408</link>
      <description>arXiv:2505.06408v1 Announce Type: new 
Abstract: Recent advances in reinforcement learning, such as Dynamic Sampling Policy Optimization (DAPO), show strong performance when paired with large language models (LLMs). Motivated by this success, we ask whether similar gains can be realized in financial trading. We design a trading agent that combines an improved Group Relative Policy Optimization (GRPO) algorithm, augmented with ideas from DAPO, with LLM-based risk and sentiment signals extracted from financial news. On the NASDAQ-100 index (FNSPID dataset), our agent attains a cumulative return of 230.49 percent and an information ratio of 0.37, outperforming the CPPO-DeepSeek baseline. It also cuts training time from about 8 hours to 2.5 hours over 100 epochs while markedly reducing RAM usage. The proposed RL-LLM framework offers a scalable path toward data-efficient trading agents. Code: https://github.com/Ruijian-Zha/FinRL-DAPO-SR/</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06408v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruijian Zha, Bojun Liu</dc:creator>
    </item>
    <item>
      <title>Energy-Efficient Ternary Encoding for High-Speed Data Transmission in 3D-Integrated Circuits Using Inductive Coupling Links</title>
      <link>https://arxiv.org/abs/2505.06908</link>
      <description>arXiv:2505.06908v1 Announce Type: new 
Abstract: This paper proposes a ternary signalling scheme for inductive coupling links (ICLs) in 3D-integrated circuits (3D-ICs) to reduce crosstalk and electromagnetic interference in multi-stacked chip communications. By converting binary data into ternary sequences with three voltage levels (-V, 0V, +V), the approach enhances signal separation, reduces crosstalk, and improves signal integrity. Unlike traditional Non-Return to Zero (NRZ) systems, the ternary scheme increases bandwidth efficiency and reduces power consumption through fewer signal transitions. A modified H-Bridge transmitter generates ternary symbols by controlling current flow based on binary-to-ternary mapping. Preliminary simulations validate the efficiency of the scheme, showing reduced power consumption and higher data rates compared to NRZ. This approach shows promise for high-performance computing and IoT devices in 3D-IC environments, offering enhanced noise resilience, lower power usage, and improved communication efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06908v1</guid>
      <category>cs.CE</category>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abdullah Saeed Alghotmi</dc:creator>
    </item>
    <item>
      <title>A comparative study of Bitcoin and Ripple cryptocurrencies trading using Deep Reinforcement Learning algorithms</title>
      <link>https://arxiv.org/abs/2505.07660</link>
      <description>arXiv:2505.07660v1 Announce Type: new 
Abstract: Artificial intelligence (AI) has demonstrated remarkable success across various applications. In light of this trend, the field of automated trading has developed a keen interest in leveraging AI techniques to forecast the future prices of financial assets. This interest stems from the need to address trading challenges posed by the inherent volatility and dynamic nature of asset prices. However, crafting a flawless strategy becomes a formidable task when dealing with assets characterized by intricate and ever-changing price dynamics. To surmount these formidable challenges, this research employs an innovative rule-based strategy approach to train Deep Reinforcement Learning (DRL). This application is carried out specifically in the context of trading Bitcoin (BTC) and Ripple (XRP). Our proposed approach hinges on the integration of Deep Q-Network, Double Deep Q-Network, Dueling Deep Q-learning networks, alongside the Advantage Actor-Critic algorithms. Each of them aims to yield an optimal policy for our application. To evaluate the effectiveness of our Deep Reinforcement Learning (DRL) approach, we rely on portfolio wealth and the trade signal as performance metrics. The experimental outcomes highlight that Duelling and Double Deep Q-Network outperformed when using XRP with the increasing of the portfolio wealth. All codes are available in this \href{https://github.com/VerlonRoelMBINGUI/RL_Final_Projects_AMMI2023}{\color{blue}Github link}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07660v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Dieu-Donne Fangnon, Armandine Sorel Kouyim Meli, Verlon Roel Mbingui, Phanie Dianelle Negho, Regis Konan Marcel Djaha</dc:creator>
    </item>
    <item>
      <title>ALFEE: Adaptive Large Foundation Model for EEG Representation</title>
      <link>https://arxiv.org/abs/2505.06291</link>
      <description>arXiv:2505.06291v1 Announce Type: cross 
Abstract: While foundation models excel in text, image, and video domains, the critical biological signals, particularly electroencephalography(EEG), remain underexplored. EEG benefits neurological research with its high temporal resolution, operational practicality, and safety profile. However, low signal-to-noise ratio, inter-subject variability, and cross-paradigm differences hinder the generalization of current models. Existing methods often employ simplified strategies, such as a single loss function or a channel-temporal joint representation module, and suffer from a domain gap between pretraining and evaluation tasks that compromises efficiency and adaptability. To address these limitations, we propose the Adaptive Large Foundation model for EEG signal representation(ALFEE) framework, a novel hybrid transformer architecture with two learning stages for robust EEG representation learning. ALFEE employs a hybrid attention that separates channel-wise feature aggregation from temporal dynamics modeling, enabling robust EEG representation with variable channel configurations. A channel encoder adaptively compresses variable channel information, a temporal encoder captures task-guided evolution, and a hybrid decoder reconstructs signals in both temporal and frequency domains. During pretraining, ALFEE optimizes task prediction, channel and temporal mask reconstruction, and temporal forecasting to enhance multi-scale and multi-channel representation. During fine-tuning, a full-model adaptation with a task-specific token dictionary and a cross-attention layer boosts performance across multiple tasks. After 25,000 hours of pretraining, extensive experimental results on six downstream EEG tasks demonstrate the superior performance of ALFEE over existing models. Our ALFEE framework establishes a scalable foundation for biological signal analysis with implementation at https://github.com/xw1216/ALFEE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06291v1</guid>
      <category>eess.SP</category>
      <category>cs.CE</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wei Xiong, Junming Lin, Jiangtong Li, Jie Li, Changjun Jiang</dc:creator>
    </item>
    <item>
      <title>PC-SRGAN: Physically Consistent Super-Resolution Generative Adversarial Network for General Transient Simulations</title>
      <link>https://arxiv.org/abs/2505.06502</link>
      <description>arXiv:2505.06502v1 Announce Type: cross 
Abstract: Machine Learning, particularly Generative Adversarial Networks (GANs), has revolutionised Super Resolution (SR). However, generated images often lack physical meaningfulness, which is essential for scientific applications. Our approach, PC-SRGAN, enhances image resolution while ensuring physical consistency for interpretable simulations. PC-SRGAN significantly improves both the Peak Signal-to-Noise Ratio and the Structural Similarity Index Measure compared to conventional methods, even with limited training data (e.g., only 13% of training data required for SRGAN). Beyond SR, PC-SRGAN augments physically meaningful machine learning, incorporating numerically justified time integrators and advanced quality metrics. These advancements promise reliable and causal machine-learning models in scientific domains. A significant advantage of PC-SRGAN over conventional SR techniques is its physical consistency, which makes it a viable surrogate model for time-dependent problems. PC-SRGAN advances scientific machine learning, offering improved accuracy and efficiency for image processing, enhanced process understanding, and broader applications to scientific research. The source codes and data will be made publicly available at https://github.com/hasan-rakibul/PC-SRGAN upon acceptance of this paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06502v1</guid>
      <category>eess.IV</category>
      <category>cs.CE</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Md Rakibul Hasan, Pouria Behnoudfar, Dan MacKinlay, Thomas Poulet</dc:creator>
    </item>
    <item>
      <title>Decoding Futures Price Dynamics: A Regularized Sparse Autoencoder for Interpretable Multi-Horizon Forecasting and Factor Discovery</title>
      <link>https://arxiv.org/abs/2505.06795</link>
      <description>arXiv:2505.06795v1 Announce Type: cross 
Abstract: Commodity price volatility creates economic challenges, necessitating accurate multi-horizon forecasting. Predicting prices for commodities like copper and crude oil is complicated by diverse interacting factors (macroeconomic, supply/demand, geopolitical, etc.). Current models often lack transparency, limiting strategic use. This paper presents a Regularized Sparse Autoencoder (RSAE), a deep learning framework for simultaneous multi-horizon commodity price prediction and discovery of interpretable latent market drivers. The RSAE forecasts prices at multiple horizons (e.g., 1-day, 1-week, 1-month) using multivariate time series. Crucially, L1 regularization ($\|\mathbf{z}\|_1$) on its latent vector $\mathbf{z}$ enforces sparsity, promoting parsimonious explanations of market dynamics through learned factors representing underlying drivers (e.g., demand, supply shocks). Drawing from energy-based models and sparse coding, the RSAE optimizes predictive accuracy while learning sparse representations. Evaluated on historical Copper and Crude Oil data with numerous indicators, our findings indicate the RSAE offers competitive multi-horizon forecasting accuracy and data-driven insights into price dynamics via its interpretable latent space, a key advantage over traditional black-box approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06795v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Abhijit Gupta</dc:creator>
    </item>
    <item>
      <title>Can LLM-based Financial Investing Strategies Outperform the Market in Long Run?</title>
      <link>https://arxiv.org/abs/2505.07078</link>
      <description>arXiv:2505.07078v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) have recently been leveraged for asset pricing tasks and stock trading applications, enabling AI agents to generate investment decisions from unstructured financial data. However, most evaluations of LLM timing-based investing strategies are conducted on narrow timeframes and limited stock universes, overstating effectiveness due to survivorship and data-snooping biases. We critically assess their generalizability and robustness by proposing FINSABER, a backtesting framework evaluating timing-based strategies across longer periods and a larger universe of symbols. Systematic backtests over two decades and 100+ symbols reveal that previously reported LLM advantages deteriorate significantly under broader cross-section and over a longer-term evaluation. Our market regime analysis further demonstrates that LLM strategies are overly conservative in bull markets, underperforming passive benchmarks, and overly aggressive in bear markets, incurring heavy losses. These findings highlight the need to develop LLM strategies that are able to prioritise trend detection and regime-aware risk controls over mere scaling of framework complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07078v1</guid>
      <category>q-fin.TR</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weixian Waylon Li, Hyeonjun Kim, Mihai Cucuringu, Tiejun Ma</dc:creator>
    </item>
    <item>
      <title>Simulating many-engine spacecraft: Exceeding 100 trillion grid points via information~geometric regularization and the MFC flow solver</title>
      <link>https://arxiv.org/abs/2505.07392</link>
      <description>arXiv:2505.07392v1 Announce Type: cross 
Abstract: This work proposes a method and optimized implementation for exascale simulations of high-speed compressible fluid flows, enabling the simulation of multi-engine rocket craft at an unprecedented scale. We significantly improve upon the state-of-the-art in terms of computational cost and memory footprint through a carefully crafted implementation of the recently proposed information geometric regularization, which eliminates the need for numerical shock capturing. Unified addressing on tightly coupled CPU--GPU platforms increases the total problem size with negligible performance hit. Despite linear stencil algorithms being memory-bound, we achieve wall clock times that are four times faster than optimized baseline numerics. This enables the execution of CFD simulations at more than 100 trillion grid points, surpassing the largest state-of-the-art publicly available simulations by an order of magnitude. Ideal weak scaling is demonstrated on OLCF Frontier and CSCS Alps using the full system, entailing 37.8K AMD MI250X GPUs (Frontier) or 9.2K NVIDIA GH200 superchips (Alps).</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07392v1</guid>
      <category>physics.comp-ph</category>
      <category>cs.CE</category>
      <category>physics.flu-dyn</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin Wilfong, Anand Radhakrishnan, Henry Le Berre, Nikolaos Tselepidis, Benedikt Dorschner, Reuben Budiardja, Brian Cornille, Stephen Abbott, Florian Sch\"afer, Spencer H. Bryngelson</dc:creator>
    </item>
    <item>
      <title>Transient Nonlinear Electrothermal Adjoint Sensitivity Analysis for HVDC Cable Joints</title>
      <link>https://arxiv.org/abs/2405.14284</link>
      <description>arXiv:2405.14284v3 Announce Type: replace 
Abstract: Efficient computation of sensitivities is a promising approach for efficiently of designing and optimizing high voltage direct current cable joints. This paper presents the adjoint variable method for coupled nonlinear transient electrothermal problems as an efficient approach to compute sensitivities with respect to a large number of design parameters. The method is used to compute material sensitivities of a 320kV high voltage direct current cable joint specimen. The results are validated against sensitivities obtained via the direct sensitivity method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14284v3</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1002/jnm.70035</arxiv:DOI>
      <arxiv:journal_reference>International Journal of Numerical Modelling: Electronic Networks, Devices and Fields, Volume 38, Issue 3, May/June 2025, first published 28th April 2025</arxiv:journal_reference>
      <dc:creator>M. Greta Ruppert, Yvonne Sp\"ack-Leigsnering, Herbert De Gersem</dc:creator>
    </item>
    <item>
      <title>Martinize2 and Vermouth: Unified Framework for Topology Generation</title>
      <link>https://arxiv.org/abs/2212.01191</link>
      <description>arXiv:2212.01191v4 Announce Type: replace-cross 
Abstract: Ongoing advances in force field and computer hardware development enable the use of molecular dynamics (MD) to simulate increasingly complex systems with the ultimate goal of reaching cellular complexity. At the same time, rational design by high-throughput (HT) simulations is another forefront of MD. In these areas, the Martini coarse-grained force field, especially the latest version (i.e. v3), is being actively explored because it offers an enhanced spatial-temporal resolution. However, the automation tools for preparing simulations with the Martini force field, accompanying the previous version, were not designed for HT simulations or studies of complex cellular systems. Therefore, they become a major limiting factor. To address these shortcomings, we present the open-source Vermouth python library. Vermouth is designed to become the unified framework for developing programs, which prepare, run, and analyze Martini simulations of complex systems. To demonstrate the power of the Vermouth library, the Martinize2 program is showcased as a generalization of the martinize script, originally aimed to set up simulations of proteins. In contrast to the previous version, Martinize2 automatically handles protonation states in proteins and post-translation modifications, offers more options to fine-tune structural biases such as the elastic network (EN), and can convert non-protein molecules such as ligands. Finally, Martinize2 is used in two high-complexity benchmarks. The entire I-TASSER protein template database as well as a subset of 200,000 structures from the AlphaFold Protein Structure Database are converted to CG resolution and we illustrate how the checks on input structure quality can safeguard high-throughput applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.01191v4</guid>
      <category>q-bio.QM</category>
      <category>cond-mat.other</category>
      <category>cs.CE</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peter C. Kroon, Fabian Gr\"unewald, Jonathan Barnoud, Marco van Tilburg, Chris Brasnett, Paulo C. T. Souza, Tsjerk A. Wassenaar, Siewert-Jan Marrink</dc:creator>
    </item>
    <item>
      <title>LSR-IGRU: Stock Trend Prediction Based on Long Short-Term Relationships and Improved GRU</title>
      <link>https://arxiv.org/abs/2409.08282</link>
      <description>arXiv:2409.08282v3 Announce Type: replace-cross 
Abstract: Stock price prediction is a challenging problem in the field of finance and receives widespread attention. In recent years, with the rapid development of technologies such as deep learning and graph neural networks, more research methods have begun to focus on exploring the interrelationships between stocks. However, existing methods mostly focus on the short-term dynamic relationships of stocks and directly integrating relationship information with temporal information. They often overlook the complex nonlinear dynamic characteristics and potential higher-order interaction relationships among stocks in the stock market. Therefore, we propose a stock price trend prediction model named LSR-IGRU in this paper, which is based on long short-term stock relationships and an improved GRU input. Firstly, we construct a long short-term relationship matrix between stocks, where secondary industry information is employed for the first time to capture long-term relationships of stocks, and overnight price information is utilized to establish short-term relationships. Next, we improve the inputs of the GRU model at each step, enabling the model to more effectively integrate temporal information and long short-term relationship information, thereby significantly improving the accuracy of predicting stock trend changes. Finally, through extensive experiments on multiple datasets from stock markets in China and the United States, we validate the superiority of the proposed LSR-IGRU model over the current state-of-the-art baseline models. We also apply the proposed model to the algorithmic trading system of a financial company, achieving significantly higher cumulative portfolio returns compared to other baseline methods. Our sources are released at https://github.com/ZP1481616577/Baselines_LSR-IGRU.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08282v3</guid>
      <category>q-fin.ST</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peng Zhu, Yuante Li, Yifan Hu, Qinyuan Liu, Dawei Cheng, Yuqi Liang</dc:creator>
    </item>
    <item>
      <title>Towards Equitable Rail Service Allocation Through Fairness-Oriented Timetabling in Liberalized Markets</title>
      <link>https://arxiv.org/abs/2504.17489</link>
      <description>arXiv:2504.17489v2 Announce Type: replace-cross 
Abstract: Over the last few decades, European rail transport has undergone major changes as part of the process of liberalization set out in European regulations. In this context of liberalization, railway undertakings compete with each other for the limited infrastructure capacity available to offer their rail services. The infrastructure manager is responsible for the equitable allocation of infrastructure between all companies in the market, which is essential to ensure the efficiency and sustainability of this competitive ecosystem. In this paper, a methodology based on Jain, Gini and Atkinson equity metrics is used to solve the rail service allocation problem in a liberalized railway market, analyzing the solutions obtained. The results show that the proposed methodology and the equity metrics used allow for equitable planning in different competitiveness scenarios. These results contrast with solutions where the objective of the infrastructure manager is to maximize its own profit, without regard for the equitable allocation of infrastructure. Therefore, the computational tests support the methodology and metrics used as a planning and decision support tool in a liberalized railway market.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17489v2</guid>
      <category>cs.NE</category>
      <category>cs.CE</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Mu\~noz-Valero, Juan Moreno-Garcia, Julio Alberto L\'opez-G\'omez, Enrique Adrian Villarrubia-Martin</dc:creator>
    </item>
  </channel>
</rss>
