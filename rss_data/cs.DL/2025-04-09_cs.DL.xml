<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DL</link>
    <description>cs.DL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 09 Apr 2025 04:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Comparative Analysis of Modeling Approaches for the Association of FAIR Digital Objects Operations</title>
      <link>https://arxiv.org/abs/2504.05361</link>
      <description>arXiv:2504.05361v1 Announce Type: new 
Abstract: The concept of FAIR Digital Objects represents a foundational step towards realizing machine-actionable, interoperable data infrastructures across scientific and industrial domains. As digital spaces become increasingly heterogeneous, scalable mechanisms for data processing and interpretability are essential. This paper provides a comparative analysis of various typing mechanisms to associate FAIR Digital Objects with their operations, addressing the pressing need for a structured approach to manage data interactions within the FAIR Digital Objects ecosystem. By examining three core models -- record typing, profile typing, and attribute typing -- this work evaluates each model's complexity, flexibility, versatility, and interoperability, shedding light on their strengths and limitations. With this assessment, we aim to offer insights for adopting FDO frameworks that enhance data automation and promote the seamless exchange of digital resources across domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05361v1</guid>
      <category>cs.DL</category>
      <category>cs.DB</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas Blumenr\"ohr, Jana B\"ohm, Philipp Ost, Marco Kul\"uke, Peter Wittenburg, Christophe Blanchi, Sven Bingert, Ulrich Schwardmann</dc:creator>
    </item>
    <item>
      <title>Rethinking Review Citations: Impact on Scientific Integrity</title>
      <link>https://arxiv.org/abs/2504.05905</link>
      <description>arXiv:2504.05905v1 Announce Type: new 
Abstract: The proliferation of surveys and review articles in academic journals has impacted citation metrics like impact factor and h-index, skewing evaluations of journal and researcher quality. This work investigates the implications of this trend, focusing on the field of Computer Science, where a notable increase in review publications has led to inflated citation counts and rankings. While reviews serve as valuable literature overviews, they should not overshadow the primary goal of research -to advance scientific knowledge through original contributions. We advocate for prioritizing citations of primary research in journal articles to uphold citation integrity and ensure fair recognition of substantive contributions. This approach preserves the reliability of citation-based metrics and supports genuine scientific advancement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05905v1</guid>
      <category>cs.DL</category>
      <category>cs.CY</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jesus S. Aguilar-Ruiz</dc:creator>
    </item>
    <item>
      <title>A Knowledge Base for Arts and Inclusion -- The Dataverse data archival platform as a knowledge base management system enabling multimodal accessibility</title>
      <link>https://arxiv.org/abs/2504.05976</link>
      <description>arXiv:2504.05976v1 Announce Type: new 
Abstract: Creating an inclusive art environment requires engaging multiple senses for a fully immersive experience. Culture is inherently synesthetic, enriched by all senses within a shared time and space. In an optimal synesthetic setting, people of all abilities can connect meaningfully; when one sense is compromised, other channels can be enhanced to compensate. This is the power of multimodality. Digital technology is increasingly able to capture aspects of multimodality. To document multimodality aspects of cultural practices and products for the long-term remains a challenge. Many artistic products from the performing arts tend to be multimodal, and are often immersive, so only a multimodal repository can offer a platform for this work. To our knowledge there is no single, comprehensive repository with a knowledge base to serve arts and disability. By knowledge base, we mean classifications, taxonomies, or ontologies (in short, knowledge organisation systems). This paper presents innovative ways to develop a knowledge base which capture multimodal features of archived representations of cultural assets, but also indicate various forms how to interact with them including machine-readable description. We will demonstrate how back-end and front-end applications, in a combined effort, can support accessible archiving and data management for complex digital objects born out of artistic practices and make them available for wider audiences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05976v1</guid>
      <category>cs.DL</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Moa Johansson, Vyacheslav Tykhonov, Sophia Alexandersson, Kim Ferguson, James Hanlon, Andrea Scharnhorst, Nigel Osborne</dc:creator>
    </item>
    <item>
      <title>Automated Archival Descriptions with Federated Intelligence of LLMs</title>
      <link>https://arxiv.org/abs/2504.05711</link>
      <description>arXiv:2504.05711v1 Announce Type: cross 
Abstract: Enforcing archival standards requires specialized expertise, and manually creating metadata descriptions for archival materials is a tedious and error-prone task. This work aims at exploring the potential of agentic AI and large language models (LLMs) in addressing the challenges of implementing a standardized archival description process. To this end, we introduce an agentic AI-driven system for automated generation of high-quality metadata descriptions of archival materials. We develop a federated optimization approach that unites the intelligence of multiple LLMs to construct optimal archival metadata. We also suggest methods to overcome the challenges associated with using LLMs for consistent metadata generation. To evaluate the feasibility and effectiveness of our techniques, we conducted extensive experiments using a real-world dataset of archival materials, which covers a variety of document types and data formats. The evaluation results demonstrate the feasibility of our techniques and highlight the superior performance of the federated optimization approach compared to single-model solutions in metadata quality and reliability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05711v1</guid>
      <category>cs.AI</category>
      <category>cs.DL</category>
      <category>cs.IR</category>
      <category>cs.LG</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jinghua Groppe, Andreas Marquet, Annabel Walz, Sven Groppe</dc:creator>
    </item>
    <item>
      <title>Old Experience Helps: Leveraging Survey Methodology to Improve AI Text Annotation Reliability in Social Sciences</title>
      <link>https://arxiv.org/abs/2502.19679</link>
      <description>arXiv:2502.19679v3 Announce Type: replace 
Abstract: This paper introduces a framework for assessing the reliability of Large Language Model (LLM) text annotations in social science research by adapting established survey methodology principles. Drawing parallels between survey respondent behavior and LLM outputs, the study implements three key interventions: option randomization, position randomization, and reverse validation. While traditional accuracy metrics may mask model instabilities, particularly in edge cases, the framework provides a more comprehensive reliability assessment. Using the F1000 dataset in biomedical science and three sizes of Llama models (8B, 70B, and 405B parameters), the paper demonstrates that these survey-inspired interventions can effectively identify unreliable annotations that might otherwise go undetected through accuracy metrics alone. The results show that 5-25% of LLM annotations change under these interventions, with larger models exhibiting greater stability. Notably, for rare categories approximately 50% of "correct" annotations demonstrate low reliability when subjected to this framework. The paper then introduce an information-theoretic reliability score (R-score) based on Kullback-Leibler divergence that quantifies annotation confidence and distinguishes between random guessing and meaningful annotations at the case level. This approach complements existing expert validation methods by providing a scalable way to assess internal annotation reliability and offers practical guidance for prompt design and downstream analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.19679v3</guid>
      <category>cs.DL</category>
      <category>cs.HC</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Linzhuo li</dc:creator>
    </item>
  </channel>
</rss>
