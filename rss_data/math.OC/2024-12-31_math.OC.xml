<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 31 Dec 2024 05:00:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Asymptotic behavior of Carleman weight functions</title>
      <link>https://arxiv.org/abs/2412.19892</link>
      <description>arXiv:2412.19892v1 Announce Type: new 
Abstract: This work aims to establish the asymptotic behavior of Carleman weight functions when discrete difference and average operators are applied. We provide a characterization of the error term in arbitrary order and dimension, extending previously known results. This generalization is of independent interest due to its applications in deriving discrete deterministic and stochastic Carleman estimates where the asymptotic behavior of the Carleman weight functions is crucial. The aforementioned asymptotic behavior holds for Carleman weight functions used for parabolic, hyperbolic, and elliptic operators, which are applied to obtain control and inverse problems results for those operators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19892v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ariel A. P\'erez</dc:creator>
    </item>
    <item>
      <title>Stochastic optimization over expectation-formulated generalized Stiefel manifold</title>
      <link>https://arxiv.org/abs/2412.20008</link>
      <description>arXiv:2412.20008v1 Announce Type: new 
Abstract: In this paper, we consider a class of stochastic optimization problems over the expectation-formulated generalized Stiefel manifold (SOEGS), where the objective function $f$ is continuously differentiable. We propose a novel constraint dissolving penalty function with a customized penalty term (CDFDP), which maintains the same order of differentiability as $f$. Our theoretical analysis establishes the global equivalence between CDFCP and SOEGS in the sense that they share the same first-order and second-order stationary points under mild conditions. These results on equivalence enable the direct implementation of various stochastic optimization approaches to solve SOEGS. In particular, we develop a stochastic gradient algorithm and its accelerated variant by incorporating an adaptive step size strategy. Furthermore, we prove their $\mathcal{O}(\varepsilon^{-4})$ sample complexity for finding an $\varepsilon$-stationary point of CDFCP. Comprehensive numerical experiments show the efficiency and robustness of our proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20008v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Linshuo Jiang, Nachuan Xiao, Xin Liu</dc:creator>
    </item>
    <item>
      <title>Global Search of Optimal Spacecraft Trajectories using Amortization and Deep Generative Models</title>
      <link>https://arxiv.org/abs/2412.20023</link>
      <description>arXiv:2412.20023v1 Announce Type: new 
Abstract: Preliminary spacecraft trajectory optimization is a parameter dependent global search problem that aims to provide a set of solutions that are of high quality and diverse. In the case of numerical solution, it is dependent on the original optimal control problem, the choice of a control transcription, and the behavior of a gradient based numerical solver. In this paper we formulate the parameterized global search problem as the task of sampling a conditional probability distribution with support on the neighborhoods of local basins of attraction to the high quality solutions. The conditional distribution is learned and represented using deep generative models that allow for prediction of how the local basins change as parameters vary. The approach is benchmarked on a low thrust spacecraft trajectory optimization problem in the circular restricted three-body problem, showing significant speed-up over a simple multi-start method and vanilla machine learning approaches. The paper also provides an in-depth analysis of the multi-modal funnel structure of a low-thrust spacecraft trajectory optimization problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20023v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryne Beeson, Anjian Li, Amlan Sinha</dc:creator>
    </item>
    <item>
      <title>Insights into Efficiency and Satisfaction Trade-offs in Facility Location Problems with Regional Preferences</title>
      <link>https://arxiv.org/abs/2412.20074</link>
      <description>arXiv:2412.20074v1 Announce Type: new 
Abstract: This paper studies a practical regional demand continuous multifacility location problems whose main goal is to locate a given number of services and entry points in each region to distribute certain products to the users at minimum transportation cost. Additionally, a minimum satisfaction level is required for the customers in each region. This satisfaction is measured through continuous preference functions that reflect the satisfaction degree of each location in the region. We provide a mathematical optimization-based framework for the problem and derive suitable Mixed Integer Second Order Cone optimization models for some interesting situations: norm-based transportation costs for the services to the entry points, and different families of preference functions. Among these preference functions, we highlight those derived from economic production models and distance-based preferences. We conduct an extensive computational study along two main lines: a computational approach, where we provide optimal solutions for up to 500 demand regions in the single-facility case and up to $50$ for the p-facility case; and a qualitative approach, where we analyze whether the incorporation of preferences is statistically significant compared to the case without preferences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20074v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>V\'ictor Blanco, Ricardo G\'azquez, Marina Leal</dc:creator>
    </item>
    <item>
      <title>Gradient Descent Methods for Regularized Optimization</title>
      <link>https://arxiv.org/abs/2412.20115</link>
      <description>arXiv:2412.20115v1 Announce Type: new 
Abstract: Regularization is a widely recognized technique in mathematical optimization. It can be used to smooth out objective functions, refine the feasible solution set, or prevent overfitting in machine learning models. Due to its simplicity and robustness, the gradient descent (GD) method is one of the primary methods used for numerical optimization of differentiable objective functions. However, GD is not well-suited for solving $\ell^1$ regularized optimization problems since these problems are non-differentiable at zero, causing iteration updates to oscillate or fail to converge. Instead, a more effective version of GD, called the proximal gradient descent employs a technique known as soft-thresholding to shrink the iteration updates toward zero, thus enabling sparsity in the solution. Motivated by the widespread applications of proximal GD in sparse and low-rank recovery across various engineering disciplines, we provide an overview of the GD and proximal GD methods for solving regularized optimization problems. Furthermore, this paper proposes a novel algorithm for the proximal GD method that incorporates a variable step size. Unlike conventional proximal GD, which uses a fixed step size based on the global Lipschitz constant, our method estimates the Lipschitz constant locally at each iteration and uses its reciprocal as the step size. This eliminates the need for a global Lipschitz constant, which can be impractical to compute. Numerical experiments we performed on synthetic and real-data sets show notable performance improvement of the proposed method compared to the conventional proximal GD with constant step size, both in terms of number of iterations and in time requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20115v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Filip Nikolovski, Irena Stojkovska, Katerina Hadzi-Velkova Saneva, Zoran Hadzi-Velkov</dc:creator>
    </item>
    <item>
      <title>A matrix-free interior point continuous trajectory for linearly constrained convex programming</title>
      <link>https://arxiv.org/abs/2412.20141</link>
      <description>arXiv:2412.20141v1 Announce Type: new 
Abstract: Interior point methods for solving linearly constrained convex programming involve a variable projection matrix at each iteration to deal with the linear constraints. This matrix often becomes ill-conditioned near the boundary of the feasible region that results in wrong search directions and extra computational cost. A matrix-free interior point augmented Lagrangian continuous trajectory is therefore proposed and studied for linearly constrained convex programming. A closely related ordinary differential equation (ODE) system is formulated. In this ODE system, the variable projection matrix is no longer needed. By only assuming the existence of an optimal solution, we show that, starting from any interior feasible point, (i) the interior point augmented Lagrangian continuous trajectory is convergent; and (ii) the limit point is indeed an optimal solution of the original optimization problem. Moreover, with the addition of the strictly complementarity condition, we show that the associated Lagrange multiplier converges to an optimal solution of the Lagrangian dual problem. Based on the studied ODE system, several possible search directions for discrete algorithms are proposed and discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20141v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xun Qian, Li-Zhi Liao, Jie Sun</dc:creator>
    </item>
    <item>
      <title>Nonlinear Conjugate Gradient Methods for Optimization of Set-Valued Mappings of Finite Cardinality</title>
      <link>https://arxiv.org/abs/2412.20168</link>
      <description>arXiv:2412.20168v1 Announce Type: new 
Abstract: This article presents nonlinear conjugate gradient methods for finding local weakly minimal points of set-valued optimization problems under a lower set less ordering relation. The set-valued objective function of the optimization problem under consideration is defined by finitely many continuously differentiable vector-valued functions. For such optimization problems, at first, we propose a general scheme for nonlinear conjugate gradient methods and then introduce Dai-Yuan, Polak-Ribi{\`e}re-Polyak, and Hestenes-Stiefel conjugate gradient parameters for set-valued functions. Toward deriving the general scheme, we introduce a condition of sufficient decrease and Wolfe line searches for set-valued functions. For a given sequence of descent directions of a set-valued function, it is found that if the proposed standard Wolfe line search technique is employed, then the generated sequence of iterates for set optimization follows a Zoutendijk-like condition. With the help of the derived Zoutendijk-like condition, we report that all the proposed nonlinear conjugate gradient schemes are globally convergent under usual assumptions. It is important to note that the ordering cone used in the entire study is not restricted to be finitely generated, and no regularity assumption on the solution set of the problem is required for any of the reported convergence analyses. Finally, we demonstrate the performance of the proposed methods through numerical experiments. In the numerical experiments, we demonstrate the effectiveness of the proposed methods not only on the commonly used test instances for set optimization but also on a few newly introduced problems under general ordering cones that are neither nonnegative hyper-octant nor finitely generated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20168v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Debdas Ghosh, Ravi Raushan, Zai-Yun Peng, Jen-Chih Yao</dc:creator>
    </item>
    <item>
      <title>Picard Iteration for Parameter Estimation in Nonlinear Ordinary Differential Equations</title>
      <link>https://arxiv.org/abs/2412.20216</link>
      <description>arXiv:2412.20216v1 Announce Type: new 
Abstract: We consider the problem of using experimental time-series data for parameter estimation in nonlinear ordinary differential equations, focusing on the case where the data is noisy, sparse, irregularly sampled, includes multiple experiments, and does not directly measure the system state or its time-derivative. To account for such low-quality data, we propose a new framework for gradient-based parameter estimation which uses the Picard operator to reformulate the problem as constrained optimization with infinite-dimensional variables and constraints. We then use the contractive properties of the Picard operator to propose a class of gradient-contractive algorithms and provide conditions under which such algorithms are guaranteed to converge to a local optima. The algorithms are then tested on a battery of models and variety of datasets in order to demonstrate robustness and improvement over alternative approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20216v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aleksandr Talitckii, Matthew M. Peet</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust Fault Detection Trade-off Design with Prior Fault Information</title>
      <link>https://arxiv.org/abs/2412.20237</link>
      <description>arXiv:2412.20237v1 Announce Type: new 
Abstract: The robustness of fault detection algorithms against uncertainty is crucial in the real-world industrial environment. Recently, a new probabilistic design scheme called distributionally robust fault detection (DRFD) has emerged and received immense interest. Despite its robustness against unknown distributions in practice, current DRFD focuses on the overall detectability of all possible faults rather than the detectability of critical faults that are a priori known. Henceforth, a new DRFD trade-off design scheme is put forward in this work by utilizing prior fault information. The key contribution includes a novel distributional robustness metric of detecting a known fault and a new soft distributionally robust chance constraint that ensures robust detectability. Then a new trade-off design scheme of fault detection under unknown probability distributions is proposed, and this offers a flexible balance between the robustness of detecting known critical faults and the overall detectability against all possible faults. To solve the resulting problem, an exact reformulation is derived and a customized solution algorithm is developed, which includes a sequential optimization procedure and an initialization strategy. Finally, case studies on a simulated three-tank system and a real-world battery cell are carried out to showcase the usefulness of our DRFD method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20237v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yulin Feng, Hailang Jin, Steven X. Ding, Hao Ye, Chao Shang</dc:creator>
    </item>
    <item>
      <title>Convex Data-Driven Contraction With Riemannian Metrics</title>
      <link>https://arxiv.org/abs/2412.20283</link>
      <description>arXiv:2412.20283v1 Announce Type: new 
Abstract: The growing complexity of dynamical systems and advances in data collection necessitates robust data-driven control strategies without explicit system identification and robust synthesis. Data-driven stability has been explored in linear and nonlinear systems, often by turning the problem into a linear or positive semidefinite program. This paper focuses on a new emerging property called contractivity, which refers to the exponential convergence of all system trajectories toward each other under a specified metric. Data-driven closed loop contractivity has been studied for the case of the 2-norm and assuming nonlinearities are lipschitz bounded in subsets of $\mathbb{R}^n$. We extend the analysis by considering Riemannian metrics for polynomial dynamics. The key to our derivation is to leverage the convex criteria for closed-loop contraction and duality results to efficiently check infinite dimensional membership constraints. Numerical examples demonstrate the effectiveness of the proposed method for both linear and nonlinear systems, highlighting its potential for robust data-driven contraction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20283v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andreas Oliveira, Jian Zheng, Mario Sznaier</dc:creator>
    </item>
    <item>
      <title>Differentiability of the value function in control-constrained parabolic problems</title>
      <link>https://arxiv.org/abs/2412.20310</link>
      <description>arXiv:2412.20310v1 Announce Type: new 
Abstract: Along the optimal trajectory of an optimal control problem constrained by a semilinear parabolic partial differential equation, we prove the differentiability of the value function with respect to the initial condition and, under additional assumptions on the solution of the state equation, the differentiability of the value function with respect to the time variable. In our proof, we rely on local growth assumptions commonly associated with the study of second-order sufficient conditions. These assumptions are generally applicable to a wide range of problems, including, for instance, certain tracking-type problems. Finally, we discuss the differentiability of the value function in a neighborhood of the optimal trajectory when a growth condition for optimal controls is used.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20310v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alberto Dom\'inguez Corella, Nicolai Jork, Stefan Volkwein</dc:creator>
    </item>
    <item>
      <title>Zeroth-Order Methods for Nonconvex Stochastic Problems with Decision-Dependent Distributions</title>
      <link>https://arxiv.org/abs/2412.20330</link>
      <description>arXiv:2412.20330v1 Announce Type: new 
Abstract: In this study, we consider an optimization problem with uncertainty dependent on decision variables, which has recently attracted attention due to its importance in machine learning and pricing applications. In this problem, the gradient of the objective function cannot be obtained explicitly because the decision-dependent distribution is unknown. Therefore, several zeroth-order methods have been proposed, which obtain noisy objective values by sampling and update the iterates. Although these existing methods have theoretical convergence for optimization problems with decision-dependent uncertainty, they require strong assumptions about the function and distribution or exhibit large variances in their gradient estimators. To overcome these issues, we propose two zeroth-order methods under mild assumptions. First, we develop a zeroth-order method with a new one-point gradient estimator including a variance reduction parameter. The proposed method updates the decision variables while adjusting the variance reduction parameter. Second, we develop a zeroth-order method with a two-point gradient estimator. There are situations where only one-point estimators can be used, but if both one-point and two-point estimators are available, it is more practical to use the two-point estimator. As theoretical results, we show the convergence of our methods to stationary points and provide the worst-case iteration and sample complexity analysis. Our simulation experiments with real data on a retail service application show that our methods output solutions with lower objective values than the conventional zeroth-order methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20330v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuya Hikima, Akiko Takeda</dc:creator>
    </item>
    <item>
      <title>Slow and fast dynamics in measure functional differential equations with state-dependent delays through averaging principles and applications to extremum seeking</title>
      <link>https://arxiv.org/abs/2412.20362</link>
      <description>arXiv:2412.20362v1 Announce Type: new 
Abstract: This paper investigates a new class of equations called measure functional differential equations with state-dependent delays. We establish the existence and uniqueness of solutions and present a discussion concerning the appropriate phase space to define these equations. Also, we prove a version of periodic averaging principle to these equations. This type of result was completely open in the literature. These equations involving measure bring the advantage to encompass others such as impulsive, dynamic equations on time scales and difference equations, expanding their application potential. Additionally, we apply our theoretical insights to a real-time optimization strategy, using extremum seeking to validate the stability of an innovative algorithm under state-dependent delays. This application confirm the relevance of our findings in practical scenarios, offering valuable tools for advanced control system design. Our research provides significant contributions to the mathematical field and suggests new directions for future technological developments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20362v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jaqueline G. Mesquita, Tiago Roux Oliveira, Henrique C. dos Reis</dc:creator>
    </item>
    <item>
      <title>A market-based efficient matching mechanism for crowdsourced delivery systems with demand/supply elasticities</title>
      <link>https://arxiv.org/abs/2412.20395</link>
      <description>arXiv:2412.20395v1 Announce Type: new 
Abstract: Crowdsourced delivery (CSD) is an emerging business model that leverages the underutilized or excess capacity of individual drivers to fulfill delivery tasks. This paper presents a general formulation of a larege-scale two-sided CSD matching problem, considering demand/supply elasticity, heterogeneous preferences of both shippers and drivers, and task-bundling. We propose a set of methodologies to solve this problem. First, we reveal that the fluid-particle decomposition approach of Akamatsu and Oyama (2024) can be extended to our general formulation. This approach decomposes the original large-scale matching problem into a fluidly-approximated task partition problem (master problem) and small-scale particle matching problems (sub-problems). We propose to introduce a truthful auction mechanism to sub-problems, which enables the observation of privately perceived costs for each shipper/driver. Furthermore, by finding a theoretical link between auction problems and parturbed utility theory, we succeed in accurately reflecting the information collected from auctions to the master problem. This reduces the master problem to a smooth convex optimization problem, theoretically guaranteeing the computational efficiency and solution accuracy of the fluid approximation. Second, we transform the master problem into a traffic assignment problem (TAP) based on a task-chain network. This transformation overcomes the difficulty in enumerating task bundles. Finally, we formulate the dual problem of the TAP, whose decision variable is only a price/reward pattern at market equilibrium, and develop an efficient accelerated gradient descent method. The numerical experiments clarify that our approach drastically reduces the computational cost of the matching problem (~700 times faster than a naive method) without sacrificing accuracy of the optimal solution (mostly within 0.5% errors).</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20395v1</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yuki Oyama, Takashi Akamatsu</dc:creator>
    </item>
    <item>
      <title>An Efficient Stochastic Optimization Method for Global Placement in VLSI Problem</title>
      <link>https://arxiv.org/abs/2412.20425</link>
      <description>arXiv:2412.20425v1 Announce Type: new 
Abstract: The placement problem in very large-scale integration (VLSI) is a critical step in chip design, the goal of which is to optimize the wirelength of circuit components within a confined area while adhering to non-overlapping constraints. Most analytical placement models often rely on smooth approximations, thereby sacrificing the accuracy of wirelength estimation. To mitigate these inaccuracies, this paper introduces a novel approach that directly optimizes the original nonsmooth wirelength and proposes an innovative penalty model tailored for the global placement problem. Specifically, we transform the non-overlapping constraints into rectified linear penalty functions, allowing for a more precise formulation of the problem. Notably, we reformulate the resultant optimization problem into an equivalent framework resembling deep neural network training. Leveraging automatic differentiation techniques from deep learning, we efficiently compute the subgradient of the objective function, thus facilitating the application of stochastic subgradient methods to solve the model. To enhance the algorithm's performance, several advanced techniques are further introduced, leading to significant improvements in both efficiency and solution quality. Numerical experiments conducted on GSRC benchmark circuits demonstrate that our proposed model and algorithm achieve significant reductions in wirelength while effectively eliminating overlaps, highlighting its potential as a transformative advancement for large-scale VLSI placement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20425v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yi-Shuang Yue, Yu-Hong Dai, Haijun Yu</dc:creator>
    </item>
    <item>
      <title>Robust targeted exploration for systems with non-stochastic disturbances</title>
      <link>https://arxiv.org/abs/2412.20426</link>
      <description>arXiv:2412.20426v1 Announce Type: new 
Abstract: In this paper, we introduce a novel targeted exploration strategy designed specifically for uncertain linear time-invariant systems with energy-bounded disturbances, i.e., without making any assumptions on the distribution of the disturbances. We use classical results characterizing the set of non-falsified parameters consistent with energy-bounded disturbances. We derive a semidefinite program which computes an exploration strategy that guarantees a desired accuracy of the parameter estimate. This design is based on sufficient conditions on the spectral content of the exploration data that robustly accounts for initial parametric uncertainty. Finally, we highlight the applicability of the exploration strategy through a numerical example involving an unmodeled nonlinearity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20426v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Janani Venkatasubramanian, Johannes K\"ohler, Mark Cannon, Frank Allg\"ower</dc:creator>
    </item>
    <item>
      <title>Selfish routing on transportation networks with supply and demand constraints</title>
      <link>https://arxiv.org/abs/2412.20449</link>
      <description>arXiv:2412.20449v1 Announce Type: new 
Abstract: Traditional non-atomic selfish routing games present some limitations in properly modeling road traffic. This paper introduces a novel type of non-atomic selfish routing game leveraging concepts from Daganzo's cell transmission model (CTM). Each network link is characterized by a supply and demand mechanism that enforces capacity constraints based on current density, providing a more accurate representation of real-world traffic phenomena. We characterize the Wardrop equilibria and social optima of this game and identify a previously unrecognized inefficiency in selfish routing: partially transferring Wardrop equilibria, where only part of the exogenous flow traverses the network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20449v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tommaso Toso, Paolo Frasca, Alain Y. Kibangou</dc:creator>
    </item>
    <item>
      <title>EM algorithms for optimization problems with polynomial objectives</title>
      <link>https://arxiv.org/abs/2412.20481</link>
      <description>arXiv:2412.20481v1 Announce Type: new 
Abstract: The EM (Expectation-Maximization) algorithm is regarded as an MM (Majorization-Minimization) algorithm for maximum likelihood estimation of statistical models. Expanding this view, this paper demonstrates that by choosing an appropriate probability distribution, even nonstatistical optimization problem can be cast as a negative log-likelihood-like minimization problem, which can be approached by an EM (or MM) algorithm. When a polynomial objective is optimized over a simple polyhedral feasible set and an exponential family distribution is employed, the EM algorithm can be reduced to a natural gradient descent of the employed distribution with a constant step size. This is demonstrated through three examples. In this paper, we demonstrate the global convergence of specific cases with some exponential family distributions in a general form. In instances when the feasible set is not sufficiently simple, the use of MM algorithms can nevertheless be adequately described. When the objective is to minimize a convex quadratic function and the constraints are polyhedral, global convergence can also be established based on the existing results for an entropy-like proximal point algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20481v1</guid>
      <category>math.OC</category>
      <category>stat.CO</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kensuke Asai, Jun-ya Gotoh</dc:creator>
    </item>
    <item>
      <title>Indefinite linear quadratic control of mean-field backwardstochastic differential equation</title>
      <link>https://arxiv.org/abs/2412.20650</link>
      <description>arXiv:2412.20650v1 Announce Type: new 
Abstract: This paper is concerned with a general linear quadratic (LQ) control problem of mean-field backward stochastic differential equation (BSDE). Here, the weighting matrices in the cost functional are allowed to be indefinite. Necessary and sufficient conditions for optimality are obtained via a mean-field forward-backward stochastic differential equation (FBSDE). By investigating the connections with LQ problems of mean-field forward systems and taking some limiting procedures, we establish the solvabilities of corresponding Riccati equations in the case that cost functional is uniformly convex. Subsequently, an explicit formula of optimal control and optimal cost are derived. Moreover, some sufficient conditions for the uniform convexity of cost functional are also proposed in terms of Riccati equations, which have not been considered in existing literatures for backward systems. Some examples are provided to illustrate our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20650v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Wencan Wang, Huanjun Zhang</dc:creator>
    </item>
    <item>
      <title>Two-Stage Distributionally Robust Optimization: Intuitive Understanding and Algorithm Development from the Primal Perspective</title>
      <link>https://arxiv.org/abs/2412.20708</link>
      <description>arXiv:2412.20708v1 Announce Type: new 
Abstract: In this paper, we study the two-stage distributionally robust optimization (DRO) problem from the primal perspective. Unlike existing approaches, this perspective allows us to build a deeper and more intuitive understanding on DRO, to leverage classical and well-established solution methods and to develop a general and fast decomposition algorithm (and its variants), and to address a couple of unsolved issues that are critical for modeling and computation. Theoretical analyses regarding the strength, convergence, and iteration complexity of the developed algorithm are also presented. A numerical study on different types of instances of the distributionally robust facility location problem demonstrates that the proposed solution algorithm (and its variants) significantly outperforms existing methods. It solves instances up to several orders of magnitude faster, and successfully addresses new types of practical instances that previously could not be handled. We believe these results will significantly enhance the accessibility of DRO, break down barriers, and unleash its potential to solve real world challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20708v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zhengsong Lu, Bo Zeng</dc:creator>
    </item>
    <item>
      <title>Nonsmooth Convex Optimization using the Specular Gradient Method with Root-Linear Convergence</title>
      <link>https://arxiv.org/abs/2412.20747</link>
      <description>arXiv:2412.20747v1 Announce Type: new 
Abstract: In this paper, we find the special case of the subgradient method minimizing a one-dimensional real-valued function, which we term the specular gradient method, that converges root-linearly without any additional assumptions except the convexity. Furthermore, we suggest a way to implement the specular gradient method without explicitly calculating specular derivatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20747v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kiyuob Jung, Jehan Oh</dc:creator>
    </item>
    <item>
      <title>A randomisation method for mean-field control problems with common noise</title>
      <link>https://arxiv.org/abs/2412.20782</link>
      <description>arXiv:2412.20782v1 Announce Type: new 
Abstract: We study mean-field control (MFC) problems with common noise using the control randomisation framework, where we substitute the control process with an independent Poisson point process, controlling its intensity instead. To address the challenges posed by the mean-field interactions in this randomisation approach, we reformulate the admissible control as L 0 -valued processes adapted only to the common noise. We then construct the randomised control problem from this reformulated control process, and show its equivalence to the original MFC problem. Thanks to this equivalence, we can represent the value function as the minimal solution to a backward stochastic differential equation (BSDE) with constrained jumps. Finally, using this probabilistic representation, we derive a randomised dynamic programming principle (DPP) for the value function, expressed as a supremum over equivalent probability measures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20782v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robert Denkert (HU Berlin), Idris Kharroubi (SU, LPSM), Huy\^en Pham (X, CMAP)</dc:creator>
    </item>
    <item>
      <title>Equivalent transformation and weighted $H_\infty$-optimization of linear descriptor systems</title>
      <link>https://arxiv.org/abs/2412.20827</link>
      <description>arXiv:2412.20827v1 Announce Type: new 
Abstract: The problem of a generalized type of $H_\infty$-control is investigated for a class of admissible descriptor systems with a non-zero initial vector. A generalized performance measure is used, which characterizes the weighted damping level of external and initial disturbances. A non-degenerate transformation of the system is proposed, which allows to apply known methods for evaluation and the achievement of desired performance measures for conventional lower-order systems. A numerical example of a controlled hydraulic system with three tanks is given.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20827v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>A. G. Mazko</dc:creator>
    </item>
    <item>
      <title>The monotonicity of the Cheeger constant for parallel bodies</title>
      <link>https://arxiv.org/abs/2412.20917</link>
      <description>arXiv:2412.20917v1 Announce Type: new 
Abstract: We prove that for every planar convex set $\Omega$, the function $t\in (-r(\Omega),+\infty)\longmapsto \sqrt{|\Omega_t|}h(\Omega_t)$ is monotonically decreasing, where $r$, $|\cdot|$ and $h$ stand for the inradius, the measure and the Cheeger constant and $(\Omega_t)$ for parallel bodies of $\Omega$. The result is shown to not hold when the convexity assumption is dropped. We also prove the differentiability of the map $t\longmapsto h(\Omega_t)$ in any dimension and without any regularity assumption on $\Omega$, obtaining an explicit formula for the derivative. Those results are then combined to obtain estimates on the contact surface of the Cheeger sets of convex bodies. Finally, potential generalizations to other functionals such as the first eigenvalue of the Dirichlet Laplacian are explored.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20917v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ilias Ftouhi</dc:creator>
    </item>
    <item>
      <title>Kolmogorov equations for 2D stochastic convective Brinkman-Forchheimer equations: Analysis and Applications</title>
      <link>https://arxiv.org/abs/2412.20948</link>
      <description>arXiv:2412.20948v1 Announce Type: new 
Abstract: In this work, we consider the following 2D stochastic convective Brinkman-Forchheimer (SCBF) equations in a bounded smooth domain $\mathcal{O}$:
  \begin{align*}
  \mathrm{d}\boldsymbol{u}+\left[-\mu \Delta\boldsymbol{u}+(\boldsymbol{u}\cdot\nabla)\boldsymbol{u}+\alpha\boldsymbol{u}+\beta|\boldsymbol{u}|^{r-1}\boldsymbol{u}+\nabla p\right]\mathrm{d}t=\sqrt{\mathrm{Q}}\mathrm{W}, \ \nabla\cdot\boldsymbol{u}=0,
  \end{align*}
  where $\mu,\alpha,\beta&gt;0$, $r\in\{1,2,3\}$, $\mathrm{Q}$ is a non-negative operator of trace class, $\mathrm{W}$ is a cylindrical Wiener process in a Hilbert space $\mathbb{H}$. Under the following assumption on the viscosity co-efficient $\mu$ and the Darcy co-efficient $\alpha$: for some positive constant $\gamma_1$,
  \begin{equation*}
  \mu(\mu+\alpha)^2&gt;\gamma_1\max\{4\mathrm{Tr}(\mathrm{Q}),\mathrm{Tr}(\mathrm{A}^{2\delta}\mathrm{Q})\},
  \end{equation*}
  where $\mathrm{A}$ is the Stokes operator and $\delta\in(0,\frac{1}{2})$, our primary goal is to solve the corresponding Kolmogorov equation in the space $\mathbb{L}^2(\mathbb{H};\eta),$ where $\eta$ is the unique invariant measure associated with 2D SCBF equations. Then, we establish the well-known ``carr\'e du champs'' identity. Some sharp estimates on the derivatives of the solution constitute the key component of the proofs. We take into consideration two control problems from the application point of view. The first is an infinite horizon control problem for which we establish the existence of a solution for the Hamilton-Jacobi-Bellman equation associated with it. Finally, by exploiting $m$-accretive theory, we demonstrate the existence of a unique solution for an obstacle problem associated with the Kolmogorov operator corresponding to the stopping-time problem for 2D SCBF equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20948v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sagar Gautam, Manil T. Mohan</dc:creator>
    </item>
    <item>
      <title>Finite Horizon Optimization: Framework and Applications</title>
      <link>https://arxiv.org/abs/2412.21068</link>
      <description>arXiv:2412.21068v1 Announce Type: new 
Abstract: In modern engineering scenarios, there is often a strict upper bound on the number of algorithm iterations that can be performed within a given time limit. This raises the question of optimal algorithmic configuration for a fixed and finite iteration budget. In this work, we introduce the framework of finite horizon optimization, which focuses on optimizing the algorithm performance under a strict iteration budget $T$. We apply this framework to linear programming (LP) and propose Finite Horizon stepsize rule for the primal-dual method. The main challenge in the stepsize design is controlling the singular values of $T$ cumulative product of non-symmetric matrices, which appears to be a highly nonconvex problem, and there are very few helpful tools. Fortunately, in the special case of the primal-dual method, we find that the optimal stepsize design problem admits hidden convexity, and we propose a convex semidefinite programming (SDP) reformulation. This SDP only involves matrix constraints of size $4 \times 4$ and can be solved efficiently in negligible time. Theoretical acceleration guarantee is also provided at the pre-fixed $T$-th iteration, but with no asymptotic guarantee. On more than 90 real-world LP instances, Finite Horizon stepsize rule reaches an average 3.9$\times$ speed-up over the optimal constant stepsize, saving 75\% wall-clock time. Our numerical results reveal substantial room for improvement when we abandon asymptotic guarantees, and instead focus on the performance under finite horizon. We highlight that the benefits are not merely theoretical - they translate directly into computational speed-up on real-world problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.21068v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yushun Zhang, Dmitry Rybin, Zhi-Quan Luo</dc:creator>
    </item>
    <item>
      <title>On the Convergence of DP-SGD with Adaptive Clipping</title>
      <link>https://arxiv.org/abs/2412.19916</link>
      <description>arXiv:2412.19916v1 Announce Type: cross 
Abstract: Stochastic Gradient Descent (SGD) with gradient clipping is a powerful technique for enabling differentially private optimization. Although prior works extensively investigated clipping with a constant threshold, private training remains highly sensitive to threshold selection, which can be expensive or even infeasible to tune. This sensitivity motivates the development of adaptive approaches, such as quantile clipping, which have demonstrated empirical success but lack a solid theoretical understanding. This paper provides the first comprehensive convergence analysis of SGD with quantile clipping (QC-SGD). We demonstrate that QC-SGD suffers from a bias problem similar to constant-threshold clipped SGD but show how this can be mitigated through a carefully designed quantile and step size schedule. Our analysis reveals crucial relationships between quantile selection, step size, and convergence behavior, providing practical guidelines for parameter selection. We extend these results to differentially private optimization, establishing the first theoretical guarantees for DP-QC-SGD. Our findings provide theoretical foundations for widely used adaptive clipping heuristic and highlight open avenues for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19916v1</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Egor Shulgin, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>Validation of Subject-Specific Knee Models from In Vivo Measurements</title>
      <link>https://arxiv.org/abs/2412.19951</link>
      <description>arXiv:2412.19951v1 Announce Type: cross 
Abstract: Calibration to experimental data is vital when developing subject-specific models towards developing digital twins. Yet, to date, subject-specific models are largely based on cadaveric testing, as in vivo data to calibrate against has been difficult to obtain until recently. To support our overall goal of building subject-specific models of the living knee, we aimed to show that subject-specific computational models built and calibrated using in vivo measurements would have accuracy comparable to models built using in vitro measurements. Two knee specimens were imaged using a combination of computed tomography (CT), and surface scans. Knee laxity measurements were made with a custom apparatus used for the living knee and from a robotic knee simulator. Models of the knees were built using the CT geometry and surface scans, and then calibrated with either laxity data from the robotic knee simulator or from the knee laxity apparatus. Model performance was compared by simulation of passive flexion, knee laxity and a clinically relevant pivot shift. Performance was similar with differences during simulated anterior-posterior laxity tests of less than 2.5 mm. Additionally, model predictions of a pivot shift were similar with differences less than 3 deg or 3 mm for rotations and translations, respectively. Still, differences in the predicted ligament loads and calibrated material properties emerged, highlighting a need for methods to include ligament load as part of the underlying calibration process. Overall, the results showed that currently available methods of measuring knee laxity in vivo are sufficient to calibrate models comparable with existing in vitro techniques, and the workflows described here may provide a basis for modeling the living knee. The models, data, and code are publicly available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19951v1</guid>
      <category>q-bio.QM</category>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thor E. Andreassen, Donald R. Hume, Landon D. Hamilton, Stormy L. Hegg, Sean E. Higinbotham, Kevin B. Shelburne</dc:creator>
    </item>
    <item>
      <title>A Nearly Optimal Single Loop Algorithm for Stochastic Bilevel Optimization under Unbounded Smoothness</title>
      <link>https://arxiv.org/abs/2412.20017</link>
      <description>arXiv:2412.20017v1 Announce Type: cross 
Abstract: This paper studies the problem of stochastic bilevel optimization where the upper-level function is nonconvex with potentially unbounded smoothness and the lower-level function is strongly convex. This problem is motivated by meta-learning applied to sequential data, such as text classification using recurrent neural networks, where the smoothness constant of the upper-level loss function scales linearly with the gradient norm and can be potentially unbounded. Existing algorithm crucially relies on the nested loop design, which requires significant tuning efforts and is not practical. In this paper, we address this issue by proposing a Single Loop bIlevel oPtimizer (SLIP). The proposed algorithm first updates the lower-level variable by a few steps of stochastic gradient descent, and then simultaneously updates the upper-level variable by normalized stochastic gradient descent with momentum and the lower-level variable by stochastic gradient descent. Under standard assumptions, we show that our algorithm finds an $\epsilon$-stationary point within $\widetilde{O}(1/\epsilon^4)$\footnote{Here $\widetilde{O}(\cdot)$ compresses logarithmic factors of $1/\epsilon$ and $1/\delta$, where $\delta\in(0,1)$ denotes the failure probability.} oracle calls of stochastic gradient or Hessian-vector product, both in expectation and with high probability. This complexity result is nearly optimal up to logarithmic factors without mean-square smoothness of the stochastic gradient oracle. Our proof relies on (i) a refined characterization and control of the lower-level variable and (ii) establishing a novel connection between bilevel optimization and stochastic optimization under distributional drift. Our experiments on various tasks show that our algorithm significantly outperforms strong baselines in bilevel optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20017v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaochuan Gong, Jie Hao, Mingrui Liu</dc:creator>
    </item>
    <item>
      <title>No-regret learning in harmonic games: Extrapolation in the face of conflicting interests</title>
      <link>https://arxiv.org/abs/2412.20203</link>
      <description>arXiv:2412.20203v1 Announce Type: cross 
Abstract: The long-run behavior of multi-agent learning - and, in particular, no-regret learning - is relatively well-understood in potential games, where players have aligned interests. By contrast, in harmonic games - the strategic counterpart of potential games, where players have conflicting interests - very little is known outside the narrow subclass of 2-player zero-sum games with a fully-mixed equilibrium. Our paper seeks to partially fill this gap by focusing on the full class of (generalized) harmonic games and examining the convergence properties of follow-the-regularized-leader (FTRL), the most widely studied class of no-regret learning schemes. As a first result, we show that the continuous-time dynamics of FTRL are Poincar\'e recurrent, that is, they return arbitrarily close to their starting point infinitely often, and hence fail to converge. In discrete time, the standard, "vanilla" implementation of FTRL may lead to even worse outcomes, eventually trapping the players in a perpetual cycle of best-responses. However, if FTRL is augmented with a suitable extrapolation step - which includes as special cases the optimistic and mirror-prox variants of FTRL - we show that learning converges to a Nash equilibrium from any initial condition, and all players are guaranteed at most O(1) regret. These results provide an in-depth understanding of no-regret learning in harmonic games, nesting prior work on 2-player zero-sum games, and showing at a high level that harmonic games are the canonical complement of potential games, not only from a strategic, but also from a dynamic viewpoint.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20203v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Davide Legacci, Panayotis Mertikopoulos, Christos H. Papadimitriou, Georgios Piliouras, Bary S. R. Pradelski</dc:creator>
    </item>
    <item>
      <title>Well-posedness and approximation of reflected McKean-Vlasov SDEs with applications</title>
      <link>https://arxiv.org/abs/2412.20247</link>
      <description>arXiv:2412.20247v1 Announce Type: cross 
Abstract: In this paper, we establish well-posedness of reflected McKean-Vlasov SDEs and their particle approximations in smooth non-convex domains. We prove convergence of the interacting particle system to the corresponding mean-field limit with the optimal rate of convergence. We motivate this study with applications to sampling and optimization in constrained domains by considering reflected mean-field Langevin SDEs and two reflected consensus-based optimization (CBO) models, respectively. We utilize reflection coupling to study long-time behaviour of reflected mean-field SDEs and also investigate convergence of the reflected CBO models to the global minimum of a constrained optimization problem. We numerically test reflected CBO models on benchmark constrained optimization problems and an inverse problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20247v1</guid>
      <category>math.PR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>P. D. Hinds, A. Sharma, M. V. Tretyakov</dc:creator>
    </item>
    <item>
      <title>High-Performance Model Predictive Control for Quadcopters with Formal Stability Guarantees</title>
      <link>https://arxiv.org/abs/2412.20277</link>
      <description>arXiv:2412.20277v1 Announce Type: cross 
Abstract: In this paper, we present a novel cascade control structure with formal guarantees of uniform almost global asymptotic stability for the state tracking error dynamics of a quadcopter. The proposed approach features a model predictive control strategy for the outer loop, explicitly accounting for the non-zero total thrust constraint. The outer-loop controller generates an acceleration reference, which is then converted into attitude, angular velocity and acceleration references, subsequently tracked by a nonlinear inner-loop controller. The proposed cascade control strategy is validated through numerical case studies, underlying high-fidelity models, demonstrating its ability to track fast trajectories with small error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20277v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Maedeh Izadi, A. T. J. R. Cobbenhagen, Ruben Sommer, A. R. P. Andri\"en, Erjen Lefeber, W. P. M. H. Heemels</dc:creator>
    </item>
    <item>
      <title>Deep Generalized Schr\"odinger Bridges: From Image Generation to Solving Mean-Field Games</title>
      <link>https://arxiv.org/abs/2412.20279</link>
      <description>arXiv:2412.20279v1 Announce Type: cross 
Abstract: Generalized Schr\"odinger Bridges (GSBs) are a fundamental mathematical framework used to analyze the most likely particle evolution based on the principle of least action including kinetic and potential energy. In parallel to their well-established presence in the theoretical realms of quantum mechanics and optimal transport, this paper focuses on an algorithmic perspective, aiming to enhance practical usage. Our motivated observation is that transportation problems with the optimality structures delineated by GSBs are pervasive across various scientific domains, such as generative modeling in machine learning, mean-field games in stochastic control, and more. Exploring the intrinsic connection between the mathematical modeling of GSBs and the modern algorithmic characterization therefore presents a crucial, yet untapped, avenue. In this paper, we reinterpret GSBs as probabilistic models and demonstrate that, with a delicate mathematical tool known as the nonlinear Feynman-Kac lemma, rich algorithmic concepts, such as likelihoods, variational gaps, and temporal differences, emerge naturally from the optimality structures of GSBs. The resulting computational framework, driven by deep learning and neural networks, operates in a fully continuous state space (i.e., mesh-free) and satisfies distribution constraints, setting it apart from prior numerical solvers relying on spatial discretization or constraint relaxation. We demonstrate the efficacy of our method in generative modeling and mean-field games, highlighting its transformative applications at the intersection of mathematical modeling, stochastic process, control, and machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20279v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guan-Horng Liu, Tianrong Chen, Evangelos A. Theodorou</dc:creator>
    </item>
    <item>
      <title>Accelerated regularized learning in finite N-person games</title>
      <link>https://arxiv.org/abs/2412.20365</link>
      <description>arXiv:2412.20365v1 Announce Type: cross 
Abstract: Motivated by the success of Nesterov's accelerated gradient algorithm for convex minimization problems, we examine whether it is possible to achieve similar performance gains in the context of online learning in games. To that end, we introduce a family of accelerated learning methods, which we call "follow the accelerated leader" (FTXL), and which incorporates the use of momentum within the general framework of regularized learning - and, in particular, the exponential/multiplicative weights algorithm and its variants. Drawing inspiration and techniques from the continuous-time analysis of Nesterov's algorithm, we show that FTXL converges locally to strict Nash equilibria at a superlinear rate, achieving in this way an exponential speed-up over vanilla regularized learning methods (which, by comparison, converge to strict equilibria at a geometric, linear rate). Importantly, FTXL maintains its superlinear convergence rate in a broad range of feedback structures, from deterministic, full information models to stochastic, realization-based ones, and even when run with bandit, payoff-based information, where players are only able to observe their individual realized payoffs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20365v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kyriakos Lotidis, Angeliki Giannou, Panayotis Mertikopoulos, Nicholas Bambos</dc:creator>
    </item>
    <item>
      <title>A Particle Algorithm for Mean-Field Variational Inference</title>
      <link>https://arxiv.org/abs/2412.20385</link>
      <description>arXiv:2412.20385v1 Announce Type: cross 
Abstract: Variational inference is a fast and scalable alternative to Markov chain Monte Carlo and has been widely applied to posterior inference tasks in statistics and machine learning. A traditional approach for implementing mean-field variational inference (MFVI) is coordinate ascent variational inference (CAVI), which relies crucially on parametric assumptions on complete conditionals. In this paper, we introduce a novel particle-based algorithm for mean-field variational inference, which we term PArticle VI (PAVI). Notably, our algorithm does not rely on parametric assumptions on complete conditionals, and it applies to the nonparametric setting. We provide non-asymptotic finite-particle convergence guarantee for our algorithm. To our knowledge, this is the first end-to-end guarantee for particle-based MFVI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20385v1</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiang Du, Kaizheng Wang, Edith Zhang, Chenyang Zhong</dc:creator>
    </item>
    <item>
      <title>Convergence of the Min-Max Langevin Dynamics and Algorithm for Zero-Sum Games</title>
      <link>https://arxiv.org/abs/2412.20471</link>
      <description>arXiv:2412.20471v1 Announce Type: cross 
Abstract: We study zero-sum games in the space of probability distributions over the Euclidean space $\mathbb{R}^d$ with entropy regularization, in the setting when the interaction function between the players is smooth and strongly convex-concave. We prove an exponential convergence guarantee for the mean-field min-max Langevin dynamics to compute the equilibrium distribution of the zero-sum game. We also study the finite-particle approximation of the mean-field min-max Langevin dynamics, both in continuous and discrete times. We prove biased convergence guarantees for the continuous-time finite-particle min-max Langevin dynamics to the stationary mean-field equilibrium distribution with an explicit bias estimate which does not scale with the number of particles. We also prove biased convergence guarantees for the discrete-time finite-particle min-max Langevin algorithm to the stationary mean-field equilibrium distribution with an additional bias term which scales with the step size and the number of particles. This provides an explicit iteration complexity for the average particle along the finite-particle algorithm to approximately compute the equilibrium distribution of the zero-sum game.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20471v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yang Cai, Siddharth Mitra, Xiuyuan Wang, Andre Wibisono</dc:creator>
    </item>
    <item>
      <title>Edge of Stochastic Stability: Revisiting the Edge of Stability for SGD</title>
      <link>https://arxiv.org/abs/2412.20553</link>
      <description>arXiv:2412.20553v1 Announce Type: cross 
Abstract: Recent findings by Cohen et al., 2021, demonstrate that when training neural networks with full-batch gradient descent at a step size of $\eta$, the sharpness--defined as the largest eigenvalue of the full batch Hessian--consistently stabilizes at $2/\eta$. These results have significant implications for convergence and generalization. Unfortunately, this was observed not to be the case for mini-batch stochastic gradient descent (SGD), thus limiting the broader applicability of these findings. We show that SGD trains in a different regime we call Edge of Stochastic Stability. In this regime, what hovers at $2/\eta$ is, instead, the average over the batches of the largest eigenvalue of the Hessian of the mini batch (MiniBS) loss--which is always bigger than the sharpness. This implies that the sharpness is generally lower when training with smaller batches or bigger learning rate, providing a basis for the observed implicit regularization effect of SGD towards flatter minima and a number of well established empirical phenomena. Additionally, we quantify the gap between the MiniBS and the sharpness, further characterizing this distinct training regime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20553v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arseniy Andreyev, Pierfrancesco Beneventano</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust Optimization via Iterative Algorithms in Continuous Probability Spaces</title>
      <link>https://arxiv.org/abs/2412.20556</link>
      <description>arXiv:2412.20556v1 Announce Type: cross 
Abstract: We consider a minimax problem motivated by distributionally robust optimization (DRO) when the worst-case distribution is continuous, leading to significant computational challenges due to the infinite-dimensional nature of the optimization problem. Recent research has explored learning the worst-case distribution using neural network-based generative models to address these computational challenges but lacks algorithmic convergence guarantees. This paper bridges this theoretical gap by presenting an iterative algorithm to solve such a minimax problem, achieving global convergence under mild assumptions and leveraging technical tools from vector space minimax optimization and convex analysis in the space of continuous probability densities. In particular, leveraging Brenier's theorem, we represent the worst-case distribution as a transport map applied to a continuous reference measure and reformulate the regularized discrepancy-based DRO as a minimax problem in the Wasserstein space. Furthermore, we demonstrate that the worst-case distribution can be efficiently computed using a modified Jordan-Kinderlehrer-Otto (JKO) scheme with sufficiently large regularization parameters for commonly used discrepancy functions, linked to the radius of the ambiguity set. Additionally, we derive the global convergence rate and quantify the total number of subgradient and inexact modified JKO iterations required to obtain approximate stationary points. These results are potentially applicable to nonconvex and nonsmooth scenarios, with broad relevance to modern machine learning applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20556v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Linglingzhi Zhu, Yao Xie</dc:creator>
    </item>
    <item>
      <title>Highway Managed Lane Usage and Tolling for Mixed Traffic Flows with Connected Automated Vehicles (CAVs) and High-Occupancy Vehicles (HOVs)</title>
      <link>https://arxiv.org/abs/2412.20667</link>
      <description>arXiv:2412.20667v1 Announce Type: cross 
Abstract: This paper investigates managed lane (ML) toll setting and its effect under mixed traffic of connected automated vehicles (CAVs), high-occupancy vehicles (HOVs), and human-driven vehicles (HDVs), with a goal to avoid flow breakdown and minimize total social cost. A mesoscopic finite-difference traffic simulation model considers the flow-density relationship at different CAV market penetration rates, lane-changing behavior, and multiple entries/exits, interacting with a reactive toll setting mechanism. The results of the Monte Carlo simulation suggest an optimal policy of untolled HOV/CAV use with HDV tolls in particular scenarios of limited CAV market penetration. Small and targeted tolling avoids flow breakdown in ML while prioritizing HOVs and other vehicles with high values of time. Extensions of the formulation and sensitivity analysis quantify the benefits of converting high-occupancy HDVs to CAVs. The optimal tolling regime combines traffic science notions of flow stability and the economics of resource allocation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20667v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1177/03611981231185145</arxiv:DOI>
      <arxiv:journal_reference>Transportation Research Record 2678.4 (2024): 505-526</arxiv:journal_reference>
      <dc:creator>Max T. M. Ng, Hani S. Mahmassani</dc:creator>
    </item>
    <item>
      <title>Differentiable Convex Optimization Layers in Neural Architectures: Foundations and Perspectives</title>
      <link>https://arxiv.org/abs/2412.20679</link>
      <description>arXiv:2412.20679v1 Announce Type: cross 
Abstract: The integration of optimization problems within neural network architectures represents a fundamental shift from traditional approaches to handling constraints in deep learning. While it is long known that neural networks can incorporate soft constraints with techniques such as regularization, strict adherence to hard constraints is generally more difficult. A recent advance in this field, however, has addressed this problem by enabling the direct embedding of optimization layers as differentiable components within deep networks. This paper surveys the evolution and current state of this approach, from early implementations limited to quadratic programming, to more recent frameworks supporting general convex optimization problems. We provide a comprehensive review of the background, theoretical foundations, and emerging applications of this technology. Our analysis includes detailed mathematical proofs and an examination of various use cases that demonstrate the potential of this hybrid approach. This work synthesizes developments at the intersection of optimization theory and deep learning, offering insights into both current capabilities and future research directions in this rapidly evolving field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20679v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Calder Katyal</dc:creator>
    </item>
    <item>
      <title>The Restricted Inverse Optimal Value Problem under Weighted Bottle-neck Hamming distance on trees</title>
      <link>https://arxiv.org/abs/2412.20703</link>
      <description>arXiv:2412.20703v1 Announce Type: cross 
Abstract: We consider the Restricted Inverse Optimal Value Problem (RIOVSP) on trees under weighted bottleneck Hamming distance, denoted as (RIOVSPT$_{BH}$). The problem aims to minimize the total cost under weighted bottle-neck Hamming distance such that the length of the shortest root-leaf path of the tree is lower-bounded by a given value by adjusting the length of some edges. Additionally, the specified lower bound must correspond to the length of a particular root-leaf path. Through careful analysis of the problem's structural properties, we develop an algorithm with $O(n\log n)$ time complexity to solve (RIOVSPT$_{BH}$). Furthermore, by removing the path-length constraint, we derive the Minimum Cost Shortest Path Interdiction Problem on Trees (MCSPIT), for which we present an $O(n\log n)$ time algorithm that operates under weighted bottleneck Hamming distance. Extensive computational experiments demonstrate the efficiency and effectiveness of both algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20703v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiao Zhang, Xiao Li, Xiucui Guan</dc:creator>
    </item>
    <item>
      <title>Gradient flow structure for some nonlocal diffusion equations</title>
      <link>https://arxiv.org/abs/2412.20969</link>
      <description>arXiv:2412.20969v1 Announce Type: cross 
Abstract: We study ``nonlocal diffusion equations'' of the form \[ \partial_{t}\frac{d\rho_{t}}{d\pi}(x)+\int_{X}\left(\frac{d\rho_{t}}{d\pi}(x)-\frac{d\rho_{t}}{d\pi}(y)\right)\eta(x,y)d\pi(y)=0\qquad(\dagger) \] where $X$ is either $\mathbb{R}^{d}$ or $\mathbb{T}^{d}$, $\pi$ is a probability distribution on $X$, and $\eta(x,y)$ is a ``transition kernel'' which may be singular as $x\rightarrow y$. For a suitable notion of weak solutions which we discuss below, we show that solutions to these nonlocal diffusion equations can be interpreted as gradient flows of the relative entropy with respect to a certain nonlocal Wasserstein-type metric defined in terms of $\eta$ and $\pi$. These ``nonlocal Wasserstein metrics'' endow the space of probability measures on $X$ with a formal Riemannian structure, thereby providing for us a nonlocal analogue of the \emph{Otto calculus} originally developed in the context of the 2-Wasserstein metric. The class of equations $(\dagger)$ includes a family of ``nonlocal Fokker-Planck equations'', which are thus identified as nonlocal Wasserstein gradient flows of the relative entropy, analogously with the usual Fokker-Planck equation and the $W_{2}$ metric.
  The gradient flow structure we provide allows us to deduce: existence and uniqueness of solutions to ($\dagger$) in a suitable class of weak solutions; stability of solutions in the sense of evolutionary $\Gamma$-convergence, with respect to perturbations of initial condition, reference measure $\pi$, and transition kernel $\eta$; sufficient conditions for exponential convergence to equilibrium, in terms of a nonlocal analogue of the log-Sobolev inequality; as well as the consistency of a finite-volume-type spatial discretization scheme in the $\mathbb{T}^{d}$ case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20969v1</guid>
      <category>math.AP</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrew Warren</dc:creator>
    </item>
    <item>
      <title>Adaptive Batch Size Schedules for Distributed Training of Language Models with Data and Model Parallelism</title>
      <link>https://arxiv.org/abs/2412.21124</link>
      <description>arXiv:2412.21124v1 Announce Type: cross 
Abstract: An appropriate choice of batch sizes in large-scale model training is crucial, yet it involves an intrinsic yet inevitable dilemma: large-batch training improves training efficiency in terms of memory utilization, while generalization performance often deteriorates due to small amounts of gradient noise. Despite this dilemma, the common practice of choosing batch sizes in language model training often prioritizes training efficiency -- employing either constant large sizes with data parallelism or implementing batch size warmup schedules. However, such batch size schedule designs remain heuristic and often fail to adapt to training dynamics, presenting the challenge of designing adaptive batch size schedules. Given the abundance of available datasets and the data-hungry nature of language models, data parallelism has become an indispensable distributed training paradigm, enabling the use of larger batch sizes for gradient computation. However, vanilla data parallelism requires replicas of model parameters, gradients, and optimizer states at each worker, which prohibits training larger models with billions of parameters. To optimize memory usage, more advanced parallelism strategies must be employed. In this work, we propose general-purpose and theoretically principled adaptive batch size schedules compatible with data parallelism and model parallelism. We develop a practical implementation with PyTorch Fully Sharded Data Parallel, facilitating the pretraining of language models of different sizes. We empirically demonstrate that our proposed approaches outperform constant batch sizes and heuristic batch size warmup schedules in the pretraining of models in the Llama family, with particular focus on smaller models with up to 3 billion parameters. We also establish theoretical convergence guarantees for such adaptive batch size schedules with Adam for general smooth nonconvex objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.21124v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tim Tsz-Kit Lau, Weijian Li, Chenwei Xu, Han Liu, Mladen Kolar</dc:creator>
    </item>
    <item>
      <title>A Jacobi-type Newton method for Nash equilibrium problems with descent guarantees</title>
      <link>https://arxiv.org/abs/2209.11571</link>
      <description>arXiv:2209.11571v4 Announce Type: replace 
Abstract: A common strategy for solving an unconstrained two-player Nash equilibrium problem with continuous variables is applying Newton's method to the system of nonlinear equations obtained by the corresponding first-order necessary optimality conditions. However, when taking into account the game dynamics, it is not clear what is the goal of each player when considering that they are taking their current decision following Newton's iterates. In this paper we provide an interpretation for Newton's iterate in view of the game dynamics as follows: instead of minimizing the quadratic approximation of their objective function parameterized by the other player current decision (as a typical Jacobi-type strategy), we show that the Newton iterate follows this approach but with the objective function parameterized by a prediction of the other player action, considering that they are following the same Newtonian strategy. This interpretation allows us to present a new Newtonian algorithm where a backtracking procedure is introduced in order to guarantee that the computed Newtonian directions, for each player, are descent directions for their corresponding parameterized functions. Thus, besides favoring global convergence, our algorithm also favors true minimizers instead of maximizers or saddle points, differently from the standard Newton method, which does not consider the minimization structure of the problem in the non-convex case. Thus, our method is more robust in comparison with other Jacobi-type strategies or the pure Newtonian approach, which is corroborated by our illustrative numerical experiments. We also present a proof of the well-definiteness of the algorithm under some standard assumptions, together with a thorough analysis of its convergence properties taking into account the game dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.11571v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Oliver Kolossoski, Lu\'is Felipe Bueno, Gabriel Haeser</dc:creator>
    </item>
    <item>
      <title>A Generalization of the Riccati Recursion for Equality-Constrained Linear Quadratic Optimal Control</title>
      <link>https://arxiv.org/abs/2302.14836</link>
      <description>arXiv:2302.14836v4 Announce Type: replace 
Abstract: This paper introduces a generalization of the well-known Riccati recursion for solving the discrete-time equality-constrained linear quadratic optimal control problem. The recursion can be used to compute the solutions as well as optimal feedback control policies. Unlike other tailored approaches for this problem class, the proposed method does not require restrictive regularity conditions on the problem. This allows its use in nonlinear optimal control problem solvers that use exact Lagrangian Hessian information. We demonstrate that our approach can be implemented in a highly efficient algorithm that scales linearly with the horizon length. Numerical tests show a significant speed-up of up to two orders of magnitude with respect to state-of-the-art general-purpose sparse linear solvers. Based on the proposed approach, faster nonlinear optimal control problem solvers can be developed that are suitable for more complex applications or for implementations on low-cost or low-power computational platforms. The implementation of the proposed algorithm is made available as open-source software.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.14836v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lander Vanroye, Joris De Schutter, Wilm Decr\'e</dc:creator>
    </item>
    <item>
      <title>New Perspectives on Regularization and Computation in Optimal Transport-Based Distributionally Robust Optimization</title>
      <link>https://arxiv.org/abs/2303.03900</link>
      <description>arXiv:2303.03900v2 Announce Type: replace 
Abstract: We study optimal transport-based distributionally robust optimization problems where a fictitious adversary, often envisioned as nature, can choose the distribution of the uncertain problem parameters by reshaping a prescribed reference distribution at a finite transportation cost. In this framework, we show that robustification is intimately related to various forms of variation and Lipschitz regularization even if the transportation cost function fails to be (some power of) a metric. We also derive conditions for the existence and the computability of a Nash equilibrium between the decision-maker and nature, and we demonstrate numerically that nature's Nash strategy can be viewed as a distribution that is supported on remarkably deceptive adversarial samples. Finally, we identify practically relevant classes of optimal transport-based distributionally robust optimization problems that can be addressed with efficient gradient descent algorithms even if the loss function or the transportation cost function are nonconvex (but not both at the same time).</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.03900v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>stat.ML</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Soroosh Shafiee, Liviu Aolaritei, Florian D\"orfler, Daniel Kuhn</dc:creator>
    </item>
    <item>
      <title>Proximal bundle methods for hybrid weakly convex composite optimization problems</title>
      <link>https://arxiv.org/abs/2303.14896</link>
      <description>arXiv:2303.14896v2 Announce Type: replace 
Abstract: This paper establishes the iteration-complexity of proximal bundle methods for solving hybrid (i.e., a blend of smooth and nonsmooth) weakly convex composite optimization (HWC-CO) problems. This is done in a unified manner by considering a proximal bundle framework (PBF) based on a generic bundle update framework which includes various well-known bundle update schemes. In contrast to hard-to-check stationary conditions (e.g., the Moreau stationarity) used by other methods for solving HWC-CO, PBF uses a stationarity measure which is easily verifiable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.14896v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiaming Liang, Renato D. C. Monteiro, Honghao Zhang</dc:creator>
    </item>
    <item>
      <title>Some Primal-Dual Theory for Subgradient Methods for Strongly Convex Optimization</title>
      <link>https://arxiv.org/abs/2305.17323</link>
      <description>arXiv:2305.17323v5 Announce Type: replace 
Abstract: We consider (stochastic) subgradient methods for strongly convex but potentially nonsmooth non-Lipschitz optimization. We provide new equivalent dual descriptions (in the style of dual averaging) for the classic subgradient method, the proximal subgradient method, and the switching subgradient method. These equivalences enable $O(1/T)$ convergence guarantees in terms of both their classic primal gap and a not previously analyzed dual gap for strongly convex optimization. Consequently, our theory provides these classic methods with simple, optimal stopping criteria and optimality certificates at no added computational cost. Our results apply to a wide range of stepsize selections and of non-Lipschitz ill-conditioned problems where the early iterations of the subgradient method may diverge exponentially quickly (a phenomenon which, to the best of our knowledge, no prior works address). Even in the presence of such undesirable behaviors, our theory still ensures and bounds eventual convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.17323v5</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin Grimmer, Danlin Li</dc:creator>
    </item>
    <item>
      <title>Ergodic Mean-Field Games of Singular Control with Regime-Switching (Extended Version)</title>
      <link>https://arxiv.org/abs/2307.12012</link>
      <description>arXiv:2307.12012v2 Announce Type: replace 
Abstract: This paper studies a class of stationary mean-field games of singular stochastic control with regime-switching. The representative agent adjusts the dynamics of a Markov-modulated It\^o-diffusion via a two-sided singular stochastic control and faces a long-time-average expected profit criterion. The mean-field interaction is of scalar type and it is given through the stationary distribution of the population. Via a constructive approach, we prove the existence and uniqueness of the stationary mean-field equilibrium. Furthermore, we show that this realizes a symmetric $\varepsilon_N$-Nash equilibrium for a suitable ergodic $N$-player game with singular controls. The proof hinges on the characterization of the optimal solution to the representative player's ergodic singular stochastic control problem with regime switching in terms of an auxiliary Dynkin game, which is of independent interest and appears here for the first time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.12012v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jodi Dianetti, Giorgio Ferrari, Ioannis Tzouanas</dc:creator>
    </item>
    <item>
      <title>Worst-case analysis of restarted primal-dual hybrid gradient on totally unimodular linear programs</title>
      <link>https://arxiv.org/abs/2309.03988</link>
      <description>arXiv:2309.03988v3 Announce Type: replace 
Abstract: We analyze restarted PDHG on totally unimodular linear programs. In particular, we show that restarted PDHG finds an $\epsilon$-optimal solution in $O( H m_1^{2.5} \sqrt{\textbf{nnz}(A)} \log(H m_2 /\epsilon) )$ matrix-vector multiplies where $m_1$ is the number of constraints, $m_2$ the number of variables, $\textbf{nnz}(A)$ is the number of nonzeros in the constraint matrix, $H$ is the largest absolute coefficient in the right hand side or objective vector, and $\epsilon$ is the distance to optimality of the outputted solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.03988v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Oliver Hinder</dc:creator>
    </item>
    <item>
      <title>Boosting Column Generation with Graph Neural Networks for Joint Rider Trip Planning and Crew Shift Scheduling</title>
      <link>https://arxiv.org/abs/2401.03692</link>
      <description>arXiv:2401.03692v2 Announce Type: replace 
Abstract: Optimizing service schedules is pivotal to the reliable, efficient, and inclusive on-demand mobility. This pressing challenge is further exacerbated by the increasing needs of an aging population, the oversubscription of existing services, and the lack of effective solution methods. This study addresses the intricacies of service scheduling, by jointly optimizing rider trip planning and crew scheduling for a complex dynamic mobility service. The resulting optimization problems are extremely challenging computationally for state-of-the-art methods. To address this fundamental gap, this paper introduces the Joint Rider Trip Planning and Crew Shift Scheduling Problem (JRTPCSSP) and a novel solution method, called Attention and Gated GNN-Informed Column Generation (AGGNNI-CG), that hybridizes column generation and machine learning to obtain near-optimal solutions to the JRTPCSSP with real-life constraints of the application. The key idea of the machine-learning component is to dramatically reduce the number of paths to explore in the pricing problem, accelerating the most time-consuming component of the column generation. The machine learning component is a graph neural network with an attention mechanism and a gated architecture, which is particularly suited to cater for the different input sizes coming from daily operations. AGGNNI-CG has been applied to a challenging, real-world dataset from the Paratransit system of Chatham County in Georgia. It produces substantial improvements compared to the baseline column generation approach, which typically cannot produce high-quality feasible solutions in reasonable time on large-scale complex instances. AGGNNI-CG also produces significant improvements in service quality compared to the existing system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.03692v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiawei Lu, Tinghan Ye, Wenbo Chen, Pascal Van Hentenryck</dc:creator>
    </item>
    <item>
      <title>Hybrid optimal control with mixed-integer Lagrangian methods</title>
      <link>https://arxiv.org/abs/2403.06842</link>
      <description>arXiv:2403.06842v2 Announce Type: replace 
Abstract: Models involving hybrid systems are versatile in their application but difficult to optimize efficiently due to their combinatorial nature. This work presents a method to cope with hybrid optimal control problems which, in contrast to decomposition techniques, does not require relaxing the integrality constraints. Based on the discretize-then-optimize approach, our scheme addresses mixed-integer nonlinear problems under mild assumptions. The proposed numerical algorithm builds upon the augmented Lagrangian framework, whose subproblems are handled using successive mixed-integer linearizations with trust regions. We validate the performance of the numerical routine with extensive investigations using hybrid optimal control problems from different fields of application. Promising preliminary results are presented for a motion planning task with hysteresis and a Lotka-Volterra fishing problem with total variation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06842v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Viktoriya Nikitina, Alberto De Marchi, Matthias Gerdts</dc:creator>
    </item>
    <item>
      <title>Computation and Control of Unstable Steady States for Mean Field Multiagent Systems</title>
      <link>https://arxiv.org/abs/2406.11725</link>
      <description>arXiv:2406.11725v2 Announce Type: replace 
Abstract: We study interacting particle systems driven by noise, modeling phenomena such as opinion dynamics. We are interested in systems that exhibit phase transitions i.e. non-uniqueness of stationary states for the corresponding McKean-Vlasov PDE, in the mean field limit. We develop an efficient numerical scheme for identifying all steady states (both stable and unstable) of the mean field McKean-Vlasov PDE, based on a spectral Galerkin approximation combined with a deflated Newton's method to handle the multiplicity of solutions. Having found all possible equilibra, we formulate an optimal control strategy for steering the dynamics towards a chosen unstable steady state. The control is computed using iterated open-loop solvers in a receding horizon fashion. We demonstrate the effectiveness of the proposed steady state computation and stabilization methodology on several examples, including the noisy Hegselmann-Krause model for opinion dynamics and the Haken-Kelso-Bunz model from biophysics. The numerical experiments validate the ability of the approach to capture the rich self-organization landscape of these systems and to stabilize unstable configurations of interest. The proposed computational framework opens up new possibilities for understanding and controlling the collective behavior of noise-driven interacting particle systems, with potential applications in various fields such as social dynamics, biological synchronization, and collective behavior in physical and social systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.11725v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sara Bicego, Dante Kalise, Grigorios A. Pavliotis</dc:creator>
    </item>
    <item>
      <title>Optimality of vaccination for an SIR epidemic with an ICU constraint</title>
      <link>https://arxiv.org/abs/2407.08425</link>
      <description>arXiv:2407.08425v3 Announce Type: replace 
Abstract: This paper studies an optimal control problem for a class of SIR epidemic models, in scenarios in which the infected population is constrained to be lower than a critical threshold imposed by the ICU (intensive care unit) capacity. The vaccination effort possibly imposed by the health-care deciders is classically modeled by a control input affecting the epidemic dynamic. After a preliminary viability analysis the existence of optimal controls is established, and their structure is characterized by using a state-constrained version of Pontryagin's theorem. The resulting optimal controls necessarily have a bang-bang regime with at most one switch. More precisely, the optimal strategies impose the maximum-allowed vaccination effort in an initial period of time, which can cease only once the ICU constraint can be satisfied without further vaccination. The switching times are characterized in order to identify conditions under which vaccination should be implemented or halted. The uniqueness of the optimal control is also discussed. Numerical examples illustrate our theoretical results and the corresponding optimal strategies. The analysis is eventually extended to the infinite horizon by $\Gamma$-convergence arguments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08425v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s10957-024-02598-w</arxiv:DOI>
      <arxiv:journal_reference>J Optim Theory Appl 204, 8 (2025)</arxiv:journal_reference>
      <dc:creator>Matteo Della Rossa, Lorenzo Freddi, Dan Goreac</dc:creator>
    </item>
    <item>
      <title>Stability and convergence analysis of AdaGrad for non-convex optimization via novel stopping time-based techniques</title>
      <link>https://arxiv.org/abs/2409.05023</link>
      <description>arXiv:2409.05023v3 Announce Type: replace 
Abstract: Adaptive gradient optimizers (AdaGrad), which dynamically adjust the learning rate based on iterative gradients, have emerged as powerful tools in deep learning. These adaptive methods have significantly succeeded in various deep learning tasks, outperforming stochastic gradient descent. However, despite AdaGrad's status as a cornerstone of adaptive optimization, its theoretical analysis has not adequately addressed key aspects such as asymptotic convergence and non-asymptotic convergence rates in non-convex optimization scenarios. This study aims to provide a comprehensive analysis of AdaGrad and bridge the existing gaps in the literature. We introduce a new stopping time technique from probability theory, which allows us to establish the stability of AdaGrad under mild conditions. We further derive the asymptotically almost sure and mean-square convergence for AdaGrad. In addition, we demonstrate the near-optimal non-asymptotic convergence rate measured by the average-squared gradients in expectation, which is stronger than the existing high-probability results. The techniques developed in this work are potentially of independent interest for future research on other adaptive stochastic algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.05023v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruinan Jin, Xiaoyu Wang, Baoxiang Wang</dc:creator>
    </item>
    <item>
      <title>A Class of Multi-Objective Control Problems for Quasi-linear Parabolic Equations</title>
      <link>https://arxiv.org/abs/2410.08532</link>
      <description>arXiv:2410.08532v3 Announce Type: replace 
Abstract: This paper is devoted to studying a multi-objective control problem for a class of multi-dimensional quasi-linear parabolic equations. The considered system is driven by a leader control and two follower controls. For each leader control, a pair of follower controls is searched for as a Nash quasi-equilibrium (or Nash equilibrium) of cost functionals, while the aim for a leader control is to solve a controllability problem. This hierarchic control problem may be transformed into controllability of a strongly coupled system of quasi-linear parabolic equations through one control. Regarding controllability for quasi-linear parabolic equations of second order, the existing results usually require coefficients in principal parts to be independent of gradient of solutions, or spacial dimension to be limited. In this paper, the coefficients in principal parts for the controlled quasi-linear system contain not only the state itself but also its gradient with general spacial dimension.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08532v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanming Dong, Xu Liu, Xu Zhang</dc:creator>
    </item>
    <item>
      <title>Extreme Points of Spectrahedra</title>
      <link>https://arxiv.org/abs/2410.14889</link>
      <description>arXiv:2410.14889v2 Announce Type: replace 
Abstract: We consider the problem of characterizing extreme points of the convex set of positive linear operators on a possibly infinite-dimensional Hilbert space under linear constraints. We show that even perturbations of points in such sets admit what resembles a Douglas factorization. Using this result, we prove that an operator is extreme iff a corresponding set of linear operators is dense in the space of trace-class self-adjoint operators with range contained in the closure of the range of that operator. If the number of constraints is finite, we show that the extreme point must be of low-rank relative to the number of constraints and derive a purely rank-based characterization of the extreme points.
  In the finite-dimensional setting, our results lead to a remarkably simple characterization of the elliptope, that is, the set of correlation matrices, in terms of the Hadamard product which allows us to characterize the set of matrices which constitute the equality case of the Hadamard rank inequality when the involved matrices are equal and positive semi-definite. We illustrate the importance of our results using examples from statistics and quantum mechanics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14889v2</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kartik G. Waghmare, Victor M. Panaretos</dc:creator>
    </item>
    <item>
      <title>A Network Flow Approach to Optimal Scheduling in Supply Chain Logistics</title>
      <link>https://arxiv.org/abs/2411.17544</link>
      <description>arXiv:2411.17544v2 Announce Type: replace 
Abstract: In the evolving digital landscape, network flow models have transcended traditional applications to become integral in diverse sectors, including supply chain management. This research develops a robust network flow model for semiconductor wafer supply chains, optimizing resource allocation and addressing maximum flow challenges in production and logistics. The model incorporates the stochastic nature of wafer batch transfers and employs a dual-layer optimization framework to reduce variability and exceedance probabilities in finished goods. Empirical comparisons reveal significant enhancements in cost efficiency, productivity, and resource utilization, with a 20% reduction in time and production costs, and a 10% increase in transportation and storage capacities. The model's efficacy is underscored by a 15% decrease in transportation time and a 6700 kg increase in total capacity, demonstrating its capability to resolve logistical bottlenecks in semiconductor manufacturing. This study concludes that network flow models are a potent tool for optimizing supply chain logistics, offering a 23% improvement in resource utilization and a 13% boost in accuracy. The findings provide valuable insights for supply chain logistics optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17544v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yichen Wang, Huanbo Zhang, Chunhong Yuan, Xiangyu Li, Zuowen Jiang</dc:creator>
    </item>
    <item>
      <title>A General Solution to Bellman's Lost-in-a-forest Problem</title>
      <link>https://arxiv.org/abs/2412.10686</link>
      <description>arXiv:2412.10686v2 Announce Type: replace 
Abstract: We present a general solution and formulation framework to Bellman's lost-in-a-forest problem. The forest boundary is known and may take any shape. The starting point and the orientation are unspecified. We convert the problem into translation and rotation of the forest boundary. This transformation allows us to formulate this problem as a constrained minimization problem. Upon discretization, the problem becomes a variation of the traveling salesman problem or the Hamiltonian path problem. We leverage discrete optimization and derive several nontrivial results consistent with those from previous papers. This method is general, and we also extend the approach to related problems, including Moser's worm problem and the shortest opaque set problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10686v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zhipeng Deng</dc:creator>
    </item>
    <item>
      <title>Accelerated Proximal Gradient Method with Backtracking for Multiobjective Optimization</title>
      <link>https://arxiv.org/abs/2412.14007</link>
      <description>arXiv:2412.14007v2 Announce Type: replace 
Abstract: This paper proposes a new backtracking strategy based on the FISTA accelerated algorithm for multiobjective optimization problems. The strategy focuses on solving the problem of Lipschitz constant being unknown. It allows estimate parameter updates non-increasingly. Furthermore, the proposed strategy effectively avoids the limitation in convergence proofs arising from the non-negativity of the auxiliary sequence, thus providing a theoretical guarantee for its performance. We demonstrate that, under relatively mild assumptions, the algorithm achieves the convergence rate of $O(1/k2)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14007v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chengzhi Huang, Jian Chen, Liping Tang</dc:creator>
    </item>
    <item>
      <title>Corrigendum to "Balance of Communication and Convergence: Predefined-time Distributed Optimization Based on Zero-Gradient-Sum"</title>
      <link>https://arxiv.org/abs/2412.16163</link>
      <description>arXiv:2412.16163v2 Announce Type: replace 
Abstract: This paper proposes a distributed optimization algorithm with a convergence time that can be assigned in advance according to task requirements. To this end, a sliding manifold is introduced to achieve the sum of local gradients approaching zero, based on which a distributed protocol is derived to reach a consensus minimizing the global cost. A novel approach for convergence analysis is derived in a unified settling time framework, resulting in an algorithm that can precisely converge to the optimal solution at the prescribed time. The method is interesting as it simply requires the primal states to be shared over the network, which implies less communication requirements. The result is extended to scenarios with time-varying objective function, by introducing local gradients prediction and non-smooth consensus terms. Numerical simulations are provided to corroborate the effectiveness of the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16163v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TCYB.2024.3498323</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Cybernetics (2024) 1-11</arxiv:journal_reference>
      <dc:creator>Renyongkang Zhang, Ge Guo, Zeng-di Zhou</dc:creator>
    </item>
    <item>
      <title>On the convergence of fictitious play algorithm in repeated games via the geometrical approach</title>
      <link>https://arxiv.org/abs/2412.19216</link>
      <description>arXiv:2412.19216v2 Announce Type: replace 
Abstract: As the earliest and one of the most fundamental learning dynamics for computing NE, fictitious play (FP) has being receiving incessant research attention and finding games where FP would converge (games with FPP) is one central question in related fields. In this paper, we identify a new class of games with FPP, i.e., $3\times3$ games without IIP, based on the geometrical approach by leveraging the location of NE and the partition of best response region. During the process, we devise a new projection mapping to reduce a high-dimensional dynamical system to a planar system. And to overcome the non-smoothness of the systems, we redefine the concepts of saddle and sink NE, which are proven to exist and help prove the convergence of CFP by separating the projected space into two parts. Furthermore, we show that our projection mapping can be extended to higher-dimensional and degenerate games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19216v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhouming Wu, Yifen Mu, Xiaoguang Yang</dc:creator>
    </item>
    <item>
      <title>A Unified Analysis of Federated Learning with Arbitrary Client Participation</title>
      <link>https://arxiv.org/abs/2205.13648</link>
      <description>arXiv:2205.13648v4 Announce Type: replace-cross 
Abstract: Federated learning (FL) faces challenges of intermittent client availability and computation/communication efficiency. As a result, only a small subset of clients can participate in FL at a given time. It is important to understand how partial client participation affects convergence, but most existing works have either considered idealized participation patterns or obtained results with non-zero optimality error for generic patterns. In this paper, we provide a unified convergence analysis for FL with arbitrary client participation. We first introduce a generalized version of federated averaging (FedAvg) that amplifies parameter updates at an interval of multiple FL rounds. Then, we present a novel analysis that captures the effect of client participation in a single term. By analyzing this term, we obtain convergence upper bounds for a wide range of participation patterns, including both non-stochastic and stochastic cases, which match either the lower bound of stochastic gradient descent (SGD) or the state-of-the-art results in specific settings. We also discuss various insights, recommendations, and experimental results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.13648v4</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shiqiang Wang, Mingyue Ji</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning for Multi-Truck Vehicle Routing Problems</title>
      <link>https://arxiv.org/abs/2211.17078</link>
      <description>arXiv:2211.17078v3 Announce Type: replace-cross 
Abstract: Deep reinforcement learning (RL) has been shown to be effective in producing approximate solutions to some vehicle routing problems (VRPs), especially when using policies generated by encoder-decoder attention mechanisms. While these techniques have been quite successful for relatively simple problem instances, there are still under-researched and highly complex VRP variants for which no effective RL method has been demonstrated. In this work we focus on one such VRP variant, which contains multiple trucks and multi-leg routing requirements. In these problems, demand is required to move along sequences of nodes, instead of just from a start node to an end node. With the goal of making deep RL a viable strategy for real-world industrial-scale supply chain logistics, we develop new extensions to existing encoder-decoder attention models which allow them to handle multiple trucks and multi-leg routing requirements. Our models have the advantage that they can be trained for a small number of trucks and nodes, and then embedded into a large supply chain to yield solutions for larger numbers of trucks and nodes. We test our approach on a real supply chain environment arising in the operations of Japanese automotive parts manufacturer Aisin Corporation, and find that our algorithm outperforms Aisin's previous best solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.17078v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua Levin (QC Ware Corp Palo Alto), Randall Correll (QC Ware Corp Palo Alto), Takanori Ide (Department of Mathematics and Information Science, Josai University, Tokyo), Takafumi Suzuki (AISIN CORPORATION Tokyo), Saito Takaho (AISIN CORPORATION Tokyo), Alan Arai (Aisin Technical Center of America San Jose)</dc:creator>
    </item>
    <item>
      <title>Riemannian Stochastic Approximation for Minimizing Tame Nonsmooth Objective Functions</title>
      <link>https://arxiv.org/abs/2302.00709</link>
      <description>arXiv:2302.00709v4 Announce Type: replace-cross 
Abstract: In many learning applications, the parameters in a model are structurally constrained in a way that can be modeled as them lying on a Riemannian manifold. Riemannian optimization, wherein procedures to enforce an iterative minimizing sequence to be constrained to the manifold, is used to train such models. At the same time, tame geometry has become a significant topological description of nonsmooth functions that appear in the landscapes of training neural networks and other important models with structural compositions of continuous nonlinear functions with nonsmooth maps. In this paper, we study the properties of such stratifiable functions on a manifold and the behavior of retracted stochastic gradient descent, with diminishing stepsizes, for minimizing such functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.00709v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johannes Aspman, Vyacheslav Kungurtsev, Reza Roohi Seraji</dc:creator>
    </item>
    <item>
      <title>Canonical Factors for Hybrid Neural Fields</title>
      <link>https://arxiv.org/abs/2308.15461</link>
      <description>arXiv:2308.15461v2 Announce Type: replace-cross 
Abstract: Factored feature volumes offer a simple way to build more compact, efficient, and intepretable neural fields, but also introduce biases that are not necessarily beneficial for real-world data. In this work, we (1) characterize the undesirable biases that these architectures have for axis-aligned signals -- they can lead to radiance field reconstruction differences of as high as 2 PSNR -- and (2) explore how learning a set of canonicalizing transformations can improve representations by removing these biases. We prove in a two-dimensional model problem that simultaneously learning these transformations together with scene appearance succeeds with drastically improved efficiency. We validate the resulting architectures, which we call TILTED, using image, signed distance, and radiance field reconstruction tasks, where we observe improvements across quality, robustness, compactness, and runtime. Results demonstrate that TILTED can enable capabilities comparable to baselines that are 2x larger, while highlighting weaknesses of neural field evaluation procedures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.15461v2</guid>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brent Yi, Weijia Zeng, Sam Buchanan, Yi Ma</dc:creator>
    </item>
    <item>
      <title>Neural Networks for Fast Optimisation in Model Predictive Control: A Review</title>
      <link>https://arxiv.org/abs/2309.02668</link>
      <description>arXiv:2309.02668v3 Announce Type: replace-cross 
Abstract: Model Predictive Control (MPC) is an optimal control algorithm with strong stability and robustness guarantees. Despite its popularity in robotics and industrial applications, the main challenge in deploying MPC is its high computation cost, stemming from the need to solve an optimisation problem at each control interval. There are several methods to reduce this cost. This survey focusses on approaches where a neural network is used to approximate an existing controller. Herein, relevant and unique neural approximation methods for linear, nonlinear, and robust MPC are presented and compared. Comparisons are based on the theoretical guarantees that are preserved, the factor by which the original controller is sped up, and the size of problem that a framework is applicable to. Research contributions include: a taxonomy that organises existing knowledge, a summary of literary gaps, discussion on promising research directions, and simple guidelines for choosing an approximation framework. The main conclusions are that (1) new benchmarking tools are needed to help prove the generalisability and scalability of approximation frameworks, (2) future breakthroughs most likely lie in the development of ties between control and learning, and (3) the potential and applicability of recently developed neural architectures and tools remains unexplored in this field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.02668v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Camilo Gonzalez (Institute for Intelligent Systems Research and Innovation, Deakin University, Waurn Ponds, Australia), Houshyar Asadi (Institute for Intelligent Systems Research and Innovation, Deakin University, Waurn Ponds, Australia), Lars Kooijman (Opportunity Tech Lab, Monash University, Caulfield East, Australia), Chee Peng Lim (Swinburne University of Technology, Hawthorn, Australia)</dc:creator>
    </item>
    <item>
      <title>Epidemic Population Games And Perturbed Best Response Dynamics</title>
      <link>https://arxiv.org/abs/2401.15475</link>
      <description>arXiv:2401.15475v3 Announce Type: replace-cross 
Abstract: This paper proposes an approach to mitigate epidemic spread in a population of strategic agents by encouraging safer behaviors through carefully designed rewards. These rewards, which adapt to the evolving state of the epidemic, are ascribed by a dynamic payoff mechanism we seek to design. We use a modified SIRS model to track how the epidemic progresses in response to the agents' strategic choices. By employing perturbed best response evolutionary dynamics to model the population's strategic behavior, we extend previous related work so as to allow for noise in the agents' perceptions of the rewards and intrinsic costs of the available strategies. Central to our approach is the use of system-theoretic methods and passivity concepts to obtain a Lyapunov function, ensuring the global asymptotic stability of an endemic equilibrium with minimized infection prevalence under budget constraints. We leverage the Lyapunov function to analyze how the epidemic's spread rate is influenced by the time scale of the payoff mechanism's dynamics. Additionally, we derive anytime upper bounds on both the infectious fraction of the population and the instantaneous cost a social planner must incur to control the spread, allowing us to quantify the trade-off between peak infection prevalence and the corresponding cost. For a class of one-parameter perturbed best response models, we propose a method to learn the model's parameter from data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.15475v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shinkyu Park, Jair Certorio, Nuno C. Martins, Richard J. La</dc:creator>
    </item>
    <item>
      <title>Analysis of the SQP Method for Hyperbolic PDE-Constrained Optimization in Acoustic Full Waveform Inversion</title>
      <link>https://arxiv.org/abs/2405.05158</link>
      <description>arXiv:2405.05158v2 Announce Type: replace-cross 
Abstract: In this paper, the SQP method applied to a hyperbolic PDE-constrained optimization problem is considered. The model arises from the acoustic full waveform inversion in the time domain. The analysis is mainly challenging due to the involved hyperbolicity and second-order bilinear structure. This notorious character leads to an undesired effect of loss of regularity in the SQP method, calling for a substantial extension of developed parabolic techniques. We propose and analyze a novel strategy for the well-posedness and convergence analysis based on the use of a smooth-in-time initial condition, a tailored self-mapping operator, and a two-step estimation process along with Stampacchia's method for second-order wave equations. Our final theoretical result is the R-superlinear convergence of the SQP method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05158v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luis Ammann, Irwin Yousept</dc:creator>
    </item>
    <item>
      <title>Finite-difference least square methods for solving Hamilton-Jacobi equations using neural networks</title>
      <link>https://arxiv.org/abs/2406.10758</link>
      <description>arXiv:2406.10758v4 Announce Type: replace-cross 
Abstract: We present a simple algorithm to approximate the viscosity solution of Hamilton-Jacobi (HJ) equations by means of an artificial deep neural network. The algorithm uses a stochastic gradient descent-based method to minimize the least square principle defined by a monotone, consistent numerical scheme. We analyze the least square principle's critical points and derive conditions that guarantee that any critical point approximates the sought viscosity solution. The use of a deep artificial neural network on a finite difference scheme lifts the restriction of conventional finite difference methods that rely on computing functions on a fixed grid. This feature makes it possible to solve HJ equations posed in higher dimensions where conventional methods are infeasible. We demonstrate the efficacy of our algorithm through numerical studies on various canonical HJ equations across different dimensions, showcasing its potential and versatility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10758v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carlos Esteve-Yag\"ue, Richard Tsai, Alex Massucco</dc:creator>
    </item>
    <item>
      <title>Infrequent Resolving Algorithm for Online Linear Programming</title>
      <link>https://arxiv.org/abs/2408.00465</link>
      <description>arXiv:2408.00465v4 Announce Type: replace-cross 
Abstract: Online linear programming (OLP) has gained significant attention from both researchers and practitioners due to its extensive applications, such as online auction, network revenue management, order fulfillment and advertising. Existing OLP algorithms fall into two categories: LP-based algorithms and LP-free algorithms. The former one typically guarantees better performance, even offering a constant regret, but requires solving a large number of LPs, which could be computationally expensive. In contrast, LP-free algorithm only requires first-order computations but induces a worse performance, lacking a constant regret bound. In this work, we bridge the gap between these two extremes by proposing a well-performing algorithm, that solves LPs at a few selected time points and conducts first-order computations at other time points. Specifically, for the case where the inputs are drawn from an unknown finite-support distribution, the proposed algorithm achieves a constant regret (even for the hard ``degenerate'' case) while solving LPs only $\mathcal{O}(\log\log T)$ times over the time horizon $T$. Moreover, when we are allowed to solve LPs only $M$ times, we design the corresponding schedule such that the proposed algorithm can guarantee a nearly $\mathcal{O}\left(T^{(1/2)^{M-1}}\right)$ regret. Our work highlights the value of resolving both at the beginning and the end of the selling horizon, and provides a novel framework to prove the performance guarantee of the proposed policy under different infrequent resolving schedules. Furthermore, when the arrival probabilities are known at the beginning, our algorithm can guarantee a constant regret by solving LPs $\mathcal{O}(\log\log T)$ times, and a nearly $\mathcal{O}\left(T^{(1/2)^{M}}\right)$ regret by solving LPs only $M$ times. Numerical experiments are conducted to demonstrate the efficiency of the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00465v4</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guokai Li, Zizhuo Wang, Jingwei Zhang</dc:creator>
    </item>
    <item>
      <title>An Accelerated Algorithm for Stochastic Bilevel Optimization under Unbounded Smoothness</title>
      <link>https://arxiv.org/abs/2409.19212</link>
      <description>arXiv:2409.19212v3 Announce Type: replace-cross 
Abstract: This paper investigates a class of stochastic bilevel optimization problems where the upper-level function is nonconvex with potentially unbounded smoothness and the lower-level problem is strongly convex. These problems have significant applications in sequential data learning, such as text classification using recurrent neural networks. The unbounded smoothness is characterized by the smoothness constant of the upper-level function scaling linearly with the gradient norm, lacking a uniform upper bound. Existing state-of-the-art algorithms require $\widetilde{O}(1/\epsilon^4)$ oracle calls of stochastic gradient or Hessian/Jacobian-vector product to find an $\epsilon$-stationary point. However, it remains unclear if we can further improve the convergence rate when the assumptions for the function in the population level also hold for each random realization almost surely (e.g., Lipschitzness of each realization of the stochastic gradient). To address this issue, we propose a new Accelerated Bilevel Optimization algorithm named AccBO. The algorithm updates the upper-level variable by normalized stochastic gradient descent with recursive momentum and the lower-level variable by the stochastic Nesterov accelerated gradient descent algorithm with averaging. We prove that our algorithm achieves an oracle complexity of $\widetilde{O}(1/\epsilon^3)$ to find an $\epsilon$-stationary point. Our proof relies on a novel lemma characterizing the dynamics of stochastic Nesterov accelerated gradient descent algorithm under distribution drift with high probability for the lower-level variable, which is of independent interest and also plays a crucial role in analyzing the hypergradient estimation error over time. Experimental results on various tasks confirm that our proposed algorithm achieves the predicted theoretical acceleration and significantly outperforms baselines in bilevel optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19212v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaochuan Gong, Jie Hao, Mingrui Liu</dc:creator>
    </item>
    <item>
      <title>Learning Optimal Control and Dynamical Structure of Global Trajectory Search Problems with Diffusion Models</title>
      <link>https://arxiv.org/abs/2410.02976</link>
      <description>arXiv:2410.02976v2 Announce Type: replace-cross 
Abstract: Spacecraft trajectory design is a global search problem, where previous work has revealed specific solution structures that can be captured with data-driven methods. This paper explores two global search problems in the circular restricted three-body problem: hybrid cost function of minimum fuel/time-of-flight and transfers to energy-dependent invariant manifolds. These problems display a fundamental structure either in the optimal control profile or the use of dynamical structures. We build on our prior generative machine learning framework to apply diffusion models to learn the conditional probability distribution of the search problem and analyze the model's capability to capture these structures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02976v2</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jannik Graebner, Anjian Li, Amlan Sinha, Ryne Beeson</dc:creator>
    </item>
    <item>
      <title>Euclidean distance discriminants and Morse attractors</title>
      <link>https://arxiv.org/abs/2412.16957</link>
      <description>arXiv:2412.16957v2 Announce Type: replace-cross 
Abstract: Our study concerns the Euclidean distance function in case of complex plane curves. We decompose the ED discriminant into 3 parts which are responsible for the 3 types of behavior of the Morse points, and we find the structure of each one. In particular we shed light on the ``atypical discriminant'' which is due to the loss of Morse points at infinity. We find formulas for the number of Morse singularities which abut to the corresponding 3 types of attractors when moving the centre of the distance function toward a point of the discriminant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16957v2</guid>
      <category>math.AG</category>
      <category>math.OC</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cezar Joi\c{t}a, Dirk Siersma, Mihai Tib\u{a}r</dc:creator>
    </item>
    <item>
      <title>Central limit theorems for vector-valued composite functionals with smoothing and applications</title>
      <link>https://arxiv.org/abs/2412.19367</link>
      <description>arXiv:2412.19367v2 Announce Type: replace-cross 
Abstract: This paper focuses on vector-valued composite functionals, which may be nonlinear in probability. Our primary goal is to establish central limit theorems for these functionals when mixed estimators are employed. Our study is relevant to the evaluation and comparison of risk in decision-making contexts and extends to functionals that arise in machine learning methods. A generalized family of composite risk functionals is presented, which encompasses most of the known coherent risk measures including systemic measures of risk. The paper makes two main contributions. First, we analyze vector-valued functionals, providing a framework for evaluating high-dimensional risks. This framework facilitates the comparison of multiple risk measures, as well as the estimation and asymptotic analysis of systemic risk and its optimal value in decision-making problems. Second, we derive novel central limit theorems for optimized composite functionals when mixed types of estimators: empirical and smoothed estimators are used. We provide verifiable sufficient conditions for the central limit formulae and show their applicability to several popular measures of risk.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19367v2</guid>
      <category>math.ST</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huhui Chen, Darinka Dentcheva, Yang Lin, Gregory J. Stock</dc:creator>
    </item>
  </channel>
</rss>
