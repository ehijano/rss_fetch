<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SC</link>
    <description>cs.SC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 22 Jan 2026 02:38:52 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Breaking the Data Barrier in Learning Symbolic Computation: A Case Study on Variable Ordering Suggestion for Cylindrical Algebraic Decomposition</title>
      <link>https://arxiv.org/abs/2601.13731</link>
      <description>arXiv:2601.13731v1 Announce Type: new 
Abstract: Symbolic computation, powered by modern computer algebra systems, has important applications in mathematical reasoning through exact deep computations. The efficiency of symbolic computation is largely constrained by such deep computations in high dimension. This creates a fundamental barrier on labelled data acquisition if leveraging supervised deep learning to accelerate symbolic computation. Cylindrical algebraic decomposition (CAD) is a pillar symbolic computation method for reasoning with first-order logic formulas over reals with many applications in formal verification and automatic theorem proving. Variable orderings have a huge impact on its efficiency. Impeded by the difficulty to acquire abundant labelled data, existing learning-based approaches are only competitive with the best expert-based heuristics. In this work, we address this problem by designing a series of intimately connected tasks for which a large amount of annotated data can be easily obtained. We pre-train a Transformer model with these data and then fine-tune it on the datasets for CAD ordering. Experiments on publicly available CAD ordering datasets show that on average the orderings predicted by the new model are significantly better than those suggested by the best heuristic methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13731v1</guid>
      <category>cs.SC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rui-Juan Jing, Yuegang Zhao, Changbo Chen</dc:creator>
    </item>
    <item>
      <title>Neurosymbolic LoRA: Why and When to Tune Weights vs. Rewrite Prompts</title>
      <link>https://arxiv.org/abs/2601.12711</link>
      <description>arXiv:2601.12711v1 Announce Type: cross 
Abstract: Large language models (LLMs) can be adapted either through numerical updates that alter model parameters or symbolic manipulations that work on discrete prompts or logical constraints. While numerical fine-tuning excels at injecting new factual knowledge, symbolic updates offer flexible control of style and alignment without retraining. We introduce a neurosymbolic LoRA framework that dynamically combines these two complementary strategies. Specifically, we present a unified monitoring signal and a reward-based classifier to decide when to employ LoRA for deeper factual reconstruction and when to apply TextGrad for token-level edits. Our approach remains memory-efficient by offloading the symbolic transformations to an external LLM only when needed. Additionally, the refined prompts produced during symbolic editing serve as high-quality, reusable training data, an important benefit in data-scarce domains like mathematical reasoning. Extensive experiments across multiple LLM backbones show that neurosymbolic LoRA consistently outperforms purely numerical or purely symbolic baselines, demonstrating superior adaptability and improved performance. Our findings highlight the value of interleaving numerical and symbolic updates to unlock a new level of versatility in language model fine-tuning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.12711v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SC</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kevin Wang, Neel P. Bhatt, Cong Liu, Junbo Li, Runjin Chen, Yihan Xi, Timothy Barclay, Alvaro Velasquez, Ufuk Topcu, Zhangyang Wang</dc:creator>
    </item>
    <item>
      <title>A Novel Approach to the Initial Value Problem with a complete validated algorithm</title>
      <link>https://arxiv.org/abs/2502.00503</link>
      <description>arXiv:2502.00503v4 Announce Type: replace 
Abstract: We consider the first order autonomous differential equation (ODE) ${\bf x}'={\bf f}({\bf x})$ where ${\bf f}: {\mathbb R}^n\to{\mathbb R}^n$ is locally Lipschitz. For ${\bf x}_0\in{\mathbb R}^n$ and $h&gt;0$, the initial value problem (IVP) for $({\bf f},{\bf x}_0,h)$ is to determine if there is a unique solution, i.e., a function ${\bf x}:[0,h]\to{\mathbb R}^n$ that satisfies the ODE with ${\bf x}(0)={\bf x}_0$. Write ${\bf x} ={\tt IVP}_{\bf f}({\bf x}_0,h)$ for this unique solution.
  We pose a corresponding computational problem, called the End Enclosure Problem: given $({\bf f},B_0,h,\varepsilon_0)$ where $B_0\subseteq{\mathbb R}^n$ is a box and $\varepsilon_0&gt;0$, to compute a pair of non-empty boxes $(\underline{B}_0,B_1)$ such that $\underline{B}_0\subseteq B_0$, width of $B_1$ is $&lt;\varepsilon_0$, and for all ${\bf x}_0\in \underline{B}_0$, ${\bf x}={\tt IVP}_{\bf f}({\bf x}_0,h)$ exists and ${\bf x}(h)\in B_1$. We provide a complete validated algorithm for this problem. Under the assumption (promise) that for all ${\bf x}_0\in B_0$, ${\tt IVP}_{\bf f}({\bf x}_0,h)$ exists, we prove the halting of our algorithm. This is the first halting algorithm for IVP problems in such a general setting.
  We also introduce novel techniques for subroutines such as StepA and StepB, and a scaffold datastructure to support our End Enclosure algorithm. Among the techniques are new ways refine full- and end-enclosures based on a {\bf radical transform} combined with logarithm norms. Our preliminary implementation and experiments show considerable promise, and compare well with current validated algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00503v4</guid>
      <category>cs.SC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bingwei Zhang, Chee Yap</dc:creator>
    </item>
    <item>
      <title>Auditable Unit-Aware Thresholds in Symbolic Regression via Logistic-Gated Operators</title>
      <link>https://arxiv.org/abs/2510.05178</link>
      <description>arXiv:2510.05178v3 Announce Type: replace-cross 
Abstract: AI for health will only scale when models are not only accurate but also readable, auditable, and governable. Many clinical and public-health decisions hinge on numeric thresholds -- cut-points that trigger alarms, treatment, or follow-up -- yet most machine-learning systems bury those thresholds inside opaque scores or smooth response curves. We introduce logistic-gated operators (LGO) for symbolic regression, which promote thresholds to first-class, unit-aware parameters inside equations and map them back to physical units for direct comparison with guidelines. On public ICU and population-health cohorts (MIMIC-IV ICU, eICU, NHANES), LGO recovers clinically plausible gates on MAP, lactate, GCS, SpO2, BMI, fasting glucose, and waist circumference while remaining competitive with established scoring systems (AutoScore) and explainable boosting machines (EBM). The gates are sparse and selective: they appear when regime switching is supported by the data and are pruned on predominantly smooth tasks, yielding compact formulas that clinicians can inspect, stress-test, and revise. As a standalone symbolic model or a safety overlay on black-box systems, LGO helps translate observational data into auditable, unit-aware rules for medicine and other threshold-driven domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05178v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.SC</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ou Deng, Ruichen Cong, Jianting Xu, Shoji Nishimura, Atsushi Ogihara, Qun Jin</dc:creator>
    </item>
    <item>
      <title>A Qualitative Model to Reason about Object Rotations (QOR) applied to solve the Cube Comparison Test (CCT)</title>
      <link>https://arxiv.org/abs/2601.08382</link>
      <description>arXiv:2601.08382v2 Announce Type: replace-cross 
Abstract: This paper presents a Qualitative model for Reasoning about Object Rotations (QOR) which is applied to solve the Cube Comparison Test (CCT) by Ekstrom et al. (1976). A conceptual neighborhood graph relating the Rotation movement to the Location change and the Orientation change (CNGRLO) of the features on the cube sides has been built and it produces composition tables to calculate inferences for reasoning about rotations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08382v2</guid>
      <category>cs.AI</category>
      <category>cs.SC</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zoe Falomir</dc:creator>
    </item>
  </channel>
</rss>
