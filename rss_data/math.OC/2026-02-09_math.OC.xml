<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 09 Feb 2026 05:00:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Optimal Control Strategies for Epidemic Dynamics: Integrating SIR-SI and Lotka--Volterra Models</title>
      <link>https://arxiv.org/abs/2602.06178</link>
      <description>arXiv:2602.06178v1 Announce Type: new 
Abstract: In this work we present a mathematical model that integrates the epidemiological dynamics of a vector-borne disease (SIR-SI) with Lotka Volterra predator prey ecological interactions. The study analyzes how the presence of natural predators acts as a biological control mechanism to regulate the vector population and, consequently, disease transmission in host. 
We introduce the concept of the ecological reproduction number, a threshold that links the amplitude of predator prey cycles to disease persistence, showing that natural control depends critically on the ratio between the maximum vector density and the minimum predator density. In scenarios where natural control is insufficient, we formulate an optimal control problem based on the release of predators. Using the Pontryagin Maximum Principle, we characterize the optimal strategy that minimizes the cumulative number of infected individuals and intervention costs, while simultaneously maximizing the susceptible host population at the end of the time horizon. Numerical simulations validate the effectiveness of the model, showing that external intervention mitigates the epidemic peak and stabilizes the system against the natural oscillations of biological populations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06178v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rocio Balderrama, Ignacio Ceresa Dussel, Constanza Sanchez de la Vega</dc:creator>
    </item>
    <item>
      <title>Process-Based Lagrange Multipliers for Nonconvex Set-Valued Optimization</title>
      <link>https://arxiv.org/abs/2602.06186</link>
      <description>arXiv:2602.06186v1 Announce Type: new 
Abstract: We develop a Lagrange multiplier theory for nonconvex set-valued optimization problems under Lipschitz-type regularity conditions. Instead of classical continuous linear functionals, we introduce closed convex processes -- set-valued mappings whose graphs are closed convex cones -- as generalized Lagrange multipliers. This geometric framework extends separation principles beyond convexity and differentiability. We establish the existence of multiplier processes under verifiable assumptions, including Lipschitz regularity at a reference point, the existence of a bounded base of the ordering cone, and a nondegeneracy condition ensuring proper isolation of optimal values. These processes preserve global optimality: nondominated (respectively, minimal) solutions of the primal problem remain nondominated (respectively, minimal) in the penalized problem. In the scalar case, we obtain a one-to-one correspondence between multiplier processes and lower semicontinuous sublinear functions, yielding exact penalty formulations without additional constraint qualifications. An infinite-dimensional example shows that interiority conditions on the ordering cone, while sufficient, are not necessary. Applications to set-valued vector equilibrium problems are also discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06186v1</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fernando Garc\'ia-Casta\~no, Miguel \'Angel Melguizo-Padial</dc:creator>
    </item>
    <item>
      <title>Predictive Energy Management for Hybrid Powertrains</title>
      <link>https://arxiv.org/abs/2602.06277</link>
      <description>arXiv:2602.06277v1 Announce Type: new 
Abstract: Hybrid power trains (HPT) run on multiple energy sources, often involving energy storage systems/batteries (ESS). As a result, the risk of battery degradation and the reliability of energy storage elements pose a major challenge in designing an energy-efficient hybrid power train. This paper presents an energy management strategy that adaptively splits power demand between the engine and the battery pack in a hybrid power train taking into account the battery degradation. Incorporating the battery degradation model directly into the underlying optimization problem is challenging on multiple fronts: 1) Any reasonable degradation model will, due to its complexity, result in a complicated optimization problem that is impractical for real-time implementation 2) the models contain a lot of time-varying parameters that can only be determined through destructive experimental procedures. As a result, it is essential to devise heuristics that reasonably capture the degradation per usage of the batteries. One such heuristic considered in this paper is the absolute power extracted from the battery. A distributed model predictive strategy is then developed to coordinate the power split to maximize efficiency while mitigating the failure risk due to battery degradation. The designed EM strategy is demonstrated through a realistic simulation of three different hybrid power trains: hybrid road vehicles (for example: a hybrid electric vehicle (HEV)), hybrid surface vehicles (for example: dynamically positioned hybrid ships (DPS)), and hybrid aerial vehicles (for example: hybrid electric aircraft (HEA)). The results show the effectiveness of the energy management strategy in managing battery degradation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06277v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Satish Vedula, Olugbenga Anubi</dc:creator>
    </item>
    <item>
      <title>D-ripALM: A Tuning-friendly Decentralized Relative-Type Inexact Proximal Augmented Lagrangian Method</title>
      <link>https://arxiv.org/abs/2602.06398</link>
      <description>arXiv:2602.06398v1 Announce Type: new 
Abstract: This paper proposes D-ripALM, a Decentralized relative-type inexact proximal Augmented Lagrangian Method for consensus convex optimization over multi-agent networks. D-ripALM adopts a double-loop distributed optimization framework that accommodates a wide range of inner solvers, enabling efficient treatment of both smooth and nonsmooth objectives. In contrast to existing double-loop distributed augmented Lagrangian methods, D-ripALM employs a relative-type error criterion to regulate the switching between inner and outer iterations, resulting in a more practical and tuning-friendly algorithmic framework with enhanced numerical robustness. Moreover, we establish rigorous convergence guarantees for D-ripALM under general convexity assumptions, without requiring smoothness or strong convexity conditions commonly imposed in the distributed optimization literature. Numerical experiments further demonstrate the tuning-friendly nature of D-ripALM and its efficiency in attaining high-precision solutions with fewer communication rounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06398v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiayi Zhu, Hong Wang, Ling Liang, Lei Yang</dc:creator>
    </item>
    <item>
      <title>Pointwise Tracking Optimal Control Problem for Cahn Hilliard Navier Stokes system</title>
      <link>https://arxiv.org/abs/2602.06447</link>
      <description>arXiv:2602.06447v1 Announce Type: new 
Abstract: We study a pointwise tracking optimal control problem for the two-dimensional local Cahn Hilliard Navier Stokes system, which models the evolution of two immiscible, incompressible fluids. The source term in the Cahn Hilliard equation acts as a control, and the cost functional measures the deviation of the phase variable from desired values at a finite set of spatial points over time. This setting reflects realistic applications where only a limited number of sensors are available. We also study a variant of the above pointwise tracking control problem where the cost is incorporated with a terminal time pointwise tracking term. The main mathematical difficulty arises from the low regularity of the cost functional due to the pointwise evaluation of the state variables. We prove the existence of strong solutions, establish the existence of an optimal control, and the differentiability of the control to state mapping. We define the adjoint system using a transposition method to characterise optimal control. Moreover, a first-order necessary optimality condition is derived in terms of the adjoint for both problems. Furthermore, we prove that our analysis can be extended to the case of singular potentials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06447v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sheetal Dharmatti, Greeshma K</dc:creator>
    </item>
    <item>
      <title>Distributed Circumferential Coverage Control in Non-Convex Annulus Environments</title>
      <link>https://arxiv.org/abs/2602.06472</link>
      <description>arXiv:2602.06472v1 Announce Type: new 
Abstract: It has long been a prominent challenge in multi-agent systems to achieve distributed coverage of non-convex annulus environments while ensuring workload equalization among agents. To address this challenge, a distributed circumferential coverage control formulation is developed in this note by constructing a Riemannian metric for the navigation in the non-convex subregion while avoiding collisions with the region boundary. In addition, a distributed partition law is designed to balance the workload on the entire coverage region by endowing each agent with a virtual partition bar that slides along the inner boundary of coverage region. Theoretical analysis is conducted to ensure the exponential convergence of workload partition and asymptotic convergence of each agent towards the local optimum in its subregion. Finally, a case study is presented to demonstrate the effectiveness of the proposed coverage control approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06472v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chao Zhai</dc:creator>
    </item>
    <item>
      <title>Approximating the Uniform Value in Hidden Stochastic Games with Doeblin Conditions</title>
      <link>https://arxiv.org/abs/2602.06480</link>
      <description>arXiv:2602.06480v1 Announce Type: new 
Abstract: In \emph{zero-sum two-player hidden stochastic games}, players observe partial information about the state. We address: $(i)$ the existence of the \emph{uniform value}, i.e., a limiting average payoff that both players can guarantee for sufficiently long durations, and $(ii)$ the existence of an algorithm to approximate it. Previous work shows that, in the general case, the uniform value may fail to exist, and, even when it does, there need not exist an algorithm to compute or approximate it. Therefore, we consider the \emph{Doeblin condition} in hidden stochastic games, requiring that, after a sufficiently long time, the posterior beliefs have a uniformly positive probability of resetting to one of finitely many neighborhoods in the belief space. We prove the existence of the uniform value and provide an algorithm to approximate it. We identify sufficient conditions, namely \emph{ergodicity} in the blind setting (when the signal is uninformative) and \emph{primitivity} in the hidden setting (when there are multiple signals). Moreover, we show that, in the hidden setting, ergodicity does not guarantee the Doeblin condition. Our results are new even for the one-player setting, i.e., partially observable Markov decision processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06480v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Krishnendu Chatterjee, David Lurie, Raimundo Saona, Bruno Ziliotto</dc:creator>
    </item>
    <item>
      <title>Markov Decision Processes of the Third Kind: Learning Distributions by Policy Gradient Descent</title>
      <link>https://arxiv.org/abs/2602.06567</link>
      <description>arXiv:2602.06567v1 Announce Type: new 
Abstract: The goal of this paper is to analyze distributional Markov Decision Processes as a class of control problems in which the objective is to learn policies that steer the distribution of a cumulative reward toward a prescribed target law, rather than optimizing an expected value or a risk functional. To solve the resulting distributional control problem in a model-free setting, we propose a policy-gradient algorithm based on neural-network parameterizations of randomized Markov policies, defined on an augmented state space and a sample-based evaluation of the characteristic-function loss. Under mild regularity and growth assumptions, we prove convergence of the algorithm to stationary points using stochastic approximation techniques. Several numerical experiments illustrate the ability of the method to match complex target distributions, recover classical optimal policies when they exist, and reveal intrinsic non-uniqueness phenomena specific to distributional control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06567v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicole B\"auerle, Athanasios Vasileiadis</dc:creator>
    </item>
    <item>
      <title>Two-stage stochastic algorithm for solving large-scale (non)-convex separable optimization problems under affine constraints</title>
      <link>https://arxiv.org/abs/2602.06637</link>
      <description>arXiv:2602.06637v1 Announce Type: new 
Abstract: We consider nonsmooth optimization problems under affine constraints, where the objective consists of the average of the component functions of a large number $N$ of agents, and we only assume access to the Fenchel conjugate of the component functions. The algorithm of choice for solving such problems is the dual subgradient method, also known as dual decomposition, which requires $O(\frac{1}{\epsilon^2})$ iterations to reach $\epsilon$-optimality in the convex case. However, each iteration requires computing the Fenchel conjugate of each of the $N$ agents, leading to a complexity $O(\frac{N}{\epsilon^2})$ which might be prohibitive in practical applications. To overcome this, we propose a two-stage algorithm, combining a stochastic subgradient algorithm on the dual problem, followed by a block-coordinate Frank-Wolfe algorithm to obtain primal solutions. The resulting algorithm requires only $O(\frac{1}{\epsilon^2} + \frac{N}{\epsilon^{2/3}})$ calls to Fenchel conjugates to obtain an $\epsilon$-optimal primal solution in expectation in the convex case. We extend our results to nonconvex component functions and show that our method still applies and gets (almost) the same convergence rate, this time only to an approximate primal solution recovering the classical duality gap bounds usually obtained using the Shapley-Folkman theorem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06637v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benjamin Dubois-Taine, Laurent Pfeiffer, Nadia Oudjane, Adrien Seguret, Francis Bach</dc:creator>
    </item>
    <item>
      <title>Optimization-based control by interconnection of nonlinear port-Hamiltonian systems</title>
      <link>https://arxiv.org/abs/2602.06670</link>
      <description>arXiv:2602.06670v1 Announce Type: new 
Abstract: In this paper, we formulate an optimization-based control-by-interconnection approach to the stabilization problem of nonlinear port-Hamiltonian systems. Motivated by model predictive control, the feedback is defined as an initial part of a suboptimal solution of a finite horizon optimal control problem. To this end, we write the optimization method given by a primal-dual gradient dynamics arising from a possibly control-constrained optimal control problem as a port-Hamiltonian system. Then, using the port-Hamiltonian structure of the plant, we show that the MPC-type feedback law is indeed a structure-preserving interconnection of two port-Hamiltonian systems. We prove that, under an observability assumption, the interconnected system asymptotically stabilizes the plant dynamics. We illustrate the theoretical results by means of a numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06670v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hannes Gernandt, Till Preuster, Manuel Schaller</dc:creator>
    </item>
    <item>
      <title>Wasserstein Distributionally Robust Performative Prediction</title>
      <link>https://arxiv.org/abs/2602.06730</link>
      <description>arXiv:2602.06730v1 Announce Type: new 
Abstract: Performativity means that the deployment of a predictive model incentivizes agents to strategically adapt their behavior, thereby inducing a model-dependent distribution shift. Practitioners often repeatedly retrain the model on data samples to adapt to evolving distributions. In this paper, we develop a Wasserstein distributionally robust optimization framework for performative prediction, where the prediction model is optimized over the worst-case distribution within a Wasserstein ambiguity set. We allow the ambiguity radius to depend on the prediction model, which subsumes the constant-radius formulation as a special case. By leveraging strong duality, the intractable robust objective is reformulated as a computationally tractable minimization problem. Based on this formulation, we develop distributionally robust repeated risk minimization (DR-RRM) and repeated gradient descent (DR-RGD), to iteratively find an equilibrium between distributional shifts and model retraining. Theoretical analyses demonstrate that, under standard regularity conditions, both algorithms converge to a unique robust performative stable point. Our analysis explicitly accounts for inner-loop approximation errors and shows convergence to a neighborhood of the stable point in inexact settings. Additionally, we establish theoretical bounds on the suboptimality gap between the stable point and the global performative optimum. Finally, numerical simulations of a dynamic credit scoring problem demonstrate the efficacy of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06730v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Siyi Wang, Zifan Wang, Karl H. Johansson</dc:creator>
    </item>
    <item>
      <title>Convergence Rates for Stochastic Proximal and Projection Estimators</title>
      <link>https://arxiv.org/abs/2602.06750</link>
      <description>arXiv:2602.06750v1 Announce Type: new 
Abstract: In this paper, we establish explicit, non-asymptotic convergence rates for the stochastic smooth approximations of infimal convolutions introduced and developed in \cite{MR4581306,MR4923371}. In particular, we quantify the convergence of the associated barycentric estimators toward proximal mappings and metric projections. We prove a dimension-explicit $\sqrt{\delta}$ bound in the $\rho$-weakly convex (possibly nonsmooth) setting and show, by examples, that this order is sharp. Under additional regularity, namely $C^{2}$ smoothness with globally Lipschitz Hessian, we derive an improved linear $O(\delta)$ rate with explicit constants, and we obtain refined projection estimates for convex sets with local $C^{2,1}$ boundary.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06750v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Diego Morales, Pedro P\'erez-Aros, Emilio Vilches</dc:creator>
    </item>
    <item>
      <title>RanSOM: Second-Order Momentum with Randomized Scaling for Constrained and Unconstrained Optimization</title>
      <link>https://arxiv.org/abs/2602.06824</link>
      <description>arXiv:2602.06824v1 Announce Type: new 
Abstract: Momentum methods, such as Polyak's Heavy Ball, are the standard for training deep networks but suffer from curvature-induced bias in stochastic settings, limiting convergence to suboptimal $\mathcal{O}(\epsilon^{-4})$ rates. Existing corrections typically require expensive auxiliary sampling or restrictive smoothness assumptions. We propose \textbf{RanSOM}, a unified framework that eliminates this bias by replacing deterministic step sizes with randomized steps drawn from distributions with mean $\eta_t$. This modification allows us to leverage Stein-type identities to compute an exact, unbiased estimate of the momentum bias using a single Hessian-vector product computed jointly with the gradient, avoiding auxiliary queries. We instantiate this framework in two algorithms: \textbf{RanSOM-E} for unconstrained optimization (using exponentially distributed steps) and \textbf{RanSOM-B} for constrained optimization (using beta-distributed steps to strictly preserve feasibility). Theoretical analysis confirms that RanSOM recovers the optimal $\mathcal{O}(\epsilon^{-3})$ convergence rate under standard bounded noise, and achieves optimal rates for heavy-tailed noise settings ($p \in (1, 2]$) without requiring gradient clipping.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06824v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>El Mahdi Chayti</dc:creator>
    </item>
    <item>
      <title>A Mode-Matching Approach to the Design of RIS-Aided Communications</title>
      <link>https://arxiv.org/abs/2602.06840</link>
      <description>arXiv:2602.06840v1 Announce Type: new 
Abstract: Reconfigurable intelligent surface (RIS) is an emerging technology for application to wireless communications. In this paper, we consider the problem of anomalous reflection and model the RIS as a periodic surface impedance boundary. We utilize the mode matching method and Floquets expansion representation to compute the field reflected from a spatially periodic RIS, and evaluate the performance versus implementation complexity tradeoffs of RIS aided communications based on the global design criterion. This allows us to maximize the power reflected towards the intended direction of propagation, while minimizing the power reradiated towards undesired directions of propagation. In addition, we discuss the advantages of the proposed electromagnetically consistent approach to the design of RIS aided wireless systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06840v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmed Najjar, Hajar El Hassani, Marco Di Renzo, Kezhi Wang, Merouane Debbah</dc:creator>
    </item>
    <item>
      <title>Circuit Diameter of Polyhedra is Strongly Polynomial</title>
      <link>https://arxiv.org/abs/2602.06958</link>
      <description>arXiv:2602.06958v1 Announce Type: new 
Abstract: We prove a strongly polynomial bound on the circuit diameter of polyhedra, resolving the circuit analogue of the polynomial Hirsch conjecture. Specifically, we show that the circuit diameter of a polyhedron $P = \{x\in \mathbb{R}^n:\, A x = b, \, x \ge 0\}$ with $A\in\mathbb{R}^{m\times n}$ is $O(m^2 \log m)$. Our construction yields monotone circuit walks, giving the same bound for the monotone circuit diameter.
  The circuit diameter, introduced by Borgwardt, Finhold, and Hemmecke (SIDMA 2015), is a natural relaxation of the combinatorial diameter that allows steps along circuit directions rather than only along edges. All prior upper bounds on the circuit diameter were only weakly polynomial. Finding a circuit augmentation algorithm that matches this bound would yield a strongly polynomial time algorithm for linear programming, resolving Smale's 9th problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06958v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bento Natura</dc:creator>
    </item>
    <item>
      <title>Optimistic Training and Convergence of Q-Learning -- Extended Version</title>
      <link>https://arxiv.org/abs/2602.06146</link>
      <description>arXiv:2602.06146v1 Announce Type: cross 
Abstract: In recent work it is shown that Q-learning with linear function approximation is stable, in the sense of bounded parameter estimates, under the $(\varepsilon,\kappa)$-tamed Gibbs policy; $\kappa$ is inverse temperature, and $\varepsilon&gt;0$ is introduced for additional exploration. Under these assumptions it also follows that there is a solution to the projected Bellman equation (PBE). Left open is uniqueness of the solution, and criteria for convergence outside of the standard tabular or linear MDP settings.
  The present work extends these results to other variants of Q-learning, and clarifies prior work: a one dimensional example shows that under an oblivious policy for training there may be no solution to the PBE, or multiple solutions, and in each case the algorithm is not stable under oblivious training.
  The main contribution is that far more structure is required for convergence. An example is presented for which the basis is ideal, in the sense that the true Q-function is in the span of the basis. However, there are two solutions to the PBE under the greedy policy, and hence also for the $(\varepsilon,\kappa)$-tamed Gibbs policy for all sufficiently small $\varepsilon&gt;0$ and $\kappa\ge 1$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06146v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Prashant Mehta, Sean Meyn</dc:creator>
    </item>
    <item>
      <title>Optimal wind farm energy and reserve scheduling incorporating wake interactions</title>
      <link>https://arxiv.org/abs/2602.06165</link>
      <description>arXiv:2602.06165v1 Announce Type: cross 
Abstract: This paper proposes a novel approach for optimal energy and reserve scheduling of wind farms by explicitly modelling wake interactions to enhance market participation and operational efficiency. Conventional methods often neglect wake effects, relying on power curve estimations that represent an upper limit and reduce market performance. To address this, a two-stage stochastic programming framework is developed, integrating a wake-aware power estimation model within the FLORIS simulation software. Wind and reserve uncertainties are addressed through scenario generation and reduction, enabling wind power producers to optimise participation in day-ahead energy and ancillary services markets, with particular focus on the Frequency Restoration Reserve (FRR). The wake-aware model provides more realistic power output predictions based on site-specific wind and atmospheric conditions, improving scheduling accuracy and reducing imbalance penalties. Wake steering is further employed to mitigate wake-induced losses and increase income through participation in ancillary services. The proposed approach is evaluated through a case study of the London Array offshore wind farm participating in the Great Britain (GB) electricity markets. Results show that conventional methods estimate production 12-13% higher, leading to imbalance penalties and 3% lower revenue compared with the wake-aware approach accounting for wake interactions. Moreover, the steering-enhanced approach yields an additional 1-2% increase in income relative to the wake-aware baseline. These findings underscore the value of accounting for wake interactions in wind farm scheduling and demonstrate the economic and operational benefits of active wake management, offering insights for improving grid stability and profitability as wind penetration continues to rise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06165v1</guid>
      <category>physics.flu-dyn</category>
      <category>math.OC</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.2139/ssrn.5272512</arxiv:DOI>
      <dc:creator>Marin Mabboux-Fort, Majid Bastankhah, Peter C Matthews, Mokhtar Bozorg</dc:creator>
    </item>
    <item>
      <title>PurSAMERE: Reliable Adversarial Purification via Sharpness-Aware Minimization of Expected Reconstruction Error</title>
      <link>https://arxiv.org/abs/2602.06269</link>
      <description>arXiv:2602.06269v1 Announce Type: cross 
Abstract: We propose a novel deterministic purification method to improve adversarial robustness by mapping a potentially adversarial sample toward a nearby sample that lies close to a mode of the data distribution, where classifiers are more reliable. We design the method to be deterministic to ensure reliable test accuracy and to prevent the degradation of effective robustness observed in stochastic purification approaches when the adversary has full knowledge of the system and its randomness. We employ a score model trained by minimizing the expected reconstruction error of noise-corrupted data, thereby learning the structural characteristics of the input data distribution. Given a potentially adversarial input, the method searches within its local neighborhood for a purified sample that minimizes the expected reconstruction error under noise corruption and then feeds this purified sample to the classifier. During purification, sharpness-aware minimization is used to guide the purified samples toward flat regions of the expected reconstruction error landscape, thereby enhancing robustness. We further show that, as the noise level decreases, minimizing the expected reconstruction error biases the purified sample toward local maximizers of the Gaussian-smoothed density; under additional local assumptions on the score model, we prove recovery of a local maximizer in the small-noise limit. Experimental results demonstrate significant gains in adversarial robustness over state-of-the-art methods under strong deterministic white-box attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06269v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vinh Hoang, Sebastian Krumscheid, Holger Rauhut, Ra\'ul Tempone</dc:creator>
    </item>
    <item>
      <title>Achieving Better Local Regret Bound for Online Non-Convex Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2602.06457</link>
      <description>arXiv:2602.06457v1 Announce Type: cross 
Abstract: Online bilevel optimization (OBO) has emerged as a powerful framework for many machine learning problems. Prior works have developed several algorithms that minimize the standard bilevel local regret or the window-averaged bilevel local regret of the OBO problem, but the optimality of existing regret bounds remains unclear. In this work, we establish optimal regret bounds for both settings. For standard bilevel local regret, we propose an algorithm that achieves the optimal regret $\Omega(1+V_T)$ with at most $O(T\log T)$ total inner-level gradient evaluations. We further develop a fully single-loop algorithm whose regret bound includes an additional gradient-variation terms. For the window-averaged bilevel local regret, we design an algorithm that captures sublinear environmental variation through a window-based analysis and achieves the optimal regret $\Omega(T/W^2)$. Experiments validate our theoretical findings and demonstrate the practical effectiveness of the proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06457v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tingkai Jia, Haiguang Wang, Cheng Chen</dc:creator>
    </item>
    <item>
      <title>Structural bias in multi-objective optimisation</title>
      <link>https://arxiv.org/abs/2602.06742</link>
      <description>arXiv:2602.06742v1 Announce Type: cross 
Abstract: Structural bias (SB) refers to systematic preferences of an optimisation algorithm for particular regions of the search space that arise independently of the objective function. While SB has been studied extensively in single-objective optimisation, its role in multi-objective optimisation remains largely unexplored. This is problematic, as dominance relations, diversity preservation and Pareto-based selection mechanisms may introduce or amplify structural effects.
  In this paper, we extend the concept of structural bias to the multi-objective setting and propose a methodology to study it in isolation from fitness-driven guidance. We introduce a suite of synthetic multi-objective test problems with analytically controlled Pareto fronts and deliberately uninformative objective values. These problems are designed to decouple algorithmic behaviour from problem structure, allowing bias induced purely by algorithmic operators and design choices to be observed. The test suite covers a range of Pareto front shapes, densities and noise levels, enabling systematic analysis of different manifestations of structural bias.
  We discuss methodological challenges specific to the multi-objective case and outline how existing SB detection approaches can be adapted. This work provides a first step towards behaviour-based benchmarking of multi-objective optimisers, complementing performance-based evaluation and informing more robust algorithm design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06742v1</guid>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jakub Kudela, Niki van Stein, Thomas B\"ack, Anna V. Kononova</dc:creator>
    </item>
    <item>
      <title>Continuous-time reinforcement learning: ellipticity enables model-free value function approximation</title>
      <link>https://arxiv.org/abs/2602.06930</link>
      <description>arXiv:2602.06930v1 Announce Type: cross 
Abstract: We study off-policy reinforcement learning for controlling continuous-time Markov diffusion processes with discrete-time observations and actions. We consider model-free algorithms with function approximation that learn value and advantage functions directly from data, without unrealistic structural assumptions on the dynamics.
  Leveraging the ellipticity of the diffusions, we establish a new class of Hilbert-space positive definiteness and boundedness properties for the Bellman operators. Based on these properties, we propose the Sobolev-prox fitted $q$-learning algorithm, which learns value and advantage functions by iteratively solving least-squares regression problems. We derive oracle inequalities for the estimation error, governed by (i) the best approximation error of the function classes, (ii) their localized complexity, (iii) exponentially decaying optimization error, and (iv) numerical discretization error. These results identify ellipticity as a key structural property that renders reinforcement learning with function approximation for Markov diffusions no harder than supervised learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06930v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenlong Mou</dc:creator>
    </item>
    <item>
      <title>Integrated timetabling and scheduling of modular autonomous vehicles under uncertainty</title>
      <link>https://arxiv.org/abs/2410.16409</link>
      <description>arXiv:2410.16409v2 Announce Type: replace 
Abstract: Addressing the Integrated Timetabling and Vehicle Scheduling (TTVS) problem is important for improving transit operations. Recently, the emerging modular autonomous vehicles composed of modular autonomous units have made it possible to dynamically adjust on-board capacity to better match space-time imbalanced passenger flows. This paper introduces an integrated framework for the TTVS problem in a dynamically capacitated and modularized bus network, considering time-varying and uncertain passenger demand. In this network, units can be decoupled and rerouted across different lines within the network at various times and locations, providing passengers with the opportunity to make in-vehicle transfers -- that is, to transfer between lines while remaining onboard. We formulate a stochastic programming model to jointly determine the optimal robust timetable, dynamic formations of vehicles, and cross-line circulations of units, aiming to minimize the weighted sum of operator and passenger costs. To solve realistic instances, we propose a tailored integer L-shaped method that dynamically solves the model through a rolling-horizon optimization algorithm. Furthermore, we extend our approach into a novel learning-based real-time decision-making framework that fine-tunes timetables and re-optimizes vehicle schedules in response to evolving and new demand realizations during operations. At its core is a scenario-retention method that selects a representative subset of scenarios using a machine learning model trained on scenario-level features. This subset is then incorporated into the optimization, ensuring both computational scalability and solution quality. To validate the effectiveness of our methods, we conduct experiments based on the Beijing bus network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16409v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Dongyang Xia, Jihui Ma, Shadi Sharif Azadeh</dc:creator>
    </item>
    <item>
      <title>Stochastic LQR Design With Disturbance Preview</title>
      <link>https://arxiv.org/abs/2412.06662</link>
      <description>arXiv:2412.06662v5 Announce Type: replace 
Abstract: This paper considers the discrete-time, stochastic LQR problem with $p$ steps of disturbance preview information where $p$ is finite. We first derive the solution for this problem on a finite horizon with linear, time-varying dynamics and time-varying costs. Next, we derive the solution on the infinite horizon with linear, time-invariant dynamics and time-invariant costs. Our proofs rely on the well-known principle of optimality. We provide an independent proof for the principle of optimality that relies only on nested information structure. Finally, we show that the finite preview controller converges to the optimal noncausal controller as the preview horizon $p$ tends to infinity. We also provide a simple example to illustrate both the finite and infinite horizon results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06662v5</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jietian Liu, Laurent Lessard, Peter Seiler</dc:creator>
    </item>
    <item>
      <title>From a Frequency-Domain Willems' Lemma to Data-Driven Predictive Control</title>
      <link>https://arxiv.org/abs/2501.19390</link>
      <description>arXiv:2501.19390v2 Announce Type: replace 
Abstract: Willems' fundamental lemma has recently received an impressive amount of attention from the data-driven control community. In this paper, we formulate a version of this celebrated result based on frequency-domain data. In doing so, we bridge the gap between recent developments in data-driven control, and the readily-available techniques and expertise for non-parametric frequency-domain identification. We also generalize our results to combine multiple frequency-domain data sets to form a sufficiently rich data set. Building on these results, we propose a data-driven predictive control scheme based on measured frequency-domain data of the plant. This novel scheme provides a frequency-domain counterpart of the well-known data-enabled predictive control scheme DeePC based on time-domain data. Under appropriate conditions, the new frequency-domain data-driven predictive control (FreePC) scheme is equivalent to the corresponding DeePC scheme. We demonstrate the benefits of FreePC and the use of frequency-domain data in several examples and a numerical case study, including the ability to collect data in closed loop, computational benefits, and intuitive visualization of the data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.19390v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>T. J. Meijer, K. J. A. Scheres, S. A. N. Nouwens, V. S. Dolk, W. P. M. H. Heemels</dc:creator>
    </item>
    <item>
      <title>Data-driven Model Predictive Control: Asymptotic Stability despite Approximation Errors exemplified in the Koopman framework</title>
      <link>https://arxiv.org/abs/2505.05951</link>
      <description>arXiv:2505.05951v3 Announce Type: replace 
Abstract: In this paper, we analyze stability of nonlinear model predictive control (MPC) using data-driven surrogate models in the optimization step. First, we establish asymptotic stability of the origin, a controlled steady state, w.r.t. the MPC closed loop without stabilizing terminal conditions for sufficiently long prediction horizons. To this end, we prove that cost controllability of the original system is preserved if sufficiently accurate proportional bounds on the approximation error hold. Here, proportional refers to state and control. The proportionality of the error bounds is a key element to derive asymptotic stability in presence of modeling errors and not only practical asymptotic stability. Second, we exemplarily verify the imposed assumptions for data-driven surrogates generated with kernel extended dynamic mode decomposition based on Koopman operator theory. Hereby, we do not impose invariance assumptions on finite dictionaries, but rather derive all conditions under non-restrictive conditions. Finally, we demonstrate our findings with numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05951v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Irene Schimperna, Karl Worthmann, Manuel Schaller, Lea Bold, Lalo Magni</dc:creator>
    </item>
    <item>
      <title>A Berger-Wang formula for impulsive switched systems</title>
      <link>https://arxiv.org/abs/2507.02434</link>
      <description>arXiv:2507.02434v3 Announce Type: replace 
Abstract: This paper addresses a class of impulsive systems defined by a mix of continuous-time and discrete-time switched linear dynamics. We first analyze a related class of weighted discrete-time switched systems for which we establish a Berger--Wang-type result. An analogous result is then derived for impulsive systems and subsequently used to characterize their exponential stability through a spectral approach, thereby extending existing results in switched-systems theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.02434v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yacine Chitour (L2S), Jamal Daafouz (IUF, CRAN), Ihab Haidar (ENSEA, LJLL), Paolo Mason (L2S), Mario Sigalotti (LJLL)</dc:creator>
    </item>
    <item>
      <title>Stability criteria for singularly perturbed impulsive linear switched systems</title>
      <link>https://arxiv.org/abs/2507.02446</link>
      <description>arXiv:2507.02446v3 Announce Type: replace 
Abstract: We study a class of singularly perturbed impulsive linear switched systems exhibiting switching between slow and fast dynamics. To analyze their behavior, we construct auxiliary switched systems evolving in a single time scale. We prove that the stability or instability of these auxiliary systems directly determines that of the original system in the regime of small singular perturbation parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.02446v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ihab Haidar (ENSEA, LJLL), Yacine Chitour (L2S), Jamal Daafouz (IUF, CRAN), Paolo Mason (L2S), Mario Sigalotti (LJLL)</dc:creator>
    </item>
    <item>
      <title>A Correspondence-Driven Approach for Bilevel Decision-making with Nonconvex Lower-Level Problems</title>
      <link>https://arxiv.org/abs/2509.01148</link>
      <description>arXiv:2509.01148v3 Announce Type: replace 
Abstract: We consider bilevel optimization problems with general nonconvex lower-level objectives and show that the classical hyperfunction-based formulation is unsettled, since the global minimizer of the lower-level problem is generally unattainable. To address this issue, we propose a correspondence-driven hyperfunction $\phi^{\text{cd}}$. In this formulation, the follower is modeled not as a rational agent always attaining a global minimizer, but as an algorithm-based bounded rational agent whose decisions are produced by a fixed algorithm with initialization and step size. Since $\phi^{\text{cd}}$ is generally discontinuous, we apply Gaussian smoothing to obtain a smooth approximation $\phi^{\text{cd}}_\xi$, then show that its value and gradient converge to those of $\phi^{\text{cd}}$. In the nonconvex setting, we identify that bifurcation phenomena, which arise when $g(x,\cdot)$ has a degenerate stationary point, pose a key challenge for hyperfunction-based methods. This is especially the case when $\phi^{\text{cd}}_\xi$ is solved using gradient methods. To overcome this challenge, we analyze the geometric structure of the bifurcation set under some weak assumptions. Building on these results, we design a biased projected SGD-based algorithm SCiNBiO to solve $\phi^{\text{cd}}_\xi$ with a cubic-regularized Newton lower-level solver. We also provide convergence guarantees and oracle complexity bounds for the upper level. Finally, we connect bifurcation theory from dynamical systems to the bilevel setting and define the notion of fold bifurcation points in this setting. Under the assumption that all degenerate stationary points are fold bifurcation points, we establish the oracle complexity of SCiNBiO for the lower-level problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01148v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaotian Jiang, Jiaxiang Li, Jiawen Bi, Mingyi Hong, Shuzhong Zhang</dc:creator>
    </item>
    <item>
      <title>Projection-width as a structural parameter for discrete separable optimization</title>
      <link>https://arxiv.org/abs/2511.02990</link>
      <description>arXiv:2511.02990v2 Announce Type: replace 
Abstract: While several classes of integer linear optimization problems are known to be solvable in polynomial time, far fewer tractability results exist for integer nonlinear optimization. In this work, we narrow this gap by identifying a broad class of discrete nonlinear optimization problems that admit polynomial-time algorithms. Central to our approach is the notion of projection-width, a structural parameter for systems of separable constraints, defined via branch decompositions of variables and constraints. We show that several fundamental discrete optimization and counting problems can be solved in polynomial time when the projection-width is polynomially bounded, including optimization, counting, top-k, and weighted constraint violation problems. Our results subsume and generalize some of the strongest known tractability results across multiple research areas: integer linear optimization, binary polynomial optimization, and Boolean satisfiability. Although these results originated independently within different communities and for seemingly distinct problem classes, our framework unifies and significantly generalizes them under a single structural perspective.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02990v2</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alberto Del Pia</dc:creator>
    </item>
    <item>
      <title>Optimal Sequential Flows</title>
      <link>https://arxiv.org/abs/2511.13806</link>
      <description>arXiv:2511.13806v2 Announce Type: replace 
Abstract: We provide a new algebraic technique to solve the sequential flow problem in polynomial space. The task is to maximise the flow through a graph where edge capacities can be changed over time by choosing a sequence of capacity labelings from a given finite set. Our method is based on a novel factorization theorem for finite semigroups that, applied to a suitable flow semigroup, allows to derive small witnesses. This generalises to multiple in/output vertices, as well as regular constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13806v2</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>cs.FL</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hugo Gimbert, Corto Mascle, Patrick Totzke</dc:creator>
    </item>
    <item>
      <title>A Unified Algorithm for Nonconvex Decentralized Nonlinear Optimization</title>
      <link>https://arxiv.org/abs/2511.19182</link>
      <description>arXiv:2511.19182v2 Announce Type: replace 
Abstract: In this paper, we study the decentralized optimization problem of minimizing a finite sum of continuously differentiable and possibly nonconvex functions over a fixed-connected undirected network. We propose a unified decentralized nonconvex algorithmic framework that includes many existing state-of-the-art gradient tracking algorithms and quasi-Newton algorithms. A general framework for the convergence analysis of our unified algorithm is presented under both nonconvex and the Kurdyka-{\L}ojasiewicz condition settings. In particular, some new quasi-Newton algorithms under this framework are proposed. Our numerical results show that these newly developed algorithms are very efficient compared with other state-of-the-art algorithms for solving decentralized nonconvex nonlinear optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19182v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hao Wu, Liping Wang, Hongchao Zhang</dc:creator>
    </item>
    <item>
      <title>D-PDLP: Scaling PDLP to Distributed Multi-GPU Systems</title>
      <link>https://arxiv.org/abs/2601.07628</link>
      <description>arXiv:2601.07628v2 Announce Type: replace 
Abstract: We present a distributed framework of the Primal-Dual Hybrid Gradient (PDHG) algorithm for solving massive-scale linear programming (LP) problems. Although PDHG-based solvers demonstrate strong performance on single-node GPU architectures, their applicability to industrial-scale instances is often limited by single-GPU computational throughput. To overcome these challenges, we propose D-PDLP, the first Distributed PDLP framework, which extends PDHG to a multi-GPU setting via a practical two-dimensional grid partitioning of the constraint matrix. To improve load balance and computational efficiency, we introduce a block-wise random permutation strategy combined with nonzero-aware matrix partitioning. By distributing the intensive computation required in PDHG iterations, the proposed framework harnesses multi-GPU parallelism to achieve substantial speedups with relatively low communication overhead. Extensive experiments on standard LP benchmarks (including MIPLIB and Mittelmann instances) as well as huge-scale real-world datasets show that our distributed implementation, built upon cuPDLPx, achieves strong scalability and high performance while preserving full FP64 numerical accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07628v2</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongpei Li, Yicheng Huang, Huikang Liu, Dongdong Ge, Yinyu Ye</dc:creator>
    </item>
    <item>
      <title>Regret of $H_\infty$ Preview Controllers</title>
      <link>https://arxiv.org/abs/2602.01420</link>
      <description>arXiv:2602.01420v2 Announce Type: replace 
Abstract: This paper studies preview control in both the $H_\infty$ and regret-optimal settings. The plant is modeled as a discrete-time, linear time-invariant system subject to external disturbances. The performance baseline is the optimal non-causal controller that has full knowledge of the disturbance sequence. We first review the construction of the $H_\infty$ preview controller with $p$-steps of disturbance preview. We then show that the closed-loop $H_\infty$ performance of this preview controller converges as $p\to \infty$ to the performance of the optimal non-causal controller. Furthermore, we prove that the optimal regret of the preview controller converges to zero. These results demonstrate that increasing preview length allows controllers to asymptotically achieve non-causal performance in both the $H_\infty$ and regret frameworks. A numerical example illustrates the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01420v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jietian Liu, Peter Seiler</dc:creator>
    </item>
    <item>
      <title>A Multi-Token Coordinate Descent Method for Semi-Decentralized Vertical Federated Learning</title>
      <link>https://arxiv.org/abs/2309.09977</link>
      <description>arXiv:2309.09977v2 Announce Type: replace-cross 
Abstract: Most federated learning (FL) methods use a client-server scheme, where clients communicate only with a central server. However, this scheme is prone to bandwidth bottlenecks at the server and has a single point of failure. In contrast, in a (fully) decentralized approach, clients communicate directly with each other, dispensing with the server and mitigating these issues. Yet, as the client network grows larger and sparser, the convergence of decentralized methods slows down, even failing to converge if the network is disconnected. This work addresses this gap between client-server and decentralized schemes, focusing on the vertical FL setup, where clients hold different features of the same samples. We propose multi-token coordinate descent (MTCD), a flexible semi-decentralized method for vertical FL that can exploit both client-server and client-client links. By selecting appropriate hyperparameters, MTCD recovers the client-sever and decentralized schemes as special cases. In fact, its decentralized instance is itself a novel method of independent interest. Yet, by controlling the degree of dependency on client-server links, MTCD can also explore a spectrum of schemes ranging from client-server to decentralized. We prove that, for sufficiently large batch sizes, MTCD converges at an $\mathcal{O}(1/T)$ rate for nonconvex objectives when the tokens roam across disjoint subsets of clients. To capture the aforementioned drawbacks of the client-server scheme succinctly, we model the relative impact of using client-server versus client-client links as the ratio of their "costs", which depends on the application. This allows us to demonstrate, both analytically and empirically, that by tuning the degree of dependency on the server, the semi-decentralized instances of MTCD can outperform both client-server and decentralized approaches across a range of applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.09977v2</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pedro Valdeira, Yuejie Chi, Cl\'audia Soares, Jo\~ao Xavier</dc:creator>
    </item>
    <item>
      <title>DUST: A Framework for Data-Driven Density Steering</title>
      <link>https://arxiv.org/abs/2408.02777</link>
      <description>arXiv:2408.02777v3 Announce Type: replace-cross 
Abstract: We consider the problem of data-driven stochastic optimal control of an unknown LTI dynamical system. Assuming the process noise is normally distributed, we pose the problem of steering the state's mean and covariance to a target normal distribution, under noisy data collected from the underlying system, a problem commonly referred to as covariance steering (CS). A novel framework for Data-driven Uncertainty quantification and density STeering (DUST) is presented that simultaneously characterizes the noise affecting the measured data and designs an optimal affine-feedback controller to steer the density of the state to a prescribed terminal value. We use both indirect and direct data-driven design approaches based on the notions of persistency of excitation and subspace identification to exactly represent the mean and covariance dynamics of the state in terms of the data and noise realizations. Since both the mean and the covariance steering sub-problems are plagued with stochastic uncertainty arising from noisy data collection, we first estimate the noise realization from this dataset and subsequently compute tractable upper bounds on the estimation errors. The first and second moment steering problems are then solved to optimality using techniques from robust control and robust optimization. Lastly, we present an alternative control design approach based on the certainty equivalence principle and interpret the problem as one of CS under multiplicative uncertainty. We analyze the performance and efficacy of each of these data-driven approaches using a case study and compare them with their model-based counterparts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02777v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua Pilipovsky, Panagiotis Tsiotras</dc:creator>
    </item>
    <item>
      <title>Dataset Distillation as Pushforward Optimal Quantization</title>
      <link>https://arxiv.org/abs/2501.07681</link>
      <description>arXiv:2501.07681v3 Announce Type: replace-cross 
Abstract: Dataset distillation aims to find a synthetic training set such that training on the synthetic data achieves similar performance to training on real data, with orders of magnitude less computational requirements. Existing methods can be broadly categorized as either bi-level optimization problems that have neural network training heuristics as the lower level problem, or disentangled methods that bypass the bi-level optimization by matching distributions of data. The latter method has the major advantages of speed and scalability in terms of size of both training and distilled datasets. We demonstrate that when equipped with an encoder-decoder structure, the empirically successful disentangled methods can be reformulated as an optimal quantization problem, where a finite set of points is found to approximate the underlying probability measure by minimizing the expected projection distance. In particular, we link existing disentangled dataset distillation methods to the classical optimal quantization and Wasserstein barycenter problems, demonstrating consistency of distilled datasets for diffusion-based generative priors. We propose Dataset Distillation by Optimal Quantization, based on clustering in a latent space. Compared to the previous SOTA method D\textsuperscript{4}M, we achieve better performance and inter-model generalization on the ImageNet-1K dataset with trivial additional computation, and SOTA performance in higher image-per-class settings. Using the distilled noise initializations in a stronger diffusion transformer model, we obtain SOTA distillation performance on ImageNet-1K and its subsets, outperforming diffusion guidance methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07681v3</guid>
      <category>cs.LG</category>
      <category>cs.CV</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hong Ye Tan, Emma Slade</dc:creator>
    </item>
    <item>
      <title>Reservoir Predictive Path Integral Control for Unknown Nonlinear Dynamics</title>
      <link>https://arxiv.org/abs/2509.03839</link>
      <description>arXiv:2509.03839v2 Announce Type: replace-cross 
Abstract: Neural networks have found extensive application in data-driven control of nonlinear dynamical systems, yet fast online identification and control of unknown dynamics remain central challenges. To meet these challenges, this paper integrates echo-state networks (ESNs)--reservoir computing models implemented with recurrent neural networks--and model predictive path integral (MPPI) control--sampling-based variants of model predictive control. The proposed reservoir predictive path integral (RPPI) enables fast learning of nonlinear dynamics with ESNs and exploits the learned nonlinearities directly in MPPI control computation without linearization approximations. This framework is further extended to uncertainty-aware RPPI (URPPI), which achieves robust stochastic control by treating ESN output weights as random variables and minimizing an expected cost over their distribution to account for identification errors. Experiments on controlling a Duffing oscillator and a four-tank system demonstrate that URPPI improves control performance, reducing control costs by up to 60% compared to traditional quadratic programming-based model predictive control methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03839v2</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <category>nlin.CD</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daisuke Inoue, Tadayoshi Matsumori, Gouhei Tanaka, Yuji Ito</dc:creator>
    </item>
    <item>
      <title>A Unified Framework for Lifted Training and Inversion Approaches</title>
      <link>https://arxiv.org/abs/2510.09796</link>
      <description>arXiv:2510.09796v2 Announce Type: replace-cross 
Abstract: The training of deep neural networks predominantly relies on a combination of gradient-based optimisation and back-propagation for the computation of the gradient. While incredibly successful, this approach faces challenges such as vanishing or exploding gradients, difficulties with non-smooth activations, and an inherently sequential structure that limits parallelisation. Lifted training methods offer an alternative by reformulating the nested optimisation problem into a higher-dimensional, constrained optimisation problem where the constraints are no longer enforced directly but penalised with penalty terms. This chapter introduces a unified framework that encapsulates various lifted training strategies, including the Method of Auxiliary Coordinates, Fenchel Lifted Networks, and Lifted Bregman Training, and demonstrates how diverse architectures, such as Multi-Layer Perceptrons, Residual Neural Networks, and Proximal Neural Networks fit within this structure. By leveraging tools from convex optimisation, particularly Bregman distances, the framework facilitates distributed optimisation, accommodates non-differentiable proximal activations, and can improve the conditioning of the training landscape. We discuss the implementation of these methods using block-coordinate descent strategies, including deterministic implementations enhanced by accelerated and adaptive optimisation techniques, as well as implicit stochastic gradient methods. Furthermore, we explore the application of this framework to inverse problems, detailing methodologies for both the training of specialised networks (e.g., unrolled architectures) and the stable inversion of pre-trained networks. Numerical results on standard imaging tasks validate the effectiveness and stability of the lifted Bregman approach compared to conventional training, particularly for architectures employing proximal activations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09796v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoyu Wang, Alexandra Valavanis, Azhir Mahmood, Andreas Mang, Martin Benning, Audrey Repetti</dc:creator>
    </item>
    <item>
      <title>The Blueprints of Intelligence: A Functional-Topological Foundation for Perception and Representation</title>
      <link>https://arxiv.org/abs/2512.05089</link>
      <description>arXiv:2512.05089v5 Announce Type: replace-cross 
Abstract: Real-world phenomena do not generate arbitrary variability: their signals concentrate on compact, low-variability subsets of functional space, enabling rapid generalization from few examples. A small child can recognize a dog after extremely limited exposure because the perceptual manifold of "dog" is compact, structured, and low-dimensional. We formalize this principle through a deterministic functional-topological framework in which the set of valid realizations produced by a physical process forms a compact subset of a Banach space, endowed with stable invariants, a finite Hausdorff radius, and an induced continuous perceptual functional.
  This geometry provides explicit limits on knowledge, conditions for identifiability, and guarantees for generalization from sparse evidence -- properties fundamental to both natural and artificial intelligence. Across electromechanical, electrochemical, and physiological domains, we show that real-world processes consistently generate compact perceptual manifolds with the same geometric characteristics. Their boundaries can be discovered in a fully self-supervised manner as the empirical radius saturates with increasing sampling, even when the governing equations are unknown.
  These results demonstrate that deterministic functional topology offers a unified mathematical foundation for perception, representation, and world-model construction. It provides a geometric explanation for why biological learners and self-supervised AI systems can generalize from few observations, and establishes compact perceptual manifolds as a fundamental building block for future AI architectures. Finally, this work unifies biological perception and modern self-supervised models under a single geometric principle: both derive their generalization ability from the compactness and invariants of real-world perceptual manifolds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05089v5</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eduardo Di Santi</dc:creator>
    </item>
    <item>
      <title>Stochastic Perturbation of Sweeping Process for Uniformly Prox-Regular Moving Sets</title>
      <link>https://arxiv.org/abs/2601.11445</link>
      <description>arXiv:2601.11445v2 Announce Type: replace-cross 
Abstract: In this paper, we study the existence of solutions to a sweeping process in the presence of stochastic perturbations, where the moving set takes uniformly prox-regular values and varies continuously with respect to the Hausdorff distance, without smoothness assumptions. We consider several geometric assumptions and establish important relationships between them.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.11445v2</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juan Guillermo Garrido, Nabil Kazi-Tani, Emilio Vilches</dc:creator>
    </item>
    <item>
      <title>Generalized Logarithmic Sobolev Inequality by the JKO Scheme</title>
      <link>https://arxiv.org/abs/2601.16620</link>
      <description>arXiv:2601.16620v3 Announce Type: replace-cross 
Abstract: Using a discrete Bakry-{\'E}mery method based on the JKO scheme, relying on the dissipation of entropy and Fisher information along a discrete flow, we establish new generalized logarithmic Sobolev inequality for log-concave measures of the form $e^{-V}$ under strict convexity assumptions on $V$ . We then show how this method recovers some well-known inequalities. This approach can be viewed as interpolating between the Bakry-{\'E}mery method and optimal transport techniques based on geodesic convexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16620v3</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thibault Caillet (IUT Saint-Denis), Fanch Coudreuse (ICJ, UCBL, MMCS)</dc:creator>
    </item>
  </channel>
</rss>
