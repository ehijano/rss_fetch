<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cond-mat.dis-nn updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cond-mat.dis-nn</link>
    <description>cond-mat.dis-nn updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cond-mat.dis-nn" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 23 Apr 2024 04:00:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 23 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Solution space and storage capacity of fully connected two-layer neural networks with generic activation functions</title>
      <link>https://arxiv.org/abs/2404.13404</link>
      <description>arXiv:2404.13404v1 Announce Type: new 
Abstract: The storage capacity of a binary classification model is the maximum number of random input-output pairs per parameter that the model can learn. It is one of the indicators of the expressive power of machine learning models and is important for comparing the performance of various models. In this study, we analyze the structure of the solution space and the storage capacity of fully connected two-layer neural networks with general activation functions using the replica method from statistical physics. Our results demonstrate that the storage capacity per parameter remains finite even with infinite width and that the weights of the network exhibit negative correlations, leading to a 'division of labor'. In addition, we find that increasing the dataset size triggers a phase transition at a certain transition point where the permutation symmetry of weights is broken, resulting in the solution space splitting into disjoint regions. We identify the dependence of this transition point and the storage capacity on the choice of activation function. These findings contribute to understanding the influence of activation functions and the number of parameters on the structure of the solution space, potentially offering insights for selecting appropriate architectures based on specific objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13404v1</guid>
      <category>cond-mat.dis-nn</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sota Nishiyama, Masayuki Ohzeki</dc:creator>
    </item>
    <item>
      <title>Uncovering Obscured Phonon Dynamics from Powder Inelastic Neutron Scattering using Machine Learning</title>
      <link>https://arxiv.org/abs/2404.13507</link>
      <description>arXiv:2404.13507v1 Announce Type: cross 
Abstract: The study of phonon dynamics is pivotal for understanding material properties, yet it faces challenges due to the irreversible information loss inherent in powder inelastic neutron scattering spectra and the limitations of traditional analysis methods. In this study, we present a machine learning framework designed to reveal obscured phonon dynamics from powder spectra. Using a variational autoencoder, we obtain a disentangled latent representation of spectra and successfully extract force constants for reconstructing phonon dispersions. Notably, our model demonstrates effective applicability to experimental data even when trained exclusively on physics-based simulations. The fine-tuning with experimental spectra further mitigates issues arising from domain shift. Analysis of latent space underscores the model's versatility and generalizability, affirming its suitability for complex system applications. Furthermore, our framework's two-stage design is promising for developing a universal pre-trained feature extractor. This approach has the potential to revolutionize neutron measurements of phonon dynamics, offering researchers a potent tool to decipher intricate spectra and gain valuable insights into the intrinsic physics of materials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13507v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>cond-mat.dis-nn</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yaokun Su, Chen Li</dc:creator>
    </item>
    <item>
      <title>Fermi-Bose Machine</title>
      <link>https://arxiv.org/abs/2404.13631</link>
      <description>arXiv:2404.13631v1 Announce Type: cross 
Abstract: Distinct from human cognitive processing, deep neural networks trained by backpropagation can be easily fooled by adversarial examples. To design a semantically meaningful representation learning, we discard backpropagation, and instead, propose a local contrastive learning, where the representation for the inputs bearing the same label shrink (akin to boson) in hidden layers, while those of different labels repel (akin to fermion). This layer-wise learning is local in nature, being biological plausible. A statistical mechanics analysis shows that the target fermion-pair-distance is a key parameter. Moreover, the application of this local contrastive learning to MNIST benchmark dataset demonstrates that the adversarial vulnerability of standard perceptron can be greatly mitigated by tuning the target distance, i.e., controlling the geometric separation of prototype manifolds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13631v1</guid>
      <category>cs.LG</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.NE</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mingshan Xie, Yuchen Wang, Haiping Huang</dc:creator>
    </item>
    <item>
      <title>Cooperativity, information gain, and energy cost during early LTP in dendritic spines</title>
      <link>https://arxiv.org/abs/2404.14123</link>
      <description>arXiv:2404.14123v1 Announce Type: cross 
Abstract: We investigate a mutual relationship between information and energy during early phase of LTP induction and maintenance in a large-scale system of mutually coupled dendritic spines, with discrete internal states and probabilistic dynamics, within the framework of nonequilibrium stochastic thermodynamics. In order to analyze this computationally intractable stochastic multidimensional system, we introduce a pair approximation, which allows us to reduce the spine dynamics into a lower dimensional manageable system of closed equations. It is found that the rates of information gain and energy attain their maximal values during an initial period of LTP (i.e. during stimulation), and after that they recover to their baseline low values, as opposed to a memory trace that lasts much longer. This suggests that learning phase is much more energy demanding than the memory phase. We show that positive correlations between neighboring spines increase both a duration of memory trace and energy cost during LTP, but the memory time per invested energy increases dramatically for very strong positive synaptic cooperativity, suggesting a beneficial role of synaptic clustering on memory duration. In contrast, information gain after LTP is the largest for negative correlations, and energy efficiency of that information generally declines with increasing synaptic cooperativity. We also find that dendritic spines can use sparse representations for encoding of long-term information, as both energetic and structural efficiencies of retained information and its lifetime exhibit maxima for low fractions of stimulated synapses during LTP. In general, our stochastic thermodynamics approach provides a unifying framework for studying, from first principles, information encoding and its energy cost during learning and memory in stochastic systems of interacting synapses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14123v1</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>physics.comp-ph</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1162/neco_a_01632</arxiv:DOI>
      <arxiv:journal_reference>Neural Computation 36: 271-311 (2024)</arxiv:journal_reference>
      <dc:creator>Jan Karbowski, Paulina Urban</dc:creator>
    </item>
    <item>
      <title>Quantum-Enhanced Neural Exchange-Correlation Functionals</title>
      <link>https://arxiv.org/abs/2404.14258</link>
      <description>arXiv:2404.14258v1 Announce Type: cross 
Abstract: Kohn-Sham Density Functional Theory (KS-DFT) provides the exact ground state energy and electron density of a molecule, contingent on the as-yet-unknown universal exchange-correlation (XC) functional. Recent research has demonstrated that neural networks can efficiently learn to represent approximations to that functional, offering accurate generalizations to molecules not present during the training process. With the latest advancements in quantum-enhanced machine learning (ML), evidence is growing that Quantum Neural Network (QNN) models may offer advantages in ML applications. In this work, we explore the use of QNNs for representing XC functionals, enhancing and comparing them to classical ML techniques. We present QNNs based on differentiable quantum circuits (DQCs) as quantum (hybrid) models for XC in KS-DFT, implemented across various architectures. We assess their performance on 1D and 3D systems. To that end, we expand existing differentiable KS-DFT frameworks and propose strategies for efficient training of such functionals, highlighting the importance of fractional orbital occupation for accurate results. Our best QNN-based XC functional yields energy profiles of the H$_2$ and planar H$_4$ molecules that deviate by no more than 1 mHa from the reference DMRG and FCI/6-31G results, respectively. Moreover, they reach chemical precision on a system, H$_2$H$_2$, not present in the training dataset, using only a few variational parameters. This work lays the foundation for the integration of quantum models in KS-DFT, thereby opening new avenues for expressing XC functionals in a differentiable way and facilitating computations of various properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14258v1</guid>
      <category>quant-ph</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.str-el</category>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Igor O. Sokolov, Gert-Jan Both, Art D. Bochevarov, Pavel A. Dub, Daniel S. Levine, Christopher T. Brown, Shaheen Acheche, Panagiotis Kl. Barkoutsos, Vincent E. Elfving</dc:creator>
    </item>
    <item>
      <title>Dipolar order controls dielectric response of glass-forming liquids</title>
      <link>https://arxiv.org/abs/2404.14277</link>
      <description>arXiv:2404.14277v1 Announce Type: cross 
Abstract: The dielectric response of liquids reflects both, reorientation of single molecular dipoles and collective modes, i.e., dipolar cross-correlations. A recent theory predicts the latter to produce an additional slow peak in the dielectric loss spectrum. Following this idea we argue that in supercooled liquids the high-frequency power law exponent of the dielectric loss $\beta$ should be correlated with the degree of dipolar order, i.e., the Kirkwood correlation factor $g_K$. This notion is confirmed for 25 supercooled liquids. While our findings support recent theoretical work the results are shown to violate the earlier Kivelson-Madden theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14277v1</guid>
      <category>cond-mat.soft</category>
      <category>cond-mat.dis-nn</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Till B\"ohmer, Florian Pabst, Jan P. Gabriel, Thomas Blochowicz</dc:creator>
    </item>
    <item>
      <title>Explicit mutual information for simple networks and neurons with lognormal activities</title>
      <link>https://arxiv.org/abs/2307.00017</link>
      <description>arXiv:2307.00017v2 Announce Type: replace 
Abstract: Networks with stochastic variables described by heavy tailed lognormal distribution are ubiquitous in nature, and hence they deserve an exact information-theoretic characterization. We derive analytical formulas for mutual information between elements of different networks with correlated lognormally distributed activities. In a special case, we find an explicit expression for mutual information between neurons when neural activities and synaptic weights are lognormally distributed, as suggested by experimental data. Comparison of this expression with the case when these two variables have short tails, reveals that mutual information with heavy tails for neurons and synapses is generally larger and can diverge for some finite variances in presynaptic firing rates and synaptic weights. This result suggests that evolution might prefer brains with heterogeneous dynamics to optimize information processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.00017v2</guid>
      <category>cond-mat.dis-nn</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1103/PhysRevE.109.014117</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. E 109, 014117 (2024)</arxiv:journal_reference>
      <dc:creator>Maurycy Chwi{\l}ka, Jan Karbowski</dc:creator>
    </item>
    <item>
      <title>Odd dipole screening in disordered matter</title>
      <link>https://arxiv.org/abs/2310.09942</link>
      <description>arXiv:2310.09942v3 Announce Type: replace-cross 
Abstract: Disordered solids, straddling the solid-fluid boundary, lack a comprehensive continuum mechanical description. They exhibit a complex microstructure wherein multiple meta-stable states exist. Deforming disordered solids induces particles rearrangements enabling the system to transition between meta-stable states. A dramatic consequence of these transitions is that quasistatic deformation cycles modify the reference state, facilitating the storage and release of mechanical energy. Here we develop a continuum mechanical theory of disordered solids, which accounts for the absence of a reference state and the lack of conserved potential energy. Our theory, which introduces a new modulus describing non-conservative mechanical screening, reduces to classical elasticity in the absence of screening. We analytically derive predictions for the deformation field for various perturbations and geometries. While our theory applies to general disordered solids, we focus on a two-dimensional disordered granular system and predict accurately the non-affine displacement fields observed in experiments for both small and large deformations, along with the observable vanishing shear modulus. The new proposed moduli satisfy universal relations that are independent of the specific experimental realization. Our work thus forms the basis of an entirely new family of continuum descriptions of the mechanics of disordered solids.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.09942v3</guid>
      <category>cond-mat.soft</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.mtrl-sci</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yael Cohen, Amit Schiller, Dong Wang, Joshua Dijksman, Michael Moshe</dc:creator>
    </item>
    <item>
      <title>A Replica-BCS theory for dirty superconductors</title>
      <link>https://arxiv.org/abs/2311.14914</link>
      <description>arXiv:2311.14914v3 Announce Type: replace-cross 
Abstract: Motivated by the discovery of the anomalous metal state in superconductor thin films, we revisit in this paper the problem of dirty superconductors using a replica-symmetric BCS (RS-BCS) theory for dirty metals with net attractive interactions. Within the RS-BCS mean field theory, we show that the (dirty) superconductor transits to a Cooper-pair-glass state beyond a critical strength of disorder. The single particle tunneling density of states and the superfluid density are computed within the RS-BCS theory for different strengths of disorder. We find that the single-particle spectral gap is strongly enhanced by disorder and the superfluid density reduces rapidly from the corresponding clean superconducting limit with increasing strength of disorder but remains finite in the Cooper-pair-glass state. The nature of the Cooper-pair-glass state and relevance of our result to the anomalous metal state are briefly discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.14914v3</guid>
      <category>cond-mat.supr-con</category>
      <category>cond-mat.dis-nn</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yat Fan Lau, Tai Kai Ng</dc:creator>
    </item>
    <item>
      <title>Dynamical heterogeneity and large deviations in the open quantum East glass model from tensor networks</title>
      <link>https://arxiv.org/abs/2404.03750</link>
      <description>arXiv:2404.03750v2 Announce Type: replace-cross 
Abstract: We study the non-equilibrium dynamics of the dissipative quantum East model via numerical tensor networks. We use matrix product states to represent evolution under quantum-jump unravellings for sizes beyond those accessible to exact diagonalisation. This allows us to demonstrate that dynamical heterogeneity accompanies slow relaxation, in analogy with what is seen in classical glassy systems. Furthermore, using variational matrix product operators we: (i) compute the spectral gap of the Lindbladian, and show that glassiness is enhanced in the presence of weak quantum fluctuations compared to the pure classical case, and (ii) obtain the dynamical large deviations by calculating the leading eigenvector of the tilted Lindbladian, and find clear evidence for a first-order active-inactive dynamical phase transition. We also show how to directly sample the rare quantum trajectories associated to the large deviations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03750v2</guid>
      <category>cond-mat.stat-mech</category>
      <category>cond-mat.dis-nn</category>
      <category>quant-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luke Causer, Mari Carmen Ba\~nuls, Juan P. Garrahan</dc:creator>
    </item>
  </channel>
</rss>
