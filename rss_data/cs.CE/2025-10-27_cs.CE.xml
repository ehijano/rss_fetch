<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 27 Oct 2025 14:08:33 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Integrated physics-informed learning and resonance process signature for the prediction of fatigue crack growth for laser-fused alloys</title>
      <link>https://arxiv.org/abs/2510.21018</link>
      <description>arXiv:2510.21018v1 Announce Type: new 
Abstract: Fatigue behaviors of metal components by laser fusion suffer from scattering due to random geometrical defects (e.g., porosity, lack of fusion). Monitoring fatigue crack initiation and growth is critical, especially for laser-fused components with significant inherent fatigue scattering. Conventional statistics-based curve-fitting fatigue models have difficulty incorporating significant scattering in their fatigue life due to the random geometrical defects. A scattering-informed predictive method is needed for laser-fused materials' crack size and growth. Current data-driven machine learning could circumvent the issue of deterministic modeling, but results in a black-box function that lacks interpretability. To address these challenges, this study explores a novel nondimensionalized physics-informed machine learning (PIML) model to predict fatigue crack growth of laser-fused SS-316L by integrating fatigue laws and constraints with small data to ensure a realistic and interpretable prediction. Resonance process signature data were leveraged with Paris's law to train the PIML model without experimental crack growth data. The results show that Paris's law constants can be learned with good similarity to comparable data from the literature, and the crack growth rate can be predicted to compute crack sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21018v1</guid>
      <category>cs.CE</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Panayiotis Kousoulas, Rahul Sharma, Y. B. Guo</dc:creator>
    </item>
    <item>
      <title>Linked Cell Traversal Algorithms for Three-Body Interactions in Molecular Dynamics</title>
      <link>https://arxiv.org/abs/2510.21230</link>
      <description>arXiv:2510.21230v1 Announce Type: new 
Abstract: In this work, algorithms for the parallel computation of three-body interactions in molecular dynamics are developed. While traversals for the computation of pair interactions are readily available in the literature, here, such traversals are extended to allow for the computation between molecules stored across three cells. A general framework for the computation of three-body interactions in linked cells is described, and then used to implement the corresponding traversals. In addition, our analysis is combined with the commonly used cutoff conditions, because they influence the total workload of the computation of interactions. The combinations between traversals and truncation conditions are validated using the well-known Lennard-Jones fluid. Validation case studies are taken from the literature and configured into homogeneous and inhomogeneous scenarios. Finally, strong scalability and performance in terms of molecule updates are measured at node-level.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21230v1</guid>
      <category>cs.CE</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jose Alfonso Pinzon Escobar, Markus M\"uhlh\"au{\ss}er, Hans-Joachim Bungartz, Philipp Neumann</dc:creator>
    </item>
    <item>
      <title>Crisis-Resilient Portfolio Management via Graph-based Spatio-Temporal Learning</title>
      <link>https://arxiv.org/abs/2510.20868</link>
      <description>arXiv:2510.20868v1 Announce Type: cross 
Abstract: Financial time series forecasting faces a fundamental challenge: predicting optimal asset allocations requires understanding regime-dependent correlation structures that transform during crisis periods. Existing graph-based spatio-temporal learning approaches rely on predetermined graph topologies--correlation thresholds, sector classifications--that fail to adapt when market dynamics shift across different crisis mechanisms: credit contagion, pandemic shocks, or inflation-driven selloffs.
  We present CRISP (Crisis-Resilient Investment through Spatio-temporal Patterns), a graph-based spatio-temporal learning framework that encodes spatial relationships via Graph Convolutional Networks and temporal dynamics via BiLSTM with self-attention, then learns sparse structures through multi-head Graph Attention Networks. Unlike fixed-topology methods, CRISP discovers which asset relationships matter through attention mechanisms, filtering 92.5% of connections as noise while preserving crisis-relevant dependencies for accurate regime-specific predictions.
  Trained on 2005--2021 data encompassing credit and pandemic crises, CRISP demonstrates robust generalization to 2022--2024 inflation-driven markets--a fundamentally different regime--by accurately forecasting regime-appropriate correlation structures. This enables adaptive portfolio allocation that maintains profitability during downturns, achieving Sharpe ratio 3.76: 707% improvement over equal-weight baselines and 94% improvement over static graph methods. Learned attention weights provide interpretable regime detection, with defensive cluster attention strengthening 49% during crises versus 31% market-wide--emergent behavior from learning to forecast rather than imposing assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20868v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zan Li, Rui Fan</dc:creator>
    </item>
    <item>
      <title>Design and Structural Validation of a Micro-UAV with On-Board Dynamic Route Planning</title>
      <link>https://arxiv.org/abs/2510.21648</link>
      <description>arXiv:2510.21648v1 Announce Type: cross 
Abstract: Micro aerial vehicles are becoming increasingly important in search and rescue operations due to their agility, speed, and ability to access confined spaces or hazardous areas. However, designing lightweight aerial systems presents significant structural, aerodynamic, and computational challenges. This work addresses two key limitations in many low-cost aerial systems under two kilograms: their lack of structural durability during flight through rough terrains and inability to replan paths dynamically when new victims or obstacles are detected. We present a fully customised drone built from scratch using only commonly available components and materials, emphasising modularity, low cost, and ease of assembly. The structural frame is reinforced with lightweight yet durable materials to withstand impact, while the onboard control system is powered entirely by free, open-source software solutions. The proposed system demonstrates real-time perception and adaptive navigation capabilities without relying on expensive hardware accelerators, offering an affordable and practical solution for real-world search and rescue missions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21648v1</guid>
      <category>cs.RO</category>
      <category>cs.CE</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Inbazhagan Ravikumar, Ram Sundhar, Narendhiran Vijayakumar</dc:creator>
    </item>
    <item>
      <title>A hybrid framework integrating classical computers and quantum annealers for optimisation of truss structures</title>
      <link>https://arxiv.org/abs/2502.19570</link>
      <description>arXiv:2502.19570v2 Announce Type: replace 
Abstract: This work proposes a hybrid framework combining classical computers with quantum annealers for structural optimisation. At each optimisation iteration of an iterative process, two minimisation problems are formulated one for the underlying mechanical boundary value problem through the minimisation potential energy principle and one for the minimisation problem to update the design variables. Our hybrid approach leverages the strength of quantum computing to solve these two minimisation problems at each step, thanks to the developed quantum annealing-assisted sequential programming strategy introduced in [Nguyen, Wu, Remacle, and Noels. A quantum annealing-sequential quadratic programming assisted finite element simulation for non-linear and history-dependent mechanical problems. European Journal of Mechanics-A/Solids 105 (2024): 105254]. The applicability of the proposed framework is demonstrated through several case studies of truss optimisation, highlighting its capability to perform optimisation with quantum computers. The proposed framework offers a promising direction for future structural optimisation applications, particularly in scenarios where the quantum computer could resolve the size limitations of the classical computers due to problem complexities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.19570v2</guid>
      <category>cs.CE</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Van-Dung Nguyen, Erin Kuci, Michel Rasquin, Ludovic Noels</dc:creator>
    </item>
    <item>
      <title>Prot2Text-V2: Protein Function Prediction with Multimodal Contrastive Alignment</title>
      <link>https://arxiv.org/abs/2505.11194</link>
      <description>arXiv:2505.11194v3 Announce Type: replace 
Abstract: Predicting protein function from sequence is a central challenge in computational biology. While existing methods rely heavily on structured ontologies or similarity-based techniques, they often lack the flexibility to express structure-free functional descriptions and novel biological functions. In this work, we introduce Prot2Text-V2, a novel multimodal sequence-to-text model that generates free-form natural language descriptions of protein function directly from amino acid sequences. Our method combines a protein language model as a sequence encoder (ESM-3B) and a decoder-only language model (LLaMA-3.1-8B-Instruct) through a lightweight nonlinear modality projector. A key innovation is our Hybrid Sequence-level Contrastive Alignment Learning (H-SCALE), which improves cross-modal learning by matching mean- and std-pooled protein embeddings with text representations via contrastive loss. After the alignment phase, we apply instruction-based fine-tuning using LoRA on the decoder to teach the model how to generate accurate protein function descriptions conditioned on the protein sequence. We train Prot2Text-V2 on about 250K curated entries from SwissProt and evaluate it under low-homology conditions, where test sequences have low similarity with training samples. Prot2Text-V2 consistently outperforms traditional and LLM-based baselines across various metrics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11194v3</guid>
      <category>cs.CE</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiao Fei, Michail Chatzianastasis, Sarah Almeida Carneiro, Hadi Abdine, Lawrence P. Petalidis, Michalis Vazirgiannis</dc:creator>
    </item>
    <item>
      <title>VENI, VINDy, VICI: a generative reduced-order modeling framework with uncertainty quantification</title>
      <link>https://arxiv.org/abs/2405.20905</link>
      <description>arXiv:2405.20905v2 Announce Type: replace-cross 
Abstract: The simulation of many complex phenomena in engineering and science requires solving expensive, high-dimensional systems of partial differential equations (PDEs). To circumvent this, reduced-order models (ROMs) have been developed to speed up computations. However, when governing equations are unknown or partially known, typically ROMs lack interpretability and reliability of the predicted solutions.
  In this work we present a data-driven, non-intrusive framework for building ROMs where the latent variables and dynamics are identified in an interpretable manner and uncertainty is quantified. Starting from a limited amount of high-dimensional, noisy data the proposed framework constructs an efficient ROM by leveraging variational autoencoders for dimensionality reduction along with a newly introduced, variational version of sparse identification of nonlinear dynamics (SINDy), which we refer to as Variational Identification of Nonlinear Dynamics (VINDy).
  In detail, the method consists of Variational Encoding of Noisy Inputs (VENI) to identify the distribution of reduced coordinates. Simultaneously, we learn the distribution of the coefficients of a pre-determined set of candidate functions by VINDy. Once trained offline, the identified model can be queried for new parameter instances and new initial conditions to compute the corresponding full-time solutions. The probabilistic setup enables uncertainty quantification as the online testing consists of Variational Inference naturally providing Certainty Intervals (VICI). In this work we showcase the effectiveness of the newly proposed VINDy method in identifying interpretable and accurate dynamical system for the Roessler system with different noise intensities and sources. Then the performance of the overall method - named VENI, VINDy, VICI - is tested on PDE benchmarks including structural mechanics and fluid dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20905v2</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>math.DS</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paolo Conti, Jonas Kneifl, Andrea Manzoni, Attilio Frangi, J\"org Fehr, Steven L. Brunton, J. Nathan Kutz</dc:creator>
    </item>
    <item>
      <title>CLT and Edgeworth Expansion for m-out-of-n Bootstrap Estimators of The Studentized Median</title>
      <link>https://arxiv.org/abs/2505.11725</link>
      <description>arXiv:2505.11725v2 Announce Type: replace-cross 
Abstract: The m-out-of-n bootstrap, originally proposed by Bickel, Gotze, and Zwet (1992), approximates the distribution of a statistic by repeatedly drawing m subsamples (with m much smaller than n) without replacement from an original sample of size n. It is now routinely used for robust inference with heavy-tailed data, bandwidth selection, and other large-sample applications. Despite its broad applicability across econometrics, biostatistics, and machine learning, rigorous parameter-free guarantees for the soundness of the m-out-of-n bootstrap when estimating sample quantiles have remained elusive.
  This paper establishes such guarantees by analyzing the estimator of sample quantiles obtained from m-out-of-n resampling of a dataset of size n. We first prove a central limit theorem for a fully data-driven version of the estimator that holds under a mild moment condition and involves no unknown nuisance parameters. We then show that the moment assumption is essentially tight by constructing a counter-example in which the CLT fails. Strengthening the assumptions slightly, we derive an Edgeworth expansion that provides exact convergence rates and, as a corollary, a Berry Esseen bound on the bootstrap approximation error. Finally, we illustrate the scope of our results by deriving parameter-free asymptotic distributions for practical statistics, including the quantiles for random walk Metropolis-Hastings and the rewards of ergodic Markov decision processes, thereby demonstrating the usefulness of our theory in modern estimation and learning tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11725v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Imon Banerjee, Sayak Chakrabarty</dc:creator>
    </item>
    <item>
      <title>Causal Climate Emulation with Bayesian Filtering</title>
      <link>https://arxiv.org/abs/2506.09891</link>
      <description>arXiv:2506.09891v2 Announce Type: replace-cross 
Abstract: Traditional models of climate change use complex systems of coupled equations to simulate physical processes across the Earth system. These simulations are highly computationally expensive, limiting our predictions of climate change and analyses of its causes and effects. Machine learning has the potential to quickly emulate data from climate models, but current approaches are not able to incorporate physically-based causal relationships. Here, we develop an interpretable climate model emulator based on causal representation learning. We derive a novel approach including a Bayesian filter for stable long-term autoregressive emulation. We demonstrate that our emulator learns accurate climate dynamics, and we show the importance of each one of its components on a realistic synthetic dataset and data from two widely deployed climate models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09891v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>physics.ao-ph</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sebastian Hickman, Ilija Trajkovic, Julia Kaltenborn, Francis Pelletier, Alex Archibald, Yaniv Gurwicz, Peer Nowack, David Rolnick, Julien Boussard</dc:creator>
    </item>
  </channel>
</rss>
