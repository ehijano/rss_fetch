<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 21 May 2025 04:00:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>New Sorting Algorithm Wave Sort (W-Sort)</title>
      <link>https://arxiv.org/abs/2505.13552</link>
      <description>arXiv:2505.13552v1 Announce Type: new 
Abstract: Modern comparison sorts like quicksort suffer from performance inconsistencies due to suboptimal pivot selection, leading to $O(N^2)$ worst-case complexity, while in-place merge sort variants face challenges with data movement overhead. We introduce Wave Sort, a novel in-place sorting algorithm that addresses these limitations through a dynamic pivot selection strategy. Wave Sort iteratively expands a sorted region and selects pivots from this growing sorted portion to partition adjacent unsorted data. This approach ensures robust pivot selection irrespective of dataset size, guarantees a logarithmic recursion stack depth, and enables efficient in-place sorting. Our analysis shows a worst-case comparison complexity bounded by $O(N(\log N)^2)$ with a small constant factor. Experimental results demonstrate that Wave Sort requires significantly fewer comparisons than quicksort on average (approximately 24% less) and performs close to the theoretical minimum, while also incorporating adaptive techniques for efficient handling of presorted sequences. Wave Sort offers a compelling alternative for applications demanding consistent, predictable, and in-place sorting performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13552v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jia Xu Wei</dc:creator>
    </item>
    <item>
      <title>Unsplittable Multicommodity Flows in Outerplanar Graphs</title>
      <link>https://arxiv.org/abs/2505.13635</link>
      <description>arXiv:2505.13635v1 Announce Type: new 
Abstract: We consider the problem of multicommodity flows in outerplanar graphs. Okamura and Seymour showed that the cut-condition is sufficient for routing demands in outerplanar graphs. We consider the unsplittable version of the problem and prove that if the cut-condition is satisfied, then we can route each demand along a single path by exceeding the capacity of an edge by no more than $\frac{18}{5} \cdot d_{max}$, where $d_{max}$ is the value of the maximum demand.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13635v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Alem\'an-Espinosa, Nikhil Kumar</dc:creator>
    </item>
    <item>
      <title>Differentially Private Quantiles with Smaller Error</title>
      <link>https://arxiv.org/abs/2505.13662</link>
      <description>arXiv:2505.13662v1 Announce Type: new 
Abstract: In the approximate quantiles problem, the goal is to output $m$ quantile estimates, the ranks of which are as close as possible to $m$ given quantiles $q_1,\dots,q_m$. We present a mechanism for approximate quantiles that satisfies $\varepsilon$-differential privacy for a dataset of $n$ real numbers where the ratio between the closest pair of points and the size of the domain is bounded by $b$. As long as the minimum gap between quantiles is large enough, $|q_i-q_{i-1}|\geq \Omega\left(\frac{m\log(m)\log(b)}{n\varepsilon}\right)$ for all $i$, the maximum rank error of our mechanism is $O\left(\frac{\log(b) + \log^2(m)}{\varepsilon}\right)$ with high probability. Previously, the best known algorithm under pure DP was due to Kaplan, Schnapp, and Stemmer~(ICML '22), who achieve a bound of $O\left(\log(b)\log^2(m)/\varepsilon\right)$, so we save a factor $\Omega(\min(\log(b),\log^2(m)))$. Our improvement stems from the use of continual counting techniques to randomize the quantiles in a correlated way. We also present an $(\varepsilon,\delta)$-differentially private mechanism that relaxes the gap assumption without affecting the error bound, improving on existing methods when $\delta$ is sufficiently close to zero. We provide experimental evaluation which confirms that our mechanism performs favorably compared to prior work in practice, in particular when the number of quantiles $m$ is large.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13662v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jacob Imola, Fabrizio Boninsegna, Hannah Keller, Anders Aamand, Amrita Roy Chowdhury, Rasmus Pagh</dc:creator>
    </item>
    <item>
      <title>Robust learning of halfspaces under log-concave marginals</title>
      <link>https://arxiv.org/abs/2505.13708</link>
      <description>arXiv:2505.13708v1 Announce Type: new 
Abstract: We say that a classifier is \emph{adversarially robust} to perturbations of norm $r$ if, with high probability over a point $x$ drawn from the input distribution, there is no point within distance $\le r$ from $x$ that is classified differently. The \emph{boundary volume} is the probability that a point falls within distance $r$ of a point with a different label. This work studies the task of computationally efficient learning of hypotheses with small boundary volume, where the input is distributed as a subgaussian isotropic log-concave distribution over $\mathbb{R}^d$.
  Linear threshold functions are adversarially robust; they have boundary volume proportional to $r$. Such concept classes are efficiently learnable by polynomial regression, which produces a polynomial threshold function (PTF), but PTFs in general may have boundary volume $\Omega(1)$, even for $r \ll 1$.
  We give an algorithm that agnostically learns linear threshold functions and returns a classifier with boundary volume $O(r+\varepsilon)$ at radius of perturbation $r$. The time and sample complexity of $d^{\tilde{O}(1/\varepsilon^2)}$ matches the complexity of polynomial regression.
  Our algorithm augments the classic approach of polynomial regression with three additional steps: a) performing the $\ell_1$-error regression under noise sensitivity constraints, b) a structured partitioning and rounding step that returns a Boolean classifier with error $\textsf{opt} + O(\varepsilon)$ and noise sensitivity $O(r+\varepsilon)$ simultaneously, and c) a local corrector that ``smooths'' a function with low noise sensitivity into a function that is adversarially robust.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13708v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jane Lange, Arsen Vasilyan</dc:creator>
    </item>
    <item>
      <title>Path Contraction Faster than $2^n$</title>
      <link>https://arxiv.org/abs/2505.13996</link>
      <description>arXiv:2505.13996v1 Announce Type: new 
Abstract: A graph $G$ is contractible to a graph $H$ if there is a set $X \subseteq E(G)$, such that $G/X$ is isomorphic to $H$. Here, $G/X$ is the graph obtained from $G$ by contracting all the edges in $X$. For a family of graphs $\cal F$, the $\mathcal{F}$-\textsc{Contraction} problem takes as input a graph $G$ on $n$ vertices, and the objective is to output the largest integer $t$, such that $G$ is contractible to a graph $H \in {\cal F}$, where $|V(H)|=t$. When $\cal F$ is the family of paths, then the corresponding $\mathcal{F}$-\textsc{Contraction} problem is called \textsc{Path Contraction}. The problem \textsc{Path Contraction} admits a simple algorithm running in time $2^{n}\cdot n^{\mathcal{O}(1)}$. In spite of the deceptive simplicity of the problem, beating the $2^{n}\cdot n^{\mathcal{O}(1)}$ bound for \textsc{Path Contraction} seems quite challenging. In this paper, we design an exact exponential time algorithm for \textsc{Path Contraction} that runs in time $1.99987^n\cdot n^{\mathcal{O}(1)}$. We also define a problem called \textsc{$3$-Disjoint Connected Subgraphs}, and design an algorithm for it that runs in time $1.88^n\cdot n^{\mathcal{O}(1)}$. The above algorithm is used as a sub-routine in our algorithm for {\sc Path Contraction}</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13996v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Akanksha Agrawal, Fedor V. Fomin, Daniel Lokshtanov, Saket Saurabh, Prafullkumar Tale</dc:creator>
    </item>
    <item>
      <title>A Single Exponential-Time FPT Algorithm for Cactus Contraction</title>
      <link>https://arxiv.org/abs/2505.14018</link>
      <description>arXiv:2505.14018v1 Announce Type: new 
Abstract: For a collection $\mathcal{F}$ of graphs, the $\mathcal{F}$-\textsc{Contraction} problem takes a graph $G$ and an integer $k$ as input and decides if $G$ can be modified to some graph in $\mathcal{F}$ using at most $k$ edge contractions. The $\mathcal{F}$-\textsc{Contraction} problem is \NP-Complete for several graph classes $\mathcal{F}$. Heggerners et al. [Algorithmica, 2014] initiated the study of $\mathcal{F}$-\textsc{Contraction} in the realm of parameterized complexity. They showed that it is \FPT\ if $\mathcal{F}$ is the set of all trees or the set of all paths. In this paper, we study $\mathcal{F}$-\textsc{Contraction} where $\mathcal{F}$ is the set of all cactus graphs and show that we can solve it in $2^{\calO(k)} \cdot |V(G)|^{\OO(1)}$ time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.14018v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>R. Krithika, Pranabendu Misra, Prafullkumar Tale</dc:creator>
    </item>
    <item>
      <title>Exploring Temporal Graphs with Frequent and Regular Edges</title>
      <link>https://arxiv.org/abs/2505.14046</link>
      <description>arXiv:2505.14046v1 Announce Type: new 
Abstract: Temporal graphs are a class of graphs defined by a constant set of vertices and a changing set of edges, each of which is known as a timestep. These graphs are well motivated in modelling real-world networks, where connections may change over time. One such example, itself the primary motivation for this paper, are public transport networks, where vertices represent stops and edges the connections available at some given time. Exploration problems are one of the most studied problems for temporal graphs, asking if an agent starting at some given vertex $v$ can visit every vertex in the graph.
  In this paper, we study two primary classes of temporal graphs. First, we study temporal graphs with \emph{frequent edges}, temporal graphs where each edge $e$ is active at least once every $f_e$ timesteps, called the frequency of the edge. Second, temporal graphs with \emph{regular edges}, graphs where each edge $e$ is active at any timestep $t$ where $t \equiv s_e \bmod r_e$, with $s_e$ being the start time of the edge, and $r_e$ the regularity.
  We show that graphs with frequent edges can be explored in $O(F n)$ timesteps, where $F = \max_{e \in E} f_e$, and that graphs with regular edges can be explored in $O(R n)$ timesteps, where $R = \max_{e \in E} r_e$. We provide additional results for \emph{public transport graphs}, temporal graphs formed by the union of several routes, corresponding to the schedules of some modes of transit, for \emph{sequential connection graphs}, temporal graphs in which each vertex has a single active in-edge per timestep, iterating over the set of edges in some order, and for \emph{broadcast networks}, a representation of communication within distributed networks where each vertex broadcasts a message either to all vertices, or none at each timestep.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.14046v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Duncan Adamson</dc:creator>
    </item>
    <item>
      <title>Linear Hashing Is Optimal</title>
      <link>https://arxiv.org/abs/2505.14061</link>
      <description>arXiv:2505.14061v1 Announce Type: new 
Abstract: We prove that hashing $n$ balls into $n$ bins via a random matrix over $\mathbf{F}_2$ yields expected maximum load $O(\log n / \log \log n)$. This matches the expected maximum load of a fully random function and resolves an open question posed by Alon, Dietzfelbinger, Miltersen, Petrank, and Tardos (STOC '97, JACM '99). More generally, we show that the maximum load exceeds $r\cdot\log n/\log\log n$ with probability at most $O(1/r^2)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.14061v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Jaber, Vinayak M. Kumar, David Zuckerman</dc:creator>
    </item>
    <item>
      <title>Simple and Optimal Algorithms for Heavy Hitters and Frequency Moments in Distributed Models</title>
      <link>https://arxiv.org/abs/2505.14250</link>
      <description>arXiv:2505.14250v1 Announce Type: new 
Abstract: We consider the problems of distributed heavy hitters and frequency moments in both the coordinator model and the distributed tracking model (also known as the distributed functional monitoring model). We present simple and optimal (up to logarithmic factors) algorithms for $\ell_p$ heavy hitters and $F_p$ estimation ($p \geq 2$) in these distributed models.
  For $\ell_p$ heavy hitters in the coordinator model, our algorithm requires only one round and uses $\tilde{O}(k^{p-1}/\eps^p)$ bits of communication. For $p &gt; 2$, this is the first near-optimal result. By combining our algorithm with the standard recursive sketching technique, we obtain a near-optimal two-round algorithm for $F_p$ in the coordinator model, matching a significant result from recent work by Esfandiari et al.\ (STOC 2024). Our algorithm and analysis are much simpler and have better costs with respect to logarithmic factors. Furthermore, our technique provides a one-round algorithm for $F_p$, which is a significant improvement over a result of Woodruff and Zhang (STOC 2012).
  Thanks to the simplicity of our heavy hitter algorithms, we manage to adapt them to the distributed tracking model with only a $\polylog(n)$ increase in communication. For $\ell_p$ heavy hitters, our algorithm has a communication cost of $\tilde{O}(k^{p-1}/\eps^p)$, representing the first near-optimal algorithm for all $p \geq 2$. By applying the recursive sketching technique, we also provide the first near-optimal algorithm for $F_p$ in the distributed tracking model, with a communication cost of $\tilde{O}(k^{p-1}/\eps^2)$ for all $p \geq 2$. Even for $F_2$, our result improves upon the bounds established by Cormode, Muthukrishnan, and Yi (SODA 2008) and Woodruff and Zhang (STOC 2012), nearly matching the existing lower bound for the first time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.14250v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zengfeng Huang, Zhongzheng Xiong, Xiaoyi Zhu, Zhewei Wei</dc:creator>
    </item>
    <item>
      <title>Credible Sets of Phylogenetic Tree Topology Distributions</title>
      <link>https://arxiv.org/abs/2505.14532</link>
      <description>arXiv:2505.14532v1 Announce Type: new 
Abstract: Credible intervals and credible sets, such as highest posterior density (HPD) intervals, form an integral statistical tool in Bayesian phylogenetics, both for phylogenetic analyses and for development. Readily available for continuous parameters such as base frequencies and clock rates, the vast and complex space of tree topologies poses significant challenges for defining analogous credible sets. Traditional frequency-based approaches are inadequate for diffuse posteriors where sampled trees are often unique. To address this, we introduce novel and efficient methods for estimating the credible level of individual tree topologies using tractable tree distributions, specifically Conditional Clade Distributions (CCDs). Furthermore, we propose a new concept called $\alpha$ credible CCD, which encapsulates a CCD whose trees collectively make up $\alpha$ probability. We present algorithms to compute these credible CCDs efficiently and to determine credible levels of tree topologies as well as of subtrees. We evaluate the accuracy of these credible set methods leveraging simulated and real datasets. Furthermore, to demonstrate the utility of our methods, we use well-calibrated simulation studies to evaluate the performance of different CCD models. In particular, we show how the credible set methods can be used to conduct rank-uniformity validation and produce Empirical Cumulative Distribution Function (ECDF) plots, supplementing standard coverage analyses for continuous parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.14532v1</guid>
      <category>cs.DS</category>
      <category>q-bio.PE</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonathan Klawitter, Alexei J. Drummond</dc:creator>
    </item>
    <item>
      <title>Approximate Spanning Tree Counting from Uncorrelated Edge Sets</title>
      <link>https://arxiv.org/abs/2505.14666</link>
      <description>arXiv:2505.14666v1 Announce Type: new 
Abstract: We show an $\widetilde{O}(m^{1.5} \epsilon^{-1})$ time algorithm that on a graph with $m$ edges and $n$ vertices outputs its spanning tree count up to a multiplicative $(1+\epsilon)$ factor with high probability, improving on the previous best runtime of $\widetilde{O}(m + n^{1.875}\epsilon^{-7/4})$ in sparse graphs. While previous algorithms were based on computing Schur complements and determinantal sparsifiers, our algorithm instead repeatedly removes sets of uncorrelated edges found using the electrical flow localization theorem of Schild-Rao-Srivastava [SODA 2018].</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.14666v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang P. Liu, Richard Peng, Junzhao Yang</dc:creator>
    </item>
    <item>
      <title>ResQue Greedy: Rewiring Sequential Greedy for Improved Submodular Maximization</title>
      <link>https://arxiv.org/abs/2505.13670</link>
      <description>arXiv:2505.13670v1 Announce Type: cross 
Abstract: This paper introduces Rewired Sequential Greedy (ResQue Greedy), an enhanced approach for submodular maximization under cardinality constraints. By integrating a novel set curvature metric within a lattice-based framework, ResQue Greedy identifies and corrects suboptimal decisions made by the standard sequential greedy algorithm. Specifically, a curvature-aware rewiring strategy is employed to dynamically redirect the solution path, leading to improved approximation performance over the conventional sequential greedy algorithm without significantly increasing computational complexity. Numerical experiments demonstrate that ResQue Greedy achieves tighter near-optimality bounds compared to the traditional sequential greedy method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13670v1</guid>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Joan Vendrell Gallart, Alan Kuhnle, Solmaz Kia</dc:creator>
    </item>
    <item>
      <title>A Private Approximation of the 2nd-Moment Matrix of Any Subsamplable Input</title>
      <link>https://arxiv.org/abs/2505.14251</link>
      <description>arXiv:2505.14251v1 Announce Type: cross 
Abstract: We study the problem of differentially private second moment estimation and present a new algorithm that achieve strong privacy-utility trade-offs even for worst-case inputs under subsamplability assumptions on the data. We call an input $(m,\alpha,\beta)$-subsamplable if a random subsample of size $m$ (or larger) preserves w.p $\geq 1-\beta$ the spectral structure of the original second moment matrix up to a multiplicative factor of $1\pm \alpha$. Building upon subsamplability, we give a recursive algorithmic framework similar to Kamath et al 2019, that abides zero-Concentrated Differential Privacy (zCDP) while preserving w.h.p. the accuracy of the second moment estimation upto an arbitrary factor of $(1\pm\gamma)$. We then show how to apply our algorithm to approximate the second moment matrix of a distribution $\mathcal{D}$, even when a noticeable fraction of the input are outliers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.14251v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bar Mahpud, Or Sheffet</dc:creator>
    </item>
    <item>
      <title>Predicting Memory Demands of BDD Operations using Maximum Graph Cuts (Extended Paper)</title>
      <link>https://arxiv.org/abs/2307.04488</link>
      <description>arXiv:2307.04488v3 Announce Type: replace 
Abstract: The BDD package Adiar manipulates Binary Decision Diagrams (BDDs) in external memory. This enables handling big BDDs, but the performance suffers when dealing with moderate-sized BDDs. This is mostly due to initializing expensive external memory data structures, even if their contents can fit entirely inside internal memory.
  The contents of these auxiliary data structures always correspond to a graph cut in an input or output BDD. Specifically, these cuts respect the levels of the BDD. We formalise the shape of these cuts and prove sound upper bounds on their maximum size for each BDD operation.
  We have implemented these upper bounds within Adiar. With these bounds, it can predict whether a faster internal memory variant of the auxiliary data structures can be used. In practice, this improves Adiar's running time across the board. Specifically for the moderate-sized BDDs, this results in an average reduction of the computation time by 86.1% (median of 89.7%). In some cases, the difference is even 99.9\%. When checking equivalence of hardware circuits from the EPFL Benchmark Suite, for one of the instances the time was decreased by 52 hours.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.04488v3</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-45332-8_4</arxiv:DOI>
      <arxiv:journal_reference>S{\o}lvsten, S.C., Van de Pol, J. (2023). Predicting Memory Demands of BDD Operations Using Maximum Graph Cuts. In: Automated Technology for Verification and Analysis. ATVA 2023. Lecture Notes in Computer Science, vol 14216. Springer</arxiv:journal_reference>
      <dc:creator>Steffan Christ S{\o}lvsten, Jaco van de Pol</dc:creator>
    </item>
    <item>
      <title>Diversity-aware clustering: Computational Complexity and Approximation Algorithms</title>
      <link>https://arxiv.org/abs/2401.05502</link>
      <description>arXiv:2401.05502v3 Announce Type: replace 
Abstract: In this work, we study diversity-aware clustering problems where the data points are associated with multiple attributes resulting in intersecting groups. A clustering solution needs to ensure that the number of chosen cluster centers from each group should be within the range defined by a lower and upper bound threshold for each group, while simultaneously minimizing the clustering objective, which can be either $k$-median, $k$-means or $k$-supplier. We study the computational complexity of the proposed problems, offering insights into their NP-hardness, polynomial-time inapproximability, and fixed-parameter intractability. We present parameterized approximation algorithms with approximation ratios $1+ \frac{2}{e} + \epsilon \approx 1.736$, $1+\frac{8}{e} + \epsilon \approx 3.943$, and $5$ for diversity-aware $k$-median, diversity-aware $k$-means and diversity-aware $k$-supplier, respectively. Assuming Gap-ETH, the approximation ratios are tight for the diversity-aware $k$-median and diversity-aware $k$-means problems. Our results imply the same approximation factors for their respective fair variants with disjoint groups -- fair $k$-median, fair $k$-means, and fair $k$-supplier -- with lower bound requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.05502v3</guid>
      <category>cs.DS</category>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Suhas Thejaswi, Ameet Gadekar, Bruno Ordozgoiti, Aristides Gionis</dc:creator>
    </item>
    <item>
      <title>The adaptive complexity of parallelized log-concave sampling</title>
      <link>https://arxiv.org/abs/2408.13045</link>
      <description>arXiv:2408.13045v2 Announce Type: replace 
Abstract: In large-data applications, such as the inference process of diffusion models, it is desirable to design sampling algorithms with a high degree of parallelization. In this work, we study the adaptive complexity of sampling, which is the minimum number of sequential rounds required to achieve sampling given polynomially many queries executed in parallel at each round. For unconstrained sampling, we examine distributions that are log-smooth or log-Lipschitz and log strongly or non-strongly concave. We show that an almost linear iteration algorithm cannot return a sample with a specific exponentially small error under total variation distance. For box-constrained sampling, we show that an almost linear iteration algorithm cannot return a sample with sup-polynomially small error under total variation distance for log-concave distributions. Our proof relies upon novel analysis with the characterization of the output for the hardness potentials based on the chain-like structure with random partition and classical smoothing techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13045v2</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Huanjian Zhou, Baoxiang Wang, Masashi Sugiyama</dc:creator>
    </item>
    <item>
      <title>Multi-variable Quantification of BDDs in External Memory using Nested Sweeping (Extended Paper)</title>
      <link>https://arxiv.org/abs/2408.14216</link>
      <description>arXiv:2408.14216v3 Announce Type: replace 
Abstract: Previous research on the Adiar BDD package has been successful at designing algorithms capable of handling large Binary Decision Diagrams (BDDs) stored in external memory. To do so, it uses consecutive sweeps through the BDDs to resolve computations. Yet, this approach has kept algorithms for multi-variable quantification, the relational product, and variable reordering out of its scope.
  In this work, we address this by introducing the nested sweeping framework. Here, multiple concurrent sweeps pass information between eachother to compute the result. We have implemented the framework in Adiar and used it to create a new external memory multi-variable quantification algorithm. Compared to conventional depth-first implementations, Adiar with nested sweeping is able to solve more instances of our benchmarks and/or solve them faster.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14216v3</guid>
      <category>cs.DS</category>
      <category>cs.DB</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Steffan Christ S{\o}lvsten, Jaco van de Pol</dc:creator>
    </item>
    <item>
      <title>A Reduction-based Algorithm for the Clique Interdiction Problem</title>
      <link>https://arxiv.org/abs/2505.12022</link>
      <description>arXiv:2505.12022v2 Announce Type: replace 
Abstract: The Clique Interdiction Problem (CIP) aims to minimize the size of the largest clique in a given graph by removing a given number of vertices. The CIP models a special Stackelberg game and has important applications in fields such as pandemic control and terrorist identification. However, the CIP is a bilevel graph optimization problem, making it very challenging to solve. Recently, data reduction techniques have been successfully applied in many (single-level) graph optimization problems like the vertex cover problem. Motivated by this, we investigate a set of novel reduction rules and design a reduction-based algorithm, RECIP, for practically solving the CIP. RECIP enjoys an effective preprocessing procedure that systematically reduces the input graph, making the problem much easier to solve. Extensive experiments on 124 large real-world networks demonstrate the superior performance of RECIP and validate the effectiveness of the proposed reduction rules.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12022v2</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenghao Zhu, Yi Zhou, Haoyu Jiang</dc:creator>
    </item>
    <item>
      <title>Embeddable of hieroglyphs into torus</title>
      <link>https://arxiv.org/abs/2208.08692</link>
      <description>arXiv:2208.08692v3 Announce Type: replace-cross 
Abstract: We are interested in finding combinatorial criteria for embedding graphs into torus and using them in the embedding check algorithm. It is a well-known fact that any connected graph can be reduced to a one-vertex graph with loops and is homotopy equivalent to such a graph. If a connected graph has intersection of some edges, then some loops of one-vertex graph will also intersect. Therefore the problem of embedding graphs in some surface is equivalent to the question of embedding one-vertex graph in given surface. This paper considers a graph with rotation structure (not necessarily geometric) or rotation graph called hieroglyph. The equivalence of four conditions is proved: (1) embedding hieroglyph in the torus; (2) the absence of forbidden subgraphs in a hieroglyph; (3) some condition for the graph of loops; (4) the existence of a reduction of hieroglyph to one of the list of hieroglyphs. We also prove the existence of an algorithm with complexity $\mathcal{O}(n)$ that recognizes embedding hieroglyph in the torus.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.08692v3</guid>
      <category>math.CO</category>
      <category>cs.DS</category>
      <category>math.GT</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tim Berezin</dc:creator>
    </item>
    <item>
      <title>A General Reduction for High-Probability Analysis with General Light-Tailed Distributions</title>
      <link>https://arxiv.org/abs/2403.02873</link>
      <description>arXiv:2403.02873v2 Announce Type: replace-cross 
Abstract: We describe a general reduction technique for analyzing learning algorithms that are subject to light-tailed (but not necessarily bounded) randomness, a scenario that is often the focus of theoretical analysis. We show that the analysis of such an algorithm can be reduced, in a black-box manner and with only a small loss in logarithmic factors, to an analysis of a simpler variant of the same algorithm that uses bounded random variables and is often easier to analyze. This approach simultaneously applies to any light-tailed randomization, including exponential, sub-Gaussian, and more general fast-decaying distributions, without needing to appeal to specialized concentration inequalities. Derivations of a generalized Azuma inequality, convergence bounds in stochastic optimization, and regret analysis in multi-armed bandits with general light-tailed randomization are provided to illustrate the technique.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02873v2</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>math.PR</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amit Attia, Tomer Koren</dc:creator>
    </item>
    <item>
      <title>New Statistical and Computational Results for Learning Junta Distributions</title>
      <link>https://arxiv.org/abs/2505.05819</link>
      <description>arXiv:2505.05819v2 Announce Type: replace-cross 
Abstract: We study the problem of learning junta distributions on $\{0, 1\}^n$, where a distribution is a $k$-junta if its probability mass function depends on a subset of at most $k$ variables. We make two main contributions:
  - We show that learning $k$-junta distributions is \emph{computationally} equivalent to learning $k$-parity functions with noise (LPN), a landmark problem in computational learning theory.
  - We design an algorithm for learning junta distributions whose statistical complexity is optimal, up to polylogarithmic factors. Computationally, our algorithm matches the complexity of previous (non-sample-optimal) algorithms.
  Combined, our two contributions imply that our algorithm cannot be significantly improved, statistically or computationally, barring a breakthrough for LPN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05819v2</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lorenzo Beretta</dc:creator>
    </item>
  </channel>
</rss>
