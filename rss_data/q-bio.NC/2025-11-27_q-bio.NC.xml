<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 27 Nov 2025 05:00:59 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Phase Plane Analysis of Firing Patterns in the Adaptive Exponential Integrate-and-Fire Model</title>
      <link>https://arxiv.org/abs/2511.20670</link>
      <description>arXiv:2511.20670v1 Announce Type: new 
Abstract: The Adaptive Exponential Integrate-and-Fire (AdEx) model is a simplified framework that effectively characterizes neuronal electrical activity. The aim of this paper is to employ phase plane analysis to systematically investigate diverse firing patterns generated by the AdEx model under varying parametric conditions. We first introduce the fundamental equations and parameter configurations of the AdEx model to numerically simulate the six representative firing patterns in the AdEx model. And then we use phase plane analysis to explore the dynamic mechanism of these firing patterns under different input currents and parametric conditions. Our findings demonstrate that the AdEx model can simulate multiple firing patterns, including Tonic Spiking, Adapting, Initial Bursting, Busting, Transient Spiking and Delayed Spiking firing patterns. These results not only advance the understanding of complex electrophysiological phenomena in neurons but also provide theoretical foundations for applications in many fields like neuromorphic computing and brain-computer interfaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.20670v1</guid>
      <category>q-bio.NC</category>
      <category>physics.bio-ph</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wu-Fei Zhang</dc:creator>
    </item>
    <item>
      <title>Morality in AI. A plea to embed morality in LLM architectures and frameworks</title>
      <link>https://arxiv.org/abs/2511.20689</link>
      <description>arXiv:2511.20689v1 Announce Type: new 
Abstract: Large language models (LLMs) increasingly mediate human decision-making and behaviour. Ensuring LLM processing of moral meaning therefore has become a critical challenge. Current approaches rely predominantly on bottom-up methods such as fine-tuning and reinforcement learning from human feedback. We propose a fundamentally different approach: embedding moral meaning processing directly into the architectural mechanisms and frameworks of transformer-based models through top-down design principles. We first sketch a framework that conceptualizes attention as a dynamic interface mediating between structure and processing, contrasting with existing linear attention frameworks in psychology. We start from established biological-artificial attention analogies in neural architecture design to improve cognitive processing. We extend this analysis to moral processing, using Iris Murdoch's theory of loving attention (sustained, just observation that enables moral transformation by reseeing others with clarity and compassion) to philosophically discuss functional analogies between human and LLM moral processing. We formulate and evaluate potentially promising technical operationalizations to embed morality in LLM architectures and frameworks. We acknowledge the limitations of our exploration and give three key contributions. (1) We conceptualize attention as a dynamic system mechanism mediating between structure and processing. (2) Drawing on the Murdoch notion of loving attention, we outline technical pathways for embedding morality in LLMs, through modified training objectives, runtime weight adjustments, and architectural refinements to attention. (3) We argue that integrating morality into architectures and frameworks complements external, constraint-based methods. We conclude with a call for collaboration between transformer designers and philosophers engaged in AI ethics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.20689v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Gunter Bombaerts, Bram Delisse, Uzay Kaymak</dc:creator>
    </item>
    <item>
      <title>The Human Brain as a Combinatorial Complex</title>
      <link>https://arxiv.org/abs/2511.20692</link>
      <description>arXiv:2511.20692v1 Announce Type: new 
Abstract: We propose a framework for constructing combinatorial complexes (CCs) from fMRI time series data that captures both pairwise and higher-order neural interactions through information-theoretic measures, bridging topological deep learning and network neuroscience. Current graph-based representations of brain networks systematically miss the higher-order dependencies that characterize neural complexity, where information processing often involves synergistic interactions that cannot be decomposed into pairwise relationships. Unlike topological lifting approaches that map relational structures into higher-order domains, our method directly constructs CCs from statistical dependencies in the data. Our CCs generalize graphs by incorporating higher-order cells that represent collective dependencies among brain regions, naturally accommodating the multi-scale, hierarchical nature of neural processing. The framework constructs data-driven combinatorial complexes using O-information and S-information measures computed from fMRI signals, preserving both pairwise connections and higher-order cells (e.g., triplets, quadruplets) based on synergistic dependencies. Using NetSim simulations as a controlled proof-of-concept dataset, we demonstrate our CC construction pipeline and show how both pairwise and higher-order dependencies in neural time series can be quantified and represented within a unified structure. This work provides a framework for brain network representation that preserves fundamental higher-order structure invisible to traditional graph methods, and enables the application of topological deep learning (TDL) architectures to neural data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.20692v1</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Valentina S\'anchez, \c{C}i\c{c}ek G\"uven, Koen Haak, Theodore Papamarkou, Gonzalo N\'apoles, Marie \v{S}af\'a\v{r} Postma</dc:creator>
    </item>
    <item>
      <title>Symbiotic Brain-Machine Drawing via Visual Brain-Computer Interfaces</title>
      <link>https://arxiv.org/abs/2511.20835</link>
      <description>arXiv:2511.20835v1 Announce Type: new 
Abstract: Brain-computer interfaces (BCIs) are evolving from research prototypes into clinical, assistive, and performance enhancement technologies. Despite the rapid rise and promise of implantable technologies, there is a need for better and more capable wearable and non-invasive approaches whilst also minimising hardware requirements. We present a non-invasive BCI for mind-drawing that iteratively infers a subject's internal visual intent by adaptively presenting visual stimuli (probes) on a screen encoded at different flicker-frequencies and analyses the steady-state visual evoked potentials (SSVEPs). A Gabor-inspired or machine-learned policies dynamically update the spatial placement of the visual probes on the screen to explore the image space and reconstruct simple imagined shapes within approximately two minutes or less using just single-channel EEG data. Additionally, by leveraging stable diffusion models, reconstructed mental images can be transformed into realistic and detailed visual representations. Whilst we expect that similar results might be achievable with e.g. eye-tracking techniques, our work shows that symbiotic human-AI interaction can significantly increase BCI bit-rates by more than a factor 5x, providing a platform for future development of AI-augmented BCI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.20835v1</guid>
      <category>q-bio.NC</category>
      <category>cs.HC</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gao Wang, Yingying Huang, Lars Muckli, Daniele Faccio</dc:creator>
    </item>
    <item>
      <title>Meditative absorption shifts brain dynamics toward criticality</title>
      <link>https://arxiv.org/abs/2511.20990</link>
      <description>arXiv:2511.20990v1 Announce Type: new 
Abstract: Criticality describes a regime between order and chaos that supports flexible yet stable information processing. Here we examine whether neural dynamics can be volitionally shifted toward criticality through the self-regulation of attention. We examined ten experienced practitioners of meditation during a 10-day retreat, comparing refined states of meditative absorption, called the jhanas, to regular mindfulness of breathing. We collected electroencephalography (EEG) and physiological data during these practices and quantified the signal's dynamical properties using Lempel-Ziv complexity, signal entropy, chaoticity and long-range temporal correlations. In addition, we estimated perturbational sensitivity using a global auditory oddball mismatch negativity (MMN) during meditation. Relative to mindfulness, jhana was associated with pronounced self-reported sensory fading, slower respiration, higher neural signal diversity across multiple measures, reduced chaoticity, and enhanced MMN amplitude over frontocentral sites. Spectral analyses showed a flatter aperiodic one over f component and a frequency-specific reorganization of long-range temporal correlations. Together, increased diversity with reduced chaoticity and heightened deviance detection indicate a shift toward a metastable, near-critical regime during jhana. We propose an overlap of the phenomenology of jhana with minimal phenomenal experiences in terms of progressive attenuation of sensory content with preserved tonic alertness. Accordingly, our findings suggest that criticality is a candidate neurophysiological marker of the absorptive, minimal-content dimension of the minimal phenomenal experience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.20990v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonas Mago, Joshua Brahinsky, Mark Miller, Charlotte Maschke, Heleen A. Slagter, Shaila Catherine, Ruben E. Laukkonen, B. Rael Cahn, Matthew D. Sacchet, Wangmo Dixey, Richard Dixey, Soham Rej, Michael Lifshitz</dc:creator>
    </item>
    <item>
      <title>Detecting absence: A dedicated prediction-error signal emerging in the auditory thalamus</title>
      <link>https://arxiv.org/abs/2511.21605</link>
      <description>arXiv:2511.21605v1 Announce Type: new 
Abstract: How does the brain know what is out there and what is not? Living organisms cannot rely solely on sensory signals for perception because they are noisy and ambiguous. To transform sensory signals into stable percepts, the brain uses its prior knowledge or beliefs. Current theories describe perceptual beliefs as probability distributions over the features of the stimuli, summarised by their mean and variance. Beliefs are updated by feature prediction errors: the mismatch between expected and observed feature values. This framework explains how the brain encodes unexpected changes in stimulus features (e.g., higher or lower pitch, stronger or weaker motion). How the brain updates beliefs about a stimulus' presence or absence is, however, unclear.
  We propose that the detection of absence relies on a distinct form of prediction error dedicated to reducing the beliefs on stimulus occurrence. We call this signal absence prediction error. Using the human auditory system as a model for sensory processing, we developed a paradigm designed to test this hypothesis. fMRI results showed that absence prediction error is encoded in the auditory thalamus and cortex, indicating that absence is explicitly represented in subcortical sensory pathways. Moreover, while feature prediction error is already encoded in the auditory midbrain, absence prediction error was not, implying that absence-related error signals are supported by a different circuit.
  These results identify a neural mechanism for the detection of sensory absence. Such mechanisms may be disrupted in conditions such as psychosis, where predictions about absence and presence are impaired.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21605v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Alejandro Tabas, Heike S\"onnichsen, Sandeep Kaur, Marco Meixner, Katharina von Kriegstein</dc:creator>
    </item>
    <item>
      <title>Lesion-Independent Thalamic Degeneration Identifies Intrinsically Vulnerable Nuclei Associated with Cognitive Impairment in Multiple Sclerosis</title>
      <link>https://arxiv.org/abs/2511.21677</link>
      <description>arXiv:2511.21677v1 Announce Type: new 
Abstract: Cognitive impairment in multiple sclerosis (MS) is driven by both focal inflammation and compartmentalized neurodegeneration, yet the relative effect of lesion-independent thalamic atrophy on information processing speed (IPS) remains unclear. This retrospective cohort study included 100 participants with MS. Automatic segmentation techniques quantified lesion load and delineated 26 thalamic regions of interest (ROIs). Linear models compared associations between ROI volumes and Symbol Digit Modalities Test (SDMT) performance in lesion-adjusted and unadjusted models. Twenty-one of 26 ROIs showed significant SDMT associations before lesion adjustment; twelve remained significant after adjustment. Lesion-independent associations were observed in the global thalamus, sensory relay nuclei (ventral posterolateral, medial and lateral geniculate), and associative hubs (pulvinar and mediodorsal-parafascicular complex). These intrinsically vulnerable nuclei exhibited significantly lower lesion-mediated effects (13.4%) than those losing significance after adjustment (34.2%, p &lt; 0.001). Our findings suggest that IPS impairment reflects heterogenous contributions from both primary and secondary degeneration, with nucleus-specific phenotyping potentially informing identification of higher risk individuals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21677v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arshya Pooladi-Darvish (Centre for Functional and Metabolic Mapping, Robarts Research Institute, London, Canada, Department of Medical Biophysics, Western University, London, Canada), Heather Rosehart (Department of Clinical Neurological Sciences, Western University, London, Canada), Marina R. Everest (Department of Clinical Neurological Sciences, Western University, London, Canada), Ali R. Khan (Centre for Functional and Metabolic Mapping, Robarts Research Institute, London, Canada, Department of Medical Biophysics, Western University, London, Canada), Sarah A. Morrow (Department of Clinical Neurological Sciences, Western University, London, Canada, Department of Clinical Neurosciences, Hotchkiss Brain Institute, University of Calgary, Calgary, Canada)</dc:creator>
    </item>
    <item>
      <title>Stabilizing Fractional Dynamical Networks Suppresses Epileptic Seizures</title>
      <link>https://arxiv.org/abs/2511.20950</link>
      <description>arXiv:2511.20950v1 Announce Type: cross 
Abstract: Medically uncontrolled epileptic seizures affect nearly 15 million people worldwide, resulting in enormous economic and psychological burdens. Treatment of medically refractory epilepsy is essential for patients to achieve remission, improve psychological functioning, and enhance social and vocational outcomes. Here, we show a state-of-the-art method that stabilizes fractional dynamical networks modeled from intracranial EEG data, effectively suppressing seizure activity in 34 out of 35 total spontaneous episodes from patients at the University of Pennsylvania and the Mayo Clinic. We perform a multi-scale analysis and show that the fractal behavior and stability properties of these data distinguish between four epileptic states: interictal, pre-ictal, ictal, and post-ictal. Furthermore, the simulated controlled signals exhibit substantial amplitude reduction ($49\%$ average). These findings highlight the potential of fractional dynamics to characterize seizure-related brain states and demonstrate its capability to suppress epileptic activity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.20950v1</guid>
      <category>q-bio.QM</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yaoyue Wang, Arian Ashourvan, Guilherme Ramos, Paul Bogdan, Emily Pereira</dc:creator>
    </item>
    <item>
      <title>Event-driven eligibility propagation in large sparse networks: efficiency shaped by biological realism</title>
      <link>https://arxiv.org/abs/2511.21674</link>
      <description>arXiv:2511.21674v1 Announce Type: cross 
Abstract: Despite remarkable technological advances, AI systems may still benefit from biological principles, such as recurrent connectivity and energy-efficient mechanisms. Drawing inspiration from the brain, we present a biologically plausible extension of the eligibility propagation (e-prop) learning rule for recurrent spiking networks. By translating the time-driven update scheme into an event-driven one, we integrate the learning rule into a simulation platform for large-scale spiking neural networks and demonstrate its applicability to tasks such as neuromorphic MNIST. We extend the model with prominent biological features such as continuous dynamics and weight updates, strict locality, and sparse connectivity. Our results show that biologically grounded constraints can inform the design of computationally efficient AI algorithms, offering scalability to millions of neurons without compromising learning performance. This work bridges machine learning and computational neuroscience, paving the way for sustainable, biologically inspired AI systems while advancing our understanding of brain-like learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21674v1</guid>
      <category>cs.NE</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Agnes Korcsak-Gorzo, Jes\'us A. Espinoza Valverde, Jonas Stapmanns, Hans Ekkehard Plesser, David Dahmen, Matthias Bolten, Sacha J. van Albada, Markus Diesmann</dc:creator>
    </item>
    <item>
      <title>Bridging Critical Gaps in Convergent Learning: How Representational Alignment Evolves Across Layers, Training, and Distribution Shifts</title>
      <link>https://arxiv.org/abs/2502.18710</link>
      <description>arXiv:2502.18710v3 Announce Type: replace 
Abstract: Understanding convergent learning -- the degree to which independently trained neural systems -- whether multiple artificial networks or brains and models -- arrive at similar internal representations -- is crucial for both neuroscience and AI. Yet, the literature remains narrow in scope -- typically examining just a handful of models with one dataset, relying on one alignment metric, and evaluating networks at a single post-training checkpoint. We present a large-scale audit of convergent learning, spanning dozens of vision models and thousands of layer-pair comparisons, to close these long-standing gaps. First, we pit three alignment families against one another -- linear regression (affine-invariant), orthogonal Procrustes (rotation-/reflection-invariant), and permutation/soft-matching (unit-order-invariant). We find that orthogonal transformations align representations nearly as effectively as more flexible linear ones, and although permutation scores are lower, they significantly exceed chance, indicating a privileged representational basis. Tracking convergence throughout training further shows that nearly all eventual alignment crystallizes within the first epoch -- well before accuracy plateaus -- indicating it is largely driven by shared input statistics and architectural biases, not by the final task solution. Finally, when models are challenged with a battery of out-of-distribution images, early layers remain tightly aligned, whereas deeper layers diverge in proportion to the distribution shift. These findings fill critical gaps in our understanding of representational convergence, with implications for neuroscience and AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18710v3</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Chaitanya Kapoor, Sudhanshu Srivastava, Meenakshi Khosla</dc:creator>
    </item>
    <item>
      <title>Category learning in deep neural networks: Information content and geometry of internal representations</title>
      <link>https://arxiv.org/abs/2510.19021</link>
      <description>arXiv:2510.19021v2 Announce Type: replace-cross 
Abstract: In humans and other animals, category learning enhances discrimination between stimuli close to the category boundary. This phenomenon, called categorical perception, was also empirically observed in artificial neural networks trained on classification tasks. In previous modeling works based on neuroscience data, we show that this expansion/compression is a necessary outcome of efficient learning. Here we extend our theoretical framework to artificial networks. We show that minimizing the Bayes cost (mean of the cross-entropy loss) implies maximizing the mutual information between the set of categories and the neural activities prior to the decision layer. Considering structured data with an underlying feature space of small dimension, we show that maximizing the mutual information implies (i) finding an appropriate projection space, and, (ii) building a neural representation with the appropriate metric. The latter is based on a Fisher information matrix measuring the sensitivity of the neural activity to changes in the projection space. Optimal learning makes this neural Fisher information follow a category-specific Fisher information, measuring the sensitivity of the category membership. Category learning thus induces an expansion of neural space near decision boundaries. We characterize the properties of the categorical Fisher information, showing that its eigenvectors give the most discriminant directions at each point of the projection space. We find that, unexpectedly, its maxima are in general not exactly at, but near, the class boundaries. Considering toy models and the MNIST dataset, we numerically illustrate how after learning the two Fisher information matrices match, and essentially align with the category boundaries. Finally, we relate our approach to the Information Bottleneck one, and we exhibit a bias-variance decomposition of the Bayes cost, of interest on its own.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19021v2</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/mp35-bdx5</arxiv:DOI>
      <arxiv:journal_reference>Physical Review E, 112, 055315, 2025</arxiv:journal_reference>
      <dc:creator>Laurent Bonnasse-Gahot, Jean-Pierre Nadal</dc:creator>
    </item>
  </channel>
</rss>
