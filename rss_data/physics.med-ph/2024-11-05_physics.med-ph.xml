<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.med-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.med-ph</link>
    <description>physics.med-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.med-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 05 Nov 2024 05:03:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Ungated, plug-and-play preclinical cardiac CEST-MRI using radial FLASH with segmented saturation</title>
      <link>https://arxiv.org/abs/2411.01004</link>
      <description>arXiv:2411.01004v1 Announce Type: new 
Abstract: Purpose: ECG and respiratory-gated preclinical cardiac CEST-MRI acquisitions are difficult due to variable saturation recovery with T1, RF interference in the ECG signal, and offset-to-offset variation in Z-magnetization and cardiac phase introduced by changes in cardiac frequency and trigger delays. Methods: The proposed method consists of segmented saturation modules with radial FLASH readouts and golden angle progression. The segmented saturation blocks drive the system to steady-state, and because center k-space is sampled repeatedly, steady-state saturation dominates contrast during gridding and reconstruction. Ten complete Z-spectra were acquired in healthy mice using both ECG and respiratory-gated, and ungated methods. Z-spectra were also acquired at multiple saturation B1 values to optimize for amide and creatine contrasts. Results: There was no significant difference between CEST contrasts (amide, creatine, MT) calculated from images acquired using ECG and respiratory-gated and ungated methods (p = 0.27, 0.11, 0.47). A saturation power of 1.8$\mu$T provides optimal contrast amplitudes for both amide and total creatine contrast without significantly complicating CEST contrast quantification due to water direct saturation, magnetization transfer, and RF spillover between amide and creatine pools. Further, variability in CEST contrast measurements was significantly reduced using the ungated radial FLASH acquisition (p = 0.002, 0.006 for amide and creatine respectively). Conclusion: This method enables CEST mapping in the murine myocardium without the need for cardiac or respiratory gating. Quantitative CEST contrasts are consistent with those obtained using gated sequences, and per-contrast variance is significantly reduced. This approach makes preclinical cardiac CEST-MRI easily accessible, even for investigators without prior experience in cardiac imaging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01004v1</guid>
      <category>physics.med-ph</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonah Weigand-Whittier (Department of Bioengineering, University of California Berkeley), Michael Wendland (Berkeley Preclinical Imaging Core, University of California Berkeley), Bonnie Lam (Department of Bioengineering, University of California Berkeley), Mark Velasquez (Department of Bioengineering, University of California Berkeley), Moriel H. Vandsburger (Department of Bioengineering, University of California Berkeley)</dc:creator>
    </item>
    <item>
      <title>Penumbra-Effect Induced Spectral Mixing in X-ray Computed Tomography: A Multi-Ray Spectrum Estimation Model and Subsampled Weighting Algorithm</title>
      <link>https://arxiv.org/abs/2411.01543</link>
      <description>arXiv:2411.01543v1 Announce Type: new 
Abstract: Purpose: With the development of spectral CT, several novel spectral filters have been introduced to modulate the spectra, such as split filters and spectral modulators. However, due to the finite size of the focal spot of X-ray source, these filters cause spectral mixing in the penumbra region. Traditional spectrum estimation methods fail to account for it, resulting in reduced spectral accuracy. Methods: To address this challenge, we develop a multi-ray spectrum estimation model and propose an Adaptive Subsampled WeIghting of Filter Thickness (A-SWIFT) method. First, we estimate the unfiltered spectrum using traditional methods. Next, we model the final spectra as a weighted summation of spectra attenuated by multiple filters. The weights and equivalent lengths are obtained by X-ray transmission measurements taken with altered spectra using different kVp or flat filters. Finally, the spectra are approximated by using the multi-ray model. To mimic the penumbra effect, we used a spectral modulator (0.2 mm Mo, 0.6 mm Mo) and a split filter (0.07 mm Au, 0.7 mm Sn) in simulations, and used a copper modulator and a molybdenum modulator (0.2 mm, 0.6 mm) in experiments. Results: Simulation results show that the mean energy bias in the penumbra region decreased from 7.43 keV using the previous SCFM method (Spectral Compensation for Modulator) to 0.72 keV using the A-SWIFT method for the split filter, and from 1.98 keV to 0.61 keV for the spectral modulator. In experiments, the root mean square error of the selected ROIs was decreased from 77 to 7 Hounsfield units (HU) for the pure water phantom with a molybdenum modulator, and from 85 to 21 HU with a copper modulator. Conclusion: Based on a multi-ray spectrum estimation model, the A-SWIFT method provides an accurate and robust approach for spectrum estimation in penumbra region of CT systems utilizing spectral filters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01543v1</guid>
      <category>physics.med-ph</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifan Deng, Hao Zhou, Hewei Gao</dc:creator>
    </item>
    <item>
      <title>Deep Multi-contrast Cardiac MRI Reconstruction via vSHARP with Auxiliary Refinement Network</title>
      <link>https://arxiv.org/abs/2411.01291</link>
      <description>arXiv:2411.01291v1 Announce Type: cross 
Abstract: Cardiac MRI (CMRI) is a cornerstone imaging modality that provides in-depth insights into cardiac structure and function. Multi-contrast CMRI (MCCMRI), which acquires sequences with varying contrast weightings, significantly enhances diagnostic capabilities by capturing a wide range of cardiac tissue characteristics. However, MCCMRI is often constrained by lengthy acquisition times and susceptibility to motion artifacts. To mitigate these challenges, accelerated imaging techniques that use k-space undersampling via different sampling schemes at acceleration factors have been developed to shorten scan durations. In this context, we propose a deep learning-based reconstruction method for 2D dynamic multi-contrast, multi-scheme, and multi-acceleration MRI. Our approach integrates the state-of-the-art vSHARP model, which utilizes half-quadratic variable splitting and ADMM optimization, with a Variational Network serving as an Auxiliary Refinement Network (ARN) to better adapt to the diverse nature of MCCMRI data. Specifically, the subsampled k-space data is fed into the ARN, which produces an initial prediction for the denoising step used by vSHARP. This, along with the subsampled k-space, is then used by vSHARP to generate high-quality 2D sequence predictions. Our method outperforms traditional reconstruction techniques and other vSHARP-based models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01291v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>physics.med-ph</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>George Yiasemis, Nikita Moriakov, Jan-Jakob Sonke, Jonas Teuwen</dc:creator>
    </item>
    <item>
      <title>Simulation of Nanorobots with Artificial Intelligence and Reinforcement Learning for Advanced Cancer Cell Detection and Tracking</title>
      <link>https://arxiv.org/abs/2411.02345</link>
      <description>arXiv:2411.02345v1 Announce Type: cross 
Abstract: Nanorobots are a promising development in targeted drug delivery and the treatment of neurological disorders, with potential for crossing the blood-brain barrier (BBB). These small devices leverage advancements in nanotechnology and bioengineering for precise navigation and targeted payload delivery, particularly for conditions like brain tumors, Alzheimer's disease, and Parkinson's disease. Recent progress in artificial intelligence (AI) and machine learning (ML) has improved the navigation and effectiveness of nanorobots, allowing them to detect and interact with cancer cells through biomarker analysis. This study presents a new reinforcement learning (RL) framework for optimizing nanorobot navigation in complex biological environments, focusing on cancer cell detection by analyzing the concentration gradients of surrounding biomarkers. We utilize a computer simulation model to explore the behavior of nanorobots in a three-dimensional space with cancer cells and biological barriers. The proposed method uses Q-learning to refine movement strategies based on real-time biomarker concentration data, enabling nanorobots to autonomously navigate to cancerous tissues for targeted drug delivery. This research lays the groundwork for future laboratory experiments and clinical applications, with implications for personalized medicine and less invasive cancer treatments. The integration of intelligent nanorobots could revolutionize therapeutic strategies, reducing side effects and enhancing treatment effectiveness for cancer patients. Further research will investigate the practical deployment of these technologies in medical settings, aiming to unlock the full potential of nanorobotics in healthcare.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02345v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>physics.med-ph</category>
      <category>q-bio.OT</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shahab Kavousinejad</dc:creator>
    </item>
    <item>
      <title>PyTomography: A Python Library for Quantitative Medical Image Reconstruction</title>
      <link>https://arxiv.org/abs/2309.01977</link>
      <description>arXiv:2309.01977v5 Announce Type: replace 
Abstract: There is a need for open-source libraries in emission tomography that (i) use modern and popular backend code to encourage community contributions and (ii) offer support for the multitude of reconstruction techniques available in recent literature, such as those that employ artificial intelligence. The purpose of this research was to create and evaluate a GPU-accelerated, open-source, and user-friendly image reconstruction library, designed to serve as a central platform for the development, validation, and deployment of various tomographic reconstruction algorithms. PyTomography was developed using Python and inherits the GPU-accelerated functionality of PyTorch and parallelproj for fast computations. Its flexible and modular design decouples system matrices, likelihoods, and reconstruction algorithms, simplifying the process of integrating new imaging modalities using various python tools. Example use cases demonstrate the software capabilities in parallel hole SPECT and listmode PET imaging. Overall, we have developed and publicly share PyTomography, a highly optimized and user-friendly software for medical image reconstruction, with a class hierarchy that fosters the development of novel imaging applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.01977v5</guid>
      <category>physics.med-ph</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Lucas Polson, Roberto Fedrigo, Chenguang Li, Maziar Sabouri, Obed Dzikunu, Shadab Ahamed, Nikolaos Karakatsanis, Arman Rahmim, Carlos Uribe</dc:creator>
    </item>
  </channel>
</rss>
