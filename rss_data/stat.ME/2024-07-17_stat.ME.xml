<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.ME updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.ME</link>
    <description>stat.ME updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.ME" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 18 Jul 2024 04:00:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 18 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Agglomerative Clustering of Simulation Output Distributions Using Regularized Wasserstein Distance</title>
      <link>https://arxiv.org/abs/2407.12100</link>
      <description>arXiv:2407.12100v1 Announce Type: new 
Abstract: We investigate the use of clustering methods on data produced by a stochastic simulator, with applications in anomaly detection, pre-optimization, and online monitoring. We introduce an agglomerative clustering algorithm that clusters multivariate empirical distributions using the regularized Wasserstein distance and apply the proposed methodology on a call-center model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12100v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammadmahdi Ghasemloo, David J. Eckman</dc:creator>
    </item>
    <item>
      <title>Bounds on causal effects in $2^{K}$ factorial experiments with non-compliance</title>
      <link>https://arxiv.org/abs/2407.12114</link>
      <description>arXiv:2407.12114v1 Announce Type: new 
Abstract: Factorial experiments are ubiquitous in the social and biomedical sciences, but when units fail to comply with each assigned factors, identification and estimation of the average treatment effects become impossible. Leveraging an instrumental variables approach, previous studies have shown how to identify and estimate the causal effect of treatment uptake among respondents who comply with treatment. A major caveat is that these identification results rely on strong assumptions on the effect of randomization on treatment uptake. This paper shows how to bound these complier average treatment effects under more mild assumptions on non-compliance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12114v1</guid>
      <category>stat.ME</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Matthew Blackwell, Nicole E. Pashley</dc:creator>
    </item>
    <item>
      <title>Temporal Configuration Model: Statistical Inference and Spreading Processes</title>
      <link>https://arxiv.org/abs/2407.12175</link>
      <description>arXiv:2407.12175v1 Announce Type: new 
Abstract: We introduce a family of parsimonious network models that are intended to generalize the configuration model to temporal settings. We present consistent estimators for the model parameters and perform numerical simulations to illustrate the properties of the estimators on finite samples. We also develop analytical solutions for basic and effective reproductive numbers for the early stage of discrete-time SIR spreading process. We apply three distinct temporal configuration models to empirical student proximity networks and compare their performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12175v1</guid>
      <category>stat.ME</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thien-Minh Le, Hali Hambridge, Jukka-Pekka Onnela</dc:creator>
    </item>
    <item>
      <title>MM Algorithms for Statistical Estimation in Quantile Regression</title>
      <link>https://arxiv.org/abs/2407.12348</link>
      <description>arXiv:2407.12348v1 Announce Type: new 
Abstract: Quantile regression is a robust and practically useful way to efficiently model quantile varying correlation and predict varied response quantiles of interest. This article constructs and tests MM algorithms, which are simple to code and have been suggested superior to some other prominent quantile regression methods in nonregularized problems, in an array of quantile regression settings including linear (modeling different quantile coefficients both separately and simultaneously), nonparametric, regularized, and monotone quantile regression. Applications to various real data sets and two simulation studies comparing MM to existing tested methods have corroborated our algorithms' effectiveness. We have made one key advance by generalizing our MM algorithm to efficiently fit easy-to-predict-and-interpret parametric quantile regression models for data sets exhibiting manifest complicated nonlinear correlation patterns, which has not yet been covered by current literature to the best of our knowledge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12348v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yifan Cheng, Anthony Yung Cheung Kuk</dc:creator>
    </item>
    <item>
      <title>Comparing Homogeneous And Inhomogeneous Time Markov Chains For Modelling Degradation In Sewer Pipe Networks</title>
      <link>https://arxiv.org/abs/2407.12557</link>
      <description>arXiv:2407.12557v1 Announce Type: new 
Abstract: Sewer pipe systems are essential for social and economic welfare. Managing these systems requires robust predictive models for degradation behaviour. This study focuses on probability-based approaches, particularly Markov chains, for their ability to associate random variables with degradation. Literature predominantly uses homogeneous and inhomogeneous Markov chains for this purpose. However, their effectiveness in sewer pipe degradation modelling is still debatable. Some studies support homogeneous Markov chains, while others challenge their utility. We examine this issue using a large-scale sewer network in the Netherlands, incorporating historical inspection data. We model degradation with homogeneous discrete and continuous time Markov chains, and inhomogeneous-time Markov chains using Gompertz, Weibull, Log-Logistic and Log-Normal density functions. Our analysis suggests that, despite their higher computational requirements, inhomogeneous-time Markov chains are more appropriate for modelling the nonlinear stochastic characteristics related to sewer pipe degradation, particularly the Gompertz distribution. However, they pose a risk of over-fitting, necessitating significant improvements in parameter inference processes to effectively address this issue.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12557v1</guid>
      <category>stat.ME</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Proceedings of the 34th European Safety and Reliability Conference (ESREL) 2024</arxiv:journal_reference>
      <dc:creator>Lisandro A. Jimenez-Roa, Tiedo Tinga, Tom Heskes, Marielle Stoelinga</dc:creator>
    </item>
    <item>
      <title>Bayesian spatial functional data clustering: applications in disease surveillance</title>
      <link>https://arxiv.org/abs/2407.12633</link>
      <description>arXiv:2407.12633v1 Announce Type: new 
Abstract: Our method extends the application of random spanning trees to cases where the response variable belongs to the exponential family, making it suitable for a wide range of real-world scenarios, including non-Gaussian likelihoods. The proposed model addresses the limitations of previous spatial clustering methods by allowing all within-cluster model parameters to be cluster-specific, thus offering greater flexibility. Additionally, we propose a Bayesian inference algorithm that overcomes the computational challenges associated with the reversible jump Markov chain Monte Carlo (RJ-MCMC) algorithm by employing composition sampling and the integrated nested Laplace approximation (INLA) to compute the marginal distribution necessary for the acceptance probability. This enhancement improves the mixing and feasibility of Bayesian inference for complex models. We demonstrate the effectiveness of our approach through simulation studies and apply it to real-world disease mapping applications: COVID-19 in the United States of America, and dengue fever in the states of Minas Gerais and S\~ao Paulo, Brazil. Our results highlight the model's capability to uncover meaningful spatial patterns and temporal dynamics in disease outbreaks, providing valuable insights for public health decision-making and resource allocation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12633v1</guid>
      <category>stat.ME</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruiman Zhong, Erick A. Chac\'on-Montalv\'an, Paula Moraga</dc:creator>
    </item>
    <item>
      <title>Bayesian Joint Modeling of Interrater and Intrarater Reliability with Multilevel Data</title>
      <link>https://arxiv.org/abs/2407.12700</link>
      <description>arXiv:2407.12700v1 Announce Type: new 
Abstract: We formulate three generalized Bayesian models for analyzing interrater and intrarater reliability in the presence of multilevel data. Stan implementations of these models provide new estimates of interrater and intrarater reliability. We also derive formulas for calculating marginal correlations under each of the three models. Comparisons of the kappa estimates and marginal correlations across the different models are presented from two real-world datasets. Simulations demonstrate properties of the different measures of agreement under different model assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12700v1</guid>
      <category>stat.ME</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nour Hawila, Arthur Berg</dc:creator>
    </item>
    <item>
      <title>Maximum-likelihood regression with systematic errors for astronomy and the physical sciences: I. Methodology and goodness-of-fit statistic of Poisson data</title>
      <link>https://arxiv.org/abs/2407.12132</link>
      <description>arXiv:2407.12132v1 Announce Type: cross 
Abstract: The paper presents a new statistical method that enables the use of systematic errors in the maximum-likelihood regression of integer-count Poisson data to a parametric model. The method is primarily aimed at the characterization of the goodness-of-fit statistic in the presence of the over-dispersion that is induced by sources of systematic error, and is based on a quasi-maximum-likelihood method that retains the Poisson distribution of the data. We show that the Poisson deviance, which is the usual goodness-of-fit statistic and that is commonly referred to in astronomy as the Cash statistics, can be easily generalized in the presence of systematic errors, under rather general conditions. The method and the associated statistics are first developed theoretically, and then they are tested with the aid of numerical simulations and further illustrated with real-life data from astronomical observations. The statistical methods presented in this paper are intended as a simple general-purpose framework to include additional sources of uncertainty for the analysis of integer-count data in a variety of practical data analysis situations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12132v1</guid>
      <category>astro-ph.IM</category>
      <category>stat.ME</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Max Bonamente, Yang Chen, Dale Zimmerman</dc:creator>
    </item>
    <item>
      <title>COKE: Causal Discovery with Chronological Order and Expert Knowledge in High Proportion of Missing Manufacturing Data</title>
      <link>https://arxiv.org/abs/2407.12254</link>
      <description>arXiv:2407.12254v1 Announce Type: cross 
Abstract: Understanding causal relationships between machines is crucial for fault diagnosis and optimization in manufacturing processes. Real-world datasets frequently exhibit up to 90% missing data and high dimensionality from hundreds of sensors. These datasets also include domain-specific expert knowledge and chronological order information, reflecting the recording order across different machines, which is pivotal for discerning causal relationships within the manufacturing data. However, previous methods for handling missing data in scenarios akin to real-world conditions have not been able to effectively utilize expert knowledge. Conversely, prior methods that can incorporate expert knowledge struggle with datasets that exhibit missing values. Therefore, we propose COKE to construct causal graphs in manufacturing datasets by leveraging expert knowledge and chronological order among sensors without imputing missing data. Utilizing the characteristics of the recipe, we maximize the use of samples with missing values, derive embeddings from intersections with an initial graph that incorporates expert knowledge and chronological order, and create a sensor ordering graph. The graph-generating process has been optimized by an actor-critic architecture to obtain a final graph that has a maximum reward. Experimental evaluations in diverse settings of sensor quantities and missing proportions demonstrate that our approach compared with the benchmark methods shows an average improvement of 39.9% in the F1-score. Moreover, the F1-score improvement can reach 62.6% when considering the configuration similar to real-world datasets, and 85.0% in real-world semiconductor datasets. The source code is available at https://github.com/OuTingYun/COKE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12254v1</guid>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ting-Yun Ou, Ching Chang, Wen-Chih Peng</dc:creator>
    </item>
    <item>
      <title>An Approximation for the 32-point Discrete Fourier Transform</title>
      <link>https://arxiv.org/abs/2407.12708</link>
      <description>arXiv:2407.12708v1 Announce Type: cross 
Abstract: This brief note aims at condensing some results on the 32-point approximate DFT and discussing its arithmetic complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12708v1</guid>
      <category>eess.SP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ME</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>R. J. Cintra</dc:creator>
    </item>
    <item>
      <title>Scalable Monte Carlo for Bayesian Learning</title>
      <link>https://arxiv.org/abs/2407.12751</link>
      <description>arXiv:2407.12751v1 Announce Type: cross 
Abstract: This book aims to provide a graduate-level introduction to advanced topics in Markov chain Monte Carlo (MCMC) algorithms, as applied broadly in the Bayesian computational context. Most, if not all of these topics (stochastic gradient MCMC, non-reversible MCMC, continuous time MCMC, and new techniques for convergence assessment) have emerged as recently as the last decade, and have driven substantial recent practical and theoretical advances in the field. A particular focus is on methods that are scalable with respect to either the amount of data, or the data dimension, motivated by the emerging high-priority application areas in machine learning and AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12751v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paul Fearnhead, Christopher Nemeth, Chris J. Oates, Chris Sherlock</dc:creator>
    </item>
    <item>
      <title>A stochastic network approach to clustering and visualising single-cell genomic count data</title>
      <link>https://arxiv.org/abs/2303.02498</link>
      <description>arXiv:2303.02498v3 Announce Type: replace 
Abstract: Important tasks in the study of genomic data include the identification of groups of similar cells (for example by clustering), and visualisation of data summaries (for example by dimensional reduction). In this paper, we propose a novel approach to studying single-cell genomic data, by modelling the observed genomic data count matrix $\mathbf{X}\in\mathbb{Z}_{\geq0}^{p\times n}$ as a bipartite network with multi-edges. Utilising this first-principles network representation of the raw data, we propose clustering single cells in a suitably identified $d$-dimensional Laplacian Eigenspace (LE) via a Gaussian mixture model (GMM-LE), and employing UMAP to non-linearly project the LE to two dimensions for visualisation (UMAP-LE). This LE representation of the data estimates transformed latent positions (of genes and cells), under a latent position model of nodes in a bipartite stochastic network. We demonstrate how these estimated latent positions can enable fine-grained clustering and visualisation of single-cell genomic data, by application to data from three recent genomics studies in different biological contexts. In each data application, clusters of cells independently learned by our proposed methodology are found to correspond to cells expressing specific marker genes that were independently defined by domain experts. In this validation setting, our proposed clustering methodology outperforms the industry-standard for these data. Furthermore, we validate components of the LE decomposition of the data by contrasting healthy cells from normal and at-risk groups in a machine-learning model, thereby generating an LE cancer biomarker that significantly predicts long-term patient survival outcome in an independent validation dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.02498v3</guid>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Thomas E. Bartlett, Swati Chandna, Sandipan Roy</dc:creator>
    </item>
    <item>
      <title>Stein Variational Rare Event Simulation</title>
      <link>https://arxiv.org/abs/2308.04971</link>
      <description>arXiv:2308.04971v2 Announce Type: replace 
Abstract: Rare event simulation and rare event probability estimation are important tasks within the analysis of systems subject to uncertainty and randomness. Simultaneously, accurately estimating rare event probabilities is an inherently difficult task that calls for dedicated tools and methods. One way to improve estimation efficiency on difficult rare event estimation problems is to leverage gradients of the computational model representing the system in consideration, e.g., to explore the rare event faster and more reliably. We present a novel approach for estimating rare event probabilities using such model gradients by drawing on a technique to generate samples from non-normalized posterior distributions in Bayesian inference - the Stein variational gradient descent. We propagate samples generated from a tractable input distribution towards a near-optimal rare event importance sampling distribution by exploiting a similarity of the latter with Bayesian posterior distributions. Sample propagation takes the shape of passing samples through a sequence of invertible transforms such that their densities can be tracked and used to construct an unbiased importance sampling estimate of the rare event probability - the Stein variational rare event estimator. We discuss settings and parametric choices of the algorithm and suggest a method for balancing convergence speed with stability by choosing the step width or base learning rate adaptively. We analyze the method's performance on several analytical test functions and two engineering examples in low to high stochastic dimensions ($d = 2 - 869$) and find that it consistently outperforms other state-of-the-art gradient-based rare event simulation methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.04971v2</guid>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Max Ehre, Iason Papaioannou, Daniel Straub</dc:creator>
    </item>
    <item>
      <title>Extreme-value modelling of migratory bird arrival dates: Insights from citizen science data</title>
      <link>https://arxiv.org/abs/2312.01870</link>
      <description>arXiv:2312.01870v3 Announce Type: replace 
Abstract: Citizen science mobilises many observers and gathers huge datasets but often without strict sampling protocols, which results in observation biases due to heterogeneity in sampling effort that can lead to biased statistical inferences. We develop a spatiotemporal Bayesian hierarchical model for bias-corrected estimation of arrival dates of the first migratory bird individuals at a breeding site. Higher sampling effort could be correlated with earlier observed dates. We implement data fusion of two citizen-science datasets with fundamentally different protocols (BBS, eBird) and map posterior distributions of the latent process, which contains four spatial components with Gaussian process priors: species niche; sampling effort; position and scale parameters of annual first date of arrival. The data layer includes four response variables: counts of observed eBird locations (Poisson); presence-absence at observed eBird locations (Binomial); BBS occurrence counts (Poisson); first arrival dates (Generalized Extreme-Value). We devise a Markov Chain Monte Carlo scheme and check by simulation that the latent process components are identifiable. We apply our model to several migratory bird species in the northeastern US for 2001--2021, and find that the sampling effort significantly modulates the observed first arrival date. We exploit this relationship to effectively bias-correct predictions of the true first arrival dates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.01870v3</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonathan Koh, Thomas Opitz</dc:creator>
    </item>
    <item>
      <title>Causal inference under transportability assumptions for conditional relative effect measures</title>
      <link>https://arxiv.org/abs/2402.02702</link>
      <description>arXiv:2402.02702v2 Announce Type: replace 
Abstract: When extending inferences from a randomized trial to a new target population, the transportability condition for conditional difference effect measures is invoked to identify the marginal causal mean difference in the target population. However, many clinical investigators believe that conditional relative effect measures are more likely to be "transportable" between populations. Here, we examine the identification and estimation of the marginal counterfactual mean difference and ratio under the transportability condition for conditional relative effect measures. We obtain identification results for two scenarios that often arise in practice when individuals in the target population (1) only have access to the control treatment, and (2) have access to the control and other treatments but not necessarily the experimental treatment evaluated in the trial. We then propose model and rate multiply robust and nonparametric efficient estimators that allow for the use of data-adaptive methods to model the nuisance functions. We examine the performance of the methods in simulation studies and illustrate their use with data from two trials of paliperidone for patients with schizophrenia. We conclude that the proposed methods are attractive when background knowledge suggests that the transportability condition for conditional relative effect measures is more plausible than alternative conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.02702v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Guanbo Wang, Alexander Levis, Jon Steingrimsson, Issa Dahabreh</dc:creator>
    </item>
    <item>
      <title>Transportability of Principal Causal Effects</title>
      <link>https://arxiv.org/abs/2405.04419</link>
      <description>arXiv:2405.04419v2 Announce Type: replace 
Abstract: Recent research in causal inference has made important progress in addressing challenges to the external validity of trial findings. Such methods weight trial participant data to more closely resemble the distribution of effect-modifying covariates in a well-defined target population. In the presence of participant non-adherence to study medication, these methods effectively transport an intention-to-treat effect that averages over heterogeneous compliance behaviors. In this paper, we develop a principal stratification framework to identify causal effects conditioning on both compliance behavior and membership in the target population. We also develop non-parametric efficiency theory for and construct efficient estimators of such "transported" principal causal effects and characterize their finite-sample performance in simulation experiments. While this work focuses on treatment non-adherence, the framework is applicable to a broad class of estimands that target effects in clinically-relevant, possibly latent subsets of a target population.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04419v2</guid>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Justin M. Clark, Kollin W. Rott, James S. Hodges, Jared D. Huling</dc:creator>
    </item>
    <item>
      <title>Subgroup Identification with Latent Factor Structure</title>
      <link>https://arxiv.org/abs/2407.00882</link>
      <description>arXiv:2407.00882v2 Announce Type: replace 
Abstract: Subgroup analysis has garnered increasing attention for its ability to identify meaningful subgroups within heterogeneous populations, thereby enhancing predictive power. However, in many fields such as social science and biology, covariates are often highly correlated due to common factors. This correlation poses significant challenges for subgroup identification, an issue that is often overlooked in existing literature. In this paper, we aim to address this gap in the ``diverging dimension" regime by proposing a center-augmented subgroup identification method within the Factor Augmented (sparse) Linear Model framework. This method bridges dimension reduction and sparse regression. Our proposed approach is adaptable to the high cross-sectional dependence among covariates and offers computational advantages with a complexity of $O(nK)$, compared to the $O(n^2)$ complexity of the conventional pairwise fusion penalty method in the literature, where $n$ is the sample size and $K$ is the number of subgroups. We also investigate the asymptotic properties of the oracle estimators under conditions on the minimal distance between group centroids. To implement the proposed approach, we introduce a Difference of Convex functions-based Alternating Direction Method of Multipliers (DC-ADMM) algorithm and demonstrate its convergence to a local minimizer in a finite number of steps. We illustrate the superiority of the proposed method through extensive numerical experiments and a real macroeconomic data example. An \texttt{R} package, \texttt{SILFS}, implementing the method is also available on CRAN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00882v2</guid>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yong He, Dong Liu, Fuxin Wang, Mingjuan Zhang, Wen-Xin Zhou</dc:creator>
    </item>
    <item>
      <title>Positive and Unlabeled Data: Model, Estimation, Inference, and Classification</title>
      <link>https://arxiv.org/abs/2407.09735</link>
      <description>arXiv:2407.09735v2 Announce Type: replace 
Abstract: This study introduces a new approach to addressing positive and unlabeled (PU) data through the double exponential tilting model (DETM). Traditional methods often fall short because they only apply to selected completely at random (SCAR) PU data, where the labeled positive and unlabeled positive data are assumed to be from the same distribution. In contrast, our DETM's dual structure effectively accommodates the more complex and underexplored selected at random PU data, where the labeled and unlabeled positive data can be from different distributions. We rigorously establish the theoretical foundations of DETM, including identifiability, parameter estimation, and asymptotic properties. Additionally, we move forward to statistical inference by developing a goodness-of-fit test for the SCAR condition and constructing confidence intervals for the proportion of positive instances in the target domain. We leverage an approximated Bayes classifier for classification tasks, demonstrating DETM's robust performance in prediction. Through theoretical insights and practical applications, this study highlights DETM as a comprehensive framework for addressing the challenges of PU data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09735v2</guid>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siyan Liu, Chi-Kuang Yeh, Xin Zhang, Qinglong Tian, Pengfei Li</dc:creator>
    </item>
    <item>
      <title>Representation of Context-Specific Causal Models with Observational and Interventional Data</title>
      <link>https://arxiv.org/abs/2101.09271</link>
      <description>arXiv:2101.09271v4 Announce Type: replace-cross 
Abstract: We address the problem of representing context-specific causal models based on both observational and experimental data collected under general (e.g. hard or soft) interventions by introducing a new family of context-specific conditional independence models called CStrees. This family is defined via a novel factorization criterion that allows for a generalization of the factorization property defining general interventional DAG models. We derive a graphical characterization of model equivalence for observational CStrees that extends the Verma and Pearl criterion for DAGs. This characterization is then extended to CStree models under general, context-specific interventions. To obtain these results, we formalize a notion of context-specific intervention that can be incorporated into concise graphical representations of CStree models. We relate CStrees to other context-specific models, showing that the families of DAGs, CStrees, labeled DAGs and staged trees form a strict chain of inclusions. We end with an application of interventional CStree models to a real data set, revealing the context-specific nature of the data dependence structure and the soft, interventional perturbations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2101.09271v4</guid>
      <category>math.ST</category>
      <category>math.CO</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eliana Duarte, Liam Solus</dc:creator>
    </item>
    <item>
      <title>Spatiotemporal factor models for functional data with application to population map forecast</title>
      <link>https://arxiv.org/abs/2302.04412</link>
      <description>arXiv:2302.04412v3 Announce Type: replace-cross 
Abstract: The proliferation of mobile devices has led to the collection of large amounts of population data. This situation has prompted the need to utilize this rich, multidimensional data in practical applications. In response to this trend, we have integrated functional data analysis (FDA) and factor analysis to address the challenge of predicting hourly population changes across various districts in Tokyo. Specifically, by assuming a Gaussian process, we avoided the large covariance matrix parameters of the multivariate normal distribution. In addition, the data were both time and spatially dependent between districts. To capture these characteristics, a Bayesian factor model was introduced, which modeled the time series of a small number of common factors and expressed the spatial structure through factor loading matrices. Furthermore, the factor loading matrices were made identifiable and sparse to ensure the interpretability of the model. We also proposed a Bayesian shrinkage method as a systematic approach for factor selection. Through numerical experiments and data analysis, we investigated the predictive accuracy and interpretability of our proposed method. We concluded that the flexibility of the method allows for the incorporation of additional time series features, thereby improving its accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.04412v3</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tomoya Wakayama, Shonosuke Sugasawa</dc:creator>
    </item>
    <item>
      <title>A mixed effects cosinor modelling framework for circadian gene expression</title>
      <link>https://arxiv.org/abs/2405.01450</link>
      <description>arXiv:2405.01450v2 Announce Type: replace-cross 
Abstract: The cosinor model is frequently used to represent the oscillatory behavior of different genes over time. When data are collected from multiple individuals, the cosinor model is estimated with recorded gene expression levels and the 24 hour day-night cycle time at which gene expression levels are observed. However, the timing of many biological processes are based on individual-specific internal timing systems that are offset relative to day-night cycle time. When these individual-specific offsets are unknown, they pose a challenge in performing statistical analyses with a cosinor model. Specifically, when each individual participating in a study has a different offset, the parameter estimates of a population cosinor model obtained with day-night cycle time are attenuated. These attenuated parameter estimates also attenuate test statistics, which inflate type II error rates in identifying genes with oscillatory behavior. To address this attenuation bias, this paper proposes a method when data are collected in a longitudinal design. This method involves first estimating individual-specific and population cosinor models for each gene, and then translating the times at which an individual's gene expression levels are recorded based on the parameter estimates of these models. Simulation studies confirm that this method mitigates bias in estimation and inference. Illustrations with data from three circadian biology studies highlight that this method produces parameter estimates and test statistics akin to those obtained when each individual's offset is known.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01450v2</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael T. Gorczyca</dc:creator>
    </item>
    <item>
      <title>Determine the Number of States in Hidden Markov Models via Marginal Likelihood</title>
      <link>https://arxiv.org/abs/2405.12343</link>
      <description>arXiv:2405.12343v2 Announce Type: replace-cross 
Abstract: Hidden Markov models (HMM) have been widely used by scientists to model stochastic systems: the underlying process is a discrete Markov chain and the observations are noisy realizations of the underlying process. Determining the number of hidden states for an HMM is a model selection problem, which is yet to be satisfactorily solved, especially for the popular Gaussian HMM with heterogeneous covariance. In this paper, we propose a consistent method for determining the number of hidden states of HMM based on the marginal likelihood, which is obtained by integrating out both the parameters and hidden states. Moreover, we show that the model selection problem of HMM includes the order selection problem of finite mixture models as a special case. We give rigorous proof of the consistency of the proposed marginal likelihood method and provide an efficient computation method for practical implementation. We numerically compare the proposed method with the Bayesian information criterion (BIC), demonstrating the effectiveness of the proposed marginal likelihood method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12343v2</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yang Chen, Cheng-Der Fuh, Chu-Lan Michael Kao</dc:creator>
    </item>
  </channel>
</rss>
