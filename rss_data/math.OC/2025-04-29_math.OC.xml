<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 30 Apr 2025 01:48:32 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Optimization of Next-Day Delivery Coverage using Constraint Programming and Random Key Optimizers</title>
      <link>https://arxiv.org/abs/2504.18749</link>
      <description>arXiv:2504.18749v1 Announce Type: new 
Abstract: We consider the logistics network of an e-commerce retailer, specifically the so-called "middle mile" network, that routes inventory from supply warehouses to distribution stations to be ingested into the terminal ("last mile") delivery network. The speed of packages through this middle mile network is a key determinant for the ultimate delivery speed to the end user. An important target for a retailer is to maximize the fraction of user orders that can be serviced within one day, i.e., next-day delivery. As such, we formulate the maximization of expected next-day delivery coverage within the middle-mile network as an optimization problem, involving a set of temporal and capacity-based constraints on the network and requiring the use of a black-box model to evaluate the objective function. We design both exact constraint programming (CP) and heuristic random-key optimizer (RKO) approaches, the former of which uses a proxy objective function. We perform experiments on large-scale, real-world problem instances and show that both approaches have merit, in that they can match or outperform the baseline solution, a bespoke greedy solver with integrated local search, in expected next-day delivery coverage. Our experiments focus on two high-level problem definitions, starting with a base problem and then adding more complexity, and also explore the generalization of the solvers across a range of problem instance sizes. We find that a hybrid model using RKO and a bespoke local search protocol performs best on the full problem definition with respect to expected next-day delivery (increase of +50 basis points [bps] over baseline) but can take days to run, whereas the hybrid model using CP and local search is slightly less competitive (+20 bps) but takes only hours to run.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18749v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kyle Brubaker, Kyle E. C. Booth, Martin J. A. Schuetz, Philipp Loick, Jian Shen, Arun Ramamurthy, Georgios Paschos</dc:creator>
    </item>
    <item>
      <title>Anticipated backward stochastic evolution equations and maximum principle for path-dependent systems in infinite dimension</title>
      <link>https://arxiv.org/abs/2504.18798</link>
      <description>arXiv:2504.18798v1 Announce Type: new 
Abstract: For a class of path-dependent stochastic evolution equations driven by cylindrical $Q$-Wiener process, we study the Pontryagin's maximum principle for the stochastic recursive optimal control problem. In this infinite-dimensional control system, the state process depends on its past trajectory, the control is delayed via an integral with respect to a general finite measure, and the final cost relies on the delayed state. To obtain the maximum principle, we introduce a new type of non-anticipative path derivative and its dual operator, which allows us to derive an anticipated backward stochastic evolution equation as the adjoint equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18798v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guomin Liu, Jian Song, Meng Wang</dc:creator>
    </item>
    <item>
      <title>A reverse isoperimetric inequality for the Cheeger constant under width constraint</title>
      <link>https://arxiv.org/abs/2504.18848</link>
      <description>arXiv:2504.18848v1 Announce Type: new 
Abstract: Henrot and Lucardesi, in Commun. Contemp. Math. (2024), conjectured that among planar convex sets with prescribed minimal width, the equilateral triangle uniquely maximizes the Cheeger constant. In this short note, we confirm this conjecture. Moreover, we establish a stability result for the inequality in terms of the Hausdorff distance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18848v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ilias Ftouhi, Ilaria Lucardesi, Giorgio Saracco</dc:creator>
    </item>
    <item>
      <title>Asynchronous Push-sum Dual Gradient Algorithm in Distributed Model Predictive Control</title>
      <link>https://arxiv.org/abs/2504.18941</link>
      <description>arXiv:2504.18941v1 Announce Type: new 
Abstract: This paper studies the distributed model predictive control (DMPC) problem for distributed discrete-time linear systems with both local and global constraints over directed communication networks. We establish an optimization problem to formulate the DMPC policy, including the design of terminal ingredients. To cope with the global constraint, we transform the primal optimization problem into its dual problem. Then, we propose a novel asynchronous push-sum dual gradient (APDG) algorithm with an adaptive step-size scheme to solve this dual problem in a fully asynchronous distributed manner. The proposed algorithm does not require synchronous waiting and any form of coordination, which greatly improves solving efficiency. We theoretically prove that the APDG algorithm converges at an R-linear rate as long as the step-size does not exceed the designed upper bound. Furthermore, we develop a distributed termination criterion to terminate the APDG algorithm when its output solution satisfies the specified suboptimality and the global constraint, thereby avoiding an infinite number of iterations. The recursive feasibility and the stability of the closed-loop system are also established. Finally, a numerical example clarifies and validates theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18941v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pengbiao Wang, Xuemei Ren, Dongdong Zheng</dc:creator>
    </item>
    <item>
      <title>Inverse Problems Over Probability Measure Space</title>
      <link>https://arxiv.org/abs/2504.18999</link>
      <description>arXiv:2504.18999v1 Announce Type: new 
Abstract: Define a forward problem as $\rho_y = G_\#\rho_x$, where the probability distribution $\rho_x$ is mapped to another distribution $\rho_y$ using the forward operator $G$. In this work, we investigate the corresponding inverse problem: Given $\rho_y$, how to find $\rho_x$? Depending on whether $ G$ is overdetermined or underdetermined, the solution can have drastically different behavior. In the overdetermined case, we formulate a variational problem $\min_{\rho_x} D( G_\#\rho_x, \rho_y)$, and find that different choices of the metric $ D$ significantly affect the quality of the reconstruction. When $ D$ is set to be the Wasserstein distance, the reconstruction is the marginal distribution, while setting $ D$ to be a $\phi$-divergence reconstructs the conditional distribution. In the underdetermined case, we formulate the constrained optimization $\min_{\{ G_\#\rho_x=\rho_y\}} E[\rho_x]$. The choice of $ E$ also significantly impacts the construction: setting $ E$ to be the entropy gives us the piecewise constant reconstruction, while setting $ E$ to be the second moment, we recover the classical least-norm solution. We also examine the formulation with regularization: $\min_{\rho_x} D( G_\#\rho_x, \rho_y) + \alpha \mathsf R[\rho_x]$, and find that the entropy-entropy pair leads to a regularized solution that is defined in a piecewise manner, whereas the $W_2$-$W_2$ pair leads to a least-norm solution where $W_2$ is the 2-Wasserstein metric.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18999v1</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qin Li, Maria Oprea, Li Wang, Yunan Yang</dc:creator>
    </item>
    <item>
      <title>Setwise Coordinate Descent for Dual Asynchronous Decentralized Optimization</title>
      <link>https://arxiv.org/abs/2504.19004</link>
      <description>arXiv:2504.19004v1 Announce Type: new 
Abstract: In decentralized optimization over networks, synchronizing the updates of all nodes incurs significant communication overhead. For this reason, much of the recent literature has focused on the analysis and design of asynchronous optimization algorithms where nodes can activate anytime and contact a single neighbor to complete an iteration together. However, most works assume that the neighbor selection is done at random based on a fixed probability distribution (e.g., uniform), a choice that ignores the optimization landscape at the moment of activation. Instead, in this work we introduce an optimization-aware selection rule that chooses the neighbor providing the highest dual cost improvement (a quantity related to a dualization of the problem based on consensus). This scheme is related to the coordinate descent (CD) method with the Gauss-Southwell (GS) rule for coordinate updates; in our setting however, only a subset of coordinates is accessible at each iteration (because each node can communicate only with its neighbors), so the existing literature on GS methods does not apply. To overcome this difficulty, we develop a new analytical framework for smooth and strongly convex functions that covers our new class of setwise CD algorithms -- a class that applies to both decentralized and parallel distributed computing scenarios -- and we show that the proposed setwise GS rule can speed up the convergence in terms of iterations by a factor equal to the size of the largest coordinate set. We analyze extensions of these algorithms that exploit the knowledge of the smoothness constants when available and otherwise propose an algorithm to estimate these constants. Finally, we validate our theoretical results through extensive simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19004v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TAC.2025.3543463</arxiv:DOI>
      <dc:creator>Marina Costantini, Nikolaos Liakopoulos, Panayotis Mertikopoulos, Thrasyvoulos Spyropoulos</dc:creator>
    </item>
    <item>
      <title>Data-driven interdiction with asymmetric cost uncertainty: a distributionally robust optimization approach</title>
      <link>https://arxiv.org/abs/2504.19022</link>
      <description>arXiv:2504.19022v1 Announce Type: new 
Abstract: We consider a class of stochastic interdiction games between an upper-level decision-maker (referred to as a leader) and a lower-level decision-maker (referred to as a follower), where the follower's objective function coefficients are subject to uncertainty. More specifically, unlike traditional deterministic interdiction problem settings, the follower's profits (or costs) in our model comprise a random vector, whose probability distribution is estimated independently by the leader and the follower, based on their own data. In order to address the distributional uncertainty, we formulate a Wasserstein distributionally robust interdiction (DRI) problem, where both decision-makers attempt to hedge against the worst-case distributions and realizations of the follower's objective function coefficients. If the leader has full information about the follower's data, then the DRI problem with properly defined Wasserstein ambiguity sets and objective criteria is shown to admit a single-level mixed-integer linear programming (MILP) reformulation of polynomial size. In contrast, when the leader has incomplete or no information about the follower's data, we propose two distinct approaches for approximating the DRI problem. The first approach employs a pessimistic approximation, which turns out to be computationally challenging and requires the design of a specialized Benders decomposition algorithm. The second approach leverages a finite set of candidate data sets that satisfy prescribed interval constraints and addresses the resulting problem via a potentially large single-level MILP reformulation. Finally, for a class of randomly generated instances of the packing interdiction problem, we evaluate numerically how the information asymmetry and the decision-makers' risk preferences affect the model's out-of-sample performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19022v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sergey S. Ketkov, Oleg A. Prokopyev</dc:creator>
    </item>
    <item>
      <title>Snake locomotion learning search</title>
      <link>https://arxiv.org/abs/2504.19114</link>
      <description>arXiv:2504.19114v1 Announce Type: new 
Abstract: This research introduces a novel heuristic algorithm known as the Snake Locomotion Learning Search algorithm (SLLS) designed to address optimization problems. The SLLS draws inspiration from the locomotion patterns observed in snakes, particularly serpentine and caterpillar locomotion. We leverage these two modes of snake locomotion to devise two distinct search mechanisms within the SLLS. In our quest to mimic a snake's natural adaptation to its surroundings, we incorporate a learning efficiency component generated from the Sigmoid function. This helps strike a balance between exploration and exploitation capabilities throughout the SLLS computation process. The efficacy and effectiveness of this innovative algorithm are demonstrated through its application to 60 standard benchmark optimization problems and seven well-known engineering optimization problems. The performance analysis reveals that in most cases, the SLLS outperforms other algorithms, and even in the remaining scenarios, it exhibits robust performance. This conforms to the No Free Lunch Theorem, affirming that the SLLS stands as a valuable heuristic algorithm with significant potential for effectively addressing specific optimization challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19114v1</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sheng-Xue He</dc:creator>
    </item>
    <item>
      <title>Rotation excursion algorithm with learning</title>
      <link>https://arxiv.org/abs/2504.19117</link>
      <description>arXiv:2504.19117v1 Announce Type: new 
Abstract: We introduce a novel heuristic algorithm named the Rotation Excursion Algorithm with Learning (REAL) designed for general-purpose optimization. REAL draws inspiration from the construction mechanism inherent in CEC optimization suites, integrating three fundamental operations with a natural growth rule to address optimization tasks. The initial operation involves rotating the current feasible solutions within the search space to generate and evaluate new solutions. The excursion operation aims to relocate current feasible solutions closer to historically superior solutions stored in a list known as the "list of visible spots." The third operation involves perturbing solutions generated by the preceding operations within their respective neighborhoods. The rotation operation is geared toward comprehensive and random exploration of the entire search space, while the excursion operation exploits known information to refine current solutions. Perturbation operation functions as a form of neighborhood search to further enhance solution quality. The natural growth rule dynamically adjusts REAL's balance between exploration and exploitation throughout the entire search process. To validate the efficacy of the proposed algorithm, we apply it to address a diverse set of 67 problems, encompassing 29 benchmark optimization problems, 30 test problems from CEC 2014, one from CEC 2022, and seven engineering problems. Numerical experiments demonstrate the superior performance of REAL when compared to various other heuristics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19117v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sheng-Xue He</dc:creator>
    </item>
    <item>
      <title>Robust Nash equilibrium seeking based on semi-Markov switching topologies</title>
      <link>https://arxiv.org/abs/2504.19229</link>
      <description>arXiv:2504.19229v1 Announce Type: new 
Abstract: This paper investigates a distributed robust Nash Equilibrium (NE) seeking problem in fluctuating environments. Specifically, the players, subject to the second-order dynamics, are considered to be influenced by external disturbances and uncertain dynamics while communicating via semi-Markov switching topologies. In such constantly changing network circumstances, the existence of disturbances and uncertain dynamics may directly affect the performance of most existing NE seeking algorithms. Moreover, the semi-Markov switching topologies may cause communication uncertainty, which are considered in NE seeking for the first time. To accommodate the above concerns, the following targets require to be reached simultaneously: (1) Disturbances and uncertain dynamics rejection in finite time; (2) Distributed estimation on unknown information required for players' cost functions; (3) A reasonable estimation consensus protocol under semi-Markov switching; (4) NE seeking for the second-order players. By combining supertwisting-based Integral Sliding-Mode Control (ISMC) with average consensus tracking, a novel robust NE seeking algorithm is constructed, incorporating an effective leader-follower consensus protocol. Furthermore, to lessen dispensable information transmission, a sampled-data-based event-triggered mechanism is introduced. Incorporating the advantages of both semi-Markov switching and event-triggered mechanism, another NE seeking algorithm is proposed. Through designing an appropriate Lyapunov-Krasovskii functional, it is shown that the leader-follower consensus can be achieved in the mean-square sense under event-triggered mechanism. Finally, a connectivity control game is formulated to illustrate the validity of the designed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19229v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianing Chen, Sitian Qin, Chuangyin Dang</dc:creator>
    </item>
    <item>
      <title>Synthesis of Discrete-time Control Barrier Functions for Polynomial Systems Based on Sum-of-Squares Programming</title>
      <link>https://arxiv.org/abs/2504.19330</link>
      <description>arXiv:2504.19330v2 Announce Type: new 
Abstract: Discrete-time Control Barrier Functions (DTCBFs) are commonly utilized in the literature as a powerful tool for synthesizing control policies that guarantee safety of discrete-time dynamical systems. However, the systematic synthesis of DTCBFs in a computationally efficient way is at present an important open problem. This article first proposes a novel alternating-descent approach based on Sum-of-Squares programming to synthesize quadratic DTCBFs and corresponding polynomial control policies for discrete-time control-affine polynomial systems with input constraints and semi-algebraic safe sets. Subsequently, two distinct approaches are introduced to extend the proposed method to the synthesis of higher-degree polynomial DTCBFs. To demonstrate its efficacy, we apply the proposed method to numerical case studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19330v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Erfan Shakhesi, W. P. M. H. Heemels, Alexander Katriniok</dc:creator>
    </item>
    <item>
      <title>Geometry of efficient weight vectors</title>
      <link>https://arxiv.org/abs/2504.19400</link>
      <description>arXiv:2504.19400v1 Announce Type: new 
Abstract: Pairwise comparison matrices and the weight vectors obtained from them are important concepts in multi-criteria decision making. A weight vector corresponding to a pairwise comparison matrix is called Pareto efficient if the approximation of the matrix elements by the weight ratios cannot be improved for any element of the matrix without worsening it for an other element. The aim of this paper is to show the geometrical properties of the set of Pareto efficient weight vectors for $4\times 4$ pairwise comparison matrices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19400v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Krist\'of \'Abele-Nagy, S\'andor Boz\'oki, Zsombor Sz\'adoczki</dc:creator>
    </item>
    <item>
      <title>Constrained Parameter Update Law for Adaptive Control</title>
      <link>https://arxiv.org/abs/2504.19412</link>
      <description>arXiv:2504.19412v1 Announce Type: new 
Abstract: In this paper, a constrained parameter update law is derived in the context of adaptive control. The parameter update law is based on constrained optimization technique where a Lagrangian is formulated to incorporate the constraints on the parameters using inverse Barrier function. The constrained parameter update law is used to develop a adaptive tracking controller and the overall stability of the adaptive controller along with the constrained parameter update law is shown using Lyapunov analysis and development in stability of constrained primal-dual dynamics. The performance of the constrained parameter update law is tested in simulation for keeping the parameters within constraints and convergence to true parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19412v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ashwin P. Dani</dc:creator>
    </item>
    <item>
      <title>Sharp higher order convergence rates for the Adam optimizer</title>
      <link>https://arxiv.org/abs/2504.19426</link>
      <description>arXiv:2504.19426v1 Announce Type: new 
Abstract: Gradient descent based optimization methods are the methods of choice to train deep neural networks in machine learning. Beyond the standard gradient descent method, also suitable modified variants of standard gradient descent involving acceleration techniques such as the momentum method and/or adaptivity techniques such as the RMSprop method are frequently considered optimization methods. These days the most popular of such sophisticated optimization schemes is presumably the Adam optimizer that has been proposed in 2014 by Kingma and Ba. A highly relevant topic of research is to investigate the speed of convergence of such optimization methods. In particular, in 1964 Polyak showed that the standard gradient descent method converges in a neighborhood of a strict local minimizer with rate (x - 1)(x + 1)^{-1} while momentum achieves the (optimal) strictly faster convergence rate (\sqrt{x} - 1)(\sqrt{x} + 1)^{-1} where x \in (1,\infty) is the condition number (the ratio of the largest and the smallest eigenvalue) of the Hessian of the objective function at the local minimizer. It is the key contribution of this work to reveal that Adam also converges with the strictly faster convergence rate (\sqrt{x} - 1)(\sqrt{x} + 1)^{-1} while RMSprop only converges with the convergence rate (x - 1)(x + 1)^{-1}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19426v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Steffen Dereich, Arnulf Jentzen, Adrian Riekert</dc:creator>
    </item>
    <item>
      <title>Sliding motions on systems with non-Euclidean state spaces: A differential-geometric perspective</title>
      <link>https://arxiv.org/abs/2504.19504</link>
      <description>arXiv:2504.19504v1 Announce Type: new 
Abstract: This paper extends sliding-mode control theory to nonlinear systems evolving on smooth manifolds. Building on differential geometric methods, we reformulate Filippov's notion of solutions, characterize well-defined vector fields on quotient spaces, and provide a consistent geometric definition of higher-order sliding modes. We generalize the regular form to non-Euclidean settings and design explicit first- and second-order sliding-mode controllers that respect the manifold structure. Particular attention is given to the role of topological obstructions, which are illustrated through examples on the cylinder, M\"obius bundle, and 2-sphere. Our results highlight how geometric and topological properties fundamentally influence sliding dynamics and suggest new directions for robust control in nonlinear spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19504v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fernando Casta\~nos</dc:creator>
    </item>
    <item>
      <title>IPAS: An Adaptive Sample Size Method for Weighted Finite Sum Problems with Linear Equality Constraints</title>
      <link>https://arxiv.org/abs/2504.19629</link>
      <description>arXiv:2504.19629v1 Announce Type: new 
Abstract: Optimization problems with the objective function in the form of weighted sum and linear equality constraints are considered. Given that the number of local cost functions can be large as well as the number of constraints, a stochastic optimization method is proposed. The method belongs to the class of variable sample size first order methods, where the sample size is adaptive and governed by the additional sampling technique earlier proposed in unconstrained optimization framework. The resulting algorithm may be a mini-batch method, increasing sample size method, or even deterministic in a sense that it eventually reaches the full sample size, depending on the problem and similarity of the local cost functions. Regarding the constraints, the method uses controlled, but inexact projections on the feasible set, yielding possibly infeasible iterates. Almost sure convergence is proved under some standard assumptions for the stochastic framework, without imposing the convexity. Numerical results on relevant problems from CUTEst collection and real-world data sets for logistic regression show the stability and the efficiency of the proposed method when compared to the state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19629v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nata\v{s}a Kreji\'c, Nata\v{s}a Krklec Jerinki\'c, Sanja Rapaji\'c, Luka Rute\v{s}i\'c</dc:creator>
    </item>
    <item>
      <title>A Polynomial-Time Inner Approximation Algorithm for Multi-Objective Optimization</title>
      <link>https://arxiv.org/abs/2504.19677</link>
      <description>arXiv:2504.19677v1 Announce Type: new 
Abstract: In multi-objective optimization, the problem of finding all non-dominated images is often intractable. However, for any multiplicative factor greater than one, an approximation set can be constructed in polynomial time for many problems. In this paper, we use the concept of convex approximation sets: Each non-dominated image is approximated by a convex combination of images of solutions in such a set. Recently, Helfrich et al. (2024) presented a convex approximation algorithm that works in an adaptive fashion and outperforms all previously existing algorithms. We use a different approach for constructing an even more efficient adaptive algorithm for computing convex approximation sets. Our algorithm is based on the skeleton algorithm for polyhedral inner approximation by Csirmaz (2021). If the weighted sum scalarization can be solved exactly or approximately in polynomial time, our algorithm can find a convex approximation set for an approximation factor arbitrarily close to this solution quality. We demonstrate that our new algorithm significantly outperforms the current state-of-the-art algorithm from Helfrich et al. (2024) on instances of the multi-objective variants of the assignment problem, the knapsack problem, and the symmetric metric travelling salesman problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19677v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Levin Nemesch, Stefan Ruzika, Clemens Thielen, Alina Wittmann</dc:creator>
    </item>
    <item>
      <title>Optimal Virtual Power Plant Investment Planning via Time Series Aggregation with Bounded Error</title>
      <link>https://arxiv.org/abs/2504.19699</link>
      <description>arXiv:2504.19699v1 Announce Type: new 
Abstract: This study addresses the investment planning problem of a virtual power plant (VPP), formulated as a mixed-integer linear programming (MILP) model. As the number of binary variables increases and the investment time horizon extends, the problem can become computationally intractable. To mitigate this issue, time series aggregation (TSA) methods are commonly employed. However, since TSA typically results in a loss of accuracy, it is standard practice to derive bounds to control the associated error. Existing methods validate these bounds only in the linear case, and when applied to MILP models, they often yield heuristics that may even produce infeasible solutions. To bridge this gap, we propose an iterative TSA method for solving the VPP investment planning problem formulated as a MILP model, while ensuring a bounded error in the objective function. Our main theoretical contribution is to formally demonstrate that the derived bounds remain valid at each iteration. Notably, the proposed method consistently guarantees feasible solutions throughout the iterative process. Numerical results show that the proposed TSA method achieves superior computational efficiency compared to standard full-scale optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19699v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luca Santosuosso, Sonja Wogrin</dc:creator>
    </item>
    <item>
      <title>Commutation principles for optimization problems involving strictly Schur-convex functions in Euclidean Jordan algebras</title>
      <link>https://arxiv.org/abs/2504.19780</link>
      <description>arXiv:2504.19780v1 Announce Type: new 
Abstract: In this work we establish several commutation principles for optimizers of shifts of spectral functions in the context of Euclidean Jordan Algebras (EJAs). For instance, we show that under certain assumptions, if $\bar x$ is a (local) optimizer of $F(x-a)$ for $x\in\Omega$, where $\Omega\subset \mathcal V$ is a spectral set of an EJA $\mathcal V$, $a\in \mathcal V$ and $F:\mathcal V\rightarrow \mathbb R$ is a strictly Schur-convex spectral function, then $a$ and $\bar x$ operator commute. We make no further assumption on the smoothness of $F$; instead, we take advantage of the smoothness (Lie structure) of the Automorphism group of $\mathcal V$ and make use of majorization techniques for the eigenvalues of elements in EJAs. Our approach allows us to deal with several problems considered in the literature, related to strictly convex spectral functions and strictly convex spectral norms. In particular, we use our commutation principles to analyze the problem of minimizing the condition number in EJAs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19780v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pedro G. Massey, Noelia B. Rios, David Sossa</dc:creator>
    </item>
    <item>
      <title>Modified Control Barrier Function for Quadratic Program Based Control Design via Sum-of-Squares Programming</title>
      <link>https://arxiv.org/abs/2504.19796</link>
      <description>arXiv:2504.19796v1 Announce Type: new 
Abstract: We consider a nonlinear control affine system controlled by inputs generated by a quadratic program (QP) induced by a control barrier functions (CBF). Specifically, we slightly modify the condition satisfied by CBFs and study how the modification can positively impact the closed loop behavior of the system. We show that, QP-based controllers designed using the modified CBF condition preserves the desired properties of QP-based controllers using standard CBF conditions. Furthermore, using the generalized S-procedure for polynomial functions, we formulate the design of the modified CBFs as a Sum-Of-Squares (SOS) program, which can be solved efficiently. Via a numerical example, the proposed CBF design is shown to have superior performance over the standard CBF widely used in existing literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19796v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yankai Lin, Michelle S. Chong, Carlos Murguia</dc:creator>
    </item>
    <item>
      <title>Queue or lounge: strategic design for strategic customer</title>
      <link>https://arxiv.org/abs/2504.19889</link>
      <description>arXiv:2504.19889v1 Announce Type: new 
Abstract: Considering an M/M/1 queue with an additional lounge facility (LF), the quest of this paper is to understand the instances when LF is an attractive option, from customer perspective as well as from system perspective: will the customers choose to join the queue or prefer to detour briefly to lounge? In reality, customers do not perform complex computations for such tasks, but instead choose based on some heuristics. We further assume that the customers pessimistically anticipate the future congestion while making the choice. Our analysis reveals that the customers use the LF only when the queue is too crowded, and the lounge is relatively empty; however, strikingly, the customer choice is more inclined towards rejection for the LF in systems with higher traffic (load).
  We also explore an optimization problem where the system determines whether to implement an LF and what capacity it should have, while accounting for customers' behavioral responses. Under low load conditions, the system benefits from designing a high-capacity lounge, and the customers also prefer to use the LF actively. Surprisingly, neither the system prefers big LF, nor the customers prefer to use the LF profusely at high load conditions; optimal for either is to use the LF sparingly. Thus, importantly, the strategic system and the bounded-rational customers are not in a tug-of-war situation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19889v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Riya Sultana, Khushboo Agarwal, Veeraruna Kavitha</dc:creator>
    </item>
    <item>
      <title>Constructing Magic Squares: an integer linear programming model and a fast heuristic</title>
      <link>https://arxiv.org/abs/2504.20017</link>
      <description>arXiv:2504.20017v1 Announce Type: new 
Abstract: Magic squares are a fascinating mathematical challenge that has intrigued mathematicians for centuries. Given a positive (and possibly large) integer $n$, one of the main challenges that still remains is to find, within a reliable computational time, a magic square of order $n$, that is, a square matrix of order $n$ with unique integers from $a_{\min}$ to $a_{\max}$, such that the sum of each row, column, and diagonal equals a constant $ \mathcal{C}(A) $. In this work, we first present an Integer Linear Programming (ILP) model for constructing a magic square of order $n$, which is formulated as a feasibility problem. Nonetheless, the solution time of this ILP model grows exponentially as the order increases. To overcome this limitation, we also propose a heuristic that constructs magic squares depending on whether $n$ is odd, singly even, or doubly even. Our numerical results show that the proposed heuristic can construct magic squares of order up to $70000$ in less than $140$ seconds, demonstrating its efficiency and scalability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20017v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jo\~ao Vitor Pamplona, Maria Eduarda Pinheiro, Luiz-Rafael Santos</dc:creator>
    </item>
    <item>
      <title>Residual-Evasive Attacks on ADMM in Distributed Optimization</title>
      <link>https://arxiv.org/abs/2504.18570</link>
      <description>arXiv:2504.18570v1 Announce Type: cross 
Abstract: This paper presents two attack strategies designed to evade detection in ADMM-based systems by preventing significant changes to the residual during the attacked iteration. While many detection algorithms focus on identifying false data injection through residual changes, we show that our attacks remain undetected by keeping the residual largely unchanged. The first strategy uses a random starting point combined with Gram-Schmidt orthogonalization to ensure stealth, with potential for refinement by enhancing the orthogonal component to increase system disruption. The second strategy builds on the first, targeting financial gains by manipulating reactive power and pushing the system to its upper voltage limit, exploiting operational constraints. The effectiveness of the proposed attack-resilient mechanism is demonstrated through case studies on the IEEE 14-bus system. A comparison of the two strategies, along with commonly used naive attacks, reveals trade-offs between simplicity, detectability, and effectiveness, providing insights into ADMM system vulnerabilities. These findings underscore the need for more robust monitoring algorithms to protect against advanced attack strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18570v1</guid>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sabrina Bruckmeier, Huadong Mo, James Qin</dc:creator>
    </item>
    <item>
      <title>A multilevel approach to accelerate the training of Transformers</title>
      <link>https://arxiv.org/abs/2504.18590</link>
      <description>arXiv:2504.18590v1 Announce Type: cross 
Abstract: In this article, we investigate the potential of multilevel approaches to accelerate the training of transformer architectures. Using an ordinary differential equation (ODE) interpretation of these architectures, we propose an appropriate way of varying the discretization of these ODE Transformers in order to accelerate the training. We validate our approach experimentally by a comparison with the standard training procedure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18590v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillaume Lauga (OCKHAM), Ma\"el Chaumette (OCKHAM), Edgar Desainte-Mar\'eville (OCKHAM), \'Etienne Lasalle (OCKHAM), Arthur Lebeurrier (OCKHAM)</dc:creator>
    </item>
    <item>
      <title>Comparison for semi-continuous viscosity solutions for second order PDEs on the Wasserstein space</title>
      <link>https://arxiv.org/abs/2504.18697</link>
      <description>arXiv:2504.18697v1 Announce Type: cross 
Abstract: In this paper, we prove a comparison result for semi-continuous viscosity solutions of a class of second-order PDEs in the Wasserstein space. This allows us to remove the Lipschitz continuity assumption with respect to the Fourier-Wasserstein distance in AriX: 2309.05040 and obtain uniqueness by directly working in the Wasserstein space. In terms of its application, we characterize the value function of a stochastic control problem with partial observation as the unique viscosity solution to its corresponding HJB equation. Additionally, we present an application to a prediction problem under partial monitoring, where we establish an upper bound on the limit of regret using our comparison principle for degenerate dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18697v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erhan Bayraktar, Ibrahim Ekren, Xihao He, Xin Zhang</dc:creator>
    </item>
    <item>
      <title>Explicit neural network classifiers for non-separable data</title>
      <link>https://arxiv.org/abs/2504.18710</link>
      <description>arXiv:2504.18710v1 Announce Type: cross 
Abstract: We fully characterize a large class of feedforward neural networks in terms of truncation maps. As an application, we show how a ReLU neural network can implement a feature map which separates concentric data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18710v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patr\'icia Mu\~noz Ewald</dc:creator>
    </item>
    <item>
      <title>Minimum Cost Nowhere-zero Flows and Cut-balanced Orientations</title>
      <link>https://arxiv.org/abs/2504.18767</link>
      <description>arXiv:2504.18767v1 Announce Type: cross 
Abstract: Flows and colorings are disparate concepts in graph algorithms -- the former is tractable while the latter is intractable. Tutte introduced the concept of nowhere-zero flows to unify these two concepts. Jaeger showed that nowhere-zero flows are equivalent to cut-balanced orientations. Motivated by connections between nowhere-zero flows, cut-balanced orientations, Nash-Williams' well-balanced orientations, and postman problems, we study optimization versions of nowhere-zero flows and cut-balanced orientations. Given a bidirected graph with asymmetric costs on two orientations of each edge, we study the min cost nowhere-zero $k$-flow problem and min cost $k$-cut-balanced orientation problem. We show that both problems are NP-hard to approximate within any finite factor. Given the strong inapproximability result, we design bicriteria approximations for both problems: we obtain a $(6,6)$-approximation to the min cost nowhere-zero $k$-flow and a $(k,6)$-approximation to the min cost $k$-cut-balanced orientation. For the case of symmetric costs (where the costs of both orientations are the same for every edge), we show that the nowhere-zero $k$-flow problem remains NP-hard and admits a $3$-approximation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18767v1</guid>
      <category>cs.DS</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karthekeyan Chandrasekaran, Siyue Liu, R. Ravi</dc:creator>
    </item>
    <item>
      <title>Entropic continuity bounds for conditional covariances with applications to Schr\" odinger and Sinkhorn bridges</title>
      <link>https://arxiv.org/abs/2504.18822</link>
      <description>arXiv:2504.18822v1 Announce Type: cross 
Abstract: The article presents new entropic continuity bounds for conditional expectations and conditional covariance matrices.
  These bounds are expressed in terms of the relative entropy between different coupling distributions.
  Our approach combines Wasserstein coupling with quadratic transportation cost inequalities. We illustrate the impact of these results in the context of entropic optimal transport problems.
  The entropic continuity theorem presented in the article allows to estimate
  the conditional expectations and the conditional covariances of Schr\" odinger and Sinkhorn transitions in terms of the relative
  entropy between the corresponding bridges. These entropic continuity bounds turns out to be a very useful tool for obtaining remarkably simple proofs of the exponential decays of the gradient and the Hessian of Schr\"odinger and Sinkhorn bridge potentials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18822v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pierre Del Moral</dc:creator>
    </item>
    <item>
      <title>Numerical Representation of Preferences over Random Availability Functions</title>
      <link>https://arxiv.org/abs/2504.18863</link>
      <description>arXiv:2504.18863v1 Announce Type: cross 
Abstract: We interpret a fuzzy set as a random availability function and provide sufficient conditions under which a preference relation over the set of all random availability functions can be represented by a utility function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18863v1</guid>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Somdeb Lahiri</dc:creator>
    </item>
    <item>
      <title>Smooth Approximations of the Rounding Function</title>
      <link>https://arxiv.org/abs/2504.19026</link>
      <description>arXiv:2504.19026v1 Announce Type: cross 
Abstract: We propose novel smooth approximations to the classical rounding function, suitable for differentiable optimization and machine learning applications. Our constructions are based on two approaches: (1) localized sigmoid window functions centered at each integer, and (2) normalized weighted sums of sigmoid derivatives representing local densities. The first method approximates the step-like behavior of rounding through differences of shifted sigmoids, while the second method achieves smooth interpolation between integers via density-based weighting. Both methods converge pointwise to the classical rounding function as the sharpness parameter k tends to infinity, and allow controlled trade-offs between smoothness and approximation accuracy. We demonstrate that by restricting the summation to a small set of nearest integers, the computational cost remains low without sacrificing precision. These constructions provide fully differentiable alternatives to hard rounding, which are valuable in contexts where gradient-based methods are essential.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19026v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stanislav Semenov</dc:creator>
    </item>
    <item>
      <title>Optimal dividends for a NatCat insurer in the presence of a climate tipping point</title>
      <link>https://arxiv.org/abs/2504.19151</link>
      <description>arXiv:2504.19151v1 Announce Type: cross 
Abstract: We study optimal dividend strategies for an insurance company facing natural catastrophe claims, anticipating the arrival of a climate tipping point after which the claim intensity and/or the claim size distribution of the underlying risks deteriorates irreversibly. Extending earlier literature based on a shot-noise Cox process assumption for claim arrivals, we show that the non-stationary feature of such a tipping point can, in fact, be an advantage for shareholders seeking to maximize expected discounted dividends over the lifetime of the portfolio. Assuming the tipping point arrives according to an Erlang distribution, we demonstrate that the corresponding system of two-dimensional stochastic control problems admits a viscosity solution, which can be numerically approximated using a discretization of the current surplus and the claim intensity level. We also prove uniform convergence of this discrete solution to that of the original continuous problem. The results are illustrated through several numerical examples, and the sensitivity of the optimal dividend strategies to the presence of a climate tipping point is analyzed. In all these examples, it turns out that when the insurance premium is adjusted fairly at the moment of the tipping point, and all quantities are observable, the non-stationarity introduced by the tipping point can, in fact, represent an upward potential for shareholders.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19151v1</guid>
      <category>q-fin.RM</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hansjoerg Albrecher, Pablo Azcue, Nora Muler</dc:creator>
    </item>
    <item>
      <title>Convergence Properties of Natural Gradient Descent for Minimizing KL Divergence</title>
      <link>https://arxiv.org/abs/2504.19259</link>
      <description>arXiv:2504.19259v1 Announce Type: cross 
Abstract: The Kullback-Leibler (KL) divergence plays a central role in probabilistic machine learning, where it commonly serves as the canonical loss function. Optimization in such settings is often performed over the probability simplex, where the choice of parameterization significantly impacts convergence. In this work, we study the problem of minimizing the KL divergence and analyze the behavior of gradient-based optimization algorithms under two dual coordinate systems within the framework of information geometry$-$ the exponential family ($\theta$ coordinates) and the mixture family ($\eta$ coordinates). We compare Euclidean gradient descent (GD) in these coordinates with the coordinate-invariant natural gradient descent (NGD), where the natural gradient is a Riemannian gradient that incorporates the intrinsic geometry of the parameter space. In continuous time, we prove that the convergence rates of GD in the $\theta$ and $\eta$ coordinates provide lower and upper bounds, respectively, on the convergence rate of NGD. Moreover, under affine reparameterizations of the dual coordinates, the convergence rates of GD in $\eta$ and $\theta$ coordinates can be scaled to $2c$ and $\frac{2}{c}$, respectively, for any $c&gt;0$, while NGD maintains a fixed convergence rate of $2$, remaining invariant to such transformations and sandwiched between them. Although this suggests that NGD may not exhibit uniformly superior convergence in continuous time, we demonstrate that its advantages become pronounced in discrete time, where it achieves faster convergence and greater robustness to noise, outperforming GD. Our analysis hinges on bounding the spectrum and condition number of the Hessian of the KL divergence at the optimum, which coincides with the Fisher information matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19259v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adwait Datar, Nihat Ay</dc:creator>
    </item>
    <item>
      <title>$O(1/k)$ Finite-Time Bound for Non-Linear Two-Time-Scale Stochastic Approximation</title>
      <link>https://arxiv.org/abs/2504.19375</link>
      <description>arXiv:2504.19375v1 Announce Type: cross 
Abstract: Two-time-scale stochastic approximation is an algorithm with coupled iterations which has found broad applications in reinforcement learning, optimization and game control. While several prior works have obtained a mean square error bound of $O(1/k)$ for linear two-time-scale iterations, the best known bound in the non-linear contractive setting has been $O(1/k^{2/3})$. In this work, we obtain an improved bound of $O(1/k)$ for non-linear two-time-scale stochastic approximation. Our result applies to algorithms such as gradient descent-ascent and two-time-scale Lagrangian optimization. The key step in our analysis involves rewriting the original iteration in terms of an averaged noise sequence which decays sufficiently fast. Additionally, we use an induction-based approach to show that the iterates are bounded in expectation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19375v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siddharth Chandak</dc:creator>
    </item>
    <item>
      <title>Negative Imaginary Neural ODEs: Learning to Control Mechanical Systems with Stability Guarantees</title>
      <link>https://arxiv.org/abs/2504.19497</link>
      <description>arXiv:2504.19497v1 Announce Type: cross 
Abstract: We propose a neural control method to provide guaranteed stabilization for mechanical systems using a novel negative imaginary neural ordinary differential equation (NINODE) controller. Specifically, we employ neural networks with desired properties as state-space function matrices within a Hamiltonian framework to ensure the system possesses the NI property. This NINODE system can serve as a controller that asymptotically stabilizes an NI plant under certain conditions. For mechanical plants with colocated force actuators and position sensors, we demonstrate that all the conditions required for stability can be translated into regularity constraints on the neural networks used in the controller. We illustrate the utility, effectiveness, and stability guarantees of the NINODE controller through an example involving a nonlinear mass-spring system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19497v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kanghong Shi, Ruigang Wang, Ian R. Manchester</dc:creator>
    </item>
    <item>
      <title>Approximation of an optimal control problem on a network with a perturbed problem in the whole space</title>
      <link>https://arxiv.org/abs/2504.19554</link>
      <description>arXiv:2504.19554v1 Announce Type: cross 
Abstract: A classical optimal control problem posed in the whole space R^2 is perturbed by a singular term of magnitude $\epsilon$^{-1} aimed at driving the trajectories to a prescribed network $\Gamma$. We are interested in the link between the limit problem, as $\epsilon$ $\rightarrow$ 0, and some optimal control problems on networks studied in the literature. We prove that the sequence of trajectories admits a subsequential limit evolving on $\Gamma$. Moreover, in the case of the Eikonal equation, we show that the sequence of value functions associated with the perturbed optimal control problems converges to a limit which, in particular, coincides with the value function of the expected optimal control problem set on the network $\Gamma$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19554v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohamed Camar-Eddine (IRMAR), M\'eriadec Chuberre (IRMAR), Mounir Haddou (IRMAR), Olivier Ley (IRMAR)</dc:creator>
    </item>
    <item>
      <title>The frequency $K_i$s for symmetrical traveling salesman problem</title>
      <link>https://arxiv.org/abs/2504.19608</link>
      <description>arXiv:2504.19608v1 Announce Type: cross 
Abstract: The frequency $K_i$s ($i\in[4,n]$) are studied for symmetrical traveling salesman problem ($TSP$) to identify the edges in optimal Hamiltonian cycle ($OHC$). A frequency $K_i$ is computed with a sort of ${{i}\choose{2}}$ optimal $i$-vertex paths with given endpoints (optimal $i$-vertex path) in a corresponding $K_i$ in $K_n$. In frequency $K_i$, the frequency of an edge is the number of the optimal $i$-vertex paths containing the edge in the corresponding $K_i$. Given an $OHC$ edge related to $K_i$, it has a frequency bigger than $\frac{1}{2}{{i}\choose{2}}$ in the corresponding frequency $K_i$, and that of an ordinary edge not in $OHC$ is smaller than $\frac{i+2}{2}$. On average, an $OHC$ edge in $K_i$ has a frequency bigger than $\frac{i^2-4i+7}{2}$ whereas an ordinary edge has a frequency smaller than 2. Moreover, given a frequency $K_i$ containing an $OHC$ edge related to $K_n$, the frequency of the $OHC$ edge is bigger than $\frac{1}{2}{{i}\choose{2}}$ in the worst average case. It implies that the average frequency of an $OHC$ edge computed with frequency $K_i$s is bigger than $\frac{1}{2}{{i}\choose{2}}$. It also found that the probability that an $OHC$ edge is contained in optimal $i$-vertex paths keeps stable or increases according to $i\in [4, n]$. As the frequency $K_i$s are used to compute the frequency of an edge, each $OHC$ edge has its own peak frequency at $i=P_0$ where $P_0=\frac{n}{2} + 2$ for even $n$ or $\frac{n+1}{2} + 1$ for odd $n$. For ordinary edges out of $OHC$, the probability that they are contained in optimal $i$-vertex paths decreases according to $i$. Moreover, the average frequency of an ordinary edge will be smaller than $\frac{1}{2}{{i}\choose{2}}$ if $i \geq [0.3660n + 1.5849]$. Based on these findings, an algorithm is presented to find $OHC$ in $O(n^62^{0.3660n})$ time using dynamic programming.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19608v1</guid>
      <category>cs.DM</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yong Wang</dc:creator>
    </item>
    <item>
      <title>Diffusion Stochastic Learning Over Adaptive Competing Networks</title>
      <link>https://arxiv.org/abs/2504.19635</link>
      <description>arXiv:2504.19635v1 Announce Type: cross 
Abstract: This paper studies a stochastic dynamic game between two competing teams, each consisting of a network of collaborating agents. Unlike fully cooperative settings, where all agents share a common objective, each team in this game aims to minimize its own distinct objective. In the adversarial setting, their objectives could be conflicting as in zero-sum games. Throughout the competition, agents share strategic information within their own team while simultaneously inferring and adapting to the strategies of the opposing team. We propose diffusion learning algorithms to address two important classes of this network game: i) a zero-sum game characterized by weak cross-team subgraph interactions, and ii) a general non-zero-sum game exhibiting strong cross-team subgraph interactions. We analyze the stability performance of the proposed algorithms under reasonable assumptions and illustrate the theoretical results through experiments on Cournot team competition and decentralized GAN training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19635v1</guid>
      <category>cs.MA</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yike Zhao, Haoyuan Cai, Ali H. Sayed</dc:creator>
    </item>
    <item>
      <title>Automated decision-making for dynamic task assignment at scale</title>
      <link>https://arxiv.org/abs/2504.19933</link>
      <description>arXiv:2504.19933v1 Announce Type: cross 
Abstract: The Dynamic Task Assignment Problem (DTAP) concerns matching resources to tasks in real time while minimizing some objectives, like resource costs or task cycle time. In this work, we consider a DTAP variant where every task is a case composed of a stochastic sequence of activities. The DTAP, in this case, involves the decision of which employee to assign to which activity to process requests as quickly as possible. In recent years, Deep Reinforcement Learning (DRL) has emerged as a promising tool for tackling this DTAP variant, but most research is limited to solving small-scale, synthetic problems, neglecting the challenges posed by real-world use cases. To bridge this gap, this work proposes a DRL-based Decision Support System (DSS) for real-world scale DTAPS. To this end, we introduce a DRL agent with two novel elements: a graph structure for observations and actions that can effectively represent any DTAP and a reward function that is provably equivalent to the objective of minimizing the average cycle time of tasks. The combination of these two novelties allows the agent to learn effective and generalizable assignment policies for real-world scale DTAPs. The proposed DSS is evaluated on five DTAP instances whose parameters are extracted from real-world logs through process mining. The experimental evaluation shows how the proposed DRL agent matches or outperforms the best baseline in all DTAP instances and generalizes on different time horizons and across instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19933v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Riccardo Lo Bianco, Willem van Jaarsveld, Jeroen Middelhuis, Luca Begnardi, Remco Dijkman</dc:creator>
    </item>
    <item>
      <title>SONC Optimization and Exact Nonnegativity Certificates via Second-Order Cone Programming</title>
      <link>https://arxiv.org/abs/2012.07903</link>
      <description>arXiv:2012.07903v4 Announce Type: replace 
Abstract: The second-order cone (SOC) is a class of simple convex cones and optimizing over them can be done more efficiently than with semidefinite programming. It is interesting both in theory and in practice to investigate which convex cones admit a representation using SOCs, given that they have a strong expressive ability. In this paper, we prove constructively that the cone of sums of nonnegative circuits (SONC) admits a SOC representation. Based on this, we give a new algorithm for unconstrained polynomial optimization via SOC programming. We also provide a hybrid numeric-symbolic scheme which combines the numerical procedure with a rounding-projection algorithm to obtain exact nonnegativity certificates. Numerical experiments demonstrate the efficiency of our algorithm for polynomials with fairly large degree and number of variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2012.07903v4</guid>
      <category>math.OC</category>
      <category>cs.SC</category>
      <category>math.AG</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Victor Magron, Jie Wang</dc:creator>
    </item>
    <item>
      <title>Characterizing Trust and Resilience in Distributed Consensus for Cyberphysical Systems</title>
      <link>https://arxiv.org/abs/2103.05464</link>
      <description>arXiv:2103.05464v2 Announce Type: replace 
Abstract: This work considers the problem of resilient consensus where stochastic values of trust between agents are available. Specifically, we derive a unified mathematical framework to characterize convergence, deviation of the consensus from the true consensus value, and expected convergence rate, when there exists additional information of trust between agents. We show that under certain conditions on the stochastic trust values and consensus protocol: 1) almost sure convergence to a common limit value is possible even when malicious agents constitute more than half of the network connectivity, 2) the deviation of the converged limit, from the case where there is no attack, i.e., the true consensus value, can be bounded with probability that approaches 1 exponentially, and 3) correct classification of malicious and legitimate agents can be attained in finite time almost surely. Further, the expected convergence rate decays exponentially as a function of the quality of the trust observations between agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2103.05464v2</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michal Yemini, Angelia Nedi\'c, Andrea Goldsmith, Stephanie Gil</dc:creator>
    </item>
    <item>
      <title>Exploiting Sparsity in Complex Polynomial Optimization</title>
      <link>https://arxiv.org/abs/2103.12444</link>
      <description>arXiv:2103.12444v2 Announce Type: replace 
Abstract: In this paper, we study the sparsity-adapted complex moment-Hermitian sum of squares (moment-HSOS) hierarchy for complex polynomial optimization problems, where the sparsity includes correlative sparsity and term sparsity. We compare the strengths of the sparsity-adapted complex moment-HSOS hierarchy with the sparsity-adapted real moment-SOS hierarchy on either randomly generated complex polynomial optimization problems or the AC optimal power flow problem. The results of numerical experiments show that the sparsity-adapted complex moment-HSOS hierarchy provides a trade-off between the computational cost and the quality of obtained bounds for large-scale complex polynomial optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2103.12444v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jie Wang, Victor Magron</dc:creator>
    </item>
    <item>
      <title>Dual dynamic programming for stochastic programs over an infinite horizon</title>
      <link>https://arxiv.org/abs/2303.02024</link>
      <description>arXiv:2303.02024v3 Announce Type: replace 
Abstract: We consider solving stochastic programs over an infinite horizon. By leveraging the stationarity of problem, we develop a novel continually-exploring infinite-horizon explorative dual dynamic programming (CE-Inf-EDDP) algorithm that matches state-of-the-art complexity while providing encouraging numerical performance on the newsvendor and hydrothermal planning problem. CE-Inf-EDDP conceptually differs from previous dual dynamic programming approaches by exploring the feasible region longer and updating the cutting-plane model more frequently. In addition, our algorithm can handle both simple linear to more complex nonlinear costs. To demonstrate this, we extend our algorithm to handle the so-called hierarchical stationary stochastic program, where the cost function is a parametric multi-stage stochastic program. The hierarchical program can model problems with a hierarchy of decision-making, e.g., how long-term decisions influence day-to-day operations. As a concrete example, we introduce a newsvendor problem that includes a second-stage multi-product assembly serving as a secondary market.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.02024v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Caleb Ju, Guanghui Lan</dc:creator>
    </item>
    <item>
      <title>A Strong Duality Result for Constrained POMDPs with Multiple Cooperative Agents</title>
      <link>https://arxiv.org/abs/2303.14932</link>
      <description>arXiv:2303.14932v2 Announce Type: replace 
Abstract: The work studies the problem of decentralized constrained POMDPs in a team-setting where multiple nonstrategic agents have asymmetric information. Using an extension of Sion's Minimax theorem for functions with positive infinity and results on weak-convergence of measures, strong duality is established for the setting of infinite-horizon expected total discounted costs when the observations lie in a countable space, the actions are chosen from a finite space, the constraint costs are bounded, and the objective cost is bounded from below.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.14932v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/CDC49753.2023.10383989</arxiv:DOI>
      <dc:creator>Nouman Khan, Vijay Subramanian</dc:creator>
    </item>
    <item>
      <title>Robust Time-inconsistent Linear-Quadratic Stochastic Controls: A Stochastic Differential Game Approach</title>
      <link>https://arxiv.org/abs/2306.16982</link>
      <description>arXiv:2306.16982v3 Announce Type: replace 
Abstract: This paper studies robust time-inconsistent (TIC) linear-quadratic stochastic control problems, formulated by stochastic differential games. By a spike variation approach, we derive sufficient conditions for achieving the Nash equilibrium, which corresponds to a time-consistent (TC) robust policy, under mild technical assumptions. To illustrate our framework, we consider two scenarios of robust mean-variance analysis, namely with state- and control-dependent ambiguity aversion. We find numerically that with time inconsistency haunting the dynamic optimal controls, the ambiguity aversion enhances the effective risk aversion faster than the linear, implying that the ambiguity in the TIC cases is more impactful than that under the TC counterparts, e.g., expected utility maximization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.16982v3</guid>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bingyan Han, Chi Seng Pun, Hoi Ying Wong</dc:creator>
    </item>
    <item>
      <title>Parallel Model Predictive Control for Deterministic Systems</title>
      <link>https://arxiv.org/abs/2309.14560</link>
      <description>arXiv:2309.14560v3 Announce Type: replace 
Abstract: In this note, we consider infinite horizon optimal control problems with deterministic systems. Since exact solutions to these problems are often intractable, we propose a parallel model predictive control (MPC) method that provides an approximate solution. Our method computes multiple lookahead minimization problems at each time, where each minimization may involve a different number of lookahead steps, and terminal cost and constraint. The policy computed via parallel MPC applies the first control of the lookahead minimization with the lowest cost. We show that the proposed method can harnesses the power of multiple computing units. Moreover, we prove that the policy computed via parallel MPC has better performance guarantee than that computed via the single lookahead minimization involved in parallel MPC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.14560v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuchao Li, Aren Karapetyan, Niklas Schmid, John Lygeros, Karl H. Johansson, Jonas M{\aa}rtensson</dc:creator>
    </item>
    <item>
      <title>Minimal and maximal solution maps of elliptic QVIs of obstacle type: Lipschitz stability, differentiability and optimal control</title>
      <link>https://arxiv.org/abs/2312.13879</link>
      <description>arXiv:2312.13879v2 Announce Type: replace 
Abstract: Quasi-variational inequalities (QVIs) of obstacle type in many cases have multiple solutions that can be ordered. We study a multitude of properties of the operator mapping the source term to the minimal or maximal solution of such QVIs. We prove that the solution maps are locally Lipschitz continuous and directionally differentiable and show existence of optimal controls for problems that incorporate these maps as the control-to-state operator. We also consider a Moreau--Yosida-type penalisation for the QVI wherein we show that it is possible to approximate the minimal and maximal solutions by sequences of minimal and maximal solutions (respectively) of certain PDEs, which have a simpler structure and offer a convenient characterisation in particular for computation. For solution mappings of these penalised problems, we prove a number of properties including Lipschitz and differential stability. Making use of the penalised equations, we derive (in the limit) C-stationarity conditions for the control problem, in addition to the Bouligand stationarity we get from the differentiability result.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.13879v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amal Alphonse, Michael Hinterm\"uller, Carlos N. Rautenberg, Gerd Wachsmuth</dc:creator>
    </item>
    <item>
      <title>On the $O(\frac{\sqrt{d}}{T^{1/4}})$ Convergence Rate of RMSProp and Its Momentum Extension Measured by $\ell_1$ Norm</title>
      <link>https://arxiv.org/abs/2402.00389</link>
      <description>arXiv:2402.00389v5 Announce Type: replace 
Abstract: Although adaptive gradient methods have been extensively used in deep learning, their convergence rates proved in the literature are all slower than that of SGD, particularly with respect to their dependence on the dimension. This paper considers the classical RMSProp and its momentum extension and establishes the convergence rate of $\frac{1}{T}\sum_{k=1}^T E\left[\|\nabla f(x^k)\|_1\right]\leq O(\frac{\sqrt{d}C}{T^{1/4}})$ measured by $\ell_1$ norm without the bounded gradient assumption, where $d$ is the dimension of the optimization variable, $T$ is the iteration number, and $C$ is a constant identical to that appeared in the optimal convergence rate of SGD. Our convergence rate matches the lower bound with respect to all the coefficients except the dimension $d$. Since $\|x\|_2\ll\|x\|_1\leq\sqrt{d}\|x\|_2$ for problems with extremely large $d$, our convergence rate can be considered to be analogous to the $\frac{1}{T}\sum_{k=1}^T E\left[\|\nabla f(x^k)\|_2\right]\leq O(\frac{C}{T^{1/4}})$ rate of SGD in the ideal case of $\|\nabla f(x)\|_1=\varTheta(\sqrt{d}\|\nabla f(x)\|_2)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.00389v5</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Huan Li, Yiming Dong, Zhouchen Lin</dc:creator>
    </item>
    <item>
      <title>Tikhonov regularization of monotone operator flows not only ensures strong convergence of the trajectories but also speeds up the vanishing of the residuals</title>
      <link>https://arxiv.org/abs/2406.00852</link>
      <description>arXiv:2406.00852v4 Announce Type: replace 
Abstract: In the framework of real Hilbert spaces, we investigate first-order dynamical systems governed by monotone and continuous operators. We demonstrate that when the monotone operator flow is augmented with a Tikhonov regularization term, the resulting trajectory converges strongly to the element of the set of zeros with minimal norm. In addition, rates of convergence in norm for the trajectory's velocity and the operator along the trajectory can be derived in terms of the regularization function. In some particular cases, these rates of convergence can outperform the ones of the coercive operator flows and can be as fast as $O(\frac{1}{t})$ as $t \rightarrow +\infty$. In this way, we emphasize a surprising acceleration feature of the Tikhonov regularization. Additionally, we explore these properties for monotone operator flows that incorporate time rescaling and an anchor point and show that they are closely linked to second-order dynamics with a vanishing damping term. The convergence and convergence rate results we achieve for these systems complement recent findings for the Fast Optimistic Gradient Descent Ascent (OGDA) dynamics.
  When the monotone operator is defined as the identity minus a nonexpansive operator, the monotone equations transform into a fixed point problem. In such cases, explicitly discretizing the system with Tikhonov regularization, enhanced by an anchor point, leads to the Halpern fixed point iteration. We identify two regimes for the regularization sequence which ensure that the generated sequence of iterates converges strongly to the fixed point nearest to the anchor point. Furthermore, we establish a general theoretical framework that provides convergence rates for the vanishing of the discrete velocity and the fixed point residual. For certain regularization sequences, we derive specific convergence rates that align with those observed in continuous time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00852v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Radu Ioan Bot, Dang-Khoa Nguyen</dc:creator>
    </item>
    <item>
      <title>Benamou-Brenier Formulation of Optimal Transport for Nonlinear Control Systems on Rd</title>
      <link>https://arxiv.org/abs/2407.16088</link>
      <description>arXiv:2407.16088v3 Announce Type: replace 
Abstract: In this paper we consider the Benamou-Brenier formulation of optimal transport for nonlinear control affine systems on $\Rd$, removing the compactness assumption of the underlying manifold in previous work by the author. By using Bernard's Young measure based weak formulation of optimal transport, the results are established for cases not covered by previous treatments using the Monge problem. Particularly, no assumptions are made on the non-existence of singular minimizing controls or the cost function being Lipschitz. Therefore, the existence of solutions to dynamical formulation is established for general Sub-Riemmanian energy costs not covered by literature previously.
  The results also establish controllability of the continuity equation whenever the corresponding Kantorovich problem admits a feasible solution, leveraging the equivalence between the Kantorovich and Benamou-Brenier formulations. Furthermore, when the cost function does not admit singular minimizing curves, we demonstrate that the Benamou-Brenier problem is equivalent to its convexified formulation in momentum and measure coordinates. In this regular setting, we further show that the constructed transport solutions possess sufficient regularity: for the feedback control laws that achieve transport, the associated continuity equation admits a unique weak solution. These findings apply in particular to linear-quadratic costs for controllable linear time-invariant (LTI) systems, as well as to certain classes of driftless nonlinear systems. Thus, in these cases, controllability of the continuity equation is achieved with control laws regular enough to guarantee uniqueness of solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16088v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karthik Elamvazhuthi</dc:creator>
    </item>
    <item>
      <title>Zeroth-order Stochastic Cubic Newton Method Revisited</title>
      <link>https://arxiv.org/abs/2410.22357</link>
      <description>arXiv:2410.22357v3 Announce Type: replace 
Abstract: This paper studies stochastic minimization of a finite-sum loss $ F (\mathbf{x}) = \frac{1}{N} \sum_{\xi=1}^N f(\mathbf{x};\xi) $. In many real-world scenarios, the Hessian matrix of such objectives exhibits a low-rank structure on a batch of data. At the same time, zeroth-order optimization has gained prominence in important applications such as fine-tuning large language models. Drawing on these observations, we propose a novel stochastic zeroth-order cubic Newton method that leverages the low-rank Hessian structure via a matrix recovery-based estimation technique. Our method circumvents restrictive incoherence assumptions, enabling accurate Hessian approximation through finite-difference queries. Theoretically, we establish that for most real-world problems in $\mathbb{R}^n$, $\mathcal{O}\left(\frac{n}{\eta^{\frac{7}{2}}}\right)+\widetilde{\mathcal{O}}\left(\frac{n^2 }{\eta^{\frac{5}{2}}}\right)$ function evaluations suffice to attain a second-order $\eta$-stationary point with high probability. This represents a significant improvement in dimensional dependence over existing methods. This improvement is mostly due to a new Hessian estimator that achieves superior sample complexity; This new Hessian estimation method might be of separate interest. Numerical experiments on matrix recovery and machine learning tasks validate the efficacy and scalability of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22357v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Liu, Weibin Peng, Tianyu Wang, Jiajia Yu</dc:creator>
    </item>
    <item>
      <title>Linear Supervision for Nonlinear, High-Dimensional Neural Control and Differential Games</title>
      <link>https://arxiv.org/abs/2412.02033</link>
      <description>arXiv:2412.02033v3 Announce Type: replace 
Abstract: As the dimension of a system increases, traditional methods for control and differential games rapidly become intractable, making the design of safe autonomous agents challenging in complex or team settings. Deep-learning approaches avoid discretization and yield numerous successes in robotics and autonomy, but at a higher dimensional limit, accuracy falls as sampling becomes less efficient. We propose using rapidly generated linear solutions to the partial differential equation (PDE) arising in the problem to accelerate and improve learned value functions for guidance in high-dimensional, nonlinear problems. We define two programs that combine supervision of the linear solution with a standard PDE loss. We demonstrate that these programs offer improvements in speed and accuracy in both a 50-D differential game problem and a 10-D quadrotor control problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02033v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>William Sharpless, Zeyuan Feng, Somil Bansal, Sylvia Herbert</dc:creator>
    </item>
    <item>
      <title>Stochastic LQR Design With Disturbance Preview</title>
      <link>https://arxiv.org/abs/2412.06662</link>
      <description>arXiv:2412.06662v3 Announce Type: replace 
Abstract: This paper considers the discrete-time, stochastic LQR problem with $p$ steps of disturbance preview information where $p$ is finite. We first derive the solution for this problem on a finite horizon with linear, time-varying dynamics and time-varying costs. Next, we derive the solution on the infinite horizon with linear, time-invariant dynamics and time-invariant costs. Our proofs rely on the well-known principle of optimality. We provide an independent proof for the principle of optimality that relies only on nested information structure. Finally, we show that the finite preview controller converges to the optimal noncausal controller as the preview horizon $p$ tends to infinity. We also provide a simple example to illustrate both the finite and infinite horizon results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06662v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jietian Liu, Laurent Lessard, Peter Seiler</dc:creator>
    </item>
    <item>
      <title>A linear-quadratic partially observed Stackelberg stochastic differential game with multiple followers and its application to multi-agent formation control</title>
      <link>https://arxiv.org/abs/2412.07159</link>
      <description>arXiv:2412.07159v2 Announce Type: replace 
Abstract: In this paper, we study a linear-quadratic partially observed Stackelberg stochastic differential game problem in which a single leader and multiple followers are involved. We consider more practical formulation for partial information that none of them can observed the complete information and the followers know more than the leader. Some completely different methods including orthogonal decomposition are applied to overcome the difficulties caused by partially observability which improves the tools and relaxes the constraint condition imposed on admissible control in the existing literature. More precisely, the followers encounter the standard linear-quadratic partially observed optimal control problems, however, a kind of forward-backward indefinite linear-quadratic partially observed optimal control problem is considered by the leader. Instead of maximum principle of forward-backward control systems, inspired by the existing work related to definite case and classical forward control system, some distinct forward-backward linear-quadratic decoupling techniques including the method of completion of squares are applied to solve the leader's problem. More interestingly, we develop the deterministic formation control in multi-agent system with a framework of Stackelberg differential game and extend it to the stochastic case. The optimal strategies are obtained by our theoretical result suitably.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.07159v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yichun Li, Yaozhong Hu, Jingtao Shi, Yueyang Zheng</dc:creator>
    </item>
    <item>
      <title>Complex extension of optical flow and its practical evaluation for undersampled dynamic MRI</title>
      <link>https://arxiv.org/abs/2412.12711</link>
      <description>arXiv:2412.12711v2 Announce Type: replace 
Abstract: Reconstructing high-quality images from undersampled dynamic MRI data is a challenging task and important for the success of this imaging modality. To remedy the naturally occurring artifacts due to measurement undersampling, one can incorporate a motion model into the reconstruction so that information can propagate across time frames. Current models for MRI imaging are using the optical flow equation. However, they are based on real-valued images. Here, we generalise the optical flow equation to complex-valued images and demonstrate, based on two real cardiac MRI datasets, that the new model is capable of improving image quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12711v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.3934/ammc.2025005</arxiv:DOI>
      <dc:creator>Matthias J. Ehrhardt, Marco Mauritz</dc:creator>
    </item>
    <item>
      <title>Optimal Preconditioning for Online Quadratic Cone Programming</title>
      <link>https://arxiv.org/abs/2501.14191</link>
      <description>arXiv:2501.14191v2 Announce Type: replace 
Abstract: First-order conic optimization solvers are sensitive to problem conditioning and typically perform poorly in the face of ill-conditioned problem data. To mitigate this, we propose an approach to preconditioning--the hypersphere preconditioner--for a class of quadratic cone programs (QCPs), i.e., conic optimization problems with a quadratic objective function, wherein the objective function is strongly convex and possesses a certain structure. This approach lends itself to factorization-free, customizable, first-order conic optimization for online applications wherein the solver is called repeatedly to solve problems of the same size/structure, but with changing problem data. We demonstrate the efficacy of our approach on numerical convex and nonconvex trajectory optimization examples, using a first-order conic optimizer under the hood.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14191v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Abhinav G. Kamath, Purnanand Elango, Beh\c{c}et A\c{c}{\i}kme\c{s}e</dc:creator>
    </item>
    <item>
      <title>On the Surprising Robustness of Sequential Convex Optimization for Contact-Implicit Motion Planning</title>
      <link>https://arxiv.org/abs/2502.01055</link>
      <description>arXiv:2502.01055v3 Announce Type: replace 
Abstract: Contact-implicit motion planning-embedding contact sequencing as implicit complementarity constraints-holds the promise of leveraging continuous optimization to discover new contact patterns online. Nevertheless, the resulting optimization, being an instance of Mathematical Programming with Complementary Constraints, fails the classical constraint qualifications that are crucial for the convergence of popular numerical solvers. We present robust contact-implicit motion planning with sequential convex programming (CRISP), a solver that departs from the usual primal-dual algorithmic framework but instead only focuses on the primal problem. CRISP solves a convex quadratic program with an adaptive trust region radius at each iteration, and its convergence is evaluated by a merit function using weighted penalty. We (i) provide sufficient conditions on CRISP's convergence to first-order stationary points of the merit function; (ii) release a high-performance C++ implementation of CRISP with a generic nonlinear programming interface; and (iii) demonstrate CRISP's surprising robustness in solving contact-implicit planning with naive initialization. In fact, CRISP solves several contact-implicit problems with all-zero initialization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01055v3</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yulin Li, Haoyu Han, Shucheng Kang, Jun Ma, Heng Yang</dc:creator>
    </item>
    <item>
      <title>Distributed and Localized Covariance Control of Coupled Systems: A System Level Approach</title>
      <link>https://arxiv.org/abs/2503.02094</link>
      <description>arXiv:2503.02094v2 Announce Type: replace 
Abstract: This work is concerned with the finite-horizon optimal covariance steering of networked systems governed by discrete-time stochastic linear dynamics. In contrast with existing work that has only considered systems with dynamically decoupled agents, we consider a dynamically coupled system composed of interconnected subsystems subject to local communication constraints. In particular, we propose a distributed algorithm to compute the localized optimal feedback control policy for each individual subsystem, which depends only on the local state histories of its neighboring subsystems. Utilizing the system-level synthesis (SLS) framework, we first recast the localized covariance steering problem as a convex SLS problem with locality constraints. Subsequently, exploiting its partially separable structure, we decompose the latter problem into smaller subproblems, introducing a transformation to deal with nonseparable instances. Finally, we employ a variation of the consensus alternating direction method of multipliers (ADMM) to distribute computation across subsystems on account of their local information and communication constraints. We demonstrate the effectiveness of our proposed algorithm on a power system with 36 interconnected subsystems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02094v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmed Khalil, Yoonjae Lee, Efstathios Bakolas</dc:creator>
    </item>
    <item>
      <title>Distributed Solving of Linear Quadratic Optimal Controller with Terminal State Constraint</title>
      <link>https://arxiv.org/abs/2504.05631</link>
      <description>arXiv:2504.05631v2 Announce Type: replace 
Abstract: This paper is concerned with the linear quadratic (LQ) optimal control of continuous-time system with terminal state constraint. In particular, multiple agents exist in the system which can only access partial information of the matrix parameters. This makes the classical solving method based on Riccati equation with global information suffering. The main contribution is to present a distributed algorithm to derive the optimal controller which is consisting of the distributed iterations for the Riccati equation, a backward differential equation driven by the optimal Lagrange multiplier and the optimal state. The effectiveness of the proposed algorithm is verified by two numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05631v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenjing Yang, Juanjuan Xu</dc:creator>
    </item>
    <item>
      <title>A constructive approach to strengthen algebraic descriptions of function and operator classes</title>
      <link>https://arxiv.org/abs/2504.14377</link>
      <description>arXiv:2504.14377v2 Announce Type: replace 
Abstract: It is well known that functions (resp. operators) satisfying a property~$p$ on a subset $Q\subset \mathbb{R}^d$ cannot necessarily be extended to a function (resp. operator) satisfying~$p$ on the whole of~$\mathbb{R}^d$. Given $Q \subseteq \mathbb{R}^d$, this work considers the problem of obtaining necessary and ideally sufficient conditions to be satisfied by a function (resp. operator) on $Q$, ensuring the existence of an extension of this function (resp. operator) satisfying $p$ on $\mathbb{R}^d$.
  More precisely, given some property $p$, we present a refinement procedure to obtain stronger necessary conditions to be imposed on $Q$. This procedure can be applied iteratively until the stronger conditions are also sufficient. We illustrate the procedure on a few examples, including the strengthening of existing descriptions for the classes of smooth functions satisfying a \L{}ojasiewicz condition, convex blockwise smooth functions, Lipschitz monotone operators, strongly monotone cocoercive operators, and uniformly convex functions.
  In most cases, these strengthened descriptions can be represented, or relaxed, to semi-definite constraints, which can be used to formulate tractable optimization problems on functions (resp. operators) within those classes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14377v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Anne Rubbens, Julien M. Hendrickx, Adrien Taylor</dc:creator>
    </item>
    <item>
      <title>A level set topology optimization theory based on Hamilton's principle</title>
      <link>https://arxiv.org/abs/2504.14892</link>
      <description>arXiv:2504.14892v2 Announce Type: replace 
Abstract: In this paper, we present a novel framework for deriving the evolution equation of the level set function in topology optimization, departing from conventional Hamilton-Jacobi based formulations. The key idea is the introduction of an auxiliary domain, geometrically identical to the physical design domain, occupied by fictitious matter which is dynamically excited by the conditions prevailing in the design domain. By assigning kinetic and potential energy to this matter and interpreting the level set function as the generalized coordinate to describe its deformation, the governing equation of motion is determined via Hamilton's principle, yielding a modified wave equation. Appropriate combinations of model parameters enable the recovery of classical physical behaviors, including the standard and biharmonic wave equations. The evolution problem is formulated in weak form using variational methods and implemented in the software environment FreeFEM++. The influence of the numerical parameters is analyzed on the example of minimum mean compliance. The results demonstrate that topological complexity and strut design can be effectively controlled by the respective parameters. In addition, the method allows for the nucleation of new holes and eliminates the need for re-initializing the level set function. The inclusion of a damping term further enhances numerical stability. To showcase the versatility and robustness of our method, we also apply it to compliant mechanism design and a bi-objective optimization problem involving self-weight and compliance minimization under local stress constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14892v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jan Oellerich, Takayuki Yamada</dc:creator>
    </item>
    <item>
      <title>Modern Computational Methods in Reinsurance Optimization: From Simulated Annealing to Quantum Branch &amp; Bound</title>
      <link>https://arxiv.org/abs/2504.16530</link>
      <description>arXiv:2504.16530v2 Announce Type: replace 
Abstract: We propose and implement modern computational methods to enhance catastrophe excess-of-loss reinsurance contracts in practice. The underlying optimization problem involves attachment points, limits, and reinstatement clauses, and the objective is to maximize the expected profit while considering risk measures and regulatory constraints. We study the problem formulation, paving the way for practitioners, for two very different approaches: A local search optimizer using simulated annealing, which handles realistic constraints, and a branch &amp; bound approach exploring the potential of a future speedup via quantum branch &amp; bound. On the one hand, local search effectively generates contract structures within several constraints, proving useful for complex treaties that have multiple local optima. On the other hand, although our branch &amp; bound formulation only confirms that solving the full problem with a future quantum computer would require a stronger, less expensive bound and substantial hardware improvements, we believe that the designed application-specific bound is sufficiently strong to serve as a basis for further works. Concisely, we provide insurance practitioners with a robust numerical framework for contract optimization that handles realistic constraints today, as well as an outlook and initial steps towards an approach which could leverage quantum computers in the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16530v2</guid>
      <category>math.OC</category>
      <category>q-fin.CP</category>
      <category>quant-ph</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>George Woodman, Ruben S. Andrist, Thomas H\"aner, Damian S. Steiger, Martin J. A. Schuetz, Helmut G. Katzgraber, Marcin Detyniecki</dc:creator>
    </item>
    <item>
      <title>Fast algorithm for centralized multi-agent maze exploration</title>
      <link>https://arxiv.org/abs/2310.02121</link>
      <description>arXiv:2310.02121v2 Announce Type: replace-cross 
Abstract: Recent advances in robotics have paved the way for robots to replace humans in perilous situations, such as searching for victims in burning buildings, in earthquake-damaged structures, in uncharted caves, traversing minefields or patrolling crime-ridden streets. These challenges can be generalized as problems where agents have to explore unknown mazes. We propose a cooperative multi-agent system of automated mobile agents for exploring unknown mazes and localizing stationary targets. The Heat Equation-Driven Area Coverage (HEDAC) algorithm for maze exploration employs a potential field to guide the exploration of the maze and integrates cooperative behaviors of the agents such as collision avoidance, coverage coordination, and path planning. In contrast to previous applications for continuous static domains, we adapt the HEDAC method for mazes on expanding rectilinear grids. The proposed algorithm guarantees the exploration of the entire maze and can ensure the avoidance of collisions and deadlocks. Moreover, this is the first application of the HEDAC algorithm to domains that expand over time. To cope with the dynamically changing domain, succesive over-relaxation (SOR) iterative linear solver has been adapted and implemented, which significantly reduced the computational complexity of the presented algorithm when compared to standard direct and iterative linear solvers. The results highlight significant improvements and show the applicability of the algorithm in different mazes. They confirm its robustness, adaptability, scalability and simplicity, which enables centralized parallel computation to control multiple agents/robots in the maze.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.02121v2</guid>
      <category>cs.RO</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bojan Crnkovi\'c, Stefan Ivi\'c, Mila Zovko</dc:creator>
    </item>
    <item>
      <title>Acceleration Meets Inverse Maintenance: Faster $\ell_{\infty}$-Regression</title>
      <link>https://arxiv.org/abs/2409.20030</link>
      <description>arXiv:2409.20030v2 Announce Type: replace-cross 
Abstract: We propose a randomized multiplicative weight update (MWU) algorithm for $\ell_{\infty}$ regression that runs in $\widetilde{O}\left(n^{2+1/22.5} \text{poly}(1/\epsilon)\right)$ time when $\omega = 2+o(1)$, improving upon the previous best $\widetilde{O}\left(n^{2+1/18} \text{poly} \log(1/\epsilon)\right)$ runtime in the low-accuracy regime. Our algorithm combines state-of-the-art inverse maintenance data structures with acceleration. In order to do so, we propose a novel acceleration scheme for MWU that exhibits {\it stabiliy} and {\it robustness}, which are required for the efficient implementations of the inverse maintenance data structures.
  We also design a faster {\it deterministic} MWU algorithm that runs in $\widetilde{O}\left(n^{2+1/12}\text{poly}(1/\epsilon)\right))$ time when $\omega = 2+o(1)$, improving upon the previous best $\widetilde{O}\left(n^{2+1/6} \text{poly} \log(1/\epsilon)\right)$ runtime in the low-accuracy regime. We achieve this by showing a novel stability result that goes beyond previously known works based on interior point methods (IPMs).
  Our work is the first to use acceleration and inverse maintenance together efficiently, finally making the two most important building blocks of modern structured convex optimization compatible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.20030v2</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Deeksha Adil, Shunhua Jiang, Rasmus Kyng</dc:creator>
    </item>
    <item>
      <title>Sample-Efficient Quantum State Tomography for Structured Quantum States in One Dimension</title>
      <link>https://arxiv.org/abs/2410.02583</link>
      <description>arXiv:2410.02583v2 Announce Type: replace-cross 
Abstract: While quantum state tomography (QST) remains the gold standard for benchmarking and verifying quantum devices, it requires an exponentially large number of measurements and classical computational resources for generic quantum many-body systems, making it impractical even for intermediate-size quantum devices. Fortunately, many physical quantum states often exhibit certain low-dimensional structures that enable the development of efficient QST. A notable example is the class of states represented by matrix product operators (MPOs) with a finite matrix/bond dimension, which include most physical states in one dimension and where the number of independent parameters describing the states only grows linearly with the number of qubits. Whether a sample efficient quantum state tomography protocol, where the number of required state copies scales only linearly as the number of parameters describing the state, exists for a generic MPO state still remains an important open question.
  In this paper, we answer this fundamental question affirmatively by using a class of informationally complete positive operator-valued measures (IC-POVMs) -- including symmetric IC-POVMs (SIC-POVMs) and spherical $t$-designs -- focusing on sample complexity while not accounting for the implementation complexity of the measurement settings. For SIC-POVMs and (approximate) spherical 2-designs, we show that the number of state copies to guarantee bounded recovery error of an MPO state with a constrained least-squares estimator depends on the probability distribution of the MPO under the POVM but scales only linearly with $n$ when the distribution is approximately uniform. For spherical $t$-designs with $t\ge3$, we prove that only a number of state copies proportional to the number of independent parameters in the MPO is needed for a guaranteed recovery of \emph{any} state represented by an MPO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02583v2</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhen Qin, Casey Jameson, Alireza Goldar, Michael B. Wakin, Zhexuan Gong, Zhihui Zhu</dc:creator>
    </item>
    <item>
      <title>Quantum Approximate Optimization Algorithm and Quantum-enhanced Markov Chain Monte Carlo: A Hybrid Approach to Data Assimilation in 4DVAR</title>
      <link>https://arxiv.org/abs/2410.03853</link>
      <description>arXiv:2410.03853v2 Announce Type: replace-cross 
Abstract: We propose a novel hybrid quantum-classical framework that integrates the Quantum Approximate Optimization Algorithm (QAOA) and Quantum-enhanced Markov Chain Monte Carlo (QMCMC) with variational particle filters to tackle the computational challenges in Four-Dimensional Variational Data Assimilation (4DVAR). 4DVAR, widely used in numerical weather prediction, suffers from inefficiencies in high-dimensional, non-linear systems. Our approach, the Quantum Variational Particle Filter (QVPF), uses QAOA to optimize particle proposals and QMCMC to efficiently compute particle weights and resample, accelerating convergence while reducing the computational load.
  The QVPF framework addresses the curse of dimensionality by minimizing the number of particles required for accurate state estimation, thus improving efficiency in systems with complex dynamics. The hybrid model offers enhanced accuracy by integrating quantum algorithms into the variational particle filter, making it particularly suited for applications in climate modeling, space weather prediction, and defense. The potential for achieving unprecedented resolution in predictive models could transform sectors that rely on high-resolution forecasting.
  We present the mathematical foundations of the approach, along with discussions on algorithmic implementation and hardware requirements. Early results suggest that this hybrid framework could significantly improve data assimilation, with future implementations on near-term quantum devices offering a practical pathway for scaling up. This work demonstrates how quantum computing can address the growing need for more accurate and computationally feasible methods in large-scale data assimilation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03853v2</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <category>physics.ao-ph</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abhiram Sripat</dc:creator>
    </item>
    <item>
      <title>On the optimal choice of the illumination function in photoacoustic tomography</title>
      <link>https://arxiv.org/abs/2411.06609</link>
      <description>arXiv:2411.06609v2 Announce Type: replace-cross 
Abstract: This work studies the inverse problem of photoacoustic tomography (more precisely, the acoustic subproblem) as the identification of a space-dependent source parameter. The model consists of a wave equation involving a time-fractional damping term to account for power law frequency dependence of the attenuation, as relevant in ultrasonics. We solve the inverse problem in a Bayesian framework using a Maximum A Posteriori (MAP) estimate, and for this purpose derive an explicit expression for the adjoint operator. On top of this, we consider optimization of the choice of the laser excitation function, which is the time-dependent part of the source in this model, to enhance the reconstruction result. The method employs the $A$-optimality criterion for Bayesian optimal experimental design with Gaussian prior and Gaussian noise. To efficiently approximate the cost functional, we introduce an approximation scheme based on projection onto finite-dimensional subspaces. Finally, we present numerical results that illustrate the theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06609v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.3934/ipi.2025017</arxiv:DOI>
      <dc:creator>Phuoc-Truong Huynh, Barbara Kaltenbacher</dc:creator>
    </item>
    <item>
      <title>Joint State and Noise Covariance Estimation</title>
      <link>https://arxiv.org/abs/2502.04584</link>
      <description>arXiv:2502.04584v2 Announce Type: replace-cross 
Abstract: This paper tackles the problem of jointly estimating the noise covariance matrix alongside states (parameters such as poses and points) from measurements corrupted by Gaussian noise and, if available, prior information. In such settings, the noise covariance matrix determines the weights assigned to individual measurements in the least squares problem. We show that the joint problem exhibits a convex structure and provide a full characterization of the optimal noise covariance estimate (with analytical solutions) within joint maximum a posteriori and likelihood frameworks and several variants. Leveraging this theoretical result, we propose two novel algorithms that jointly estimate the primary parameters and the noise covariance matrix. Our BCD algorithm can be easily integrated into existing nonlinear least squares solvers, with negligible per-iteration computational overhead. To validate our approach, we conduct extensive experiments across diverse scenarios and offer practical insights into their application in robotics and computer vision estimation problems with a particular focus on SLAM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04584v2</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kasra Khosoussi, Iman Shames</dc:creator>
    </item>
    <item>
      <title>Building Rome with Convex Optimization</title>
      <link>https://arxiv.org/abs/2502.04640</link>
      <description>arXiv:2502.04640v3 Announce Type: replace-cross 
Abstract: Global bundle adjustment is made easy by depth prediction and convex optimization. We (i) propose a scaled bundle adjustment (SBA) formulation that lifts 2D keypoint measurements to 3D with learned depth, (ii) design an empirically tight convex semidfinite program (SDP) relaxation that solves SBA to certfiable global optimality, (iii) solve the SDP relaxations at extreme scale with Burer-Monteiro factorization and a CUDA-based trust-region Riemannian optimizer (dubbed XM), (iv) build a structure from motion (SfM) pipeline with XM as the optimization engine and show that XM-SfM compares favorably with existing pipelines in terms of reconstruction quality while being significantly faster, more scalable, and initialization-free.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04640v3</guid>
      <category>cs.RO</category>
      <category>cs.CV</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoyu Han, Heng Yang</dc:creator>
    </item>
    <item>
      <title>Implicit bias of Normalized Steepest Descent in Multiclass Classification: Sign Descent, Spectral Descent, and Adam</title>
      <link>https://arxiv.org/abs/2502.04664</link>
      <description>arXiv:2502.04664v2 Announce Type: replace-cross 
Abstract: In the optimization of overparameterized models, different gradient-based methods can achieve zero training error yet converge to distinctly different solutions inducing different generalization properties. Despite a decade of research on implicit optimization bias, important questions remain open even in the foundational case of linear classification with separable data. We address this gap by characterizing the implicit bias of both Adam and Sign gradient descent (SignGD) in multi-class cross-entropy minimization: we prove that their iterates converge to solutions maximizing the margin with respect to the classifier matrix's max-norm, and we establish the corresponding convergence rates. We then generalize our analysis to p-norm normalized steepest descent (NSD) algorithms. This includes Spectral Descent, which we show converges to the max-margin solution with respect to the spectral norm. A key insight is that the analysis of general entry-wise and Schatten p-norms can be reduced to the analysis of NSD with max-norm (i.e., SignGD) by exploiting a natural ordering property between all p-norms relative to the max-norm and its dual sum-norm. Our results demonstrate that the multi-class linear setting, which is inherently richer than the binary counterpart, provides the most transparent playground for studying implicit biases of matrix-parameter optimization algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04664v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chen Fan, Mark Schmidt, Christos Thrampoulidis</dc:creator>
    </item>
    <item>
      <title>Low-Rank Thinning</title>
      <link>https://arxiv.org/abs/2502.12063</link>
      <description>arXiv:2502.12063v5 Announce Type: replace-cross 
Abstract: The goal in thinning is to summarize a dataset using a small set of representative points. Remarkably, sub-Gaussian thinning algorithms like Kernel Halving and Compress can match the quality of uniform subsampling while substantially reducing the number of summary points. However, existing guarantees cover only a restricted range of distributions and kernel-based quality measures and suffer from pessimistic dimension dependence. To address these deficiencies, we introduce a new low-rank analysis of sub-Gaussian thinning that applies to any distribution and any kernel, guaranteeing high-quality compression whenever the kernel or data matrix is approximately low-rank. To demonstrate the broad applicability of the techniques, we design practical sub-Gaussian thinning approaches that improve upon the best known guarantees for approximating attention in transformers, accelerating stochastic gradient training through reordering, and distinguishing distributions in near-linear time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12063v5</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Annabelle Michael Carrell, Albert Gong, Abhishek Shetty, Raaz Dwivedi, Lester Mackey</dc:creator>
    </item>
    <item>
      <title>An Efficient Alternating Algorithm for ReLU-based Symmetric Matrix Decomposition</title>
      <link>https://arxiv.org/abs/2503.16846</link>
      <description>arXiv:2503.16846v2 Announce Type: replace-cross 
Abstract: Symmetric matrix decomposition is an active research area in machine learning. This paper focuses on exploiting the low-rank structure of non-negative and sparse symmetric matrices via the rectified linear unit (ReLU) activation function. We propose the ReLU-based nonlinear symmetric matrix decomposition (ReLU-NSMD) model, introduce an accelerated alternating partial Bregman (AAPB) method for its solution, and present the algorithm's convergence results. Our algorithm leverages the Bregman proximal gradient framework to overcome the challenge of estimating the global $L$-smooth constant in the classic proximal gradient algorithm. Numerical experiments on synthetic and real datasets validate the effectiveness of our model and algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16846v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qingsong Wang</dc:creator>
    </item>
    <item>
      <title>A mixed-integer framework for analyzing neural network-based controllers for piecewise affine systems with bounded disturbances</title>
      <link>https://arxiv.org/abs/2504.11125</link>
      <description>arXiv:2504.11125v2 Announce Type: replace-cross 
Abstract: We present a method for representing the closed-loop dynamics of piecewise affine (PWA) systems with bounded additive disturbances and neural network-based controllers as mixed-integer (MI) linear constraints. We show that such representations enable the computation of robustly positively invariant (RPI) sets for the specified system class by solving MI linear programs. These RPI sets can subsequently be used to certify stability and constraint satisfaction. Furthermore, the approach allows to handle non-linear systems based on suitable PWA approximations and corresponding error bounds, which can be interpreted as the bounded disturbances from above.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11125v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dieter Teichrib, Moritz Schulze Darup</dc:creator>
    </item>
    <item>
      <title>Convergence and Implicit Bias of Gradient Descent on Continual Linear Classification</title>
      <link>https://arxiv.org/abs/2504.12712</link>
      <description>arXiv:2504.12712v2 Announce Type: replace-cross 
Abstract: We study continual learning on multiple linear classification tasks by sequentially running gradient descent (GD) for a fixed budget of iterations per task. When all tasks are jointly linearly separable and are presented in a cyclic/random order, we show the directional convergence of the trained linear classifier to the joint (offline) max-margin solution. This is surprising because GD training on a single task is implicitly biased towards the individual max-margin solution for the task, and the direction of the joint max-margin solution can be largely different from these individual solutions. Additionally, when tasks are given in a cyclic order, we present a non-asymptotic analysis on cycle-averaged forgetting, revealing that (1) alignment between tasks is indeed closely tied to catastrophic forgetting and backward knowledge transfer and (2) the amount of forgetting vanishes to zero as the cycle repeats. Lastly, we analyze the case where the tasks are no longer jointly separable and show that the model trained in a cyclic order converges to the unique minimum of the joint loss function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.12712v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hyunji Jung, Hanseul Cho, Chulhee Yun</dc:creator>
    </item>
  </channel>
</rss>
