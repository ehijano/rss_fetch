<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 20 Feb 2025 02:38:43 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>KiSS: A Novel Container Size-Aware Memory Management Policy for Serverless in Edge-Cloud Continuum</title>
      <link>https://arxiv.org/abs/2502.12540</link>
      <description>arXiv:2502.12540v1 Announce Type: cross 
Abstract: Serverless computing has revolutionized cloud architectures by enabling developers to deploy event-driven applications via lightweight, self-contained virtualized containers. However, serverless frameworks face critical cold-start challenges in resource-constrained edge environments, where traditional solutions fall short. The limitations are especially pronounced in edge environments, where heterogeneity and resource constraints exacerbate inefficiencies in resource utilization.
  This paper introduces KiSS (Keep it Separated Serverless), a static, container size-aware memory management policy tailored for the edge-cloud continuum. The design of KiSS is informed by a detailed workload analysis that identifies critical patterns in container size, invocation frequency, and memory contention. Guided by these insights, KiSS partitions memory pools into categories for small, frequently invoked containers and larger, resource-intensive ones, ensuring efficient resource utilization while minimizing cold starts and inter-function interference. Using a discrete-event simulator, we evaluate KiSS on edge-cluster environments with real-world-inspired workloads.
  Results show that KiSS reduces cold-start percentages by 60% and function drops by 56.5%, achieving significant performance gains in resource-constrained settings. This work underscores the importance of workload-driven design in advancing serverless efficiency at the edge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12540v1</guid>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sabyasachi Gupta, Paul Gratz, John Lusher</dc:creator>
    </item>
    <item>
      <title>Neuromorphic Readout for Hadron Calorimeters</title>
      <link>https://arxiv.org/abs/2502.12693</link>
      <description>arXiv:2502.12693v1 Announce Type: cross 
Abstract: We simulate hadrons impinging on a homogeneous lead-tungstate (PbWO4) calorimeter to investigate how the resulting light yield and its temporal structure, as detected by an array of light-sensitive sensors, can be processed by a neuromorphic computing system. Our model encodes temporal photon distributions as spike trains and employs a fully connected spiking neural network to estimate the total deposited energy, as well as the position and spatial distribution of the light emissions within the sensitive material. The extracted primitives offer valuable topological information about the shower development in the material, achieved without requiring a segmentation of the active medium. A potential nanophotonic implementation using III-V semiconductor nanowires is discussed. It can be both fast and energy efficient.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12693v1</guid>
      <category>hep-ex</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Enrico Lupi (INFN sezione di Padova, Italy, Universit\`a di Padova dipartimento di Fisica e Astronomia, Italy),  Abhishek (National Institute of Science Education and Research, India), Max Aehle (University of Kaiserslautern-Landau, MODE Collaboration), Muhammad Awais (INFN sezione di Padova, Italy, MODE Collaboration), Alessandro Breccia (Universit\`a di Padova dipartimento di Fisica e Astronomia, Italy), Riccardo Carroccio (Universit\`a di Padova dipartimento di Fisica e Astronomia, Italy), Long Chen (University of Kaiserslautern-Landau, MODE Collaboration), Abhijit Das (Department of Physics and NanoLund, Lund University, Sweden), Andrea De Vita (INFN sezione di Padova, Italy, Universit\`a di Padova dipartimento di Fisica e Astronomia, Italy), Tommaso Dorigo (INFN sezione di Padova, Italy, MODE Collaboration), Nicolas R. Gauger (University of Kaiserslautern-Landau, MODE Collaboration), Ralf Keidel (Karlsruhe Institute of Technology, Germany, MODE Collaboration), Jan Kieseler (Karlsruhe Institute of Technology, Germany), Anders Mikkelsen (Department of Physics and NanoLund, Lund University, Sweden), Federico Nardi (Universit\`a di Padova dipartimento di Fisica e Astronomia, Italy, Laboratoire de Physique Clermont Auvergne, France), Xuan Tung Nguyen (INFN sezione di Padova, Italy, University of Kaiserslautern-Landau), Fredrik Sandin (Lule{\aa} University of Technology, Sweden, MODE Collaboration), Kylian Schmidt (Karlsruhe Institute of Technology, Germany), Pietro Vischia (Universal Scientific Education and Research Network, Italy, MODE Collaboration), Joseph Willmore (INFN sezione di Padova, Italy)</dc:creator>
    </item>
    <item>
      <title>The Early Days of the Ethereum Blob Fee Market and Lessons Learnt</title>
      <link>https://arxiv.org/abs/2502.12966</link>
      <description>arXiv:2502.12966v1 Announce Type: cross 
Abstract: Ethereum has adopted a rollup-centric roadmap to scale by making rollups (layer 2 scaling solutions) the primary method for handling transactions. The first significant step towards this goal was EIP-4844, which introduced blob transactions that are designed to meet the data availability needs of layer 2 protocols. This work constitutes the first rigorous and comprehensive empirical analysis of transaction- and mempool-level data since the institution of blobs on Ethereum on March 13, 2024. We perform a longitudinal study of the early days of the blob fee market analyzing the landscape and the behaviors of its participants. We identify and measure the inefficiencies arising out of suboptimal block packing, showing that at times it has resulted in up to 70% relative fee loss. We hone in and give further insight into two (congested) peak demand periods for blobs. Finally, we document a market design issue relating to subset bidding due to the inflexibility of the transaction structure on packing data as blobs and suggest possible ways to fix it. The latter market structure issue also applies more generally for any discrete objects included within transactions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12966v1</guid>
      <category>cs.CE</category>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lioba Heimbach, Jason Milionis</dc:creator>
    </item>
    <item>
      <title>A Silicon Photonic Neural Network for Chromatic Dispersion Compensation in 20 Gbps PAM4 Signal at 125 km and Its Scalability up to 100 Gbps</title>
      <link>https://arxiv.org/abs/2409.03547</link>
      <description>arXiv:2409.03547v2 Announce Type: replace 
Abstract: A feed-forward photonic neural network (PNN) is tested for chromatic dispersion compensation in Intensity Modulation/Direct Detection optical links. The PNN is based on a sequence of linear and nonlinear transformations. The linear stage is constituted by an 8-tap time-delayed complex perceptron implemented on a Silicon-On-insulator platform and acting as a tunable optical filter. The nonlinear stage is provided by the square modulus of the electrical field applied at the end-of-line photodetector. The training maximizes the separation between the optical levels (i.e. the eye diagram aperture), with consequent reduction of the Bit Error Rate. Effective equalization is experimentally demonstrated for 20 Gbps 4-level Pulse Amplitude Modulated signal up to 125 km. An evolutionary algorithm and a gradient-based approach are tested for the training and then compared in terms of repeatability and convergence time. The optimal weights resulting from the training are interpreted in light of the theoretical transfer function of the optical fiber. Finally, a simulative study proves the scalability of the layout to larger bandwidths, up to 100 Gbps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03547v2</guid>
      <category>cs.ET</category>
      <category>physics.app-ph</category>
      <category>physics.optics</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1109/JLT.2024.3466293</arxiv:DOI>
      <arxiv:journal_reference>IEEE Journal of Lightwave Technology, Volume 43, Issue: 2, 15 January 2025, Pages: 557 - 571</arxiv:journal_reference>
      <dc:creator>Emiliano Staffoli, Gianpietro Maddinelli, Lorenzo Pavesi</dc:creator>
    </item>
    <item>
      <title>I don't trust you (anymore)! -- The effect of students' LLM use on Lecturer-Student-Trust in Higher Education</title>
      <link>https://arxiv.org/abs/2406.14871</link>
      <description>arXiv:2406.14871v2 Announce Type: replace-cross 
Abstract: Trust plays a pivotal role in Lecturer-Student-Collaboration, encompassing teaching and research aspects. The advent of Large Language Models (LLMs) in platforms like Open AI's ChatGPT, coupled with their cost-effectiveness and high-quality results, has led to their rapid adoption among university students. However, discerning genuine student input from LLM-generated output poses a challenge for lecturers. This dilemma jeopardizes the trust relationship between lecturers and students, potentially impacting university downstream activities, particularly collaborative research initiatives. Despite attempts to establish guidelines for student LLM use, a clear framework mutually beneficial for lecturers and students in higher education remains elusive. This study addresses the research question: How does the use of LLMs by students impact Informational and Procedural Justice, influencing Team Trust and Expected Team Performance? Methodically, we applied a quantitative construct-based survey, evaluated using techniques of Structural Equation Modelling (PLS- SEM) to examine potential relationships among these constructs. Our findings based on 23 valid respondents from Ndejje University indicate that lecturers are less concerned about the fairness of LLM use per se but are more focused on the transparency of student utilization, which significantly influences Team Trust positively. This research contributes to the global discourse on integrating and regulating LLMs and subsequent models in education. We propose that guidelines should support LLM use while enforcing transparency in Lecturer-Student- Collaboration to foster Team Trust and Performance. The study contributes valuable insights for shaping policies enabling ethical and transparent LLMs usage in education to ensure effectiveness of collaborative learning environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14871v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.58653/nche.v12i1.6</arxiv:DOI>
      <arxiv:journal_reference>The Uganda Higher Education Review, 12(1), 74-90 (2024)</arxiv:journal_reference>
      <dc:creator>Simon Kloker, Matthew Bazanya, Twaha Kateete</dc:creator>
    </item>
    <item>
      <title>WaferLLM: A Wafer-Scale LLM Inference System</title>
      <link>https://arxiv.org/abs/2502.04563</link>
      <description>arXiv:2502.04563v2 Announce Type: replace-cross 
Abstract: Emerging AI accelerators increasingly adopt wafer-scale manufacturing technologies, integrating hundreds of thousands of AI cores in a mesh-based architecture with large distributed on-chip memory (tens of GB in total) and ultra-high on-chip memory bandwidth (tens of PB/s). However, current LLM inference systems, optimized for shared memory architectures like GPUs, fail to fully exploit these accelerators.
  We introduce WaferLLM, the first wafer-scale LLM inference system. WaferLLM is guided by a novel PLMR model (pronounced as "Plummer") that captures the unique hardware characteristics of wafer-scale architectures. Leveraging this model, WaferLLM pioneers wafer-scale LLM parallelism, optimizing the utilization of hundreds of thousands of on-chip cores. It also introduces MeshGEMM and MeshGEMV, the first GEMM and GEMV implementations designed to scale effectively on wafer-scale accelerators.
  Evaluations show that WaferLLM achieves 200$\times$ better wafer-scale accelerator utilization than state-of-the-art systems. On a commodity wafer-scale accelerator, WaferLLM delivers 606$\times$ faster and 22$\times$ more energy-efficient GEMV compared to an advanced GPU. For LLMs, based on 16-bit data type, WaferLLM achieves 2700 toks/sec/req decode speed on Llama3-8B model and 840 toks/sec/req decode speed on Qwen2-72B model, which enables 39$\times$ faster decoding with 1.7$\times$ better energy efficiency. We anticipate these numbers will grow significantly as wafer-scale AI models, software, and hardware continue to mature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04563v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.AR</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Congjie He, Yeqi Huang, Pei Mu, Ziming Miao, Jilong Xue, Lingxiao Ma, Fan Yang, Luo Mai</dc:creator>
    </item>
  </channel>
</rss>
