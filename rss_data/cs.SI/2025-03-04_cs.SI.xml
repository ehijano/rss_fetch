<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 05 Mar 2025 03:01:46 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Robust Evidence for Declining Disruptiveness: Assessing the Role of Zero-Backward-Citation Works</title>
      <link>https://arxiv.org/abs/2503.00184</link>
      <description>arXiv:2503.00184v1 Announce Type: new 
Abstract: We respond to Holst et al.'s (HATWG) critique that the observed decline in scientific disruptiveness demonstrated in Park et al. (PLF) stems from including works with zero backward citations (0-bcites). Applying their own advocated dataset, metric, and exclusion criteria, we demonstrate statistically and practically significant declines in disruptiveness that equal major benchmark transformations in science. Notably, we show that HATWG's own regression model -- designed specifically to address their concerns about 0-bcite works -- reveals highly significant declines for both papers (p&lt;0.001) and patents (p&lt;0.001), a finding they neither acknowledge nor interpret. Their critique is undermined by methodological deficiencies, including reliance on visual inspection without statistical assessment, and severe data quality issues in their SciSciNet dataset, which contains nearly three times more 0-bcite papers than our original data. HATWG's departure from established scientometric practices -- notably their inclusion of document types and fields known for poor metadata quality -- invalidates their conclusions. Monte Carlo simulations and additional analyses using multiple disruptiveness measures across datasets further validate the robustness of the declining trend. Our findings collectively demonstrate that the observed decline in disruptiveness is not an artifact of 0-bcite works but represents a substantive change in scientific and technological innovation patterns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00184v1</guid>
      <category>cs.SI</category>
      <category>cs.DL</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Park, Erin Leahey, Russell J. Funk</dc:creator>
    </item>
    <item>
      <title>Large Engagement Networks for Classifying Coordinated Campaigns and Organic Twitter Trends</title>
      <link>https://arxiv.org/abs/2503.00599</link>
      <description>arXiv:2503.00599v1 Announce Type: new 
Abstract: Social media users and inauthentic accounts, such as bots, may coordinate in promoting their topics. Such topics may give the impression that they are organically popular among the public, even though they are astroturfing campaigns that are centrally managed. It is challenging to predict if a topic is organic or a coordinated campaign due to the lack of reliable ground truth. In this paper, we create such ground truth by detecting the campaigns promoted by ephemeral astroturfing attacks. These attacks push any topic to Twitter's (X) trends list by employing bots that tweet in a coordinated manner in a short period and then immediately delete their tweets. We manually curate a dataset of organic Twitter trends. We then create engagement networks out of these datasets which can serve as a challenging testbed for graph classification task to distinguish between campaigns and organic trends. Engagement networks consist of users as nodes and engagements as edges (retweets, replies, and quotes) between users. We release the engagement networks for 179 campaigns and 135 non-campaigns, and also provide finer-grain labels to characterize the type of the campaigns and non-campaigns. Our dataset, LEN (Large Engagement Networks), is available in the URL below. In comparison to traditional graph classification datasets, which are small with tens of nodes and hundreds of edges at most, graphs in LEN are larger. The average graph in LEN has ~11K nodes and ~23K edges. We show that state-of-the-art GNN methods give only mediocre results for campaign vs. non-campaign and campaign type classification on LEN. LEN offers a unique and challenging playfield for the graph classification problem. We believe that LEN will help advance the frontiers of graph classification techniques on large networks and also provide an interesting use case in terms of distinguishing coordinated campaigns and organic trends.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00599v1</guid>
      <category>cs.SI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:journal_reference>ICWSM 2025</arxiv:journal_reference>
      <dc:creator>Atul Anand Gopalakrishnan, Jakir Hossain, Tugrulcan Elmas, Ahmet Erdem Sariyuce</dc:creator>
    </item>
    <item>
      <title>Deep Identification of Propagation Trees</title>
      <link>https://arxiv.org/abs/2503.00646</link>
      <description>arXiv:2503.00646v1 Announce Type: new 
Abstract: Understanding propagation structures in graph diffusion processes, such as epidemic spread or misinformation diffusion, is a fundamental yet challenging problem. While existing methods primarily focus on source localization, they cannot reconstruct the underlying propagation trees i.e., "who infected whom", which are substantial for tracking the propagation pathways and investigate diffusion mechanisms. In this work, we propose Deep Identification of Propagation Trees (DIPT), a probabilistic framework that infers propagation trees from observed diffused states. DIPT models local influence strengths between nodes and leverages an alternating optimization strategy to jointly learn the diffusion mechanism and reconstruct the propagation structure. Extensive experiments on five real-world datasets demonstrate the effectiveness of DIPT in accurately reconstructing propagation trees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00646v1</guid>
      <category>cs.SI</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zeeshan Memon, Chen Ling, Ruochen Kong, Vishwanath Seshagiri, Andreas Zufle, Liang Zhao</dc:creator>
    </item>
    <item>
      <title>Analyzing Social Media Engagement of Computer Science Conferences</title>
      <link>https://arxiv.org/abs/2503.01038</link>
      <description>arXiv:2503.01038v1 Announce Type: new 
Abstract: Context: X, formerly known as Twitter, is one of the largest social media platforms and has been widely used for communication during research conferences. While previous studies have examined how users engage with X during these events, limited research has focused on analyzing the content posted by computer science conferences. Objective: This study investigates how conferences from different areas of computer science perform on social media by analyzing their activity, follower engagement, and the content posted on X. Method: We collect posts from 22 computer science conferences and conduct statistical experiments to identify variations in content. Additionally, we perform a manual analysis of the top five posts for each engagement metric. Results: Our findings indicate statistically significant differences in category, sentiment, and post length across computer science conference posts. Among all engagement metrics, likes were the most common way users interacted with conference content. Conclusion: This study provides insights into the social media presence of computer science conferences, highlighting key differences in content, sentiment, and engagement patterns across different venues.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01038v1</guid>
      <category>cs.SI</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rey Ortiz, Sharif Ahmed, Priscilla Salas, Nasir U Eisty</dc:creator>
    </item>
    <item>
      <title>Enhancing Social Media Rumor Detection: A Semantic and Graph Neural Network Approach for the 2024 Global Election</title>
      <link>https://arxiv.org/abs/2503.01394</link>
      <description>arXiv:2503.01394v1 Announce Type: new 
Abstract: The development of social media platforms has revolutionized the speed and manner in which information is disseminated, leading to both beneficial and detrimental effects on society. While these platforms facilitate rapid communication, they also accelerate the spread of rumors and extremist speech, impacting public perception and behavior significantly. This issue is particularly pronounced during election periods, where the influence of social media on election outcomes has become a matter of global concern. With the unprecedented number of elections in 2024, against this backdrop, the election ecosystem has encountered unprecedented challenges. This study addresses the urgent need for effective rumor detection on social media by proposing a novel method that combines semantic analysis with graph neural networks. We have meticulously collected a dataset from PolitiFact and Twitter, focusing on politically relevant rumors. Our approach involves semantic analysis using a fine-tuned BERT model to vectorize text content and construct a directed graph where tweets and comments are nodes, and interactions are edges. The core of our method is a graph neural network, SAGEWithEdgeAttention, which extends the GraphSAGE model by incorporating first-order differences as edge attributes and applying an attention mechanism to enhance feature aggregation. This innovative approach allows for the fine-grained analysis of the complex social network structure, improving rumor detection accuracy. The study concludes that our method significantly outperforms traditional content analysis and time-based models, offering a theoretically sound and practically efficient solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01394v1</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Liu Yan, Liu Yunpeng, Zhao Liang</dc:creator>
    </item>
    <item>
      <title>Leveraging LLMs for Mental Health: Detection and Recommendations from Social Discussions</title>
      <link>https://arxiv.org/abs/2503.01442</link>
      <description>arXiv:2503.01442v1 Announce Type: new 
Abstract: Textual data from social platforms captures various aspects of mental health through discussions around and across issues, while users reach out for help and others sympathize and offer support. We propose a comprehensive framework that leverages Natural Language Processing (NLP) and Generative AI techniques to identify and assess mental health disorders, detect their severity, and create recommendations for behavior change and therapeutic interventions based on users' posts on Reddit.
  To classify the disorders, we use rule-based labeling methods as well as advanced pre-trained NLP models to extract nuanced semantic features from the data. We fine-tune domain-adapted and generic pre-trained NLP models based on predictions from specialized Large Language Models (LLMs) to improve classification accuracy. Our hybrid approach combines the generalization capabilities of pre-trained models with the domain-specific insights captured by LLMs, providing an improved understanding of mental health discourse. Our findings highlight the strengths and limitations of each model, offering valuable insights into their practical applicability.
  This research potentially facilitates early detection and personalized care to aid practitioners and aims to facilitate timely interventions and improve overall well-being, thereby contributing to the broader field of mental health surveillance and digital health analytics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01442v1</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <category>cs.IR</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vaishali Aggarwal, Sachin Thukral, Krushil Patel, Arnab Chatterjee</dc:creator>
    </item>
    <item>
      <title>Geo-Semantic-Parsing: AI-powered geoparsing by traversing semantic knowledge graphs</title>
      <link>https://arxiv.org/abs/2503.01386</link>
      <description>arXiv:2503.01386v1 Announce Type: cross 
Abstract: Online social networks convey rich information about geospatial facets of reality. However in most cases, geographic information is not explicit and structured, thus preventing its exploitation in real-time applications. We address this limitation by introducing a novel geoparsing and geotagging technique called Geo-Semantic-Parsing (GSP). GSP identifies location references in free text and extracts the corresponding geographic coordinates. To reach this goal, we employ a semantic annotator to identify relevant portions of the input text and to link them to the corresponding entity in a knowledge graph. Then, we devise and experiment with several efficient strategies for traversing the knowledge graph, thus expanding the available set of information for the geoparsing task. Finally, we exploit all available information for learning a regression model that selects the best entity with which to geotag the input text. We evaluate GSP on a well-known reference dataset including almost 10k event-related tweets, achieving $F1=0.66$. We extensively compare our results with those of 2 baselines and 3 state-of-the-art geoparsing techniques, achieving the best performance. On the same dataset, competitors obtain $F1 \leq 0.55$. We conclude by providing in-depth analyses of our results, showing that the overall superior performance of GSP is mainly due to a large improvement in recall, with respect to existing techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01386v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.dss.2020.113346</arxiv:DOI>
      <arxiv:journal_reference>Decision Support Systems 136:113346, 2020</arxiv:journal_reference>
      <dc:creator>Leonardo Nizzoli, Marco Avvenuti, Maurizio Tesconi, Stefano Cresci</dc:creator>
    </item>
    <item>
      <title>Automated Annotation of Evolving Corpora for Augmenting Longitudinal Network Data: A Framework Integrating Large Language Models and Expert Knowledge</title>
      <link>https://arxiv.org/abs/2503.01672</link>
      <description>arXiv:2503.01672v1 Announce Type: cross 
Abstract: Longitudinal network data are essential for analyzing political, economic, and social systems and processes. In political science, these datasets are often generated through human annotation or supervised machine learning applied to evolving corpora. However, as semantic contexts shift over time, inferring dynamic interaction types on emerging issues among a diverse set of entities poses significant challenges, particularly in maintaining timely and consistent annotations. This paper presents the Expert-Augmented LLM Annotation (EALA) approach, which leverages Large Language Models (LLMs) in combination with historically annotated data and expert-constructed codebooks to extrapolate and extend datasets into future periods. We evaluate the performance and reliability of EALA using a dataset of climate negotiations. Our findings demonstrate that EALA effectively predicts nuanced interactions between negotiation parties and captures the evolution of topics over time. At the same time, we identify several limitations inherent to LLM-based annotation, highlighting areas for further improvement. Given the wide availability of codebooks and annotated datasets, EALA holds substantial promise for advancing research in political science and beyond.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01672v1</guid>
      <category>cs.CL</category>
      <category>cs.SI</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xiao Liu, Zirui Wu, Jiayi Li, Zhicheng Shao, Xun Pang, Yansong Feng</dc:creator>
    </item>
    <item>
      <title>Learning Exposure Mapping Functions for Inferring Heterogeneous Peer Effects</title>
      <link>https://arxiv.org/abs/2503.01722</link>
      <description>arXiv:2503.01722v1 Announce Type: cross 
Abstract: In causal inference, interference refers to the phenomenon in which the actions of peers in a network can influence an individual's outcome. Peer effect refers to the difference in counterfactual outcomes of an individual for different levels of peer exposure, the extent to which an individual is exposed to the treatments, actions, or behaviors of peers. Estimating peer effects requires deciding how to represent peer exposure. Typically, researchers define an exposure mapping function that aggregates peer treatments and outputs peer exposure. Most existing approaches for defining exposure mapping functions assume peer exposure based on the number or fraction of treated peers. Recent studies have investigated more complex functions of peer exposure which capture that different peers can exert different degrees of influence. However, none of these works have explicitly considered the problem of automatically learning the exposure mapping function. In this work, we focus on learning this function for the purpose of estimating heterogeneous peer effects, where heterogeneity refers to the variation in counterfactual outcomes for the same peer exposure but different individual's contexts. We develop EgoNetGNN, a graph neural network (GNN)-based method, to automatically learn the appropriate exposure mapping function allowing for complex peer influence mechanisms that, in addition to peer treatments, can involve the local neighborhood structure and edge attributes. We show that GNN models that use peer exposure based on the number or fraction of treated peers or learn peer exposure naively face difficulty accounting for such influence mechanisms. Our comprehensive evaluation on synthetic and semi-synthetic network data shows that our method is more robust to different unknown underlying influence mechanisms when estimating heterogeneous peer effects when compared to state-of-the-art baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01722v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shishir Adhikari, Sourav Medya, Elena Zheleva</dc:creator>
    </item>
    <item>
      <title>How Low Can You Go? Searching for the Intrinsic Dimensionality of Complex Networks using Metric Node Embeddings</title>
      <link>https://arxiv.org/abs/2503.01723</link>
      <description>arXiv:2503.01723v1 Announce Type: cross 
Abstract: Low-dimensional embeddings are essential for machine learning tasks involving graphs, such as node classification, link prediction, community detection, network visualization, and network compression. Although recent studies have identified exact low-dimensional embeddings, the limits of the required embedding dimensions remain unclear. We presently prove that lower dimensional embeddings are possible when using Euclidean metric embeddings as opposed to vector-based Logistic PCA (LPCA) embeddings. In particular, we provide an efficient logarithmic search procedure for identifying the exact embedding dimension and demonstrate how metric embeddings enable inference of the exact embedding dimensions of large-scale networks by exploiting that the metric properties can be used to provide linearithmic scaling. Empirically, we show that our approach extracts substantially lower dimensional representations of networks than previously reported for small-sized networks. For the first time, we demonstrate that even large-scale networks can be effectively embedded in very low-dimensional spaces, and provide examples of scalable, exact reconstruction for graphs with up to a million nodes. Our approach highlights that the intrinsic dimensionality of networks is substantially lower than previously reported and provides a computationally efficient assessment of the exact embedding dimension also of large-scale networks. The surprisingly low dimensional representations achieved demonstrate that networks in general can be losslessly represented using very low dimensional feature spaces, which can be used to guide existing network analysis tasks from community detection and node classification to structure revealing exact network visualizations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01723v1</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikolaos Nakis, Niels Raunkj{\ae}r Holm, Andreas Lyhne Fiehn, Morten M{\o}rup</dc:creator>
    </item>
    <item>
      <title>Unmasking Social Bots: How Confident Are We?</title>
      <link>https://arxiv.org/abs/2407.13929</link>
      <description>arXiv:2407.13929v2 Announce Type: replace 
Abstract: Social bots remain a major vector for spreading disinformation on social media and a menace to the public. Despite the progress made in developing multiple sophisticated social bot detection algorithms and tools, bot detection remains a challenging, unsolved problem that is fraught with uncertainty due to the heterogeneity of bot behaviors, training data, and detection algorithms. Detection models often disagree on whether to label the same account as bot or human-controlled. However, they do not provide any measure of uncertainty to indicate how much we should trust their results. We propose to address both bot detection and the quantification of uncertainty at the account level - a novel feature of this research. This dual focus is crucial as it allows us to leverage additional information related to the quantified uncertainty of each prediction, thereby enhancing decision-making and improving the reliability of bot classifications. Specifically, our approach facilitates targeted interventions for bots when predictions are made with high confidence and suggests caution (e.g., gathering more data) when predictions are uncertain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13929v2</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>James Giroux, Ariyarathne Gangani, Alexander C. Nwala, Cristiano Fanelli</dc:creator>
    </item>
    <item>
      <title>Disruption Risk Evaluation on Large-scale Production Network with Establishments and Products</title>
      <link>https://arxiv.org/abs/2410.05595</link>
      <description>arXiv:2410.05595v3 Announce Type: replace 
Abstract: We constructed an establishment-level production network where each establishment inputs and outputs multiple products, using data that includes the firm-level production network and establishments covering nearly all Japanese entities. The network represents the manufacturing sector with 183,951 establishments across 157,537 firms and 919,982 inter-establishment linkages. A probabilistic model of supply chain disruptions was applied to this network. The key findings are as follows: (1) The establishment-level network exhibits greater shock propagation compared to the firm-level network. (2) Incorporating actual product information leads to a larger impact on propagation compared to using industry-level information. (3) Regional shock simulations reveal that while the firm-level network shows greater shock propagation when the shock originates in Tokyo, no such difference is observed in the establishment-level network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05595v3</guid>
      <category>cs.SI</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hiroyasu Inoue, Yasuyuki Todo</dc:creator>
    </item>
    <item>
      <title>Destabilizing a Social Network Model via Intrinsic Feedback Vulnerabilities</title>
      <link>https://arxiv.org/abs/2411.10868</link>
      <description>arXiv:2411.10868v3 Announce Type: replace 
Abstract: Social influence plays a significant role in shaping individual sentiments and actions, particularly in a world of ubiquitous digital interconnection. The rapid development of generative AI has engendered well-founded concerns regarding the potential scalable implementation of radicalization techniques in social media. Motivated by these developments, we present a case study investigating the effects of small but intentional perturbations on a simple social network. We employ Taylor's classic model of social influence and tools from robust control theory (most notably the Dynamical Structure Function (DSF)), to identify perturbations that qualitatively alter the system's behavior while remaining as unobtrusive as possible. We examine two such scenarios: perturbations to an existing link and perturbations that introduce a new link to the network. In each case, we identify destabilizing perturbations of minimal norm and simulate their effects. Remarkably, we find that small but targeted alterations to network structure may lead to the radicalization of all agents, exhibiting the potential for large-scale shifts in collective behavior to be triggered by comparatively minuscule adjustments in social influence. Given that this method of identifying perturbations that are innocuous yet destabilizing applies to any suitable dynamical system, our findings emphasize a need for similar analyses to be carried out on real systems (e.g., real social networks), to identify the places where such dynamics may already exist.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10868v3</guid>
      <category>cs.SI</category>
      <category>math.OC</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lane H. Rogers, Emma J. Reid, Robert A. Bridges</dc:creator>
    </item>
    <item>
      <title>IOHunter: Graph Foundation Model to Uncover Online Information Operations</title>
      <link>https://arxiv.org/abs/2412.14663</link>
      <description>arXiv:2412.14663v2 Announce Type: replace 
Abstract: Social media platforms have become vital spaces for public discourse, serving as modern agor\`as where a wide range of voices influence societal narratives. However, their open nature also makes them vulnerable to exploitation by malicious actors, including state-sponsored entities, who can conduct information operations (IOs) to manipulate public opinion. The spread of misinformation, false news, and misleading claims threatens democratic processes and societal cohesion, making it crucial to develop methods for the timely detection of inauthentic activity to protect the integrity of online discourse. In this work, we introduce a methodology designed to identify users orchestrating information operations, a.k.a. IO drivers, across various influence campaigns. Our framework, named IOHunter, leverages the combined strengths of Language Models and Graph Neural Networks to improve generalization in supervised, scarcely-supervised, and cross-IO contexts. Our approach achieves state-of-the-art performance across multiple sets of IOs originating from six countries, significantly surpassing existing approaches. This research marks a step toward developing Graph Foundation Models specifically tailored for the task of IO detection on social media platforms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14663v2</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Marco Minici, Luca Luceri, Francesco Fabbri, Emilio Ferrara</dc:creator>
    </item>
    <item>
      <title>How Does Emotion Affect Information Communication</title>
      <link>https://arxiv.org/abs/2502.16038</link>
      <description>arXiv:2502.16038v2 Announce Type: replace 
Abstract: In recent years, the pivotal role of emotions in information dissemination has attracted extensive attention. Research indicates that emotionally charged content significantly outperforms neutral content in dissemination speed and coverage due to its ability to evoke stronger emotional responses. Valence, arousal, and dominance are key factors influencing information retention, comprehension, and sharing. However, systematic analysis of the mechanisms by which emotions affect dissemination and the application of multidimensional emotional design remain limited. This study reviews 166 relevant articles, examining the role of emotions in understanding and sharing information, and proposes a multidimensional design framework based on text, visuals, sound, and interaction design. Incorporating the ``Four-System" model of emotion activation, it develops an emotion regulation framework to optimize the application of emotions in dissemination. This research offers theoretical support and practical guidance for emotion-driven dissemination, laying a foundation for advancing this field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16038v2</guid>
      <category>cs.SI</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shixiong Cao, Nan Cao</dc:creator>
    </item>
    <item>
      <title>Early-Bird GCNs: Graph-Network Co-Optimization Towards More Efficient GCN Training and Inference via Drawing Early-Bird Lottery Tickets</title>
      <link>https://arxiv.org/abs/2103.00794</link>
      <description>arXiv:2103.00794v3 Announce Type: replace-cross 
Abstract: Graph Convolutional Networks (GCNs) have emerged as the state-of-the-art deep learning model for representation learning on graphs. However, it remains notoriously challenging to train and inference GCNs over large graph datasets, limiting their application to large real-world graphs and hindering the exploration of deeper and more sophisticated GCN graphs. This is because as the graph size grows, the sheer number of node features and the large adjacency matrix can easily explode the required memory and data movements. To tackle the aforementioned challenges, we explore the possibility of drawing lottery tickets when sparsifying GCN graphs, i.e., subgraphs that largely shrink the adjacency matrix yet are capable of achieving accuracy comparable to or even better than their full graphs. Specifically, we for the first time discover the existence of graph early-bird (GEB) tickets that emerge at the very early stage when sparsifying GCN graphs, and propose a simple yet effective detector to automatically identify the emergence of such GEB tickets. Furthermore, we advocate graph-model co-optimization and develop a generic efficient GCN early-bird training framework dubbed GEBT that can significantly boost the efficiency of GCN training by (1) drawing joint early-bird tickets between the GCN graphs and models and (2) enabling simultaneously sparsification of both the GCN graphs and models. Experiments on various GCN models and datasets consistently validate our GEB finding and the effectiveness of our GEBT, e.g., our GEBT achieves up to 80.2% ~ 85.6% and 84.6% ~ 87.5% savings of GCN training and inference costs while offering a comparable or even better accuracy as compared to state-of-the-art methods. Our source code and supplementary appendix are available at https://github.com/RICE-EIC/Early-Bird-GCN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2103.00794v3</guid>
      <category>cs.LG</category>
      <category>cs.CV</category>
      <category>cs.SI</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Haoran You, Zhihan Lu, Zijian Zhou, Yonggan Fu, Yingyan Celine Lin</dc:creator>
    </item>
    <item>
      <title>Uncovering the Dark Side of Telegram: Fakes, Clones, Scams, and Conspiracy Movements</title>
      <link>https://arxiv.org/abs/2111.13530</link>
      <description>arXiv:2111.13530v3 Announce Type: replace-cross 
Abstract: Telegram is one of the most used instant messaging apps worldwide. Some of its success lies in providing high privacy protection and social network features like the channels -- virtual rooms in which only the admins can post and broadcast messages to all its subscribers. However, these same features contributed to the emergence of borderline activities and, as is common with Online Social Networks, the heavy presence of fake accounts. Telegram started to address these issues by introducing the verified and scam marks for the channels. Unfortunately, the problem is far from being solved. In this work, we perform a large-scale analysis of Telegram by collecting 35,382 different channels and over 130,000,000 messages. We study the channels that Telegram marks as verified or scam, highlighting analogies and differences. Then, we move to the unmarked channels. Here, we find some of the infamous activities also present on privacy-preserving services of the Dark Web, such as carding, sharing of illegal adult and copyright protected content. In addition, we identify and analyze two other types of channels: the clones and the fakes. Clones are channels that publish the exact content of another channel to gain subscribers and promote services. Instead, fakes are channels that attempt to impersonate celebrities or well-known services. Fakes are hard to identify even by the most advanced users. To detect the fake channels automatically, we propose a machine learning model that is able to identify them with an accuracy of 86%. Lastly, we study Sabmyk, a conspiracy theory that exploited fakes and clones to spread quickly on the platform reaching over 1,000,000 users.</description>
      <guid isPermaLink="false">oai:arXiv.org:2111.13530v3</guid>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Massimo La Morgia, Alessandro Mei, Alberto Maria Mongardini, Jie Wu</dc:creator>
    </item>
    <item>
      <title>Topological Point Cloud Clustering</title>
      <link>https://arxiv.org/abs/2303.16716</link>
      <description>arXiv:2303.16716v3 Announce Type: replace-cross 
Abstract: We present Topological Point Cloud Clustering (TPCC), a new method to cluster points in an arbitrary point cloud based on their contribution to global topological features. TPCC synthesizes desirable features from spectral clustering and topological data analysis and is based on considering the spectral properties of a simplicial complex associated to the considered point cloud. As it is based on considering sparse eigenvector computations, TPCC is similarly easy to interpret and implement as spectral clustering. However, by focusing not just on a single matrix associated to a graph created from the point cloud data, but on a whole set of Hodge-Laplacians associated to an appropriately constructed simplicial complex, we can leverage a far richer set of topological features to characterize the data points within the point cloud and benefit from the relative robustness of topological techniques against noise. We test the performance of TPCC on both synthetic and real-world data and compare it with classical spectral clustering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.16716v3</guid>
      <category>math.AT</category>
      <category>cs.CG</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>ICML 2023 - 40th International Conference on Machine Learning (ICML)</arxiv:journal_reference>
      <dc:creator>Vincent P. Grande, Michael T. Schaub</dc:creator>
    </item>
    <item>
      <title>Heterogeneous Graph Neural Network on Semantic Tree</title>
      <link>https://arxiv.org/abs/2402.13496</link>
      <description>arXiv:2402.13496v2 Announce Type: replace-cross 
Abstract: The recent past has seen an increasing interest in Heterogeneous Graph Neural Networks (HGNNs), since many real-world graphs are heterogeneous in nature, from citation graphs to email graphs. However, existing methods ignore a tree hierarchy among metapaths, naturally constituted by different node types and relation types. In this paper, we present HetTree, a novel HGNN that models both the graph structure and heterogeneous aspects in a scalable and effective manner. Specifically, HetTree builds a semantic tree data structure to capture the hierarchy among metapaths. To effectively encode the semantic tree, HetTree uses a novel subtree attention mechanism to emphasize metapaths that are more helpful in encoding parent-child relationships. Moreover, HetTree proposes carefully matching pre-computed features and labels correspondingly, constituting a complete metapath representation. Our evaluation of HetTree on a variety of real-world datasets demonstrates that it outperforms all existing baselines on open benchmarks and efficiently scales to large real-world graphs with millions of nodes and edges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.13496v2</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mingyu Guan, Jack W. Stokes, Qinlong Luo, Fuchen Liu, Purvanshi Mehta, Elnaz Nouri, Taesoo Kim</dc:creator>
    </item>
    <item>
      <title>Enhancing Fairness in Unsupervised Graph Anomaly Detection through Disentanglement</title>
      <link>https://arxiv.org/abs/2406.00987</link>
      <description>arXiv:2406.00987v2 Announce Type: replace-cross 
Abstract: Graph anomaly detection (GAD) is increasingly crucial in various applications, ranging from financial fraud detection to fake news detection. However, current GAD methods largely overlook the fairness problem, which might result in discriminatory decisions skewed toward certain demographic groups defined on sensitive attributes (e.g., gender, religion, ethnicity, etc.). This greatly limits the applicability of these methods in real-world scenarios in light of societal and ethical restrictions. To address this critical gap, we make the first attempt to integrate fairness with utility in GAD decision-making. Specifically, we devise a novel DisEntangle-based FairnEss-aware aNomaly Detection framework on the attributed graph, named DEFEND. DEFEND first introduces disentanglement in GNNs to capture informative yet sensitive-irrelevant node representations, effectively reducing societal bias inherent in graph representation learning. Besides, to alleviate discriminatory bias in evaluating anomalous nodes, DEFEND adopts a reconstruction-based anomaly detection, which concentrates solely on node attributes without incorporating any graph structure. Additionally, given the inherent association between input and sensitive attributes, DEFEND constrains the correlation between the reconstruction error and the predicted sensitive attributes. Our empirical evaluations on real-world datasets reveal that DEFEND performs effectively in GAD and significantly enhances fairness compared to state-of-the-art baselines. To foster reproducibility, our code is available at https://github.com/AhaChang/DEFEND.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00987v2</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenjing Chang, Kay Liu, Philip S. Yu, Jianjun Yu</dc:creator>
    </item>
    <item>
      <title>Grassroots Platforms with Atomic Transactions: Social Networks, Cryptocurrencies, and Democratic Federations</title>
      <link>https://arxiv.org/abs/2502.11299</link>
      <description>arXiv:2502.11299v2 Announce Type: replace-cross 
Abstract: Grassroots platforms aim to offer an egalitarian alternative to global platforms -- centralized/autocratic (Facebook etc.) and decentralized/plutocratic (Bitcoin etc.) alike. Key grassroots platforms include grassroots social networks, grassroots cryptocurrencies, and grassroots democratic federations. Previously, grassroots platforms were defined formally and proven grassroots using unary distributed transition systems, in which each transition is carried out by a single agent. However, grassroots platforms cater for a more abstract specification using transactions carried out atomically by multiple agents, something that cannot be expressed by unary transition systems. As a result, their original specifications and proofs were unnecessarily cumbersome and opaque.
  Here, we aim to provide a more suitable formal foundation for grassroots platforms. To do so, we enhance the notion of a distributed transition system to include atomic transactions and revisit the notion of grassroots platforms within this new foundation. We present crisp specifications of key grassroots platforms using atomic transactions: befriending and defriending for grassroots social networks, coin swaps for grassroots cryptocurrencies, and communities forming, joining, and leaving a federation for grassroots democratic federations. We prove a general theorem that a platform specified by atomic transactions that are so-called interactive is grassroots; show that the atomic transactions used to specify all three platforms are interactive; and conclude that the platforms thus specified are indeed grassroots. We thus provide a better mathematical foundation for grassroots platforms and a solid and clear starting point from which their implementation can commence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11299v2</guid>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <category>cs.SI</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ehud Shapiro</dc:creator>
    </item>
  </channel>
</rss>
