<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 30 Oct 2024 02:05:31 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Dimension reduction via score ratio matching</title>
      <link>https://arxiv.org/abs/2410.19990</link>
      <description>arXiv:2410.19990v1 Announce Type: new 
Abstract: Gradient-based dimension reduction decreases the cost of Bayesian inference and probabilistic modeling by identifying maximally informative (and informed) low-dimensional projections of the data and parameters, allowing high-dimensional problems to be reformulated as cheaper low-dimensional problems. A broad family of such techniques identify these projections and provide error bounds on the resulting posterior approximations, via eigendecompositions of certain diagnostic matrices. Yet these matrices require gradients or even Hessians of the log-likelihood, excluding the purely data-driven setting and many problems of simulation-based inference. We propose a framework, derived from score-matching, to extend gradient-based dimension reduction to problems where gradients are unavailable. Specifically, we formulate an objective function to directly learn the score ratio function needed to compute the diagnostic matrices, propose a tailored parameterization for the score ratio network, and introduce regularization methods that capitalize on the hypothesized low-dimensional structure. We also introduce a novel algorithm to iteratively identify the low-dimensional reduced basis vectors more accurately with limited data based on eigenvalue deflation methods. We show that our approach outperforms standard score-matching for problems with low-dimensional structure, and demonstrate its effectiveness for PDE-constrained Bayesian inverse problems and conditional generative modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19990v1</guid>
      <category>stat.CO</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ricardo Baptista, Michael Brennan, Youssef Marzouk</dc:creator>
    </item>
    <item>
      <title>CDsampling: an R Package for Constrained D-optimal Sampling in Paid Research Study</title>
      <link>https://arxiv.org/abs/2410.20606</link>
      <description>arXiv:2410.20606v1 Announce Type: new 
Abstract: In the context of paid research studies and clinical trials, budget considerations and patient sampling from available populations are subject to inherent constraints. We introduce the R package CDsampling, which is the first to our knowledge to integrate optimal design theories within the framework of constrained sampling. This package offers the possibility to find both D-optimal approximate and exact allocations for samplings with or without constraints. Additionally, it provides functions to find constrained uniform sampling as a robust sampling strategy when the model information is limited. To demonstrate its efficacy, we provide simulated examples and a real-data example with datasets embedded in the package and compare them with classical sampling methods. Furthermore, it revisits the theoretical results of the Fisher information matrix for generalized linear models (including regular linear regression model) and multinomial logistic models, offering functions for its computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20606v1</guid>
      <category>stat.CO</category>
      <category>stat.AP</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifei Huang, Liping Tong, Jie Yang</dc:creator>
    </item>
    <item>
      <title>Valid Bootstraps for Networks with Applications to Network Visualisation</title>
      <link>https://arxiv.org/abs/2410.20895</link>
      <description>arXiv:2410.20895v2 Announce Type: new 
Abstract: Quantifying uncertainty in networks is an important step in modelling relationships and interactions between entities. We consider the challenge of bootstrapping an inhomogeneous random graph when only a single observation of the network is made and the underlying data generating function is unknown. We utilise an exchangeable network test that can empirically validate bootstrap samples generated by any method, by testing if the observed and bootstrapped networks are statistically distinguishable. We find that existing methods fail this test. To address this, we propose a principled, novel, distribution-free network bootstrap using k-nearest neighbour smoothing, that can regularly pass this exchangeable network test in both synthetic and real-data scenarios. We demonstrate the utility of this work in combination with the popular data visualisation method t-SNE, where uncertainty estimates from bootstrapping are used to explain whether visible structures represent real statistically sound structures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20895v2</guid>
      <category>stat.CO</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emerald Dilworth, Ed Davis, Daniel J. Lawson</dc:creator>
    </item>
    <item>
      <title>Copula-Linked Parallel ICA: A Method for Coupling Structural and Functional MRI brain Networks</title>
      <link>https://arxiv.org/abs/2410.19774</link>
      <description>arXiv:2410.19774v1 Announce Type: cross 
Abstract: Different brain imaging modalities offer unique insights into brain function and structure. Combining them enhances our understanding of neural mechanisms. Prior multimodal studies fusing functional MRI (fMRI) and structural MRI (sMRI) have shown the benefits of this approach. Since sMRI lacks temporal data, existing fusion methods often compress fMRI temporal information into summary measures, sacrificing rich temporal dynamics. Motivated by the observation that covarying networks are identified in both sMRI and resting-state fMRI, we developed a novel fusion method, by combining deep learning frameworks, copulas and independent component analysis (ICA), named copula linked parallel ICA (CLiP-ICA). This method estimates independent sources for each modality and links the spatial sources of fMRI and sMRI using a copula-based model for more flexible integration of temporal and spatial data. We tested CLiP-ICA using data from the Alzheimer's Disease Neuroimaging Initiative (ADNI). Our results showed that CLiP-ICA effectively captures both strongly and weakly linked sMRI and fMRI networks, including the cerebellum, sensorimotor, visual, cognitive control, and default mode networks. It revealed more meaningful components and fewer artifacts, addressing the long-standing issue of optimal model order in ICA. CLiP-ICA also detected complex functional connectivity patterns across stages of cognitive decline, with cognitively normal subjects generally showing higher connectivity in sensorimotor and visual networks compared to patients with Alzheimer, along with patterns suggesting potential compensatory mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19774v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>stat.CO</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Oktay Agcaoglu (for the Alzheimers Disease Neuroimaging Initiative), Rogers F. Silva (for the Alzheimers Disease Neuroimaging Initiative), Deniz Alacam (for the Alzheimers Disease Neuroimaging Initiative), Sergey Plis (for the Alzheimers Disease Neuroimaging Initiative), Tulay Adali (for the Alzheimers Disease Neuroimaging Initiative), Vince Calhoun (for the Alzheimers Disease Neuroimaging Initiative)</dc:creator>
    </item>
    <item>
      <title>Sampling from Bayesian Neural Network Posteriors with Symmetric Minibatch Splitting Langevin Dynamics</title>
      <link>https://arxiv.org/abs/2410.19780</link>
      <description>arXiv:2410.19780v1 Announce Type: cross 
Abstract: We propose a scalable kinetic Langevin dynamics algorithm for sampling parameter spaces of big data and AI applications. Our scheme combines a symmetric forward/backward sweep over minibatches with a symmetric discretization of Langevin dynamics. For a particular Langevin splitting method (UBU), we show that the resulting Symmetric Minibatch Splitting-UBU (SMS-UBU) integrator has bias $O(h^2 d^{1/2})$ in dimension $d&gt;0$ with stepsize $h&gt;0$, despite only using one minibatch per iteration, thus providing excellent control of the sampling bias as a function of the stepsize. We apply the algorithm to explore local modes of the posterior distribution of Bayesian neural networks (BNNs) and evaluate the calibration performance of the posterior predictive probabilities for neural networks with convolutional neural network architectures for classification problems on three different datasets (Fashion-MNIST, Celeb-A and chest X-ray). Our results indicate that BNNs sampled with SMS-UBU can offer significantly better calibration performance compared to standard methods of training and stochastic weight averaging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19780v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Paulin, Peter A. Whalley, Neil K. Chada, Benedict Leimkuhler</dc:creator>
    </item>
    <item>
      <title>Low-rank Bayesian matrix completion via geodesic Hamiltonian Monte Carlo on Stiefel manifolds</title>
      <link>https://arxiv.org/abs/2410.20318</link>
      <description>arXiv:2410.20318v1 Announce Type: cross 
Abstract: We present a new sampling-based approach for enabling efficient computation of low-rank Bayesian matrix completion and quantifying the associated uncertainty. Firstly, we design a new prior model based on the singular-value-decomposition (SVD) parametrization of low-rank matrices. Our prior is analogous to the seminal nuclear-norm regularization used in non-Bayesian setting and enforces orthogonality in the factor matrices by constraining them to Stiefel manifolds. Then, we design a geodesic Hamiltonian Monte Carlo (-within-Gibbs) algorithm for generating posterior samples of the SVD factor matrices. We demonstrate that our approach resolves the sampling difficulties encountered by standard Gibbs samplers for the common two-matrix factorization used in matrix completion. More importantly, the geodesic Hamiltonian sampler allows for sampling in cases with more general likelihoods than the typical Gaussian likelihood and Gaussian prior assumptions adopted in most of the existing Bayesian matrix completion literature. We demonstrate an applications of our approach to fit the categorical data of a mice protein dataset and the MovieLens recommendation problem. Numerical examples demonstrate superior sampling performance, including better mixing and faster convergence to a stationary distribution. Moreover, they demonstrate improved accuracy on the two real-world benchmark problems we considered.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20318v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tiangang Cui, Alex Gorodetsky</dc:creator>
    </item>
    <item>
      <title>Refining CART Models for Covariate Shift with Importance Weight</title>
      <link>https://arxiv.org/abs/2410.20978</link>
      <description>arXiv:2410.20978v1 Announce Type: cross 
Abstract: Machine learning models often face challenges in medical applications due to covariate shifts, where discrepancies between training and target data distributions can decrease predictive accuracy. This paper introduces an adaptation of Classification and Regression Trees (CART) that incorporates importance weighting to address these distributional differences effectively. By assigning greater weight to training samples that closely represent the target distribution, our approach modifies the CART model to improve performance in the presence of covariate shift. We evaluate the effectiveness of this method through simulation studies and apply it to real-world medical data, showing significant improvements in predictive accuracy. The results indicate that this weighted CART approach can be valuable in medical and other fields where covariate shift poses challenges, enabling more reliable predictions across diverse data distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20978v1</guid>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mingyang Cai, Thomas Klausch, Mark A. van de Wiel</dc:creator>
    </item>
    <item>
      <title>funcharts: Control charts for multivariate functional data in R</title>
      <link>https://arxiv.org/abs/2207.09321</link>
      <description>arXiv:2207.09321v2 Announce Type: replace 
Abstract: Modern statistical process monitoring (SPM) applications focus on profile monitoring, i.e., the monitoring of process quality characteristics that can be modeled as profiles, also known as functional data. Despite the large interest in the profile monitoring literature, there is still a lack of software to facilitate its practical application. This article introduces the funcharts R package that implements recent developments on the SPM of multivariate functional quality characteristics, possibly adjusted by the influence of additional variables, referred to as covariates. The package also implements the real-time version of all control charting procedures to monitor profiles partially observed up to an intermediate domain point. The package is illustrated both through its built-in data generator and a real-case study on the SPM of Ro-Pax ship CO2 emissions during navigation, which is based on the ShipNavigation data provided in the Supplementary Material.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.09321v2</guid>
      <category>stat.CO</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christian Capezza, Fabio Centofanti, Antonio Lepore, Alessandra Menafoglio, Biagio Palumbo, Simone Vantini</dc:creator>
    </item>
    <item>
      <title>Scalable couplings for the random walk Metropolis algorithm</title>
      <link>https://arxiv.org/abs/2211.12585</link>
      <description>arXiv:2211.12585v3 Announce Type: replace 
Abstract: There has been a recent surge of interest in coupling methods for Markov chain Monte Carlo algorithms: they facilitate convergence quantification and unbiased estimation, while exploiting embarrassingly parallel computing capabilities. Motivated by these, we consider the design and analysis of couplings of the random walk Metropolis algorithm which scale well with the dimension of the target measure. Methodologically, we introduce a low-rank modification of the synchronous coupling that is provably optimally contractive in standard high-dimensional asymptotic regimes. We expose a shortcoming of the reflection coupling, the state of the art at the time of writing, and we propose a modification which mitigates the issue. Our analysis bridges the gap to the optimal scaling literature and builds a framework of asymptotic optimality which may be of independent interest. We illustrate the applicability of our proposed couplings, and the potential for extending our ideas, with various numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.12585v3</guid>
      <category>stat.CO</category>
      <category>math.PR</category>
      <category>stat.ME</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tam\'as P. Papp, Chris Sherlock</dc:creator>
    </item>
    <item>
      <title>MPCR: Multi- and Mixed-Precision Computations Package in R</title>
      <link>https://arxiv.org/abs/2406.02701</link>
      <description>arXiv:2406.02701v2 Announce Type: replace 
Abstract: Computational statistics has traditionally utilized double-precision (64-bit) data structures and full-precision operations, resulting in higher-than-necessary accuracy for certain applications. Recently, there has been a growing interest in exploring low-precision options that could reduce computational complexity while still achieving the required level of accuracy. This trend has been amplified by new hardware such as NVIDIA's Tensor Cores in their V100, A100, and H100 GPUs, which are optimized for mixed-precision computations, Intel CPUs with Deep Learning (DL) boost, Google Tensor Processing Units (TPUs), Field Programmable Gate Arrays (FPGAs), ARM CPUs, and others. However, using lower precision may introduce numerical instabilities and accuracy issues. Nevertheless, some applications have shown robustness to low-precision computations, leading to new multi- and mixed-precision algorithms that balance accuracy and computational cost. To address this need, we introduce MPCR, a novel R package that supports three different precision types (16-, 32-, and 64-bit) and their combinations, along with its usage in commonly-used Frequentist/Bayesian statistical examples. The MPCR package is written in C++ and integrated into R through the \pkg{Rcpp} package, enabling highly optimized operations in various precisions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02701v2</guid>
      <category>stat.CO</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mary Lai O. Salvana, Sameh Abdulah, Minwoo Kim, David Helmy, Ying Sun, Marc G. Genton</dc:creator>
    </item>
    <item>
      <title>A Fast Coordinate Descent Method for High-Dimensional Non-Negative Least Squares using a Unified Sparse Regression Framework</title>
      <link>https://arxiv.org/abs/2410.03014</link>
      <description>arXiv:2410.03014v2 Announce Type: replace 
Abstract: We develop theoretical results that establish a connection across various regression methods such as the non-negative least squares, bounded variable least squares, simplex constrained least squares, and lasso. In particular, we show in general that a polyhedron constrained least squares problem admits a locally unique sparse solution in high dimensions. We demonstrate the power of our result by concretely quantifying the sparsity level for the aforementioned methods. Furthermore, we propose a novel coordinate descent based solver for NNLS in high dimensions using our theoretical result as motivation. We show through simulated data and a real data example that our solver achieves at least a 5x speed-up from the state-of-the-art solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03014v2</guid>
      <category>stat.CO</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James Yang, Trevor Hastie</dc:creator>
    </item>
    <item>
      <title>A Short Note on the Efficiency of Markov Chains for Bayesian Linear Regression Models with Heavy-Tailed Errors</title>
      <link>https://arxiv.org/abs/2410.17070</link>
      <description>arXiv:2410.17070v3 Announce Type: replace-cross 
Abstract: In this short note, we consider posterior simulation for a linear regression model when the error distribution is given by a scale mixture of multivariate normals. We first show that the sampler of Backlund and Hobert (2020) for the case of the conditionally conjugate normal-inverse Wishart prior continues to be geometrically ergodic even when the error density is heavier-tailed. Moreover, we prove that the ergodicity is uniform by verifying the minorization condition. In the second half of this note, we treat an improper case and show that the sampler of Section 4 of Roy and Hobert (2010) is geometrically ergodic under significantly milder conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17070v3</guid>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yasuyuki Hamura</dc:creator>
    </item>
  </channel>
</rss>
