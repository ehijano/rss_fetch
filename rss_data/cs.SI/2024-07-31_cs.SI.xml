<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 01 Aug 2024 04:00:21 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 01 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Network and Sentiment Analysis of Enron Emails</title>
      <link>https://arxiv.org/abs/2407.21063</link>
      <description>arXiv:2407.21063v1 Announce Type: new 
Abstract: The objective of the research was to analyze e-mails exchanged at Enron, a power company that declared bankruptcy in 2001 following an investigation into unethical operations regarding their financials. Like other researchers, we identify the most important employees and detect communities using network science methods. We find that the importance of a person depends on the centrality measure used; while the communities we detected resembled the formal organizational structure of the company. In addition, because previous work required that 10 e-mails be sent and received for an e-mail relationship to exist, we analyzed the effect of different thresholds on the results and found that results were very dependent on the threshold used. We also performed sentiment analyses on the e-mails to evaluate whether sentiment changed over time and found that the sentiments of the e-mails do not give insight into the financial wellbeing of Enron. Our results provide insight into how information flowed through Enron, who the key employees were, and e-mail sentiment before and after the crisis</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21063v1</guid>
      <category>cs.SI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Natnael Belay</dc:creator>
    </item>
    <item>
      <title>Socio-cognitive Networks between Researchers</title>
      <link>https://arxiv.org/abs/2407.21067</link>
      <description>arXiv:2407.21067v1 Announce Type: new 
Abstract: Understanding why researchers cite each other has been a longstanding conjecture in studying scientific networks. Prior research suggests relevance, group cohesion, or honest source crediting as possible factors. However, the dual nature of cognitive and social dimensions underlying citation is often overlooked by not considering the intermediary steps leading up to a citation. For one work to be cited by another, it must first be published by a set of authors. Therefore, we investigate the reasons behind researchers' citations, explicitly examining the interplay of socio-cognitive ties through the interdependence of coauthorship and citation networks. We assess our claims in an empirical analysis by employing the Author-Oriented Relational HyperEvent Model (AuthRHEM) to study Chilean astronomers' citation and collaboration behavior between 2013 and 2015 in a joint framework. We find evidence that when deciding which work to cite, authors prefer other work with novelty and cognitive ties, such as work-to-work relations. At the same time, coherent groups are relevant because coauthors are cocited more frequently in subsequent publications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21067v1</guid>
      <category>cs.SI</category>
      <category>cs.DL</category>
      <category>physics.soc-ph</category>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alejandro Espinosa-Rada, J\"urgen Lerner, Cornelius Fritz</dc:creator>
    </item>
    <item>
      <title>Characterizing User Archetypes and Discussions on Scored.co</title>
      <link>https://arxiv.org/abs/2407.21753</link>
      <description>arXiv:2407.21753v1 Announce Type: new 
Abstract: In recent years, the proliferation of social platforms has drastically transformed the way individuals interact, organize, and share information. In this scenario, we experience an unprecedented increase in the scale and complexity of interactions and, at the same time, little to no research about some fringe social platforms. In this paper, we present a multi-dimensional framework for characterizing nodes and hyperedges in social hypernetworks, with a focus on the understudied alt-right platform Scored.co. Our approach integrates the possibility of studying higher-order interactions, thanks to the hypernetwork representation, and various node features such as user activity, sentiment, and toxicity, with the aim to define distinct user archetypes and understand their roles within the network. Utilizing a comprehensive dataset from Scored.co, we analyze the dynamics of these archetypes over time and explore their interactions and influence within the community. The framework's versatility allows for detailed analysis of both individual user behaviors and broader social structures. Our findings highlight the importance of higher-order interactions in understanding social dynamics, offering new insights into the roles and behaviors that emerge in complex online environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21753v1</guid>
      <category>cs.SI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrea Failla, Salvatore Citraro, Giulio Rossetti, Francesco Cauteruccio</dc:creator>
    </item>
    <item>
      <title>They Look Like Each Other: Case-based Reasoning for Explainable Depression Detection on Twitter using Large Language Models</title>
      <link>https://arxiv.org/abs/2407.21041</link>
      <description>arXiv:2407.21041v1 Announce Type: cross 
Abstract: Depression is a common mental health issue that requires prompt diagnosis and treatment. Despite the promise of social media data for depression detection, the opacity of employed deep learning models hinders interpretability and raises bias concerns. We address this challenge by introducing ProtoDep, a novel, explainable framework for Twitter-based depression detection. ProtoDep leverages prototype learning and the generative power of Large Language Models to provide transparent explanations at three levels: (i) symptom-level explanations for each tweet and user, (ii) case-based explanations comparing the user to similar individuals, and (iii) transparent decision-making through classification weights. Evaluated on five benchmark datasets, ProtoDep achieves near state-of-the-art performance while learning meaningful prototypes. This multi-faceted approach offers significant potential to enhance the reliability and transparency of depression detection on social media, ultimately aiding mental health professionals in delivering more informed care.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21041v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Mohammad Saeid Mahdavinejad, Peyman Adibi, Amirhassan Monadjemi, Pascal Hitzler</dc:creator>
    </item>
    <item>
      <title>What Matters in Explanations: Towards Explainable Fake Review Detection Focusing on Transformers</title>
      <link>https://arxiv.org/abs/2407.21056</link>
      <description>arXiv:2407.21056v1 Announce Type: cross 
Abstract: Customers' reviews and feedback play crucial role on electronic commerce~(E-commerce) platforms like Amazon, Zalando, and eBay in influencing other customers' purchasing decisions. However, there is a prevailing concern that sellers often post fake or spam reviews to deceive potential customers and manipulate their opinions about a product. Over the past decade, there has been considerable interest in using machine learning (ML) and deep learning (DL) models to identify such fraudulent reviews. Unfortunately, the decisions made by complex ML and DL models - which often function as \emph{black-boxes} - can be surprising and difficult for general users to comprehend. In this paper, we propose an explainable framework for detecting fake reviews with high precision in identifying fraudulent content with explanations and investigate what information matters most for explaining particular decisions by conducting empirical user evaluation. Initially, we develop fake review detection models using DL and transformer models including XLNet and DistilBERT. We then introduce layer-wise relevance propagation (LRP) technique for generating explanations that can map the contributions of words toward the predicted class. The experimental results on two benchmark fake review detection datasets demonstrate that our predictive models achieve state-of-the-art performance and outperform several existing methods. Furthermore, the empirical user evaluation of the generated explanations concludes which important information needs to be considered in generating explanations in the context of fake review identification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21056v1</guid>
      <category>cs.CL</category>
      <category>cs.IR</category>
      <category>cs.SI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Md Shajalal, Md Atabuzzaman, Alexander Boden, Gunnar Stevens, Delong Du</dc:creator>
    </item>
    <item>
      <title>Decentralized and Uncoordinated Learning of Stable Matchings: A Game-Theoretic Approach</title>
      <link>https://arxiv.org/abs/2407.21294</link>
      <description>arXiv:2407.21294v1 Announce Type: cross 
Abstract: We consider the problem of learning stable matchings in a fully decentralized and uncoordinated manner. In this problem, there are $n$ men and $n$ women, each having preference over the other side. It is assumed that women know their preferences over men, but men are not aware of their preferences over women, and they only learn them if they propose and successfully get matched to women. A matching is called stable if no man and woman prefer each other over their current matches. When all the preferences are known a priori, the celebrated Deferred-Acceptance algorithm proposed by Gale and Shapley provides a decentralized and uncoordinated algorithm to obtain a stable matching. However, when the preferences are unknown, developing such an algorithm faces major challenges due to a lack of coordination. We achieve this goal by making a connection between stable matchings and learning Nash equilibria (NE) in noncooperative games. First, we provide a complete information game formulation for the stable matching problem with known preferences such that its set of pure NE coincides with the set of stable matchings, while its mixed NE can be rounded in a decentralized manner to a stable matching. Relying on such a game-theoretic formulation, we show that for hierarchical markets, adopting the exponential weight (EXP) learning algorithm for the stable matching game achieves logarithmic regret with polynomial dependence on the number of players, thus answering a question posed in previous literature. Moreover, we show that the same EXP learning algorithm converges locally and exponentially fast to a stable matching in general matching markets. We complement this result by introducing another decentralized and uncoordinated learning algorithm that globally converges to a stable matching with arbitrarily high probability, leveraging the weak acyclicity property of the stable matching game.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21294v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>cs.SI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>S. Rasoul Etesami, R. Srikant</dc:creator>
    </item>
    <item>
      <title>Does the Source of a Warning Matter? Examining the Effectiveness of Veracity Warning Labels Across Warners</title>
      <link>https://arxiv.org/abs/2407.21592</link>
      <description>arXiv:2407.21592v1 Announce Type: cross 
Abstract: In this study, we conducted an online, between-subjects experiment (N = 2,049) to better understand the impact of warning label sources on information trust and sharing intentions. Across four warners (the social media platform, other social media users, Artificial Intelligence (AI), and fact checkers), we found that all significantly decreased trust in false information relative to control, but warnings from AI were modestly more effective. All warners significantly decreased the sharing intentions of false information, except warnings from other social media users. AI was again the most effective. These results were moderated by prior trust in media and the information itself. Most noteworthy, we found that warning labels from AI were significantly more effective than all other warning labels for participants who reported a low trust in news organizations, while warnings from AI were no more effective than any other warning label for participants who reported a high trust in news organizations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21592v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.SI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benjamin D. Horne</dc:creator>
    </item>
    <item>
      <title>Endogenous Coalition Formation in Policy Debates</title>
      <link>https://arxiv.org/abs/1904.05327</link>
      <description>arXiv:1904.05327v2 Announce Type: replace 
Abstract: Political actors form coalitions around their joint normative beliefs in order to influence the policy process on contentious issues such as climate change or population ageing. Policy process theory maintains that learning within and across coalitions is a central predictor of coalition formation and policy change but has yet to explain how policy learning works. The present article explains the formation and maintenance of coalitions by focusing on the ways actors adopt policy beliefs from other actors in policy debates. A policy debate is a complex social system in which temporal network dependence guides how actors contribute ideological statements to the debate. Belief adoption matters in three complementary ways: bonding, which exploits cues within coalitions; bridging, which explores new beliefs outside one's perimeter in the debate; and repulsion, which reinforces polarization between coalitions and cements their belief systems. We formalize this theory of endogenous coalition formation in policy debates and test it on a micro-level empirical dataset using statistical network analysis and event history analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:1904.05327v2</guid>
      <category>cs.SI</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Philip Leifeld, Laurence Brandenberger</dc:creator>
    </item>
    <item>
      <title>Disentangled Condensation for Large-scale Graphs</title>
      <link>https://arxiv.org/abs/2401.12231</link>
      <description>arXiv:2401.12231v2 Announce Type: replace 
Abstract: Graph condensation has emerged as an intriguing technique to save the expensive training costs of Graph Neural Networks (GNNs) by substituting a condensed small graph with the original graph. Despite the promising results achieved, previous methods usually employ an entangled paradigm of redundant parameters (nodes, edges, GNNs), which incurs complex joint optimization during condensation. This paradigm has considerably impeded the scalability of graph condensation, making it challenging to condense extremely large-scale graphs and generate high-fidelity condensed graphs. Therefore, we propose to disentangle the condensation process into a two-stage GNN-free paradigm, independently condensing nodes and generating edges while eliminating the need to optimize GNNs at the same time. The node condensation module avoids the complexity of GNNs by focusing on node feature alignment with anchors of the original graph, while the edge translation module constructs the edges of the condensed nodes by transferring the original structure knowledge with neighborhood anchors. This simple yet effective approach achieves at least 10 times faster than state-of-the-art methods with comparable accuracy on medium-scale graphs. Moreover, the proposed DisCo can successfully scale up to the Ogbn-papers100M graph with flexible reduction rates. Extensive downstream tasks and ablation study on five common datasets further demonstrate the effectiveness of the proposed DisCo framework. The source code will be made publicly available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.12231v2</guid>
      <category>cs.SI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhenbang Xiao, Shunyu Liu, Yu Wang, Tongya Zheng, Mingli Song</dc:creator>
    </item>
    <item>
      <title>Mapping Literary Space: A Social Network from the Timeline of Cultural Events</title>
      <link>https://arxiv.org/abs/2406.11907</link>
      <description>arXiv:2406.11907v2 Announce Type: replace 
Abstract: This study applies social network analysis (SNA) to map and analyze literary networks in St Petersburg from 1999 to 2019, using data from the 'SPbLitGuide' newsletter. By examining co-participation in literary events, we reveal the dynamics and structures of these networks, identifying key communities and influential figures. Our network graph, consisting of 14,066 nodes and 127,068 edges, represents a highly interconnected and cohesive small-world network with robust local clustering and extensive collaboration. Focusing on core participants, we refined the graph and applied community detection methods to identify distinct groups with specific aesthetic preferences and personal connections. These findings provide insights into the structure and dynamics of literary groups in St. Petersburg and provide a foundation for further research in the digital humanities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.11907v2</guid>
      <category>cs.SI</category>
      <category>cs.DL</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maria Levchenko</dc:creator>
    </item>
    <item>
      <title>Medfluencer: A Network Representation of Medical Influencers' Identities and Discourse on Social Media</title>
      <link>https://arxiv.org/abs/2407.05198</link>
      <description>arXiv:2407.05198v2 Announce Type: replace 
Abstract: In our study, we first constructed a dataset from the tweets of the top 100 medical influencers with the highest Influencer Score during the COVID-19 pandemic. This dataset was then used to construct a socio-semantic network, mapping both their identities and key topics, which are crucial for understanding their impact on public health discourse. To achieve this, we developed a few-shot multi-label classifier to identify influencers and their network actors' identities, employed BERTopic for extracting thematic content, and integrated these components into a network model to analyze their impact on health discourse. To ensure the reproducibility of our results, we have made the code available at https://github.com/ZhijinGuo/Medinfluencer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05198v2</guid>
      <category>cs.SI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhijin Guo, Edwin Simpson, Roberta Bernardi</dc:creator>
    </item>
    <item>
      <title>In-class Data Analysis Replications: Teaching Students while Testing Science</title>
      <link>https://arxiv.org/abs/2308.16491</link>
      <description>arXiv:2308.16491v2 Announce Type: replace-cross 
Abstract: Science is facing a reproducibility crisis. Previous work has proposed incorporating data analysis replications into classrooms as a potential solution. However, despite the potential benefits, it is unclear whether this approach is feasible, and if so, what the involved stakeholders-students, educators, and scientists-should expect from it. Can students perform a data analysis replication over the course of a class? What are the costs and benefits for educators? And how can this solution help benchmark and improve the state of science?
  In the present study, we incorporated data analysis replications in the project component of the Applied Data Analysis course (CS-401) taught at EPFL (N=354 students). Here we report pre-registered findings based on surveys administered throughout the course. First, we demonstrate that students can replicate previously published scientific papers, most of them qualitatively and some exactly. We find discrepancies between what students expect of data analysis replications and what they experience by doing them along with changes in expectations about reproducibility, which together serve as evidence of attitude shifts to foster students' critical thinking. Second, we provide information for educators about how much overhead is needed to incorporate replications into the classroom and identify concerns that replications bring as compared to more traditional assignments. Third, we identify tangible benefits of the in-class data analysis replications for scientific communities, such as a collection of replication reports and insights about replication barriers in scientific work that should be avoided going forward.
  Overall, we demonstrate that incorporating replication tasks into a large data science class can increase the reproducibility of scientific work as a by-product of data science instruction, thus benefiting both science and students.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.16491v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kristina Gligoric, Tiziano Piccardi, Jake Hofman, Robert West</dc:creator>
    </item>
    <item>
      <title>Evolutionary game selection creates cooperative environments</title>
      <link>https://arxiv.org/abs/2311.11128</link>
      <description>arXiv:2311.11128v2 Announce Type: replace-cross 
Abstract: The emergence of collective cooperation in competitive environments is a well-known phenomenon in biology, economics, and social systems. While most evolutionary game models focus on the evolution of strategies for a fixed game, how strategic decisions coevolve with the environment has so far mostly been overlooked. Here, we consider a game selection model where not only the strategies but also the game can change over time following evolutionary principles. Our results show that coevolutionary dynamics of games and strategies can induce novel collective phenomena, fostering the emergence of cooperative environments. When the model is taken on structured populations the architecture of the interaction network can significantly amplify pro-social behavior, with a critical role played by network heterogeneity and the presence of clustered groups of similar players, distinctive features observed in real-world populations. By unveiling the link between the evolution of strategies and games for different structured populations, our model sheds new light on the origin of social dilemmas ubiquitously observed in real-world social systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.11128v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.GT</category>
      <category>cs.SI</category>
      <category>math.DS</category>
      <category>q-bio.PE</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1103/PhysRevE.110.014306</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. E 110, 014306 (2024)</arxiv:journal_reference>
      <dc:creator>Onkar Sadekar, Andrea Civilini, Jes\'us G\'omez-Garde\~nes, Vito Latora, Federico Battiston</dc:creator>
    </item>
    <item>
      <title>A Survey on Self-Supervised Graph Foundation Models: Knowledge-Based Perspective</title>
      <link>https://arxiv.org/abs/2403.16137</link>
      <description>arXiv:2403.16137v2 Announce Type: replace-cross 
Abstract: Graph self-supervised learning (SSL) is now a go-to method for pre-training graph foundation models (GFMs). There is a wide variety of knowledge patterns embedded in the graph data, such as node properties and clusters, which are crucial to learning generalized representations for GFMs. However, existing surveys of GFMs have several shortcomings: they lack comprehensiveness regarding the most recent progress, have unclear categorization of self-supervised methods, and take a limited architecture-based perspective that is restricted to only certain types of graph models. As the ultimate goal of GFMs is to learn generalized graph knowledge, we provide a comprehensive survey of self-supervised GFMs from a novel knowledge-based perspective. We propose a knowledge-based taxonomy, which categorizes self-supervised graph models by the specific graph knowledge utilized. Our taxonomy consists of microscopic (nodes, links, etc.), mesoscopic (context, clusters, etc.), and macroscopic knowledge (global structure, manifolds, etc.). It covers a total of 9 knowledge categories and more than 25 pretext tasks for pre-training GFMs, as well as various downstream task generalization strategies. Such a knowledge-based taxonomy allows us to re-examine graph models based on new architectures more clearly, such as graph language models, as well as provide more in-depth insights for constructing GFMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16137v2</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziwen Zhao, Yixin Su, Yuhua Li, Yixiong Zou, Ruixuan Li, Rui Zhang</dc:creator>
    </item>
    <item>
      <title>FTF-ER: Feature-Topology Fusion-Based Experience Replay Method for Continual Graph Learning</title>
      <link>https://arxiv.org/abs/2407.19429</link>
      <description>arXiv:2407.19429v2 Announce Type: replace-cross 
Abstract: Continual graph learning (CGL) is an important and challenging task that aims to extend static GNNs to dynamic task flow scenarios. As one of the mainstream CGL methods, the experience replay (ER) method receives widespread attention due to its superior performance. However, existing ER methods focus on identifying samples by feature significance or topological relevance, which limits their utilization of comprehensive graph data. In addition, the topology-based ER methods only consider local topological information and add neighboring nodes to the buffer, which ignores the global topological information and increases memory overhead. To bridge these gaps, we propose a novel method called Feature-Topology Fusion-based Experience Replay (FTF-ER) to effectively mitigate the catastrophic forgetting issue with enhanced efficiency. Specifically, from an overall perspective to maximize the utilization of the entire graph data, we propose a highly complementary approach including both feature and global topological information, which can significantly improve the effectiveness of the sampled nodes. Moreover, to further utilize global topological information, we propose Hodge Potential Score (HPS) as a novel module to calculate the topological importance of nodes. HPS derives a global node ranking via Hodge decomposition on graphs, providing more accurate global topological information compared to neighbor sampling. By excluding neighbor sampling, HPS significantly reduces buffer storage costs for acquiring topological information and simultaneously decreases training time. Compared with state-of-the-art methods, FTF-ER achieves a significant improvement of 3.6% in AA and 7.1% in AF on the OGB-Arxiv dataset, demonstrating its superior performance in the class-incremental learning setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.19429v2</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3664647.3681457</arxiv:DOI>
      <dc:creator>Jinhui Pang, Changqing Lin, Xiaoshuai Hao, Rong Yin, Zixuan Wang, Zhihui Zhang, Jinglin He, Huang Tai Sheng</dc:creator>
    </item>
  </channel>
</rss>
