<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 04 Dec 2024 05:00:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Linear Reduction and Homotopy Control for Steady Drift-Diffusion Systems in Narrow Convex Domains</title>
      <link>https://arxiv.org/abs/2412.01918</link>
      <description>arXiv:2412.01918v1 Announce Type: new 
Abstract: This article develops and applies results, originally introduced in earlier work, for the existence of homotopy curves, terminating at a desired solution. We describe the principal hypotheses and results in section two; right inverse approximation is at the core of the theory. We apply this theory in section three to the basic drift-diffusion equations. The carrier densities are not assumed to satisfy Boltzmann statistics and the Einstein relations are not assumed. By proving the existence of the homotopy curve, we validate the underlying computational framework of a predictor/corrector scheme, where the corrector utilizes an approximate Newton method. The analysis depends on the assumption of domains of narrow width. However, no assumption is made regarding the domain diameter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01918v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joseph W. Jerome</dc:creator>
    </item>
    <item>
      <title>Machine learning-based moment closure model for the semiconductor Boltzmann equation with uncertainties</title>
      <link>https://arxiv.org/abs/2412.01932</link>
      <description>arXiv:2412.01932v1 Announce Type: new 
Abstract: In this paper, we propose a machine learning (ML)-based moment closure model for the linearized Boltzmann equation of semiconductor devices, addressing both the deterministic and stochastic settings. Our approach leverages neural networks to learn the spatial gradient of the unclosed highest-order moment, enabling effective training through natural output normalization. For the deterministic problem, to ensure global hyperbolicity and stability, we derive and apply the constraints that enforce symmetrizable hyperbolicity of the system. For the stochastic problem, we adopt the generalized polynomial chaos (gPC)-based stochastic Galerkin method to discretize the random variables, resulting in a system for which the approach in the deterministic case can be used similarly. Several numerical experiments will be shown to demonstrate the effectiveness and accuracy of our ML-based moment closure model for the linear semiconductor Boltzmann equation with (or without) uncertainties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01932v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Juntao Huang, Liu Liu, Kunlun Qi, Jiayu Wan</dc:creator>
    </item>
    <item>
      <title>A Simple Channel Compression Method for Brain Signal Decoding on Classification Task</title>
      <link>https://arxiv.org/abs/2412.02078</link>
      <description>arXiv:2412.02078v1 Announce Type: new 
Abstract: In the application of brain-computer interface (BCI), while pursuing accurate decoding of brain signals, we also need consider the computational efficiency of BCI devices. ECoG signals are multi-channel temporal signals which is collected using a high-density electrode array at a high sampling frequency. The data between channels has a high similarity or redundancy in the temporal domain. The redundancy of data not only reduces the computational efficiency of the model, but also overwhelms the extraction of effective features, resulting in a decrease in performance. How to efficiently utilize ECoG multi-channel signals is one of the research topics. Effective channel screening or compression can greatly reduce the model size, thereby improving computational efficiency, this would be a good direction to solve the problem. Based on previous work [1], this paper proposes a very simple channel compression method, which uses a learnable matrix to perform matrix multiplication on the original channels, that is, assigning weights to the channels and then linearly add them up. This effectively reduces the number of final channels. In the experiment, we used the vision-based ECoG multi-classification dataset owned by our laboratory to test the proposed channel selection (compression) method. We found that the new method can compress the original 128-channel ECoG signal to 32 channels (of which subject MonJ is compressed to 8 channels), greatly reducing the size of the model. The demand for GPU memory resources during model training is reduced by about 68.57%, 84.33% for each subject respectively; the model training speed also increased up around 3.82, 4.65 times of the original speed for each subject respectively. More importantly, the performance of the model has improved by about 1.10% compared with our previous work, reached the SOTA level of our unique visual based ECoG dataset</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02078v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Changqing Ji, Keisuke Kawasaki, Isao Hasegawa, Takayuki Okatani</dc:creator>
    </item>
    <item>
      <title>AAROC: Reduced Over-Collocation Method with Adaptive Time Partitioning and Adaptive Enrichment for Parametric Time-Dependent Equations</title>
      <link>https://arxiv.org/abs/2412.02152</link>
      <description>arXiv:2412.02152v1 Announce Type: new 
Abstract: Nonlinear and nonaffine terms in parametric partial differential equations can potentially lead to a computational cost of a reduced order model (ROM) that is comparable to the cost of the original full order model (FOM). To address this, the Reduced Residual Reduced Over-Collocation method (R2-ROC) is developed as a hyper-reduction method within the framework of the reduced basis method in the collocation setting. R2-ROC greedily selects two sets of reduced collocation points based on the (generalized) empirical interpolation method for both solution snapshots and residuals, thereby avoiding the computational inefficiency. The vanilla R2-ROC method can face instability when applied to parametric fluid dynamic problems. To address this, an adaptive enrichment strategy has been proposed to stabilize the ROC method. However, this strategy can involve in an excessive number of reduced collocation points, thereby negatively impacting online efficiency.
  To ensure both efficiency and accuracy, we propose an adaptive time partitioning and adaptive enrichment strategy-based ROC method (AAROC). The adaptive time partitioning dynamically captures the low-rank structure, necessitating fewer reduced collocation points being sampled in each time segment. Numerical experiments on the parametric viscous Burgers' equation and lid-driven cavity problems demonstrate the efficiency, enhanced stability, and accuracy of the proposed AAROC method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02152v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.flu-dyn</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lijie Ji, Zhichao Peng, Yanlai Chen</dc:creator>
    </item>
    <item>
      <title>Weighted Essentially Non-Oscillatory Shepard method</title>
      <link>https://arxiv.org/abs/2412.02286</link>
      <description>arXiv:2412.02286v1 Announce Type: new 
Abstract: Shepard method is a fast algorithm that has been classically used to interpolate scattered data in several dimensions. This is an important and well-known technique in numerical analysis founded in the main idea that data that is far away from the approximation point should contribute less to the resulting approximation. Approximating piecewise smooth functions in $\mathbb{R}^n$ near discontinuities along a hypersurface in $\mathbb{R}^{n-1}$ is challenging for the Shepard method or any other linear technique for sparse data due to the inherent difficulty in accurately capturing sharp transitions and avoiding oscillations. This letter is devoted to constructing a non-linear Shepard method using the basic ideas that arise from the weighted essentially non-oscillatory interpolation method (WENO). The proposed method aims to enhance the accuracy and stability of the traditional Shepard method by incorporating WENO's adaptive and nonlinear weighting mechanism. To address this challenge, we will nonlinearly modify the weight function in a general Shepard method, considering any weight function, rather than relying solely on the inverse of the distance squared. This approach effectively reduces oscillations near discontinuities and improves the overall interpolation quality. Numerical experiments demonstrate the superior performance of the new method in handling complex datasets, making it a valuable tool for various applications in scientific computing and data analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02286v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Levin, Jos\'e M. Ram\'on, Juan Ruiz-Alvarez, Dionisio F. Y\'a\~nez</dc:creator>
    </item>
    <item>
      <title>Data dependent Moving Least Squares</title>
      <link>https://arxiv.org/abs/2412.02304</link>
      <description>arXiv:2412.02304v1 Announce Type: new 
Abstract: In this paper, we address a data dependent modification of the moving least squares (MLS) problem. We propose a novel approach by replacing the traditional weight functions with new functions that assign smaller weights to nodes that are close to discontinuities, while still assigning smaller weights to nodes that are far from the point of approximation. Through this adjustment, we are able to mitigate the undesirable Gibbs phenomenon that appears close to the discontinuities in the classical MLS approach, and reduce the smearing of discontinuities in the final approximation of the original data. The core of our method involves accurately identifying those nodes affected by the presence of discontinuities using smoothness indicators, a concept derived from the data-dependent WENO method. Our formulation results in a data-dependent weighted least squares problem where the weights depend on two factors: the distances between nodes and the point of approximation, and the smoothness of the data in a region of predetermined radius around the nodes. We explore the design of the new data-dependent approximant, analyze its properties including polynomial reproduction, accuracy, and smoothness, and study its impact on diffusion and the Gibbs phenomenon. Numerical experiments are conducted to validate the theoretical findings, and we conclude with some insights and potential directions for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02304v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Levin, Jos\'e M. Ram\'on, Juan Ruiz-Alvarez, Dionisio F. Y\'a\~nez</dc:creator>
    </item>
    <item>
      <title>Hanke-Raus heuristic rule for iteratively regularized stochastic gradient descent</title>
      <link>https://arxiv.org/abs/2412.02397</link>
      <description>arXiv:2412.02397v1 Announce Type: new 
Abstract: In this work, we present a novel variant of the stochastic gradient descent method termed as iteratively regularized stochastic gradient descent (IRSGD) method to solve nonlinear ill-posed problems in Hilbert spaces. Under standard assumptions, we demonstrate that the mean square iteration error of the method converges to zero for exact data. In the presence of noisy data, we first propose a heuristic parameter choice rule (HPCR) based on the method suggested by Hanke and Raus, and then apply the IRSGD method in combination with HPCR. Precisely, HPCR selects the regularization parameter without requiring any a-priori knowledge of the noise level. We show that the method terminates in finitely many steps in case of noisy data and has regularizing features. Further, we discuss the convergence rates of the method using well-known source and other related conditions under HPCR as well as discrepancy principle. To the best of our knowledge, this is the first work that establishes both the regularization properties and convergence rates of a stochastic gradient method using a heuristic type rule in the setting of infinite-dimensional Hilbert spaces. Finally, we provide the numerical experiments to showcase the practical efficacy of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02397v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.CA</category>
      <category>math.FA</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Harshit Bajpai, Gaurav Mittal, Ankik Kumar Giri</dc:creator>
    </item>
    <item>
      <title>Efficient parallel inversion of ParaOpt preconditioners</title>
      <link>https://arxiv.org/abs/2412.02425</link>
      <description>arXiv:2412.02425v1 Announce Type: new 
Abstract: Recently, the ParaOpt algorithm was proposed as an extension of the time-parallel Parareal method to optimal control. ParaOpt uses quasi-Newton steps that each require solving a system of matching conditions iteratively. The state-of-the-art parallel preconditioner for linear problems leads to a set of independent smaller systems that are currently hard to solve. We generalize the preconditioner to the nonlinear case and propose a new, fast inversion method for these smaller systems, avoiding disadvantages of the current options with adjusted boundary conditions in the subproblems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02425v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Corentin Bonte, Arne Bouillon, Giovanni Samaey, Karl Meerbergen</dc:creator>
    </item>
    <item>
      <title>Numerical approaches to compute spectra of non-self adjoint operators in dimensions two and three</title>
      <link>https://arxiv.org/abs/2412.02465</link>
      <description>arXiv:2412.02465v1 Announce Type: new 
Abstract: In this article we are interested for the numerical computation of spectra of non-self adjoint quadratic operators, in two and three spatial dimensions. Indeed, in the multidimensional case very few results are known on the location of the eignevalues. This leads to solve nonlinear eigenvalue problems. In introduction we begin with a review of theoretical results and numerical results obtained for the one dimensional case. Then we present the numerical methods developed to compute the spectra (finite difference discretization) for the two and three dimensional cases. The numerical results obtained are presented and analyzed. One difficulty here is that we have to compute eigenvalues of strongly non-self-adjoint operators which are unstable. This work is in continuity of a previous work in one spatial dimension.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02465v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Fatima Aboud, Fran\c{c}ois Jauberteau, Didier Robert</dc:creator>
    </item>
    <item>
      <title>Exact discretization, tight frames and recovery via D-optimal designs</title>
      <link>https://arxiv.org/abs/2412.02489</link>
      <description>arXiv:2412.02489v1 Announce Type: new 
Abstract: $D$-optimal designs originate in statistics literature as an approach for optimal experimental designs. In numerical analysis points and weights resulting from maximal determinants turned out to be useful for quadrature and interpolation. Also recently, two of the present authors and coauthors investigated a connection to the discretization problem for the uniform norm. Here we use this approach of maximizing the determinant of a certain Gramian matrix with respect to points and weights for the construction of tight frames and exact Marcinkiewicz-Zygmund inequalities in $L_2$. We present a direct and constructive approach resulting in a discrete measure with at most $N \leq n^2+1$ atoms, which discretely and accurately subsamples the $L_2$-norm of complex-valued functions contained in a given $n$-dimensional subspace. This approach can as well be used for the reconstruction of functions from general RKHS in $L_2$ where one only has access to the most important eigenfunctions. We verifiably and deterministically construct points and weights for a weighted least squares recovery procedure and pay in the rate of convergence compared to earlier optimal, however probabilistic approaches. The general results apply to the $d$-sphere or multivariate trigonometric polynomials on $\mathbb{T}^d$ spectrally supported on arbitrary finite index sets~$I \subset \mathbb{Z}^d$. They can be discretized using at most $|I|^2-|I|+1$ points and weights. Numerical experiments indicate the sharpness of this result. As a negative result we prove that, in general, it is not possible to control the number of points in a reconstructing lattice rule only in the cardinality $|I|$ without additional condition on the structure of $I$. We support our findings with numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02489v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Felix Bartel, Lutz K\"ammerer, Kateryna Pozharska, Martin Sch\"afer, Tino Ullrich</dc:creator>
    </item>
    <item>
      <title>Quasi-optimal interpolation of gradients and vector-fields on protected Delaunay meshes in $\mathbb{R}^d$</title>
      <link>https://arxiv.org/abs/2412.02551</link>
      <description>arXiv:2412.02551v1 Announce Type: new 
Abstract: There are very few mathematical results governing the interpolation of functions or their gradients on Delaunay meshes in more than two dimensions. Unfortunately, the standard techniques for proving optimal interpolation properties are often limited to triangular meshes. Furthermore, the results which do exist, are tailored towards interpolation with piecewise linear polynomials. In fact, we are unaware of any results which govern the high-order, piecewise polynomial interpolation of functions or their gradients on Delaunay meshes. In order to address this issue, we prove that quasi-optimal, high-order, piecewise polynomial gradient interpolation can be successfully achieved on protected Delaunay meshes. In addition, we generalize our analysis beyond gradient interpolation, and prove quasi-optimal interpolation properties for sufficiently-smooth vector fields. Throughout the paper, we use the words 'quasi-optimal', because the quality of interpolation depends (in part) on the minimum thickness of simplicies in the mesh. Fortunately, the minimum thickness can be precisely controlled on protected Delaunay meshes in $\mathbb{R}^d$. Furthermore, the current best mathematical estimates for minimum thickness have been obtained on such meshes. In this sense, the proposed interpolation is optimal, although, we acknowledge that future work may reveal an alternative Delaunay meshing strategy with better control over the minimum thickness. With this caveat in mind, we refer to our interpolation on protected Delaunay meshes as quasi-optimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02551v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David M. Williams, Mathijs Wintraecken</dc:creator>
    </item>
    <item>
      <title>Properties of median-dual regions on triangulations in $\mathbb{R}^{4}$ with extensions to higher dimensions</title>
      <link>https://arxiv.org/abs/2412.02555</link>
      <description>arXiv:2412.02555v1 Announce Type: new 
Abstract: Many time-dependent problems in the field of computational fluid dynamics can be solved in a four-dimensional space-time setting. However, such problems are computationally expensive to solve using modern high-order numerical methods. In order to address this issue, efficient, node-centered edge-based schemes are currently being developed. In these schemes, a median-dual tessellation of the space-time domain is constructed based on an initial triangulation. Unfortunately, it is not straightforward to construct median-dual regions or deduce their properties on triangulations for $d \geq 4$. In this work, we provide the first rigorous definition of median-dual regions on triangulations in any number of dimensions. In addition, we present the first methods for calculating the geometric properties of these dual regions. We introduce a new method for computing the hypervolume of a median-dual region in $\mathbb{R}^d$. Furthermore, we provide a new approach for computing the directed-hyperarea vectors for facets of a median-dual region in $\mathbb{R}^{4}$. These geometric properties are key for facilitating the construction of node-centered edge-based schemes in higher dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02555v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David M. Williams, Hiroaki Nishikawa</dc:creator>
    </item>
    <item>
      <title>Adaptive Neural Network Subspace Method for Solving Partial Differential Equations with High Accuracy</title>
      <link>https://arxiv.org/abs/2412.02586</link>
      <description>arXiv:2412.02586v1 Announce Type: new 
Abstract: Based on neural network and adaptive subspace approximation method, we propose a new machine learning method for solving partial differential equations. The neural network is adopted to build the basis of the finite dimensional subspace. Then the discrete solution is obtained by using the subspace approximation. Especially, based on the subspace approximation, a posteriori error estimator can be derivated by the hypercircle technique. This a posteriori error estimator can act as the loss function for adaptively refining the parameters of neural network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02586v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zhongshuo Lin, Yifan Wang, Hehu Xie</dc:creator>
    </item>
    <item>
      <title>Randomized algorithms for Kroncecker tensor decomposition and applications</title>
      <link>https://arxiv.org/abs/2412.02597</link>
      <description>arXiv:2412.02597v1 Announce Type: new 
Abstract: This paper proposes fast randomized algorithms for computing the Kronecker Tensor Decomposition (KTD). The proposed algorithms can decompose a given tensor into the KTD format much faster than the existing state-of-the-art algorithms. Our principal idea is to use the randomization framework to reduce computational complexity significantly. We provide extensive simulations to verify the effectiveness and performance of the proposed randomized algorithms with several orders of magnitude acceleration compared to the deterministic one. Our simulations use synthetics and real-world datasets with applications to tensor completion, video/image compression, image denoising, and image super-resolution</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02597v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Salman Ahmadi-Asl, Naeim Rezaeian, Andre L. F. de Almeida, Yipeng Liu</dc:creator>
    </item>
    <item>
      <title>Efficient Algorithms for Low Tubal Rank Tensor Approximation with Applications to Image Compression, Super-Resolution and Deep Learning</title>
      <link>https://arxiv.org/abs/2412.02598</link>
      <description>arXiv:2412.02598v1 Announce Type: new 
Abstract: In this paper we propose efficient randomized fixed-precision techniques for low tubal rank approximation of tensors. The proposed methods are faster and more efficient than the existing fixed-precision algorithms for approximating the truncated tensor SVD (T-SVD). Besides, there are a few works on randomized single-pass algorithms for computing low tubal rank approximation of tensors, none of them experimentally reports the robustness of such algorithms for low-rank approximation of real-world data tensors e.g., images and videos. The current single-pass algorithms for tensors are generalizations of those developed for matrices to tensors. However, the single-pass randomized algorithms for matrices have been recently improved and stabilized. Motivated by this progress, in this paper, we also generalize them to the tensor case based on the tubal product (T-product). We conduct extensive simulations to study the robustness of them compared with the existing single-pass randomized algorithms. In particular, we experimentally found that single-pass algorithms with the sketching parameters of equal sizes usually lead to ill-conditioned tensor least-squares problems and inaccurate results. It is experimentally shown that our proposed single-pass algorithms are robust in this sense. Numerical results demonstrate that under the same conditions (setting the same hyper-parameters), our proposed algorithms provide better performance. Three applications to image compression, super-resolution problem and deep learning are also presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02598v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Salman Ahmadi-Asl, Naeim Rezaeian, Cesar F. Caiafa, Andre L. F. de Almeidad</dc:creator>
    </item>
    <item>
      <title>Geometry-aware PINNs for Turbulent Flow Prediction</title>
      <link>https://arxiv.org/abs/2412.01954</link>
      <description>arXiv:2412.01954v1 Announce Type: cross 
Abstract: Design exploration or optimization using computational fluid dynamics (CFD) is commonly used in the industry. Geometric variation is a key component of such design problems, especially in turbulent flow scenarios, which involves running costly simulations at every design iteration. While parametric RANS-PINN type approaches have been proven to make effective turbulent surrogates, as a means of predicting unknown Reynolds number flows for a given geometry at near real-time, geometry aware physics informed surrogates with the ability to predict varying geometries are a relatively less studied topic. A novel geometry aware parametric PINN surrogate model has been created, which can predict flow fields for NACA 4 digit airfoils in turbulent conditions, for unseen shapes as well as inlet flow conditions. A local+global approach for embedding has been proposed, where known global design parameters for an airfoil as well as local SDF values can be used as inputs to the model along with velocity inlet/Reynolds number ($\mathcal{R}_e$) to predict the flow fields. A RANS formulation of the Navier-Stokes equations with a 2-equation k-epsilon turbulence model has been used for the PDE losses, in addition to limited CFD data from 8 different NACA airfoils for training. The models have then been validated with unknown NACA airfoils at unseen Reynolds numbers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01954v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.flu-dyn</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shinjan Ghosh, Julian Busch, Georgia Olympia Brikis, Biswadip Dey</dc:creator>
    </item>
    <item>
      <title>A sharp bound for the functional calculus of $\rho$-contractions</title>
      <link>https://arxiv.org/abs/2412.02326</link>
      <description>arXiv:2412.02326v1 Announce Type: cross 
Abstract: Let $A$ be a $\rho$-contraction and $f$ a rational function mapping the closed unit disk into itself. With a new characterization of $\rho$-contractions we prove that \begin{align*} \big\|f(A)\big\|\leq \frac{\rho}{2}\big(1-|f(0)|^{2}\big)+\sqrt{\frac{\rho^{2}}{4}\big(1-|f(0)|^{2}\big){}^{2}+|f(0)|^{2}}. \end{align*} We further show that this bound is sharp. This refines an estimate by Okubo--Ando and, for $\rho=2$, is consistent with a result by Drury.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02326v1</guid>
      <category>math.FA</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OA</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Felix L. Schwenninger, Jens de Vries</dc:creator>
    </item>
    <item>
      <title>Backtracking New Q-Newton's method for finding roots of meromorphic functions in 1 complex variable: Global convergence, and local stable/unstable curves</title>
      <link>https://arxiv.org/abs/2412.02476</link>
      <description>arXiv:2412.02476v1 Announce Type: cross 
Abstract: In this paper, we research more in depth properties of Backtracking New Q-Newton's method (recently designed by the third author), when used to find roots of meromorphic functions.
  If $f=P/Q$, where $P$ and $Q$ are polynomials in 1 complex variable z with $deg (P)&gt;deg (Q)$, we show the existence of an exceptional set $\mathcal{E}\subset\mathbf{C}$, which is contained in a countable union of real analytic curves in $\mathbf{R}^2=\mathbf{C}$, so that the following statements A and B hold. Here, $\{z_n\}$ is the sequence constructed by BNQN with an initial point $z_0$, not a pole of $f$.
  A) If $z_0\in\mathbb{C}\backslash\mathcal{E}$, then $\{z_n\}$ converges to a root of $f$.
  B) If $z_0\in \mathcal{E}$, then $\{z_n\}$ converges to a critical point - but not a root - of $f$.
  Experiments seem to indicate that in general, even when $f$ is a polynomial, the set $\mathcal{E}$ is not contained in a finite union of real analytic curves. We provide further results relevant to whether locally $\mathcal{E}$ is contained in a finite number of real analytic curves. A similar result holds for general meromorphic functions. Moreover, unlike previous work, here we do not require that the parameters of BNQN are random, or that the meromorphic function $f$ is generic.
  Based on the theoretical results, we explain (both rigorously and heuristically) of what observed in experiments with BNQN, in previous works by the authors. The dynamics of BNQN seems also to have some similarities (and differences) to the classical Leau-Fatou's flowers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02476v1</guid>
      <category>math.DS</category>
      <category>cs.NA</category>
      <category>math.CV</category>
      <category>math.NA</category>
      <category>math.NT</category>
      <category>math.OC</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>John Erik Forn{\ae}ss, Mi Hu, Tuyen Trung Truong</dc:creator>
    </item>
    <item>
      <title>An efficient stochastic particle method for high-dimensional nonlinear PDEs</title>
      <link>https://arxiv.org/abs/2310.18666</link>
      <description>arXiv:2310.18666v3 Announce Type: replace 
Abstract: Numerical resolution of high-dimensional nonlinear PDEs remains a huge challenge due to the curse of dimensionality. Starting from the weak formulation of the Lawson-Euler scheme, this paper proposes a stochastic particle method (SPM) by tracking the deterministic motion, random jump, resampling and reweighting of particles. Real-valued weighted particles are adopted by SPM to approximate the high-dimensional solution, which automatically adjusts the point distribution to intimate the relevant feature of the solution. A piecewise constant reconstruction with virtual uniform grid is employed to evaluate the nonlinear terms, which fully exploits the intrinsic adaptive characteristic of SPM. Combining both, SPM can achieve the goal of adaptive sampling in time. Numerical experiments on the 6-D Allen-Cahn equation and the 7-D Hamiltonian-Jacobi-Bellman equation demonstrate the potential of SPM in solving high-dimensional nonlinear PDEs efficiently while maintaining an acceptable accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.18666v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhengyang Lei, Sihong Shao, Yunfeng Xiong</dc:creator>
    </item>
    <item>
      <title>QR-based Parallel Set-Valued Approximation with Rational Functions</title>
      <link>https://arxiv.org/abs/2312.10260</link>
      <description>arXiv:2312.10260v2 Announce Type: replace 
Abstract: In this article a fast and parallelizable algorithm for rational approximation is presented. The method, called (P)QR-AAA, is a (parallel) set-valued variant of the AAA algorithm for scalar functions. It builds on the set-valued AAA framework introduced by Lietaert, Meerbergen, P{\'e}rez and Vandereycken, accelerating it by using an approximate orthogonal basis obtained from a truncated QR decomposition. We demonstrate both theoretically and numerically this method's accuracy and efficiency. We show how it can be parallelized while maintaining the desired accuracy, with minimal communication cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.10260v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Simon Dirckx, Karl Meerbergen, Daan Huybrechs</dc:creator>
    </item>
    <item>
      <title>B\'ezier curves and the Takagi function</title>
      <link>https://arxiv.org/abs/2401.16178</link>
      <description>arXiv:2401.16178v2 Announce Type: replace 
Abstract: We consider B\'ezier curves with complex parameters, and we determine explicitly the affine iterated function system (IFS) corresponding to the de Casteljau subdivision algorithm, together with the complex parametric domain over which such an IFS has a unique global connected attractor. For a specific family of complex parameters having vanishing imaginary part, we prove that the Takagi fractal curve is the attractor, under suitable scaling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.16178v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lenka Ptackova, Franco Vivaldi</dc:creator>
    </item>
    <item>
      <title>A subspace method for large-scale trace ratio problems</title>
      <link>https://arxiv.org/abs/2402.02920</link>
      <description>arXiv:2402.02920v2 Announce Type: replace 
Abstract: A subspace method is introduced to solve large-scale trace ratio problems. This approach is matrix-free, requiring only the action of the two matrices involved in the trace ratio. At each iteration, a smaller trace ratio problem is addressed in the search subspace. Additionally, the algorithm is endowed with a restarting strategy, that ensures the monotonicity of the trace ratio value throughout the iterations. The behavior of the approximate solution is investigated from a theoretical viewpoint, extending existing results on Ritz values and vectors, as the angle between the search subspace and the exact solution approaches zero. Numerical experiments in multigroup classification show that this new subspace method tends to be more efficient than iterative approaches relying on (partial) eigenvalue decompositions at each step.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.02920v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>G. Ferrandi, M. E. Hochstenbach, M. R. Oliveira</dc:creator>
    </item>
    <item>
      <title>Fast Numerical Approximation of Parabolic Problems Using Model Order Reduction and the Laplace Transform</title>
      <link>https://arxiv.org/abs/2403.02847</link>
      <description>arXiv:2403.02847v2 Announce Type: replace 
Abstract: We introduce a novel, fast method for the numerical approximation of parabolic partial differential equations (PDEs for short) based on model order reduction techniques and the Laplace transform. We start by applying said transform to the evolution problem, thus yielding a time-independent boundary value problem solely depending on the complex Laplace parameter. In an offline stage, we judiciously sample the Laplace parameter and numerically solve the corresponding collection of high-fidelity or full-order problems. Next, we apply a proper orthogonal decomposition (POD) to this collection of solutions in order to obtain a reduced basis in the Laplace domain. We project the linear parabolic problem onto this basis, and then using any suitable time-stepping method, we solve the evolution problem. A key insight to justify the implementation and analysis of the proposed method corresponds to resorting to Hardy spaces of analytic functions and establishing, through the Paley-Wiener theorem, an isometry between the solution of the time-dependent problem and its Laplace transform. As a result, one may conclude that computing a POD with samples taken in the Laplace domain produces an exponentially accurate reduced basis for the time-dependent problem. Numerical experiments portray the performance of the method in terms of accuracy and, in particular, speed-up when compared to the solution obtained by solving the full-order model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02847v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fernando Henr\'iquez, Jan S. Hesthaven</dc:creator>
    </item>
    <item>
      <title>Extended Galerkin neural network approximation of singular variational problems with error control</title>
      <link>https://arxiv.org/abs/2405.00815</link>
      <description>arXiv:2405.00815v2 Announce Type: replace 
Abstract: We present extended Galerkin neural networks (xGNN), a variational framework for approximating general boundary value problems (BVPs) with error control. The main contributions of this work are (1) a rigorous theory guiding the construction of new weighted least squares variational formulations suitable for use in neural network approximation of general BVPs (2) an ``extended'' feedforward network architecture which incorporates and is even capable of learning singular solution structures, thus greatly improving approximability of singular solutions. Numerical results are presented for several problems including steady Stokes flow around re-entrant corners and in convex corners with Moffatt eddies in order to demonstrate efficacy of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00815v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mark Ainsworth, Justin Dong</dc:creator>
    </item>
    <item>
      <title>High Order Accurate Hermite Schemes on Curvilinear Grids with Compatibility Boundary Conditions</title>
      <link>https://arxiv.org/abs/2406.19496</link>
      <description>arXiv:2406.19496v4 Announce Type: replace 
Abstract: High order accurate Hermite methods for the wave equation on curvilinear domains are presented. Boundaries are treated using centered compatibility conditions rather than more standard one-sided approximations. Both first-order-in-time (FOT) and second-order-in-time (SOT) Hermite schemes are developed. Hermite methods use the solution and multiple derivatives as unknowns and achieve space-time orders of accuracy $2m-1$ (FOT) and $2m$ (SOT) for methods using $(m+1)^d$ degree of freedom per node in $d$ dimensions. The compatibility boundary conditions (CBCs) are based on taking time derivatives of the boundary conditions and using the governing equations to replace the time derivatives with spatial derivatives. These resulting constraint equations augment the Hermite scheme on the boundary. The solvability of the equations resulting from the compatibility conditions are analyzed. Numerical examples demonstrate the accuracy and stability of the new schemes in two dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19496v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Journal of Computational Physics,522(2025),113597</arxiv:journal_reference>
      <dc:creator>Allen Alvarez Loya, Daniel Appel\"o, William D. Henshaw</dc:creator>
    </item>
    <item>
      <title>Towards Universal Mesh Movement Networks</title>
      <link>https://arxiv.org/abs/2407.00382</link>
      <description>arXiv:2407.00382v4 Announce Type: replace 
Abstract: Solving complex Partial Differential Equations (PDEs) accurately and efficiently is an essential and challenging problem in all scientific and engineering disciplines. Mesh movement methods provide the capability to improve the accuracy of the numerical solution without increasing the overall mesh degree of freedom count. Conventional sophisticated mesh movement methods are extremely expensive and struggle to handle scenarios with complex boundary geometries. However, existing learning-based methods require re-training from scratch given a different PDE type or boundary geometry, which limits their applicability, and also often suffer from robustness issues in the form of inverted elements. In this paper, we introduce the Universal Mesh Movement Network (UM2N), which -- once trained -- can be applied in a non-intrusive, zero-shot manner to move meshes with different size distributions and structures, for solvers applicable to different PDE types and boundary geometries. UM2N consists of a Graph Transformer (GT) encoder for extracting features and a Graph Attention Network (GAT) based decoder for moving the mesh. We evaluate our method on advection and Navier-Stokes based examples, as well as a real-world tsunami simulation case. Our method outperforms existing learning-based mesh movement methods in terms of the benchmarks described above. In comparison to the conventional sophisticated Monge-Amp\`ere PDE-solver based method, our approach not only significantly accelerates mesh movement, but also proves effective in scenarios where the conventional method fails. Our project page is at https://erizmr.github.io/UM2N/.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00382v4</guid>
      <category>math.NA</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mingrui Zhang, Chunyang Wang, Stephan Kramer, Joseph G. Wallwork, Siyi Li, Jiancheng Liu, Xiang Chen, Matthew D. Piggott</dc:creator>
    </item>
    <item>
      <title>A Class of Generalized Shift-Splitting Preconditioners for Double Saddle Point Problems</title>
      <link>https://arxiv.org/abs/2408.11750</link>
      <description>arXiv:2408.11750v3 Announce Type: replace 
Abstract: In this paper, we propose a generalized shift-splitting (GSS) preconditioner, along with its two relaxed variants to solve the double saddle point problem (DSPP). The convergence of the associated GSS iterative method is analyzed, and sufficient conditions for its convergence are established. Spectral analyses are performed to derive sharp bounds for the eigenvalues of the preconditioned matrices. Numerical experiments based on examples arising from the PDE-constrained optimization problems demonstrate the effectiveness and robustness of the proposed preconditioners compared with existing state-of-the-art preconditioners.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11750v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sk. Safique Ahmad, Pinki Khatun</dc:creator>
    </item>
    <item>
      <title>Gradient flow-based modularity maximization for community detection in multiplex networks</title>
      <link>https://arxiv.org/abs/2408.15003</link>
      <description>arXiv:2408.15003v2 Announce Type: replace 
Abstract: We propose two methods for the unsupervised detection of communities in undirected multiplex networks. These networks consist of multiple layers that record different relationships between the same entities or incorporate data from different sources. Both methods are formulated as gradient flows of suitable energy functionals: the first (MPBTV) builds on the minimization of a balanced total variation functional, which we show to be equivalent to multiplex modularity maximization, while the second (DGFM3) directly maximizes multiplex modularity. The resulting non-linear matrix-valued ordinary differential equations (ODEs) are solved efficiently by a graph Merriman--Bence--Osher (MBO) scheme. Key to the efficiency is the approximate integration of the discrete linear differential operators by truncated eigendecompositions in the matrix exponential function. Numerical experiments on several real-world multiplex networks show that our methods are competitive with the state of the art with respect to various metrics. Their major benefit is a significant reduction of computational complexity leading to runtimes that are orders of magnitude faster for large multiplex networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.15003v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>cs.SI</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kai Bergermann, Martin Stoll</dc:creator>
    </item>
    <item>
      <title>Preconditioned Low-Rank Riemannian Optimization for Symmetric Positive Definite Linear Matrix Equations</title>
      <link>https://arxiv.org/abs/2408.16416</link>
      <description>arXiv:2408.16416v2 Announce Type: replace 
Abstract: This work is concerned with the numerical solution of large-scale symmetric positive definite matrix equations of the form $A_1XB_1^\top + A_2XB_2^\top + \dots + A_\ell X B_\ell^\top = F$, as they arise from discretized partial differential equations and control problems. One often finds that $X$ admits good low-rank approximations, in particular when the right-hand side matrix $F$ has low rank. For $\ell \le 2$ terms, the solution of such equations is well studied and effective low-rank solvers have been proposed, including Alternating Direction Implicit (ADI) methods for Lyapunov and Sylvester equations. For $\ell &gt; 2$, several existing methods try to approach $X$ through combining a classical iterative method, such as the conjugate gradient (CG) method, with low-rank truncation. In this work, we consider a more direct approach that approximates $X$ on manifolds of fixed-rank matrices through Riemannian CG. One particular challenge is the incorporation of effective preconditioners into such a first-order Riemannian optimization method. We propose several novel preconditioning strategies, including a change of metric in the ambient space, preconditioning the Riemannian gradient, and a variant of ADI on the tangent space. Combined with a strategy for adapting the rank of the approximation, the resulting method is demonstrated to be competitive for a number of examples representative for typical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16416v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ivan Bioli, Daniel Kressner, Leonardo Robol</dc:creator>
    </item>
    <item>
      <title>Eigen-componentwise convergence of SGD for quadratic programming</title>
      <link>https://arxiv.org/abs/2411.06476</link>
      <description>arXiv:2411.06476v2 Announce Type: replace 
Abstract: Stochastic gradient descent (SGD) is a workhorse algorithm for solving large-scale optimization problems in data science and machine learning. Understanding the convergence of SGD is hence of fundamental importance. In this work we examine the SGD convergence (with various step sizes) when applied to unconstrained convex quadratic programming (essentially least-squares (LS) problems), and in particular analyze the error components respect to the eigenvectors of the Hessian. The main message is that the convergence depends largely on the corresponding eigenvalues (singular values of the coefficient matrix in the LS context), namely the components for the large singular values converge faster in the initial phase. We then show there is a phase transition in the convergence where the convergence speed of the components, especially those corresponding to the larger singular values, will decrease. Finally, we show that the convergence of the overall error (in the solution) tends to decay as more iterations are run, that is, the initial convergence is faster than the asymptote.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06476v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lehan Chen, Yuji Nakatsukasa</dc:creator>
    </item>
    <item>
      <title>Explicit error bounds of the SE and DE formulas for integrals with logarithmic and algebraic singularity</title>
      <link>https://arxiv.org/abs/2411.19755</link>
      <description>arXiv:2411.19755v2 Announce Type: replace 
Abstract: The SE and DE formulas are known as efficient quadrature formulas for integrals with endpoint singularity. Particularly, for integrals with algebraic singularity, explicit error bounds in a computable form have been provided, which are useful for computations with guaranteed accuracy. Such explicit error bounds have also been provided for integrals with logarithmic singularity. However, these error bounds have two points to be discussed. The first point is on overestimation of divergence speed of logarithmic singularity. The second point is on the case where there exist both logarithmic and algebraic singularity. To address these issues, this study provides new error bounds for integrals with logarithmic and algebraic singularity. Although existing and new error bounds described above handle integrals over the finite interval, the SE and DE formulas can be applied to integrals over the semi-infinite interval. On the basis of the new results, this study provides new error bounds for integrals over the semi-infinite interval with logarithmic and algebraic singularity at the origin.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19755v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tomoaki Okayama, Kosei Arakawa, Ryo Kamigaki, Eita Yabumoto</dc:creator>
    </item>
    <item>
      <title>A Single-Loop Gradient Descent and Perturbed Ascent Algorithm for Nonconvex Functional Constrained Optimization</title>
      <link>https://arxiv.org/abs/2207.05650</link>
      <description>arXiv:2207.05650v2 Announce Type: replace-cross 
Abstract: Nonconvex constrained optimization problems can be used to model a number of machine learning problems, such as multi-class Neyman-Pearson classification and constrained Markov decision processes. However, such kinds of problems are challenging because both the objective and constraints are possibly nonconvex, so it is difficult to balance the reduction of the loss value and reduction of constraint violation. Although there are a few methods that solve this class of problems, all of them are double-loop or triple-loop algorithms, and they require oracles to solve some subproblems up to certain accuracy by tuning multiple hyperparameters at each iteration. In this paper, we propose a novel gradient descent and perturbed ascent (GDPA) algorithm to solve a class of smooth nonconvex inequality constrained problems. The GDPA is a primal-dual algorithm, which only exploits the first-order information of both the objective and constraint functions to update the primal and dual variables in an alternating way. The key feature of the proposed algorithm is that it is a single-loop algorithm, where only two step-sizes need to be tuned. We show that under a mild regularity condition GDPA is able to find Karush-Kuhn-Tucker (KKT) points of nonconvex functional constrained problems with convergence rate guarantees. To the best of our knowledge, it is the first single-loop algorithm that can solve the general nonconvex smooth problems with nonconvex inequality constraints. Numerical results also showcase the superiority of GDPA compared with the best-known algorithms (in terms of both stationarity measure and feasibility of the obtained solutions).</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.05650v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Songtao Lu</dc:creator>
    </item>
    <item>
      <title>Infinite quantum signal processing</title>
      <link>https://arxiv.org/abs/2209.10162</link>
      <description>arXiv:2209.10162v2 Announce Type: replace-cross 
Abstract: Quantum signal processing (QSP) represents a real scalar polynomial of degree $d$ using a product of unitary matrices of size $2\times 2$, parameterized by $(d+1)$ real numbers called the phase factors. This innovative representation of polynomials has a wide range of applications in quantum computation. When the polynomial of interest is obtained by truncating an infinite polynomial series, a natural question is whether the phase factors have a well defined limit as the degree $d\to \infty$. While the phase factors are generally not unique, we find that there exists a consistent choice of parameterization so that the limit is well defined in the $\ell^1$ space. This generalization of QSP, called the infinite quantum signal processing, can be used to represent a large class of non-polynomial functions. Our analysis reveals a surprising connection between the regularity of the target function and the decay properties of the phase factors. Our analysis also inspires a very simple and efficient algorithm to approximately compute the phase factors in the $\ell^1$ space. The algorithm uses only double precision arithmetic operations, and provably converges when the $\ell^1$ norm of the Chebyshev coefficients of the target function is upper bounded by a constant that is independent of $d$. This is also the first numerically stable algorithm for finding phase factors with provable performance guarantees in the limit $d\to \infty$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.10162v2</guid>
      <category>quant-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yulong Dong, Lin Lin, Hongkang Ni, Jiasu Wang</dc:creator>
    </item>
    <item>
      <title>The Riemannian Convex Bundle Method</title>
      <link>https://arxiv.org/abs/2402.13670</link>
      <description>arXiv:2402.13670v2 Announce Type: replace-cross 
Abstract: We introduce the convex bundle method to solve convex, non-smooth optimization problems on Riemannian manifolds of bounded sectional curvature. Each step of our method is based on a model that involves the convex hull of previously collected subgradients, parallelly transported into the current serious iterate. This approach generalizes the dual form of classical bundle subproblems in Euclidean space. We prove that, under mild conditions, the convex bundle method converges to a minimizer. Several numerical examples implemented using Manopt.jl illustrate the performance of the proposed method and compare it to the subgradient method, the cyclic proximal point algorithm, as well as the proximal bundle method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.13670v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.DG</category>
      <category>math.NA</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Ronny Bergmann, Roland Herzog, Hajg Jasa</dc:creator>
    </item>
    <item>
      <title>Combinatorial Potential of Random Equations with Mixture Models: Modeling and Simulation</title>
      <link>https://arxiv.org/abs/2403.20152</link>
      <description>arXiv:2403.20152v5 Announce Type: replace-cross 
Abstract: The goal of this paper is to demonstrate the general modeling and practical simulation of random equations with mixture model parameter random variables. Random equations, understood as stationary (non-dynamical) equations with parameters as random variables, have a long history and a broad range of applications. The specific novelty of this explorative study lies on the demonstration of the combinatorial complexity of these equations and their solutions with mixture model parameters. In a Bayesian argumentation framework, we derive a likelihood function and posterior density of approximate solutions while avoiding significant restrictions about the type of nonlinearity of the equation or mixture models, and demonstrate their numerically efficient implementation for the applied researcher. In the results section, we are specifically focusing on expressive example simulations showcasing the combinatorial potential of random linear equation systems and nonlinear systems of random conic section equations. Introductory applications to portfolio optimization, stochastic control and random matrix theory are provided in order to show the wide applicability of the presented methodology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.20152v5</guid>
      <category>stat.CO</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wolfgang Hoegele</dc:creator>
    </item>
    <item>
      <title>Rigged Dynamic Mode Decomposition: Data-Driven Generalized Eigenfunction Decompositions for Koopman Operators</title>
      <link>https://arxiv.org/abs/2405.00782</link>
      <description>arXiv:2405.00782v2 Announce Type: replace-cross 
Abstract: We introduce the Rigged Dynamic Mode Decomposition (Rigged DMD) algorithm, which computes generalized eigenfunction decompositions of Koopman operators. By considering the evolution of observables, Koopman operators transform complex nonlinear dynamics into a linear framework suitable for spectral analysis. While powerful, traditional Dynamic Mode Decomposition (DMD) techniques often struggle with continuous spectra. Rigged DMD addresses these challenges with a data-driven methodology that approximates the Koopman operator's resolvent and its generalized eigenfunctions using snapshot data from the system's evolution. At its core, Rigged DMD builds wave-packet approximations for generalized Koopman eigenfunctions and modes by integrating Measure-Preserving Extended Dynamic Mode Decomposition with high-order kernels for smoothing. This provides a robust decomposition encompassing both discrete and continuous spectral elements. We derive explicit high-order convergence theorems for generalized eigenfunctions and spectral measures. Additionally, we propose a novel framework for constructing rigged Hilbert spaces using time-delay embedding, significantly extending the algorithm's applicability (Rigged DMD can be used with any rigging). We provide examples, including systems with a Lebesgue spectrum, integrable Hamiltonian systems, the Lorenz system, and a high-Reynolds number lid-driven flow in a two-dimensional square cavity, demonstrating Rigged DMD's convergence, efficiency, and versatility. This work paves the way for future research and applications of decompositions with continuous spectra.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00782v2</guid>
      <category>math.DS</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>math.SP</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthew J. Colbrook, Catherine Drysdale, Andrew Horning</dc:creator>
    </item>
    <item>
      <title>Paired Autoencoders for Likelihood-free Estimation in Inverse Problems</title>
      <link>https://arxiv.org/abs/2405.13220</link>
      <description>arXiv:2405.13220v2 Announce Type: replace-cross 
Abstract: We consider the solution of nonlinear inverse problems where the forward problem is a discretization of a partial differential equation. Such problems are notoriously difficult to solve in practice and require minimizing a combination of a data-fit term and a regularization term. The main computational bottleneck of typical algorithms is the direct estimation of the data misfit. Therefore, likelihood-free approaches have become appealing alternatives. Nonetheless, difficulties in generalization and limitations in accuracy have hindered their broader utility and applicability. In this work, we use a paired autoencoder framework as a likelihood-free estimator for inverse problems. We show that the use of such an architecture allows us to construct a solution efficiently and to overcome some known open problems when using likelihood-free estimators. In particular, our framework can assess the quality of the solution and improve on it if needed. We demonstrate the viability of our approach using examples from full waveform inversion and inverse electromagnetic imaging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13220v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthias Chung, Emma Hart, Julianne Chung, Bas Peters, Eldad Haber</dc:creator>
    </item>
    <item>
      <title>Relevance of the Basset history term for Lagrangian particle dynamics</title>
      <link>https://arxiv.org/abs/2407.01041</link>
      <description>arXiv:2407.01041v2 Announce Type: replace-cross 
Abstract: The movement of small but finite spherical particles in a fluid can be described by the Maxey-Riley equation (MRE) if they are too large to be considered passive tracers. The MRE contains an integral "history term" modeling wake effects, which causes the force acting on a particle at some given time to depend on its full past trajectory. The history term causes complications in the numerical solution of the MRE and is therefore often neglected, despite both numerical and experimental evidence that its effects are generally not negligible. By numerically computing trajectories with and without the history term of a large number of particles in different flow fields, we investigate its impact on the large-scale Lagrangian dynamics of simulated particles. We show that for moderate to large Stokes numbers, ignoring the history term leads to significant differences in clustering patterns. Furthermore, we compute finite-time Lyapunov exponents and show that, even for small particles, the differences in the resulting scalar field from ignoring the BHT can be significant, in particular if the underlying flow is turbulent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01041v2</guid>
      <category>physics.flu-dyn</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.NA</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julio Urizarna-Carasa, Daniel Ruprecht, Alexandra von Kameke, Kathrin Padberg-Gehle</dc:creator>
    </item>
  </channel>
</rss>
