<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 22 Nov 2024 05:00:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Why the p-norms $p{=}1$, $p{=}2$ and $p{=}\infty$ are so special? An answer based on spatial uniformity</title>
      <link>https://arxiv.org/abs/2411.13567</link>
      <description>arXiv:2411.13567v1 Announce Type: new 
Abstract: Among all metrics based on p-norms, the Manhattan (p=1), euclidean (p=2) and Chebyshev distances (p=infinity) are the most widely used for their interpretability, simplicity and technical convenience. But these are not the only arguments for the ubiquity of these three p-norms. This article proves that there is a volume-surface correspondence property that is unique to them. More precisely, it is shown that sampling uniformly from the volume of an n-dimensional p-ball and projecting to its surface is equivalent to directly sampling uniformly from its surface if and only if p is 1, 2 or infinity. Sampling algorithms and their implementations in Python are also provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13567v1</guid>
      <category>math.ST</category>
      <category>cs.CR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.TH</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Carlos Pinz\'on</dc:creator>
    </item>
    <item>
      <title>Active Subsampling for Measurement-Constrained M-Estimation of Individualized Thresholds with High-Dimensional Data</title>
      <link>https://arxiv.org/abs/2411.13763</link>
      <description>arXiv:2411.13763v1 Announce Type: new 
Abstract: In the measurement-constrained problems, despite the availability of large datasets, we may be only affordable to observe the labels on a small portion of the large dataset. This poses a critical question that which data points are most beneficial to label given a budget constraint. In this paper, we focus on the estimation of the optimal individualized threshold in a measurement-constrained M-estimation framework. Our goal is to estimate a high-dimensional parameter $\theta$ in a linear threshold $\theta^T Z$ for a continuous variable $X$ such that the discrepancy between whether $X$ exceeds the threshold $\theta^T Z$ and a binary outcome $Y$ is minimized. We propose a novel $K$-step active subsampling algorithm to estimate $\theta$, which iteratively samples the most informative observations and solves a regularized M-estimator. The theoretical properties of our estimator demonstrate a phase transition phenomenon with respect to $\beta\geq 1$, the smoothness of the conditional density of $X$ given $Y$ and $Z$. For $\beta&gt;(1+\sqrt{3})/2$, we show that the two-step algorithm yields an estimator with the parametric convergence rate $O_p((s \log d /N)^{1/2})$ in $l_2$ norm. The rate of our estimator is strictly faster than the minimax optimal rate with $N$ i.i.d. samples drawn from the population. For the other two scenarios $1&lt;\beta\leq (1+\sqrt{3})/2$ and $\beta=1$, the estimator from the two-step algorithm is sub-optimal. The former requires to run $K&gt;2$ steps to attain the same parametric rate, whereas in the latter case only a near parametric rate can be obtained. Furthermore, we formulate a minimax framework for the measurement-constrained M-estimation problem and prove that our estimator is minimax rate optimal up to a logarithmic factor. Finally, we demonstrate the performance of our method in simulation studies and apply the method to analyze a large diabetes dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13763v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingyi Duan, Yang Ning</dc:creator>
    </item>
    <item>
      <title>Filtering and Statistical Properties of Unimodal Maps Perturbed by Heteroscedastic Noises</title>
      <link>https://arxiv.org/abs/2411.13939</link>
      <description>arXiv:2411.13939v1 Announce Type: new 
Abstract: We propose a theory of unimodal maps perturbed by an heteroscedastic Markov chain noise and experiencing another heteroscedastic noise due to uncertain observation. We address and treat the filtering problem showing that by collecting more and more observations, one would predict the same distribution for the state of the underlying Markov chain no matter one's initial guess. Moreover we give other limit theorems, emphasizing in particular concentration inequalities and extreme value and Poisson distributions. Our results apply to a family of maps arising from a model of systemic risk in finance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13939v1</guid>
      <category>math.ST</category>
      <category>math.DS</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabrizio Lillo, Stefano Marmi, Matteo Tanzi, Sandro Vaienti</dc:creator>
    </item>
    <item>
      <title>Distributional regression: CRPS-error bounds for model fitting, model selection and convex aggregation</title>
      <link>https://arxiv.org/abs/2411.13974</link>
      <description>arXiv:2411.13974v1 Announce Type: new 
Abstract: Distributional regression aims at estimating the conditional distribution of a targetvariable given explanatory co-variates. It is a crucial tool for forecasting whena precise uncertainty quantification is required. A popular methodology consistsin fitting a parametric model via empirical risk minimization where the risk ismeasured by the Continuous Rank Probability Score (CRPS). For independentand identically distributed observations, we provide a concentration result for theestimation error and an upper bound for its expectation. Furthermore, we considermodel selection performed by minimization of the validation error and provide aconcentration bound for the regret. A similar result is proved for convex aggregationof models. Finally, we show that our results may be applied to various models suchas Ensemble Model Output Statistics (EMOS), distributional regression networks,distributional nearest neighbors or distributional random forests and we illustrateour findings on two data sets (QSAR aquatic toxicity and Airfoil self-noise).</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13974v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>38th Conference on Neural Information Processing Systems (NeurIPS 2024), Dec 2024, Vancoucer, Canada</arxiv:journal_reference>
      <dc:creator>Cl\'ement Dombry (LMB), Ahmed Zaoui (LMB)</dc:creator>
    </item>
    <item>
      <title>Tensors in algebraic statistics</title>
      <link>https://arxiv.org/abs/2411.14080</link>
      <description>arXiv:2411.14080v1 Announce Type: new 
Abstract: Tensors are ubiquitous in statistics and data analysis. The central object that links data science to tensor theory and algebra is that of a model with latent variables. We provide an overview of tensor theory, with a particular emphasis on its applications in algebraic statistics. This high-level treatment is supported by numerous examples to illustrate key concepts. Additionally, an extensive literature review is included to guide readers toward more detailed studies on the subject.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14080v1</guid>
      <category>math.ST</category>
      <category>math.AG</category>
      <category>math.HO</category>
      <category>stat.TH</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marta Casanellas, Luis Sierra, Piotr Zwiernik</dc:creator>
    </item>
    <item>
      <title>The stabilizing role of multiplicative noise in non-confining potentials</title>
      <link>https://arxiv.org/abs/2411.13606</link>
      <description>arXiv:2411.13606v1 Announce Type: cross 
Abstract: We provide a simple framework for the study of parametric (multiplicative) noise, making use of scale parameters. We show that for a large class of stochastic differential equations increasing the multiplicative noise intensity surprisingly causes the mass of the stationary probability distribution to become increasingly concentrated around the minima of the multiplicative noise term, whilst under quite general conditions exhibiting a kind of intermittent burst like jumps between these minima. If the multiplicative noise term has one zero this causes on-off intermittency. Our framework relies on first term expansions, which become more accurate for larger noise intensities. In this work we show that the full width half maximum in addition to the maximum is appropriate for quantifying the stationary probability distribution (instead of the mean and variance, which are often undefined). We define a corresponding new kind of weak sense stationarity. We consider a double well potential as an example of application, demonstrating relevance to tipping points in noisy systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13606v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.ST</category>
      <category>nlin.AO</category>
      <category>stat.TH</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Ewan T. Phillips, Benjamin Lindner, Holger Kantz</dc:creator>
    </item>
    <item>
      <title>Selective inference is easier with p-values</title>
      <link>https://arxiv.org/abs/2411.13764</link>
      <description>arXiv:2411.13764v1 Announce Type: cross 
Abstract: Selective inference is a subfield of statistics that enables valid inference after selection of a data-dependent question. In this paper, we introduce selectively dominant p-values, a class of p-values that allow practitioners to easily perform inference after arbitrary selection procedures. Unlike a traditional p-value, whose distribution must stochastically dominate the uniform distribution under the null, a selectively dominant p-value must have a post-selection distribution that stochastically dominates that of a uniform having undergone the same selection process; moreover, this property must hold simultaneously for all possible selection processes. Despite the strength of this condition, we show that all commonly used p-values (e.g., p-values from two-sided testing in parametric families, one-sided testing in monotone likelihood ratio and exponential families, $F$-tests for linear regression, and permutation tests) are selectively dominant. By recasting two canonical selective inference problems-inference on winners and rank verification-in our selective dominance framework, we provide simpler derivations, a deeper conceptual understanding, and new generalizations and variations of these methods. Additionally, we use our insights to introduce selective variants of methods that combine p-values, such as Fisher's combination test.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13764v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anav Sood</dc:creator>
    </item>
    <item>
      <title>Robust Detection of Watermarks for Large Language Models Under Human Edits</title>
      <link>https://arxiv.org/abs/2411.13868</link>
      <description>arXiv:2411.13868v1 Announce Type: cross 
Abstract: Watermarking has offered an effective approach to distinguishing text generated by large language models (LLMs) from human-written text. However, the pervasive presence of human edits on LLM-generated text dilutes watermark signals, thereby significantly degrading detection performance of existing methods. In this paper, by modeling human edits through mixture model detection, we introduce a new method in the form of a truncated goodness-of-fit test for detecting watermarked text under human edits, which we refer to as Tr-GoF. We prove that the Tr-GoF test achieves optimality in robust detection of the Gumbel-max watermark in a certain asymptotic regime of substantial text modifications and vanishing watermark signals. Importantly, Tr-GoF achieves this optimality \textit{adaptively} as it does not require precise knowledge of human edit levels or probabilistic specifications of the LLMs, in contrast to the optimal but impractical (Neyman--Pearson) likelihood ratio test. Moreover, we establish that the Tr-GoF test attains the highest detection efficiency rate in a certain regime of moderate text modifications. In stark contrast, we show that sum-based detection rules, as employed by existing methods, fail to achieve optimal robustness in both regimes because the additive nature of their statistics is less resilient to edit-induced noise. Finally, we demonstrate the competitive and sometimes superior empirical performance of the Tr-GoF test on both synthetic data and open-source LLMs in the OPT and LLaMA families.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13868v1</guid>
      <category>cs.LG</category>
      <category>cs.CL</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiang Li, Feng Ruan, Huiyuan Wang, Qi Long, Weijie J. Su</dc:creator>
    </item>
    <item>
      <title>A note on numerical evaluation of conditional Akaike information for nonlinear mixed-effects models</title>
      <link>https://arxiv.org/abs/2411.14185</link>
      <description>arXiv:2411.14185v1 Announce Type: cross 
Abstract: We propose two methods to evaluate the conditional Akaike information (cAI) for nonlinear mixed-effects models with no restriction on cluster size. Method 1 is designed for continuous data and includes formulae for the derivatives of fixed and random effects estimators with respect to observations. Method 2, compatible with any type of observation, requires modeling the marginal (or prior) distribution of random effects as a multivariate normal distribution. Simulations show that Method 1 performs well with Gaussian data but struggles with skewed continuous distributions, whereas Method 2 consistently performs well across various distributions, including normal, gamma, negative binomial, and Tweedie, with flexible link functions. Based on our findings, we recommend Method 2 as a distributionally robust cAI criterion for model selection in nonlinear mixed-effects models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14185v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nan Zheng, Noel Cadigan, James T. Thorson</dc:creator>
    </item>
    <item>
      <title>Stochastic interventions, sensitivity analysis, and optimal transport</title>
      <link>https://arxiv.org/abs/2411.14285</link>
      <description>arXiv:2411.14285v1 Announce Type: cross 
Abstract: Recent methodological research in causal inference has focused on effects of stochastic interventions, which assign treatment randomly, often according to subject-specific covariates. In this work, we demonstrate that the usual notion of stochastic interventions have a surprising property: when there is unmeasured confounding, bounds on their effects do not collapse when the policy approaches the observational regime. As an alternative, we propose to study generalized policies, treatment rules that can depend on covariates, the natural value of treatment, and auxiliary randomness. We show that certain generalized policy formulations can resolve the "non-collapsing" bound issue: bounds narrow to a point when the target treatment distribution approaches that in the observed data. Moreover, drawing connections to the theory of optimal transport, we characterize generalized policies that minimize worst-case bound width in various sensitivity analysis models, as well as corresponding sharp bounds on their causal effects. These optimal policies are new, and can have a more parsimonious interpretation compared to their usual stochastic policy analogues. Finally, we develop flexible, efficient, and robust estimators for the sharp nonparametric bounds that emerge from the framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14285v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander W. Levis, Edward H. Kennedy, Alec McClean, Sivaraman Balakrishnan, Larry Wasserman</dc:creator>
    </item>
    <item>
      <title>On the Sample Complexity of One Hidden Layer Networks with Equivariance, Locality and Weight Sharing</title>
      <link>https://arxiv.org/abs/2411.14288</link>
      <description>arXiv:2411.14288v1 Announce Type: cross 
Abstract: Weight sharing, equivariance, and local filters, as in convolutional neural networks, are believed to contribute to the sample efficiency of neural networks. However, it is not clear how each one of these design choices contribute to the generalization error. Through the lens of statistical learning theory, we aim to provide an insight into this question by characterizing the relative impact of each choice on the sample complexity. We obtain lower and upper sample complexity bounds for a class of single hidden layer networks. It is shown that the gain of equivariance is directly manifested in the bound, while getting a similar increase for weight sharing depends on the sharing mechanism. Among our results, we obtain a completely dimension-free bound for equivariant networks for a class of pooling operations. We show that the bound depends merely on the norm of filters, which is tighter than using the spectral norm of the respective matrix. We also characterize the trade-off in sample complexity between the parametrization of filters in spatial and frequency domains, particularly when spatial filters are localized as in vanilla convolutional neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14288v1</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arash Behboodi, Gabriele Cesa</dc:creator>
    </item>
    <item>
      <title>Asymptotic confidence interval for R2 in multiple linear regression</title>
      <link>https://arxiv.org/abs/2401.12598</link>
      <description>arXiv:2401.12598v2 Announce Type: replace 
Abstract: Following White's approach of robust multiple linear regression, we give asymptotic confidence intervals for the multiple correlation coefficient R2 under minimal moment conditions. We also give the asymptotic joint distribution of the empirical estimators of the individual R2's. Through different sets of simulations, we show that the procedure is indeed robust (contrary to the procedure involving the near exact distribution of the empirical estimator of R2 is the multivariate Gaussian case) and can be also applied to count linear regression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.12598v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>J Dedecker (MAP5 - UMR 8145), Odelia Guedj (LaMME), Marie-Luce Taupin (LaMME)</dc:creator>
    </item>
    <item>
      <title>Exchangeability, prediction and predictive modeling in Bayesian statistics</title>
      <link>https://arxiv.org/abs/2402.10126</link>
      <description>arXiv:2402.10126v2 Announce Type: replace 
Abstract: There is currently a renewed interest in the Bayesian predictive approach to statistics. This paper offers a review on foundational concepts and focuses on predictive modeling, which by directly reasoning on prediction, bypasses inferential models or may characterize them. We detail predictive characterizations in exchangeable and partially exchangeable settings, for a large variety of data structures, and hint at new directions. The underlying concept is that Bayesian predictive rules are probabilistic learning rules, formalizing through conditional probability how we learn on future events given the available information. This concept has implications in any statistical problem and in inference, from classic contexts to less explored challenges, such as providing Bayesian uncertainty quantification to predictive algorithms in data science, as we show in the last part of the paper. The paper gives a historical overview, but also includes a few new results, presents some recent developments and poses some open questions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.10126v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sandra Fortini, Sonia Petrone</dc:creator>
    </item>
    <item>
      <title>The Instrumental Variable Model with Categorical Instrument, Treatment and Outcome: Characterization, Partial Identification, and Statistical Inference</title>
      <link>https://arxiv.org/abs/2405.09510</link>
      <description>arXiv:2405.09510v4 Announce Type: replace 
Abstract: Instrumental variable (IV) analysis is a crucial tool in estimating causal relationships by addressing the issue of confounding variables that may bias the results. Among other work on IV models with binary exposure and outcomes, Richardson and Robins (2014) studied the instrumental variable model with binary exposure (X) and binary outcome (Y) with an instrument (Z) that takes Q states where Q&gt;=2. However, IV models beyond binary X and Y have been less explored. In this work, we consider the instrumental variable model with categorical X, Y, Z taking values in {1, ..., K}, {1, ..., M}, and {1, ..., Q} respectively. We first give a simple closed-form characterization of the set of joint distributions of the potential outcomes P(Y(x=1), ..., Y(x=K)) compatible with a given observed probability distribution P(X, Y | Z). We further show the bounds we derived are necessary, sufficient, and non-redundant, and they hold under various versions of the independence assumptions that have been discussed in the literature. We also provide how a confidence region of any convex function of the joint counterfactual probability including the average causal effect (ATE) can be computed using an algorithm proposed by Guo and Richardson (2021) which is based on a new tail bound for the KL-divergence. We implement our bounds and provide practical recommendations through a real data example of a cash-incentive smoking cessation program.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09510v4</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yilin Song, F. Richard Guo, K. C. Gary Chan, Thomas S. Richardson</dc:creator>
    </item>
    <item>
      <title>Sharp Bounds for Multiple Models in Matrix Completion</title>
      <link>https://arxiv.org/abs/2411.13199</link>
      <description>arXiv:2411.13199v2 Announce Type: replace 
Abstract: In this paper, we demonstrate how a class of advanced matrix concentration inequalities, introduced in \cite{brailovskaya2024universality}, can be used to eliminate the dimensional factor in the convergence rate of matrix completion. This dimensional factor represents a significant gap between the upper bound and the minimax lower bound, especially in high dimension. Through a more precise spectral norm analysis, we remove the dimensional factors for five different estimators in various settings, thereby establishing their minimax rate optimality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13199v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dali Liu, Haolei Weng</dc:creator>
    </item>
    <item>
      <title>In-and-Out: Algorithmic Diffusion for Sampling Convex Bodies</title>
      <link>https://arxiv.org/abs/2405.01425</link>
      <description>arXiv:2405.01425v2 Announce Type: replace-cross 
Abstract: We present a new random walk for uniformly sampling high-dimensional convex bodies. It achieves state-of-the-art runtime complexity with stronger guarantees on the output than previously known, namely in R\'enyi divergence (which implies TV, $\mathcal{W}_2$, KL, $\chi^2$). The proof departs from known approaches for polytime algorithms for the problem -- we utilize a stochastic diffusion perspective to show contraction to the target distribution with the rate of convergence determined by functional isoperimetric constants of the stationary density.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01425v2</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yunbum Kook, Santosh S. Vempala, Matthew S. Zhang</dc:creator>
    </item>
  </channel>
</rss>
