<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 06 Aug 2025 01:35:43 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Measuring the entropy of a neuron cell from its membrane current signal</title>
      <link>https://arxiv.org/abs/2508.00968</link>
      <description>arXiv:2508.00968v1 Announce Type: new 
Abstract: The purpose of this study was to investigate how the entropy of a neuron cell can be measured using membrane ion current signals, which were recorded from neurons in the mouse medial prefrontal cortex (mPFC). The sample entropy and the Scalogram entropy were used as entropy measurement methods. It is well known that the entropy increases in the direction of the movement of the system towards the equilibrium. Therefore, in the process of the electrical activity of a living cell, the entropy is expected to reach a maximum at the moment when the membrane potential reaches the 'Nernst equilibrium potential' (or ionic equilibrium) of the ions. However, it was observed that the entropy values obtained by traditional calculations did not reach the peak at the equilibrium state of the ions. Therefore, two modifications to these measurement methods were proposed to adjust the entropy value to the maximum at the equilibrium potential of the ions. As a result of these proposed modifications, the entropy values were observed to peak around the equilibrium potential of the ions. These refined approaches were successfully validated using the Logistic map. Additionally, the entropy results were compared with Lyapunov exponents. The results show that the behaviour of living cells can be analysed using entropy measurements. The results also suggest that the method could be used to detect differences in the behaviour of tumour and normal cells, or the effects of drugs on cells.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00968v1</guid>
      <category>q-bio.NC</category>
      <category>physics.bio-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mahmut Akilli</dc:creator>
    </item>
    <item>
      <title>Algebraic Connectivity Enhances Hyperedge Specificity in the Alzheimer's Disease Continuum</title>
      <link>https://arxiv.org/abs/2508.01252</link>
      <description>arXiv:2508.01252v1 Announce Type: new 
Abstract: Functional MRI is a neuroimaging technique aiming at analyzing the functional activity of the brain by measuring blood-oxygen-level-dependent signals throughout the brain. The derived functional features can be used for investigating brain alterations in neurological and psychiatric disorders. In this work, we employed the hypergraph structure to model high-order functional relations across brain regions, introducing algebraic connectivity (a(G)) for estimating the hyperedge weights. The hypergraph structure was derived from healthy controls to build a common topological structure across individuals. The considered cohort included subjects covering the Alzheimer's disease (AD) continuum, that is both mild cognitive impairment and AD patients. Statistical analysis was performed using the hyperedges' weights as features to assess the differences across the three groups. Additionally, a mediation analysis was performed to evaluate the effectiveness and reliability of the a(G) values, representing the functional information, as the mediator between tau-PET levels, a key biomarker of AD, and cognitive scores. The proposed approach outperformed state-of-the-art methods in identifying a larger number of hyperedges statistically different across groups. Among these, two hyperedges belonging to salience ventral attention and somatomotor networks showed a partial mediation effect between the tau biomarkers and cognitive decline. These results suggested that the a(G) can be an effective approach for extracting the hyperedge weights, including important functional information that resides in the brain areas forming the hyperedges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01252v1</guid>
      <category>q-bio.NC</category>
      <category>eess.IV</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giorgio Dolci, Silvia Saglia, Lorenza Brusini, Vince D. Calhoun, Ilaria Boscolo Galazzo, Gloria Menegaz</dc:creator>
    </item>
    <item>
      <title>Patterns of imbalance states between sub-brain regimes during development in the resting state</title>
      <link>https://arxiv.org/abs/2508.01307</link>
      <description>arXiv:2508.01307v1 Announce Type: new 
Abstract: The functional brain network is the result of neurons and different areas working together in a coordinated manner. The findings indicate that the spatial distribution of anticorrelations in the brain network is not inherent. In this study, using Heider balance theory, we examine the network of imbalanced triangles with negative links in the brain, which undergoes dynamic changes across development. By analyzing the age-related transformations in the connectivity of imbalanced triangles at the level of brain subnetworks. We show that anticorrelations evolve from childhood to adulthood, reflecting a developmental trajectory from a locally modular organization in childhood, through a flexible and reconfigurable architecture during adolescence, to a highly segregated and functionally specialized network system in adulthood. This mature configuration supports a balance between internally directed cognition and external task demands, enabling efficient and adaptive cognitive control. Specifically, in childhood, prominent anticorrelations were observed between the default mode network (DMN) and the dorsal attention network (DAN), as well as between the default mode network (DMN) and the ventral attention network (VAN). During adolescence, these anticorrelations persisted but became weaker. By adulthood, dominant anticorrelations were observed between the DMN and both the DAN and the frontoparietal network (FPN).</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01307v1</guid>
      <category>q-bio.NC</category>
      <category>physics.bio-ph</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fahimeh Ahmadi, Zahra Moradimanesh, Reza Khosrowabadi, G. Reza Jafari</dc:creator>
    </item>
    <item>
      <title>CITS: Nonparametric Statistical Causal Modeling for High-Resolution Neural Time Series</title>
      <link>https://arxiv.org/abs/2508.01920</link>
      <description>arXiv:2508.01920v1 Announce Type: new 
Abstract: Understanding how signals propagate through neural circuits is central to deciphering brain computation. While functional connectivity captures statistical associations, it does not reveal directionality or causal mechanisms. We introduce CITS (Causal Inference in Time Series), a non-parametric method for inferring statistically causal neural circuitry from high-resolution time series data. CITS models neural dynamics using a structural causal model with arbitrary Markov order and tests for time-lagged conditional independence using either Gaussian or distribution-free statistics. Unlike classical Granger Causality, which assumes linear autoregressive models and Gaussian noise, or the Peter-Clark algorithm, which assumes i.i.d. data and no temporal structure, CITS handles temporally dependent, potentially non-Gaussian data with flexible testing procedures. We prove consistency under mild mixing assumptions and validate CITS on simulated linear, nonlinear, and continuous-time recurrent neural network data, where it outperforms state-of-the-art methods. We then apply CITS to Neuropixels recordings from mouse brain during visual tasks. CITS uncovers interpretable, stimulus-specific causal circuits linking cortical, thalamic, and hippocampal regions, consistent with experimental literature. It also reveals that neurons with similar orientation selectivity indices are more likely to be causally connected. Our results demonstrate the utility of CITS in uncovering biologically meaningful pathways and generating hypotheses for future experimental studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01920v1</guid>
      <category>q-bio.NC</category>
      <category>q-bio.QM</category>
      <category>stat.AP</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rahul Biswas, SuryaNarayana Sripada, Somabha Mukherjee, Reza Abbasi-Asl</dc:creator>
    </item>
    <item>
      <title>A large-scale complexity-graded dataset of neuronal images and annotations</title>
      <link>https://arxiv.org/abs/2508.02059</link>
      <description>arXiv:2508.02059v1 Announce Type: new 
Abstract: Accurate reconstruction of neuronal morphology is essential for classifying cell types and understanding brain connectivity. Recent advances in imaging and reconstruction techniques have greatly expanded the scale and quality of neuronal data. However, large-scale, standardized annotated datasets remain limited. Here, we present an open, multi-level neuronal dataset covering the whole mouse brain. Using a hierarchical strategy, we divided imaging data from 237 mouse brains into about 13,570,000 standardized blocks, classified into four levels of reconstruction difficulty. With the custom-developed reconstruction platform, we achieved high-precision three-dimensional reconstructions of 9,676 neurons at the whole-brain scale. This dataset will be made publicly available, providing a valuable resource for algorithm development and brain circuit modeling in neuroscience research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02059v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wu Chen, Mingwei Liao, Xueyan Jia, Xiaowei Chen, Chi Xiao, Qingming Luo, Hui Gong, Anan Li</dc:creator>
    </item>
    <item>
      <title>The refresh rate of overhead projectors may affect the perception of fast moving objects: a modelling study</title>
      <link>https://arxiv.org/abs/2508.02325</link>
      <description>arXiv:2508.02325v1 Announce Type: new 
Abstract: Using simulation and a simple mathematical argument we argue that the refresh rate of overhead projectors, used in experiments on the visual system, may impact the perception of fast moving objects at the retinal and cortical level (V1), and thereby at the level of psychophysics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02325v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>J\'er\^ome Emonet, Bruno Cessac</dc:creator>
    </item>
    <item>
      <title>Distinct inhibitory connectivity motifs trigger distinct forms of anticipation in the retinal network</title>
      <link>https://arxiv.org/abs/2508.02436</link>
      <description>arXiv:2508.02436v1 Announce Type: new 
Abstract: Motion is an important feature of visual scenes and retinal neuronal circuits selectively signal different motion features. It has been shown that the retina can extrapolate the position of a moving object, thereby compensating sensory transmission delays and enabling signal processing in real-time. Amacrine cells, the inhibitory interneurons of the retina, play essential roles in such computations although their precise function remain unclear. Here, we computationally explore the effect of two different inhibitory connectivity motifs on the retina's response to moving objects: feed-forward and recurrent feed-back inhibition. We show that both can account for motion anticipation with two different mechanisms. Feed-forward inhibition truncates motion responses and shifts peak responses forward via subtractive inhibition, whereas recurrent feedback coupling evokes, via divisive inhibition, excitatory and inhibitory waves with different phases that add up and shift the response peak. A key difference between the two mechanisms is how the peak response scales with the speed of a moving object. Motion prediction with feedforward circuits monotonically decreases with increasing speeds, while recurrent feedback coupling induces tuning curves that exhibit a preferred speed for which motion prediction is maximal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02436v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>S. Ebert, B. Cessac</dc:creator>
    </item>
    <item>
      <title>Perception of dynamic multi-speaker auditory scenes under different modes of attention</title>
      <link>https://arxiv.org/abs/2508.02620</link>
      <description>arXiv:2508.02620v1 Announce Type: new 
Abstract: Attention is not monolithic; rather, it operates in multiple forms to facilitate efficient cognitive processing. In the auditory domain, attention enables the prioritization of relevant sounds in an auditory scene and can be either attracted by elements in the scene in a bottom-up fashion or directed towards features, objects, or the entire scene in a top-down fashion. How these modes of attention interact and whether their neural underpinnings are distinct remains unclear. In this work, we investigate the perceptual and neural correlates of different attentional modes in a controlled "cocktail party" paradigm, where listeners listen to the same stimuli and attend to either a spatial location (feature-based), a speaker (object-based), or the entire scene (global or free-listening) while detecting deviations in pitch of a voice in the scene. Our findings indicate that object-based attention is more perceptually effective than feature-based or global attention. Furthermore, object-based and spatial-based attention engage distinct neural mechanisms and are differentially modulated by bottom-up salience. Notably, while bottom-up salience aids in the initial segregation of auditory objects, it plays a reduced role in object tracking once attention has been voluntarily allocated. In addition, decoding the stimulus envelope from the EEG data revealed a source-sampling scheme in the global attention mode that is not present in the object or spatial modes. Overall, the study shows that the perception of the same acoustic scene differs according to the listening task, guided by an interaction between top-down and bottom-up processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02620v1</guid>
      <category>q-bio.NC</category>
      <category>eess.AS</category>
      <category>eess.SP</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stephanie Graceffo, David F Little, Emine Merve Kaya, Mounya Elhilali</dc:creator>
    </item>
    <item>
      <title>Toward Efficient Spiking Transformers: Synapse Pruning Meets Synergistic Learning-Based Compensation</title>
      <link>https://arxiv.org/abs/2508.01992</link>
      <description>arXiv:2508.01992v1 Announce Type: cross 
Abstract: As a foundational architecture of artificial intelligence models, Transformer has been recently adapted to spiking neural networks with promising performance across various tasks. However, existing spiking Transformer (ST)-based models require a substantial number of parameters and incur high computational costs, thus limiting their deployment in resource-constrained environments. To address these challenges, we propose combining synapse pruning with a synergistic learning-based compensation strategy to derive lightweight ST-based models. Specifically, two types of tailored pruning strategies are introduced to reduce redundancy in the weight matrices of ST blocks: an unstructured $\mathrm{L_{1}P}$ method to induce sparse representations, and a structured DSP method to induce low-rank representations. In addition, we propose an enhanced spiking neuron model, termed the synergistic leaky integrate-and-fire (sLIF) neuron, to effectively compensate for model pruning through synergistic learning between synaptic and intrinsic plasticity mechanisms. Extensive experiments on benchmark datasets demonstrate that the proposed methods significantly reduce model size and computational overhead while maintaining competitive performance. These results validate the effectiveness of the proposed pruning and compensation strategies in constructing efficient and high-performing ST-based models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01992v1</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongze Sun, Wuque Cai, Duo Chen, Shifeng Mao, Jiayi He, Zhenxing Wang, Dezhong Yao, Daqing Guo</dc:creator>
    </item>
    <item>
      <title>Explainable AI Methods for Neuroimaging: Systematic Failures of Common Tools, the Need for Domain-Specific Validation, and a Proposal for Safe Application</title>
      <link>https://arxiv.org/abs/2508.02560</link>
      <description>arXiv:2508.02560v1 Announce Type: cross 
Abstract: Trustworthy interpretation of deep learning models is critical for neuroimaging applications, yet commonly used Explainable AI (XAI) methods lack rigorous validation, risking misinterpretation. We performed the first large-scale, systematic comparison of XAI methods on ~45,000 structural brain MRIs using a novel XAI validation framework. This framework establishes verifiable ground truth by constructing prediction tasks with known signal sources - from localized anatomical features to subject-specific clinical lesions - without artificially altering input images. Our analysis reveals systematic failures in two of the most widely used methods: GradCAM consistently failed to localize predictive features, while Layer-wise Relevance Propagation generated extensive, artifactual explanations that suggest incompatibility with neuroimaging data characteristics. Our results indicate that these failures stem from a domain mismatch, where methods with design principles tailored to natural images require substantial adaptation for neuroimaging data. In contrast, the simpler, gradient-based method SmoothGrad, which makes fewer assumptions about data structure, proved consistently accurate, suggesting its conceptual simplicity makes it more robust to this domain shift. These findings highlight the need for domain-specific adaptation and validation of XAI methods, suggest that interpretations from prior neuroimaging studies using standard XAI methodology warrant re-evaluation, and provide urgent guidance for practical application of XAI in neuroimaging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02560v1</guid>
      <category>cs.LG</category>
      <category>cs.CV</category>
      <category>eess.IV</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nys Tjade Siegel, James H. Cole, Mohamad Habes, Stefan Haufe, Kerstin Ritter, Marc-Andr\'e Schulz</dc:creator>
    </item>
    <item>
      <title>Neural subspaces, minimax entropy, and mean-field theory for networks of neurons</title>
      <link>https://arxiv.org/abs/2508.02633</link>
      <description>arXiv:2508.02633v1 Announce Type: cross 
Abstract: Recent advances in experimental techniques enable the simultaneous recording of activity from thousands of neurons in the brain, presenting both an opportunity and a challenge: to build meaningful, scalable models of large neural populations. Correlations in the brain are typically weak but widespread, suggesting that a mean-field approach might be effective in describing real neural populations, and we explore a hierarchy of maximum entropy models guided by this idea. We begin with models that match only the mean and variance of the total population activity, and extend to models that match the experimentally observed mean and variance of activity along multiple projections of the neural state. Confronted by data from several different brain regions, these models are driven toward a first-order phase transition, characterized by the presence of two nearly degenerate minima in the energy landscape, and this leads to predictions in qualitative disagreement with other features of the data. To resolve this problem we introduce a novel class of models that constrain the full probability distribution of activity along selected projections. We develop the mean-field theory for this class of models and apply it to recordings from 1000+ neurons in the mouse hippocampus. This 'distributional mean--field' model provides an accurate and consistent description of the data, offering a scalable and principled approach to modeling complex neural population dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02633v1</guid>
      <category>physics.bio-ph</category>
      <category>cond-mat.stat-mech</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luca Di Carlo, Francesca Mignacco, Christopher W. Lynn, William Bialek</dc:creator>
    </item>
    <item>
      <title>Ordinal Characterization of Similarity Judgments</title>
      <link>https://arxiv.org/abs/2310.07543</link>
      <description>arXiv:2310.07543v4 Announce Type: replace 
Abstract: Characterizing judgments of similarity within a perceptual or semantic domain, and making inferences about the underlying structure of this domain from these judgments, has an increasingly important role in cognitive and systems neuroscience. We present a new framework for this purpose that makes limited assumptions about how perceptual distances are converted into similarity judgments. The approach starts from a dataset of empirical judgments of relative similarities: the fraction of times that a subject chooses one of two comparison stimuli to be more similar to a reference stimulus. These empirical judgments provide Bayesian estimates of underling choice probabilities. From these estimates, we derive indices that characterize the set of judgments in three ways: compatibility with a symmetric dis-similarity, compatibility with an ultrametric space, and compatibility with an additive tree. Each of the indices is derived from rank-order relationships among the choice probabilities that, as we show, are necessary and sufficient for local consistency with the three respective characteristics. We illustrate this approach with simulations and example psychophysical datasets of dis-similarity judgments in several visual domains and provide code that implements the analyses at https://github.com/jvlab/simrank.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.07543v4</guid>
      <category>q-bio.NC</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.46298/mna.12457</arxiv:DOI>
      <dc:creator>Jonathan D. Victor, Guillermo Aguilar, Suniyya A. Waraich</dc:creator>
    </item>
    <item>
      <title>A Brain Graph Foundation Model: Pre-Training and Prompt-Tuning for Any Atlas and Disorder</title>
      <link>https://arxiv.org/abs/2506.02044</link>
      <description>arXiv:2506.02044v2 Announce Type: replace 
Abstract: As large language models (LLMs) continue to revolutionize AI research, there is a growing interest in building large-scale brain foundation models to advance neuroscience. While most existing brain foundation models are pre-trained on time-series signals or connectome features, we propose a novel graph-based pre-training paradigm for constructing a brain graph foundation model. In this paper, we introduce the Brain Graph Foundation Model, termed BrainGFM, a unified framework that leverages graph contrastive learning and graph masked autoencoders for large-scale fMRI-based pre-training. BrainGFM is pre-trained on a diverse mixture of brain atlases with varying parcellations, significantly expanding the pre-training corpus and enhancing the model's ability to generalize across heterogeneous fMRI-derived brain representations. To support efficient and versatile downstream transfer, we integrate both graph prompts and language prompts into the model design, enabling BrainGFM to flexibly adapt to a wide range of atlases, neurological and psychiatric disorders, and task settings. Furthermore, we employ meta-learning to optimize the graph prompts, facilitating strong generalization to previously unseen disorders under both few-shot and zero-shot learning conditions via language-guided prompting. BrainGFM is pre-trained on 27 neuroimaging datasets spanning 25 common neurological and psychiatric disorders, encompassing 2 types of brain atlases (functional and anatomical) across 8 widely-used parcellations, and covering over 25,000 subjects, 60,000 fMRI scans, and a total of 400,000 graph samples aggregated across all atlases and parcellations. The code is available at: https://github.com/weixinxu666/BrainGFM</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02044v2</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinxu Wei, Kanhao Zhao, Yong Jiao, Lifang He, Yu Zhang</dc:creator>
    </item>
    <item>
      <title>Markov Blanket Density and Free Energy Minimization</title>
      <link>https://arxiv.org/abs/2506.05794</link>
      <description>arXiv:2506.05794v4 Announce Type: replace 
Abstract: This paper presents a continuous, information-theoretic extension of the Free Energy Principle through the concept of Markov blanket density, i.e., a scalar field that quantifies the degree of conditional independence between internal and external states at each point in space (ranging from 0 for full coupling to 1 for full separation). It demonstrates that active inference dynamics, including the minimization of variational and expected free energy, naturally emerge from spatial gradients in this density, making Markov blanket density a necessary foundation for the Free Energy Principle. These ideas are developed through a mathematically framework that links density gradients to precise and testable dynamics, offering a foundation for novel predictions and simulation paradigms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05794v4</guid>
      <category>q-bio.NC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Luca M. Possati</dc:creator>
    </item>
    <item>
      <title>Enhancing deep neural networks through complex-valued representations and Kuramoto synchronization dynamics</title>
      <link>https://arxiv.org/abs/2502.21077</link>
      <description>arXiv:2502.21077v2 Announce Type: replace-cross 
Abstract: Neural synchrony is hypothesized to play a crucial role in how the brain organizes visual scenes into structured representations, enabling the robust encoding of multiple objects within a scene. However, current deep learning models often struggle with object binding, limiting their ability to represent multiple objects effectively. Inspired by neuroscience, we investigate whether synchrony-based mechanisms can enhance object encoding in artificial models trained for visual categorization. Specifically, we combine complex-valued representations with Kuramoto dynamics to promote phase alignment, facilitating the grouping of features belonging to the same object. We evaluate two architectures employing synchrony: a feedforward model and a recurrent model with feedback connections to refine phase synchronization using top-down information. Both models outperform their real-valued counterparts and complex-valued models without Kuramoto synchronization on tasks involving multi-object images, such as overlapping handwritten digits, noisy inputs, and out-of-distribution transformations. Our findings highlight the potential of synchrony-driven mechanisms to enhance deep learning models, improving their performance, robustness, and generalization in complex visual categorization tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.21077v2</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>nlin.AO</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sabine Muzellec, Andrea Alamia, Thomas Serre, Rufin VanRullen</dc:creator>
    </item>
    <item>
      <title>The Cognitive Foundations of Economic Exchange: A Modular Framework Grounded in Behavioral Evidence</title>
      <link>https://arxiv.org/abs/2505.02945</link>
      <description>arXiv:2505.02945v4 Announce Type: replace-cross 
Abstract: The origins of economic behavior remain unresolved-not only in the social sciences but also in AI, where dominant theories often rely on predefined incentives or institutional assumptions. Contrary to the longstanding myth of barter as the foundation of exchange, converging evidence from early human societies suggests that reciprocity-not barter-was the foundational economic logic, enabling communities to sustain exchange and social cohesion long before formal markets emerged. Yet despite its centrality, reciprocity lacks a simulateable and cognitively grounded account. Here, we introduce a minimal behavioral framework based on three empirically supported cognitive primitives-individual recognition, reciprocal credence, and cost--return sensitivity-that enable agents to participate in and sustain reciprocal exchange, laying the foundation for scalable economic behavior. These mechanisms scaffold the emergence of cooperation, proto-economic exchange, and institutional structure from the bottom up. By bridging insights from primatology, developmental psychology, and economic anthropology, this framework offers a unified substrate for modeling trust, coordination, and economic behavior in both human and artificial systems. For an interactive visualization of the framework, see: https://egil158.github.io/cogfoundations-econ/</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02945v4</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>econ.GN</category>
      <category>q-bio.NC</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Egil Diau</dc:creator>
    </item>
  </channel>
</rss>
