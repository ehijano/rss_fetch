<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 10 Oct 2025 02:01:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Finite element approximation and very weak solution existence in a two-dimensional, degenerate Keller-Segel model</title>
      <link>https://arxiv.org/abs/2510.06341</link>
      <description>arXiv:2510.06341v1 Announce Type: new 
Abstract: This paper is devoted to the design and analysis of a numerical algorithm for approximating solutions of a degenerate cross-diffusion system, which models particular instances of taxis-type migration processes under local sensing mechanisms. The degeneracy leads to solutions that are very weak due to the low regularity themselves. Specifically, the solutions satisfy pointwise bounds (such as positivity and the maximum principle), integrability (such as mass conservation), and dual a priori estimates.
  The proposed numerical scheme combines a finite element spatial discretization with Euler time stepping. The discrete solutions preserve the above-mentioned properties at the discrete level, enabling the derivation of compactness arguments and the convergence (up to a subsequence) of the numerical solutions to a very weak solution of the continuous problem on two-dimensional polygonal domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06341v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Juan Vicente Guti\'errez-Santacreu</dc:creator>
    </item>
    <item>
      <title>Structurally informed data assimilation in two dimensions</title>
      <link>https://arxiv.org/abs/2510.06369</link>
      <description>arXiv:2510.06369v1 Announce Type: new 
Abstract: Accurate data assimilation (DA) for systems with piecewise-smooth or discontinuous state variables remains a significant challenge, as conventional covariance-based ensemble Kalman filter approaches often fail to effectively balance observations and model information near sharp features. In this paper we develop a structurally informed DA framework using ensemble transform Kalman filtering (ETKF). Our approach introduces gradient-based weighting matrices constructed from finite difference statistics of the forecast ensemble, thereby allowing the assimilation process to dynamically adjust the influence of observations and prior estimates according to local roughness. The design is intentionally flexible so that it can be suitably refined for sparse data environments. Numerical experiments demonstrate that our new structurally informed data assimilation framework consistently yields greater accuracy when compared to more conventional approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06369v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tongtong Li, Anne Gelb, Yoonsang Lee</dc:creator>
    </item>
    <item>
      <title>Media Coverage of War Victims: Journalistic Biases in Reporting on Israel and Gaza</title>
      <link>https://arxiv.org/abs/2510.06453</link>
      <description>arXiv:2510.06453v1 Announce Type: new 
Abstract: October 7th 2023 marked the start of a war against Gaza, which is considered one of the most devastating wars in modern history and has led to a stark attitudinal divide within and between countries. To investigate the role of media bias in reporting on this asymmetrical warfare, we analyzed over 14,000 news articles published during the first year of war in three Western (The New York Times, BBC, CNN) and one non-Western English-language outlets (Al Jazeera English). Exploring the media narratives concerning Israeli and Palestinian victims experiencing hardship, we found three systematic biases in Western media. 1) Compared to Palestinian victims, represented mainly as undifferentiated collectives, Israeli victims were more likely to be portrayed as identifiable individual human beings. 2) Despite the striking difference in all forms of hardship (casualties, displacement, etc.), Western journalists created a false balance, equating Israeli and Palestinian suffering, by persistently referring back to the 7th of October massacre, even in the absence of new events involving Israeli victims. 3) When reporting on numbers of Palestinian (vs. Israeli) victims, journalists used language that casts doubt about the credibility of the information and the reputation of the source providing it, thereby selectively undermining the reader's trust in the information regarding Palestinian suffering. Together, our analysis reveals a series of systematic journalistic biases in high-profile Western media that are absent or greatly reduced in Al Jazeera.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06453v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bedoor AlShebli, Bruno Gabriel Salvador Casara, Anne Maass</dc:creator>
    </item>
    <item>
      <title>A Precise Performance Analysis of the Randomized Singular Value Decomposition</title>
      <link>https://arxiv.org/abs/2510.06490</link>
      <description>arXiv:2510.06490v1 Announce Type: new 
Abstract: The Randomized Singular Value Decomposition (RSVD) is a widely used algorithm for efficiently computing low-rank approximations of large matrices, without the need to construct a full-blown SVD. Of interest, of course, is the approximation error of RSVD compared to the optimal low-rank approximation error obtained from the SVD. While the literature provides various upper and lower error bounds for RSVD, in this paper we derive precise asymptotic expressions that characterize its approximation error as the matrix dimensions grow to infinity. Our expressions depend only on the singular values of the matrix, and we evaluate them for two important matrix ensembles: those with power law and bilevel singular value distributions. Our results aim to quantify the gap between the existing theoretical bounds and the actual performance of RSVD. Furthermore, we extend our analysis to polynomial-filtered RSVD, deriving performance characterizations that provide insights into optimal filter selection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06490v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Danil Akhtiamov, Reza Ghane, Babak Hassibi</dc:creator>
    </item>
    <item>
      <title>Convergence of the Immersed Boundary Method for an Elastically Bound Particle Immersed in a 2D Navier-Stokes Fluid Fluid</title>
      <link>https://arxiv.org/abs/2510.06586</link>
      <description>arXiv:2510.06586v1 Announce Type: new 
Abstract: The immersed boundary (IB) method has been used as a means to simulate fluid-membrane interactions in a wide variety of biological and engineering applications. Although the numerical convergence of the method has been empirically verified, it is theoretically unproved because of the singular forcing terms present in the governing equations. This paper is motivated by a specific variant of the IB method, in which the fluid is 2 dimensions greater than the dimension of the immersed structure. In these co-dimension 2 problems the immersed boundary is necessarily mollified in the continuous formulation. In this paper we leverage this fact to prove convergence of the IB method as applied to a moving elastically bound particle in a fully non-linear fluid.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06586v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexandre X. Milewski (Courant Institute of Mathematical Sciences, New York, NY), Charles S. Peskin (Courant Institute of Mathematical Sciences, New York, NY)</dc:creator>
    </item>
    <item>
      <title>Algorithm for constructing optimal explicit finite-difference formulas in the Hilbert space</title>
      <link>https://arxiv.org/abs/2510.06643</link>
      <description>arXiv:2510.06643v1 Announce Type: new 
Abstract: This work presents problems of constructing finite-difference formulas in the Hilbert space, i.e., setting problems of constructing finite-difference formulas using functional methods. The work presents a functional statement of the problem of optimizing finite-difference formulas in the space $W_{2}^{\left(m,m-1\right)} \left(0,1\right)$. Here, representations of optimal coefficients of explicit finite-difference formulas of the Adams type on classes $W_{2}^{\left(m,m-1\right)} \left(0,1\right)$ for any $m\ge 3$ will be found.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06643v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>R. S. Karimov, D. D. Atoev</dc:creator>
    </item>
    <item>
      <title>Mass-Lumped Virtual Element Method with Strong Stability-Preserving Runge-Kutta Time Stepping for Two-Dimensional Parabolic Problems</title>
      <link>https://arxiv.org/abs/2510.06653</link>
      <description>arXiv:2510.06653v1 Announce Type: new 
Abstract: This paper presents a mass-lumped Virtual Element Method (VEM) with explicit Strong Stability-Preserving Runge-Kutta (SSP-RK) time integration for two-dimensional parabolic problems on general polygonal meshes. A diagonal mass matrix is constructed via row-sum operations combined with flooring to ensure uniform positivity. Stabilization terms vanish identically under row summation, so the lumped weights derive solely from the $L^2$ projector and are computable through a small polynomial system at cost $\mathcal{O}(N_k^3)$ per element. The resulting lumped bilinear form satisfies $L^2$-equivalence with edge-count-independent constants, yielding a symmetric positive definite discrete inner product. A mesh-robust spectral bound $\lambda_{\max}\big((\hat{\mathbf{M}}_h)^{-1}\mathbf{K}_h\big) \le C_{\mathrm{inv}}^2/\hat{\beta}_* \cdot h^{-2}$ is established with constants depending only on spatial dimension, polynomial order, and mesh regularity. This delivers the classical diffusion-type CFL condition $\Delta t=\mathcal{O}(h^2)$ for forward Euler stability and extends to higher-order SSP-RK schemes, guaranteeing preservation of energy decay, positivity, and discrete maximum principles. Numerical experiments on distorted quadrilaterals, serendipity elements, and Voronoi polygons validate the theoretical predictions: the lumped VEM with $k=1$ achieves optimal convergence rates ($\mathcal{O}(h)$ in $H^1$, $\mathcal{O}(h^2)$ in $L^2$) with no degradation from geometric distortion or mass lumping, while SSP-RK integrators remain stable under the predicted $\Delta t\propto h^{2}$ scaling</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06653v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paulo Akira F. Enabe, Rodrigo Provasi</dc:creator>
    </item>
    <item>
      <title>An Integral Equation Method for Linear Two-Point Boundary Value Systems</title>
      <link>https://arxiv.org/abs/2510.06678</link>
      <description>arXiv:2510.06678v1 Announce Type: new 
Abstract: We present an integral equation-based method for the numerical solution of two-point boundary value systems. Special care is devoted to the mathematical formulation, namely the choice of the background Green's function that leads to a well-conditioned integral equation. We then make use of a high-order Nystrom discretization and a fast direct solver on the continuous level to obtain a black-box solver that is fast and accurate. A numerical study of the conditioning of different integral formulations is carried out. Excellent performance in speed, accuracy, and robustness is demonstrated with several challenging numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06678v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianze Zhang, Yixuan Ma, Jun Wang</dc:creator>
    </item>
    <item>
      <title>Randomized Quasi-Monte Carlo with Importance Sampling for Functions under Generalized Growth Conditions and Its Applications in Finance</title>
      <link>https://arxiv.org/abs/2510.06705</link>
      <description>arXiv:2510.06705v1 Announce Type: new 
Abstract: Many problems can be formulated as high-dimensional integrals of discontinuous functions that often exhibit significant growth, challenging the error analysis of randomized quasi-Monte Carlo (RQMC) methods. This paper studies RQMC methods for functions with generalized exponential growth conditions, with a special focus on financial derivative pricing. The main contribution of this work is threefold. First, by combining RQMC and importance sampling (IS) techniques, we derive a new error bound for a class of integrands with the critical growth condition $e^{A\|\boldsymbol{x}\|^2}$ where $A = 1/2$. This theory extends existing results in the literature, which are limited to the case $A &lt; 1/2$, and we demonstrate that by imposing a light-tail condition on the proposal distribution in the IS, the RQMC method can maintain its high-efficiency convergence rate even in this critical growth scenario. Second, we verify that the Gaussian proposals used in Optimal Drift Importance Sampling (ODIS) satisfy the required light-tail condition, providing rigorous theoretical guarantees for RQMC-ODIS in critical growth scenarios. Third, for discontinuous integrands from finance, we combine the preintegration technique with RQMC-IS. We prove that this integrand after preintegration preserves the exponential growth condition. This ensures that the preintegrated discontinuous functions can be seamlessly incorporated into our RQMC-IS convergence framework. Finally, numerical results validate our theory, showing that the proposed method is effective in handling these problems with discontinuous payoffs, successfully achieving the expected convergence rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06705v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianlong Chen, Yu Xu, Xiaoqun Wang</dc:creator>
    </item>
    <item>
      <title>An Inertial Langevin Algorithm</title>
      <link>https://arxiv.org/abs/2510.06723</link>
      <description>arXiv:2510.06723v1 Announce Type: new 
Abstract: We present a novel method for drawing samples from Gibbs distributions with densities of the form $\pi(x) \propto \exp(-U(x))$. The method accelerates the unadjusted Langevin algorithm by introducing an inertia term similar to Polyak's heavy ball method, together with a corresponding noise rescaling. Interpreting the scheme as a discretization of \emph{kinetic} Langevin dynamics, we prove ergodicity (in continuous and discrete time) for twice continuously differentiable, strongly convex, and $L$-smooth potentials and bound the bias of the discretization to the target in Wasserstein-2 distance. In particular, the presented proofs allow for smaller friction parameters in the kinetic Langevin diffusion compared to existing literature. Moreover, we show the close ties of the proposed method to the over-relaxed Gibbs sampler. The scheme is tested in an extensive set of numerical experiments covering simple toy examples, total variation image denoising, and the complex task of maximum likelihood learning of an energy-based model for molecular structure generation. The experimental results confirm the acceleration provided by the proposed scheme even beyond the strongly convex and $L$-smooth setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06723v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Falk, Andreas Habring, Christoph Griesbacher, Thomas Pock</dc:creator>
    </item>
    <item>
      <title>Optimal network pricing with oblivious users: a new model and algorithm</title>
      <link>https://arxiv.org/abs/2510.07157</link>
      <description>arXiv:2510.07157v2 Announce Type: new 
Abstract: Traffic modeling is important in modern society. In this work we propose a new model on the optimal network pricing (Onp) with the assumption of oblivious users, in which the users remain oblivious to real-time traffic conditions and others' behavior. Inspired by works on transportation research and network pricing for selfish traffic, we mathematically derive and prove a new formulation of Onp with decision-dependent modeling that relax certain existing modeling constraints in the literature. Then, we express the Onp formulation as a constrained nonconvex stochastic quadratic program with uncertainty, and we propose an efficient algorithm to solve the problem, utilizing graph theory, sparse linear algebra and stochastic approximation. Lastly, we showcase the effectiveness of the proposed algorithm and the usefulness of the new Onp formulation. The proposed algorithm achieves a 5x speedup by exploiting the sparsity structure of the model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.07157v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yixuan Li, Andersen Ang, Sebastian Stein</dc:creator>
    </item>
    <item>
      <title>Greedy Thiele continued-fraction approximation on continuum domains in the complex plane</title>
      <link>https://arxiv.org/abs/2510.07295</link>
      <description>arXiv:2510.07295v1 Announce Type: new 
Abstract: We describe an adaptive greedy algorithm for Thiele continued-fraction approximation of a function defined on a continuum domain in the complex plane. The algorithm iteratively selects interpolation nodes from an adaptively refined set of sample points on the domain boundary. We also present new algorithms for evaluating Thiele continued fractions and their accessory weights using only a single floating-point division. Numerical experiments comparing the greedy TCF method with the AAA algorithm on several challenging functions defined on the interval $[-1,1]$ and on the unit circle show that continuum TCF is consistently 2.5 to 8 times faster than AAA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.07295v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.CV</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Tobin A. Driscoll, Yuxing Zhou</dc:creator>
    </item>
    <item>
      <title>Quantum matrix arithmetics with Hamiltonian evolution</title>
      <link>https://arxiv.org/abs/2510.06316</link>
      <description>arXiv:2510.06316v1 Announce Type: cross 
Abstract: The efficient implementation of matrix arithmetic operations underpins the speedups of many quantum algorithms. We develop a suite of methods to perform matrix arithmetics -- with the result encoded in the off-diagonal blocks of a Hamiltonian -- using Hamiltonian evolutions of input operators. We show how to maintain this $\textit{Hamiltonian block encoding}$, so that matrix operations can be composed one after another, and the entire quantum computation takes $\leq 2$ ancilla qubits. We achieve this for matrix multiplication, matrix addition, matrix inversion, Hermitian conjugation, fractional scaling, integer scaling, complex phase scaling, as well as singular value transformation for both odd and even polynomials. We also present an overlap estimation algorithm to extract classical properties of Hamiltonian block encoded operators, analogous to the well known Hadmard test, at no extra cost of qubit. Our Hamiltonian matrix multiplication uses the Lie group commutator product formula and its higher-order generalizations due to Childs and Wiebe. Our Hamiltonian singular value transformation employs a dominated polynomial approximation, where the approximation holds within the domain of interest, while the constructed polynomial is upper bounded by the target function over the entire unit interval. We describe a circuit for simulating a class of sum-of-squares Hamiltonians, attaining a commutator scaling in step count, while leveraging the power of matrix arithmetics to reduce the cost of each simulation step. In particular, we apply this to the doubly factorized tensor hypercontracted Hamiltonians from recent studies of quantum chemistry, obtaining further improvements for initial states with a fixed number of particles. We achieve this with $1$ ancilla qubit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06316v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.chem-ph</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christopher Kang, Yuan Su</dc:creator>
    </item>
    <item>
      <title>AutoBalance: An Automatic Balancing Framework for Training Physics-Informed Neural Networks</title>
      <link>https://arxiv.org/abs/2510.06684</link>
      <description>arXiv:2510.06684v1 Announce Type: cross 
Abstract: Physics-Informed Neural Networks (PINNs) provide a powerful and general framework for solving Partial Differential Equations (PDEs) by embedding physical laws into loss functions. However, training PINNs is notoriously difficult due to the need to balance multiple loss terms, such as PDE residuals and boundary conditions, which often have conflicting objectives and vastly different curvatures. Existing methods address this issue by manipulating gradients before optimization (a "pre-combine" strategy). We argue that this approach is fundamentally limited, as forcing a single optimizer to process gradients from spectrally heterogeneous loss landscapes disrupts its internal preconditioning. In this work, we introduce AutoBalance, a novel "post-combine" training paradigm. AutoBalance assigns an independent adaptive optimizer to each loss component and aggregates the resulting preconditioned updates afterwards. Extensive experiments on challenging PDE benchmarks show that AutoBalance consistently outperforms existing frameworks, achieving significant reductions in solution error, as measured by both the MSE and $L^{\infty}$ norms. Moreover, AutoBalance is orthogonal to and complementary with other popular PINN methodologies, amplifying their effectiveness on demanding benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06684v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kang An, Chenhao Si, Ming Yan, Shiqian Ma</dc:creator>
    </item>
    <item>
      <title>Machine Learning enhanced parametric Reynolds-averaged Navier-Stokes equations at the full and reduced order levels</title>
      <link>https://arxiv.org/abs/2510.06992</link>
      <description>arXiv:2510.06992v1 Announce Type: cross 
Abstract: In this contribution, we focus on the Reynolds-Averaged Navier-Stokes (RANS) models and their exploitation to build reliable reduced order models to further accelerate predictions for real-time applications and many-query scenarios. Specifically, we investigate how machine learning can be employed to enhance the predictive capabilities of the model, both at the Full Order Model (FOM) and Reduced Order Model (ROM) levels. We explore a novel integration of these two areas. We generate the FOM snapshots, essential for ROM construction, using a data-driven RANS model: the $\nu_t$-Vector Basis Neural Network. This is the first time that these machine learning procedure generalizes a large parametric variation, and we propose tailored training strategies to increase the accuracy of the FOM model. At the ROM level, we compare the results obtained by standard Proper Orthogonal Decomposition in an intrusive Galerkin setting (PODG) and POD Neural Network approach (PODNN). The numerical validation is based on a classic turbulent flow benchmark: the flow in a square duct. Our investigation reveals that the PODG method, proves unstable and inaccurate for turbulent flow prediction, while PODNN demonstrates superior performance in terms of accuracy and computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06992v1</guid>
      <category>physics.flu-dyn</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Davide Oberto, Maria Strazzullo, Stefano Berrone</dc:creator>
    </item>
    <item>
      <title>TOMATOES: Topology and Material Optimization for Latent Heat Thermal Energy Storage Devices</title>
      <link>https://arxiv.org/abs/2510.07057</link>
      <description>arXiv:2510.07057v1 Announce Type: cross 
Abstract: Latent heat thermal energy storage (LHTES) systems are compelling candidates for energy storage, primarily owing to their high storage density. Improving their performance is crucial for developing the next-generation efficient and cost effective devices. Topology optimization (TO) has emerged as a powerful computational tool to design LHTES systems by optimally distributing a high-conductivity material (HCM) and a phase change material (PCM). However, conventional TO typically limits to optimizing the geometry for a fixed, pre-selected materials. This approach does not leverage the large and expanding databases of novel materials. Consequently, the co-design of material and geometry for LHTES remains a challenge and unexplored.
  To address this limitation, we present an automated design framework for the concurrent optimization of material choice and topology. A key challenge is the discrete nature of material selection, which is incompatible with the gradient-based methods used for TO. We overcome this by using a data-driven variational autoencoder (VAE) to project discrete material databases for both the HCM and PCM onto continuous and differentiable latent spaces. These continuous material representations are integrated into an end-to-end differentiable, transient nonlinear finite-element solver that accounts for phase change. We demonstrate this framework on a problem aimed at maximizing the discharged energy within a specified time, subject to cost constraints. The effectiveness of the proposed method is validated through several illustrative examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.07057v1</guid>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rahul Kumar Padhy, Krishnan Suresh, Aaditya Chandrasekhar</dc:creator>
    </item>
    <item>
      <title>Derivation of the fourth-order DLSS equation with nonlinear mobility via chemical reactions</title>
      <link>https://arxiv.org/abs/2510.07149</link>
      <description>arXiv:2510.07149v1 Announce Type: cross 
Abstract: We provide a derivation of the fourth-order DLSS equation based on an interpretation as a chemical reaction network. We consider the rate equation on the discretized circle for a process in which pairs of particles occupying the same site simultaneously jump to the two neighboring sites; the reverse process involves pairs of particles at adjacent sites simultaneously jumping back to the site located between them. Depending on the rates, in the vanishing-mesh-size limit we obtain either the classical DLSS equation or a variant with nonlinear mobility of power type. Via EDP convergence, we identify the limiting gradient structure to be driven by entropy with respect to a generalization of diffusive transport with nonlinear mobility. Interestingly, the DLSS equation with power-type mobility shares qualitative similarities with the fast diffusion and porous medium equation, since we find traveling wave solutions with algebraic tails or compactly supported polynomials, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.07149v1</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.NA</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Mielke, Andr\'e Schlichting, Artur Stephan</dc:creator>
    </item>
    <item>
      <title>Goal-oriented adaptivity for multilevel stochastic Galerkin FEM with nonlinear goal functionals</title>
      <link>https://arxiv.org/abs/2208.09388</link>
      <description>arXiv:2208.09388v3 Announce Type: replace 
Abstract: This paper is concerned with the numerical approximation of quantities of interest associated with solutions to parametric elliptic partial differential equations (PDEs). The key novelty of this work is in its focus on the quantities of interest represented by continuously G\^ateaux differentiable nonlinear functionals. We consider a class of parametric elliptic PDEs where the underlying differential operator has affine dependence on a countably infinite number of uncertain parameters. We design a goal-oriented adaptive algorithm for approximating nonlinear functionals of solutions to this class of parametric PDEs. In the algorithm, the approximations of parametric solutions to the primal and dual problems are computed using the multilevel stochastic Galerkin finite element method (SGFEM) and the adaptive refinement process is guided by reliable spatial and parametric error reduction indicators. We prove that the proposed algorithm generates multilevel SGFEM approximations for which the estimates of the error in the goal functional converge to zero. Numerical experiments for a selection of test problems and nonlinear quantities of interest illustrate and underpin our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.09388v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alex Bespalov, Dirk Praetorius, Michele Ruggeri</dc:creator>
    </item>
    <item>
      <title>Stability in Training PINNs for Stiff PDEs: Why Initial Conditions Matter</title>
      <link>https://arxiv.org/abs/2404.16189</link>
      <description>arXiv:2404.16189v3 Announce Type: replace 
Abstract: Training Physics-Informed Neural Networks (PINNs) on stiff time-dependent PDEs remains highly unstable. Through rigorous ablation studies, we identify a surprisingly critical factor: the enforcement of initial conditions. We present the first systematic ablation of two core strategies, hard initial-condition constraints and adaptive loss weighting. Across challenging benchmarks (sharp transitions, higher-order derivatives, coupled systems, and high frequency modes), we find that exact enforcement of initial conditions (ICs) is not optional but essential. Our study demonstrates that stability and efficiency in PINN training fundamentally depend on ICs, paving the way toward more reliable PINN solvers in stiff regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16189v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Baoli Hao, Ulisses Braga-Neto, Chun Liu, Lifan Wang, Ming Zhong</dc:creator>
    </item>
    <item>
      <title>Hyper-differential sensitivity analysis with respect to model discrepancy: Prior distributions</title>
      <link>https://arxiv.org/abs/2504.19812</link>
      <description>arXiv:2504.19812v2 Announce Type: replace 
Abstract: Hyper-differential sensitivity analysis with respect to model discrepancy was recently developed to enable uncertainty quantification for optimization problems. The approach consists of two primary steps: (i) Bayesian calibration of the discrepancy between high- and low-fidelity models, and (ii) propagating the model discrepancy uncertainty through the optimization problem. When high-fidelity model evaluations are limited, as is common in practice, the prior discrepancy distribution plays a crucial role in the uncertainty analysis. However, specification of this prior is challenging due to its mathematical complexity and many hyper-parameters. This article presents a novel approach to specify the prior distribution. Our approach consists of two parts: (1) an algorithmic initialization of the prior hyper-parameters that uses existing data to initialize a hyper-parameter estimate, and (2) a visualization framework to systematically explore properties of the prior and guide tuning of the hyper-parameters to ensure that the prior captures the appropriate range of uncertainty. We provide detailed mathematical analysis and a collection of numerical examples that elucidate properties of the prior that are crucial to ensure uncertainty quantification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19812v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joseph Hart, Bart van Bloemen Waanders, Jixian Li, Timbwaoga A. J. Ouermi, Chris R. Johnson</dc:creator>
    </item>
    <item>
      <title>Convergence Guarantees for Gradient-Based Training of Neural PDE Solvers: From Linear to Nonlinear PDEs</title>
      <link>https://arxiv.org/abs/2505.14002</link>
      <description>arXiv:2505.14002v3 Announce Type: replace 
Abstract: We present a unified convergence theory for gradient-based training of neural network methods for partial differential equations (PDEs), covering both physics-informed neural networks (PINNs) and the Deep Ritz method. For linear PDEs, we extend the neural tangent kernel (NTK) framework for PINNs to establish global convergence guarantees for a broad class of linear operators. For nonlinear PDEs, we prove convergence to critical points via the \L{}ojasiewicz inequality under the random feature model, eliminating the need for strong over-parameterization and encompassing both gradient flow and implicit gradient descent dynamics. Our results further reveal that the random feature model exhibits an implicit regularization effect, preventing parameter divergence to infinity. Theoretical findings are corroborated by numerical experiments, providing new insights into the training dynamics and robustness of neural network PDE solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.14002v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wei Zhao, Tao Luo</dc:creator>
    </item>
    <item>
      <title>A noise-robust Monte Carlo method for electric field calculations in EMC3</title>
      <link>https://arxiv.org/abs/2509.19178</link>
      <description>arXiv:2509.19178v2 Announce Type: replace 
Abstract: One of the main codes to analyze and optimize stellarator configurations is the EMC3 code, which implements a state-of-the-art 3D Monte Carlo plasma edge transport code. However, so far, a self-consistent treatment of the E x B drift is absent. This plasma drift is known to significantly impact the particle and heat distribution in the plasma edge. It is desirable to incorporate this drift into EMC3 to improve the predictive capabilities of the code. The calculation of the E x B drift requires the approximation of the electric field E, which is proportional to the gradient of the electric potential $ \varphi $. In previous work, the gradient was calculated with a least squares method based on a finite difference approximation of the electric potential. However, due to the stochastic nature of EMC3, the output plasma fields computed by the code are inherently noisy. The finite difference method further amplifies the noise, with the amplification growing as the grid size decreases. We continue from, which introduced a new noise-robust method for 1D derivatives. We extend the noise-robust method to 2D and apply it to the electric potential. We show that a PDE can be derived that describes the evolution of the electric field in case of a uniform diffusion coefficient. This PDE allows us to approximate the electric field directly with a Monte Carlo simulation, thus avoiding the need for a finite difference approximation. We illustrate the accuracy of the method and the noise robustness with a test case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.19178v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.plasm-ph</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>William De Deyn, Ruben De Wolf, Vince Maes, Giovanni Samaey</dc:creator>
    </item>
    <item>
      <title>Error Bounds for Physics-Informed Neural Networks in Fokker-Planck PDEs</title>
      <link>https://arxiv.org/abs/2410.22371</link>
      <description>arXiv:2410.22371v3 Announce Type: replace-cross 
Abstract: Stochastic differential equations are commonly used to describe the evolution of stochastic processes. The state uncertainty of such processes is best represented by the probability density function (PDF), whose evolution is governed by the Fokker-Planck partial differential equation (FP-PDE). However, it is generally infeasible to solve the FP-PDE in closed form. In this work, we show that physics-informed neural networks (PINNs) can be trained to approximate the solution PDF. Our main contribution is the analysis of PINN approximation error: we develop a theoretical framework to construct tight error bounds using PINNs. In addition, we derive a practical error bound that can be efficiently constructed with standard training methods. We discuss that this error-bound framework generalizes to approximate solutions of other linear PDEs. Empirical results on nonlinear, high-dimensional, and chaotic systems validate the correctness of our error bounds while demonstrating the scalability of PINNs and their significant computational speedup in obtaining accurate PDF solutions compared to the Monte Carlo approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22371v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chun-Wei Kong, Luca Laurenti, Jay McMahon, Morteza Lahijanian</dc:creator>
    </item>
    <item>
      <title>Amplitude Expansion Phase Field Crystal (APFC) Modeling based Efficient Dislocation Simulations using Fourier Pseudospectral Method</title>
      <link>https://arxiv.org/abs/2410.22720</link>
      <description>arXiv:2410.22720v3 Announce Type: replace-cross 
Abstract: Crystalline defects critically influence material properties, necessitating accurate simulation methods. Existing approaches, from atomic-scale configurations to continuum elasticity, face inherent limitations in modeling dislocation-induced lattice deformation. The amplitude expansion of the phase field crystal (APFC) model bridges this gap with a mesoscopic description. This paper introduces a computationally efficient Fourier pseudospectral method for solving the APFC equations. The method exploits system periodicity and solution analyticity--the latter's rigorous proof remaining an open question, as discussed herein--to enable precise implementation of periodic boundary conditions. Numerical experiments on 2D triangular and 3D body-centered cubic lattices demonstrate that the method accurately reproduces the strain fields of edge dislocations, matching continuum theory predictions. These results confirm the APFC model's potential for capturing complex defect structures at the mesoscale, paving the way for simulating more intricate defect dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22720v3</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xinyi Wei, Yangshuai Wang, Kai Jiang, Lei Zhang</dc:creator>
    </item>
    <item>
      <title>VICON: Vision In-Context Operator Networks for Multi-Physics Fluid Dynamics Prediction</title>
      <link>https://arxiv.org/abs/2411.16063</link>
      <description>arXiv:2411.16063v4 Announce Type: replace-cross 
Abstract: In-Context Operator Networks (ICONs) have demonstrated the ability to learn operators across diverse partial differential equations using few-shot, in-context learning. However, existing ICONs process each spatial point as an individual token, severely limiting computational efficiency when handling dense data in higher spatial dimensions. We propose Vision In-Context Operator Networks (VICON), which integrates vision transformer architectures to efficiently process 2D data through patch-wise operations while preserving ICON's adaptability to multiphysics systems and varying timesteps. Evaluated across three fluid dynamics benchmarks, VICON significantly outperforms state-of-the-art baselines: DPOT and MPP, reducing the averaged last-step rollout error by 37.9% compared to DPOT and 44.7% compared to MPP, while requiring only 72.5% and 34.8% of their respective inference times. VICON naturally supports flexible rollout strategies with varying timestep strides, enabling immediate deployment in imperfect measurement systems where sampling frequencies may differ or frames might be dropped - common challenges in real-world settings - without requiring retraining or interpolation. In these realistic scenarios, VICON exhibits remarkable robustness, experiencing only 24.41% relative performance degradation compared to 71.37%-74.49% degradation in baseline methods, demonstrating its versatility for deploying in realistic applications. Our scripts for processing datasets and code are publicly available at https://github.com/Eydcao/VICON.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16063v4</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.flu-dyn</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yadi Cao, Yuxuan Liu, Liu Yang, Rose Yu, Hayden Schaeffer, Stanley Osher</dc:creator>
    </item>
    <item>
      <title>Efficient gradient-based methods for bilevel learning via recycling Krylov subspaces</title>
      <link>https://arxiv.org/abs/2412.08264</link>
      <description>arXiv:2412.08264v2 Announce Type: replace-cross 
Abstract: Many optimization problems require hyperparameters, i.e., parameters that must be pre-specified in advance, such as regularization parameters and parametric regularizers in variational regularization methods for inverse problems, and dictionaries in compressed sensing. A data-driven approach to determine appropriate hyperparameter values is via a nested optimization framework known as bilevel learning. Even when it is possible to employ a gradient-based solver to the bilevel optimization problem, construction of the gradients, known as hypergradients, is computationally challenging, each one requiring both a solution of a minimization problem and a linear system solve. These systems do not change much during the iterations, which motivates us to apply recycling Krylov subspace methods, wherein information from one linear system solve is re-used to solve the next linear system. Existing recycling strategies often employ eigenvector approximations called Ritz vectors. In this work we propose a novel recycling strategy based on a new concept, Ritz generalized singular vectors, which acknowledge the bilevel setting. Additionally, while existing iterative methods primarily terminate according to the residual norm, this new concept allows us to define a new stopping criterion that directly approximates the error of the associated hypergradient. The proposed approach is validated through extensive numerical testing in the context of inverse problems in imaging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08264v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthias J. Ehrhardt, Silvia Gazzola, Sebastian J. Scott</dc:creator>
    </item>
    <item>
      <title>Improving Interoperability in Scientific Computing via MaRDI Open Interfaces</title>
      <link>https://arxiv.org/abs/2504.03628</link>
      <description>arXiv:2504.03628v2 Announce Type: replace-cross 
Abstract: MaRDI Open Interfaces is a software project aimed at improving reuse and interoperability in Scientific Computing by alleviating the difficulties of crossing boundaries between different programming languages, in which numerical packages are usually implemented, and of switching between multiple implementations of the same mathematical problem. The software consists of a set of formal interface specifications for common Scientific Computing tasks, as well as a set of loosely coupled libraries that facilitate implementing these interfaces or adapting existing implementations for multiple programming languages and handle data marshalling automatically without sacrificing performance, enabling users to use different implementations without significant code efforts. The software has high reuse potential due to aim to solve general numerical problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03628v2</guid>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dmitry I. Kabanov (Mathematics M\"unster, University of M\"unster, Germany), Stephan Rave (Mathematics M\"unster, University of M\"unster, Germany), Mario Ohlberger (Mathematics M\"unster, University of M\"unster, Germany)</dc:creator>
    </item>
    <item>
      <title>PolyKAN: A Polyhedral Analysis Framework for Provable and Approximately Optimal KAN Compression</title>
      <link>https://arxiv.org/abs/2510.04205</link>
      <description>arXiv:2510.04205v2 Announce Type: replace-cross 
Abstract: Kolmogorov-Arnold Networks (KANs) have emerged as a promising alternative to traditional Multi-Layer Perceptrons (MLPs), offering enhanced interpretability and a solid mathematical foundation. However, their parameter efficiency remains a significant challenge for practical deployment. This paper introduces PolyKAN, a novel theoretical framework for KAN compression that provides formal guarantees on both model size reduction and approximation error. By leveraging the inherent piecewise polynomial structure of KANs, we formulate the compression problem as a polyhedral region merging task. We establish a rigorous polyhedral characterization of KANs, develop a complete theory of $\epsilon$-equivalent compression, and design a dynamic programming algorithm that achieves approximately optimal compression under specified error bounds. Our theoretical analysis demonstrates that PolyKAN achieves provably near-optimal compression while maintaining strict error control, with guaranteed global optimality for univariate spline functions. This framework provides the first formal foundation for KAN compression with mathematical guarantees, opening new directions for the efficient deployment of interpretable neural architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04205v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Di Zhang</dc:creator>
    </item>
    <item>
      <title>Structure-Preserving MHD-Driftkinetic Discretization for Wave-Particle Interactions</title>
      <link>https://arxiv.org/abs/2510.04385</link>
      <description>arXiv:2510.04385v2 Announce Type: replace-cross 
Abstract: We present a structure-preserving discretization of the hybrid magnetohydrodynamics (MHD)-driftkinetic system for simulations of low-frequency wave-particle interactions. The model equations are derived from a variational principle, assuring energetically consistent couplings between MHD fluids and driftkinetic particles. The spatial discretization is based on a finite-element-exterior-calculus (FEEC) framework for the MHD and a particle-in-cell (PIC) method for the driftkinetic. A key feature of the scheme is the inclusion of the non-quadratic particle magnetic moment energy term in the Hamiltonian, which is introduced by the guiding-center approximation. The resulting discrete Hamiltonian structure naturally organizes the dynamics into skew-symmetric subsystems, enabling balanced energy exchange. To handle the non-quadratic energy term, we develop energy-preserving time integrators based on discrete gradient methods. The algorithm is implemented in the open-source Python package $\texttt{STRUPHY}$. Numerical experiments confirm the energy-conserving property of the scheme and demonstrate the capability to simulate energetic particles (EP) induced excitation of toroidal Alfv\'en eigenmodes (TAE) without artificial dissipation or mode filtering. This capability highlights the potential of structure-preserving schemes for high-fidelity simulations of hybrid systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04385v2</guid>
      <category>physics.comp-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.plasm-ph</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Byung Kyu Na, Stefan Possanner, Xin Wang</dc:creator>
    </item>
  </channel>
</rss>
