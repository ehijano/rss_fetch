<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 01 Nov 2024 02:05:38 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 31 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Systematic Literature Review of Spatio-Temporal Graph Neural Network Models for Time Series Forecasting and Classification</title>
      <link>https://arxiv.org/abs/2410.22377</link>
      <description>arXiv:2410.22377v1 Announce Type: cross 
Abstract: In recent years, spatio-temporal graph neural networks (GNNs) have attracted considerable interest in the field of time series analysis, due to their ability to capture dependencies among variables and across time points. The objective of the presented systematic literature review is hence to provide a comprehensive overview of the various modeling approaches and application domains of GNNs for time series classification and forecasting. A database search was conducted, and over 150 journal papers were selected for a detailed examination of the current state-of-the-art in the field. This examination is intended to offer to the reader a comprehensive collection of proposed models, links to related source code, available datasets, benchmark models, and fitting results. All this information is hoped to assist researchers in future studies. To the best of our knowledge, this is the first systematic literature review presenting a detailed comparison of the results of current spatio-temporal GNN models in different domains. In addition, in its final part this review discusses current limitations and challenges in the application of spatio-temporal GNNs, such as comparability, reproducibility, explainability, poor information capacity, and scalability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22377v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>physics.data-an</category>
      <pubDate>Thu, 31 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Flavio Corradini, Marco Gori, Carlo Lucheroni, Marco Piangerelli, Martina Zannotti</dc:creator>
    </item>
    <item>
      <title>Physical Meaning of Principal Component Analysis for Lattice Systems with Translational Invariance</title>
      <link>https://arxiv.org/abs/2410.22682</link>
      <description>arXiv:2410.22682v1 Announce Type: cross 
Abstract: We seek for the physical implication of principal component analysis (PCA) applied to lattice systems with phase transitions, especially when the system is translationally invariant. We present a general approximate formula for a principal component as well as all other eigenvalues and argue that the approximation becomes exact if the size of data is infinite. The formula explains the connection between the principal component and the corresponding order parameter and, therefore, the reason why PCA is successful. Our result can also be used to estimate a principal component without performing matrix diagonalization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22682v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>physics.data-an</category>
      <pubDate>Thu, 31 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Su-Chan Park</dc:creator>
    </item>
    <item>
      <title>Elephant random walks with graph based shared memory: First and second order asymptotics</title>
      <link>https://arxiv.org/abs/2410.22969</link>
      <description>arXiv:2410.22969v1 Announce Type: cross 
Abstract: We consider a generalization of the so-called elephant random walk by introducing multiple elephants moving along the integer line, $\mathbb{Z}$. When taking a new step, each elephant considers not only its own previous steps but also the past steps of other elephants. The dynamics of "who follows whom" are governed by a directed graph, where each vertex represents an elephant, and the edges indicate that an elephant will consider the past steps of its in-neighbour elephants when deciding its next move. In other words, this model involves a collection of reinforced random walks evolving through graph-based interactions. We briefly investigate the first- and second-order asymptotic behaviour of the joint walks and establish connections with other network-based reinforced stochastic processes studied in the literature. We show that the joint walk can be expressed as a stochastic approximation scheme. In certain regimes, we employ tools from stochastic approximation theory to derive the asymptotic properties of the joint walks. Additionally, in a specific regime, we use better techniques to establish a strong invariance principle and a central limit theorem with improved rates compared to existing results in the stochastic approximation literature. These techniques can also be used to strengthen equivalent results in stochastic approximation theory. As a byproduct, we establish a strong invariance principle for the simple elephant random walk with significantly improved rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22969v1</guid>
      <category>math.PR</category>
      <category>physics.data-an</category>
      <pubDate>Thu, 31 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Deborshi Das</dc:creator>
    </item>
    <item>
      <title>Full-waveform earthquake source inversion using simulation-based inference</title>
      <link>https://arxiv.org/abs/2410.23238</link>
      <description>arXiv:2410.23238v1 Announce Type: cross 
Abstract: This paper presents a novel framework for full-waveform seismic source inversion using simulation-based inference (SBI). Traditional probabilistic approaches often rely on simplifying assumptions about data errors, which we show can lead to inaccurate uncertainty quantification. SBI addresses this limitation by building an empirical probabilistic model of the data errors using machine learning models, known as neural density estimators, which can then be integrated into the Bayesian inference framework. We apply the SBI framework to point-source moment tensor inversions as well as joint moment tensor and time-location inversions. We construct a range of synthetic examples to explore the quality of the SBI solutions, as well as to compare the SBI results with standard Gaussian likelihood-based Bayesian inversions. We then demonstrate that under real seismic noise, common Gaussian likelihood assumptions for treating full-waveform data yield overconfident posterior distributions that underestimate the moment tensor component uncertainties by up to a factor of 3. We contrast this with SBI, which produces well-calibrated posteriors that generally agree with the true seismic source parameters, and offers an order-of-magnitude reduction in the number of simulations required to perform inference compared to standard Monte Carlo techniques. Finally, we apply our methodology to a pair of moderate magnitude earthquakes in the North Atlantic. We utilise seismic waveforms recorded by the recent UPFLOW ocean bottom seismometer array as well as by regional land stations in the Azores, comparing full moment tensor and source-time location posteriors between SBI and a Gaussian likelihood approach. We find that our adaptation of SBI can be directly applied to real earthquake sources to efficiently produce high quality posterior distributions that significantly improve upon Gaussian likelihood approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23238v1</guid>
      <category>physics.geo-ph</category>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <pubDate>Thu, 31 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>A. A. Saoulis, D. Piras, A. Spurio Mancini, B. Joachimi, A. M. G. Ferreira</dc:creator>
    </item>
    <item>
      <title>Lorentz-Equivariant Geometric Algebra Transformers for High-Energy Physics</title>
      <link>https://arxiv.org/abs/2405.14806</link>
      <description>arXiv:2405.14806v3 Announce Type: replace 
Abstract: Extracting scientific understanding from particle-physics experiments requires solving diverse learning problems with high precision and good data efficiency. We propose the Lorentz Geometric Algebra Transformer (L-GATr), a new multi-purpose architecture for high-energy physics. L-GATr represents high-energy data in a geometric algebra over four-dimensional space-time and is equivariant under Lorentz transformations, the symmetry group of relativistic kinematics. At the same time, the architecture is a Transformer, which makes it versatile and scalable to large systems. L-GATr is first demonstrated on regression and classification tasks from particle physics. We then construct the first Lorentz-equivariant generative model: a continuous normalizing flow based on an L-GATr network, trained with Riemannian flow matching. Across our experiments, L-GATr is on par with or outperforms strong domain-specific baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14806v3</guid>
      <category>physics.data-an</category>
      <category>cs.LG</category>
      <category>hep-ph</category>
      <category>stat.ML</category>
      <pubDate>Thu, 31 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonas Spinner, Victor Bres\'o, Pim de Haan, Tilman Plehn, Jesse Thaler, Johann Brehmer</dc:creator>
    </item>
    <item>
      <title>Structure and inference in hypergraphs with node attributes</title>
      <link>https://arxiv.org/abs/2311.03857</link>
      <description>arXiv:2311.03857v2 Announce Type: replace-cross 
Abstract: Many networked datasets with units interacting in groups of two or more, encoded with hypergraphs, are accompanied by extra information about nodes, such as the role of an individual in a workplace. Here we show how these node attributes can be used to improve our understanding of the structure resulting from higher-order interactions. We consider the problem of community detection in hypergraphs and develop a principled model that combines higher-order interactions and node attributes to better represent the observed interactions and to detect communities more accurately than using either of these types of information alone. The method learns automatically from the input data the extent to which structure and attributes contribute to explain the data, down weighing or discarding attributes if not informative. Our algorithmic implementation is efficient and scales to large hypergraphs and interactions of large numbers of units. We apply our method to a variety of systems, showing strong performance in hyperedge prediction tasks and in selecting community divisions that correlate with attributes when these are informative, but discarding them otherwise. Our approach illustrates the advantage of using informative node attributes when available with higher-order data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.03857v2</guid>
      <category>cs.SI</category>
      <category>physics.data-an</category>
      <category>physics.soc-ph</category>
      <category>stat.ML</category>
      <pubDate>Thu, 31 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1038/s41467-024-51388-5</arxiv:DOI>
      <arxiv:journal_reference>Nat Commun 15, 7073 (2024)</arxiv:journal_reference>
      <dc:creator>Anna Badalyan, Nicol\`o Ruggeri, Caterina De Bacco</dc:creator>
    </item>
    <item>
      <title>Parameter uncertainties for imperfect surrogate models in the low-noise regime</title>
      <link>https://arxiv.org/abs/2402.01810</link>
      <description>arXiv:2402.01810v4 Announce Type: replace-cross 
Abstract: Bayesian regression determines model parameters by minimizing the expected loss, an upper bound to the true generalization error. However, the loss ignores misspecification, where models are imperfect. Parameter uncertainties from Bayesian regression are thus significantly underestimated and vanish in the large data limit. This is particularly problematic when building models of low-noise, or near-deterministic, calculations, as the main source of uncertainty is neglected. We analyze the generalization error of misspecified, near-deterministic surrogate models, a regime of broad relevance in science and engineering. We show posterior distributions must cover every training point to avoid a divergent generalization error and design an ansatz that respects this constraint, which for linear models incurs minimal overhead. This is demonstrated on model problems before application to thousand dimensional datasets in atomistic machine learning. Our efficient misspecification-aware scheme gives accurate prediction and bounding of test errors where existing schemes fail, allowing this important source of uncertainty to be incorporated in computational workflows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.01810v4</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <pubDate>Thu, 31 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas D Swinburne, Danny Perez</dc:creator>
    </item>
  </channel>
</rss>
