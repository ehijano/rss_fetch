<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 19 Jun 2025 01:30:07 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Seq2Bind Webserver for Decoding Binding Hotspots directly from Sequences using Fine-Tuned Protein Language Models</title>
      <link>https://arxiv.org/abs/2506.13830</link>
      <description>arXiv:2506.13830v1 Announce Type: new 
Abstract: Decoding protein-protein interactions (PPIs) at the residue level is crucial for understanding cellular mechanisms and developing targeted therapeutics. We present Seq2Bind Webserver, a computational framework that leverages fine-tuned protein language models (PLMs) to determine binding affinity between proteins and identify critical binding residues directly from sequences, eliminating the structural requirements that limit most affinity prediction tools. We fine-tuned four architectures including ProtBERT, ProtT5, ESM2, and BiLSTM on the SKEMPI 2.0 dataset containing 5,387 protein pairs with experimental binding affinities. Through systematic alanine mutagenesis on each residue for 14 therapeutically relevant protein complexes, we evaluated each model's ability to identify interface residues. Performance was assessed using N-factor metrics, where N-factor=3 evaluates whether true residues appear within 3n top predictions for n interface residues. ESM2 achieved 49.5% accuracy at N-factor=3, with both ESM2 (37.2%) and ProtBERT (35.1%) outperforming structural docking method HADDOCK3 (32.1%) at N-factor=2. Our sequence-based approach enables rapid screening (minutes versus hours for docking), handles disordered proteins, and provides comparable accuracy, making Seq2Bind a valuable prior to steer blind docking protocols to identify putative binding residues from each protein for therapeutic targets. Seq2Bind Webserver is accessible at https://agrivax.onrender.com under StructF suite.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.13830v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiang Ma, Supantha Dey, Vaishnavey SR, Casey Zelinski, Qi Li, Ratul Chowdhury</dc:creator>
    </item>
    <item>
      <title>A Silent Speech Decoding System from EEG and EMG with Heterogenous Electrode Configurations</title>
      <link>https://arxiv.org/abs/2506.13835</link>
      <description>arXiv:2506.13835v1 Announce Type: new 
Abstract: Silent speech decoding, which performs unvocalized human speech recognition from electroencephalography/electromyography (EEG/EMG), increases accessibility for speech-impaired humans. However, data collection is difficult and performed using varying experimental setups, making it nontrivial to collect a large, homogeneous dataset. In this study we introduce neural networks that can handle EEG/EMG with heterogeneous electrode placements and show strong performance in silent speech decoding via multi-task training on large-scale EEG/EMG datasets. We achieve improved word classification accuracy in both healthy participants (95.3%), and a speech-impaired patient (54.5%), substantially outperforming models trained on single-subject data (70.1% and 13.2%). Moreover, our models also show gains in cross-language calibration performance. This increase in accuracy suggests the feasibility of developing practical silent speech decoding systems, particularly for speech-impaired patients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.13835v1</guid>
      <category>q-bio.QM</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Masakazu Inoue, Motoshige Sato, Kenichi Tomeoka, Nathania Nah, Eri Hatakeyama, Kai Arulkumaran, Ilya Horiguchi, Shuntaro Sasai</dc:creator>
    </item>
    <item>
      <title>BlastDiffusion: A Latent Diffusion Model for Generating Synthetic Embryo Images to Address Data Scarcity in In Vitro Fertilization</title>
      <link>https://arxiv.org/abs/2506.13843</link>
      <description>arXiv:2506.13843v1 Announce Type: new 
Abstract: Accurately identifying oocytes that progress to the blastocyst stage is crucial in reproductive medicine, but the limited availability of annotated high-quality embryo images presents challenges for developing automated diagnostic tools. To address this, we propose BlastDiffusion, a generative model based on Latent Diffusion Models (LDMs) that synthesizes realistic oocyte images conditioned on developmental outcomes. Our approach utilizes a pretrained Variational Autoencoder (VAE) for latent space representation, combined with a diffusion process to generate images that distinguish between oocytes that reach the blastocyst stage and those that do not. When compared to Blastocyst-GAN, a GAN-based model we trained for this task, BlastDiffusion achieves superior performance, with a global Frechet Inception Distance (FID) of 94.32, significantly better than Blastocyst-GAN's FID of 232.73. Additionally, our model shows improvements in perceptual (LPIPS) and structural (SSIM) similarity to real oocyte images. Qualitative analysis further demonstrates that BlastDiffusion captures key morphological differences linked to developmental outcomes. These results highlight the potential of diffusion models in reproductive medicine, offering an effective tool for data augmentation and automated embryo assessment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.13843v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Alejandro Golfe, Natalia P. Garc\'ia-de-la-puente, Adri\'an Colomer, Valery Naranjo</dc:creator>
    </item>
    <item>
      <title>Beyond Black Boxes: Enhancing Interpretability of Transformers Trained on Neural Data</title>
      <link>https://arxiv.org/abs/2506.14014</link>
      <description>arXiv:2506.14014v1 Announce Type: new 
Abstract: Transformer models have become state-of-the-art in decoding stimuli and behavior from neural activity, significantly advancing neuroscience research. Yet greater transparency in their decision-making processes would substantially enhance their utility in scientific and clinical contexts. Sparse autoencoders offer a promising solution by producing hidden units that respond selectively to specific variables, enhancing interpretability. Here, we introduce SAEs into a neural decoding framework by augmenting a transformer trained to predict visual stimuli from calcium imaging in the mouse visual cortex. The enhancement of the transformer model with an SAE preserved its original performance while yielding hidden units that selectively responded to interpretable features, such as stimulus orientation and genetic background. Furthermore, ablating units associated with a given variable impaired the model's ability to process that variable, revealing how specific internal representations support downstream computations. Together, these results demonstrate that integrating SAEs with transformers combines the power of modern deep learning with the interpretability essential for scientific understanding and clinical translation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.14014v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Laurence Freeman, Philip Shamash, Vinam Arora, Caswell Barry, Tiago Branco, Eva Dyer</dc:creator>
    </item>
    <item>
      <title>An 11,000-Study Open-Access Dataset of Longitudinal Magnetic Resonance Images of Brain Metastases</title>
      <link>https://arxiv.org/abs/2506.14021</link>
      <description>arXiv:2506.14021v1 Announce Type: new 
Abstract: Brain metastases are a common complication of systemic cancer, affecting over 20% of patients with primary malignancies. Longitudinal magnetic resonance imaging (MRI) is essential for diagnosing patients, tracking disease progression, assessing therapeutic response, and guiding treatment selection. However, the manual review of longitudinal imaging is time-intensive, especially for patients with multifocal disease. Artificial intelligence (AI) offers opportunities to streamline image evaluation, but developing robust AI models requires comprehensive training data representative of real-world imaging studies. Thus, there is an urgent necessity for a large dataset with heterogeneity in imaging protocols and disease presentation. To address this, we present an open-access dataset of 11,884 longitudinal brain MRI studies from 1,430 patients with clinically confirmed brain metastases, paired with clinical and image metadata. The provided dataset will facilitate the development of AI models to assist in the long-term management of patients with brain metastasis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.14021v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saahil Chadha, David Weiss, Anastasia Janas, Divya Ramakrishnan, Thomas Hager, Klara Osenberg, Klara Willms, Joshua Zhu, Veronica Chiang, Spyridon Bakas, Nazanin Maleki, Durga V. Sritharan, Sven Schoenherr, Malte Westerhoff, Matthew Zawalich, Melissa Davis, Ajay Malhotra, Khaled Bousabarah, Cornelius Deuschl, MingDe Lin, Sanjay Aneja, Mariam S. Aboian</dc:creator>
    </item>
    <item>
      <title>Inhibiting Alzheimer's Disease by Targeting Aggregation of Beta-Amyloid</title>
      <link>https://arxiv.org/abs/2506.14052</link>
      <description>arXiv:2506.14052v1 Announce Type: new 
Abstract: Alzheimer's disease is characterized by dangerous amyloid plaques formed by deposits of the protein Beta-Amyloid aggregates in the brain. The specific amino acid sequence that is responsible for the aggregates of Beta-Amyloid is lys-leu-val-phe-phe (KLVFF). KLVFF aggregation inhibitors, which we design in this paper, prevent KLVFF from binding with itself to form oligomers or fibrils (and eventually plaques) that cause neuronal death. Our binder-blocker peptides are designed such that, on one side, they bind strongly to KLVFF, and on the other side, they disrupt critical interactions, thus preventing aggregation. Our methods use optimization techniques and molecular simulations and identify 10 candidate sequences for trial of the 3.2 million possible sequences. This approach for inhibitor identification can be generalized to other diseases characterized by protein aggregation, such as Parkinson's, Huntington's, and prion diseases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.14052v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ananya Joshi, George Khoury, Christodoulas Floudas</dc:creator>
    </item>
    <item>
      <title>Leveraging Transfer Learning and User-Specific Updates for Rapid Training of BCI Decoders</title>
      <link>https://arxiv.org/abs/2506.14120</link>
      <description>arXiv:2506.14120v1 Announce Type: new 
Abstract: Lengthy subject- or session-specific data acquisition and calibration remain a key barrier to deploying electroencephalography (EEG)-based brain-computer interfaces (BCIs) outside the laboratory. Previous work has shown that cross subject, cross-session invariant features exist in EEG. We propose a transfer learning pipeline based on a two-layer convolutional neural network (CNN) that leverages these invariants to reduce the burden of data acquisition and calibration. A baseline model is trained on EEG data from five able-bodied individuals and then rapidly updated with a small amount of data from a sixth, holdout subject. The remaining holdout data were used to test the performance of both the baseline and updated models. We repeated this procedure via a leave-one-subject out (LOSO) validation framework. Averaged over six LOSO folds, the updated model improved classification accuracy upon the baseline by 10.0, 18.8, and 22.1 percentage points on two binary and one ternary classification tasks, respectively. These results demonstrate that decoding accuracy can be substantially improved with minimal subject-specific data. They also indicate that a CNN-based decoder can be personalized rapidly, enabling near plug-and-play BCI functionality for neurorehabilitation and other time-critical EEG applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.14120v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziheng Chen, Po T. Wang, Mina Ibrahim, Shivali Baveja, Rong Mu, An H. Do, Zoran Nenadic</dc:creator>
    </item>
    <item>
      <title>DeepSeq: High-Throughput Single-Cell RNA Sequencing Data Labeling via Web Search-Augmented Agentic Generative AI Foundation Models</title>
      <link>https://arxiv.org/abs/2506.13817</link>
      <description>arXiv:2506.13817v1 Announce Type: cross 
Abstract: Generative AI foundation models offer transformative potential for processing structured biological data, particularly in single-cell RNA sequencing, where datasets are rapidly scaling toward billions of cells. We propose the use of agentic foundation models with real-time web search to automate the labeling of experimental data, achieving up to 82.5% accuracy. This addresses a key bottleneck in supervised learning for structured omics data by increasing annotation throughput without manual curation and human error. Our approach enables the development of virtual cell foundation models capable of downstream tasks such as cell-typing and perturbation prediction. As data volume grows, these models may surpass human performance in labeling, paving the way for reliable inference in large-scale perturbation screens. This application demonstrates domain-specific innovation in health monitoring and diagnostics, aligned with efforts like the Human Cell Atlas and Human Tumor Atlas Network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.13817v1</guid>
      <category>q-bio.GN</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SE</category>
      <category>q-bio.QM</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>International Conference on Machine Learning (ICML). Workshop on Multi-modal Foundation Models and Large Language Models for Life Sciences (FM4LS), July 2025</arxiv:journal_reference>
      <dc:creator>Saleem A. Al Dajani, Abel Sanchez, John R. Williams</dc:creator>
    </item>
    <item>
      <title>A Robust Nonparametric Framework for Detecting Repeated Spatial Patterns</title>
      <link>https://arxiv.org/abs/2506.14103</link>
      <description>arXiv:2506.14103v1 Announce Type: cross 
Abstract: Identifying spatially contiguous clusters and repeated spatial patterns (RSP) characterized by similar underlying distributions that are spatially apart is a key challenge in modern spatial statistics. Existing constrained clustering methods enforce spatial contiguity but are limited in their ability to identify RSP. We propose a novel nonparametric framework that addresses this limitation by combining constrained clustering with a post-clustering reassigment step based on the maximum mean discrepancy (MMD) statistic. We employ a block permutation strategy within each cluster that preserves local attribute structure when approximating the null distribution of the MMD. We also show that the MMD$^2$ statistic is asymptotically consistent under second-order stationarity and spatial mixing conditions. This two-stage approach enables the detection of clusters that are both spatially distant and similar in distribution. Through simulation studies that vary spatial dependence, cluster sizes, shapes, and multivariate dimensionality, we demonstrate the robustness of our proposed framework in detecting RSP. We further illustrate its applicability through an analysis of spatial proteomics data from patients with triple-negative breast cancer. Overall, our framework presents a methodological advancement in spatial clustering, offering a flexible and robust solution for spatial datasets that exhibit repeated patterns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.14103v1</guid>
      <category>stat.ME</category>
      <category>q-bio.QM</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rajitha Senanayake, Pratheepa Jeganathan</dc:creator>
    </item>
    <item>
      <title>Querying functional and structural niches on spatial transcriptomics data</title>
      <link>https://arxiv.org/abs/2410.10652</link>
      <description>arXiv:2410.10652v2 Announce Type: replace 
Abstract: Cells in multicellular organisms coordinate to form functional and structural niches. With spatial transcriptomics enabling gene expression profiling in spatial contexts, it has been revealed that spatial niches serve as cohesive and recurrent units in physiological and pathological processes. These observations suggest universal tissue organization principles encoded by conserved niche patterns, and call for a query-based niche analytical paradigm beyond current computational tools. In this work, we defined the Niche Query Task, which is to identify similar niches across ST samples given a niche of interest (NOI). We further developed QueST, a specialized method for solving this task. QueST models each niche as a subgraph, uses contrastive learning to learn discriminative niche embeddings, and incorporates adversarial training to mitigate batch effects. In simulations and benchmark datasets, QueST outperformed existing methods repurposed for niche querying, accurately capturing niche structures in heterogeneous environments and demonstrating strong generalizability across diverse sequencing platforms. Applied to tertiary lymphoid structures in renal and lung cancers, QueST revealed functionally distinct niches associated with patient prognosis and uncovered conserved and divergent spatial architectures across cancer types. These results demonstrate that QueST enables systematic, quantitative profiling of spatial niches across samples, providing a powerful tool to dissect spatial tissue architecture in health and disease.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10652v2</guid>
      <category>q-bio.QM</category>
      <category>cs.LG</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mo Chen, Minsheng Hao, Xinquan Liu, Lin Deng, Chen Li, Dongfang Wang, Kui Hua, Xuegong Zhang, Lei Wei</dc:creator>
    </item>
    <item>
      <title>Protein folding classes -- High-dimensional geometry of amino acid composition space revisited</title>
      <link>https://arxiv.org/abs/2506.01857</link>
      <description>arXiv:2506.01857v2 Announce Type: replace-cross 
Abstract: In this study, the distributions of protein structure classes (or folding types) of experimentally determined structures from a legacy dataset and a comprehensive database SCOP are modeled precisely with geometric constructs such as convex polytopes in high-dimensional amino acid composition space. This is a follow-up of a previous non-statistical, geometry-motivated modeling of protein classes with ellipsoidal models, which are superseded presently in three important respects: (1) as a paradigm shift descriptive 'distribution model' of experimental data is de-coupled from, and serves as the basis for, possible future predictive 'domain model' generalizable to proteins in the same class for which 3D structures have yet to be determined experimentally, (2) the geometric and analytic characteristics of class distributions are obtained via exact computational geometry calculations, and (3) the full data from a comprehensive database are included in such calculations, eschewing training set selection and biases. In contrast to statistical and machine-learning approaches, the analytical, non-statistical geometry models of protein class distributions demonstrated in this study furnish complete and precise information on their size and relative disposition in the high-dimensional space (vis-\`a-vis any overlaps leading to ambiguity and limits in classification). Intended principally as accurate and summary description of the complex relationships between amino acid composition and protein classes, and suitably as a basis for predictive modeling where permissible, the results suggest that pen-ultimately they may be useful adjuncts for validating sequence-based protein structure predictions and contribute to theoretical and fundamental understanding of secondary structure formation and protein folding, demonstrating the role of high dimensional amino acid composition space in protein studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01857v2</guid>
      <category>q-bio.BM</category>
      <category>q-bio.QM</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Boryeu Mao</dc:creator>
    </item>
    <item>
      <title>Effective Stimulus Propagation in Neural Circuits: Driver Node Selection</title>
      <link>https://arxiv.org/abs/2506.13615</link>
      <description>arXiv:2506.13615v2 Announce Type: replace-cross 
Abstract: Precise control of signal propagation in modular neural networks represents a fundamental challenge in computational neuroscience. We establish a framework for identifying optimal control nodes that maximize stimulus transmission between weakly coupled neural populations. Using spiking stochastic block model networks, we systematically compare driver node selection strategies - including random sampling and topology-based centrality measures (degree, betweenness, closeness, eigenvector, harmonic, and percolation centrality) - to determine minimal control inputs for achieving inter-population synchronization. Targeted stimulation of just 10-20% of the most central neurons in the source population significantly enhances spiking propagation fidelity compared to random selection. This approach yields a 64-fold increase in signal transfer efficiency at critical inter-module connection densities. These findings establish a theoretical foundation for precision neuromodulation in biological neural systems and neurotechnology applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.13615v2</guid>
      <category>q-bio.NC</category>
      <category>cs.NE</category>
      <category>q-bio.QM</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bulat Batuev, Arsenii Onuchin, Sergey Sukhov</dc:creator>
    </item>
  </channel>
</rss>
