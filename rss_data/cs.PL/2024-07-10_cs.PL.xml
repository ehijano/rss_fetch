<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.PL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.PL</link>
    <description>cs.PL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.PL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 11 Jul 2024 01:34:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 10 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Proceedings of the Thirteenth Workshop on Trends in Functional Programming in Education</title>
      <link>https://arxiv.org/abs/2407.06355</link>
      <description>arXiv:2407.06355v1 Announce Type: new 
Abstract: This volume of the Electronic Proceedings in Theoretical Computer Science (EPTCS) contains revised selected papers that were initially presented at the 13th International Workshop on Trends in Functional Programming in Education (TFPIE 2024). This workshop was held at Seton Hall University in South Orange, NJ, USA on January 9, 2024. It was co-located with the 25th International Symposium on Trends in Functional Programming (TFP 2024), which took place on January 10-12, 2024.
  The goal of TFPIE is to gather researchers, teachers, and professionals that use, or are interested in the use of, functional programming in education. TFPIE aims to be a venue where novel ideas, classroom-tested ideas, and works-in-progress on the use of functional programming in education are discussed.
  TFPIE workshops have previously been held in St Andrews, Scotland (2012), Provo, Utah, USA (2013), Soesterberg, The Netherlands (2014), Sophia-Antipolis, France (2015), College Park, MD, USA (2016), Canterbury, UK (2017), Gothenburg, Sweden (2018), Vancouver, Canada (2019), Krakow, Poland (2020), online due to COVID-19 (2021, 2022, with some talks from TFPIE 2022 also presented in person at the Lambda Days in Krakow, Poland), and Boston, MA, USA (2023, back in-person).
</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06355v1</guid>
      <category>cs.PL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.405</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 405, 2024</arxiv:journal_reference>
      <dc:creator>Stephen Chang (UMass Boston)</dc:creator>
    </item>
    <item>
      <title>Toward Programming Languages for Reasoning: Humans, Symbolic Systems, and AI Agents</title>
      <link>https://arxiv.org/abs/2407.06356</link>
      <description>arXiv:2407.06356v1 Announce Type: new 
Abstract: Integration, composition, mechanization, and AI assisted development are the driving themes in the future of software development. At their core these concepts are rooted in the increasingly important role of computing in our world, the desire to deliver functionality faster, with higher quality, and to empower more people to benefit from programmatic automation. These themes, and how they impact the human developers driving them, are the foundations for the next generation of programming languages. At first glance the needs of mechanization tools, AI agents, and human developers along with the various goals around development velocity, software quality, and software democratization are a broad and seemingly diverse set of needs. However, at their core is a single challenge that, once resolved, enables us to make radical progress in all of these areas.
  Our hypothesis is that, fundamentally, software development is a problem of reasoning about code and semantics. This is true for human developers implementing a feature, symbolic tools building models of application behavior, and even for language based AI agents as they perform tasks. While the particular aspects of reasoning that each agent struggles with varies to some degree, they share many common themes and, surprisingly, most mainstream languages extensively employ (anti)features that make this task harder or infeasible! This paper proposes a novel approach to this challenge -- instead of new language features or logical constructs, that add more complexity to what is already a problem of complexity, we propose radical simplification in the form of the Bosque platform and language.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06356v1</guid>
      <category>cs.PL</category>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3622758.3622895</arxiv:DOI>
      <dc:creator>Mark Marron</dc:creator>
    </item>
    <item>
      <title>Macaw: A Machine Code Toolbox for the Busy Binary Analyst</title>
      <link>https://arxiv.org/abs/2407.06375</link>
      <description>arXiv:2407.06375v1 Announce Type: new 
Abstract: When attempting to understand the behavior of an executable, a binary analyst can make use of many different techniques. These include program slicing, dynamic instrumentation, binary-level rewriting, symbolic execution, and formal verification, all of which can uncover insights into how a piece of machine code behaves. As a result, there is no one-size-fits-all binary analysis tool, so a binary analysis researcher will often combine several different tools. Sometimes, a researcher will even need to design new tools to study problems that existing frameworks are not well equipped to handle. Designing such tools from complete scratch is rarely time- or cost-effective, however, given the scale and complexity of modern instruction set architectures.
  We present Macaw, a modular framework that makes it possible to rapidly build reliable binary analysis tools across a range of use cases. Over a decade of development, we have used Macaw to support an industrial research team in building tools for machine code-related tasks. As such, the name "Macaw" refers not just to the framework itself, but also a suite of tools that are built on top of the framework. We describe Macaw in depth and describe the different static and dynamic analyses that it performs, many of which are powered by an SMT-based symbolic execution engine. We put a particular focus on interoperability between machine code and higher-level languages, including binary lifting from x86 to LLVM, as well verifying the correctness of mixed C and assembly code.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06375v1</guid>
      <category>cs.PL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ryan G. Scott, Brett Boston, Benjamin Davis, Iavor Diatchki, Mike Dodds, Joe Hendrix, Daniel Matichuk, Kevin Quick, Tristan Ravitch, Valentin Robert, Benjamin Selfridge, Andrei Stef\u{a}nescu, Daniel Wagner, Simon Winwood</dc:creator>
    </item>
    <item>
      <title>Type Universes as Allocation Effects</title>
      <link>https://arxiv.org/abs/2407.06473</link>
      <description>arXiv:2407.06473v1 Announce Type: new 
Abstract: In this paper, we explore a connection between type universes and memory allocation. Type universe hierarchies are used in dependent type theories to ensure consistency, by forbidding a type from quantifying over all types. Instead, the types of types (universes) form a hierarchy, and a type can only quantify over types in other universes (with some exceptions), restricting cyclic reasoning in proofs. We present a perspective where universes also describe \emph{where} values are allocated in the heap, and the choice of universe algebra imposes a structure on the heap overall. The resulting type system provides a simple declarative system for reasoning about and restricting memory allocation, without reasoning about reads or writes. We present a theoretical framework for equipping a type system with higher-order references restricted by a universe hierarchy, and conjecture that many existing universe algebras give rise to interesting systems for reasoning about allocation. We present 3 instantiations of this approach to enable reasoning about allocation in the simply typed $\lambda$-calculus: (1) the standard ramified universe hierarchy, which we prove guarantees termination of the language extended with higher-order references by restricting cycles in the heap; (2) an extension with an \emph{impredicative} base universe, which we conjecture enables full-ground references (with terminating computation but cyclic ground data structures); (3) an extension with \emph{universe polymorphism}, which divides the heap into fine-grained regions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06473v1</guid>
      <category>cs.PL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Paulette Koronkevich, William J. Bowman</dc:creator>
    </item>
    <item>
      <title>Toward Verified Library-Level Choreographic Programming with Algebraic Effects</title>
      <link>https://arxiv.org/abs/2407.06509</link>
      <description>arXiv:2407.06509v1 Announce Type: new 
Abstract: Choreographic programming (CP) is a paradigm for programming distributed applications as single, unified programs, called choreographies, that are then compiled to node-local programs via endpoint projection (EPP). Recently, library-level CP frameworks have emerged, in which choreographies and EPP are expressed as constructs in an existing host language. So far, however, library-level CP lacks a solid theoretical foundation.
  In this paper, we propose modeling library-level CP using algebraic effects, an abstraction that generalizes the approach taken by existing CP libraries. Algebraic effects let us define choreographies as computations with user-defined effects and EPP as location-specific effect handlers. Algebraic effects also lend themselves to reasoning about correctness properties, such as soundness and completeness of EPP. We present a prototype of a library-level CP framework based on algebraic effects, implemented in the Agda proof assistant, and discuss our ongoing work on leveraging the algebraic-effects-based approach to prove the correctness of our library-level CP implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06509v1</guid>
      <category>cs.PL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gan Shen, Lindsey Kuper</dc:creator>
    </item>
    <item>
      <title>Failure Transparency in Stateful Dataflow Systems (Technical Report)</title>
      <link>https://arxiv.org/abs/2407.06738</link>
      <description>arXiv:2407.06738v1 Announce Type: new 
Abstract: Failure transparency enables users to reason about distributed systems at a higher level of abstraction, where complex failure-handling logic is hidden. This is especially true for stateful dataflow systems, which are the backbone of many cloud applications. In particular, this paper focuses on proving failure transparency in Apache Flink, a popular stateful dataflow system. Even though failure transparency is a critical aspect of Apache Flink, to date it has not been formally proven. Showing that the failure transparency mechanism is correct, however, is challenging due to the complexity of the mechanism itself. Nevertheless, this complexity can be effectively hidden behind a failure transparent programming interface. To show that Apache Flink is failure transparent, we model it in small-step operational semantics. Next, we provide a novel definition of failure transparency based on observational explainability, a concept which relates executions according to their observations. Finally, we provide a formal proof of failure transparency for the implementation model; i.e., we prove that the failure-free model correctly abstracts from the failure-related details of the implementation model. We also show liveness of the implementation model under a fair execution assumption. These results are a first step towards a verified stack for stateful dataflow systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06738v1</guid>
      <category>cs.PL</category>
      <category>cs.DC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aleksey Veresov (KTH Royal Institute of Technology), Jonas Spenger (KTH Royal Institute of Technology), Paris Carbone (KTH Royal Institute of Technology, RISE Research Institutes of Sweden), Philipp Haller (KTH Royal Institute of Technology)</dc:creator>
    </item>
    <item>
      <title>Towards Algebraic Subtyping for Extensible Records</title>
      <link>https://arxiv.org/abs/2407.06747</link>
      <description>arXiv:2407.06747v1 Announce Type: new 
Abstract: MLsub is a minimal language with a type system combining subtyping and parametric polymorphism and a type inference algorithm which infers compact principal types. Simple-sub is an alternative inference algorithm which can be implemented efficiently and is easier to understand. MLsub supports explicitly typed records which are not extensible. Here we extend Simple-sub with extensible records, meaning that we can add new fields to a previously defined record. For this we add row variables to our type language and extend the type constraint solving method of our type inference algorithm accordingly, keeping the decidability of type inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06747v1</guid>
      <category>cs.PL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rodrigo Marques, M\'ario Florido, Pedro Vasconcelos</dc:creator>
    </item>
    <item>
      <title>Meerkat: A Distributed Reactive Programming Language with Live Updates</title>
      <link>https://arxiv.org/abs/2407.06885</link>
      <description>arXiv:2407.06885v1 Announce Type: new 
Abstract: We propose a novel type-safe reactive programming language with live updates that extends an existing work to support multiple distributed evolution queues. Dependency sets of definitions are incorporated in the type system to protect the interaction between the frontend user interface and the backend database. Distributed live updates submitted by multiple programmers are ensured strong consistency based on an existing framework for distributed reactive propagation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06885v1</guid>
      <category>cs.PL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Heng Zhong, Anrui Liu</dc:creator>
    </item>
    <item>
      <title>foetus -- Termination Checker for Simple Functional Programs</title>
      <link>https://arxiv.org/abs/2407.06924</link>
      <description>arXiv:2407.06924v1 Announce Type: new 
Abstract: We introduce a simple functional language foetus (lambda calculus with tuples, constructors and pattern matching) supplied with a termination checker. This checker tries to find a well-founded structural order on the parameters on the given function to prove termination. The components of the check algorithm are: function call extraction out of the program text, call graph completion and finding a lexical order for the function parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06924v1</guid>
      <category>cs.PL</category>
      <category>cs.LO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andreas Abel</dc:creator>
    </item>
    <item>
      <title>FORAY: Towards Effective Attack Synthesis against Deep Logical Vulnerabilities in DeFi Protocols</title>
      <link>https://arxiv.org/abs/2407.06348</link>
      <description>arXiv:2407.06348v1 Announce Type: cross 
Abstract: Blockchain adoption has surged with the rise of Decentralized Finance (DeFi) applications. However, the significant value of digital assets managed by DeFi protocols makes them prime targets for attacks. Current smart contract vulnerability detection tools struggle with DeFi protocols due to deep logical bugs arising from complex financial interactions between multiple smart contracts. These tools primarily analyze individual contracts and resort to brute-force methods for DeFi protocols crossing numerous smart contracts, leading to inefficiency. We introduce Foray, a highly effective attack synthesis framework against deep logical bugs in DeFi protocols. Foray proposes a novel attack sketch generation and completion framework. Specifically, instead of treating DeFis as regular programs, we design a domain-specific language (DSL) to lift the low-level smart contracts into their high-level financial operations. Based on our DSL, we first compile a given DeFi protocol into a token flow graph, our graphical representation of DeFi protocols. Then, we design an efficient sketch generation method to synthesize attack sketches for a certain attack goal (e.g., price manipulation, arbitrage, etc.). This algorithm strategically identifies candidate sketches by finding reachable paths in TFG, which is much more efficient than random enumeration. For each candidate sketch written in our DSL, Foray designs a domain-specific symbolic compilation to compile it into SMT constraints. Our compilation simplifies the constraints by removing redundant smart contract semantics. It maintains the usability of symbolic compilation, yet scales to problems orders of magnitude larger. Finally, the candidates are completed via existing solvers and are transformed into concrete attacks via direct syntax transformation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06348v1</guid>
      <category>cs.CR</category>
      <category>cs.PL</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongbo Wen, Hanzhi Liu, Jiaxin Song, Yanju Chen, Wenbo Guo, Yu Feng</dc:creator>
    </item>
    <item>
      <title>VEXIR2Vec: An Architecture-Neutral Embedding Framework for Binary Similarity</title>
      <link>https://arxiv.org/abs/2312.00507</link>
      <description>arXiv:2312.00507v2 Announce Type: replace 
Abstract: Binary similarity involves determining whether two binary programs exhibit similar functionality, often originating from the same source code. In this work, we propose VexIR2Vec, an approach for binary similarity using VEX-IR, an architecture-neutral Intermediate Representation (IR). We extract the embeddings from sequences of basic blocks, termed peepholes, derived by random walks on the control-flow graph. The peepholes are normalized using transformations inspired by compiler optimizations. The VEX-IR Normalization Engine mitigates, with these transformations, the architectural and compiler-induced variations in binaries while exposing semantic similarities. We then learn the vocabulary of representations at the entity level of the IR using the knowledge graph embedding techniques in an unsupervised manner. This vocabulary is used to derive function embeddings for similarity assessment using VexNet, a feed-forward Siamese network designed to position similar functions closely and separate dissimilar ones in an n-dimensional space. This approach is amenable for both diffing and searching tasks, ensuring robustness against Out-Of-Vocabulary (OOV) issues.
  We evaluate VexIR2Vec on a dataset comprising 2.7M functions and 15.5K binaries from 7 projects compiled across 12 compilers targeting x86 and ARM architectures. In diffing experiments, VexIR2Vec outperforms the nearest baselines by $40\%$, $18\%$, $21\%$, and $60\%$ in cross-optimization, cross-compilation, cross-architecture, and obfuscation settings, respectively. In the searching experiment, VexIR2Vec achieves a mean average precision of $0.76$, outperforming the nearest baseline by $46\%$. Our framework is highly scalable and is built as a lightweight, multi-threaded, parallel library using only open-source tools. VexIR2Vec is $3.1$-$3.5 \times$ faster than the closest baselines and orders-of-magnitude faster than other tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.00507v2</guid>
      <category>cs.PL</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>S. VenkataKeerthy, Soumya Banerjee, Sayan Dey, Yashas Andaluri, Raghul PS, Subrahmanyam Kalyanasundaram, Fernando Magno Quint\~ao Pereira, Ramakrishna Upadrasta</dc:creator>
    </item>
    <item>
      <title>Preserving Power Optimizations Across the High Level Synthesis of Distinct Application-Specific Circuits</title>
      <link>https://arxiv.org/abs/2401.07726</link>
      <description>arXiv:2401.07726v2 Announce Type: replace 
Abstract: We evaluate the use of software interpretation to push High Level Synthesis of application-specific accelerators toward a higher level of abstraction. Our methodology is supported by a formal power consumption model that computes the power consumption of accelerator components, accurately predicting the power consumption on new designs from prior optimization estimations. We demonstrate how our approach simplifies the re-use of power optimizations across distinct designs, by leveraging the higher level of design abstraction, using two accelerators representative of the robotics domain, implemented through the Bambu High Level Synthesis tool. Results support the research hypothesis, achieving predictions accurate within +/- 1%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.07726v2</guid>
      <category>cs.PL</category>
      <category>cs.RO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paulo Garcia</dc:creator>
    </item>
  </channel>
</rss>
