<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 30 May 2025 04:00:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Quadratic convergence of an SQP method for some optimization problems with applications to control theory</title>
      <link>https://arxiv.org/abs/2505.22750</link>
      <description>arXiv:2505.22750v1 Announce Type: new 
Abstract: We analyze a sequential quadratic programming algorithm for solving a class of abstract optimization problems. Assuming that the initial point is in an $L^2$ neighborhood of a local solution that satisfies no-gap second-order sufficient optimality conditions and a strict complementarity condition, we obtain stability and quadratic convergence in $L^q$ for all $q\in[p,\infty]$ where $p\geq 2$ depends on the problem. Many of the usual optimal control problems of partial differential equations fit into this abstract formulation. Some examples are given in the paper. Finally, a computational comparison with other versions of the SQP method is presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22750v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eduardo Casas, Mariano Mateos</dc:creator>
    </item>
    <item>
      <title>Non-convex entropic mean-field optimization via Best Response flow</title>
      <link>https://arxiv.org/abs/2505.22760</link>
      <description>arXiv:2505.22760v1 Announce Type: new 
Abstract: We study the problem of minimizing non-convex functionals on the space of probability measures, regularized by the relative entropy (KL divergence) with respect to a fixed reference measure, as well as the corresponding problem of solving entropy-regularized non-convex-non-concave min-max problems. We utilize the Best Response flow (also known in the literature as the fictitious play flow) and study how its convergence is influenced by the relation between the degree of non-convexity of the functional under consideration, the regularization parameter and the tail behaviour of the reference measure. In particular, we demonstrate how to choose the regularizer, given the non-convex functional, so that the Best Response operator becomes a contraction with respect to the $L^1$-Wasserstein distance, which then ensures the existence of its unique fixed point, which is then shown to be the unique global minimizer for our optimization problem. This extends recent results where the Best Response flow was applied to solve convex optimization problems regularized by the relative entropy with respect to arbitrary reference measures, and with arbitrary values of the regularization parameter. Our results explain precisely how the assumption of convexity can be relaxed, at the expense of making a specific choice of the regularizer. Additionally, we demonstrate how these results can be applied in reinforcement learning in the context of policy optimization for Markov Decision Processes and Markov games with softmax parametrized policies in the mean-field regime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22760v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Razvan-Andrei Lascu, Mateusz B. Majka</dc:creator>
    </item>
    <item>
      <title>A Contingency Model Predictive Control Framework for Safe Learning</title>
      <link>https://arxiv.org/abs/2505.22776</link>
      <description>arXiv:2505.22776v1 Announce Type: new 
Abstract: This research introduces a multi-horizon contingency model predictive control (CMPC) framework in which classes of robust MPC (RMPC) algorithms are combined with classes of learning-based MPC (LB-MPC) algorithms to enable safe learning. We prove that the CMPC framework inherits the robust recursive feasibility properties of the underlying RMPC scheme, thereby ensuring safety of the CMPC in the sense of constraint satisfaction. The CMPC leverages the LB-MPC to safely learn the unmodeled dynamics to reduce conservatism and improve performance compared to standalone RMPC schemes, which are conservative in nature. In addition, we present an implementation of the CMPC framework that combines a particular RMPC and a Gaussian Process MPC scheme. A simulation study on automated lane merging demonstrates the advantages of our general CMPC framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22776v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1109/LCSYS.2025.3575191</arxiv:DOI>
      <dc:creator>Merlijne Geurts, Tren Baltussen, Alexander Katriniok, Maurice Heemels</dc:creator>
    </item>
    <item>
      <title>On the Resolution of Stochastic MPECs over Networks: Distributed Implicit Zeroth-Order Gradient Tracking Methods</title>
      <link>https://arxiv.org/abs/2505.22916</link>
      <description>arXiv:2505.22916v1 Announce Type: new 
Abstract: The mathematical program with equilibrium constraints (MPEC) is a powerful yet challenging class of constrained optimization problems, where the constraints are characterized by a parametrized variational inequality (VI) problem. While efficient algorithms for addressing MPECs and their stochastic variants (SMPECs) have been recently presented, distributed SMPECs over networks pose significant challenges. This work aims to develop fully iterative methods with complexity guarantees for resolving distributed SMPECs in two problem settings: (1) distributed single-stage SMPECs and (2) distributed two-stage SMPECs. In both cases, the global objective function is distributed among a network of agents that communicate cooperatively. Under the assumption that the parametrized VI is uniquely solvable, the resulting implicit problem in upper-level decisions is generally neither convex nor smooth. Under some standard assumptions, including the uniqueness of the solution to the VI problems and the Lipschitz continuity of the implicit global objective function, we propose single-stage and two-stage zeroth-order distributed gradient tracking optimization methods where the gradient of a smoothed implicit objective function is approximated using two (possibly inexact) evaluations of the lower-level VI solutions. In the exact setting of both the single-stage and two-stage problems, we achieve the best-known complexity bound for centralized nonsmooth nonconvex stochastic optimization. This complexity bound is also achieved (for the first time) for our method in addressing the inexact setting of the distributed two-stage SMPEC. In addressing the inexact setting of the single-stage problem, we derive an overall complexity bound, improving the dependence on the dimension compared to the existing results for the centralized SMPECs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22916v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammadjavad Ebrahimi, Uday V. Shanbhag, Farzad Yousefian</dc:creator>
    </item>
    <item>
      <title>Mean-Field Games with two-sided singular controls for L\'evy processes</title>
      <link>https://arxiv.org/abs/2505.22936</link>
      <description>arXiv:2505.22936v1 Announce Type: new 
Abstract: In a probabilistic mean field game driven by a L\'evy process an individual player aims to minimize a long run discounted/ergodic cost by controlling the process through a pair of increasing and decreasing c\`adl\`ag processes, while he is interacting with an aggregate of players through the expectation of a controlled process by another pair of c\`adl\`ag processes. With the Brouwer fixed point theorem, we provide easy to check conditions for the existence of mean field game equilibrium controls for both the discounted and ergodic control problem, characterize them as the solution of an integro-differential equation and show with a counterexample that uniqueness does not always holds. Furthermore, we study the convergence of equilibrium controls in the abelian sense. Finally, we treat the convergence of a finite-player game to this problem to justify our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22936v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Facundo Oli\'u</dc:creator>
    </item>
    <item>
      <title>Improved Last-Iterate Convergence of Shuffling Gradient Methods for Nonsmooth Convex Optimization</title>
      <link>https://arxiv.org/abs/2505.23056</link>
      <description>arXiv:2505.23056v1 Announce Type: new 
Abstract: We study the convergence of the shuffling gradient method, a popular algorithm employed to minimize the finite-sum function with regularization, in which functions are passed to apply (Proximal) Gradient Descent (GD) one by one whose order is determined by a permutation on the indices of functions. In contrast to its easy implementation and effective performance in practice, the theoretical understanding remains limited. A recent advance by (Liu &amp; Zhou, 2024b) establishes the first last-iterate convergence results under various settings, especially proving the optimal rates for smooth (strongly) convex optimization. However, their bounds for nonsmooth (strongly) convex functions are only as fast as Proximal GD. In this work, we provide the first improved last-iterate analysis for the nonsmooth case demonstrating that the widely used Random Reshuffle ($\textsf{RR}$) and Single Shuffle ($\textsf{SS}$) strategies are both provably faster than Proximal GD, reflecting the benefit of randomness. As an important implication, we give the first (nearly) optimal convergence result for the suffix average under the $\textsf{RR}$ sampling scheme in the general convex case, matching the lower bound shown by (Koren et al., 2022).</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23056v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zijian Liu, Zhengyuan Zhou</dc:creator>
    </item>
    <item>
      <title>Optimal Periodic Double-Barrier Strategies for Spectrally Negative L\'{e}vy Processes</title>
      <link>https://arxiv.org/abs/2505.23080</link>
      <description>arXiv:2505.23080v1 Announce Type: new 
Abstract: We study a stochastic control problem where the underlying process follows a spectrally negative L\'{e}vy process. A controller can continuously increase the process but only decrease it at independent Poisson arrival times. We show the optimality of the double-barrier strategy, which increases the process whenever it would fall below some lower barrier and decreases it whenever it is observed above a higher barrier. An optimal strategy and the associated value function are written semi-explicitly using scale functions. Numerical results are also given.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23080v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kazutoshi Yamazaki, Qingyuan Zhang</dc:creator>
    </item>
    <item>
      <title>Gradient Methods with Online Scaling Part I. Theoretical Foundations</title>
      <link>https://arxiv.org/abs/2505.23081</link>
      <description>arXiv:2505.23081v1 Announce Type: new 
Abstract: This paper establishes the theoretical foundations of the online scaled gradient methods (OSGM), a framework that utilizes online learning to adapt stepsizes and provably accelerate first-order methods. OSGM quantifies the effectiveness of a stepsize by a feedback function motivated from a convergence measure and uses the feedback to adjust the stepsize through an online learning algorithm. Consequently, instantiations of OSGM achieve convergence rates that are asymptotically no worse than the optimal stepsize. OSGM yields desirable convergence guarantees on smooth convex problems, including 1) trajectory-dependent global convergence on smooth convex objectives; 2) an improved complexity result on smooth strongly convex problems, and 3) local superlinear convergence. Notably, OSGM constitutes a new family of first-order methods with non-asymptotic superlinear convergence, joining the celebrated quasi-Newton methods. Finally, OSGM explains the empirical success of the popular hypergradient-descent heuristic in optimization for machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23081v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Wenzhi Gao, Ya-Chi Chu, Yinyu Ye, Madeleine Udell</dc:creator>
    </item>
    <item>
      <title>Stochastic Production Planning in Manufacturing Systems</title>
      <link>https://arxiv.org/abs/2505.23149</link>
      <description>arXiv:2505.23149v1 Announce Type: new 
Abstract: We extend the stochastic production planning framework to manufacturing systems, where the set of admissible production configurations is described by a general smooth convex domain $\omega $. In our setting, production operations continue as long as the production inventory $y(t)$ remains inside the capacity limits of $\omega $ and are halted once the state exits this region, i.e.,% \begin{equation*} \tau =\inf \{t&gt;0:\Vert y(t)-x_{0}\Vert &gt;\text{dist}(x_{0},\partial \omega )\}. \end{equation*}% The running cost is partitioned into a quadratic production cost $% a(p)=\left\Vert p\right\Vert ^{2}$ and an inventory holding cost modeled by a positive continuous function $b(y)$. We derive the associated Hamilton--Jacobi--Bellman (HJB) equation, verify the supermartingale property of the value function, and characterize the optimal feedback control. Techniques inspired by Lasry, Lions and Alvarez enable us to prove existence and uniqueness within this generalized production planning framework. Numerical experiments and a real-world examples illustrate the practical relevance of our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23149v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dragos-Patru Covei</dc:creator>
    </item>
    <item>
      <title>Provable Benefit of Random Permutations over Uniform Sampling in Stochastic Coordinate Descent</title>
      <link>https://arxiv.org/abs/2505.23152</link>
      <description>arXiv:2505.23152v1 Announce Type: new 
Abstract: We analyze the convergence rates of two popular variants of coordinate descent (CD): random CD (RCD), in which the coordinates are sampled uniformly at random, and random-permutation CD (RPCD), in which random permutations are used to select the update indices. Despite abundant empirical evidence that RPCD outperforms RCD in various tasks, the theoretical gap between the two algorithms' performance has remained elusive. Even for the benign case of positive-definite quadratic functions with permutation-invariant Hessians, previous efforts have failed to demonstrate a provable performance gap between RCD and RPCD. To this end, we present novel results showing that, for a class of quadratics with permutation-invariant structures, the contraction rate upper bound for RPCD is always strictly smaller than the contraction rate lower bound for RCD for every individual problem instance. Furthermore, we conjecture that this function class contains the worst-case examples of RPCD among all positive-definite quadratics. Combined with our RCD lower bound, this conjecture extends our results to the general class of positive-definite quadratic functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23152v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Donghwa Kim, Jaewook Lee, Chulhee Yun</dc:creator>
    </item>
    <item>
      <title>Robust Sparse Phase Retrieval: Statistical Guarantee, Optimality Theory and Convergent Algorithm</title>
      <link>https://arxiv.org/abs/2505.23273</link>
      <description>arXiv:2505.23273v1 Announce Type: new 
Abstract: Phase retrieval (PR) is a popular research topic in signal processing and machine learning. However, its performance degrades significantly when the measurements are corrupted by noise or outliers. To address this limitation, we propose a novel robust sparse PR method that covers both real- and complex-valued cases. The core is to leverage the Huber function to measure the loss and adopt the $\ell_{1/2}$-norm regularization to realize feature selection, thereby improving the robustness of PR. In theory, we establish statistical guarantees for such robustness and derive necessary optimality conditions for global minimizers. Particularly, for the complex-valued case, we provide a fixed point inclusion property inspired by Wirtinger derivatives. Furthermore, we develop an efficient optimization algorithm by integrating the gradient descent method into a majorization-minimization (MM) framework. It is rigorously proved that the whole generated sequence is convergent and also has a linear convergence rate under mild conditions, which has not been investigated before. Numerical examples under different types of noise validate the robustness and effectiveness of our proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23273v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jun Fan, Ailing Yan, Xianchao Xiu, Wanquan Liu</dc:creator>
    </item>
    <item>
      <title>Group zero-norm regularized robust loss minimization: proximal MM method and statistical error bound</title>
      <link>https://arxiv.org/abs/2505.23294</link>
      <description>arXiv:2505.23294v1 Announce Type: new 
Abstract: This study focuses on solving group zero-norm regularized robust loss minimization problems. We propose a proximal Majorization-Minimization (PMM) algorithm to address a class of equivalent Difference-of-Convex (DC) surrogate optimization problems. First, we present the core principles and iterative framework of the PMM method. Under the Kurdyka-{\L}ojasiewicz (KL) property assumption of the potential function, we establish the global convergence of the algorithm and characterize its local (sub)linear convergence rate. Furthermore, for linear observation models with design matrices satisfying restricted eigenvalue conditions, we derive statistical estimation error bounds between the PMM-generated iterates (including their limit points) and the ground truth solution. These bounds not only rigorously quantify the approximation accuracy of the algorithm but also extend previous results on element-wise sparse composite optimization from reference [57]. To efficiently implement the PMM framework, we develop a proximal dual semismooth Newton method for solving critical subproblems. Extensive numerical experiments on both synthetic data and the UCI benchmark demonstrate the superior computational efficiency of our PMM method compared to the proximal Alternating Direction Method of Multipliers (pADMM).</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23294v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ling Liang, Shujun Bi</dc:creator>
    </item>
    <item>
      <title>Mean Field Control with Poissonian Common Noise: A Pathwise Compactification Approach</title>
      <link>https://arxiv.org/abs/2505.23441</link>
      <description>arXiv:2505.23441v1 Announce Type: new 
Abstract: This paper contributes to the compactification approach to tackle mean-field control (MFC) problems with Poissonian common noise. To overcome the lack of compactness and continuity issues due to common noise, we exploit the point process representation of the Poisson random measure with finite intensity and propose a pathwise formulation by freezing a sample path of the common noise. We first study a pathwise relaxed control problem in an auxiliary setup without common noise but with finite deterministic jumping times over the finite horizon. By employing the compactification argument for the pathwise relaxed control problem with Skorokhod topology, we establish the existence of optimal controls in the pathwise formulation. To address the original problem, the main challenge is to close the gap between the problem in the original model with common noise and the pathwise formulation. With the help of concatenation techniques over the sequence of deterministic jumping times, we develop a new tool, also interpreted as the superposition principle in the pathwise formulation, to draw a relationship between the pathwise relaxed control problem and the pathwise measure-valued control problem associated to Fokker-Planck equation. As a result, we can bridge the desired equivalence among different problem formulations. We also extend the methodology to solve mean-field games with Poissonian common noise, confirming the existence of a strong mean field equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23441v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lijun Bo, Jingfei Wang, Xiaoli Wei, Xiang Yu</dc:creator>
    </item>
    <item>
      <title>Incorporating Preconditioning into Accelerated Approaches: Theoretical Guarantees and Practical Improvement</title>
      <link>https://arxiv.org/abs/2505.23510</link>
      <description>arXiv:2505.23510v1 Announce Type: new 
Abstract: Machine learning and deep learning are widely researched fields that provide solutions to many modern problems. Due to the complexity of new problems related to the size of datasets, efficient approaches are obligatory. In optimization theory, the Heavy Ball and Nesterov methods use \textit{momentum} in their updates of model weights. On the other hand, the minimization problems considered may be poorly conditioned, which affects the applicability and effectiveness of the aforementioned techniques. One solution to this issue is \textit{preconditioning}, which has already been investigated in approaches such as \textsc{AdaGrad}, \textsc{RMSProp}, \textsc{Adam} and others. Despite this, momentum acceleration and preconditioning have not been fully explored together. Therefore, we propose the Preconditioned Heavy Ball (\textsc{PHB}) and Preconditioned Nesterov method (\textsc{PN}) with theoretical guarantees of convergence under \textit{unified} assumption on the scaling matrix. Furthermore, we provide numerical experiments that demonstrate superior performance compared to the unscaled techniques in terms of iteration and oracle complexities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23510v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stepan Trifonov, Leonid Levin, Savelii Chezhegov, Aleksandr Beznosikov</dc:creator>
    </item>
    <item>
      <title>Inexact JKO and proximal-gradient algorithms in the Wasserstein space</title>
      <link>https://arxiv.org/abs/2505.23517</link>
      <description>arXiv:2505.23517v1 Announce Type: new 
Abstract: This paper studies the convergence properties of the inexact Jordan-Kinderlehrer-Otto (JKO) scheme and proximal-gradient algorithm in the context of Wasserstein spaces. The JKO scheme, a widely-used method for approximating solutions to gradient flows in Wasserstein spaces, typically assumes exact solutions to iterative minimization problems. However, practical applications often require approximate solutions due to computational limitations. This work focuses on the convergence of the scheme to minimizers for the underlying functional and addresses these challenges by analyzing two types of inexactness: errors in Wasserstein distance and errors in energy functional evaluations. The paper provides rigorous convergence guarantees under controlled error conditions, demonstrating that weak convergence can still be achieved with inexact steps. The analysis is further extended to proximal-gradient algorithms, showing that convergence is preserved under inexact evaluations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23517v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simone Di Marino, Emanuele Naldi, Silvia Villa</dc:creator>
    </item>
    <item>
      <title>Going from a Representative Agent to Counterfactuals in Combinatorial Choice</title>
      <link>https://arxiv.org/abs/2505.23546</link>
      <description>arXiv:2505.23546v1 Announce Type: new 
Abstract: We study decision-making problems where data comprises points from a collection of binary polytopes, capturing aggregate information stemming from various combinatorial selection environments. We propose a nonparametric approach for counterfactual inference in this setting based on a representative agent model, where the available data is viewed as arising from maximizing separable concave utility functions over the respective binary polytopes. Our first contribution is to precisely characterize the selection probabilities representable under this model and show that verifying the consistency of any given aggregated selection dataset reduces to solving a polynomial-sized linear program. Building on this characterization, we develop a nonparametric method for counterfactual prediction. When data is inconsistent with the model, finding a best-fitting approximation for prediction reduces to solving a compact mixed-integer convex program. Numerical experiments based on synthetic data demonstrate the method's flexibility, predictive accuracy, and strong representational power even under model misspecification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23546v1</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yanqiu Ruan, Karthyek Murthy, Karthik Natarajan</dc:creator>
    </item>
    <item>
      <title>Ambulance Allocation for Patient-Centered Care</title>
      <link>https://arxiv.org/abs/2505.23560</link>
      <description>arXiv:2505.23560v1 Announce Type: new 
Abstract: Emergency Medical Services (EMS) in the United States and similar systems typically utilize a single treatment pathway, transporting all patients to emergency departments (EDs), regardless of their actual care needs or preferences. Recent policy reforms have sought to introduce alternative treatment pathways to divert lower acuity patients from the ED, but operationalizing these options has proven difficult. This paper proposes a patient-centered EMS (PC-EMS) ambulance allocation model that supports multiple care pathways by aligning EMS responses with individual patient needs. We develop a two-stage mixed-integer optimization framework that incorporates multiple dispatch and secondary assignment strategies which enable dynamic resource deployment. The model maximizes appropriate ED diversions while maintaining ambulance availability using a queueing-based availability constraint. We leverage national EMS data and machine learning to estimate dispatcher accuracy and diversion potential. Simulations across diverse geographic regions suggest that agencies can achieve up to 80% of possible ED diversions by equipping only 15 to 25% of their fleet with diversion capable units. Adaptive dispatch strategies improve diversion rates by 3.4 to 8.6 times compared to conventional single unit dispatch. These results provide actionable guidance for PC-EMS implementation by quantifying the trade off between equipment investment and operational coordination. Using the allocation model, agencies can strategically choose between upgrading fewer units with advanced dispatching protocols versus larger fleet investments with simpler operations. This approach offers flexible pathways suited to different organizational capabilities and implementation readiness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23560v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eric G. Stratman, Justin J. Boutilier, Laura A. Albert</dc:creator>
    </item>
    <item>
      <title>On the Convergence of Decentralized Stochastic Gradient-Tracking with Finite-Time Consensus</title>
      <link>https://arxiv.org/abs/2505.23577</link>
      <description>arXiv:2505.23577v1 Announce Type: new 
Abstract: Algorithms for decentralized optimization and learning rely on local optimization steps coupled with combination steps over a graph. Recent works have demonstrated that using a time-varying sequence of matrices that achieve finite-time consensus can improve the communication and iteration complexity of decentralized optimization algorithms based on gradient tracking. In practice, a sequence of matrices satisfying the exact finite-time consensus property may not be available due to imperfect knowledge of the network topology, a limit on the length of the sequence, or numerical instabilities. In this work, we quantify the impact of approximate finite-time consensus sequences on the convergence of a gradient-tracking based decentralized optimization algorithm, clarifying the interplay between accuracy and length of the sequence as well as typical problem parameters such as smoothness and gradient noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23577v1</guid>
      <category>math.OC</category>
      <category>eess.SP</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aaron Fainman, Stefan Vlaski</dc:creator>
    </item>
    <item>
      <title>Optimizing Flexible Complex Systems with Coupled and Co-Evolving Subsystems under Operational Uncertainties</title>
      <link>https://arxiv.org/abs/2505.23611</link>
      <description>arXiv:2505.23611v1 Announce Type: new 
Abstract: The paper develops a novel design optimization framework and associated computational techniques for staged deployment optimization of complex systems under operational uncertainties. It proposes a local scenario discretization method that offers a computationally efficient approach to optimize staged co-deployment of multiple coupled subsystems by decoupling weak dynamic interaction among subsystems. The proposed method is applied to a case study and is demonstrated to provide an effective and scalable strategy to determine the optimal and flexible systems design under uncertainty. The developed optimization framework is expected to improve the staged deployment design of various complex engineering systems, such as water, energy, food, and other infrastructure systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23611v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Koki Ho, Masafumi Isaji</dc:creator>
    </item>
    <item>
      <title>Hybrid subgradient and simulated annealing method for hemivariational inequalities</title>
      <link>https://arxiv.org/abs/2505.23676</link>
      <description>arXiv:2505.23676v1 Announce Type: new 
Abstract: In this paper, we employ a global aggregate subgradient method for the numerical solution of hemivariational inequality problems arising in contact mechanics. The method integrates a global search procedure to identify starting points for a local minimization algorithm. The algorithm consists of two types of steps: null steps and serious steps. In each null step, only two subgradients are utilized: the aggregate subgradient and the subgradient computed at the current iteration point, which together determine the search direction. Furthermore, we compare the performance of the proposed method with selected solvers using a representative contact mechanics problem as a case study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23676v1</guid>
      <category>math.OC</category>
      <category>cs.CE</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Piotr Bartman-Szwarc, Adil M. Bagirov, Anna Ochal</dc:creator>
    </item>
    <item>
      <title>PGLearn -- An Open-Source Learning Toolkit for Optimal Power Flow</title>
      <link>https://arxiv.org/abs/2505.22825</link>
      <description>arXiv:2505.22825v1 Announce Type: cross 
Abstract: Machine Learning (ML) techniques for Optimal Power Flow (OPF) problems have recently garnered significant attention, reflecting a broader trend of leveraging ML to approximate and/or accelerate the resolution of complex optimization problems. These developments are necessitated by the increased volatility and scale in energy production for modern and future grids. However, progress in ML for OPF is hindered by the lack of standardized datasets and evaluation metrics, from generating and solving OPF instances, to training and benchmarking machine learning models. To address this challenge, this paper introduces PGLearn, a comprehensive suite of standardized datasets and evaluation tools for ML and OPF. PGLearn provides datasets that are representative of real-life operating conditions, by explicitly capturing both global and local variability in the data generation, and by, for the first time, including time series data for several large-scale systems. In addition, it supports multiple OPF formulations, including AC, DC, and second-order cone formulations. Standardized datasets are made publicly available to democratize access to this field, reduce the burden of data generation, and enable the fair comparison of various methodologies. PGLearn also includes a robust toolkit for training, evaluating, and benchmarking machine learning models for OPF, with the goal of standardizing performance evaluation across the field. By promoting open, standardized datasets and evaluation metrics, PGLearn aims at democratizing and accelerating research and innovation in machine learning applications for optimal power flow problems. Datasets are available for download at https://www.huggingface.co/PGLearn.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22825v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Klamkin, Mathieu Tanneau, Pascal Van Hentenryck</dc:creator>
    </item>
    <item>
      <title>Smart Surrogate Losses for Contextual Stochastic Linear Optimization with Robust Constraints</title>
      <link>https://arxiv.org/abs/2505.22881</link>
      <description>arXiv:2505.22881v1 Announce Type: cross 
Abstract: We study an extension of contextual stochastic linear optimization (CSLO) that, in contrast to most of the existing literature, involves inequality constraints that depend on uncertain parameters predicted by a machine learning model. To handle the constraint uncertainty, we use contextual uncertainty sets constructed via methods like conformal prediction. Given a contextual uncertainty set method, we introduce the "Smart Predict-then-Optimize with Robust Constraints" (SPO-RC) loss, a feasibility-sensitive adaptation of the SPO loss that measures decision error of predicted objective parameters. We also introduce a convex surrogate, SPO-RC+, and prove Fisher consistency with SPO-RC. To enhance performance, we train on truncated datasets where true constraint parameters lie within the uncertainty sets, and we correct the induced sample selection bias using importance reweighting techniques. Through experiments on fractional knapsack and alloy production problem instances, we demonstrate that SPO-RC+ effectively handles uncertainty in constraints and that combining truncation with importance reweighting can further improve performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22881v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hyungki Im, Wyame Benslimane, Paul Grigas</dc:creator>
    </item>
    <item>
      <title>Latent Representations for Control Design with Provable Stability and Safety Guarantees</title>
      <link>https://arxiv.org/abs/2505.23210</link>
      <description>arXiv:2505.23210v1 Announce Type: cross 
Abstract: We initiate a formal study on the use of low-dimensional latent representations of dynamical systems for verifiable control synthesis. Our main goal is to enable the application of verification techniques -- such as Lyapunov or barrier functions -- that might otherwise be computationally prohibitive when applied directly to the full state representation. Towards this goal, we first provide dynamics-aware approximate conjugacy conditions which formalize the notion of reconstruction error necessary for systems analysis. We then utilize our conjugacy conditions to transfer the stability and invariance guarantees of a latent certificate function (e.g., a Lyapunov or barrier function) for a latent space controller back to the original system. Importantly, our analysis contains several important implications for learning latent spaces and dynamics, by highlighting the necessary geometric properties which need to be preserved by the latent space, in addition to providing concrete loss functions for dynamics reconstruction that are directly related to control design. We conclude by demonstrating the applicability of our theory to two case studies: (1) stabilization of a cartpole system, and (2) collision avoidance for a two vehicle system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23210v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul Lutkus, Kaiyuan Wang, Lars Lindemann, Stephen Tu</dc:creator>
    </item>
    <item>
      <title>Accelerating RLHF Training with Reward Variance Increase</title>
      <link>https://arxiv.org/abs/2505.23247</link>
      <description>arXiv:2505.23247v1 Announce Type: cross 
Abstract: Reinforcement learning from human feedback (RLHF) is an essential technique for ensuring that large language models (LLMs) are aligned with human values and preferences during the post-training phase. As an effective RLHF approach, group relative policy optimization (GRPO) has demonstrated success in many LLM-based applications. However, efficient GRPO-based RLHF training remains a challenge. Recent studies reveal that a higher reward variance of the initial policy model leads to faster RLHF training. Inspired by this finding, we propose a practical reward adjustment model to accelerate RLHF training by provably increasing the reward variance and preserving the relative preferences and reward expectation. Our reward adjustment method inherently poses a nonconvex optimization problem, which is NP-hard to solve in general. To overcome the computational challenges, we design a novel $O(n \log n)$ algorithm to find a global solution of the nonconvex reward adjustment model by explicitly characterizing the extreme points of the feasible set. As an important application, we naturally integrate this reward adjustment model into the GRPO algorithm, leading to a more efficient GRPO with reward variance increase (GRPOVI) algorithm for RLHF training. As an interesting byproduct, we provide an indirect explanation for the empirical effectiveness of GRPO with rule-based reward for RLHF training, as demonstrated in DeepSeek-R1. Experiment results demonstrate that the GRPOVI algorithm can significantly improve the RLHF training efficiency compared to the original GRPO algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23247v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zonglin Yang, Zhexuan Gu, Houduo Qi, Yancheng Yuan</dc:creator>
    </item>
    <item>
      <title>Grower-in-the-Loop Interactive Reinforcement Learning for Greenhouse Climate Control</title>
      <link>https://arxiv.org/abs/2505.23355</link>
      <description>arXiv:2505.23355v1 Announce Type: cross 
Abstract: Climate control is crucial for greenhouse production as it directly affects crop growth and resource use. Reinforcement learning (RL) has received increasing attention in this field, but still faces challenges, including limited training efficiency and high reliance on initial learning conditions. Interactive RL, which combines human (grower) input with the RL agent's learning, offers a potential solution to overcome these challenges. However, interactive RL has not yet been applied to greenhouse climate control and may face challenges related to imperfect inputs. Therefore, this paper aims to explore the possibility and performance of applying interactive RL with imperfect inputs into greenhouse climate control, by: (1) developing three representative interactive RL algorithms tailored for greenhouse climate control (reward shaping, policy shaping and control sharing); (2) analyzing how input characteristics are often contradicting, and how the trade-offs between them make grower's inputs difficult to perfect; (3) proposing a neural network-based approach to enhance the robustness of interactive RL agents under limited input availability; (4) conducting a comprehensive evaluation of the three interactive RL algorithms with imperfect inputs in a simulated greenhouse environment. The demonstration shows that interactive RL incorporating imperfect grower inputs has the potential to improve the performance of the RL agent. RL algorithms that influence action selection, such as policy shaping and control sharing, perform better when dealing with imperfect inputs, achieving 8.4% and 6.8% improvement in profit, respectively. In contrast, reward shaping, an algorithm that manipulates the reward function, is sensitive to imperfect inputs and leads to a 9.4% decrease in profit. This highlights the importance of selecting an appropriate mechanism when incorporating imperfect inputs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23355v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Maxiu Xiao, Jianglin Lan, Jingxing Yu, Eldert van Henten, Congcong Sun</dc:creator>
    </item>
    <item>
      <title>Robust Aperiodic Sampled-Data Washout Control for Uncertain Affine Systems</title>
      <link>https://arxiv.org/abs/2505.23534</link>
      <description>arXiv:2505.23534v1 Announce Type: cross 
Abstract: In this paper, we address the problem of designing an aperiodic sampled-data controller stabilizing the zero-input equilibrium of an uncertain affine plant. The closed-loop system is modeled as a hybrid dynamical system incorporating a timer triggering the occurrence of the sampling events and two memory states storing the value of the controller state and controller output at each sampling time. Necessary and sufficient conditions on the controller parameters are given to establish the sought property. A constructive controller design algorithm based on sum-of-squares programming is given. A numerical example illustrates the effectiveness of the approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23534v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Folco Giorgetti, Francesco Crocetti, Mario Luca Fravolini, Francesco Ferrante</dc:creator>
    </item>
    <item>
      <title>Integrated design of system structure and delayed resonator towards efficient non-collocated vibration absorption</title>
      <link>https://arxiv.org/abs/2505.23608</link>
      <description>arXiv:2505.23608v1 Announce Type: cross 
Abstract: The problem of non-collocated vibration absorption by a delayed resonator is addressed with emphasis on system fatigue resistance and energy efficiency of control actions. The analysis is performed for a system consisting of an arbitrary large series of flexibly linked single-degree-of-freedom masses. For the stage where the vibration of the target mass is fully absorbed by the non-collocated resonator, key forces, motion amplitudes and potential energies across the system structure are assessed. Next, a complete parameter set of the resonator gain and delay is derived, and the actuation force and power needed by the resonator for the full vibration absorption is determined. The derived quantities are utilized in forming an optimization problem to balance minimal risk of fatigue across the system structure and power needed by the resonator, under the closed loop stability and parameter constraints. Next to the gain and delay of the resonator, selected structural parameters of the system are used as variables in the constrained nonlinear optimization problem. Experimental and numerical case studies are included to demonstrate benefits of the proposed integrated structural and control design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23608v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jsv.2025.119101</arxiv:DOI>
      <arxiv:journal_reference>Journal of Sound and Vibration, 612, 2025, 119101</arxiv:journal_reference>
      <dc:creator>Adam Peichl, Mat\v{e}j Ku\v{r}e, Wim Michiels, Tom\'a\v{s} Vyhl\'idal</dc:creator>
    </item>
    <item>
      <title>Global optimization of graph acquisition functions for neural architecture search</title>
      <link>https://arxiv.org/abs/2505.23640</link>
      <description>arXiv:2505.23640v1 Announce Type: cross 
Abstract: Graph Bayesian optimization (BO) has shown potential as a powerful and data-efficient tool for neural architecture search (NAS). Most existing graph BO works focus on developing graph surrogates models, i.e., metrics of networks and/or different kernels to quantify the similarity between networks. However, the acquisition optimization, as a discrete optimization task over graph structures, is not well studied due to the complexity of formulating the graph search space and acquisition functions. This paper presents explicit optimization formulations for graph input space including properties such as reachability and shortest paths, which are used later to formulate graph kernels and the acquisition function. We theoretically prove that the proposed encoding is an equivalent representation of the graph space and provide restrictions for the NAS domain with either node or edge labels. Numerical results over several NAS benchmarks show that our method efficiently finds the optimal architecture for most cases, highlighting its efficacy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23640v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yilin Xie, Shiqiang Zhang, Jixiang Qing, Ruth Misener, Calvin Tsay</dc:creator>
    </item>
    <item>
      <title>On the Convergence Analysis of Muon</title>
      <link>https://arxiv.org/abs/2505.23737</link>
      <description>arXiv:2505.23737v1 Announce Type: cross 
Abstract: The majority of parameters in neural networks are naturally represented as matrices. However, most commonly used optimizers treat these matrix parameters as flattened vectors during optimization, potentially overlooking their inherent structural properties. Recently, an optimizer called Muon has been proposed, specifically designed to optimize matrix-structured parameters. Extensive empirical evidence shows that Muon can significantly outperform traditional optimizers when training neural networks. Nonetheless, the theoretical understanding of Muon's convergence behavior and the reasons behind its superior performance remain limited. In this work, we present a comprehensive convergence rate analysis of Muon and its comparison with Gradient Descent (GD). We further characterize the conditions under which Muon can outperform GD. Our theoretical results reveal that Muon can benefit from the low-rank and approximate blockwise diagonal structure of Hessian matrices -- phenomena widely observed in practical neural network training. Our experimental results support and corroborate the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23737v1</guid>
      <category>stat.ML</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei Shen, Ruichuan Huang, Minhui Huang, Cong Shen, Jiawei Zhang</dc:creator>
    </item>
    <item>
      <title>Analysis of Four-Dimensional Variational Data Assimilation Problems in Low Regularity Spaces</title>
      <link>https://arxiv.org/abs/2303.00847</link>
      <description>arXiv:2303.00847v2 Announce Type: replace 
Abstract: We carry out a rigorous analysis of four-dimensional variational data assimilation ($4D$-VAR) problems for linear and semilinear parabolic partial differential equations. Continuity of the state with respect to the spatial variable is required since pointwise observations of the state variable appear in the cost functional. Using maximal parabolic regularity tools, we prove this regularity for initial conditions with $L^\beta$-regularity guaranteed by control constraints, rather than Sobolev regularity of the controls ensured by artificial cost terms. We obtain existence of optimal controls and first order necessary optimality conditions for both the convex and nonconvex problem with spatial dimension $d=2,3$, as well as second order sufficient optimality conditions for the nonconvex problem for $d=2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.00847v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paula Castro, Juan Carlos De los Reyes, Ira Neitzel</dc:creator>
    </item>
    <item>
      <title>Two-sided Assortment Optimization: Adaptivity Gaps and Approximation Algorithms</title>
      <link>https://arxiv.org/abs/2403.08929</link>
      <description>arXiv:2403.08929v5 Announce Type: replace 
Abstract: To address efficiency and design challenges in choice-based matching platforms, we introduce a two-sided assortment optimization framework under general choice preferences. The goal in this problem is to maximize the expected number of matches by deciding which assortments are displayed to the agents and the order in which they are shown. In this context, we identify several classes of policies that platforms can use in their design. Our goals are: (1) to measure the value that one class of policies has over another one, and (2) to approximately solve the optimization problem itself for a given class. For (1), we define the adaptivity gap as the worst-case ratio between the optimal values of two different policy classes. First, we show that the gap between the class of policies that statically show assortments to one-side first and the class of policies that adaptively show assortments to one-side first is exactly $e/(e-1)$. Second, we show that the gap between the latter class of policies and the fully adaptive class of policies that show assortments to agents one by one is exactly $2$. We also note that the worst policies are those who simultaneously show assortments to all the agents. For (2), we first design a polynomial time algorithm that achieves a $1/4$ approximation factor within the class of policies that adaptively show assortments to agents one by one. Furthermore, when agents' preferences are governed by multinomial-logit models, we show that a 0.067 approximation factor can be obtained within the class of policies that show assortments to all agents at once. We further generalize our results to constrained assortment settings, where we impose an upper bound on the size of the displayed assortments. Finally, we present a computational study to evaluate the empirical performance of our theoretical guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08929v5</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Omar El Housni, Ulysse Hennebelle, Alfredo Torrico</dc:creator>
    </item>
    <item>
      <title>Nonlinear Network Identifiability with Full Excitations</title>
      <link>https://arxiv.org/abs/2405.07636</link>
      <description>arXiv:2405.07636v2 Announce Type: replace 
Abstract: We derive conditions for the identifiability of nonlinear networks characterized by additive dynamics at the level of the edges when all the nodes are excited. In contrast to linear systems, we show that the measurement of all sinks is necessary and sufficient for the identifiability of directed acyclic graphs, under the assumption that dynamics are described by analytic functions without constant terms (i.e., $f(0)=0$). But if constant terms are present, then the identifiability is impossible as soon as one node has more than one in-neighbor. In the case of general digraphs that may contain cycles, we consider additively separable functions for the analysis of the identifiability, and we show that the measurement of one node of all the sinks of the condensation digraph is necessary and sufficient. Several examples are added to illustrate the results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07636v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Renato Vizuete, Julien M. Hendrickx</dc:creator>
    </item>
    <item>
      <title>Stochastic Variance-Reduced Forward-Reflected-Backward Splitting Methods for Nonmonotone Generalized Equations</title>
      <link>https://arxiv.org/abs/2406.00937</link>
      <description>arXiv:2406.00937v2 Announce Type: replace 
Abstract: We develop two novel stochastic variance-reduction methods to approximate solutions of a class of nonmonotone [generalized] equations. Our algorithms leverage a new combination of ideas from the forward-reflected-backward splitting method and a class of unbiased variance-reduced estimators. We construct two new stochastic estimators within this class, inspired by the well-known SVRG and SAGA estimators. These estimators significantly differ from existing approaches used in minimax and variational inequality problems. By appropriately choosing parameters, both algorithms achieve a state-of-the-art oracle complexity of $\mathcal{O}(n + n^{2/3}\epsilon^{-2})$ for obtaining an $\epsilon$-solution in terms of the operator residual norm for a class of nonmonotone problems, where $n$ is the number of summands and $\epsilon$ signifies the desired accuracy. This complexity aligns with the best-known results in SVRG and SAGA methods for stochastic nonconvex optimization. We test our algorithms on some numerical examples and compare them with existing methods. The results demonstrate promising improvements offered by the new methods compared to their competitors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00937v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>ICML 2025</arxiv:journal_reference>
      <dc:creator>Quoc Tran-Dinh</dc:creator>
    </item>
    <item>
      <title>An Extended Validity Domain for Constraint Learning</title>
      <link>https://arxiv.org/abs/2406.10065</link>
      <description>arXiv:2406.10065v2 Announce Type: replace 
Abstract: We consider embedding a predictive machine-learning model within a prescriptive optimization problem. In this setting, called constraint learning, we study the concept of a validity domain, i.e., a constraint added to the feasible set, which keeps the optimization close to the training data, thus helping to ensure that the computed optimal solution exhibits less prediction error. In particular, we propose a new validity domain which uses a standard convex-hull idea but in an extended space. We investigate its properties and compare it empirically with existing validity domains on a set of test problems for which the ground truth is known. Results show that our extended convex hull routinely outperforms existing validity domains, especially in terms of the function value error, that is, it exhibits closer agreement between the true function value and the predicted function value at the computed optimal solution. We also consider our approach within two stylized optimization models, which show that our method reduces feasibility error, as well as a real-world pricing case study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10065v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yilin Zhu, Samuel Burer</dc:creator>
    </item>
    <item>
      <title>Guarantees of a Preconditioned Subgradient Algorithm for Overparameterized Asymmetric Low-rank Matrix Recovery</title>
      <link>https://arxiv.org/abs/2410.16826</link>
      <description>arXiv:2410.16826v2 Announce Type: replace 
Abstract: In this paper, we focus on a matrix factorization-based approach to recover low-rank {\it asymmetric} matrices from corrupted measurements. We propose an {\it Overparameterized Preconditioned Subgradient Algorithm (OPSA)} and provide, for the first time in the literature, linear convergence rates independent of the rank of the sought asymmetric matrix in the presence of gross corruptions. Our work goes beyond existing results in preconditioned-type approaches addressing their current limitation, i.e., the lack of convergence guarantees in the case of {\it asymmetric matrices of unknown rank}. By applying our approach to (robust) matrix sensing, we highlight its merits when the measurement operator satisfies a mixed-norm restricted isometry property. Lastly, we present extensive numerical experiments that validate our theoretical results and demonstrate the effectiveness of our approach for different levels of overparameterization and outlier corruptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16826v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>International Conference on Machine Learning, 2025</arxiv:journal_reference>
      <dc:creator>Paris Giampouras, HanQin Cai, Rene Vidal</dc:creator>
    </item>
    <item>
      <title>New results related to cutters and to an extrapolated block-iterative method for finding a common fixed point of a collection of them</title>
      <link>https://arxiv.org/abs/2410.20448</link>
      <description>arXiv:2410.20448v2 Announce Type: replace 
Abstract: Given a Hilbert space and a finite family of operators defined on the space, the common fixed point problem (CFPP) is to find a point in the intersection of the fixed point sets of these operators. Instances of the problem have numerous applications in science and engineering. We consider an extrapolated block-iterative method with dynamic weights for solving the CFPP assuming the operators belong to a wide class of operators called cutters. Global convergence is proved in two different scenarios, one of them is under a seemingly new condition on the weights which is less restrictive than a condition suggested in previous works. In order to establish convergence, we derive various new results of independent interest related to cutters, some of them extend, generalize and clarify previously published results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20448v2</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yair Censor, Daniel Reem, Maroun Zaknoon</dc:creator>
    </item>
    <item>
      <title>Optimizing Perishable and Non-Perishable Product Assignment to Packaging Lines in a Sustainable Manufacturing System: An AUGMECON2VIKOR Algorithm</title>
      <link>https://arxiv.org/abs/2410.21844</link>
      <description>arXiv:2410.21844v2 Announce Type: replace 
Abstract: Identifying appropriate manufacturing systems for products can be considered a pivotal manufacturing task contributing to the optimization of operational and planning activities. It has gained importance in the food industry due to the distinct constraints and considerations posed by perishable and non-perishable items in this problem. Hence, this study proposes a new mathematical model according to knowledge discovery as well as an assignment model to optimize manufacturing systems for perishable, non-perishable, and hybrid products tailored to meet their unique characteristics. In the presented model, three objective functions are taken into account: (1) minimizing production costs by assigning the products to the right set of manufacturing systems, (2) maximizing the product quality by assigning the products to the systems, and (3) minimizing total CO2 emissions of the machines. A numerical example is utilized to evaluate the performance of AUGMECON2VIKOR compared to AUGMECON2. The results show that AUGMECON2VIKOR obtains superior Pareto solutions across all objective functions. Furthermore, the sensitivity analysis explores the positive green impacts, influencing both cost and quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21844v2</guid>
      <category>math.OC</category>
      <category>cs.CE</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ifacol.2024.09.068</arxiv:DOI>
      <dc:creator>Reza Shahabi-Shahmiri, Reza Tavakkoli-Moghaddam, Zdenek Hanzalek, Mohammad Ghasemi, Seyed-Ali Mirnezami, Mohammad Rohaninejad</dc:creator>
    </item>
    <item>
      <title>DeePC-Hunt: Data-enabled Predictive Control Hyperparameter Tuning via Differentiable Optimization</title>
      <link>https://arxiv.org/abs/2412.06481</link>
      <description>arXiv:2412.06481v2 Announce Type: replace 
Abstract: This paper introduces Data-enabled Predictive Control Hyperparameter Tuning via Differentiable Optimization (DeePC-Hunt), a backpropagation-based method for automatic hyperparameter tuning of the DeePC algorithm. The necessity for such a method arises from the importance of hyperparameter selection to achieve satisfactory closed-loop DeePC performance. The standard methods for hyperparameter selection are to either optimize the open-loop performance, or use manual guess-and-check. Optimizing the open-loop performance can result in unacceptable closed-loop behavior, while manual guess-and-check can pose safety challenges. DeePC-Hunt provides an alternative method for hyperparameter tuning which uses an approximate model of the system dynamics and backpropagation to directly optimize hyperparameters for the closed-loop DeePC performance. Numerical simulations demonstrate the effectiveness of DeePC in combination with DeePC-Hunt in a complex stabilization task for a nonlinear system and its superiority over model-based control strategies in terms of robustness to model misspecifications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06481v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Michael Cummins, Alberto Padoan, Keith Moffat, Florian Dorfler, John Lygeros</dc:creator>
    </item>
    <item>
      <title>Stable Recovery of Regularized Linear Inverse Problems</title>
      <link>https://arxiv.org/abs/2412.11313</link>
      <description>arXiv:2412.11313v2 Announce Type: replace 
Abstract: Recovering a low-complexity signal from its noisy observations by regularization methods is a cornerstone of inverse problems and compressed sensing. Stable recovery ensures that the original signal can be approximated linearly by optimal solutions of the corresponding Morozov or Tikhonov regularized optimization problems. In this paper, we propose new characterizations for stable recovery in finite-dimensional spaces, uncovering the role of nonsmooth second-order information. These insights enable a deeper understanding of stable recovery and their practical implications. As a consequence, we apply our theory to derive new sufficient conditions for stable recovery of the analysis group sparsity problems, including the group sparsity and isotropic total variation problems. Numerical experiments on these two problems give favorable results about using our conditions to test stable recovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11313v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tran T. A. Nghia, Huy N. Pham, Nghia V. Vo</dc:creator>
    </item>
    <item>
      <title>Nonconvex Stochastic Optimization under Heavy-Tailed Noises: Optimal Convergence without Gradient Clipping</title>
      <link>https://arxiv.org/abs/2412.19529</link>
      <description>arXiv:2412.19529v4 Announce Type: replace 
Abstract: Recently, the study of heavy-tailed noises in first-order nonconvex stochastic optimization has gotten a lot of attention since it was recognized as a more realistic condition as suggested by many empirical observations. Specifically, the stochastic noise (the difference between the stochastic and true gradient) is considered to have only a finite $\mathfrak{p}$-th moment where $\mathfrak{p}\in\left(1,2\right]$ instead of assuming it always satisfies the classical finite variance assumption. To deal with this more challenging setting, people have proposed different algorithms and proved them to converge at an optimal $\mathcal{O}(T^{\frac{1-\mathfrak{p}}{3\mathfrak{p}-2}})$ rate for smooth objectives after $T$ iterations. Notably, all these new-designed algorithms are based on the same technique - gradient clipping. Naturally, one may want to know whether the clipping method is a necessary ingredient and the only way to guarantee convergence under heavy-tailed noises. In this work, by revisiting the existing Batched Normalized Stochastic Gradient Descent with Momentum (Batched NSGDM) algorithm, we provide the first convergence result under heavy-tailed noises but without gradient clipping. Concretely, we prove that Batched NSGDM can achieve the optimal $\mathcal{O}(T^{\frac{1-\mathfrak{p}}{3\mathfrak{p}-2}})$ rate even under the relaxed smooth condition. More interestingly, we also establish the first $\mathcal{O}(T^{\frac{1-\mathfrak{p}}{2\mathfrak{p}}})$ convergence rate in the case where the tail index $\mathfrak{p}$ is unknown in advance, which is arguably the common scenario in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19529v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zijian Liu, Zhengyuan Zhou</dc:creator>
    </item>
    <item>
      <title>Optimal control of the fidelity coefficient in a Cahn-Hilliard image inpainting model</title>
      <link>https://arxiv.org/abs/2502.03025</link>
      <description>arXiv:2502.03025v2 Announce Type: replace 
Abstract: We consider an inpainting model proposed by A. Bertozzi et al., which is based on a Cahn-Hilliard-type equation. This equation describes the evolution of an order parameter that represents an approximation of the original image occupying a bounded two-dimensional domain. The given image is assumed to be damaged in a fixed subdomain, and the equation is characterised by a linear reaction term. This term is multiplied by the so-called fidelity coefficient, which is a strictly positive bounded function defined in the undamaged region. The idea is that, given an initial image, the order parameter evolves towards the given image, and this process properly diffuses through the boundary of the damaged region, restoring the damaged image, provided that the fidelity coefficient is large enough. Here, we formulate an optimal control problem based on this fact, namely, our cost functional accounts for the magnitude of the fidelity coefficient. Assuming a singular potential to ensure that the order parameter takes its values in between 0 and 1, we first analyse the control-to-state operator and prove the existence of at least one optimal control, establishing the validity of first-order optimality conditions. Then, under suitable assumptions, we demonstrate second-order optimality conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03025v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elena Beretta, Cecilia Cavaterra, Matteo Fornoni, Maurizio Grasselli</dc:creator>
    </item>
    <item>
      <title>A three-term Polak-Ribi\`{e}re-Polyak conjugate gradient method for vector optimization</title>
      <link>https://arxiv.org/abs/2505.08408</link>
      <description>arXiv:2505.08408v2 Announce Type: replace 
Abstract: A three-term Polak-Ribi\`{e}re-Polyak conjugate gradient method is first proposed in this paper for solving vector optimization problems. This method can autonomously generate descent directions independent of line search procedures, while retaining the conjugate property. The global convergence of the proposed scheme is established by the generalized Wolfe line search procedure without self-adjusting strategies, regular restarts and convexity assumptions. Finally, numerical experiments illustrating the practical performance of this method are presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08408v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guangxuan Lin, Shouqiang Du</dc:creator>
    </item>
    <item>
      <title>A gradient flow for the Porous Medium Equations with Dirichlet boundary conditions</title>
      <link>https://arxiv.org/abs/2212.06092</link>
      <description>arXiv:2212.06092v3 Announce Type: replace-cross 
Abstract: We consider the gradient flow structure of the porous medium equations with non-negative constant Dirichlet boundary conditions. We construct weak solutions to the equations via the minimizing movement scheme by considering an entropy functional with respect to $Wb_2$ distance, which is a modified Wasserstein distance introduced by Figalli and Gigli [J. Math. Pures Appl. 94, (2010), pp. 107-130]. Furthermore, the constructed solutions are characterized as curves of maximal slope in a suitable sense.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.06092v3</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dongkwang Kim, Dowan Koo, Geuntaek Seo</dc:creator>
    </item>
    <item>
      <title>Exponential Utility Maximization in a Continuous Time Gaussian Framework</title>
      <link>https://arxiv.org/abs/2311.17270</link>
      <description>arXiv:2311.17270v4 Announce Type: replace-cross 
Abstract: In this work we study the continuous time exponential utility maximization problem in the framework of an investor who is informed about the price changes with a delay. This leads to a non-Markovian stochastic control problem. In the case where the risky asset is given by a Gaussian process (with some additional properties) we establish a solution for the optimal control and the corresponding value. Our approach is purely probabilistic and is based on the theory for Radon-Nikodym derivatives of Gaussian measures developed by Shepp \cite{S:66}, Hitsuda \cite{H:68} and received a new and unifying angle in [2].</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.17270v4</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yan Dolinsky</dc:creator>
    </item>
    <item>
      <title>Proximal Interacting Particle Langevin Algorithms</title>
      <link>https://arxiv.org/abs/2406.14292</link>
      <description>arXiv:2406.14292v3 Announce Type: replace-cross 
Abstract: We introduce a class of algorithms, termed proximal interacting particle Langevin algorithms (PIPLA), for inference and learning in latent variable models whose joint probability density is non-differentiable. Leveraging proximal Markov chain Monte Carlo techniques and interacting particle Langevin algorithms, we propose three algorithms tailored to the problem of estimating parameters in a non-differentiable statistical model. We prove nonasymptotic bounds for the parameter estimates produced by the different algorithms in the strongly log-concave setting and provide comprehensive numerical experiments on various models to demonstrate the effectiveness of the proposed methods. In particular, we demonstrate the utility of our family of algorithms for sparse Bayesian logistic regression, training of sparse Bayesian neural networks or neural networks with non-differentiable activation functions, image deblurring, and sparse matrix completion. Our theory and experiments together show that PIPLA family can be the de facto choice for parameter estimation problems in non-differentiable latent variable models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14292v3</guid>
      <category>stat.CO</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Conference on Uncertainty in Artificial Intelligence (UAI) 2025. Oral presentation</arxiv:journal_reference>
      <dc:creator>Paula Cordero Encinar, Francesca R. Crucinio, O. Deniz Akyildiz</dc:creator>
    </item>
    <item>
      <title>Sequential bi-level regularized inversion with application to hidden reaction law discovery</title>
      <link>https://arxiv.org/abs/2409.03834</link>
      <description>arXiv:2409.03834v2 Announce Type: replace-cross 
Abstract: In this article, we develop and present a novel regularization scheme for ill-posed inverse problems governed by nonlinear \blue{time-dependent} partial differential equations (PDEs). In our recent work, we introduced a bi-level regularization framework. This study significantly improves upon the bi-level algorithm by sequentially initializing the lower-level problem, yielding accelerated convergence and demonstrable multi-scale effect, while retaining regularizing effect and allows for the usage of inexact PDE solvers. Moreover, by collecting the lower-level trajectory, we uncover an interesting connection to the incremental load method. The sequential bi-level approach illustrates its universality through several reaction-diffusion applications, in which the nonlinear reaction law needs to be determined. We moreover prove that the proposed tangential cone condition is satisfied.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03834v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tram Thi Ngoc Nguyen</dc:creator>
    </item>
    <item>
      <title>Asymptotic stability equals exponential stability -- while you twist your eyes</title>
      <link>https://arxiv.org/abs/2411.03277</link>
      <description>arXiv:2411.03277v2 Announce Type: replace-cross 
Abstract: Suppose that two vector fields on a smooth manifold render some equilibrium point globally asymptotically stable (GAS). We show that there exists a homotopy between the corresponding semiflows such that this point remains GAS along this homotopy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03277v2</guid>
      <category>math.DS</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wouter Jongeneel</dc:creator>
    </item>
    <item>
      <title>Fundamental Bias in Inverting Random Sampling Matrices with Application to Sub-sampled Newton</title>
      <link>https://arxiv.org/abs/2502.13583</link>
      <description>arXiv:2502.13583v2 Announce Type: replace-cross 
Abstract: A substantial body of work in machine learning (ML) and randomized numerical linear algebra (RandNLA) has exploited various sorts of random sketching methodologies, including random sampling and random projection, with much of the analysis using Johnson--Lindenstrauss and subspace embedding techniques. Recent studies have identified the issue of inversion bias -- the phenomenon that inverses of random sketches are not unbiased, despite the unbiasedness of the sketches themselves. This bias presents challenges for the use of random sketches in various ML pipelines, such as fast stochastic optimization, scalable statistical estimators, and distributed optimization. In the context of random projection, the inversion bias can be easily corrected for dense Gaussian projections (which are, however, too expensive for many applications). Recent work has shown how the inversion bias can be corrected for sparse sub-gaussian projections. In this paper, we show how the inversion bias can be corrected for random sampling methods, both uniform and non-uniform leverage-based, as well as for structured random projections, including those based on the Hadamard transform. Using these results, we establish problem-independent local convergence rates for sub-sampled Newton methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13583v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chengmei Niu, Zhenyu Liao, Zenan Ling, Michael W. Mahoney</dc:creator>
    </item>
    <item>
      <title>Localization of tumor through a non-conventional numerical shape optimization technique</title>
      <link>https://arxiv.org/abs/2502.20656</link>
      <description>arXiv:2502.20656v3 Announce Type: replace-cross 
Abstract: This paper introduces a method for estimating the shape and location of an embedded tumor. The approach utilizes shape optimization techniques, applying the coupled complex boundary method. By rewriting the problem -- characterized by a measured temperature profile and corresponding flux (e.g., from infrared thermography) -- into a complex boundary value problem with a complex Robin boundary condition, the method simplifies the over-specified nature of the problem. The size and location of the tumor are identified by optimizing an objective function based on the imaginary part of the solution across the domain. Shape sensitivity analysis is conducted to compute the shape derivative of the functional. An iterative algorithm, which uses the Riesz representative of the gradient, is developed to numerically determine the geometry of the tumor via the finite element method. Additionally, we analyze the mesh sensitivity of the finite element solution of the associated state problem and derive a bound on its variation in terms of mesh deformation and its gradient. Numerical examples are provided to validate the theoretical findings and demonstrate the accuracy and effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20656v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julius Fergy Tiongson Rabago</dc:creator>
    </item>
    <item>
      <title>Optimal Bounds for Adversarial Constrained Online Convex Optimization</title>
      <link>https://arxiv.org/abs/2503.13366</link>
      <description>arXiv:2503.13366v4 Announce Type: replace-cross 
Abstract: Constrained Online Convex Optimization (COCO) can be seen as a generalization of the standard Online Convex Optimization (OCO) framework. At each round, a cost function and constraint function are revealed after a learner chooses an action. The goal is to minimize both the regret and cumulative constraint violation (CCV) against an adaptive adversary. We show for the first time that is possible to obtain the optimal $O(\sqrt{T})$ bound on both regret and CCV, improving the best known bounds of $O \left( \sqrt{T} \right)$ and $\tilde{O} \left( \sqrt{T} \right)$ for the regret and CCV, respectively. Based on a new surrogate loss function enforcing a minimum penalty on the constraint function, we demonstrate that both the Follow-the-Regularized-Leader and the Online Gradient Descent achieve the optimal bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13366v4</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ricardo N. Ferreira, Cl\'audia Soares</dc:creator>
    </item>
    <item>
      <title>A generalized global Hartman-Grobman theorem for asymptotically stable semiflows</title>
      <link>https://arxiv.org/abs/2505.21401</link>
      <description>arXiv:2505.21401v2 Announce Type: replace-cross 
Abstract: We extend the generalized global Hartman-Grobman theorem by Kvalheim and Sontag for flows to a case of asymptotically stable semiflows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21401v2</guid>
      <category>math.DS</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wouter Jongeneel</dc:creator>
    </item>
  </channel>
</rss>
