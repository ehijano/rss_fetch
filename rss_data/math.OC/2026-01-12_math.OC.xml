<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 13 Jan 2026 03:30:38 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>The Pontryagin maximum principle and $Q$-functions in rough environments</title>
      <link>https://arxiv.org/abs/2601.05354</link>
      <description>arXiv:2601.05354v1 Announce Type: new 
Abstract: We derive the Pontryagin maximum principle and $Q$-functions for the relaxed control of noisy rough differential equations. Our main tool is the development of a novel differentiation procedure along `spike variation' perturbations of the optimal state-control pair. We then exploit our development of the infinitesimal $Q$-function (also known as the $q$-function) to derive a policy improvement algorithm for settings with entropic cost constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05354v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Estepan Ashkarian, Prakash Chakraborty, Harsha Honnappa, Samy Tindel</dc:creator>
    </item>
    <item>
      <title>Markovian Compression: Looking to the Past Helps Accelerate the Future</title>
      <link>https://arxiv.org/abs/2601.05398</link>
      <description>arXiv:2601.05398v2 Announce Type: new 
Abstract: This paper deals with distributed optimization problems that use compressed communication to achieve efficient performance and mitigate communication bottleneck. We propose a family of compression schemes in which operators transform vectors fed to their input according to a Markov chain, i.e. the stochasticity of the compressors depends on previous iterations. The compressors are implemented in the vanilla Quantized Stochastic Gradient Descent algorithm (QSGD), and, to further improve the efficiency and convergence rate, in the momentum accelerated QSGD. We provide convergence results for our algorithms with Markovian compressors, the analysis covers non-convex, Polyak-Lojasiewicz, and strongly convex cases. To demonstrate the applicability of our approach to distributed data-parallel optimization problems, we conduct experiments on the CIFAR-10 and GLUE datasets with the Resnet-18 and DeBERTaV3 models. Practical results show the superiority of methods that use our compressor design over existing schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05398v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrey Veprikov, Vladimir Solodkin, Mikhail Rudakov, Petr Babkin, Aleksandr Beznosikov</dc:creator>
    </item>
    <item>
      <title>Dynamic Inclusion and Bounded Multi-Factor Tilts for Robust Portfolio Construction</title>
      <link>https://arxiv.org/abs/2601.05428</link>
      <description>arXiv:2601.05428v1 Announce Type: new 
Abstract: This paper proposes a portfolio construction framework designed to remain robust under estimation error, non-stationarity, and realistic trading constraints. The methodology combines dynamic asset eligibility, deterministic rebalancing, and bounded multi-factor tilts applied to an equal-weight baseline. Asset eligibility is formalized as a state-dependent constraint on portfolio construction, allowing factor exposure to adjust endogenously in response to observable market conditions such as liquidity, volatility, and cross-sectional breadth. Rather than estimating expected returns or covariances, the framework relies on cross-sectional rankings and hard structural bounds to control concentration, turnover, and fragility. The resulting approach is fully algorithmic, transparent, and directly implementable. It provides a robustness-oriented alternative to parametric optimization and unconstrained multi-factor models, particularly suited for long-horizon allocations where stability and operational feasibility are primary objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05428v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roberto Garrone</dc:creator>
    </item>
    <item>
      <title>Stochastic Bounded Real Lemma and $H_{\infty}$ Control of Difference Systems in Hilbert Spaces</title>
      <link>https://arxiv.org/abs/2601.05460</link>
      <description>arXiv:2601.05460v1 Announce Type: new 
Abstract: This paper mainly establishes the finite-horizon stochastic bounded real lemma, and then solves the $H_{\infty}$ control problem for discrete-time stochastic linear systems defined on the separable Hilbert spaces, thereby unifying the relevant theoretical results previously confined to the Euclidean space $\mathbb{R}^n$. To achieve these goals, the indefinite linear quadratic (LQ)-optimal control problem is firstly discussed. By employing the bounded linear operator theory and the inner product, a sufficient and necessary condition for the existence of a linear state feedback LQ-optimal control law is derived, which is closely linked with the solvability of the backward Riccati operator equation with a sign condition. Based on this, stochastic bounded real lemma is set up to facilitate the $H_{\infty}$ performance of the disturbed system in Hilbert spaces. Furthermore, the Nash equilibrium problem associated with two parameterized quadratic performance indices is worked out, which enables a uniform treatment of the $H_{\infty}$ and $H_2/H_{\infty}$ control designs by selecting specific values for the parameters. Several examples are supplied to illustrate the effectiveness of the obtained results, especially the practical significance in engineering applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05460v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cheng'ao Li, Ting Hou, Weihai Zhang, Feiqi Deng</dc:creator>
    </item>
    <item>
      <title>Difference of Convex (DC) approach for neural network approximation with uniform loss function</title>
      <link>https://arxiv.org/abs/2601.05557</link>
      <description>arXiv:2601.05557v1 Announce Type: new 
Abstract: Neural networks (NNs) can be viewed as approximation tools. Traditionally, NNs are relying on gradient and stochastic gradient (SG) methods. There are a number of available computational packages for constructing least squares approximations, while uniform (minimax) approximations are hard due to their nonsmooth nature. It was recently demonstrated that a difference convex (DC) programming approach is an efficient alternative optimiser for NNs. In this paper, we demonstrate that a DC programming approach is also efficient for minimax approximation. In our numerical experiments, we compare a DC-programming approach and ADAMAX, a commonly used method for minimax NN approximations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05557v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vinesha Peiris, Nadezda Sukhorukova</dc:creator>
    </item>
    <item>
      <title>The Maximum Clique Problem under Adversarial Uncertainty: a min-max approach</title>
      <link>https://arxiv.org/abs/2601.05644</link>
      <description>arXiv:2601.05644v1 Announce Type: new 
Abstract: We analyze the problem of identifying large cliques in graphs that are affected by adversarial uncertainty. More specifically, we consider a new formulation, namely the adversarial maximum clique problem, which extends the classical maximum-clique problem to graphs with edges strategically perturbed by an adversary. The proposed mathematical model is thus formulated as a two-player zero-sum game between a clique seeker and an opposing agent. Inspired by regularized continuous reformulations of the maximum-clique problem, we derive a penalized continuous formulation leading to a nonconvex and nonsmooth optimization problem. We further introduce the notion of stable global solutions, namely points remaining optimal under small perturbations of the penalty parameters, and prove an equivalence between stable global solutions of the continuous reformulation and largest cliques that are common to all the adversarially perturbed graphs. In order to solve the given nonsmooth problem, we develop a first-order and projection-free algorithm based on generalized subdifferential calculus in the sense of Clarke and Goldstein, and establish global sublinear convergence rates for it. Finally, we report numerical experiments on benchmark instances showing that the proposed method efficiently detects large common cliques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05644v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Immanuel Bomze, Chiara Faccio, Francesco Rinaldi, Giovanni Spisso</dc:creator>
    </item>
    <item>
      <title>FormOpt: A FEniCSx toolbox for level set-based shape optimization supporting parallel computing</title>
      <link>https://arxiv.org/abs/2601.05709</link>
      <description>arXiv:2601.05709v1 Announce Type: new 
Abstract: This article presents the toolbox FormOpt for two- and three-dimensional shape optimization with parallel computing capabilities, built on the FEniCSx software framework. We introduce fundamental concepts of shape sensitivity analysis and their numerical applications, mainly for educational purposes, while also emphasizing computational efficiency via parallelism for practitioners. We adopt an optimize-then-discretize strategy based on the distributed shape derivative and its tensor representation, following the approach of \cite{MR3843884} and extending it in several directions. The numerical shape modeling relies on a level set method, whose evolution is driven by a descent direction computed from the shape derivative. Geometric constraints are treated accurately through a Proximal-Perturbed Lagrangian approach. FormOpt leverages the powerful features of FEniCSx, particularly its support for weak formulations of partial differential equations, diverse finite element types, and scalable parallelism. The implementation supports three different parallel computing modes: data parallelism, task parallelism, and a mixed mode. Data parallelism exploits FEniCSx's mesh partitioning features, and we implement a task parallelism mode which is useful for problems governed by a set of partial differential equations with varying parameters. The mixed mode conveniently combines both strategies to achieve efficient utilization of computational resources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05709v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Josu\'e D. D\'iaz-Avalos, Antoine Laurain</dc:creator>
    </item>
    <item>
      <title>Optimal velocity control of a Brinkman-Cahn-Hilliard system with curvature effects</title>
      <link>https://arxiv.org/abs/2601.05820</link>
      <description>arXiv:2601.05820v1 Announce Type: new 
Abstract: We address an optimal control problem governed by a system coupling a Brinkman-type momentum equation for the velocity field with a sixth-order Cahn-Hilliard equation for the phase variable, incorporating curvature effects in the free energy. The control acts as a distributed velocity control, allowing for the manipulation of the flow field and, consequently, the phase separation dynamics. We establish the existence of optimal controls, prove the Fr\'echet differentiability of the control-to-state operator, and derive first-order necessary optimality conditions in terms of a variational inequality involving the adjoint state variables. We also discuss the aspect of sparsity. Beyond its analytical novelty, this work provides a rigorous control framework for Brinkman-Cahn-Hilliard systems incorporating a curvature regularization, offering a foundation for applications in microfluidic design and controlled pattern formation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05820v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pierluigi Colli, Gianni Gilardi, Andrea Signori, J\"urgen Sprekels</dc:creator>
    </item>
    <item>
      <title>Viscous Approximation of Optimal Control Problems Governed by Rate-Independent Systems with Non-Convex Energies</title>
      <link>https://arxiv.org/abs/2601.05862</link>
      <description>arXiv:2601.05862v1 Announce Type: new 
Abstract: We consider an optimal control problem governed by a rate-inde\-pendent system with non-convex energy. The state equation is approximated by means of viscous regularization w.r.t.\ to hierarchy of two different Hilbert spaces. The regularized problem corresponds to an optimal control problem subject to a non-smooth ODE in Hilbert space, which is substantially easier to solve than the original optimal control problem. The convergence properties of the viscous regularization are investigated. It is shown that every sequence of globally optimal solutions of the viscous problems admits a (weakly) converging subsequence whose limit is a globally optimal solution of the original problem, provided that the latter admits at least one optimal solution with an optimal state that is continuous in time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05862v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Merlin Andreia, Christian Meyer</dc:creator>
    </item>
    <item>
      <title>Sequential Bayesian Optimal Experimental Design in Infinite Dimensions via Policy Gradient Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2601.05868</link>
      <description>arXiv:2601.05868v1 Announce Type: new 
Abstract: Sequential Bayesian optimal experimental design (SBOED) for PDE-governed inverse problems is computationally challenging, especially for infinite-dimensional random field parameters. High-fidelity approaches require repeated forward and adjoint PDE solves inside nested Bayesian inversion and design loops. We formulate SBOED as a finite-horizon Markov decision process and learn an amortized design policy via policy-gradient reinforcement learning (PGRL), enabling online design selection from the experiment history without repeatedly solving an SBOED optimization problem. To make policy training and reward evaluation scalable, we combine dual dimension reduction -- active subspace projection for the parameter and principal component analysis for the state -- with an adjusted derivative-informed latent attention neural operator (LANO) surrogate that predicts both the parameter-to-solution map and its Jacobian. We use a Laplace-based D-optimality reward while noting that, in general, other expected-information-gain utilities such as KL divergence can also be used within the same framework. We further introduce an eigenvalue-based evaluation strategy that uses prior samples as proxies for maximum a posteriori (MAP) points, avoiding repeated MAP solves while retaining accurate information-gain estimates. Numerical experiments on sequential multi-sensor placement for contaminant source tracking demonstrate approximately $100\times$ speedup over high-fidelity finite element methods, improved performance over random sensor placements, and physically interpretable policies that discover an ``upstream'' tracking strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05868v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kaichen Shen, Peng Chen</dc:creator>
    </item>
    <item>
      <title>Global Optimization for Combinatorial Geometry Problems</title>
      <link>https://arxiv.org/abs/2601.05943</link>
      <description>arXiv:2601.05943v1 Announce Type: new 
Abstract: Recent progress in LLM-driven algorithm discovery, exemplified by DeepMind's AlphaEvolve, has produced new best-known solutions for a range of hard geometric and combinatorial problems. This raises a natural question: to what extent can modern off-the-shelf global optimization solvers match such results when the problems are formulated directly as nonlinear optimization problems (NLPs)?
  We revisit a subset of problems from the AlphaEvolve benchmark suite and evaluate straightforward NLP formulations with two state-of-the-art solvers, the commercial FICO Xpress and the open-source SCIP. Without any solver modifications, both solvers reproduce, and in several cases improve upon, the best solutions previously reported in the literature, including the recent LLM-driven discoveries. Our results not only highlight the maturity of generic NLP technology and its ability to tackle nonlinear mathematical problems that were out of reach for general-purpose solvers only a decade ago, but also position global NLP solvers as powerful tools that may be exploited within LLM-driven algorithm discovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05943v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Timo Berthold, Dominik Kamp, Gioni Mexi, Sebastian Pokutta, Imre P\'olik</dc:creator>
    </item>
    <item>
      <title>Imitation Learning for Combinatorial Optimisation under Uncertainty</title>
      <link>https://arxiv.org/abs/2601.05383</link>
      <description>arXiv:2601.05383v1 Announce Type: cross 
Abstract: Imitation learning (IL) provides a data-driven framework for approximating policies for large-scale combinatorial optimisation problems formulated as sequential decision problems (SDPs), where exact solution methods are computationally intractable. A central but underexplored aspect of IL in this context is the role of the \emph{expert} that generates training demonstrations. Existing studies employ a wide range of expert constructions, yet lack a unifying framework to characterise their modelling assumptions, computational properties, and impact on learning performance.
  This paper introduces a systematic taxonomy of experts for IL in combinatorial optimisation under uncertainty. Experts are classified along three dimensions: (i) their treatment of uncertainty, including myopic, deterministic, full-information, two-stage stochastic, and multi-stage stochastic formulations; (ii) their level of optimality, distinguishing task-optimal and approximate experts; and (iii) their interaction mode with the learner, ranging from one-shot supervision to iterative, interactive schemes. Building on this taxonomy, we propose a generalised Dataset Aggregation (DAgger) algorithm that supports multiple expert queries, expert aggregation, and flexible interaction strategies.
  The proposed framework is evaluated on a dynamic physician-to-patient assignment problem with stochastic arrivals and capacity constraints. Computational experiments compare learning outcomes across expert types and interaction regimes. The results show that policies learned from stochastic experts consistently outperform those learned from deterministic or full-information experts, while interactive learning improves solution quality using fewer expert demonstrations. Aggregated deterministic experts provide an effective alternative when stochastic optimisation becomes computationally challenging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05383v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Prakash Gawas, Antoine Legrain, Louis-Martin Rousseau</dc:creator>
    </item>
    <item>
      <title>Data-Based Analysis of Relative Degree and Zero Dynamics in Linear Systems</title>
      <link>https://arxiv.org/abs/2601.05395</link>
      <description>arXiv:2601.05395v1 Announce Type: cross 
Abstract: Data-driven control offers a powerful alternative to traditional model-based methods, particularly when accurate system models are unavailable or prohibitively complex. While existing data-driven control methods primarily aim to construct controllers directly from measured data, our approach uses the available data to assess fundamental system-theoretic properties. This allows the informed selection of suitable control strategies without explicit model identification. We provide data-based conditions characterizing the (vector) relative degree and the stability of the zero dynamics, which are critical for ensuring proper performance of modern controllers. Our results cover both single- and multi-input/output settings of discrete-time linear systems. We further show how a continuous-time system can be reconstructed from three sampling discretizations obtained via Zero-order Hold at suitable sampling times, thus allowing the extension of the results to the combined data collected from these discretizations. All results can be applied directly to observed data sets using the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05395v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Janina Schaa, Thomas Berger</dc:creator>
    </item>
    <item>
      <title>A brief note on learning problem with global perspectives</title>
      <link>https://arxiv.org/abs/2601.05441</link>
      <description>arXiv:2601.05441v1 Announce Type: cross 
Abstract: This brief note considers the problem of learning with dynamic-optimizing principal-agent setting, in which the agents are allowed to have global perspectives about the learning process, i.e., the ability to view things according to their relative importances or in their true relations based-on some aggregated information shared by the principal. Whereas, the principal, which is exerting an influence on the learning process of the agents in the aggregation, is primarily tasked to solve a high-level optimization problem posed as an empirical-likelihood estimator under conditional moment restrictions model that also accounts information about the agents' predictive performances on out-of-samples as well as a set of private datasets available only to the principal. In particular, we present a coherent mathematical argument which is necessary for characterizing the learning process behind this abstract principal-agent learning framework, although we acknowledge that there are a few conceptual and theoretical issues still need to be addressed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05441v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Getachew K. Befekadu</dc:creator>
    </item>
    <item>
      <title>Discrete Homogeneity and Quantizer Design for Nonlinear Homogeneous Control Systems</title>
      <link>https://arxiv.org/abs/2601.05526</link>
      <description>arXiv:2601.05526v1 Announce Type: cross 
Abstract: This paper proposes a framework for analysis of generalized homogeneous control systems under state quantization. In particular, it addresses the challenge of maintaining finite/fixed-time stability of nonlinear systems in the presence of quantized measurements. To analyze the behavior of quantized control system, we introduce a new type of discrete homogeneity, where the dilation is defined by a discrete group. The converse Lyapunov function theorem is established for homogeneous systems with respect to discrete dilations. By extending the notion of sector-boundedness to a homogeneous vector space, we derive a generalized homogeneous sector-boundedness condition that guarantees finite/fixed-time stability of nonlinear control system under quantized measurements. A geometry-aware homogeneous static vector quantizer is then designed using generalized homogeneous coordinates, enabling an efficient quantization scheme. The resulting homogeneous control system with the proposed quantizer is proven to be homogeneous with respect to discrete dilation and globally finite-time, nearly fixed-time, or exponentially stable, depending on the homogeneity degree. Numerical examples validate the effectiveness of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05526v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Zhou, Andrey Polyakov, Gang Zheng, Masaaki Nagahara</dc:creator>
    </item>
    <item>
      <title>Buffered AUC maximization for scoring systems via mixed-integer optimization</title>
      <link>https://arxiv.org/abs/2601.05544</link>
      <description>arXiv:2601.05544v1 Announce Type: cross 
Abstract: A scoring system is a linear classifier composed of a small number of explanatory variables, each assigned a small integer coefficient. This system is highly interpretable and allows predictions to be made with simple manual calculations without the need for a calculator. Several previous studies have used mixed-integer optimization (MIO) techniques to develop scoring systems for binary classification; however, they have not focused on directly maximizing AUC (i.e., area under the receiver operating characteristic curve), even though AUC is recognized as an essential evaluation metric for scoring systems. Our goal herein is to establish an effective MIO framework for constructing scoring systems that directly maximize the buffered AUC (bAUC) as the tightest concave lower bound on AUC. Our optimization model is formulated as a mixed-integer linear optimization (MILO) problem that maximizes bAUC subject to a group sparsity constraint for limiting the number of questions in the scoring system. Computational experiments using publicly available real-world datasets demonstrate that our MILO method can build scoring systems with superior AUC values compared to the baseline methods based on regularization and stepwise regression. This research contributes to the advancement of MIO techniques for developing highly interpretable classification models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05544v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.AP</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Moe Shiina, Shunnosuke Ikeda, Yuichi Takano</dc:creator>
    </item>
    <item>
      <title>A Poincar\'e-Bendixson theorem for Bebutov shifts and applications to switched systems</title>
      <link>https://arxiv.org/abs/2601.05863</link>
      <description>arXiv:2601.05863v1 Announce Type: cross 
Abstract: We prove a version of the Poincar\'e-Bendixson theorem for certain classes of curves on the 2-sphere which are not required to be the trajectories of an underlying flow or semiflow on the sphere itself. Using this result we extend the Poincar\'e-Bendixson theorem to the context of continuous semiflows on compact subsets of the 2-sphere and the projective plane, give new sufficient conditions for the existence of periodic trajectories of certain low-dimensional affine control systems, and give a new criterion for the global uniform exponential stability of switched systems of homogeneous ODEs in dimension three. We prove in particular that periodic asymptotic stability implies global uniform exponential stability for real linear switched systems of dimension three and complex linear switched systems of dimension two. In combination with a recent result of the second author, this resolves a question of R. Shorten, F. Wirth, O. Mason, K. Wulff and C. King and resolves a natural analogue of the Lagarias-Wang finiteness conjecture in continuous time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05863v1</guid>
      <category>math.DS</category>
      <category>math.CA</category>
      <category>math.OC</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jairo Bochi, Ian D. Morris</dc:creator>
    </item>
    <item>
      <title>Manifold limit for the training of shallow graph convolutional neural networks</title>
      <link>https://arxiv.org/abs/2601.06025</link>
      <description>arXiv:2601.06025v1 Announce Type: cross 
Abstract: We study the discrete-to-continuum consistency of the training of shallow graph convolutional neural networks (GCNNs) on proximity graphs of sampled point clouds under a manifold assumption. Graph convolution is defined spectrally via the graph Laplacian, whose low-frequency spectrum approximates that of the Laplace-Beltrami operator of the underlying smooth manifold, and shallow GCNNs of possibly infinite width are linear functionals on the space of measures on the parameter space. From this functional-analytic perspective, graph signals are seen as spatial discretizations of functions on the manifold, which leads to a natural notion of training data consistent across graph resolutions. To enable convergence results, the continuum parameter space is chosen as a weakly compact product of unit balls, with Sobolev regularity imposed on the output weight and bias, but not on the convolutional parameter. The corresponding discrete parameter spaces inherit the corresponding spectral decay, and are additionally restricted by a frequency cutoff adapted to the informative spectral window of the graph Laplacians. Under these assumptions, we prove $\Gamma$-convergence of regularized empirical risk minimization functionals and corresponding convergence of their global minimizers, in the sense of weak convergence of the parameter measures and uniform convergence of the functions over compact sets. This provides a formalization of mesh and sample independence for the training of such networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06025v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johanna Tengler, Christoph Brune, Jos\'e A. Iglesias</dc:creator>
    </item>
    <item>
      <title>Improved Approximation Bounds for Moore-Penrose Inverses of Banded Matrices with Applications to Continuous-Time Linear Quadratic Control</title>
      <link>https://arxiv.org/abs/2411.04400</link>
      <description>arXiv:2411.04400v2 Announce Type: replace 
Abstract: We present improved approximation bounds for the Moore-Penrose inverses of banded matrices, where the bandedness is induced by a metric on the index set. We show that the pseudoinverse of a banded matrix can be approximated by another banded matrix, and the error of approximation is exponentially small in the ratio of the bandwidth of the approximation to that of the original matrix. An intuitive corollary can be obtained: the off-diagonal blocks of the pseudoinverse decay exponentially with the distance between the node sets associated with row and column indices, on the given metric space. Our bounds are expressed in terms of the bound of singular values of the system. For saddle point systems, commonly encountered in optimization, we provide the bounds of singular values associated under standard regularity conditions. Remarkably, our bounds improve previously reported ones and allow us to establish a perturbation bound for continuous-domain optimal control problems by analyzing the asymptotic limit of their finite difference discretization, which has been challenging with previously reported bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04400v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sungho Shin, Wallace Gian Yion Tan, Mihai Anitescu</dc:creator>
    </item>
    <item>
      <title>Gradient sampling algorithm for subsmooth functions</title>
      <link>https://arxiv.org/abs/2503.16638</link>
      <description>arXiv:2503.16638v2 Announce Type: replace 
Abstract: This paper considers non-smooth optimization problems where we seek to minimize the pointwise maximum of a continuously parameterized family of functions. Since the objective function is given as the solution to a maximization problem, neither its values nor its gradients are available in closed form, which calls for approximation. Our approach hinges upon extending the so-called gradient sampling algorithm, which approximates the Clarke generalized gradient of the objective function at a point by sampling its derivative at nearby locations. This allows us to select descent directions around points where the function may fail to be differentiable and establish algorithm convergence to a stationary point from any initial condition. Our key contribution is to prove this convergence by alleviating the requirement on continuous differentiability of the objective function on an open set of full measure. We further provide assumptions under which a desired convex subset of the decision space is rendered attractive for the iterates of the algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16638v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dimitris Boskos, Jorge Cort\'es, Sonia Mart\'inez</dc:creator>
    </item>
    <item>
      <title>Penalty decomposition derivative free method for the minimization of partially separable functions over a convex feasible set</title>
      <link>https://arxiv.org/abs/2503.21631</link>
      <description>arXiv:2503.21631v3 Announce Type: replace 
Abstract: In this paper, we consider the problem of minimizing a smooth function, given as finite sum of black-box functions, over a convex set. In order to advantageously exploit the structure of the problem, for instance when the terms of the objective functions are partially separable, noisy, costly or with first-order information partially accessible, we propose a framework where the penalty decomposition approach is combined with a derivative-free line-search-based method. Under standard assumptions, we state theoretical results showing that the proposed algorithm is well-defined and globally convergent to stationary points. The results of preliminary numerical experiments, performed on test problems with number of variables up to thousands, show the validity of the proposed method w.r.t. state of the art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21631v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francesco Cecere, Matteo Lapucci, Davide Pucci, Marco Sciandrone</dc:creator>
    </item>
    <item>
      <title>On the complexity of proximal gradient and proximal gradient-Newton-CG methods for \(\ell_1\)-regularized Optimization</title>
      <link>https://arxiv.org/abs/2504.15752</link>
      <description>arXiv:2504.15752v2 Announce Type: replace 
Abstract: In this paper, we propose two second-order methods for solving the \(\ell_1\)-regularized composite optimization problem, which are developed based on two distinct definitions of approximate second-order stationary points. We introduce a hybrid proximal gradient and negative curvature method, as well as an adaptive hybrid proximal gradient-Newton-CG method with negative curvature directions, to find a strong* approximate second-order stationary point and a weak approximate second-order stationary point for \(\ell_1\)-regularized optimization problems, respectively. Comprehensive analyses are provided regarding the iteration complexity, computational complexity, and the local superlinear convergence rates of the first phases of these two methods under specific error bound conditions. We demonstrate that the proximal gradient-Newton-CG method achieves the best-known iteration complexity for attaining the proposed weak approximate second-order stationary point, which is consistent with the results for finding an approximate second-order stationary point in unconstrained optimization. Through a toy example, we show that our proposed methods can effectively escape the first-order approximate solution. Numerical experiments implemented on the \(\ell_1\)-regularized Student's t-regression problem validate the effectiveness of both methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15752v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hong Zhu</dc:creator>
    </item>
    <item>
      <title>Convex Trajectory Optimization via Monomial Coordinates Transcription for Cislunar Rendezvous</title>
      <link>https://arxiv.org/abs/2505.07521</link>
      <description>arXiv:2505.07521v2 Announce Type: replace 
Abstract: This paper proposes a nonlinear guidance algorithm for fuel-optimal impulsive trajectories for rendezvous operations close to a reference orbit. The approach involves overparameterized monomial coordinates and a high-order approximation of the dynamic flow precomputed using differential algebra, which eliminates the need for real-time integration. To address non-convexity in the monomial coordinate formulation of the guidance problem, sequential convex programming is applied. Using the methodology presented in this paper, repeatedly evaluating the nonlinear dynamics is not necessary, as in shooting or collocation methods. Instead, only the monomial equations require updating between iterations, drastically reducing computational burden. The proposed algorithm is tested in the circular restricted three-body problem framework with the target spacecraft on a near-rectilinear halo orbit. The results demonstrate stability, efficiency, and low computational demand while achieving minimal terminal guidance errors. Compared to linear methods, this nonlinear convex approach exhibits superior performance in open-loop propagation of impulsive maneuvers in cislunar space, particularly in terms of accuracy. These advantages make the algorithm an attractive candidate for autonomous onboard guidance for rendezvous operations in the cislunar domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07521v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Omar Regantini, Ethan R. Burnett, Antonio Rizza, Alessandro Morselli, Francesco Topputo</dc:creator>
    </item>
    <item>
      <title>The factorization of matrices into products of positive definite factors</title>
      <link>https://arxiv.org/abs/2507.12560</link>
      <description>arXiv:2507.12560v2 Announce Type: replace 
Abstract: Positive-definite matrices materialize as state transition matrices of linear time-invariant gradient flows, and the composition of such materializes as the state transition after successive steps where the driving potential is suitably adjusted. Thus, factoring an arbitrary matrix (with positive determinant) into a product of positive-definite ones provides the needed schedule for a time-varying potential to have a desired effect. The present work provides a detailed analysis of this factorization problem by lifting it into a sequence of Monge-Kantorovich transportation steps on Gaussian distributions and studying the induced holonomy of the optimal transportation problem. From this vantage point we determine the minimal number of positive-definite factors that have a desired effect on the spectrum of the product, e.g., ensure specified eigenvalues or being a rotation matrix. Our approach is computational and allows to identify the needed number of factors as well as trade off their conditioning number with their actual number.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12560v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <category>math.NA</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mahmoud Abdelgalil, Tryphon T. Georgiou</dc:creator>
    </item>
    <item>
      <title>Policy Optimization in the Linear Quadratic Gaussian Problem: A Frequency Domain Perspective</title>
      <link>https://arxiv.org/abs/2508.17252</link>
      <description>arXiv:2508.17252v3 Announce Type: replace 
Abstract: The Linear Quadratic Gaussian (LQG) problem is a classic and widely studied model in optimal control, providing a fundamental framework for designing controllers for linear systems subject to process and observation noises. In recent years, researchers have increasingly focused on directly parameterizing dynamic controllers and optimizing the LQG cost over the resulting parameterized set. However, this parameterization typically gives rise to a highly non-convex optimization landscape for the resulting parameterized LQG problem. To our knowledge, there is currently no general method for certifying the global optimality of candidate controller parameters in this setting. In this work, we address these gaps with the following contributions. First, we derive a necessary and sufficient condition for the global optimality of stationary points in a parameterized LQG problems. This condition reduces the verification of optimality to a test of the controllability and observability for a novel, specially constructed transfer function, yielding a precise and computationally tractable certificate. Furthermore, our condition provides a rigorous explanation for why traditional parameterizations can lead to suboptimal stationary points. Second, we elevate the controller parameter space from conventional finite-dimensional settings to the infinite-dimensional $\mathcal{RH}_\infty$ space and develop a gradient-based algorithm in this setting, for which we provide a theoretical analysis establishing global convergence. Finally, representative numerical experiments validate the theoretical findings and demonstrate the practical viability of the proposed approach. Additionally, the appendix section explores a data-driven extension to the model-free setting, where we outline a parameter estimation scheme and demonstrate its practical viability through numerical simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17252v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoran Li, Xun Li, Yuan-Hua Ni, Xuebo Zhang</dc:creator>
    </item>
    <item>
      <title>Efficient Quantification of Time-Series Prediction Error: Optimal Selection Conformal Prediction</title>
      <link>https://arxiv.org/abs/2511.02103</link>
      <description>arXiv:2511.02103v3 Announce Type: replace 
Abstract: Uncertainty is almost ubiquitous in safety-critical autonomous systems due to dynamic environments and the integration of learning-based components. Quantifying this uncertainty--particularly for time-series predictions in multi-stage optimization--is essential for safe control and verification tasks. Conformal Prediction (CP) is a distribution-free uncertainty quantification tool with rigorous finite-sample guarantees, but its performance relies on the design of the nonconformity measure, which remains challenging for time-series data. Existing methods either overfit on small datasets, or are computationally intensive on long-time-horizon problems and/or large datasets. To overcome these issues, we propose a new parameterization of the score functions and formulate an optimization program to compute the associated parameters. The optimal parameters directly lead to norm-ball regions that constitute minimal-average-radius conformal sets. We then provide a reformulation of the underlying optimization program to enable faster computation. We provide theoretical proofs on both the validity and efficiency of predictors constructed based on the proposed approach. Numerical results on various case studies demonstrate that our method outperforms state-of-the-art methods in terms of efficiency, with much lower computational requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02103v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Boyu Pang, Kostas Margellos</dc:creator>
    </item>
    <item>
      <title>Finite horizon stochastic $H_2/H_\infty$ control for continuous-time mean-field systems with Poisson jumps</title>
      <link>https://arxiv.org/abs/2512.01000</link>
      <description>arXiv:2512.01000v5 Announce Type: replace 
Abstract: The stochastic $H_2/H_\infty$ control problem for continuous-time mean-field stochastic differential equations with Poisson jumps over finite horizon is investigated in this paper. Continuous and jump diffusion terms in the system depend not only on the state but also on the control input, external disturbance, and mean-field components. By employing the quasi-linear technique and the method of completing the square, a mean-field stochastic jump bounded real lemma of the system is derived, which plays a crucial role in solving stochastic $H_2/H_\infty$ control problem. It is demonstrated in this study that the feasibility of the stochastic $H_2/H_\infty$ control problem is equivalent to the solvability of four sets of cross-coupled generalized differential Riccati equations, thus generalizing the previous results to mean-field jump-diffusion systems. To validate the proposed methodology, a numerical simulation example is provided to illustrate the effectiveness of the control strategy. The results establish a systematic approach for designing $H_2/H_\infty$ controllers that simultaneously guarantee the robustness against disturbances and optimal performance for interacting particle systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01000v5</guid>
      <category>math.OC</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huimin Han, Shaolin Ji, Weihai Zhang</dc:creator>
    </item>
    <item>
      <title>Communication-Efficient Stochastic Distributed Learning</title>
      <link>https://arxiv.org/abs/2501.13516</link>
      <description>arXiv:2501.13516v2 Announce Type: replace-cross 
Abstract: We address distributed learning problems, both nonconvex and convex, over undirected networks. In particular, we design a novel algorithm based on the distributed Alternating Direction Method of Multipliers (ADMM) to address the challenges of high communication costs, and large datasets. Our design tackles these challenges i) by enabling the agents to perform multiple local training steps between each round of communications; and ii) by allowing the agents to employ stochastic gradients while carrying out local computations. We show that the proposed algorithm converges to a neighborhood of a stationary point, for nonconvex problems, and of an optimal point, for convex problems. We also propose a variant of the algorithm to incorporate variance reduction thus achieving exact convergence. We show that the resulting algorithm indeed converges to a stationary (or optimal) point, and moreover that local training accelerates convergence. We thoroughly compare the proposed algorithms with the state of the art, both theoretically and through numerical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13516v2</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoxing Ren, Nicola Bastianello, Karl H. Johansson, Thomas Parisini</dc:creator>
    </item>
    <item>
      <title>Variance Reduction Methods Do Not Need to Compute Full Gradients: Improved Efficiency through Shuffling</title>
      <link>https://arxiv.org/abs/2502.14648</link>
      <description>arXiv:2502.14648v2 Announce Type: replace-cross 
Abstract: Stochastic optimization algorithms are widely used for machine learning with large-scale data. However, their convergence often suffers from non-vanishing variance. Variance Reduction (VR) methods, such as SVRG and SARAH, address this issue but introduce a bottleneck by requiring periodic full gradient computations. In this paper, we explore popular VR techniques and propose an approach that eliminates the necessity for expensive full gradient calculations. To avoid these computations and make our approach memory-efficient, we employ two key techniques: the shuffling heuristic and the concept of SAG/SAGA methods. For non-convex objectives, our convergence rates match those of standard shuffling methods, while under strong convexity, they demonstrate an improvement. We empirically validate the efficiency of our approach and demonstrate its scalability on large-scale machine learning tasks including image classification problem on CIFAR-10 and CIFAR-100 datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14648v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniil Medyakov, Gleb Molodtsov, Savelii Chezhegov, Alexey Rebrikov, Aleksandr Beznosikov</dc:creator>
    </item>
    <item>
      <title>GPU-based complete search for nonlinear minimization subject to bounds</title>
      <link>https://arxiv.org/abs/2507.01770</link>
      <description>arXiv:2507.01770v3 Announce Type: replace-cross 
Abstract: This paper introduces a GPU-based complete search method to enclose the global minimum of a nonlinear function subject to simple bounds on the variables. Using interval analysis, coupled with the computational power and architecture of GPU, the method iteratively rules out the regions in the search domain where the global minimum cannot exist and leaves a finite set of regions where the global minimum must exist. For effectiveness, because of the rigor of interval analysis, the method is guaranteed to enclose the global minimum of the nonlinear function even in the presence of rounding errors. For efficiency, the method employs a novel GPU-based single program, single data parallel programming style to circumvent major GPU performance bottlenecks, and a variable cycling technique is also integrated into the method to reduce computational cost when minimizing large-scale nonlinear functions. The method is validated by minimizing 10 multimodal benchmark test functions with scalable dimensions, including the well-known Ackley function, Griewank function, Levy function, and Rastrigin function. These benchmark test functions represent grand challenges of global optimization, and enclosing the guaranteed global minimum of these benchmark test functions with more than 80 dimensions has not been reported in the literature. Our method completely searches the feasible domain and successfully encloses the guaranteed global minimum of these 10 benchmark test functions with up to 10,000 dimensions using only one GPU in a reasonable computation time, far exceeding the reported results in the literature due to the unique method design and implementation based on GPU architecture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01770v3</guid>
      <category>math.NA</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Guanglu Zhang, Qihang Shan, Jonathan Cagan</dc:creator>
    </item>
  </channel>
</rss>
