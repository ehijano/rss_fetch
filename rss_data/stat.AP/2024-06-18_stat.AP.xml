<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 19 Jun 2024 04:01:21 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 19 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Identifying Genetic Variants for Obesity Incorporating Prior Insights: Quantile Regression with Insight Fusion for Ultra-high Dimensional Data</title>
      <link>https://arxiv.org/abs/2406.12212</link>
      <description>arXiv:2406.12212v1 Announce Type: new 
Abstract: Obesity is widely recognized as a critical and pervasive health concern. We strive to identify important genetic risk factors from hundreds of thousands of single nucleotide polymorphisms (SNPs) for obesity. We propose and apply a novel Quantile Regression with Insight Fusion (QRIF) approach that can integrate insights from established studies or domain knowledge to simultaneously select variables and modeling for ultra-high dimensional genetic data, focusing on high conditional quantiles of body mass index (BMI) that are of most interest. We discover interesting new SNPs and shed new light on a comprehensive view of the underlying genetic risk factors for different levels of BMI. This may potentially pave the way for more precise and targeted treatment strategies. The QRIF approach intends to balance the trade-off between the prior insights and the observed data while being robust to potential false information. We further establish the desirable asymptotic properties under the challenging non-differentiable check loss functions via Huber loss approximation and nonconvex SCAD penalty via local linear approximation. Finally, we develop an efficient algorithm for the QRIF approach. Our simulation studies further demonstrate its effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12212v1</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiantong Wang, Heng Lian, Yan Yu, Heping Zhang</dc:creator>
    </item>
    <item>
      <title>A Review of EMA Public Assessment Reports where Non-Proportional Hazards were Identified</title>
      <link>https://arxiv.org/abs/2406.12492</link>
      <description>arXiv:2406.12492v1 Announce Type: new 
Abstract: While well-established methods for time-to-event data are available when the proportional hazards assumption holds, there is no consensus on the best approach under non-proportional hazards. A wide range of parametric and non-parametric methods for testing and estimation in this scenario have been proposed. In this review we identified EMA marketing authorization procedures where non-proportional hazards were raised as a potential issue in the risk-benefit assessment and extract relevant information on trial design and results reported in the corresponding European Assessment Reports (EPARs) available in the database at paediatricdata.eu.
  We identified 16 Marketing authorization procedures, reporting results on a total of 18 trials. Most procedures covered the authorization of treatments from the oncology domain. For the majority of trials NPH issues were related to a suspected delayed treatment effect, or different treatment effects in known subgroups. Issues related to censoring, or treatment switching were also identified. For most of the trials the primary analysis was performed using conventional methods assuming proportional hazards, even if NPH was anticipated. Differential treatment effects were addressed using stratification and delayed treatment effect considered for sample size planning. Even though, not considered in the primary analysis, some procedures reported extensive sensitivity analyses and model diagnostics evaluating the proportional hazards assumption. For a few procedures methods addressing NPH (e.g.~weighted log-rank tests) were used in the primary analysis. We extracted estimates of the median survival, hazard ratios, and time of survival curve separation. In addition, we digitized the KM curves to reconstruct close to individual patient level data. Extracted outcomes served as the basis for a simulation study of methods for time to event analysis under NPH.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12492v1</guid>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Florian Klinglmueller, Norbert Benda, Tim Friede, Tobias Fellinger, Harald Heinzl, Andrew Hooker, Franz Koenig, Tim Mathes, Martin Posch, Florian Stampfer, Susanne Urach</dc:creator>
    </item>
    <item>
      <title>The Modified Combo i3+3 Design for Novel-Novel Combination Dose-Finding Trials in Oncology</title>
      <link>https://arxiv.org/abs/2406.12666</link>
      <description>arXiv:2406.12666v1 Announce Type: new 
Abstract: We consider a modified Ci3+3 (MCi3+3) design for dual-agent dose-finding trials in which both agents are tested on multiple doses. This usually happens when the agents are novel therapies. The MCi3+3 design offers a two-stage or three-stage version, depending on the practical need. The first stage begins with single-agent dose escalation, the second stage launches a model-free combination dose finding for both agents, and optionally, the third stage follows with a model-based design. MCi3+3 aims to maintain a relatively simple framework to facilitate practical application, while also address challenges that are unique to novel-novel combination dose finding. Through simulations, we demonstrate that the MCi3+3 design adeptly manages various toxicity scenarios. It exhibits operational characteristics on par with other combination designs, while offering an enhanced safety profile. The design is motivated and tested for a real-life clinical trial.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12666v1</guid>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiaxin Liu, Shijie Yuan, Qiqi Deng, Yuan Ji</dc:creator>
    </item>
    <item>
      <title>Detecting Outbreaks Using a Latent Field: Part I -- Spatial Modeling</title>
      <link>https://arxiv.org/abs/2406.12810</link>
      <description>arXiv:2406.12810v1 Announce Type: new 
Abstract: In this paper, we develop a method to estimate the infection-rate of a disease, over a region, as a field that varies in space and time. To do so, we use time-series of case-counts of symptomatic patients as observed in the areal units that comprise the region. We also extend an epidemiological model, initially developed to represent the temporal dynamics in a single areal unit, to encompass multiple areal units. This is done using a (parameterized) Gaussian random field, whose structure is modeled using the dynamics in the case-counts, and which serves as a spatial prior, in the estimation process. The estimation is performed using an adaptive Markov chain Monte Carlo method, using COVID-19 case-count data collected from three adjacent counties in New Mexico, USA. We find that we can estimate both the temporal and spatial variation of the infection with sufficient accuracy to be useful in forecasting. Further, the ability to "borrow" information from neighboring areal units allows us to regularize the estimation in areal units with high variance ("poor quality") data. The ability to forecast allows us to check whether the estimated infection-rate can be used to detect a change in the epidemiological dynamics e.g., the arrival of a new wave of infection, such as the fall wave of 2020 which arrived in New Mexico in mid-September 2020. We fashion a simple anomaly detector, conditioned on the estimated infection-rate and find that it performs better than a conventional surveillance algorithm that uses case-counts (and not the infection-rate) to detect the arrival of the same wave.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12810v1</guid>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cosmin Safta, Wyatt Bridgman, Jaideep Ray</dc:creator>
    </item>
    <item>
      <title>Clustering functional data with measurement errors: a simulation-based approach</title>
      <link>https://arxiv.org/abs/2406.11942</link>
      <description>arXiv:2406.11942v1 Announce Type: cross 
Abstract: Clustering analysis of functional data, which comprises observations that evolve continuously over time or space, has gained increasing attention across various scientific disciplines. Practical applications often involve functional data that are contaminated with measurement errors arising from imprecise instruments, sampling errors, or other sources. These errors can significantly distort the inherent data structure, resulting in erroneous clustering outcomes. In this paper, we propose a simulation-based approach designed to mitigate the impact of measurement errors. Our proposed method estimates the distribution of functional measurement errors through repeated measurements. Subsequently, the clustering algorithm is applied to simulated data generated from the conditional distribution of the unobserved true functional data given the observed contaminated functional data, accounting for the adjustments made to rectify measurement errors. We illustrate through simulations show that the proposed method has improved numerical performance than the naive methods that neglect such errors. Our proposed method was applied to a childhood obesity study, giving more reliable clustering results</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.11942v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tingyu Zhu, Lan Xue, Carmen Tekwe, Keith Diaz, Mark Benden, Roger Zoh</dc:creator>
    </item>
    <item>
      <title>Mixed-resolution hybrid modeling in an element-based framework</title>
      <link>https://arxiv.org/abs/2406.12028</link>
      <description>arXiv:2406.12028v1 Announce Type: cross 
Abstract: Computational modeling of a complex system is limited by the parts of the system with the least information. While detailed models and high-resolution data may be available for parts of a system, abstract relationships are often necessary to connect the parts and model the full system. For example, modeling food security necessitates the interaction of climate and socioeconomic factors, with models of system components existing at different levels of information in terms of granularity and resolution. Connecting these models is an ongoing challenge. In this work, we demonstrate methodology to quantize and integrate information from data and detailed component models alongside abstract relationships in a hybrid element-based modeling and simulation framework. In a case study of modeling food security, we apply quantization methods to generate (1) time-series model input from climate data and (2) a discrete representation of a component model (a statistical emulator of crop yield), which we then incorporate as an update rule in the hybrid element-based model, bridging differences in model granularity and resolution. Simulation of the hybrid element-based model recapitulated the trends of the original emulator, supporting the use of this methodology to integrate data and information from component models to simulate complex systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12028v1</guid>
      <category>stat.ME</category>
      <category>cs.SI</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kara Bocan, Natasa Miskov-Zivanov</dc:creator>
    </item>
    <item>
      <title>Model Selection for Causal Modeling in Missing Exposure Problems</title>
      <link>https://arxiv.org/abs/2406.12171</link>
      <description>arXiv:2406.12171v1 Announce Type: cross 
Abstract: In causal inference, properly selecting the propensity score (PS) model is a popular topic and has been widely investigated in observational studies. In addition, there is a large literature concerning the missing data problem. However, there are very few studies investigating the model selection issue for causal inference when the exposure is missing at random (MAR). In this paper, we discuss how to select both imputation and PS models, which can result in the smallest RMSE of the estimated causal effect. Then, we provide a new criterion, called the ``rank score" for evaluating the overall performance of both models. The simulation studies show that the full imputation plus the outcome-related PS models lead to the smallest RMSE and the rank score can also pick the best models. An application study is conducted to study the causal effect of CVD on the mortality of COVID-19 patients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12171v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuliang Shi, Yeying Zhu, Joel A. Dubin</dc:creator>
    </item>
    <item>
      <title>Lasso regularization for mixture experiments with noise variables</title>
      <link>https://arxiv.org/abs/2406.12237</link>
      <description>arXiv:2406.12237v1 Announce Type: cross 
Abstract: We apply classical and Bayesian lasso regularizations to a family of models with the presence of mixture and process variables. We analyse the performance of these estimates with respect to ordinary least squares estimators by a simulation study and a real data application. Our results demonstrate the superior performance of Bayesian lasso, particularly via coordinate ascent variational inference, in terms of variable selection accuracy and response optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12237v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Manuel Gonz\'alez-Navarrete, Fabi\'an Manr\'iquez-M\'endez, Manuel Pereira-Barahona</dc:creator>
    </item>
    <item>
      <title>Anatomy of Elite and Mass Polarization in Social Networks</title>
      <link>https://arxiv.org/abs/2406.12525</link>
      <description>arXiv:2406.12525v1 Announce Type: cross 
Abstract: Existing methods for quantifying polarization in social networks typically report a single value describing the amount of polarization in a social system. While this approach can be used to confirm the observation that many societies have witnessed an increase in political polarization in recent years, it misses the complexities that could be used to understand the reasons behind this phenomenon. Notably, opposing groups can have unequal impact on polarization, and the elites are often understood to be more divided than the masses, making it critical to differentiate their roles in polarized systems. We propose a method to characterize these distinct hierarchies in polarized networks, enabling separate polarization measurements for these groups within a single social system. Applied to polarized topics in the Finnish Twittersphere surrounding the 2019 and 2023 parliamentary elections, our analysis reveals valuable insights: 1) The impact of opposing groups on observed polarization is rarely balanced, and 2) while the elite strongly contributes to structural polarization and consistently display greater alignment across various topics, the masses have also recently experienced a surge in issue alignment, a special form of polarization. Our findings suggest that the masses may not be as immune to an increasingly polarized environment as previously thought.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12525v1</guid>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ali Salloum, Ted Hsuan Yun Chen, Mikko Kivel\"a</dc:creator>
    </item>
    <item>
      <title>Spatial von-Mises Fisher Regression for Directional Data</title>
      <link>https://arxiv.org/abs/2207.08321</link>
      <description>arXiv:2207.08321v3 Announce Type: replace 
Abstract: Spatially varying directional data are routinely observed in several modern applications such as meteorology, biology, geophysics, and engineering, etc. However, only a few approaches are available for covariate-dependent statistical analysis for such data. To address this gap, we propose a novel generalized linear model to analyze such that using a von Mises Fisher (vMF) distributed error structure. Using a novel link function that relies on the transformation between Cartesian and spherical coordinates, we regress the vMF-distributed directional data on the external covariates. This regression model enables us to quantify the impact of external factors on the observed directional data. Furthermore, we impose the spatial dependence using an autoregressive model, appropriately accounting for the directional dependence in the outcome. This novel specification renders computational efficiency and flexibility. In addition, a comprehensive Bayesian inferential toolbox is thoroughly developed and applied to our analysis. Subsequently, employing our regression model to the Alzheimer's Disease Neuroimaging Initiative (ADNI) data, we gain new insights into the relationship between cognitive impairment and the orientations of brain fibers along with examining empirical efficacy through simulation experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.08321v3</guid>
      <category>stat.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhou Lan, Arkaprava Roy</dc:creator>
    </item>
    <item>
      <title>SUrvival Control Chart EStimation Software in R: the success package</title>
      <link>https://arxiv.org/abs/2302.07658</link>
      <description>arXiv:2302.07658v2 Announce Type: replace 
Abstract: Monitoring the quality of statistical processes has been of great importance, mostly in industrial applications. Control charts are widely used for this purpose, but often lack the possibility to monitor survival outcomes. Recently, inspecting survival outcomes has become of interest, especially in medical settings where outcomes often depend on risk factors of patients. For this reason many new survival control charts have been devised and existing ones have been extended to incorporate survival outcomes. The R package success allows users to construct risk-adjusted control charts for survival data. Functions to determine control chart parameters are included, which can be used even without expert knowledge on the subject of control charts. The package allows to create static as well as interactive charts, which are built using ggplot2 (Wickham 2016) and plotly (Sievert 2020).</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.07658v2</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Gomon, Marta Fiocco, Hein Putter, Mirko Signorelli</dc:creator>
    </item>
    <item>
      <title>Statistical significance revisited</title>
      <link>https://arxiv.org/abs/2104.00262</link>
      <description>arXiv:2104.00262v3 Announce Type: replace-cross 
Abstract: Statistical significance measures the reliability of a result obtained from a random experiment. We investigate the number of repetitions needed for a statistical result to have a certain significance. In the first step, we consider binomially distributed variables in the example of medication testing with fixed placebo efficacy, asking how many experiments are needed in order to achieve a significance of 95 %. In the next step, we take the probability distribution of the placebo efficacy into account, which to the best of our knowledge has not been done so far. Depending on the specifics, we show that in order to obtain identical significance, it may be necessary to perform twice as many experiments than in a setting where the placebo distribution is neglected. We proceed by considering more general probability distributions and close with comments on some erroneous assumptions on probability distributions which lead, for instance, to a trivial explanation of the fat tail.</description>
      <guid isPermaLink="false">oai:arXiv.org:2104.00262v3</guid>
      <category>stat.ME</category>
      <category>q-fin.ST</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.20944/preprints202103.0398.v1</arxiv:DOI>
      <dc:creator>Maike Torm\"ahlen, Galiya Klinkova, Michael Grabinski</dc:creator>
    </item>
    <item>
      <title>Bayesian Networks and Machine Learning for COVID-19 Severity Explanation and Demographic Symptom Classification</title>
      <link>https://arxiv.org/abs/2406.10807</link>
      <description>arXiv:2406.10807v2 Announce Type: replace-cross 
Abstract: With the prevailing efforts to combat the coronavirus disease 2019 (COVID-19) pandemic, there are still uncertainties that are yet to be discovered about its spread, future impact, and resurgence. In this paper, we present a three-stage data-driven approach to distill the hidden information about COVID-19. The first stage employs a Bayesian network structure learning method to identify the causal relationships among COVID-19 symptoms and their intrinsic demographic variables. As a second stage, the output from the Bayesian network structure learning, serves as a useful guide to train an unsupervised machine learning (ML) algorithm that uncovers the similarities in patients' symptoms through clustering. The final stage then leverages the labels obtained from clustering to train a demographic symptom identification (DSID) model which predicts a patient's symptom class and the corresponding demographic probability distribution. We applied our method on the COVID-19 dataset obtained from the Centers for Disease Control and Prevention (CDC) in the United States. Results from the experiments show a testing accuracy of 99.99%, as against the 41.15% accuracy of a heuristic ML method. This strongly reveals the viability of our Bayesian network and ML approach in understanding the relationship between the virus symptoms, and providing insights on patients' stratification towards reducing the severity of the virus.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10807v2</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Oluwaseun T. Ajayi, Yu Cheng</dc:creator>
    </item>
  </channel>
</rss>
