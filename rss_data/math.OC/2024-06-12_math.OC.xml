<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 13 Jun 2024 01:46:42 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 12 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Optimal control for a SIR model with limited hospitalised patients</title>
      <link>https://arxiv.org/abs/2406.06770</link>
      <description>arXiv:2406.06770v1 Announce Type: new 
Abstract: This paper analyses the optimal control of infectious disease propagation using a classic susceptible-infected-recovered (SIR) model characterised by permanent immunity and the absence of available vaccines. The control is performed over a time-dependent mean reproduction number, in order to minimise the cumulative number of ever-infected individuals (recovered), under different constraints. We consider constraints on isolation measures ranging from partial lockdown to non-intervention, as well as the social and economic costs associated with such isolation, and the capacity limitations of intensive care units that limits the number of infected individuals to a maximum allowed value. We rigorously derive an optimal quarantine strategy based on necessary optimality conditions. The obtained optimal strategy is of a boundary-bang type, comprising three phases: an initial phase with no intervention, a second phase maintaining the infected population at its maximum possible value, and a final phase of partial lockdown applied over a single interval. The optimal policy is further refined by optimising the transition times between these phases. We show that these results are in excellent agreement with the numerical solution of the problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06770v1</guid>
      <category>math.OC</category>
      <category>physics.soc-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Roc\'io Balderrama, Mariana In\'es Prieto, Constanza S\'anchez de la Vega, Federico Vazquez</dc:creator>
    </item>
    <item>
      <title>Stochastic Frank-Wolfe: Unified Analysis and Zoo of Special Cases</title>
      <link>https://arxiv.org/abs/2406.06788</link>
      <description>arXiv:2406.06788v1 Announce Type: new 
Abstract: The Conditional Gradient (or Frank-Wolfe) method is one of the most well-known methods for solving constrained optimization problems appearing in various machine learning tasks. The simplicity of iteration and applicability to many practical problems helped the method to gain popularity in the community. In recent years, the Frank-Wolfe algorithm received many different extensions, including stochastic modifications with variance reduction and coordinate sampling for training of huge models or distributed variants for big data problems. In this paper, we present a unified convergence analysis of the Stochastic Frank-Wolfe method that covers a large number of particular practical cases that may have completely different nature of stochasticity, intuitions and application areas. Our analysis is based on a key parametric assumption on the variance of the stochastic gradients. But unlike most works on unified analysis of other methods, such as SGD, we do not assume an unbiasedness of the real gradient estimation. We conduct analysis for convex and non-convex problems due to the popularity of both cases in machine learning. With this general theoretical framework, we not only cover rates of many known methods, but also develop numerous new methods. This shows the flexibility of our approach in developing new algorithms based on the Conditional Gradient approach. We also demonstrate the properties of the new methods through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06788v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruslan Nazykov, Aleksandr Shestakov, Vladimir Solodkin, Aleksandr Beznosikov, Gauthier Gidel, Alexander Gasnikov</dc:creator>
    </item>
    <item>
      <title>Modified Legendre-Gauss Collocation Method for Solving Optimal Control Problems with Nonsmooth Solutions</title>
      <link>https://arxiv.org/abs/2406.06824</link>
      <description>arXiv:2406.06824v1 Announce Type: new 
Abstract: A modified form of Legendre-Gauss orthogonal direct collocation is developed for solving optimal control problems whose solutions are nonsmooth due to control discontinuities. This new method adds switch-time variables, control variables, and collocation conditions at both endpoints of a mesh interval, whereas these new variables and collocation conditions are not included in standard Legendre-Gauss orthogonal collocation. The modified Legendre-Gauss collocation method alters the search space of the resulting nonlinear programming problem and enables determining accurately the location of the nonsmoothness in the optimal control. The transformed adjoint system of the modified Legendre-Gauss collocation method is then derived and shown to satisfy a discrete form of the continuous variational necessary conditions for optimality. The method is motivated via a control-constrained triple-integrator minimum-time optimal control problem where the solution possesses a two-switch bang-bang optimal control structure. In addition, the method developed in this paper is compared with existing Gaussian quadrature collocation methods. The method developed in this paper is shown to be capable of accurately solving optimal control problems with a discontinuous optimal control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06824v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriela Abadia-Doyle, Anil V. Rao</dc:creator>
    </item>
    <item>
      <title>Design and Scheduling of an AI-based Queueing System</title>
      <link>https://arxiv.org/abs/2406.06855</link>
      <description>arXiv:2406.06855v1 Announce Type: new 
Abstract: To leverage prediction models to make optimal scheduling decisions in service systems, we must understand how predictive errors impact congestion due to externalities on the delay of other jobs. Motivated by applications where prediction models interact with human servers (e.g., content moderation), we consider a large queueing system comprising of many single server queues where the class of a job is estimated using a prediction model. By characterizing the impact of mispredictions on congestion cost in heavy traffic, we design an index-based policy that incorporates the predicted class information in a near-optimal manner. Our theoretical results guide the design of predictive models by providing a simple model selection procedure with downstream queueing performance as a central concern, and offer novel insights on how to design queueing systems with AI-based triage. We illustrate our framework on a content moderation task based on real online comments, where we construct toxicity classifiers by finetuning large language models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06855v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiung Lee, Hongseok Namkoong, Yibo Zeng</dc:creator>
    </item>
    <item>
      <title>A Characterization for Tightness of the Sparse Moment-SOS Hierarchy</title>
      <link>https://arxiv.org/abs/2406.06882</link>
      <description>arXiv:2406.06882v1 Announce Type: new 
Abstract: This paper studies the sparse Moment-SOS hierarchy of relaxations for solving sparse polynomial optimization problems. We show that this sparse hierarchy is tight if and only if the objective can be written as a sum of sparse nonnegative polynomials, each of which belongs to the sum of the ideal and quadratic module generated by the corresponding sparse constraints. Based on this characterization, we give several sufficient conditions for the sparse Moment-SOS hierarchy to be tight. In particular, we show that this sparse hierarchy is tight under some assumptions such as convexity, optimality conditions or finiteness of constraining sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06882v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiawang Nie, Zheng Qu, Xindong Tang, Linghao Zhang</dc:creator>
    </item>
    <item>
      <title>John property of anisotropic minimal surfaces</title>
      <link>https://arxiv.org/abs/2406.06906</link>
      <description>arXiv:2406.06906v1 Announce Type: new 
Abstract: For a convex set $K\subset \mathbb R^n$ and the associated anisotropic perimeter $P_K$, we establish that every $(\epsilon,\,r)$-minimizer for $P_K$ satisfies a local John property. Furthermore, we prove that a certain class of John domains, including $(\epsilon,\,r)$-minimizers close to $K$, admits a trace inequality. As a consequence, we provide a more concrete proof for a crucial step in the quantitative Wulff inequality, thereby complementing the seminal work of Figalli, Maggi, and Pratelli.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06906v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Weicong Su, Yi Ru-Ya Zhang</dc:creator>
    </item>
    <item>
      <title>AC False Data Injection Attacks in Power Systems: Design and Optimization</title>
      <link>https://arxiv.org/abs/2406.06988</link>
      <description>arXiv:2406.06988v1 Announce Type: new 
Abstract: False Data Injection (FDI) attacks are one of the challenges that the modern power system, as a cyber-physical system, is encountering. Designing AC FDI attacks that accurately address the physics of the power systems could jeopardize the security of power systems as they can easily bypass the traditional Bad Data Detection (BDD) algorithm. Knowing the essence of the AC FDI attack and how they can be designed gives insight about detecting the system again these attacks. Moreover, recognition of the nature of these attacks, especially when they are designed optimally, is essential for benchmarking various defensive approaches to increase the resilience of power systems. This paper presents a unified approach to demonstrate the process of designing optimal AC FDI attack. In this connection, we first define the process of designing an AC-based FDI attack that satisfies AC power flow equations. We then formulate an optimization problem to design an optimal AC FDI attack that both satisfies AC power flow equations and overloads a specific line in the system. The objective function is defined to optimize the magnitude of the attack vector in such a way that it can evade residue-based BDD approaches. The proposed approach for designing AC FDI attacks is applied to the IEEE 118-bus test case system. Various comparisons are conducted to elaborate on the impact of optimally designing AC FDI attacks on the residual for the AC state estimation algorithm. Comparing the results of optimal and non-optimal AC FDI attacks demonstrates the impact on the difficulty of detecting FDI attacks and the importance of optimally designing these attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06988v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammadreza Iranpour, Mohammad Rasoul Narimani</dc:creator>
    </item>
    <item>
      <title>Bilevel optimization with sustainability perspective: a survey on applications</title>
      <link>https://arxiv.org/abs/2406.07184</link>
      <description>arXiv:2406.07184v1 Announce Type: new 
Abstract: Bilevel optimization, a well-established field for modeling hierarchical decision-making problems, has recently intersected with sustainability studies and practices, resulting in a series of works focusing on bilevel optimization problems involving multiple decision makers with diverse economic, environmental, and social objectives. This survey offers a comprehensive overview of sustainable bilevel optimization applications. First, we introduce the main concepts related to the nature of bilevel optimization problems and present some typical mathematical formulations for bilevel pricing problems that cover the majority of the collected applications. Then, we review the most relevant works published in sustainable bilevel optimization, giving a classification based on the application domains and their association with well-known operations research problems, while briefly discussing the proposed solution methodologies. We survey applications on transportation and logistics, production planning and manufacturing, water, waste, and agriculture management, supply chains, and disaster prevention and response. Finally, we outline a list of open questions and opportunities for future research in this domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07184v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giulia Caselli, Manuel Iori, Ivana Ljubi\'c</dc:creator>
    </item>
    <item>
      <title>Variational inequalities and smooth-fit principle for singular stochastic control problems in Hilbert spaces</title>
      <link>https://arxiv.org/abs/2406.07242</link>
      <description>arXiv:2406.07242v1 Announce Type: new 
Abstract: We consider a class of infinite-dimensional singular stochastic control problems. These can be thought of as spatial monotone follower problems and find applications in spatial models of production and climate transition. Let $(D,\mathcal{M},\mu)$ be a finite measure space and consider the Hilbert space $H:=L^2(D,\mathcal{M},\mu; \mathbb{R})$. Let then $X$ be an $H$-valued stochastic process on a suitable complete probability space, whose evolution is determined through an SPDE driven by a self-adjoint linear operator $\mathcal{A}$ and affected by a cylindrical Brownian motion. The evolution of $X$ is controlled linearly via an $H$-valued control consisting of the direction and the intensity of action, a real-valued nondecreasing right-continuous stochastic process, adapted to the underlying filtration. The goal is to minimize a discounted convex cost-functional over an infinite time-horizon. By combining properties of semiconcave functions and techniques from viscosity theory, we first show that the value function of the problem $V$ is a $C^{1,Lip}(H)$-viscosity solution to the corresponding dynamic programming equation, which here takes the form of a variational inequality with gradient constraint. Then, by allowing the decision maker to choose only the intensity of the control and requiring that the given control direction $\hat{n}$ is an eigenvector of the linear operator $\mathcal{A}$, we establish that the directional derivative $V_{\hat{n}}$ is of class $C^1(H)$, hence a second-order smooth-fit principle in the controlled direction holds for $V$. This result is obtained by exploiting a connection to optimal stopping and combining results and techniques from convex analysis and viscosity theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07242v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Salvatore Federico, Giorgio Ferrari, Frank Riedel, Michael R\"ockner</dc:creator>
    </item>
    <item>
      <title>Infinite-Horizon Distributionally Robust Regret-Optimal Control</title>
      <link>https://arxiv.org/abs/2406.07248</link>
      <description>arXiv:2406.07248v1 Announce Type: new 
Abstract: We study the infinite-horizon distributionally robust (DR) control of linear systems with quadratic costs, where disturbances have unknown, possibly time-correlated distribution within a Wasserstein-2 ambiguity set. We aim to minimize the worst-case expected regret-the excess cost of a causal policy compared to a non-causal one with access to future disturbance. Though the optimal policy lacks a finite-order state-space realization (i.e., it is non-rational), it can be characterized by a finite-dimensional parameter. Leveraging this, we develop an efficient frequency-domain algorithm to compute this optimal control policy and present a convex optimization method to construct a near-optimal state-space controller that approximates the optimal non-rational controller in the $\mathit{H}_\infty$-norm. This approach avoids solving a computationally expensive semi-definite program (SDP) that scales with the time horizon in the finite-horizon setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07248v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Taylan Kargin, Joudi Hajar, Vikrant Malik, Babak Hassibi</dc:creator>
    </item>
    <item>
      <title>Closing the Computational-Query Depth Gap in Parallel Stochastic Convex Optimization</title>
      <link>https://arxiv.org/abs/2406.07373</link>
      <description>arXiv:2406.07373v1 Announce Type: new 
Abstract: We develop a new parallel algorithm for minimizing Lipschitz, convex functions with a stochastic subgradient oracle. The total number of queries made and the query depth, i.e., the number of parallel rounds of queries, match the prior state-of-the-art, [CJJLLST23], while improving upon the computational depth by a polynomial factor for sufficiently small accuracy. When combined with previous state-of-the-art methods our result closes a gap between the best-known query depth and the best-known computational depth of parallel algorithms.
  Our method starts with a ball acceleration framework of previous parallel methods, i.e., [CJJJLST20, ACJJS21], which reduce the problem to minimizing a regularized Gaussian convolution of the function constrained to Euclidean balls. By developing and leveraging new stability properties of the Hessian of this induced function, we depart from prior parallel algorithms and reduce these ball-constrained optimization problems to stochastic unconstrained quadratic minimization problems. Although we are unable to prove concentration of the asymmetric matrices that we use to approximate this Hessian, we nevertheless develop an efficient parallel method for solving these quadratics. Interestingly, our algorithms can be improved using fast matrix multiplication and use nearly-linear work if the matrix multiplication exponent is 2.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07373v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arun Jambulapati, Aaron Sidford, Kevin Tian</dc:creator>
    </item>
    <item>
      <title>Fast Adaptive Meta-Heuristic for Large-Scale Facility Location Problem</title>
      <link>https://arxiv.org/abs/2406.07382</link>
      <description>arXiv:2406.07382v1 Announce Type: new 
Abstract: Facility location problems have been a major research area of interest in the last several decades. In particular, uncapacitated location problems (ULP) have enormous applications. Variations of ULP often appear, especially as large-scale subproblems in more complex combinatorial optimization problems. Although many researchers have studied different versions of ULP (e.g., uncapacitated facility location problem (UCFLP) and p-Median problem), most of these authors have considered small to moderately sized problems. In this paper, we address the ULP and provide a fast adaptive meta-heuristic for large-scale problems. The approach is based on critical event memory tabu search. For the diversification component of the algorithm, we have chosen a procedure based on a sequencing problem commonly used for traveling salesman-type problems. The efficacy of this approach is evaluated across a diverse range of benchmark problems sourced from the Internet, with a comprehensive comparison against four prominent algorithms in the literature. The proposed adaptive critical event tabu search (ACETS) demonstrates remarkable effectiveness for large-scale problems. The algorithm successfully solved all problems optimally within a short computing time. Notably, ACETS discovered three best new solutions for benchmark problems, specifically for Asymmetric 500A-1, Asymmetric 750A-1, and Symmetric 750B-4, underscoring its innovative and robust nature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07382v1</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bahram Alidaee, Haibo Wang</dc:creator>
    </item>
    <item>
      <title>Optimal Marital Strategies: How Couples Develop Successful Interaction Styles</title>
      <link>https://arxiv.org/abs/2406.07403</link>
      <description>arXiv:2406.07403v1 Announce Type: new 
Abstract: The study of marriage dynamics and of strategies to reduce the likelihood of divorce has been an important research area for many years. Gottman's research on successful marriages revealed three matched interaction styles: conflict-avoiding, validating, and volatile. There has, however, been little progress in explaining how couples develop these styles of interaction and why failure to do so leads to failed marriages. In this paper, we show that these interaction styles arise as solutions to an optimal control problem where the couples jointly maximize a common goal. The validating style arises when the benefit from achieving joint happiness is balanced by the emotional cost of adopting a particular style. The ubiquitous conflict-avoider style arises naturally when the couple does not care about the cost. The volatile style is not an optimal solution, but volatile marriages may still be successful for couples with highly positive natural dispositions. The problem of the spouses having different goals in marriage is relevant to marriage repair, and this problem will be studied in the next paper using differential game theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07403v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Micah Henson, Mark Kot, Ka-Kit Tung</dc:creator>
    </item>
    <item>
      <title>The Price of Cognition and Replicator Equations in Parallel Neural Networks</title>
      <link>https://arxiv.org/abs/2406.06726</link>
      <description>arXiv:2406.06726v1 Announce Type: cross 
Abstract: In this paper, we are aiming to propose a novel mathematical model that studies the dynamics of synaptic damage in terms of concentrations of toxic neuropeptides/neurotransmitters during neurotransmission processes. Our primary objective is to employ Wardrop's first and second principles within a neural network of the brain. In order to comprehensively incorporate Wardrop's first and second principles into the neural network of the brain, we introduce two novel concepts: \textit{neuropeptide's (neurotransmitter's) equilibrium} and \textit{synapses optimum}. The \textit{neuropeptide/neurotransmitter equilibrium} refers to \textit{a distribution of toxic neuropeptides/neurotransmitters that leads to uniform damage across all synaptic links}. Meanwhile, \textit{synapses optimum} is \textit{the most desirable distribution of toxic neuropeptides/neurotransmitters that minimizes the cumulative damage experienced by all synapses}. In the context of a neural network within the brain, an analogue of the price of anarchy is \textit{the price of cognition} which is \textit{the most unfavorable ratio between the overall impairment caused by toxic neuropeptide's (neurotransmitter's) equilibrium in comparison to the optimal state of synapses (synapses optimum)}. To put it differently, \textit{the price of cognition} measures \textit{the loss of cognitive ability resulting from increased concentrations of toxic neuropeptides/neurotransmitters}. Additionally, a replicator equation is proposed within this framework that leads to the establishment of the synapses optimum during the neurotransmission process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06726v1</guid>
      <category>q-bio.NC</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Armen Bagdasaryan, Antonios Kalampakas, Mansoor Saburov</dc:creator>
    </item>
    <item>
      <title>Locally Interdependent Multi-Agent MDP: Theoretical Framework for Decentralized Agents with Dynamic Dependencies</title>
      <link>https://arxiv.org/abs/2406.06823</link>
      <description>arXiv:2406.06823v1 Announce Type: cross 
Abstract: Many multi-agent systems in practice are decentralized and have dynamically varying dependencies. There has been a lack of attempts in the literature to analyze these systems theoretically. In this paper, we propose and theoretically analyze a decentralized model with dynamically varying dependencies called the Locally Interdependent Multi-Agent MDP. This model can represent problems in many disparate domains such as cooperative navigation, obstacle avoidance, and formation control. Despite the intractability that general partially observable multi-agent systems suffer from, we propose three closed-form policies that are theoretically near-optimal in this setting and can be scalable to compute and store. Consequentially, we reveal a fundamental property of Locally Interdependent Multi-Agent MDP's that the partially observable decentralized solution is exponentially close to the fully observable solution with respect to the visibility radius. We then discuss extensions of our closed-form policies to further improve tractability. We conclude by providing simulations to investigate some long horizon behaviors of our closed-form policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06823v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alex DeWeese, Guannan Qu</dc:creator>
    </item>
    <item>
      <title>Random Shadows of Fixed Polytopes</title>
      <link>https://arxiv.org/abs/2406.06936</link>
      <description>arXiv:2406.06936v1 Announce Type: cross 
Abstract: Estimating the number of vertices of a two dimensional projection, called a shadow, of a polytope is a fundamental tool for understanding the performance of the shadow simplex method for linear programming among other applications. We prove multiple upper bounds on the expected number of vertices of a random shadow of a fixed polytope. Our bounds are in terms of various parameters in the literature including geometric diameter and edge lengths, minimal and maximal slack, maximal coordinates for lattice polytopes, and maximum absolute values of subdeterminants. For the case of geometric diameter and edge lengths, we prove lower bounds and argue that our upper and lower bounds are both tight for zonotopes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06936v1</guid>
      <category>math.CO</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander E. Black, Francisco Criado</dc:creator>
    </item>
    <item>
      <title>Optimal Matrix-Mimetic Tensor Algebras via Variable Projection</title>
      <link>https://arxiv.org/abs/2406.06942</link>
      <description>arXiv:2406.06942v1 Announce Type: cross 
Abstract: Recent advances in {matrix-mimetic} tensor frameworks have made it possible to preserve linear algebraic properties for multilinear data analysis and, as a result, to obtain optimal representations of multiway data. Matrix mimeticity arises from interpreting tensors as operators that can be multiplied, factorized, and analyzed analogous to matrices. Underlying the tensor operation is an algebraic framework parameterized by an invertible linear transformation. The choice of linear mapping is crucial to representation quality and, in practice, is made heuristically based on expected correlations in the data. However, in many cases, these correlations are unknown and common heuristics lead to suboptimal performance. In this work, we simultaneously learn optimal linear mappings and corresponding tensor representations without relying on prior knowledge of the data. Our new framework explicitly captures the coupling between the transformation and representation using variable projection. We preserve the invertibility of the linear mapping by learning orthogonal transformations with Riemannian optimization. We provide original theory of uniqueness of the transformation and convergence analysis of our variable-projection-based algorithm. We demonstrate the generality of our framework through numerical experiments on a wide range of applications, including financial index tracking, image compression, and reduced order modeling. We have published all the code related to this work at https://github.com/elizabethnewman/star-M-opt.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06942v1</guid>
      <category>math.NA</category>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elizabeth Newman, Katherine Keegan</dc:creator>
    </item>
    <item>
      <title>Distributional MIPLIB: a Multi-Domain Library for Advancing ML-Guided MILP Methods</title>
      <link>https://arxiv.org/abs/2406.06954</link>
      <description>arXiv:2406.06954v1 Announce Type: cross 
Abstract: Mixed Integer Linear Programming (MILP) is a fundamental tool for modeling combinatorial optimization problems. Recently, a growing body of research has used machine learning to accelerate MILP solving. Despite the increasing popularity of this approach, there is a lack of a common repository that provides distributions of similar MILP instances across different domains, at different hardness levels, with standardized test sets. In this paper, we introduce Distributional MIPLIB, a multi-domain library of problem distributions for advancing ML-guided MILP methods. We curate MILP distributions from existing work in this area as well as real-world problems that have not been used, and classify them into different hardness levels. It will facilitate research in this area by enabling comprehensive evaluation on diverse and realistic domains. We empirically illustrate the benefits of using Distributional MIPLIB as a research vehicle in two ways. We evaluate the performance of ML-guided variable branching on previously unused distributions to identify potential areas for improvement. Moreover, we propose to learn branching policies from a mix of distributions, demonstrating that mixed distributions achieve better performance compared to homogeneous distributions when there is limited data and generalize well to larger instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06954v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weimin Huang, Taoan Huang, Aaron M Ferber, Bistra Dilkina</dc:creator>
    </item>
    <item>
      <title>Secrecy Energy Efficiency Maximization in RIS-Aided Wireless Networks</title>
      <link>https://arxiv.org/abs/2406.06983</link>
      <description>arXiv:2406.06983v1 Announce Type: cross 
Abstract: This work proposes a provably convergent and low complexity optimization algorithm for the maximization of the secrecy energy efficiency in the uplink of a wireless network aided by a Reconfigurable Intelligent Surface (RIS), in the presence of an eavesdropper. The mobil users' transmit powers and the RIS reflection coefficients are optimized. Numerical results show the performance of the proposed methods and compare the use of active and nearly-passive RISs from an energy-efficient perspective.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06983v1</guid>
      <category>eess.SP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robert Kuku Fotock, Alessio Zappone, Marco Di Renzo</dc:creator>
    </item>
    <item>
      <title>Differentiability and Optimization of Multiparameter Persistent Homology</title>
      <link>https://arxiv.org/abs/2406.07224</link>
      <description>arXiv:2406.07224v1 Announce Type: cross 
Abstract: Real-valued functions on geometric data -- such as node attributes on a graph -- can be optimized using descriptors from persistent homology, allowing the user to incorporate topological terms in the loss function. When optimizing a single real-valued function (the one-parameter setting), there is a canonical choice of descriptor for persistent homology: the barcode. The operation mapping a real-valued function to its barcode is differentiable almost everywhere, and the convergence of gradient descent for losses using barcodes is relatively well understood. When optimizing a vector-valued function (the multiparameter setting), there is no unique choice of descriptor for multiparameter persistent homology, and many distinct descriptors have been proposed. This calls for the development of a general framework for differentiability and optimization that applies to a wide range of multiparameter homological descriptors. In this article, we develop such a framework and show that it encompasses well-known descriptors of different flavors, such as signed barcodes and the multiparameter persistence landscape. We complement the theory with numerical experiments supporting the idea that optimizing multiparameter homological descriptors can lead to improved performances compared to optimizing one-parameter descriptors, even when using the simplest and most efficiently computable multiparameter descriptors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07224v1</guid>
      <category>cs.CG</category>
      <category>math.AT</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luis Scoccola, Siddharth Setlur, David Loiseaux, Mathieu Carri\`ere, Steve Oudot</dc:creator>
    </item>
    <item>
      <title>Convergence rate of random scan Coordinate Ascent Variational Inference under log-concavity</title>
      <link>https://arxiv.org/abs/2406.07292</link>
      <description>arXiv:2406.07292v1 Announce Type: cross 
Abstract: The Coordinate Ascent Variational Inference scheme is a popular algorithm used to compute the mean-field approximation of a probability distribution of interest. We analyze its random scan version, under log-concavity assumptions on the target density. Our approach builds on the recent work of M. Arnese and D. Lacker, \emph{Convergence of coordinate ascent variational inference for log-concave measures via optimal transport} [arXiv:2404.08792] which studies the deterministic scan version of the algorithm, phrasing it as a block-coordinate descent algorithm in the space of probability distributions endowed with the geometry of optimal transport. We obtain tight rates for the random scan version, which imply that the total number of factor updates required to converge scales linearly with the condition number and the number of blocks of the target distribution. By contrast, available bounds for the deterministic scan case scale quadratically in the same quantities, which is analogue to what happens for optimization of convex functions in Euclidean spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07292v1</guid>
      <category>stat.ML</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hugo Lavenant, Giacomo Zanella</dc:creator>
    </item>
    <item>
      <title>Accelerating Ill-conditioned Hankel Matrix Recovery via Structured Newton-like Descent</title>
      <link>https://arxiv.org/abs/2406.07409</link>
      <description>arXiv:2406.07409v1 Announce Type: cross 
Abstract: This paper studies the robust Hankel recovery problem, which simultaneously removes the sparse outliers and fulfills missing entries from the partial observation. We propose a novel non-convex algorithm, coined Hankel Structured Newton-Like Descent (HSNLD), to tackle the robust Hankel recovery problem. HSNLD is highly efficient with linear convergence, and its convergence rate is independent of the condition number of the underlying Hankel matrix. The recovery guarantee has been established under some mild conditions. Numerical experiments on both synthetic and real datasets show the superior performance of HSNLD against state-of-the-art algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07409v1</guid>
      <category>stat.ML</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>HanQin Cai, Longxiu Huang, Xiliang Lu, Juntao You</dc:creator>
    </item>
    <item>
      <title>G\^ateaux semiderivative approach applied to shape optimization for contact problems</title>
      <link>https://arxiv.org/abs/2208.03687</link>
      <description>arXiv:2208.03687v3 Announce Type: replace 
Abstract: Shape optimization problems constrained by variational inequalities (VI) are non-smooth and non-convex optimization problems. The non-smoothness arises due to the variational inequality constraint, which makes it challenging to derive optimality conditions. Besides the non-smoothness there are complementary aspects due to the VIs as well as distributed, non-linear, non-convex and infinite-dimensional aspects due to the shapes which complicate to set up an optimality system and, thus, to develop efficient solution algorithms. In this paper, we consider G\^ateaux semiderivatives in order to formulate optimality conditions. In the application, we concentrate on a shape optimization problem constrained by the contact problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.03687v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nico Goldammer, Volker H. Schulz, Kathrin Welker</dc:creator>
    </item>
    <item>
      <title>On growth error bound conditions with an application to heavy ball method</title>
      <link>https://arxiv.org/abs/2310.03947</link>
      <description>arXiv:2310.03947v2 Announce Type: replace 
Abstract: In this paper, we investigate the growth error bound condition. By using the proximal point algorithm, we first provide a more accessible and elementary proof of the fact that Kurdyka-{\L}ojasiewicz conditions imply growth error bound conditions for convex functions which has been established before via a subgradient flow. We then extend the result for nonconvex functions. Furthermore we show that every definable function in an o-minimal structure must satisfy a growth error bound condition. Finally, as an application, we consider the heavy ball method for solving convex optimization problems and propose an adaptive strategy for selecting the momentum coefficient. Under growth error bound conditions, we derive convergence rates of the proposed method. A numerical experiment is conducted to demonstrate its acceleration effect over the gradient method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.03947v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qinian Jin</dc:creator>
    </item>
    <item>
      <title>(Accelerated) Noise-adaptive Stochastic Heavy-Ball Momentum</title>
      <link>https://arxiv.org/abs/2401.06738</link>
      <description>arXiv:2401.06738v2 Announce Type: replace 
Abstract: Stochastic heavy ball momentum (SHB) is commonly used to train machine learning models, and often provides empirical improvements over stochastic gradient descent. By primarily focusing on strongly-convex quadratics, we aim to better understand the theoretical advantage of SHB and subsequently improve the method. For strongly-convex quadratics, Kidambi et al. (2018) show that SHB (with a mini-batch of size $1$) cannot attain accelerated convergence, and hence has no theoretical benefit over SGD. They conjecture that the practical gain of SHB is a by-product of using larger mini-batches. We first substantiate this claim by showing that SHB can attain an accelerated rate when the mini-batch size is larger than a threshold $b^*$ that depends on the condition number $\kappa$. Specifically, we prove that with the same step-size and momentum parameters as in the deterministic setting, SHB with a sufficiently large mini-batch size results in an $O\left(\exp(-\frac{T}{\sqrt{\kappa}}) + \sigma \right)$ convergence, where $T$ is the number of iterations and $\sigma^2$ is the variance in the stochastic gradients. We prove a lower-bound which demonstrates that a $\kappa$ dependence in $b^*$ is necessary. To ensure convergence to the minimizer, we design a noise-adaptive multi-stage algorithm that results in an $O\left(\exp\left(-\frac{T}{\sqrt{\kappa}}\right) + \frac{\sigma}{T}\right)$ rate. We also consider the general smooth, strongly-convex setting and propose the first noise-adaptive SHB variant that converges to the minimizer at an $O(\exp(-\frac{T}{\kappa}) + \frac{\sigma^2}{T})$ rate. We empirically demonstrate the effectiveness of the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.06738v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anh Dang, Reza Babanezhad, Sharan Vaswani</dc:creator>
    </item>
    <item>
      <title>Net-Zero Energy House-oriented Linear Programming for the Sizing Problem of Photovoltaic Panels and Batteries</title>
      <link>https://arxiv.org/abs/2401.07425</link>
      <description>arXiv:2401.07425v2 Announce Type: replace 
Abstract: The global drive towards carbon neutrality has led to a significant increase in the number of power plants based on renewable energy sources (RES). Concurrently, numerous households are adopting RES to generate their own energy, aiming to decrease both electricity costs and carbon footprints. To support these users, many papers have been devoted to developing optimal investment strategies for residential energy systems. However, there is still a significant gap as these studies often neglect important aspects like carbon neutrality. For this reason, in this paper, we explore the concept of net-zero energy houses (ZEHs) -- houses designed to have an annual net energy consumption around zero -- by presenting a constrained optimization problem to find the optimal number of photovoltaic panels and the optimal size of the battery system for home integration. Solving this constrained optimization problem is difficult due to its nonconvex constraints. Nevertheless, by applying a series of transformations, we reveal that it is possible to find an equivalent linear programming (LP) problem which is computationally tractable. The attainment of ZEH can be tackled by introducing a single constraint in the optimization problem. Additionally, we propose a sharing economy approach to the investment problem, offering a strategy that could potentially reduce investment costs and facilitate the attainment of ZEH more efficiently. Finally, we apply the proposed frameworks to a neighborhood in Japan as a case study, demonstrating the potential for long-term ZEH attainment. The results show that, under the right incentive, users can achieve ZEH, reduce their electricity costs and have a minimal impact on the main grid.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.07425v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/ACCESS.2024.3410369</arxiv:DOI>
      <arxiv:journal_reference>IEEE Access 2024</arxiv:journal_reference>
      <dc:creator>A. Daniel Carnerero, Taichi Tanaka, Mengmou Li, Takeshi Hatanaka, Yasuaki Wasa, Kenji Hirata, Yoshiaki Ushifusa, Takanori Ida</dc:creator>
    </item>
    <item>
      <title>A Scalable Approach to Equitable Facility Location</title>
      <link>https://arxiv.org/abs/2401.15452</link>
      <description>arXiv:2401.15452v2 Announce Type: replace 
Abstract: In a recent advance in the environmental justice literature, the Kolm-Pollak Equally Distributed Equivalent (EDE) was introduced as the most principled metric for ranking distributions of disamenities, such as air pollution, radiation levels, or, in our case, distance from an essential service, when equity is a concern. The Kolm-Pollak EDE incorporates both the center and the spread of a distribution by penalizing inequality at a level prescribed by the decision-maker via an aversion to inequality parameter, thereby capturing the experience of an individual more accurately than the population mean. We present, analyze, and computationally test a model for optimizing the Kolm-Pollak EDE in the context of facility location, both with and without a penalty term applied for the selection of less-suitable potential locations. Extensive computational experiments demonstrate that, unlike other facility location models that incorporate measures of equity, this model scales to extremely large practical problem instances. Optimal solutions represent significant improvements for the worst-off residents with respect to distance from an open amenity, while also attaining a near-optimal "average" experience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.15452v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Drew Horton, Tom Logan, Joshua Murrell, Daphne Skipper, Emily Speakman</dc:creator>
    </item>
    <item>
      <title>Distributed Sequential Quadratic Programming with Overlapping Graph Decomposition and Exact Augmented Lagrangian</title>
      <link>https://arxiv.org/abs/2402.17170</link>
      <description>arXiv:2402.17170v2 Announce Type: replace 
Abstract: In this paper, we address the challenge of solving large-scale graph-structured nonlinear programs (gsNLPs) in a scalable manner. GsNLPs are problems in which the objective and constraint functions are associated with nodes on a graph and depend on the variables of adjacent nodes. This graph-structured formulation encompasses various specific instances, such as dynamic optimization, PDE-constrained optimization, multistage stochastic optimization, and general network optimization. By leveraging the sequential quadratic programming (SQP) framework, we propose a globally convergent overlapping graph decomposition method to solve large-scale gsNLPs under standard mild regularity conditions on the graph topology. In each iteration, we perform an overlapping graph decomposition to compute an approximate Newton direction in a parallel environment. Then, we select a suitable stepsize and update the primal-dual iterate by performing a backtracking line search on an exact augmented Lagrangian merit function. Built on the exponential decay of sensitivity of gsNLPs, we show that the approximate Newton direction is a descent direction of the augmented Lagrangian, which leads to global convergence with a local linear convergence rate. In particular, global convergence is achieved for sufficiently large overlaps, and the local linear convergence rate improves exponentially in terms of the overlap size. Our results match existing state-of-the-art guarantees established for dynamic programs (which simply correspond to linear graphs). We validate the theory on a semilinear elliptic PDE-constrained problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.17170v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Runxin Ni, Sen Na, Sungho Shin, Mihai Anitescu</dc:creator>
    </item>
    <item>
      <title>Second-order optimality conditions for the sparse optimal control of nonviscous Cahn-Hilliard systems</title>
      <link>https://arxiv.org/abs/2406.02384</link>
      <description>arXiv:2406.02384v2 Announce Type: replace 
Abstract: In this paper we study the optimal control of an initial-boundary value problem for the classical nonviscous Cahn-Hilliard system with zero Neumann boundary conditions. Phase field systems of this type govern the evolution of diffusive phase transition processes with conserved order parameter. For such systems, optimal control problems have been studied in the past. We focus here on the situation when the cost functional of the optimal control problem contains a sparsity-enhancing nondifferentiable term like the L1-norm. For such cases, we establish first-order necessary and second-order sufficient optimality conditions for locally optimal controls, where in the approach to second-order sufficient conditions we employ a technique introduced by E. Casas, C. Ryll and F. Tr\"oltzsch in the paper [SIAM J. Control Optim. 53 (2015), 2168-2202]. The main novelty of this paper is that this method, which has recently been successfully applied to systems of viscous Cahn-Hilliard type, can be adapted also to the classical nonviscous case. Since in the case without viscosity the solutions to the state and adjoint systems turn out to be considerably less regular than in the viscous case, numerous additional technical difficulties have to be overcome, and additional conditions have to be imposed. In particular, we have to restrict ourselves to the case when the nonlinearity driving the phase separation is regular, while in the presence of a viscosity term also nonlinearities of logarithmic type turn could be admitted. In addition, the implicit function theorem, which was employed to establish the needed differentiability properties of the control-to-state operator in the viscous case, does not apply in our situation and has to be substituted by other arguments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02384v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pierluigi Colli, J\"urgen Sprekels</dc:creator>
    </item>
    <item>
      <title>Fast and Certifiable Trajectory Optimization</title>
      <link>https://arxiv.org/abs/2406.05846</link>
      <description>arXiv:2406.05846v2 Announce Type: replace 
Abstract: We propose semidefinite trajectory optimization (STROM), a framework that computes fast and certifiably optimal solutions for nonconvex trajectory optimization problems defined by polynomial objectives and constraints. STROM employs sparse second-order Lasserre's hierarchy to generate semidefinite program (SDP) relaxations of trajectory optimization. Different from existing tools (e.g., YALMIP and SOSTOOLS in Matlab), STROM generates chain-like multiple-block SDPs with only positive semidefinite (PSD) variables. Moreover, STROM does so two orders of magnitude faster. Underpinning STROM is cuADMM, the first ADMM-based SDP solver implemented in CUDA and runs in GPUs. cuADMM builds upon the symmetric Gauss-Seidel ADMM algorithm and leverages GPU parallelization to speedup solving sparse linear systems and projecting onto PSD cones. In five trajectory optimization problems (inverted pendulum, cart-pole, vehicle landing, flying robot, and car back-in), cuADMM computes optimal trajectories (with certified suboptimality below 1%) in minutes (when other solvers take hours or run out of memory) and seconds (when others take minutes). Further, when warmstarted by data-driven initialization in the inverted pendulum problem, cuADMM delivers real-time performance: providing certifiably optimal trajectories in 0.66 seconds despite the SDP has 49,500 variables and 47,351 constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05846v2</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shucheng Kang, Xiaoyang Xu, Jay Sarva, Ling Liang, Heng Yang</dc:creator>
    </item>
    <item>
      <title>Dynamic Control of Service Systems with Returns: Application to Design of Post-Discharge Hospital Readmission Prevention Programs</title>
      <link>https://arxiv.org/abs/2203.00093</link>
      <description>arXiv:2203.00093v2 Announce Type: replace-cross 
Abstract: We study a control problem for queueing systems where customers may return for additional episodes of service after their initial service completion. At each service completion epoch, the decision maker can choose to reduce the probability of return for the departing customer but at a cost that is convex increasing in the amount of reduction in the return probability. Other costs are incurred as customers wait in the queue and every time they return for service. Our primary motivation comes from post-discharge Quality Improvement (QI) interventions (e.g., follow up phone-calls, appointments) frequently used in a variety of healthcare settings to reduce unplanned hospital readmissions. Our objective is to understand how the cost of interventions should be balanced with the reductions in congestion and service costs. To this end, we consider a fluid approximation of the queueing system and characterize the structure of optimal long-run average and bias-optimal transient control policies for the fluid model. Our structural results motivate the design of intuitive surge protocols whereby different intensities of interventions (corresponding to different levels of reduction in the return probability) are provided based on the congestion in the system. Through extensive simulation experiments, we study the performance of the fluid policy for the stochastic system and identify parameter regimes where it leads to significant cost savings compared to a fixed long-run average optimal policy that ignores holding costs and a simple policy that uses the highest level of intervention whenever the queue is non-empty. In particular, we find that in a parameter regime relevant to our motivating application, dynamically adjusting the intensity of interventions could result in up to 25.4% reduction in long-run average cost and 33.7% in finite-horizon costs compared to the simple aggressive policy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2203.00093v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Timothy C. Y. Chan, Simon Y. Huang, Vahid Sarhangian</dc:creator>
    </item>
    <item>
      <title>Metrizing Fairness</title>
      <link>https://arxiv.org/abs/2205.15049</link>
      <description>arXiv:2205.15049v5 Announce Type: replace-cross 
Abstract: We study supervised learning problems that have significant effects on individuals from two demographic groups, and we seek predictors that are fair with respect to a group fairness criterion such as statistical parity (SP). A predictor is SP-fair if the distributions of predictions within the two groups are close in Kolmogorov distance, and fairness is achieved by penalizing the dissimilarity of these two distributions in the objective function of the learning problem. In this paper, we identify conditions under which hard SP constraints are guaranteed to improve predictive accuracy. We also showcase conceptual and computational benefits of measuring unfairness with integral probability metrics (IPMs) other than the Kolmogorov distance. Conceptually, we show that the generator of any IPM can be interpreted as a family of utility functions and that unfairness with respect to this IPM arises if individuals in the two demographic groups have diverging expected utilities. We also prove that the unfairness-regularized prediction loss admits unbiased gradient estimators, which are constructed from random mini-batches of training samples, if unfairness is measured by the squared $\mathcal L^2$-distance or by a squared maximum mean discrepancy. In this case, the fair learning problem is susceptible to efficient stochastic gradient descent (SGD) algorithms. Numerical experiments on synthetic and real data show that these SGD algorithms outperform state-of-the-art methods for fair learning in that they achieve superior accuracy-unfairness trade-offs -- sometimes orders of magnitude faster.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.15049v5</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yves Rychener, Bahar Taskesen, Daniel Kuhn</dc:creator>
    </item>
    <item>
      <title>Decentralized Stochastic Gradient Descent Ascent for Finite-Sum Minimax Problems</title>
      <link>https://arxiv.org/abs/2212.02724</link>
      <description>arXiv:2212.02724v3 Announce Type: replace-cross 
Abstract: Minimax optimization problems have attracted significant attention in recent years due to their widespread application in numerous machine learning models. To solve the minimax problem, a wide variety of stochastic optimization methods have been proposed. However, most of them ignore the distributed setting where the training data is distributed on multiple workers. In this paper, we developed a novel decentralized stochastic gradient descent ascent method for the finite-sum minimax problem. In particular, by employing the variance-reduced gradient, our method can achieve $O(\frac{\sqrt{n}\kappa^3}{(1-\lambda)^2\epsilon^2})$ sample complexity and $O(\frac{\kappa^3}{(1-\lambda)^2\epsilon^2})$ communication complexity for the nonconvex-strongly-concave minimax problem. As far as we know, our work is the first one to achieve such theoretical complexities for this kind of minimax problem. At last, we apply our method to AUC maximization, and the experimental results confirm the effectiveness of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.02724v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongchang Gao</dc:creator>
    </item>
    <item>
      <title>Using Reinforcement Learning for the Three-Dimensional Loading Capacitated Vehicle Routing Problem</title>
      <link>https://arxiv.org/abs/2307.12136</link>
      <description>arXiv:2307.12136v2 Announce Type: replace-cross 
Abstract: Heavy goods vehicles are vital backbones of the supply chain delivery system but also contribute significantly to carbon emissions with only 60% loading efficiency in the United Kingdom. Collaborative vehicle routing has been proposed as a solution to increase efficiency, but challenges remain to make this a possibility. One key challenge is the efficient computation of viable solutions for co-loading and routing. Current operations research methods suffer from non-linear scaling with increasing problem size and are therefore bound to limited geographic areas to compute results in time for day-to-day operations. This only allows for local optima in routing and leaves global optimisation potential untouched. We develop a reinforcement learning model to solve the three-dimensional loading capacitated vehicle routing problem in approximately linear time. While this problem has been studied extensively in operations research, no publications on solving it with reinforcement learning exist. We demonstrate the favourable scaling of our reinforcement learning model and benchmark our routing performance against state-of-the-art methods. The model performs within an average gap of 3.83% to 8.10% compared to established methods. Our model not only represents a promising first step towards large-scale logistics optimisation with reinforcement learning but also lays the foundation for this research stream. GitHub: https://github.com/if-loops/3L-CVRP</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.12136v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stefan Schoepf, Stephen Mak, Julian Senoner, Liming Xu, Netland Torbj\"orn, Alexandra Brintrup</dc:creator>
    </item>
    <item>
      <title>UniAP: Unifying Inter- and Intra-Layer Automatic Parallelism by Mixed Integer Quadratic Programming</title>
      <link>https://arxiv.org/abs/2307.16375</link>
      <description>arXiv:2307.16375v4 Announce Type: replace-cross 
Abstract: Distributed learning is commonly used for training deep learning models, especially large models. In distributed learning, manual parallelism (MP) methods demand considerable human effort and have limited flexibility. Hence, automatic parallelism (AP) methods have recently been proposed for automating the parallel strategy optimization process. Existing AP methods suffer from sub-optimal solutions because they do not jointly optimize the two categories of parallel strategies (i.e., inter-layer parallelism and intra-layer parallelism). In this paper, we propose a novel AP method called UniAP, which unifies inter- and intra-layer automatic parallelism by mixed integer quadratic programming. To the best of our knowledge, UniAP is the first parallel method that can jointly optimize the two categories of parallel strategies to find an optimal solution. Experimental results show that UniAP outperforms state-of-the-art methods by up to 3.80$\times$ in throughput and reduces strategy optimization time by up to 107$\times$ across five Transformer-based models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.16375v4</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Lin, Ke Wu, Jie Li, Jun Li, Wu-Jun Li</dc:creator>
    </item>
    <item>
      <title>The algebraic degree of sparse polynomial optimization</title>
      <link>https://arxiv.org/abs/2308.07765</link>
      <description>arXiv:2308.07765v2 Announce Type: replace-cross 
Abstract: We study a broad class of polynomial optimization problems whose constraints and objective functions exhibit sparsity patterns. We give two characterizations of the number of critical points to these problems, one as a mixed volume and one as an intersection product on a toric variety. As a corollary, we obtain a convex geometric interpretation of polar degrees, a classical invariant of algebraic varieties, as well as Euclidean distance degrees. Furthermore, we prove the BKK generality of Lagrange systems in many instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.07765v2</guid>
      <category>math.AG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julia Lindberg, Leonid Monin, Kemal Rose</dc:creator>
    </item>
    <item>
      <title>Discrete-time Negative Imaginary Systems from ZOH Sampling</title>
      <link>https://arxiv.org/abs/2312.05419</link>
      <description>arXiv:2312.05419v3 Announce Type: replace-cross 
Abstract: A new definition of discrete-time negative imaginary (NI) systems is provided. This definition characterizes the dissipative property of a zero-order hold sampled continuous-time NI system. Under some assumptions, asymptotic stability can be guaranteed for the closed-loop interconnection of an NI system and an output strictly negative imaginary system, with one of them having a one step advance. In the case of linear systems, we also provide necessary and sufficient frequency-domain and LMI conditions under which the definition is satisfied. Also provided is a simple DC gain condition for the stability results in the linear case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.05419v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kanghong Shi, Ian R. Petersen, Igor G. Vladimirov</dc:creator>
    </item>
    <item>
      <title>Fun with Flags: Robust Principal Directions via Flag Manifolds</title>
      <link>https://arxiv.org/abs/2401.04071</link>
      <description>arXiv:2401.04071v3 Announce Type: replace-cross 
Abstract: Principal component analysis (PCA), along with its extensions to manifolds and outlier contaminated data, have been indispensable in computer vision and machine learning. In this work, we present a unifying formalism for PCA and its variants, and introduce a framework based on the flags of linear subspaces, ie a hierarchy of nested linear subspaces of increasing dimension, which not only allows for a common implementation but also yields novel variants, not explored previously. We begin by generalizing traditional PCA methods that either maximize variance or minimize reconstruction error. We expand these interpretations to develop a wide array of new dimensionality reduction algorithms by accounting for outliers and the data manifold. To devise a common computational approach, we recast robust and dual forms of PCA as optimization problems on flag manifolds. We then integrate tangent space approximations of principal geodesic analysis (tangent-PCA) into this flag-based framework, creating novel robust and dual geodesic PCA variations. The remarkable flexibility offered by the 'flagification' introduced here enables even more algorithmic variants identified by specific flag types. Last but not least, we propose an effective convergent solver for these flag-formulations employing the Stiefel manifold. Our empirical results on both real-world and synthetic scenarios, demonstrate the superiority of our novel algorithms, especially in terms of robustness to outliers on manifolds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.04071v3</guid>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>math.DG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nathan Mankovich, Gustau Camps-Valls, Tolga Birdal</dc:creator>
    </item>
    <item>
      <title>Multi-qubit Lattice Surgery Scheduling</title>
      <link>https://arxiv.org/abs/2405.17688</link>
      <description>arXiv:2405.17688v2 Announce Type: replace-cross 
Abstract: Fault-tolerant quantum computation using two-dimensional topological quantum error correcting codes can benefit from multi-qubit long-range operations. By using simple commutation rules, a quantum circuit can be transpiled into a sequence of solely non-Clifford multi-qubit gates. Prior work on fault-tolerant compilation avoids optimal scheduling of such gates since they reduce the parallelizability of the circuit. We observe that the reduced parallelization potential is outweighed by the significant reduction in the number of gates. We therefore devise a method for scheduling multi-qubit lattice surgery using an earliest-available-first policy, solving the associated forest packing problem using a representation of the multi-qubit gates as Steiner trees. Our extensive testing on random and application-inspired circuits demonstrates the method's scalability and performance. We show that the transpilation significantly reduces the circuit length on the set of circuits tested, and that the resulting circuit of multi-qubit gates has a further reduction in the expected circuit execution time compared to serial execution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17688v2</guid>
      <category>quant-ph</category>
      <category>cs.AR</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Allyson Silva, Xiangyi Zhang, Zak Webb, Mia Kramer, Chan Woo Yang, Xiao Liu, Jessica Lemieux, Ka-Wai Chen, Artur Scherer, Pooya Ronagh</dc:creator>
    </item>
    <item>
      <title>Model Predictive Control and Reinforcement Learning: A Unified Framework Based on Dynamic Programming</title>
      <link>https://arxiv.org/abs/2406.00592</link>
      <description>arXiv:2406.00592v2 Announce Type: replace-cross 
Abstract: In this paper we describe a new conceptual framework that connects approximate Dynamic Programming (DP), Model Predictive Control (MPC), and Reinforcement Learning (RL). This framework centers around two algorithms, which are designed largely independently of each other and operate in synergy through the powerful mechanism of Newton's method. We call them the off-line training and the on-line play algorithms. The names are borrowed from some of the major successes of RL involving games; primary examples are the recent (2017) AlphaZero program (which plays chess, [SHS17], [SSS17]), and the similarly structured and earlier (1990s) TD-Gammon program (which plays backgammon, [Tes94], [Tes95], [TeG96]). In these game contexts, the off-line training algorithm is the method used to teach the program how to evaluate positions and to generate good moves at any given position, while the on-line play algorithm is the method used to play in real time against human or computer opponents.
  Significantly, the synergy between off-line training and on-line play also underlies MPC (as well as other major classes of sequential decision problems), and indeed the MPC design architecture is very similar to the one of AlphaZero and TD-Gammon. This conceptual insight provides a vehicle for bridging the cultural gap between RL and MPC, and sheds new light on some fundamental issues in MPC. These include the enhancement of stability properties through rollout, the treatment of uncertainty through the use of certainty equivalence, the resilience of MPC in adaptive control settings that involve changing system parameters, and the insights provided by the superlinear performance bounds implied by Newton's method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00592v2</guid>
      <category>eess.SY</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dimitri P. Bertsekas</dc:creator>
    </item>
    <item>
      <title>Random Features Approximation for Control-Affine Systems</title>
      <link>https://arxiv.org/abs/2406.06514</link>
      <description>arXiv:2406.06514v2 Announce Type: replace-cross 
Abstract: Modern data-driven control applications call for flexible nonlinear models that are amenable to principled controller synthesis and realtime feedback. Many nonlinear dynamical systems of interest are control affine. We propose two novel classes of nonlinear feature representations which capture control affine structure while allowing for arbitrary complexity in the state dependence. Our methods make use of random features (RF) approximations, inheriting the expressiveness of kernel methods at a lower computational cost. We formalize the representational capabilities of our methods by showing their relationship to the Affine Dot Product (ADP) kernel proposed by Casta\~neda et al. (2021) and a novel Affine Dense (AD) kernel that we introduce. We further illustrate the utility by presenting a case study of data-driven optimization-based control using control certificate functions (CCF). Simulation experiments on a double pendulum empirically demonstrate the advantages of our methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06514v2</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kimia Kazemian, Yahya Sattar, Sarah Dean</dc:creator>
    </item>
  </channel>
</rss>
