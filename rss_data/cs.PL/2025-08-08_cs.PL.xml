<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.PL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.PL</link>
    <description>cs.PL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.PL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 08 Aug 2025 04:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Consistent Updates for Scalable Microservices</title>
      <link>https://arxiv.org/abs/2508.04829</link>
      <description>arXiv:2508.04829v1 Announce Type: new 
Abstract: Online services are commonly implemented with a scalable microservice architecture, where isomorphic worker processes service client requests, recording persistent state in a backend data store. To maintain service, any modifications to the service functionality must be made on the fly -- i.e., as the service continues to process client requests -- but doing so is challenging. The central difficulty is that of avoiding potential inconsistencies caused by ''mixed mode'' operation, where workers of current and new versions are concurrently active and interact via the data store. Some update methods avoid mixed mode altogether, but only at the cost of substantial inefficiency -- by doubling resources (memory and compute), or by halving throughput. The alternative is a so-called ''rolling'' update, which is uncontrolled and runs the risk of serious service failures arising from inconsistent mixed-mode behavior.
  In this paper, we present the first algorithms that guarantee consistency for mixed mode updates. The algorithms rely on semantic properties of service actions, such as commutativity. We show that semantic awareness is required, by proving that any semantically oblivious, mixed-mode update method cannot avoid inconsistencies. Ideally, it should appear to every client that a service update takes effect atomically; this ensures that a client is not exposed to inconsistent mixed-mode behavior. We introduce a framework that formalizes this intuition and develop foundational theory for reasoning about the consistency of mixed-mode updates, applying that theory to derive the new algorithms and establish their correctness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04829v1</guid>
      <category>cs.PL</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Devora Chait-Roth, Kedar S. Namjoshi, Thomas Wies</dc:creator>
    </item>
    <item>
      <title>Agnostics: Learning to Code in Any Programming Language via Reinforcement with a Universal Learning Environment</title>
      <link>https://arxiv.org/abs/2508.04865</link>
      <description>arXiv:2508.04865v1 Announce Type: cross 
Abstract: Large language models (LLMs) already excel at writing code in high-resource languages such as Python and JavaScript, yet stumble on low-resource languages that remain essential to science and engineering. Besides the obvious shortage of pre-training data, post-training itself is a bottleneck: every new language seems to require new datasets, test harnesses, and reinforcement-learning (RL) infrastructure.
  We introduce Agnostics, a language-agnostic post-training pipeline that eliminates this per-language engineering. The key idea is to judge code solely by its externally observable behavior, so a single verifier can test solutions written in any language. Concretely, we (i) use an LLM to rewrite existing unit-test datasets into an I/O format, (ii) supply a short configuration that tells the verifier how to compile and run a target language, and (iii) apply reinforcement learning with verifiable rewards (RLVR) in a robust code execution environment.
  Applied to five low-resource languages--Lua, Julia, R, OCaml, and Fortran--Agnostics (1) improves Qwen-3 4B to performance that rivals other 16B-70B open-weight models; (2) scales cleanly to larger and diverse model families (Qwen-3 8B, DeepSeek Coder 6.7B Instruct, Phi 4 Mini); and (3) for ${\le} 16$B parameter models, sets new state-of-the-art pass@1 results on MultiPL-E and a new multi-language version LiveCodeBench that we introduce.
  We will release the language-agnostic training datasets (Ag-MBPP-X, Ag-Codeforces-X, Ag-LiveCodeBench-X), training code, and ready-to-use configurations, making RL post-training in any programming language as simple as editing a short YAML file.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04865v1</guid>
      <category>cs.LG</category>
      <category>cs.PL</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aleksander Boruch-Gruszecki, Yangtian Zi, Zixuan Wu, Tejas Oberoi, Carolyn Jane Anderson, Joydeep Biswas, Arjun Guha</dc:creator>
    </item>
    <item>
      <title>Qunity: A Unified Language for Quantum and Classical Computing (Extended Version)</title>
      <link>https://arxiv.org/abs/2204.12384</link>
      <description>arXiv:2204.12384v5 Announce Type: replace 
Abstract: We introduce Qunity, a new quantum programming language designed to treat quantum computing as a natural generalization of classical computing. Qunity presents a unified syntax where familiar programming constructs can have both quantum and classical effects. For example, one can use sum types to implement the direct sum of linear operators, exception-handling syntax to implement projective measurements, and aliasing to induce entanglement. Further, Qunity takes advantage of the overlooked BQP subroutine theorem, allowing one to construct reversible subroutines from irreversible quantum algorithms through the uncomputation of "garbage" outputs. Unlike existing languages that enable quantum aspects with separate add-ons (like a classical language with quantum gates bolted on), Qunity provides a unified syntax and a novel denotational semantics that guarantees that programs are quantum mechanically valid. We present Qunity's syntax, type system, and denotational semantics, showing how it can cleanly express several quantum algorithms. We also detail how Qunity can be compiled into a low-level qubit circuit language like OpenQASM, proving the realizability of our design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2204.12384v5</guid>
      <category>cs.PL</category>
      <category>cs.LO</category>
      <category>quant-ph</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3571225</arxiv:DOI>
      <dc:creator>Finn Voichick, Liyi Li, Robert Rand, Michael Hicks</dc:creator>
    </item>
    <item>
      <title>Theorem-Carrying Transactions: Runtime Verification to Ensure Interface Specifications for Smart Contract Safety</title>
      <link>https://arxiv.org/abs/2408.06478</link>
      <description>arXiv:2408.06478v2 Announce Type: replace-cross 
Abstract: Security bugs and trapdoors in smart contracts have been impacting the Ethereum community since its inception. Conceptually, the 1.45-million Ethereum's contracts form a single "gigantic program" whose behaviors are determined by the complex compositions of contracts. Can programmers be assured that this gigantic program conforms to high-level safety specifications, despite unforeseeable code-level intricacies? Static code verification cannot be faithful to this gigantic program due to its scale and high polymorphism. In this paper, we present a viable approach to achieve this goal. Our technology, called Theorem-Carrying Transactions (TCT), combines the benefits of concrete execution and symbolic proofs. Under the TCT protocol, every transaction carries a theorem that proves its adherence to the specified properties in the invoked contracts, and the runtime system checks the theorem before executing the transaction. Once a theorem is proven, it will be reused for future transactions, so TCT's runtime overhead is minimal. As case studies, we demonstrate that TCT secures token contracts without foreseeing code-level intricacies, such as integer overflow and reentrancy. TCT is also successfully applied to a Uniswap codebase, showcasing a complex decentralized finance (DeFi) scenario. Our evaluation shows a negligible runtime overhead, two orders of magnitude lower than a state-of-the-art approach for runtime checking of contract code safety.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06478v2</guid>
      <category>cs.CR</category>
      <category>cs.PL</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas Ball (Microsoft Research), Nikolaj S. Bj{\o}rner (Microsoft Research), Ashley J. Chen (New York University Shanghai), Shuo Chen (Microsoft Research), Yang Chen (Microsoft Research), Zhongxin Guo (Microsoft Research), Tzu-Han Hsu (Michigan State University), Peng Liu (Pennsylvania State University), Nanqing Luo (Pennsylvania State University)</dc:creator>
    </item>
    <item>
      <title>From Code to Correctness: Closing the Last Mile of Code Generation with Hierarchical Debugging</title>
      <link>https://arxiv.org/abs/2410.01215</link>
      <description>arXiv:2410.01215v3 Announce Type: replace-cross 
Abstract: While large language models have made significant strides in code generation, the pass rate of the generated code is bottlenecked on subtle errors, often requiring human intervention to pass tests, especially for complex problems. Existing LLM-based debugging systems treat generated programs as monolithic units, failing to address bugs at multiple levels of granularity, from low-level syntax errors to high-level algorithmic flaws. In this paper, we introduce Multi-Granularity Debugger (MGDebugger), a hierarchical code debugger by isolating, identifying, and resolving bugs at various levels of granularity. MGDebugger decomposes problematic code into a hierarchical tree structure of subfunctions, with each level representing a particular granularity of error. During debugging, it analyzes each subfunction and iteratively resolves bugs in a bottom-up manner. To effectively test each subfunction, we propose an LLM-simulated Python executor, which traces code execution and tracks important variable states to pinpoint errors accurately. Extensive experiments demonstrate that MGDebugger outperforms existing debugging systems, achieving an 18.9% improvement in accuracy over seed generations in HumanEval and a 97.6% repair success rate in HumanEvalFix. Furthermore, MGDebugger effectively fixes bugs across different categories and difficulty levels, demonstrating its robustness and effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01215v3</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.PL</category>
      <category>cs.SE</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuling Shi, Songsong Wang, Chengcheng Wan, Min Wang, Xiaodong Gu</dc:creator>
    </item>
    <item>
      <title>Modular Reasoning about Error Bounds for Concurrent Probabilistic Programs (Extended Version)</title>
      <link>https://arxiv.org/abs/2503.04512</link>
      <description>arXiv:2503.04512v3 Announce Type: replace-cross 
Abstract: We present Coneris, the first higher-order concurrent separation logic for reasoning about error probability bounds of higher-order concurrent probabilistic programs with higher-order state. To support modular reasoning about concurrent (non-probabilistic) program modules, state-of-the-art program logics internalize the classic notion of linearizability within the logic through the concept of logical atomicity.
  Coneris extends this idea to probabilistic concurrent program modules. Thus Coneris supports modular reasoning about probabilistic concurrent modules by capturing a novel notion of randomized logical atomicity within the logic. To do so, Coneris utilizes presampling tapes and a novel probabilistic update modality to describe how state is changed probabilistically at linearization points. We demonstrate this approach by means of smaller synthetic examples and larger case studies.
  All of the presented results, including the meta-theory, have been mechanized in the Rocq proof assistant and the Iris separation logic framework
  This is the extended version of the same paper accepted at ICFP 2025, where more details of proofs and case studies are included in the Appendix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04512v3</guid>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Kwing Hei Li, Alejandro Aguirre, Simon Oddershede Gregersen, Philipp G. Haselwarter, Joseph Tassarotti, Lars Birkedal</dc:creator>
    </item>
  </channel>
</rss>
