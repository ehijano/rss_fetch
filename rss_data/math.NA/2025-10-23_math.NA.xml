<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 23 Oct 2025 04:01:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Cardiocirculatory Computational Models for the Study of Hypertension</title>
      <link>https://arxiv.org/abs/2510.19302</link>
      <description>arXiv:2510.19302v1 Announce Type: new 
Abstract: In this work, we develop patient-specific cardiocirculatory models with the aim of building Digital Twins for hypertension. In particular, in our pathophysiology-based framework, we consider both 0D cardiocirculatory models and a 3D-0D electromechanical model. The 0D model, which consists of an RLC circuit, is studied in two variants, with and without capillaries. The 3D-0D model consists of a three-dimensional electromechanical model of the left ventricle, coupled with a 0D model for the external blood circulation: this representation enables the assessment of additional quantities related to ventricular deformation and stress, and offers a more detailed representation compared to a fully 0D model. Sensitivity analysis is performed on the 0D model, with both a mono- and a multi-parametric approach, in order to identify the parameters that most influence the model outputs and guide the calibration process. We studied three different scenarios, corresponding to systemic, pulmonary and renovascular hypertension, each in three nuances of severity. To maintain a fair comparison among the models, a parameter calibration strategy is developed; the outputs of the 0D model with capillaries are utilized to enhance the 3D-0D model. The results demonstrate that the 3D-0D model yields an accurate representation of cardiocirculatory dynamics in the presence of hypertension; this model represents a powerful step toward digital twins for real-time hypertension control, providing refined and clinically meaningful insights beyond those achievable with 0D models alone.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19302v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simone Celora, Andrea Tonini, Francesco Regazzoni, Luca Dede', Gianfranco Parati, Alfio Quarteroni</dc:creator>
    </item>
    <item>
      <title>Energy dissipation and global convergence of a discrete normalized gradient flow for computing ground states of two-component Bose-Einstein condensates</title>
      <link>https://arxiv.org/abs/2510.19392</link>
      <description>arXiv:2510.19392v1 Announce Type: new 
Abstract: The gradient flow with semi-implicit discretization (GFSI) is the most widely used algorithm for computing the ground state of Gross-Pitaevskii energy functional. Numerous numerical experiments have shown that the energy dissipation holds when calculating the ground states of multicomponent Bose-Einstein condensates (MBECs) with GFSI, while rigorous proof remains an open challenge. By introducing a Lagrange multiplier, we reformulate the GFSI into an equivalent form and thereby prove the energy dissipation for GFSI in two-component scenario with Josephson junction and rotating term, which is one of the most important and topical model in MBECs. Based on this, we further establish the global convergence to stationary states. Also, the numerical results of energy dissipation in practical experiments corroborate our rigorous mathematical proof, and we numerically verified the upper bound of time step that guarantees energy dissipation is indeed related to the strength of particle interactions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19392v1</guid>
      <category>math.NA</category>
      <category>cond-mat.quant-gas</category>
      <category>cs.NA</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zixu Feng, Lunxu Liu, Qinglin Tang</dc:creator>
    </item>
    <item>
      <title>Interpolatory Dynamical Low-Rank Approximation: Theoretical Foundations and Algorithms</title>
      <link>https://arxiv.org/abs/2510.19518</link>
      <description>arXiv:2510.19518v1 Announce Type: new 
Abstract: Dynamical low-rank approximation (DLRA) is a widely used paradigm for solving large-scale matrix differential equations, as they arise, for example, from the discretization of time-dependent partial differential equations on tensorized domains. Through orthogonally projecting the dynamics onto the tangent space of a low-dimensional manifold, DLRA achieves a significant reduction of the storage required to represent the solution. However, the need for evaluating the velocity field can make it challenging to attain a corresponding reduction of computational cost in the presence of nonlinearities. In this work, we address this challenge by replacing orthogonal tangent space projections with oblique, data-sparse projections selected by a discrete empirical interpolation method (DEIM). At the continuous-time level, this leads to DLRA-DEIM, a well-posed differential inclusion (in the Filippov sense) that captures the discontinuities induced by changes in the indices selected by DEIM. We establish an existence result, exactness property and error bound for DLRA-DEIM that match existing results for DLRA. For the particular case of QDEIM, a popular variant of DEIM, we provide an explicit convex-polytope characterization of the differential inclusion. Building on DLRA-DEIM, we propose a new class of projected integrators, called PRK-DEIM, that combines explicit Runge--Kutta methods with DEIM-based projections. We analyze the convergence order of PRK-DEIM and show that it matches the accuracy of previously proposed projected Runge-Kutta methods, while being significantly cheaper. Extensions to exponential Runge--Kutta methods and low-order tensor differential equations demonstrate the versatility of our framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19518v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Benjamin Carrel, Daniel Kressner, Hei Yin Lam, Bart Vandereycken</dc:creator>
    </item>
    <item>
      <title>Non-intrusive structural-preserving sequential data assimilation</title>
      <link>https://arxiv.org/abs/2510.19701</link>
      <description>arXiv:2510.19701v1 Announce Type: new 
Abstract: Data assimilation (DA) methods combine model predictions with observational data to improve state estimation in dynamical systems, inspiring their increasingly prominent role in geophysical and climate applications. Classical DA methods assume that the governing equations modeling the dynamics are known, which is unlikely for most real world applications. Machine learning (ML) provides a flexible alternative by learning surrogate models directly from data, but standard ML methods struggle in noisy and data-scarce environments, where meaningful extrapolation requires incorporating physical constraints. Recent advances in structure-preserving ML architectures, such as the development of the entropy-stable conservative flux form network (ESCFN), highlight the critical role of physical structure in improving learning stability and accuracy for unknown systems of conservation laws. Structural information has also been shown to improve DA performance. Gradient-based measures of spatial variability, in particular, can help refine ensemble updates in discontinuous systems. Motivated by both of these recent innovations, this investigation proposes a new non-intrusive, structure-preserving sequential data assimilation (NSSDA) framework that leverages structure at both the forecast and analysis stages. We use the ESCFN to construct a surrogate model to preserve physical laws during forecasting, and a structurally informed ensemble transform Kalman filter (SETKF) to embed local statistical structure into the assimilation step. Our method operates in a highly constrained environment, using only a single noisy trajectory for both training and assimilation. Numerical experiments where the unknown dynamics correspond respectively to the shallow water and Euler equations demonstrate significantly improved predictive accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19701v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lizuo Liu, Tongtong Li, Anne Gelb</dc:creator>
    </item>
    <item>
      <title>Dictionary learning methods for brain activity mapping with MEG data</title>
      <link>https://arxiv.org/abs/2510.19702</link>
      <description>arXiv:2510.19702v1 Announce Type: new 
Abstract: A central goal in many brain studies is the identification of those brain regions that are activated during an observation window that may correspond to a motor task, a stimulus, or simply a resting state. While functional MRI is currently the most commonly employed modality for such task, methods based on the electromagnetic activity of the brain are valuable alternatives because of their excellent time resolution and of the fact that the measured signals are directly related to brain activation and not to a secondary effect such as the hemodynamic response. In this work we focus on the MEG modality, investigating the performance of a recently proposed Bayesian dictionary learning (BDL) algorithm for brain region identification. The partitioning of the source space into the 148 regions of interest (ROI) corresponding to parcellation of the Destrieux atlas provides a natural determination of the subdictionaries necessary for the BDL algorithm. We design a simulation protocol where a small randomly selected patch in each ROI is activated, the MEG signal is computed and the inverse problem of active brain region identification is solved using the BDL algorithm. The BDL algorithm consists of two phases, the first one comprising dictionary compression and Bayesian compression error analysis, and the second one performing dictionary coding with a deflated dictionary built on the output of the first phase, both steps relying on Bayesian sparsity promoting computations. For assessing the performance, we give a probabilistic interpretation of the confusion matrix, and consider different impurity measures for a multi-class classifier.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19702v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniela Calvetti, Erkki Somersalo</dc:creator>
    </item>
    <item>
      <title>An active-flux-type scheme for ideal MHD with provable positivity and discrete divergence-free property</title>
      <link>https://arxiv.org/abs/2510.19721</link>
      <description>arXiv:2510.19721v1 Announce Type: new 
Abstract: We develop a positivity-preserving (PP) PAMPA (Point-Average-Moment PolynomiAl-interpreted) scheme that enforces a discrete divergence-free (DDF) magnetic field for ideal MHD on Cartesian grids. Extending our 1D invariant-domain-preserving (IDP) PAMPA framework (Abgrall, Jiao, Liu, Wu, SIAM J. Sci. Comput., to appear) to multidimensional, multiwave MHD, the method combines a limiter-free PP update of interface point values via a new nonconservative reformulation with a local DDF projection. Cell averages are provably PP under a mild a~priori positivity condition on one cell-centered state, using: (i) DDF-constrained interface values, (ii) a PP limiter only at the cell center, (iii) a PP flux with appropriate wave-speed bounds, and (iv) a suitable discretization of the Godunov--Powell source term. The PP proof employs geometric quasi-linearization (GQL; Wu &amp; Shu, SIAM Review, 2023), which linearizes the pressure constraint. The scheme avoids explicit polynomial reconstructions, is compatible with arbitrarily high-order strong-stability-preserving (SSP) time integration, and is simple to implement. Robustness and resolution are enhanced by a problem-independent Lax-type entropy troubled-cell indicator using only two characteristic speeds and a convex oscillation elimination (COE) mechanism with a new intercell-difference norm. Tests -- including a blast wave with plasma $\beta \approx 2.51\times 10^{-6}$ and jets up to Mach $10^{4}$ -- show high-order accuracy, sharp MHD-structure resolution, and strong-shock robustness. To our knowledge, this is the first active-flux-type ideal-MHD method rigorously PP for both cell averages and interface point values while maintaining DDF throughout.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19721v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mengqing Liu, Dongwen Pang, Remi Abgrall, Kailiang Wu</dc:creator>
    </item>
    <item>
      <title>Extreme Event Aware ($\eta$-) Learning</title>
      <link>https://arxiv.org/abs/2510.19161</link>
      <description>arXiv:2510.19161v1 Announce Type: cross 
Abstract: Quantifying and predicting rare and extreme events persists as a crucial yet challenging task in understanding complex dynamical systems. Many practical challenges arise from the infrequency and severity of these events, including the considerable variance of simple sampling methods and the substantial computational cost of high-fidelity numerical simulations. Numerous data-driven methods have recently been developed to tackle these challenges. However, a typical assumption for the success of these methods is the occurrence of multiple extreme events, either within the training dataset or during the sampling process. This leads to accurate models in regions of quiescent events but with high epistemic uncertainty in regions associated with extremes. To overcome this limitation, we introduce Extreme Event Aware (e2a or eta) or $\eta$-learning which does not assume the existence of extreme events in the available data. $\eta$-learning reduces the uncertainty even in `uncharted' extreme event regions, by enforcing the extreme event statistics of an observable indicative of extremeness during training, which can be available through qualitative arguments or estimated with unlabeled data. This type of statistical regularization results in models that fit the observed data, while enforcing consistency with the prescribed observable statistics, enabling the generation of unprecedented extreme events even when the training data lack extremes therein. Theoretical results based on optimal transport offer a rigorous justification and highlight the optimality of the introduced method. Additionally, extensive numerical experiments illustrate the favorable properties of the $\eta$-learning framework on several prototype problems and real-world precipitation downscaling problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19161v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.NA</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kai Chang, Themistoklis P. Sapsis</dc:creator>
    </item>
    <item>
      <title>DARE: A Deformable Adaptive Regularization Estimator for Learning-Based Medical Image Registration</title>
      <link>https://arxiv.org/abs/2510.19353</link>
      <description>arXiv:2510.19353v1 Announce Type: cross 
Abstract: Deformable medical image registration is a fundamental task in medical image analysis. While deep learning-based methods have demonstrated superior accuracy and computational efficiency compared to traditional techniques, they often overlook the critical role of regularization in ensuring robustness and anatomical plausibility. We propose DARE (Deformable Adaptive Regularization Estimator), a novel registration framework that dynamically adjusts elastic regularization based on the gradient norm of the deformation field. Our approach integrates strain and shear energy terms, which are adaptively modulated to balance stability and flexibility. To ensure physically realistic transformations, DARE includes a folding-prevention mechanism that penalizes regions with negative deformation Jacobian. This strategy mitigates non-physical artifacts such as folding, avoids over-smoothing, and improves both registration accuracy and anatomical plausibility</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19353v1</guid>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahsan Raza Siyal, Markus Haltmeier, Ruth Steiger, Malik Galijasevic, Elke Ruth Gizewski, Astrid Ellen Grams</dc:creator>
    </item>
    <item>
      <title>Singular Value-based Atmospheric Tomography with Fourier Domain Regularization (SAFR)</title>
      <link>https://arxiv.org/abs/2510.19542</link>
      <description>arXiv:2510.19542v1 Announce Type: cross 
Abstract: Atmospheric tomography, the problem of reconstructing atmospheric turbulence profiles from wavefront sensor measurements, is an integral part of many adaptive optics systems. It is used to enhance the image quality of ground-based telescopes, such as for the Multiconjugate Adaptive Optics Relay For ELT Observations (MORFEO) instrument on the Extremely Large Telescope (ELT). To solve this problem, a singular-value decomposition (SVD) based approach has been proposed before. In this paper, we focus on the numerical implementation of the SVD-based Atmospheric Tomography with Fourier Domain Regularization Algorithm (SAFR) and its performance for Multi-Conjugate Adaptive Optics (MCAO) systems. The key features of the SAFR algorithm are the utilization of the FFT and the pre-computation of computationally demanding parts. Together, this yields a fast algorithm with less memory requirements than commonly used Matrix Vector Multiplication (MVM) approaches. We evaluate the performance of SAFR regarding reconstruction quality and computational expense in numerical experiments using the simulation environment COMPASS, in which we use an MCAO setup resembling the physical parameters of the MORFEO instrument of the ELT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19542v1</guid>
      <category>astro-ph.IM</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lukas Weissinger, Simon Hubmer, Bernadett Stadler, Ronny Ramlau</dc:creator>
    </item>
    <item>
      <title>On an adjoint-based numerical approach for time-dependent optimal control problems of biomedical interest</title>
      <link>https://arxiv.org/abs/2510.19576</link>
      <description>arXiv:2510.19576v1 Announce Type: cross 
Abstract: This work develops a rigorous numerical framework for solving time-dependent Optimal Control Problems (OCPs) governed by partial differential equations, with a particular focus on biomedical applications. The approach deals with adjoint-based Lagrangian methodology, which enables efficient gradient computation and systematic derivation of optimality conditions for both distributed and concentrated control formulations. The proposed framework is first verified using a time-dependent advection-diffusion problem endowed with a manufactured solution to assess accuracy and convergence properties. Subsequently, two representative applications involving drug delivery are investigated: (i) a light-triggered drug delivery system for targeted cancer therapy and (ii) a catheter-based drug delivery system in a patient-specific coronary artery. Numerical experiments not only demonstrate the accuracy of the approach, but also its flexibility and robustness in handling complex geometries, heterogeneous parameters, and realistic boundary conditions, highlighting its potential for the optimal design and control of complex biomedical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19576v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zahra Mirzaiyan, Pierfrancesco Siena, Pasquale Claudio Africa, Michele Girfoglio, Gianluigi Rozza</dc:creator>
    </item>
    <item>
      <title>Matrix-Free Least Squares Solvers: Values, Gradients, and What to Do With Them</title>
      <link>https://arxiv.org/abs/2510.19634</link>
      <description>arXiv:2510.19634v1 Announce Type: cross 
Abstract: This paper argues that the method of least squares has significant unfulfilled potential in modern machine learning, far beyond merely being a tool for fitting linear models. To release its potential, we derive custom gradients that transform the solver into a differentiable operator, like a neural network layer, enabling many diverse applications. Empirically, we demonstrate: (i) scalability by enforcing weight sparsity on a 50 million parameter model; (ii) imposing conservativeness constraints in score-based generative models; and (iii) hyperparameter tuning of Gaussian processes based on predictive performance. By doing this, our work represents the next iteration in developing differentiable linear-algebra tools and making them widely accessible to machine learning practitioners.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19634v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hrittik Roy, S{\o}ren Hauberg, Nicholas Kr\"amer</dc:creator>
    </item>
    <item>
      <title>T2 mapping at 0.55 T using Ultra-Fast Spin Echo MRI</title>
      <link>https://arxiv.org/abs/2510.19680</link>
      <description>arXiv:2510.19680v1 Announce Type: cross 
Abstract: Low-field T2 mapping MRI can democratize neuropediatric imaging by improving accessibility and providing quantitative biomarkers of brain development. \textbf{Purpose:} To evaluate the feasibility of high-resolution T2 mapping using a single-shot fast spin-echo (SS-FSE) sequence at 0.55~T in a healthy control cohort. \textbf{Study Type:} Prospective single-center study. \textbf{Population:} In vivo: ten healthy adults (18--43~years, 5 females/5 males). In vitro: NIST Phantom. \textbf{Field strength/sequence:} Multi-echo ultra-fast spin-echo at 0.55~T and 1.5~T. \textbf{Assessment:} Feasibility was first assessed in vitro using the NIST Phantom, comparing T2 relaxation times to spectrometer references at 0.55~T. Acquisition and T2-fitting parameters optimized in vitro were applied in vivo. Repeatability was evaluated by atlas-based analysis of white matter (WM) and cortical grey matter (GM) regions. Coefficients of variation (CoV) were computed across runs, sessions, and subjects. \textbf{Statistical Tests:} Wilcoxon signed-rank test with Bonferroni correction ($\alpha = 0.05/n_{ROI}$) assessed CoV differences. Pearson correlation coefficients quantified T2 associations. \textbf{Results:} In vitro, mono-exponential fitting under Gaussian--Rician noise yielded deviations $&lt;12\%$ from reference values. In vivo, inter-subject CoV was 5.2\% (WM) and 17.7\% (GM), comparable to 1.5~T. Mean T2 times were 118~ms (WM) and 188~ms (GM) at 0.55~T, with a 16.5-minute acquisition. \textbf{Conclusion:} A rapid, robust high-resolution T2 mapping protocol at 0.55~T for HASTE MRI is presented, employing Gaussian noise-based fitting. We report the first normative T2 values for healthy adult brains at 0.55~T, demonstrating technical feasibility and reliability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19680v1</guid>
      <category>physics.app-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Margaux Roulet, Hamza Kebiri, Busra Bulut, Vladyslav Zalevskyi, Thomas Sanchez, Jean-Baptiste Ledoux, Vincent Dunet, M\'eriam Koob, Tom Hilbert, Tobias Kober, Erick J Canales-Rodriguez, Meritxell Bach Cuadra</dc:creator>
    </item>
    <item>
      <title>The Generalized Matrix Norm Problem</title>
      <link>https://arxiv.org/abs/2310.00605</link>
      <description>arXiv:2310.00605v4 Announce Type: replace 
Abstract: We study the computability of the operator norm of a matrix with respect to norms induced by linear operators. Our findings reveal that this problem can be solved exactly in polynomial time in certain situations, and we discuss how it can be approximated in other cases. Along the way, we investigate the concept of push-forward and pull-back of seminorms, which leads us to uncover novel duality principles that come into play when optimizing over the unit ball of norms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.00605v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1137/23M1605545</arxiv:DOI>
      <arxiv:journal_reference>SIAM Journal on Matrix Analysis and Applications, Vol. 46, Iss. 4 (2025)</arxiv:journal_reference>
      <dc:creator>Adrian Kulmburg</dc:creator>
    </item>
    <item>
      <title>Asymptotic-preserving IMEX schemes for the Euler equations of non-ideal gases</title>
      <link>https://arxiv.org/abs/2402.09252</link>
      <description>arXiv:2402.09252v4 Announce Type: replace 
Abstract: We analyze schemes based on a general Implicit-Explicit (IMEX) time discretization for the compressible Euler equations of gas dynamics, showing that they are asymptotic-preserving (AP) in the low Mach number limit. The analysis is carried out for a general equation of state (EOS). We consider both a single asymptotic length scale and two length scales. We then show that, when coupling these time discretizations with a Discontinuous Galerkin (DG) space discretization with appropriate fluxes, a numerical method effective for a wide range of Mach numbers is obtained. A number of benchmarks for ideal gases and their non-trivial extension to non-ideal EOS validate the performed analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.09252v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jcp.2025.113889</arxiv:DOI>
      <arxiv:journal_reference>Journal of Computational Physics 529 (2025): 113889</arxiv:journal_reference>
      <dc:creator>Giuseppe Orlando, Luca Bonaventura</dc:creator>
    </item>
    <item>
      <title>Error Bounds for Open Quantum Systems with Harmonic Bosonic Bath</title>
      <link>https://arxiv.org/abs/2408.04009</link>
      <description>arXiv:2408.04009v3 Announce Type: replace 
Abstract: We investigate the dependence of physical observable of open quantum systems with Bosonic bath on the bath correlation function. We provide an error estimate of the difference of physical observable induced by the variation of bath correlation function, based on diagrammatic and combinatorial arguments. This gives a mathematically rigorous justification of the result in [Mascherpa et al, Phys Rev Lett 2017].</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04009v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>quant-ph</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kaizhao Liu, Jianfeng Lu</dc:creator>
    </item>
    <item>
      <title>Efficient and scalable atmospheric dynamics simulations using non-conforming meshes</title>
      <link>https://arxiv.org/abs/2408.08129</link>
      <description>arXiv:2408.08129v3 Announce Type: replace 
Abstract: We present the massively parallel performance of a $h$-adaptive solver for atmosphere dynamics that allows for non-conforming mesh refinement. The numerical method is based on a Discontinuous Galerkin (DG) spatial discretization, highly scalable thanks to its data locality properties, and on a second order Implicit-Explicit Runge-Kutta (IMEX-RK) method for time discretization, particularly well suited for low Mach number flows. Simulations with non-conforming meshes for flows over orography can increase the accuracy of the local flow description without affecting the larger scales, which can be solved on coarser meshes. We show that the local refining procedure has no significant impact on the parallel performance and, therefore, both efficiency and scalability can be achieved in this framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08129v3</guid>
      <category>math.NA</category>
      <category>cs.DC</category>
      <category>cs.NA</category>
      <category>cs.PF</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.procs.2025.02.258</arxiv:DOI>
      <arxiv:journal_reference>Procedia Computer Science 255 (2025): 33-42</arxiv:journal_reference>
      <dc:creator>Giuseppe Orlando, Tommaso Benacchio, Luca Bonaventura</dc:creator>
    </item>
    <item>
      <title>Computer-assisted proofs for finding the monodromy of Picard-Fuchs differential equations for a family of K3 toric hypersurfaces</title>
      <link>https://arxiv.org/abs/2501.03792</link>
      <description>arXiv:2501.03792v2 Announce Type: replace 
Abstract: In this paper, we present a numerical method for rigorously finding the monodromy of linear differential equations. Beginning at a base point where certain particular solutions are explicitly given by series expansions, we first compute the value of fundamental system of solutions using interval arithmetic to rigorously control truncation and rounding errors. The solutions are then analytically continued along a prescribed contour encircling the singular points of the differential equation via a rigorous integrator. From these computations, the monodromy matrices are derived, generating the monodromy group of the differential equation. This method establishes a mathematically rigorous framework for addressing the monodromy problem in differential equations. For a notable example, we apply our computer-assisted proof method to resolve the monodromy problem for a Picard--Fuchs differential equation associated with a family of K3 toric hypersurfaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03792v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AG</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cnsns.2025.109408</arxiv:DOI>
      <dc:creator>Toshimasa Ishige, Akitoshi Takayasu</dc:creator>
    </item>
    <item>
      <title>A quantitative comparison of high-order asymptotic-preserving and asymptotically-accurate IMEX methods for the Euler equations with non-ideal gases</title>
      <link>https://arxiv.org/abs/2501.12733</link>
      <description>arXiv:2501.12733v5 Announce Type: replace 
Abstract: We present a quantitative comparison between two different Implicit-Explicit Runge-Kutta (IMEX-RK) approaches for the Euler equations of gas dynamics, specifically tailored for the low Mach limit. In this regime, a classical IMEX-RK approach involves an implicit coupling between the momentum and energy balance so as to avoid the acoustic CFL restriction, while the density can be treated in a fully explicit fashion. This approach leads to a mildly nonlinear equation for the pressure, which can be solved according to a fixed point procedure. An alternative strategy consists of employing a semi-implicit temporal integrator based on IMEX-RK methods (SI-IMEX-RK). The stiff dependence is carefully analyzed, so as to avoid the solution of a nonlinear equation for the pressure also for equations of state (EOS) of non-ideal gases. The spatial discretization is based on a Discontinuous Galerkin (DG) method, which naturally allows high-order accuracy. The asymptotic-preserving (AP) and the asymptotically-accurate (AA) properties of the two approaches are assessed on a number of classical benchmarks for ideal gases and on their extension to non-ideal gases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12733v5</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cma.2025.118037</arxiv:DOI>
      <arxiv:journal_reference>Computer Methods in Applied Mechanics and Engineering 442 (2025): 118037</arxiv:journal_reference>
      <dc:creator>Giuseppe Orlando, Sebastiano Boscarino, Giovanni Russo</dc:creator>
    </item>
    <item>
      <title>Localized Dynamic Mode Decomposition with Temporally Adaptive Segmentation</title>
      <link>https://arxiv.org/abs/2503.13093</link>
      <description>arXiv:2503.13093v2 Announce Type: replace 
Abstract: Dynamic mode decomposition (DMD) is a widely used data-driven algorithm for predicting the future states of dynamical systems. However, its standard formulation often struggles with poor long-term predictive accuracy. To address this limitation, we propose a localized DMD (LDMD) framework that improves prediction performance by integrating DMD's strong linear forecasting capabilities with time-domain segmentation techniques. In this framework, the temporal domain is segmented into multiple subintervals, within which snapshot matrices are constructed and localized predictions are performed. We first present the localized DMD method with predefined segmentation, and then explore an adaptive segmentation strategy to further enhance computational efficiency and prediction robustness. Furthermore, we conduct an error analysis that provides the upper bound of the local and global truncation error for the proposed framework. The effectiveness of LDMD is demonstrated on four benchmark problems-Burgers', Allen-Cahn, nonlinear Schrodinger, and Maxwell's equations. Numerical results show that LDMD significantly enhances long-term predictive accuracy while preserving high computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13093v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiuqi Li, Chang Liu, Yifei Yang</dc:creator>
    </item>
    <item>
      <title>Explicit error bounds and guaranteed convergence of the Koopman-Hill projection stability method for linear time-periodic dynamics</title>
      <link>https://arxiv.org/abs/2503.21318</link>
      <description>arXiv:2503.21318v2 Announce Type: replace 
Abstract: The Koopman-Hill projection method offers an efficient approach for stability analysis of linear time-periodic systems, and thereby also for the Floquet stability analysis of periodic solutions of nonlinear systems. However, its accuracy has previously been supported only by numerical evidence, lacking rigorous theoretical guarantees. This paper presents the first explicit error bound for the truncation error of the Koopman-Hill projection method, establishing a solid theoretical foundation for its application. The bound applies to linear time-periodic systems whose Fourier coefficients decay exponentially with a sufficient rate, and is derived using constructive series expansions. The bound quantifies the difference between the true and approximated fundamental solution matrices, clarifies conditions for guaranteed convergence, and enables conservative but reliable inference of Floquet multipliers and stability properties. Additionally, the same methodology applied to a subharmonic formulation demonstrates improved convergence rates of the latter. Numerical examples, including the Mathieu equation and the Duffing oscillator, illustrate the practical relevance of the bound and underscore its importance as the first rigorous theoretical justification for the Koopman-Hill projection method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21318v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabia Bayer, Remco I. Leine</dc:creator>
    </item>
    <item>
      <title>Trajectory learning for ensemble forecasts via the continuous ranked probability score: a Lorenz '96 case study</title>
      <link>https://arxiv.org/abs/2508.21664</link>
      <description>arXiv:2508.21664v2 Announce Type: replace 
Abstract: This paper demonstrates the feasibility of trajectory learning for ensemble forecasts by employing the continuous ranked probability score (CRPS) as a loss function. Using the two-scale Lorenz '96 system as a case study, we develop and train both additive and multiplicative stochastic parametrizations to generate ensemble predictions. Results indicate that CRPS-based trajectory learning produces parametrizations that are both accurate and sharp. The resulting parametrizations are straightforward to calibrate and outperform derivative-fitting-based parametrizations in short-term forecasts. This approach is particularly promising for data assimilation applications due to its accuracy over short lead times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21664v2</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sagy Ephrati, James Woodfield</dc:creator>
    </item>
    <item>
      <title>Error analysis of a fully discrete structure-preserving finite element scheme for a diffuse-interface model of tumour growth</title>
      <link>https://arxiv.org/abs/2509.14486</link>
      <description>arXiv:2509.14486v2 Announce Type: replace 
Abstract: We develop a linear fully discrete structure-preserving finite element method for a diffuse-interface model of tumour growth. The system couples a Cahn--Hilliard type equation with a nonlinear reaction-diffusion equation for nutrient concentration and admits a dissipative energy law at the continuous level. For the discretisation, we employ a scalar auxiliary variable (SAV) formulation together with a mixed finite element method for the Cahn--Hilliard part and standard conforming finite elements for the reaction-diffusion equation in space, combined with a first-order Euler time-stepping scheme. The resulting method is unconditionally energy-stable, mass-preserving, and inherits a discrete energy dissipation law associated with the SAV-based approximate energy functional, while requiring the solution of only linear systems at each time step. Under suitable regularity assumptions on the exact solution, we derive rigorous error estimates in $L^2$, $H^1$, and $L^\infty$ norms, establishing first-order accuracy in time and optimal-order accuracy in space. A key step in this analysis is the proof of boundedness of the numerical solutions in $L^\infty$. Numerical experiments validate the theoretical convergence rates and demonstrate the robustness of the method in capturing characteristic phenomena such as aggregation and chemotactic tumour growth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14486v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Agus L. Soenjaya, Ping Lin, Thanh Tran</dc:creator>
    </item>
    <item>
      <title>LDMD with Temporally Adaptive Segmentation</title>
      <link>https://arxiv.org/abs/2510.08065</link>
      <description>arXiv:2510.08065v2 Announce Type: replace 
Abstract: Dynamic mode decomposition (DMD) is a widely used data-driven algorithm for predicting the future states of dynamical systems. However, its standard formulation often struggles with poor long-term predictive accuracy. To address this limitation, we propose a localized DMD (LDMD) framework that improves prediction performance by integrating DMD's strong linear forecasting capabilities with time-domain segmentation techniques. In this framework, the temporal domain is segmented into multiple subintervals, within which snapshot matrices are constructed and localized predictions are performed. We first present the localized DMD method with predefined segmentation, and then explore an adaptive segmentation strategy to further enhance computational efficiency and prediction robustness. Furthermore, we conduct an error analysis that provides the upper bound of the local and global truncation error for the proposed framework. The effectiveness of LDMD is demonstrated on four benchmark problems-Burgers', Allen-Cahn, nonlinear Schrodinger, and Maxwell's equations. Numerical results show that LDMD significantly enhances long-term predictive accuracy while preserving high computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08065v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiuqi Li, Chang Liu, Yifei Yang</dc:creator>
    </item>
    <item>
      <title>Is simplicity still possible for a more accurate approximation to the perimeter of the ellipse? or, Using the exponential function to further improve the second Ramanujan's approximation</title>
      <link>https://arxiv.org/abs/2510.16191</link>
      <description>arXiv:2510.16191v2 Announce Type: replace 
Abstract: The perimeter of an ellipse has no exact closed-form expression in terms of elementary functions, and numerous approximations have been proposed since the eighteenth century. Classical formulas by Fagnano, Euler, and Ramanujan, as well as modern refinements such as Cantrell and Koshy methods, aim to reduce the approximation error while maintaining computational simplicity. In this paper, we introduce a new closed-form expression that enhances Ramanujan second formula by dividing it by 1 minus a binomial of two exponential terms resulting in a very stable approximation in a range of b/a between 1 and 1/10000, or even up to a smaller ratio. The resulting approximation remains compact, requiring only four constants, and achieving a remarkable tradeoff between simplicity and accuracy. Across the full eccentricity range of b/a in [0.0001,1], our method attains a maximum relative error of approximately 0.57 ppm with respect to the exact perimeter computed via elliptic integral. Our formula is quasi-exact at the extremes, for the circle b/a=1 and for the degenerate flat ellipse b/a=0. Compared with Cantrell approximation, the proposed method reduces the maximum relative error by a factor of 25 while preserving a short and elegant expression. This makes it one of the simplest yet most accurate closed-form and single-line approximations to the ellipse perimeter currently available in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16191v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Salvador E. Ayala-Raggi, Manuel Rend\'on-Mar\'in</dc:creator>
    </item>
    <item>
      <title>Efficient Tensor Completion Algorithms for Highly Oscillatory Operators</title>
      <link>https://arxiv.org/abs/2510.17734</link>
      <description>arXiv:2510.17734v2 Announce Type: replace 
Abstract: This paper presents low-complexity tensor completion algorithms and their efficient implementation to reconstruct highly oscillatory operators discretized as $n\times n$ matrices. The underlying tensor decomposition is based on the reshaping of the input matrix and its butterfly decomposition into an order $O (\log n)$ tensor. The reshaping of the input matrix into a tensor allows for representation of the butterfly decomposition as a tensor decomposition with dense tensors. This leads to efficient utilization of the existing software infrastructure for dense and sparse tensor computations. We propose two tensor completion algorithms in the butterfly format, using alternating least squares and gradient-based optimization, as well as a novel strategy that uses low-rank matrix completion to efficiently generate an initial guess for the proposed algorithms. To demonstrate the efficiency and applicability of our proposed algorithms, we perform three numerical experiments using simulated oscillatory operators in seismic applications. In these experiments, we use $O (n \log n)$ observed entries in the input matrix and demonstrate an $O(n\log^3 n)$ computational cost of the proposed algorithms, leading to a speedup of orders of magnitudes per iteration for large matrices compared to the low-rank matrix and quantized tensor-train completion. Moreover, the proposed butterfly completion algorithms, equipped with the novel initial guess generation strategy, achieve reconstruction errors that are smaller by an order of magnitude, enabling accurate recovery of the underlying structure compared to the state-of-the-art completion algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17734v2</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Navjot Singh, Edgar Solomonik, Xiaoye Sherry Li, Yang Liu</dc:creator>
    </item>
    <item>
      <title>Entrywise Approximation for Matrix Inversion and Linear Systems</title>
      <link>https://arxiv.org/abs/2504.19054</link>
      <description>arXiv:2504.19054v2 Announce Type: replace-cross 
Abstract: We study the bit complexity of inverting diagonally dominant matrices, which are associated with random walk quantities such as hitting times and escape probabilities. Such quantities can be exponentially small, even on undirected unit-weighted graphs. However, their nonnegativity suggests that they can be approximated entrywise, leading to a stronger notion of approximation than vector norm-based error.
  Under this notion of error, existing Laplacian solvers and fast matrix multiplication approaches have bit complexities of $mn^2$ and $n^{\omega+1}$, respectively, where $m$ is the number of nonzero entries in the matrix, $n$ is its size, and $\omega$ is the matrix multiplication exponent.
  We present algorithms that compute entrywise $\exp(\epsilon)$-approximate inverses of row diagonally dominant $L$-matrices (RDDL) in two settings: (1) when the matrix entries are given in floating-point representation; (2) when they are given in fixed-point representation.
  For floating-point inputs, we present a cubic-time algorithm and show that it has an optimal running time under the all-pairs shortest paths (APSP) conjecture.
  For fixed-point inputs, we present several algorithms for solving linear systems and inverting RDDL and SDDM matrices, all with high probability.
  Omitting logarithmic factors:
  (1) For SDDM matrices, we provide an algorithm for solving a linear system with entrywise approximation guarantees using $\tilde{O}(m\sqrt{n})$ bit operations, and another for computing an entrywise approximate inverse using $\tilde{O}(mn)$ bit operations.
  (2) For RDDL matrices, we present an algorithm for solving a linear system using $\tilde{O}(mn^{1+o(1)})$ bit operations, and two algorithms for computing an entrywise approximate inverse: one using $\tilde{O}(n^{\omega+0.5})$ bit operations, and the other using $\tilde{O}(mn^{1.5+o(1)})$ bit operations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19054v2</guid>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>An extended abstract is published in SODA 2026</arxiv:journal_reference>
      <dc:creator>Mehrdad Ghadiri, Hoai-An Nguyen, Junzhao Yang</dc:creator>
    </item>
    <item>
      <title>A meshless method for computational electromagnetics with improved dispersion properties</title>
      <link>https://arxiv.org/abs/2508.18205</link>
      <description>arXiv:2508.18205v2 Announce Type: replace-cross 
Abstract: The finite difference time domain method is one of the simplest and most popular methods in computational electromagnetics. This work considers two possible ways of generalising it to a meshless setting by employing local radial basis function interpolation. The resulting methods remain fully explicit and are convergent if properly chosen hyperviscosity terms are added to the update equations. We demonstrate that increasing the stencil size of the approximation has a desirable effect on numerical dispersion. Furthermore, our proposed methods can exhibit a decreased dispersion anisotropy compared to the finite difference time domain method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18205v2</guid>
      <category>physics.comp-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrej Kolar-Po\v{z}un, Gregor Kosec</dc:creator>
    </item>
    <item>
      <title>Time-causal and time-recursive wavelets</title>
      <link>https://arxiv.org/abs/2510.05834</link>
      <description>arXiv:2510.05834v3 Announce Type: replace-cross 
Abstract: When to apply wavelet analysis to real-time temporal signals, where the future cannot be accessed, it is essential to base all the steps in the signal processing pipeline on computational mechanisms that are truly time-causal.
  This paper describes how a time-causal wavelet analysis can be performed based on concepts developed in the area of temporal scale-space theory, originating from a complete classification of temporal smoothing kernels that guarantee non-creation of new structures from finer to coarser temporal scale levels. By necessity, convolution with truncated exponential kernels in cascade constitutes the only permissable class of kernels, as well as their temporal derivatives as a natural complement to fulfil the admissibility conditions of wavelet representations. For a particular way of choosing the time constants in the resulting infinite convolution of truncated exponential kernels, to ensure temporal scale covariance and thus self-similarity over temporal scales, we describe how mother wavelets can be chosen as temporal derivatives of the resulting time-causal limit kernel.
  By developing connections between wavelet theory and scale-space theory, we characterize and quantify how the continuous scaling properties transfer to the discrete implementation, demonstrating how the proposed time-causal wavelet representation can reflect the duration of locally dominant temporal structures in the input signals.
  We propose that this notion of time-causal wavelet analysis could be a valuable tool for signal processing tasks, where streams of signals are to be processed in real time, specifically for signals that may contain local variations over a rich span of temporal scales, or more generally for analysing physical or biophysical temporal phenomena, where a fully time-causal analysis is called for to be physically realistic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05834v3</guid>
      <category>eess.SP</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.IV</category>
      <category>eess.SY</category>
      <category>math.NA</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tony Lindeberg</dc:creator>
    </item>
  </channel>
</rss>
