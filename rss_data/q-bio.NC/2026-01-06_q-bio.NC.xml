<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 07 Jan 2026 02:34:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 06 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Biologically Plausible Dense Associative Memory with Exponential Capacity</title>
      <link>https://arxiv.org/abs/2601.00984</link>
      <description>arXiv:2601.00984v1 Announce Type: new 
Abstract: Krotov and Hopfield (2021) proposed a biologically plausible two-layer associative memory network with memory storage capacity exponential in the number of visible neurons. However, the capacity was only linear in the number of hidden neurons. This limitation arose from the choice of nonlinearity between the visible and hidden units, which enforced winner-takes-all dynamics in the hidden layer, thereby restricting each hidden unit to encode only a single memory. We overcome this limitation by introducing a novel associative memory network with a threshold nonlinearity that enables distributed representations. In contrast to winner-takes-all dynamics, where each hidden neuron is tied to an entire memory, our network allows hidden neurons to encode basic components shared across many memories. Consequently, complex patterns are represented through combinations of hidden neurons. These representations reduce redundancy and allow many correlated memories to be stored compositionally. Thus, we achieve much higher capacity: exponential in the number of hidden units, provided the number of visible units is sufficiently larger than the number of hidden neurons. Exponential capacity arises because all binary states of the hidden units can become stable memory patterns with an appropriately chosen threshold. Moreover, the distributed hidden representation, which has much lower dimensionality than the visible layer, preserves class-discriminative structure, supporting efficient nonlinear decoding. These results establish a new regime for associative memory, enabling high-capacity, robust, and scalable architectures consistent with biological constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00984v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 06 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohadeseh Shafiei Kafraj, Dmitry Krotov, Peter E. Latham</dc:creator>
    </item>
    <item>
      <title>From Theory of Mind to Theory of Environment: Counterfactual Simulation of Latent Environmental Dynamics</title>
      <link>https://arxiv.org/abs/2601.01599</link>
      <description>arXiv:2601.01599v1 Announce Type: new 
Abstract: The vertebrate motor system employs dimensionality-reducing strategies to limit the complexity of movement coordination, for efficient motor control. But when environments are dense with hidden action-outcome contingencies, movement complexity can promote behavioral innovation. Humans, perhaps uniquely, may infer the presence of hidden environmental dynamics from social cues, by drawing upon computational mechanisms shared with Theory of Mind. This proposed "Theory of Environment" supports behavioral innovation by expanding the dimensionality of motor exploration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.01599v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 06 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryutaro Uchiyama</dc:creator>
    </item>
    <item>
      <title>Insular intracranial activity identifies multiple facial expressions via diverse, intermixed temporal patterns at the single-contact level</title>
      <link>https://arxiv.org/abs/2601.01782</link>
      <description>arXiv:2601.01782v1 Announce Type: new 
Abstract: How neural representations in the insular cortex support emotional processing remains poorly understood, and the extent to which the insula is specialized for disgust processing remains debated. We recorded stereoelectroencephalography data from the insula while human subjects with implanted electrode contacts performed a facial emotion recognition task involving disgusted, fearful, angry, sad, neutral, and happy expressions. Expression category specificity of insular activity was assessed via pairwise comparisons of within- and between-category pattern similarities, capturing both the shape and scale of event-related potentials (ERPs) and event-related spectral perturbations (ERSPs; theta to high-gamma frequency ranges). Insular activity successfully identified all investigated expressions, mediated by diverse ERP responses intermixed across the insula. In contrast to the marked heterogeneity of insula ERP responses, the fusiform face area exhibited convergent ERP responses across expressions and contacts, with ERSPs also contributing substantially to expression identification. These findings not only elucidate the insula's neural mechanisms underlying facial emotion perception, but also establish a potential single-contact-level neural substrate for how the insula leverages its heterogeneous response profiles to act as a key hub for versatile cognitive and emotional functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.01782v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 06 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yingyu Huang, Lisen Sui, Liying Zhan, Chaolun Wang, Zhihan Guo, Yanjuan Li, Xiang Wu</dc:creator>
    </item>
    <item>
      <title>A neural network for modeling human concept formation, understanding and communication</title>
      <link>https://arxiv.org/abs/2601.02010</link>
      <description>arXiv:2601.02010v1 Announce Type: new 
Abstract: A remarkable capability of the human brain is to form more abstract conceptual representations from sensorimotor experiences and flexibly apply them independent of direct sensory inputs. However, the computational mechanism underlying this ability remains poorly understood. Here, we present a dual-module neural network framework, the CATS Net, to bridge this gap. Our model consists of a concept-abstraction module that extracts low-dimensional conceptual representations, and a task-solving module that performs visual judgement tasks under the hierarchical gating control of the formed concepts. The system develops transferable semantic structure based on concept representations that enable cross-network knowledge transfer through conceptual communication. Model-brain fitting analyses reveal that these emergent concept spaces align with both neurocognitive semantic model and brain response structures in the human ventral occipitotemporal cortex, while the gating mechanisms mirror that in the semantic control brain network. This work establishes a unified computational framework that can offer mechanistic insights for understanding human conceptual cognition and engineering artificial systems with human-like conceptual intelligence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.02010v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <pubDate>Tue, 06 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Liangxuan Guo, Haoyang Chen, Yang Chen, Yanchao Bi, Shan Yu</dc:creator>
    </item>
    <item>
      <title>How much neuroscience does a neuroscientist need to know?</title>
      <link>https://arxiv.org/abs/2601.02063</link>
      <description>arXiv:2601.02063v1 Announce Type: new 
Abstract: How much of the brain's learned algorithms depend on the fact it is a brain? We argue: a lot, but surprisingly few details matter. We point to simple biological details -- e.g. nonnegative firing and energetic/space budgets in connectionist architectures -- which, when mixed with the requirements of solving a task, produce models that predict brain responses down to single-neuron tuning. We understand this as details constraining the set of plausible algorithms, and their implementations, such that only `brain-like' algorithms are learned. In particular, each biological detail breaks a symmetry in connectionist models (scale, rotation, permutation) leading to interpretable single-neuron responses that are meaningfully characteristic of particular algorithms. This view helps us not only understand the brain's choice of algorithm but also infer algorithm from measured neural responses. Further, this perspective aligns computational neuroscience with mechanistic interpretability in AI, suggesting a more unified approach to studying the mechanisms of intelligence, both natural and artificial.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.02063v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 06 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James C. R. Whittington, William Dorrell</dc:creator>
    </item>
    <item>
      <title>Responses of the Neurobiological Craving Signature to smoking versus alternative social rewards predict craving and monthly smoking in adolescents</title>
      <link>https://arxiv.org/abs/2601.02143</link>
      <description>arXiv:2601.02143v1 Announce Type: new 
Abstract: Smoking remains the leading cause of preventable mortality worldwide. Adolescents are particularly vulnerable to the development of tobacco addiction due to ongoing brain maturation and susceptibility to social influences, such as exposure to environmental tobacco smoke (ETS). Craving -the strong desire to use drugs -already emerges with non-daily tobacco use and predicts continued use and relapse. However, the roles of craving and ETS exposure during the early stages of tobacco use in adolescence remain poorly understood. In this pre-registered study, we harness a recently developed fMRI marker of craving -the Neurobiological Craving Signature (NCS) -to compare craving-related brain responses to smoking versus social cues in adolescent Experimental Smokers (N=100) and Non-smokers (N=48) with varying levels of ETS exposure levels. Results showed that NCS responses to smoking cues compared to alternative social rewards were higher in Experimental Smokers compared to Non-smokers and predicted individual differences in self-reported craving and monthly smoking. Both smoking behavior and NCS responses were correlated with the relative amount of ETS exposure from peers compared to exposure from family members. Together, these findings indicate a heightened sensitivity of craving-related brain circuits already during experimental smoking and highlight the important role of peer social norms on craving and smoking initiation in the critical period of adolescence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.02143v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 06 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maddalena Tamellini (CRNL-SOCIALHEALTH), Joyce Dieleman (CRNL-PSYR2, CRNL), Guillaume Sescousse (CRNL-PSYR2, CRNL), Maartje Luijten (CRNL-SOCIALHEALTH), Leonie Koban (CRNL-SOCIALHEALTH)</dc:creator>
    </item>
    <item>
      <title>Unveiling the Heart-Brain Connection: An Analysis of ECG in Cognitive Performance</title>
      <link>https://arxiv.org/abs/2601.01424</link>
      <description>arXiv:2601.01424v1 Announce Type: cross 
Abstract: Understanding the interaction of neural and cardiac systems during cognitive activity is critical to advancing physiological computing. Although EEG has been the gold standard for assessing mental workload, its limited portability restricts its real-world use. Widely available ECG through wearable devices proposes a pragmatic alternative. This research investigates whether ECG signals can reliably reflect cognitive load and serve as proxies for EEG-based indicators. In this work, we present multimodal data acquired from two different paradigms involving working-memory and passive-listening tasks. For each modality, we extracted ECG time-domain HRV metrics and Catch22 descriptors against EEG spectral and Catch22 features, respectively. We propose a cross-modal XGBoost framework to project the ECG features onto EEG-representative cognitive spaces, thereby allowing workload inferences using only ECG. Our results show that ECG-derived projections expressively capture variation in cognitive states and provide good support for accurate classification. Our findings underpin ECG as an interpretable, real-time, wearable solution for everyday cognitive monitoring.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.01424v1</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 06 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akshay Sasi, Malavika Pradeep, Nusaibah Farrukh, Rahul Venugopal, Elizabeth Sherly</dc:creator>
    </item>
    <item>
      <title>Self-regulated emergence of heavy-tailed weight distributions in evolving complex network architectures</title>
      <link>https://arxiv.org/abs/2508.21445</link>
      <description>arXiv:2508.21445v2 Announce Type: replace 
Abstract: Synaptic plasticity typically produces heavy-tailed distributions of synaptic strengths, consisting of a few strong connections among many weaker ones. Meanwhile, structural plasticity relies on distinct signaling cascades to reshape network topology. We propose a model in which both types of plasticity adhere to the Hebbian principle while operating within homeostatically regulated activity. Synaptic plasticity alone generates heavy-tailed weight distributions, but only when any activity spreading beyond neighboring units is discarded. However, when combined with Hebbian structural plasticity, i.e., adaptive rewiring, heavy-tailed weight distributions also arise with more extensive activity flow. Furthermore, adaptive rewiring provides complex network structures with convergent-divergent circuits similar to those that facilitate signal transmission throughout the nervous system. Having adaptive weight adjustment and rewiring driven by the same homeostatic dynamics gives our model a parsimonious and robust framework that simultaneously produces heavy-tailed weight distributions and convergent-divergent units under a wide range of dynamical regimes. Consequently, the model accounts for key connectivity structures in both C. elegans and the mouse, suggesting that its principles are shared across species of different complexities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21445v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 06 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jia Li, Cees van Leeuwen, Roman Bauer, Ilias Rentzeperis</dc:creator>
    </item>
    <item>
      <title>The Bayesian Origin of the Probability Weighting Function in Human Representation of Probabilities</title>
      <link>https://arxiv.org/abs/2510.04698</link>
      <description>arXiv:2510.04698v2 Announce Type: replace 
Abstract: Understanding the representation of probability in the human mind has been of great interest to understanding human decision making. Classical paradoxes in decision making suggest that human perception distorts probability magnitudes. Previous accounts postulate a Probability Weighting Function that transforms perceived probabilities; however, its motivation has been debated. Recent work has sought to motivate this function in terms of noisy representations of probabilities in the human mind. Here, we present an account of the Probability Weighting Function grounded in rational inference over optimal decoding from noisy neural encoding of quantities. We show that our model accurately accounts for behavior in a lottery task and a dot counting task. It further accounts for adaptation to a bimodal short-term prior. Taken together, our results provide a unifying account grounding the human representation of probability in rational inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04698v2</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>econ.TH</category>
      <pubDate>Tue, 06 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Tong, Thi Thu Uyen Hoang, Xue-Xin Wei, Michael Hahn</dc:creator>
    </item>
    <item>
      <title>The Human Brain as a Combinatorial Complex</title>
      <link>https://arxiv.org/abs/2511.20692</link>
      <description>arXiv:2511.20692v2 Announce Type: replace 
Abstract: We propose a framework for constructing combinatorial complexes (CCs) from fMRI time series data that captures both pairwise and higher-order neural interactions through information-theoretic measures, bridging topological deep learning and network neuroscience. Current graph-based representations of brain networks systematically miss the higher-order dependencies that characterize neural complexity, where information processing often involves synergistic interactions that cannot be decomposed into pairwise relationships. Unlike topological lifting approaches that map relational structures into higher-order domains, our method directly constructs CCs from statistical dependencies in the data. Our CCs generalize graphs by incorporating higher-order cells that represent collective dependencies among brain regions, naturally accommodating the multi-scale, hierarchical nature of neural processing. The framework constructs data-driven combinatorial complexes using O-information and S-information measures computed from fMRI signals, preserving both pairwise connections and higher-order cells (e.g., triplets, quadruplets) based on synergistic dependencies. Using NetSim simulations as a controlled proof-of-concept dataset, we demonstrate our CC construction pipeline and show how both pairwise and higher-order dependencies in neural time series can be quantified and represented within a unified structure. This work provides a framework for brain network representation that preserves fundamental higher-order structure invisible to traditional graph methods, and enables the application of topological deep learning (TDL) architectures to neural data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.20692v2</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 06 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Valentina S\'anchez, \c{C}i\c{c}ek G\"uven, Koen Haak, Theodore Papamarkou, Gonzalo N\'apoles, Marie \v{S}af\'a\v{r} Postma</dc:creator>
    </item>
    <item>
      <title>Dynamical Mechanisms for Coordinating Long-term Working Memory Based on the Precision of Spike-timing in Cortical Neurons</title>
      <link>https://arxiv.org/abs/2512.15891</link>
      <description>arXiv:2512.15891v2 Announce Type: replace 
Abstract: In the last century, most sensorimotor studies of cortical neurons relied on average firing rates. Rate coding is efficient for fast sensorimotor processing that occurs within a few seconds. Much less is known about long-term working memory with a time scale of hours (Ericsson and Kintsch, 1995). The discovery of millisecond-precision spike initiation in cortical neurons was unexpected (Mainen and Sejnowski, 1995). Even more striking was the precision of spiking in vivo, in response to rapidly fluctuating sensory inputs, suggesting that neural circuits could, in principle, preserve and manipulate sensory information through spike timing, enabling a broader range of neural codes. It could also support spike-timing-dependent plasticity (STDP), which is triggered by the relative timing of spikes between presynaptic and postsynaptic neurons in the millisecond range. What spike-timing mechanisms could regulate STDP in vivo? Cortical traveling waves have been observed across many frequency bands with high temporal precision. Traveling waves have wave fronts that could link spike timing to STDP. As a wave front passes through a cortical column, excitatory synapses on the dendrites of both pyramidal and basket cells are stimulated synchronously. Inhibitory basket cells form a calyx on pyramidal cell bodies, and inhibitory rebound following a strong transient hyperpolarization can trigger a backpropagating action potential, which arrives shortly after the excitatory inputs on pyramidal dendrites. STDP activated in this way could persist for hours, creating a second-tier network. This temporary network could support long-term working memory, a cognitive network riding above the long-term sensorimotor network. On their own, traveling waves and STDP have not yet yielded new insights into cortical function. Together, they could be responsible for how we think (Sejnowski, 2025).</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15891v2</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 06 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Terrence J. Sejnowski</dc:creator>
    </item>
    <item>
      <title>Quantifying task-relevant representational similarity using decision variable correlation</title>
      <link>https://arxiv.org/abs/2506.02164</link>
      <description>arXiv:2506.02164v3 Announce Type: replace-cross 
Abstract: Previous studies have compared neural activities in the visual cortex to representations in deep neural networks trained on image classification. Interestingly, while some suggest that their representations are highly similar, others argued the opposite. Here, we propose a new approach to characterize the similarity of the decision strategies of two observers (models or brains) using decision variable correlation (DVC). DVC quantifies the image-by-image correlation between the decoded decisions based on the internal neural representations in a classification task. Thus, it can capture task-relevant information rather than general representational alignment. We evaluate DVC using monkey V4/IT recordings and network models trained on image classification tasks. We find that model-model similarity is comparable to monkey-monkey similarity, whereas model-monkey similarity is consistently lower. Strikingly, DVC decreases with increasing network performance on ImageNet-1k. Adversarial training does not improve model-monkey similarity in task-relevant dimensions assessed using DVC, although it markedly increases the model-model similarity. Similarly, pre-training on larger datasets does not improve model-monkey similarity. These results suggest a divergence between the task-relevant representations in monkey V4/IT and those learned by models trained on image classification tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02164v3</guid>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 06 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator> Yu (Eric),  Qian, Wilson S. Geisler, Xue-Xin Wei</dc:creator>
    </item>
    <item>
      <title>Contrastive Self-Supervised Learning As Neural Manifold Packing</title>
      <link>https://arxiv.org/abs/2506.13717</link>
      <description>arXiv:2506.13717v2 Announce Type: replace-cross 
Abstract: Contrastive self-supervised learning based on point-wise comparisons has been widely studied for vision tasks. In the visual cortex of the brain, neuronal responses to distinct stimulus classes are organized into geometric structures known as neural manifolds. Accurate classification of stimuli can be achieved by effectively separating these manifolds, akin to solving a packing problem. We introduce Contrastive Learning As Manifold Packing (CLAMP), a self-supervised framework that recasts representation learning as a manifold packing problem. CLAMP introduces a loss function inspired by the potential energy of short-range repulsive particle systems, such as those encountered in the physics of simple liquids and jammed packings. In this framework, each class consists of sub-manifolds embedding multiple augmented views of a single image. The sizes and positions of the sub-manifolds are dynamically optimized by following the gradient of a packing loss. This approach yields interpretable dynamics in the embedding space that parallel jamming physics, and introduces geometrically meaningful hyperparameters within the loss function. Under the standard linear evaluation protocol, which freezes the backbone and trains only a linear classifier, CLAMP achieves competitive performance with state-of-the-art self-supervised models. Furthermore, our analysis reveals that neural manifolds corresponding to different categories emerge naturally and are effectively separated in the learned representation space, highlighting the potential of CLAMP to bridge insights from physics, neural science, and machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.13717v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 06 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guanming Zhang, David J. Heeger, Stefano Martiniani</dc:creator>
    </item>
    <item>
      <title>Toward Efficient Spiking Transformers: Synapse Pruning Meets Synergistic Learning-Based Compensation</title>
      <link>https://arxiv.org/abs/2508.01992</link>
      <description>arXiv:2508.01992v4 Announce Type: replace-cross 
Abstract: As a foundational architecture of artificial intelligence models, Transformer has been recently adapted to spiking neural networks with promising performance across various tasks. However, existing spiking Transformer(ST)-based models require a substantial number of parameters and incur high computational costs, thus limiting their deployment in resource-constrained environments. To address these challenges, we propose combining synapse pruning with a synergistic learning-based compensation strategy to derive lightweight ST-based models. Specifically, two types of tailored pruning strategies are introduced to reduce redundancy in the weight matrices of ST blocks: an unstructured $\mathrm{L_{1}P}$ method to induce sparse representations, and a structured DSP method to induce low-rank representations. In addition, we propose an enhanced spiking neuron model, termed the synergistic leaky integrate-and-fire (sLIF) neuron, to effectively compensate for model pruning through synergistic learning between synaptic and intrinsic plasticity mechanisms. Extensive experiments on benchmark datasets demonstrate that the proposed methods significantly reduce model size and computational overhead while maintaining competitive performance. These results validate the effectiveness of the proposed pruning and compensation strategies in constructing efficient and high-performing ST-based models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01992v4</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 06 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongze Sun, Wuque Cai, Duo Chen, Quan Tang, Shifeng Mao, Jiayi He, Zhenxing Wang, Yan Cui, Dezhong Yao, Daqing Guo</dc:creator>
    </item>
  </channel>
</rss>
