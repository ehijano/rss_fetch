<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 16 Jul 2025 04:03:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>FARS: Factor Augmented Regression Scenarios in R</title>
      <link>https://arxiv.org/abs/2507.10679</link>
      <description>arXiv:2507.10679v1 Announce Type: new 
Abstract: Obtaining realistic scenarios for the distribution of key economic variables is crucial for econometricians, policy-makers, and financial analysts. The FARS package provides a comprehensive framework in R for modeling and designing economic scenarios based on distributions derived from multi-level dynamic factor models (ML-DFMs) and factor-augmented quantile regressions (FA-QRs). The package enables users to: (i) extract global and block-specific factors using a flexible multi-level factor structure; (ii) compute asymptotically valid confidence regions for the estimated factors, accounting for uncertainty in the factor loadings; (iii) estimate FA-QRs; (iv) recover full predictive conditional densities from quantile forecasts; and (v) estimate the conditional density when the factors are stressed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.10679v1</guid>
      <category>stat.CO</category>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gian Pietro Bellocca, Ignacio Garr\'on, Vladimir Rodr\'iguez-Caballero, Esther Ruiz</dc:creator>
    </item>
    <item>
      <title>Start from the End: A Framework for Computational Policy Exploration to Inform Effective and Geospatially Consistent Interventions applied to COVID-19 in St. Louis</title>
      <link>https://arxiv.org/abs/2507.10870</link>
      <description>arXiv:2507.10870v1 Announce Type: cross 
Abstract: Mathematical models are a powerful tool to study infectious disease dynamics and intervention strategies against them in social systems. However, due to their detailed implementation and steep computational requirements, practitioners and stakeholders are typically only able to explore a small subset of all possible intervention scenarios, a severe limitation when preparing for disease outbreaks. In this work, we propose a parameter exploration framework utilizing emulator models to make uncertainty-aware predictions of high-dimensional parameter spaces and identify large numbers of feasible response strategies. We apply our framework to a case study of a large-scale agent-based disease model of the COVID-19 ``Omicron wave'' in St. Louis, Missouri that took place from December 2021 to February 2022. We identify large numbers of response strategies that would have been estimated to have reduced disease spread by a substantial amount. We also identify policy interventions that would have been able to reduce the geospatial variation in disease spread, which has additional implications for designing thoughtful response strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.10870v1</guid>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David O'Gara, Matt Kasman, Matthew D. Haslam, Ross A. Hammond</dc:creator>
    </item>
    <item>
      <title>Active Learning via Heteroskedastic Rational Kriging</title>
      <link>https://arxiv.org/abs/2507.10952</link>
      <description>arXiv:2507.10952v1 Announce Type: cross 
Abstract: Active learning methods for emulating complex computer models that rely on stationary Gaussian processes tend to produce design points that uniformly fill the entire experimental region, which can be wasteful for functions which vary only in small regions. In this article, we propose a new Gaussian process model that captures the heteroskedasticity of the function. Active learning using this new model can place design points in the more interesting regions of the response surface, and thus obtain surrogate models with better accuracy. The proposed active learning method is compared with the state-of-the-art methods using simulations and two real datasets. It is found to have comparable or better performance relative to other non-stationary Gaussian process-based methods, but faster by orders of magnitude.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.10952v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shangkun Wang, V. Roshan Joseph</dc:creator>
    </item>
    <item>
      <title>Canonical Bayesian Linear System Identification</title>
      <link>https://arxiv.org/abs/2507.11535</link>
      <description>arXiv:2507.11535v1 Announce Type: cross 
Abstract: Standard Bayesian approaches for linear time-invariant (LTI) system identification are hindered by parameter non-identifiability; the resulting complex, multi-modal posteriors make inference inefficient and impractical. We solve this problem by embedding canonical forms of LTI systems within the Bayesian framework. We rigorously establish that inference in these minimal parameterizations fully captures all invariant system dynamics (e.g., transfer functions, eigenvalues, predictive distributions of system outputs) while resolving identifiability. This approach unlocks the use of meaningful, structure-aware priors (e.g., enforcing stability via eigenvalues) and ensures conditions for a Bernstein--von Mises theorem -- a link between Bayesian and frequentist large-sample asymptotics that is broken in standard forms. Extensive simulations with modern MCMC methods highlight advantages over standard parameterizations: canonical forms achieve higher computational efficiency, generate interpretable and well-behaved posteriors, and provide robust uncertainty estimates, particularly from limited data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11535v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>stat.CO</category>
      <pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrey Bryutkin, Matthew E. Levine, I\~nigo Urteaga, Youssef Marzouk</dc:creator>
    </item>
    <item>
      <title>Error estimation for quasi-Monte Carlo</title>
      <link>https://arxiv.org/abs/2501.00150</link>
      <description>arXiv:2501.00150v3 Announce Type: replace-cross 
Abstract: Quasi-Monte Carlo sampling can attain far better accuracy than plain Monte Carlo sampling. However, with plain Monte Carlo sampling it is much easier to estimate the attained accuracy. This article describes methods old and new to quantify the error in quasi-Monte Carlo estimates. An important challenge in this setting is that the goal of getting accuracy conflicts with that of estimating the attained accuracy. A related challenge is that rigorous uncertainty quantifications can be extremely conservative. A recent surprise is that some RQMC estimates have nearly symmetric distributions and that has the potential to allow confidence intervals that do not require either a central limit theorem or a consistent variance estimate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00150v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>stat.CO</category>
      <pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Art B. Owen</dc:creator>
    </item>
    <item>
      <title>Counterfactual Q Learning via the Linear Buckley James Method for Longitudinal Survival Data</title>
      <link>https://arxiv.org/abs/2505.12159</link>
      <description>arXiv:2505.12159v2 Announce Type: replace-cross 
Abstract: Treatment strategies are critical in healthcare, particularly when outcomes are subject to censoring. This study introduces the Counterfactual Buckley-James Q-Learning framework, which integrates the Buckley-James method with reinforcement learning to address challenges posed by censored survival data. The Buckley-James method imputes censored survival times via conditional expectations based on observed data, offering a robust mechanism for handling incomplete outcomes. By incorporating these imputed values into a counterfactual Q-learning framework, the proposed method enables the estimation and comparison of potential outcomes under different treatment strategies. This facilitates the identification of optimal dynamic treatment regimes that maximize expected survival time. Through extensive simulation studies, the method demonstrates robust performance across various sample sizes and censoring scenarios, including right censoring and missing at random (MAR). Application to real-world clinical trial data further highlights the utility of this approach in informing personalized treatment decisions, providing an interpretable and reliable tool for optimizing survival outcomes in complex clinical settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12159v2</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jeongjin Lee, Jong-Min Kim</dc:creator>
    </item>
  </channel>
</rss>
