<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.comp-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.comp-ph</link>
    <description>physics.comp-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.comp-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 06 Jun 2024 01:50:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 05 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Validating Automated Resonance Evaluation with Synthetic Data</title>
      <link>https://arxiv.org/abs/2406.01754</link>
      <description>arXiv:2406.01754v1 Announce Type: new 
Abstract: The integrity and precision of nuclear data are crucial for a broad spectrum of applications, from national security and nuclear reactor design to medical diagnostics, where the associated uncertainties can significantly impact outcomes. A substantial portion of uncertainty in nuclear data originates from the subjective biases in the evaluation process, a crucial phase in the nuclear data production pipeline. Recent advancements indicate that automation of certain routines can mitigate these biases, thereby standardizing the evaluation process, reducing uncertainty and enhancing reproducibility. This article contributes to developing a framework for automated evaluation techniques testing, emphasizing automated fitting methods that do not require the user to provide any prior information. This approach simplifies the process and reduces the manual effort needed in the initial evaluation stage. It highlights the capability of the framework to validate and optimize subroutines, targeting the performance analysis and optimization of the fitting procedure using high-fidelity synthetic data (labeled experimental data) and the concept of a fully controlled computational experiment. An error metric is introduced to provide a clear and intuitive measure of the fitting quality by quantifying the accuracy and performance across the specified energy. This metric sets a scale for comparison and optimization of routines or hyperparameter selection, improving the entire evaluation process methodology and increasing reproducibility and objectivity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01754v1</guid>
      <category>physics.comp-ph</category>
      <category>nucl-ex</category>
      <category>nucl-th</category>
      <category>physics.med-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Oleksii Zivenko, Noah A. W. Walton, William Fritsch, Jacob Forbes, Amanda M. Lewis, Aaron Clark, Jesse M. Brown, Vladimir Sobes</dc:creator>
    </item>
    <item>
      <title>Porting the grid-based 3D+3V hybrid-Vlasov kinetic plasma simulation Vlasiator to heterogeneous GPU architectures</title>
      <link>https://arxiv.org/abs/2406.02201</link>
      <description>arXiv:2406.02201v1 Announce Type: new 
Abstract: Vlasiator is a space plasma simulation code which models near-Earth ion-kinetic dynamics in three spatial and three velocity dimensions. It is highly parallelized, modeling the Vlasov equation directly through the distribution function, discretized on a Cartesian grid, instead of the more common particle-in-cell approach. Modeling near-Earth space, plasma properties span several orders of magnitude in temperature, density, and magnetic field strength. In order to fit the required six-dimensional grids in memory, Vlasiator utilizes a sparse block-based velocity mesh, where chunks of velocity space are added or deleted based on the advection requirements of the Vlasov solver. In addition, the spatial mesh is adaptively refined through cell-based octree refinement. In this paper, we describe the design choices of porting Vlasiator to heterogeneous CPU/GPU architectures. We detail the memory management, algorithmic changes, and kernel construction as well as our unified codebase approach, resulting in portability to both NVIDIA and AMD hardware (CUDA and HIP languages, respectively). In particular, we showcase a highly parallel block adjustment approach allowing efficient re-ordering of a sparse velocity mesh. We detail pitfalls we have overcome and lay out a plan for optimization to facilitate future exascale simulations using multi-node GPU supercomputing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02201v1</guid>
      <category>physics.comp-ph</category>
      <category>physics.plasm-ph</category>
      <category>physics.space-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Markus Battarbee, Konstantinos Papadakis, Urs Ganse, Jaro Hokkanen, Leo Kotipalo, Yann Pfau-Kempf, Markku Alho, Minna Palmroth</dc:creator>
    </item>
    <item>
      <title>Neural network sampling of Bethe-Heitler process in particle-in-cell codes</title>
      <link>https://arxiv.org/abs/2406.02491</link>
      <description>arXiv:2406.02491v1 Announce Type: new 
Abstract: This study uses neural networks to improve Monte Carlo (MC) implementations of the Bethe-Heitler process in Particle-In-Cell (PIC) codes. We provide a neural network that is as accurate as pre-calculated tables, and requires a hundred times less memory to store. It is trained to predict Bethe-Heitler pair production cross-sections for atomic numbers 1-50 and photon energies between 1 MeV and 10 GeV in the PIC code OSIRIS. We first validate our approach against a theoretical estimate in a simplified context. We later prove that both approaches have similar performance in a typical relativistic laser-plasma interaction scenario. The large memory decrease accessible with neural networks will enable introducing more advanced cross-section models for Bethe-Heitler pair production and other QED mechanisms in the MC modules of PIC codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02491v1</guid>
      <category>physics.comp-ph</category>
      <category>physics.plasm-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>\'Oscar Amaro, Chiara Badiali, Bertrand Martinez</dc:creator>
    </item>
    <item>
      <title>Ferromagnetic semimetal and charge-density wave phases of interacting electrons in a honeycomb moir\'e potential</title>
      <link>https://arxiv.org/abs/2406.01715</link>
      <description>arXiv:2406.01715v1 Announce Type: cross 
Abstract: The exploration of quantum phases in moir\'e systems has drawn intense experimental and theoretical efforts. The realization of honeycomb symmetry has been a recent focus. The combination of strong interaction and honeycomb symmetry can lead to exotic electronic states such as fractional Chern insulator, unconventional superconductor, and quantum spin liquid. Accurate computations in such systems, with reliable treatment of strong long-ranged Coulomb interaction and approaching the large system sizes to extract thermodynamic phases, are mostly missing. We study the two-dimensional electron gas on a honeycomb moir\'e lattice at quarter filling, using fixed-phase diffusion Monte Carlo. The ground state phases of this important model are determined in the parameter regime relevant to current experiments. With increasing moir\'e potential, the systems transitions from a paramagnetic metal to an itinerant ferromagnetic semimetal and then a charge-density-wave insulator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01715v1</guid>
      <category>cond-mat.str-el</category>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.comp-ph</category>
      <category>quant-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yubo Yang, Miguel A. Morales, Shiwei Zhang</dc:creator>
    </item>
    <item>
      <title>Unitary Dynamics for Open Quantum Systems with Density-Matrix Purification</title>
      <link>https://arxiv.org/abs/2406.01783</link>
      <description>arXiv:2406.01783v1 Announce Type: cross 
Abstract: Accurate modeling of quantum systems interacting with environments requires addressing non-unitary dynamics, which significantly complicates computational approaches. In this work, we enhance an open quantum system (OQS) theory using density-matrix purification, enabling a unitary description of dynamics by entangling the system with an environment of equal dimension. We first establish the connection between density-matrix purification and conventional OQS methods. We then demonstrate the standalone applicability of purification theory by deriving system-environment interactions from fundamental design principles. Using model systems, we show that the purification approach extends beyond the complete positivity condition and effectively models both Markovian and non-Markovian dynamics. Finally, we implement density-matrix purification on a quantum simulator, illustrating its capability to map non-unitary OQS dynamics onto a unitary framework suitable for quantum computers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01783v1</guid>
      <category>quant-ph</category>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luis H. Delgado-Granados, Samuel Warren, David A. Mazziotti</dc:creator>
    </item>
    <item>
      <title>Error Field Predictability and Consequences for ITER</title>
      <link>https://arxiv.org/abs/2406.01824</link>
      <description>arXiv:2406.01824v1 Announce Type: cross 
Abstract: ITER coil tolerances are re-evaluated using the modern understanding of coupling to least-stable plasma modes and an updated center-line-traced model of ITER's coil windings. This reassessment finds the tolerances to be conservative through a statistical, linear study of $n=1$ error fields (EFs) due to tilted, shifted misplacements and nominal windings of central solenoid and poloidal field coils within tolerance. We also show that a model-based correction scheme remains effective even when metrology quality is sub-optimal, and compare this to projected empirical correction schemes. We begin with an analysis of the necessity of error field correction (EFC) for daily operation in ITER using scaling laws for the EF penetration threshold. We then consider the predictability of EF dominant mode overlap across early planned ITER scenarios and, as measuring EFs in high power scenarios can pose risks to the device, the potential for extrapolation to the ITER Baseline Scenario (IBS). We find that carefully designing a scenario matching currents proportionally to those of the IBS is far more important than plasma shape or profiles in accurately measuring an optimal correction current set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01824v1</guid>
      <category>physics.plasm-ph</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthew Pharr, Nikolas Logan, Carlos Paz-Soldan Jong-Kyu Park, Chistopher Hansen</dc:creator>
    </item>
    <item>
      <title>Quantum states from normalizing flows</title>
      <link>https://arxiv.org/abs/2406.02451</link>
      <description>arXiv:2406.02451v1 Announce Type: cross 
Abstract: We introduce an architecture for neural quantum states for many-body quantum-mechanical systems, based on normalizing flows. The use of normalizing flows enables efficient uncorrelated sampling of configurations from the probability distribution defined by the wavefunction, mitigating a major cost of using neural states in simulation. We demonstrate the use of this architecture for both ground-state preparation (for self-interacting particles in a harmonic trap) and real-time evolution (for one-dimensional tunneling). Finally, we detail a procedure for obtaining rigorous estimates of the systematic error when using neural states to approximate quantum evolution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02451v1</guid>
      <category>quant-ph</category>
      <category>nucl-th</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Scott Lawrence, Arlee Shelby, Yukari Yamauchi</dc:creator>
    </item>
    <item>
      <title>Quantized tensor networks for solving the Vlasov-Maxwell equations</title>
      <link>https://arxiv.org/abs/2311.07756</link>
      <description>arXiv:2311.07756v4 Announce Type: replace 
Abstract: The Vlasov-Maxwell equations provide an \textit{ab-initio} description of collisionless plasmas, but solving them is often impractical because of the wide range of spatial and temporal scales that must be resolved and the high dimensionality of the problem. In this work, we present a quantum-inspired semi-implicit Vlasov-Maxwell solver that utilizes the quantized tensor network (QTN) framework. With this QTN solver, the cost of grid-based numerical simulation of size $N$ is reduced from $\mathcal{O}(N)$ to $\mathcal{O}(\text{poly}(D))$, where $D$ is the ``rank'' or ``bond dimension'' of the QTN and is typically set to be much smaller than $N$. We find that for the five-dimensional test problems considered here, a modest $D=64$ appears to be sufficient for capturing the expected physics despite the simulations using a total of $N=2^{36}$ grid points, \edit{which would require $D=2^{18}$ for full-rank calculations}. Additionally, we observe that a QTN time evolution scheme based on the Dirac-Frenkel variational principle allows one to use somewhat larger time steps than prescribed by the Courant-Friedrichs-Lewy (CFL) constraint. As such, this work demonstrates that the QTN format is a promising means of approximately solving the Vlasov-Maxwell equations with significantly reduced cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.07756v4</guid>
      <category>physics.comp-ph</category>
      <category>physics.plasm-ph</category>
      <category>quant-ph</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Erika Ye, Nuno Loureiro</dc:creator>
    </item>
    <item>
      <title>Accelerating the Convergence of Coupled Cluster Calculations of the Homogeneous Electron Gas Using Bayesian Ridge Regression</title>
      <link>https://arxiv.org/abs/2403.04645</link>
      <description>arXiv:2403.04645v2 Announce Type: replace 
Abstract: The homogeneous electron gas is a system which has many applications in chemistry and physics. However, its infinite nature makes studies at the many-body level complicated due to long computational run times. Because it is size extensive, coupled cluster theory is capable of studying the homogeneous electron gas, but it still poses a large computational challenge as the time needed for precise calculations increases in a polynomial manner with the number of particles and single-particle states. Consequently, achieving convergence in energy calculations becomes challenging, if not prohibited, due to long computational run times and high computational resource requirements. This paper develops the sequential regression extrapolation (SRE) to predict the coupled cluster energies of the homogeneous electron gas in the complete basis limit using Bayesian ridge regression to make predictions from calculations at truncated basis sizes. Using the SRE method we were able to predict the coupled cluster doubles energies for the electron gas across a variety of values of N and $r_s$, for a total of 70 predictions, with an average error of 4.28x10$^{-4}$ Hartrees while saving 88.9 hours of computational time. The SRE method can accurately extrapolate electron gas energies to the complete basis limit, saving both computational time and resources. Additionally, the SRE is a general method that can be applied to a variety of systems, many-body methods, and extrapolations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04645v2</guid>
      <category>physics.comp-ph</category>
      <category>cond-mat.other</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julie Butler, Morten Hjorth-Jensen, Justin Lietz</dc:creator>
    </item>
    <item>
      <title>Two-dimensional coherent spectrum of high-spin models via a quantum computing approach</title>
      <link>https://arxiv.org/abs/2311.14035</link>
      <description>arXiv:2311.14035v4 Announce Type: replace-cross 
Abstract: We present and benchmark a quantum computing approach to calculate the two-dimensional coherent spectrum (2DCS) of high-spin models. Our approach is based on simulating their real-time dynamics in the presence of several magnetic field pulses, which are spaced in time. We utilize the adaptive variational quantum dynamics simulation (AVQDS) algorithm for the study due to its compact circuits, which enables simulations over sufficiently long times to achieve the required resolution in frequency space. Specifically, we consider an antiferromagnetic quantum spin model that incorporates Dzyaloshinskii-Moriya interactions and single-ion anisotropy. The obtained 2DCS spectra exhibit distinct peaks at multiples of the magnon frequency, arising from transitions between different eigenstates of the unperturbed Hamiltonian. By comparing the one-dimensional coherent spectrum with 2DCS, we demonstrate that 2DCS provides a higher resolution of the energy spectrum. We further investigate how the quantum resources scale with the magnitude of the spin using two different binary encodings of the high-spin operators: the standard binary encoding and the Gray code. At low magnetic fields both encodings require comparable quantum resources, but at larger field strengths the Gray code is advantageous. Numerical simulations for spin models with increasing number of sites indicate a polynomial system-size scaling for quantum resources. Lastly, we compare the numerical 2DCS with experimental results on a rare-earth orthoferrite system. The observed strength of the magnonic high-harmonic generation signals in the 2DCS of the quantum high-spin model aligns well with the experimental data, showing significant improvement over the corresponding mean-field results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.14035v4</guid>
      <category>quant-ph</category>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Mootz, Peter P. Orth, Chuankun Huang, Liang Luo, Jigang Wang, Yong-Xin Yao</dc:creator>
    </item>
    <item>
      <title>Two dimensional quantum lattice models via mode optimized hybrid CPU-GPU density matrix renormalization group method</title>
      <link>https://arxiv.org/abs/2311.14106</link>
      <description>arXiv:2311.14106v2 Announce Type: replace-cross 
Abstract: We present a hybrid numerical approach to simulate quantum many body problems on two spatial dimensional quantum lattice models via the non-Abelian ab initio version of the density matrix renormalization group method on state-of-the-art high performance computing infrastructures. We demonstrate for the two dimensional spinless fermion model and for the Hubbard model on torus geometry that altogether several orders of magnitude in computational time can be saved by performing calculations on an optimized basis and by utilizing hybrid CPU-multiGPU parallelization. At least an order of magnitude reduction in computational complexity results from mode optimization, while a further order of reduction in wall time is achieved by massive parallelization. Our results are measured directly in FLOP and seconds. A detailed scaling analysis of the obtained performance as a function of matrix ranks and as a function of system size up to $12\times 12$ lattice topology is discussed. Our CPU-multiGPU model also tremendously accelerates the calculation of the one- and two-particle reduced density matrices, which can be used to construct various order parameters and trace quantum phase transitions with high fidelity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.14106v2</guid>
      <category>cond-mat.str-el</category>
      <category>physics.comp-ph</category>
      <category>quant-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/PhysRevB.109.195148</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. B 109, 195148 (2024)</arxiv:journal_reference>
      <dc:creator>Andor Menczer, Korn\'el Kap\'as, Mikl\'os Antal Werner, \"Ors Legeza</dc:creator>
    </item>
    <item>
      <title>TENG: Time-Evolving Natural Gradient for Solving PDEs With Deep Neural Nets Toward Machine Precision</title>
      <link>https://arxiv.org/abs/2404.10771</link>
      <description>arXiv:2404.10771v2 Announce Type: replace-cross 
Abstract: Partial differential equations (PDEs) are instrumental for modeling dynamical systems in science and engineering. The advent of neural networks has initiated a significant shift in tackling these complexities though challenges in accuracy persist, especially for initial value problems. In this paper, we introduce the $\textit{Time-Evolving Natural Gradient (TENG)}$, generalizing time-dependent variational principles and optimization-based time integration, leveraging natural gradient optimization to obtain high accuracy in neural-network-based PDE solutions. Our comprehensive development includes algorithms like TENG-Euler and its high-order variants, such as TENG-Heun, tailored for enhanced precision and efficiency. TENG's effectiveness is further validated through its performance, surpassing current leading methods and achieving $\textit{machine precision}$ in step-by-step optimizations across a spectrum of PDEs, including the heat equation, Allen-Cahn equation, and Burgers' equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10771v2</guid>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhuo Chen, Jacob McCarran, Esteban Vizcaino, Marin Solja\v{c}i\'c, Di Luo</dc:creator>
    </item>
    <item>
      <title>Flowy: High performance probabilistic lava emplacement prediction</title>
      <link>https://arxiv.org/abs/2405.20144</link>
      <description>arXiv:2405.20144v2 Announce Type: replace-cross 
Abstract: Lava emplacement is a complex physical phenomenon, affected by several factors. These include, but are not limited to features of the terrain, the lava settling process, the effusion rate or total erupted volume, and the probability of effusion from different locations. One method, which has been successfully employed to predict lava flow emplacement and forecast the inundated area and final lava thickness, is the MrLavaLoba method from Vitturi et al. The MrLavaLoba method has been implemented in their code of the same name. Here, we introduce Flowy, a new computational tool that implements the MrLavaLoba method in a more efficient manner. New fast algorithms have been incorporated for all performance critical code paths, resulting in a complete overhaul of the implementation. When compared to the MrLavaLoba code, Flowy exhibits a significant reduction in runtime -- between 100 to 400 times faster -- depending on the specific input parameters. The accuracy and the probabilistic convergence of the model outputs are not compromised, maintaining high fidelity in generating possible lava flow paths and deposition characteristics. We have validated Flowy's performance and reliability through comprehensive unit-testing and a real-world eruption scenario. The source code is freely available on GitHub, facilitating transparency, reproducibility and collaboration within the geoscientific community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20144v2</guid>
      <category>physics.geo-ph</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Moritz Sallermann, Amrita Goswami, Alejandro Pe\~na-Torres, Rohit Goswami</dc:creator>
    </item>
  </channel>
</rss>
