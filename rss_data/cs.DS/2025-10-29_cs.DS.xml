<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 29 Oct 2025 04:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Expander Decomposition for Non-Uniform Vertex Measures</title>
      <link>https://arxiv.org/abs/2510.23913</link>
      <description>arXiv:2510.23913v1 Announce Type: new 
Abstract: A $(\phi,\epsilon)$-expander-decomposition of a graph $G$ (with $n$ vertices and $m$ edges) is a partition of $V$ into clusters $V_1,\ldots,V_k$ with conductance $\Phi(G[V_i]) \ge \phi$, such that there are at most $\epsilon m$ inter-cluster edges. Such a decomposition plays a crucial role in many graph algorithms. [ADK23] gave a randomized $\tilde{O}(m)$ time algorithm for computing a $(\phi, \phi\log^2 {n})$-expander decomposition.
  In this paper we generalize this result for a broader notion of expansion. Let $\mu \in {\mathbb{R}}_{\ge 0 }^n$ be a vertex measure. A standard generalization of conductance of a cut $(S,\bar{S})$ is its $\mu$-expansion $\Phi^{\mu}_G(S,\bar{S}) = |E(S,\bar{S})|/\min \mu(S)),\mu(\bar{S})\}$, where $\mu(S) = \sum_{v\in S} \mu(v)$. We present a randomized $\tilde{O}(m)$ time algorithm for computing a $(\phi, \phi \log^2 {n}\left(\frac{\mu(V)}{m}\right))$-expander decomposition with respect to $\mu$-expansion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23913v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Agassy, Dani Dorfman, Haim Kaplan</dc:creator>
    </item>
    <item>
      <title>On Competitiveness of Dynamic Replication for Distributed Data Access</title>
      <link>https://arxiv.org/abs/2510.24098</link>
      <description>arXiv:2510.24098v1 Announce Type: new 
Abstract: This paper studies an online cost optimization problem for distributed storage and access. The goal is to dynamically create and delete copies of data objects over time at geo-distributed servers to serve access requests and minimize the total storage and network cost. We revisit a recent algorithm in the literature and show that it does not have a competitive ratio of $2$ as claimed by constructing a counterexample. We further prove that no deterministic online algorithm can achieve a competitive ratio bounded by $2$ for the general cost optimization problem. We develop an online algorithm and prove that it achieves a competitive ratio of $\max\{2, \min\{\gamma, 3\}\}$, where $\gamma$ is the max/min storage cost ratio among all servers. Examples are given to confirm the tightness of competitive analysis. We also empirically evaluate algorithms using real object access traces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24098v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianyu Zuo, Xueyan Tang, Bu Sung Lee, Jianfei Cai</dc:creator>
    </item>
    <item>
      <title>Coreset for Robust Geometric Median: Eliminating Size Dependency on Outliers</title>
      <link>https://arxiv.org/abs/2510.24621</link>
      <description>arXiv:2510.24621v1 Announce Type: new 
Abstract: We study the robust geometric median problem in Euclidean space $\mathbb{R}^d$, with a focus on coreset construction.A coreset is a compact summary of a dataset $P$ of size $n$ that approximates the robust cost for all centers $c$ within a multiplicative error $\varepsilon$. Given an outlier count $m$, we construct a coreset of size $\tilde{O}(\varepsilon^{-2} \cdot \min\{\varepsilon^{-2}, d\})$ when $n \geq 4m$, eliminating the $O(m)$ dependency present in prior work [Huang et al., 2022 &amp; 2023]. For the special case of $d = 1$, we achieve an optimal coreset size of $\tilde{\Theta}(\varepsilon^{-1/2} + \frac{m}{n} \varepsilon^{-1})$, revealing a clear separation from the vanilla case studied in [Huang et al., 2023; Afshani and Chris, 2024]. Our results further extend to robust $(k,z)$-clustering in various metric spaces, eliminating the $m$-dependence under mild data assumptions. The key technical contribution is a novel non-component-wise error analysis, enabling substantial reduction of outlier influence, unlike prior methods that retain them.Empirically, our algorithms consistently outperform existing baselines in terms of size-accuracy tradeoffs and runtime, even when data assumptions are violated across a wide range of datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24621v1</guid>
      <category>cs.DS</category>
      <category>cs.CG</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziyi Fang, Lingxiao Huang, Runkai Yang</dc:creator>
    </item>
    <item>
      <title>Matchings Under Biased and Correlated Evaluations</title>
      <link>https://arxiv.org/abs/2510.23628</link>
      <description>arXiv:2510.23628v1 Announce Type: cross 
Abstract: We study a two-institution stable matching model in which candidates from two distinct groups are evaluated using partially correlated signals that are group-biased. This extends prior work (which assumes institutions evaluate candidates in an identical manner) to a more realistic setting in which institutions rely on overlapping, but independently processed, criteria. These evaluations could consist of a variety of informative tools such as standardized tests, shared recommendation systems, or AI-based assessments with local noise. Two key parameters govern evaluations: the bias parameter $\beta \in (0,1]$, which models systematic disadvantage faced by one group, and the correlation parameter $\gamma \in [0,1]$, which captures the alignment between institutional rankings. We study the representation ratio, i.e., the ratio of disadvantaged to advantaged candidates selected by the matching process in this setting. Focusing on a regime in which all candidates prefer the same institution, we characterize the large-market equilibrium and derive a closed-form expression for the resulting representation ratio. Prior work shows that when $\gamma = 1$, this ratio scales linearly with $\beta$. In contrast, we show that the representation ratio increases nonlinearly with $\gamma$ and even modest losses in correlation can cause sharp drops in the representation ratio. Our analysis identifies critical $\gamma$-thresholds where institutional selection behavior undergoes discrete transitions, and reveals structural conditions under which evaluator alignment or bias mitigation are most effective. Finally, we show how this framework and results enable interventions for fairness-aware design in decentralized selection systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23628v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.CY</category>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amit Kumar, Nisheeth K. Vishnoi</dc:creator>
    </item>
    <item>
      <title>Pinwheel Scheduling with Real Periods</title>
      <link>https://arxiv.org/abs/2510.24068</link>
      <description>arXiv:2510.24068v1 Announce Type: cross 
Abstract: For a sequence of tasks, each with a positive integer period, the pinwheel scheduling problem involves finding a valid schedule in the sense that the schedule performs one task per day and each task is performed at least once every consecutive days of its period. It had been conjectured by Chan and Chin in 1993 that there exists a valid schedule for any sequence of tasks with density, the sum of the reciprocals of each period, at most $\frac{5}{6}$. Recently, Kawamura settled this conjecture affirmatively. In this paper we consider an extended version with real periods proposed by Kawamura, in which a valid schedule must perform each task $i$ having a real period~$a_{i}$ at least $l$ times in any consecutive $\lceil l a_{i} \rceil$ days for all positive integer $l$. We show that any sequence of tasks such that the periods take three distinct real values and the density is at most $\frac{5}{6}$ admits a valid schedule. We hereby conjecture that the conjecture of Chan and Chin is true also for real periods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24068v1</guid>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hiroshi Fujiwara, Kota Miyagi, Katsuhisa Ouchi</dc:creator>
    </item>
    <item>
      <title>Faster Algorithm for Structured John Ellipsoid Computation</title>
      <link>https://arxiv.org/abs/2211.14407</link>
      <description>arXiv:2211.14407v2 Announce Type: replace 
Abstract: The famous theorem of Fritz John states that any convex body has a unique maximal volume inscribed ellipsoid, known as the John Ellipsoid. Computing the John Ellipsoid is a fundamental problem in convex optimization. In this paper, we focus on approximating the John Ellipsoid inscribed in a convex and centrally symmetric polytope defined by $ P := \{ x \in \mathbb{R}^d : -\mathbf{1}_n \leq A x \leq \mathbf{1}_n \},$ where $ A \in \mathbb{R}^{n \times d} $ is a rank-$d$ matrix and $ \mathbf{1}_n \in \mathbb{R}^n $ is the all-ones vector. We develop two efficient algorithms for approximating the John Ellipsoid. The first is a sketching-based algorithm that runs in nearly input-sparsity time $ \widetilde{O}(\mathrm{nnz}(A) + d^\omega) $, where $ \mathrm{nnz}(A) $ denotes the number of nonzero entries in the matrix $A$ and $ \omega \approx 2.37$ is the current matrix multiplication exponent. The second is a treewidth-based algorithm that runs in time $ \widetilde{O}(n \tau^2)$, where $\tau$ is the treewidth of the dual graph of the matrix $A$. Our algorithms significantly improve upon the state-of-the-art running time of $ \widetilde{O}(n d^2) $ achieved by [Cohen, Cousins, Lee, and Yang, COLT 2019].</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.14407v2</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yang Cao, Xiaoyu Li, Zhao Song, Xin Yang, Tianyi Zhou</dc:creator>
    </item>
    <item>
      <title>Error Correction for Message Streams</title>
      <link>https://arxiv.org/abs/2307.07087</link>
      <description>arXiv:2307.07087v3 Announce Type: replace 
Abstract: In the setting of error correcting codes, Alice wants to send a message $x \in \{0,1\}^n$ to Bob via an encoding $\text{enc}(x)$ that is resilient to error. In this work, we investigate the scenario where Bob is a low space decoder. More precisely, he receives Alice's encoding $\text{enc}(x)$ bit-by-bit and desires to compute some function $f(x)$ in low space. A generic error-correcting code does not accomplish this because decoding is a very global process and requires at least linear space. Locally decodable codes partially solve this problem as they allow Bob to learn a given bit of $x$ in low space, but not compute a generic function $f$.
  Our main result is an encoding and decoding procedure where Bob is still able to compute any such function $f$ in low space when a constant fraction of the stream is corrupted. More precisely, we describe an encoding function $\text{enc}(x)$ of length $\text{poly}(n)$ so that for any decoder (streaming algorithm) $A$ that on input $x$ computes $f(x)$ in space $s$, there is an explicit decoder $B$ that computes $f(x)$ in space $s \cdot \text{polylog}(n)$ as long as there were not more than $\frac14 - \varepsilon$ fraction of (adversarial) errors in the input stream $\text{enc}(x)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.07087v3</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Meghal Gupta, Rachel Yun Zhang</dc:creator>
    </item>
    <item>
      <title>Induced Minor Models. II. Sufficient conditions for polynomial-time detection of induced minors</title>
      <link>https://arxiv.org/abs/2501.00161</link>
      <description>arXiv:2501.00161v4 Announce Type: replace 
Abstract: The $H$-Induced Minor Containment problem ($H$-IMC) consists in deciding if a fixed graph $H$ is an induced minor of a graph $G$ given as input, that is, whether $H$ can be obtained from $G$ by deleting vertices and contracting edges. Equivalently, the problem asks if there exists an induced minor model of $H$ in $G$, that is, a collection of disjoint subsets of vertices of $G$, each inducing a connected subgraph, such that contracting each subgraph into a single vertex results in $H$.
  It is known that $H$-IMC is NP-complete for several graphs $H$, even when $H$ is a tree. In this work, we investigate which properties of $H$ guarantee the existence of an induced minor model whose structure can be leveraged to solve the problem in polynomial time. This allows us to identify four infinite families of graphs $H$ that enjoy such properties. Moreover, we show that if the input graph $G$ excludes long induced paths, then $H$-IMC is polynomial-time solvable for any fixed graph $H$. As a byproduct of our results, this implies that $H$-IMC is polynomial-time solvable for all graphs $H$ with at most $5$ vertices, except for three open cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00161v4</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cl\'ement Dallard, Ma\"el Dumas, Claire Hilaire, Anthony Perez</dc:creator>
    </item>
    <item>
      <title>Space-Efficient Hierholzer: Eulerian Cycles in $\mathrm{O}(m)$ Time and $\mathrm{O}(n)$ Space</title>
      <link>https://arxiv.org/abs/2508.05251</link>
      <description>arXiv:2508.05251v2 Announce Type: replace 
Abstract: We describe a simple variant of Hierholzer's algorithm that finds an Eulerian cycle in a (multi)graph with $n$ vertices and $m$ edges using $\mathrm{O}(n \lg m)$ bits of working memory. This substantially improves the working space compared to standard implementations of Hierholzer's algorithm, which use $\mathrm{O}(m \lg n)$ bits of space. Our algorithm runs in linear time, like the classical versions, but avoids an $\mathrm{O}(m)$-size stack of vertices or storing information for each edge. To our knowledge, this is the first linear-time algorithm to achieve this space bound, and the method is very easy to implement. The correctness argument, by contrast, is surprisingly subtle; we give a detailed formal proof. The space savings are particularly relevant for dense graphs or multigraphs with large edge multiplicities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05251v2</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziad Ismaili Alaoui, Detlef Plump, Sebastian Wild</dc:creator>
    </item>
    <item>
      <title>Parameterized Algorithms for Diversity of Networks with Ecological Dependencies</title>
      <link>https://arxiv.org/abs/2510.09512</link>
      <description>arXiv:2510.09512v2 Announce Type: replace 
Abstract: For a phylogenetic tree, the phylogenetic diversity of a set A of taxa is the total weight of edges on paths to A. Finding small sets of maximal diversity is crucial for conservation planning, as it indicates where limited resources can be invested most efficiently. In recent years, efficient algorithms have been developed to find sets of taxa that maximize phylogenetic diversity either in a phylogenetic network or in a phylogenetic tree subject to ecological constraints, such as a food web. However, these aspects have mostly been studied independently. Since both factors are biologically important, it seems natural to consider them together. In this paper, we introduce decision problems where, given a phylogenetic network, a food web, and integers k, and D, the task is to find a set of k taxa with phylogenetic diversity of at least D under the maximize all paths measure, while also satisfying viability conditions within the food web. Here, we consider different definitions of viability, which all demand that a "sufficient" number of prey species survive to support surviving predators. We investigate the parameterized complexity of these problems and present several fixed-parameter tractable (FPT) algorithms. Specifically, we provide a complete complexity dichotomy characterizing which combinations of parameters - out of the size constraint k, the acceptable diversity loss D, the scanwidth of the food web, the maximum in-degree in the network, and the network height h - lead to W[1]-hardness and which admit FPT algorithms. Our primary methodological contribution is a novel algorithmic framework for solving phylogenetic diversity problems in networks where dependencies (such as those from a food web) impose an order, using a color coding approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09512v2</guid>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mark Jones, Jannik Schestag</dc:creator>
    </item>
    <item>
      <title>Assignment-Routing Optimization with Cutting-Plane Subtour Elimination: Solver and Benchmark Dataset</title>
      <link>https://arxiv.org/abs/2510.17888</link>
      <description>arXiv:2510.17888v2 Announce Type: replace 
Abstract: We study a joint routing-assignment optimization problem in which a set of items must be paired one-to-one with a set of placeholders while simultaneously determining a Hamiltonian cycle that visits every node exactly once. Both the assignment and routing decisions are optimized jointly to minimize the total travel cost. In this work, we propose a method to solve this problem using an exact MIP formulation with Gurobi, including cutting-plane subtour elimination. With analysis of the computational complexity and through extensive experiments, we analyze the computational limitations of this approach as the problem size grows and reveal the challenges associated with the need for more efficient algorithms for larger instances. The dataset, formulations, and experimental results provided here can serve as benchmarks for future studies in this research area. GitHub repository: https://github.com/QL-YUAN/Joint-Assignment-Routing-Optimization</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17888v2</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qilong Yuan</dc:creator>
    </item>
    <item>
      <title>Hierarchical Exponential Search Via K-Spines</title>
      <link>https://arxiv.org/abs/2510.22837</link>
      <description>arXiv:2510.22837v2 Announce Type: replace 
Abstract: We introduce the concept of a k-spine of a tree. A k-spine is essentially a path in the tree whose removal leaves only "less-bushy" components of a smaller pathwidth. Using a k-spine as a central guide, we introduce an O(klog dist) exponential search algorithm on a tree by searching mainly along the spine to narrow down the target's vicinity and then recursively handling the smaller components.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22837v2</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bob Dong</dc:creator>
    </item>
    <item>
      <title>A Threshold Phenomenon for the Shortest Lattice Vector Problem in the Infinity Norm</title>
      <link>https://arxiv.org/abs/2508.02249</link>
      <description>arXiv:2508.02249v2 Announce Type: replace-cross 
Abstract: One important question in the theory of lattices is to detect a shortest vector: given a norm and a lattice, what is the smallest norm attained by a non-zero vector contained in the lattice? We focus on the infinity norm and work with lattices of the form $A\mathbb{Z}^n$, where $A$ has integer entries and is of full column rank. Finding a shortest vector is NP-hard. We show that this task is fixed parameter tractable in the parameter $\Delta$, the largest absolute value of the determinant of a full rank submatrix of $A$. The algorithm is based on a structural result that can be interpreted as a threshold phenomenon: whenever the dimension $n$ exceeds a certain value determined only by $\Delta$, then a shortest lattice vector attains an infinity norm value of one. This threshold phenomenon has several applications. In particular, it reveals that integer optimal solutions lie on faces of the given polyhedron whose dimensions are bounded only in terms of $\Delta$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02249v2</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stefan Kuhlmann, Robert Weismantel</dc:creator>
    </item>
    <item>
      <title>Computational Complexity in Property Testing</title>
      <link>https://arxiv.org/abs/2510.05927</link>
      <description>arXiv:2510.05927v2 Announce Type: replace-cross 
Abstract: We initiate a systematic study of the computational complexity of property testing, focusing on the relationship between query and time complexity. While traditional work in property testing has emphasized query complexity, relatively little is known about the computational hardness of property testers. Our goal is to chart the landscape of time-query interplay and develop tools for proving time complexity lower bounds. Our first contribution is a pair of time-query hierarchy theorems for property testing. For all suitable nondecreasing functions $q(n)$ and $t(n)$ with $t(n)\geq q(n)$, we construct properties with query complexity $\tilde{\Theta}(q(n))$ and time complexity $\tilde\Omega(t(n))$. Our weak hierarchy holds unconditionally, whereas the strong version-assuming the Strong Exponential Time Hypothesis-provides better control over the time complexity of the constructed properties.
  We then turn to halfspaces in $\mathbb{R}^d$, a fundamental class in property testing and learning theory. We study the problem of approximating the distance from the input function to the nearest halfspace within additive error $\epsilon$. For the distribution-free distance approximation problem, known algorithms achieve query complexity $O(d/\epsilon^2)$, but take time $\tilde{\Theta}(1/\epsilon^d)$. We provide a fine-grained justification for this gap: assuming the $k$-SUM conjecture, any algorithm must have running time ${\Omega}(1/\epsilon^{d/2})$. This fine-grained lower bound yields a provable separation between query and time complexity for a natural and well-studied (tolerant) testing problem. We also prove that any Statistical Query (SQ) algorithm under the standard Gaussian distribution requires $(1/\epsilon)^{\Omega(d)}$ queries if the queries are answered with additive error up to $\epsilon^{\Omega(d)}$, revealing a fundamental barrier even in the distribution-specific setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05927v2</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Renato Ferreira Pinto Jr., Diptaksho Palit, Sofya Raskhodnikova</dc:creator>
    </item>
  </channel>
</rss>
