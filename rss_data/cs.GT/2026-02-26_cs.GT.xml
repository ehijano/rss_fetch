<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 27 Feb 2026 02:42:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A General Equilibrium Theory of Orchestrated AI Agent Systems</title>
      <link>https://arxiv.org/abs/2602.21255</link>
      <description>arXiv:2602.21255v1 Announce Type: new 
Abstract: We establish a general equilibrium theory for systems of large language model (LLM) agents operating under centralized orchestration. The framework is a production economy in the sense of Arrow-Debreu (1954), extended to infinite-dimensional commodity spaces following Bewley (1972). Each LLM agent is modeled as a firm whose production set Y a $\subset$ H = L 2 ([0, T ], R R ) represents the feasible metric trajectories determined by its frozen model weights. The orchestrator is the consumer, choosing a routing policy over the agent DAG to maximize system welfare subject to a budget constraint evaluated at functional prices p $\in$ H A . These prices-elements of the Hilbert dual of the commodity space-assign a shadow value to each metric of each agent at each instant. We prove, via Brouwer's theorem applied to a finitedimensional approximation V K $\subset$ H, that every such economy admits at least one general equilibrium (p * , y * , $\pi$ * ). A functional Walras' law  holds as a theorem: the value of functional excess demand is zero for all prices, as a consequence of the consumer's budget constraint-not by construction. We further establish Pareto optimality (First Welfare Theorem), decentralizability of Pareto optima (Second Welfare Theorem), and uniqueness with geometric convergence under a contraction condition (Banach). The orchestration dynamics constitute a Walrasian t{\^a}tonnement that converges globally under the contraction condition, unlike classical t{\^a}tonnement (Scarf, 1960). The framework admits a DSGE interpretation with SLO parameters as policy rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21255v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jean-Philippe Garnier (Br.AI.K)</dc:creator>
    </item>
    <item>
      <title>The Headless Firm: How AI Reshapes Enterprise Boundaries</title>
      <link>https://arxiv.org/abs/2602.21401</link>
      <description>arXiv:2602.21401v1 Announce Type: new 
Abstract: The boundary of the firm is determined by coordination cost. We argue that agentic AI induces a structural change in how coordination costs scale: in prior modular systems, integration cost grew with interaction topology (O(n^2) in the number of components); in protocol-mediated agentic systems, integration cost collapses to O(n) while verification scales with task throughput rather than interaction count. This shift selects for a specific organizational equilibrium -- the Headless Firm -- structured as an hourglass: a personalized generative interface at the top, a standardized protocol waist in the middle, and a competitive market of micro-specialized execution agents at the bottom. We formalize this claim as a coordination cost model with two falsifiable empirical predictions: (1) the marginal cost of adding an execution provider should be approximately constant in a mature hourglass ecosystem; (2) the ratio of total coordination cost to task throughput should remain stable as ecosystem size grows. We derive conditions for hourglass stability versus re-centralization and analyze implications for firm size distributions, labor markets, and software economics. The analysis predicts a domain-conditional Great Unbundling: in high knowledge-velocity domains, firm size distributions shift mass from large integrated incumbents toward micro-specialized agents and thin protocol orchestrators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21401v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tassilo Klein, Sebastian Wieczorek</dc:creator>
    </item>
    <item>
      <title>Simple vs. Optimal Congestion Pricing</title>
      <link>https://arxiv.org/abs/2602.21495</link>
      <description>arXiv:2602.21495v1 Announce Type: new 
Abstract: Congestion pricing has emerged as an effective tool for mitigating traffic congestion, yet implementing welfare or revenue-optimal dynamic tolls is often impractical. Most real-world congestion pricing deployments, including New York City's recent program, rely on significantly simpler, often static, tolls. This discrepancy motivates the question of how much revenue and welfare loss there is when real-world traffic systems use static rather than optimal dynamic pricing.
  We address this question by analyzing the performance gap between static (simple) and dynamic (optimal) congestion pricing schemes in two canonical frameworks: Vickrey's bottleneck model with a public transit outside option and its city-scale extension based on the Macroscopic Fundamental Diagram (MFD). In both models, we first characterize the revenue-optimal static and dynamic tolling policies, which have received limited attention in prior work. In the worst-case, revenue-optimal static tolls achieve at least half of the dynamic optimal revenue and at most twice the minimum achievable system cost across a wide range of practically relevant parameter regimes, with stronger and more general guarantees in the bottleneck model than in the MFD model. We further corroborate our theoretical guarantees with numerical results based on real-world datasets from the San Francisco Bay Area and New York City, which demonstrate that static tolls achieve roughly 80-90% of the dynamic optimal revenue while incurring at most a 8-20% higher total system cost than the minimum achievable system cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21495v1</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Devansh Jalota, Sharon Di, Adam N. Elmachtoub</dc:creator>
    </item>
    <item>
      <title>Revisiting the Bertrand Paradox via Equilibrium Analysis of No-regret Learners</title>
      <link>https://arxiv.org/abs/2602.21620</link>
      <description>arXiv:2602.21620v1 Announce Type: new 
Abstract: We study the discrete Bertrand pricing game with a non-increasing demand function. The game has $n \ge 2$ players who simultaneously choose prices from the set $\{1/k, 2/k, \ldots, 1\}$, where $k\in\mathbb{N}$. The player who sets the lowest price captures the entire demand; if multiple players tie for the lowest price, they split the demand equally.
  We study the Bertrand paradox, where classical theory predicts low prices, yet real markets often sustain high prices. To understand this gap, we analyze a repeated-game model in which firms set prices using no-regret learners. Our goal is to characterize the equilibrium outcomes that can arise under different no-regret learning guarantees. We are particularly interested in questions such as whether no-external-regret learners can converge to undesirable high-price outcomes, and how stronger guarantees such as no-swap regret shape the emergence of competitive low-price behavior. We address these and related questions through a theoretical analysis, complemented by experiments that support the theory and reveal surprising phenomena for no-swap regret learners.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21620v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arnab Maiti, Junyan Liu, Kevin Jamieson, Lillian J. Ratliff</dc:creator>
    </item>
    <item>
      <title>Solving Imperfect-Recall Games via Sum-of-Squares Optimization</title>
      <link>https://arxiv.org/abs/2602.21722</link>
      <description>arXiv:2602.21722v1 Announce Type: new 
Abstract: Extensive-form games (EFGs) provide a powerful framework for modeling sequential decision making, capturing strategic interaction under imperfect information, chance events, and temporal structure. Most positive algorithmic and theoretical results for EFGs assume perfect recall, where players remember all past information and actions. We study the increasingly relevant setting of imperfect-recall EFGs (IREFGs), where players may forget parts of their history or previously acquired information, and where equilibrium computation is provably hard. We propose sum-of-squares (SOS) hierarchies for computing ex-ante optimal strategies in single-player IREFGs and Nash equilibria in multi-player IREFGs, working over behavioral strategies. Our theoretical results show that (i) these hierarchies converge asymptotically, (ii) under genericity assumptions, the convergence is finite, and (iii) in single-player non-absentminded IREFGs, convergence occurs at a finite level determined by the number of information sets. Finally, we introduce the new classes of (SOS)-concave and (SOS)-monotone IREFGs, and show that in the single-player setting the SOS hierarchy converges at the first level, enabling equilibrium computation with a single semidefinite program (SDP).</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21722v1</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rui Zheng, Ryann Sim, Antonios Varvitsiotis</dc:creator>
    </item>
    <item>
      <title>Autobidding Equilibria in Sponsored Shopping</title>
      <link>https://arxiv.org/abs/2602.21966</link>
      <description>arXiv:2602.21966v2 Announce Type: new 
Abstract: As commerce shifts to digital marketplaces, platforms increasingly monetize traffic through Sponsored Shopping auctions. Unlike classic ``Sponsored Search", where an advertiser typically bids for a single link, these settings involve advertisers with broad catalogs of distinct products. In these auctions, a single advertiser can secure multiple slots simultaneously to promote different items within the same query. This creates a fundamental complexity: the allocation is combinatorial, as advertisers simultaneously win a bundle of slots rather than a single position.
  We study this setting through the lens of autobidding, where value-maximizing agents employ uniform bidding strategies to optimize total value subject to Return-on-Investment (ROI) constraints. We analyze two prevalent auction formats: Generalized Second-Price (GSP) and Vickrey-Clarke-Groves (VCG). Our first main contribution is establishing the universal existence of an Autobidding Equilibrium for both settings. Second, we prove a tight Price of Anarchy (PoA) of 2 for both mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21966v2</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paul D\"utting, Yuhao Li, Renato Paes Leme, Kelly Spendlove, Yifeng Teng</dc:creator>
    </item>
    <item>
      <title>Timing Games: Probabilistic backrunning and spam</title>
      <link>https://arxiv.org/abs/2602.22032</link>
      <description>arXiv:2602.22032v1 Announce Type: new 
Abstract: There are $n$ players who compete by timing their actions. An opportunity appears randomly on a time interval. Whoever takes an action the fastest after the opportunity has arisen wins. The occurrence of the opportunity is observed only with a delay. Taking actions is costly. We characterize the unique symmetric equilibrium of this game and study worst-case inefficiency of equilibria. Our main motivation is the study of ``probabilistic backrunning" on blockchains, where arbitrageurs want to place an order immediately after a trade that impacts the price on an exchange or after an oracle update. In this context, the number of actions taken can be interpreted as a measure of costly ``spam" generated to compete for the opportunity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22032v1</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bruno Mazorra, Christoph Schlegel, Akaki Mamageishvili</dc:creator>
    </item>
    <item>
      <title>Efficient Opportunistic Approachability</title>
      <link>https://arxiv.org/abs/2602.21328</link>
      <description>arXiv:2602.21328v1 Announce Type: cross 
Abstract: We study the problem of opportunistic approachability: a generalization of Blackwell approachability where the learner would like to obtain stronger guarantees (i.e., approach a smaller set) when their adversary limits themselves to a subset of their possible action space. Bernstein et al. (2014) introduced this problem in 2014 and presented an algorithm that guarantees sublinear approachability rates for opportunistic approachability. However, this algorithm requires the ability to produce calibrated online predictions of the adversary's actions, a problem whose standard implementations require time exponential in the ambient dimension and result in approachability rates that scale as $T^{-O(1/d)}$. In this paper, we present an efficient algorithm for opportunistic approachability that achieves a rate of $O(T^{-1/4})$ (and an inefficient one that achieves a rate of $O(T^{-1/3})$), bypassing the need for an online calibration subroutine. Moreover, in the case where the dimension of the adversary's action set is at most two, we show it is possible to obtain the optimal rate of $O(T^{-1/2})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21328v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Teodor Vanislavov Marinov, Mehryar Mohri, Princewill Okoroafor, Jon Schneider, Julian Zimmert</dc:creator>
    </item>
    <item>
      <title>Efficient Uncoupled Learning Dynamics with $\tilde{O}\!\left(T^{-1/4}\right)$ Last-Iterate Convergence in Bilinear Saddle-Point Problems over Convex Sets under Bandit Feedback</title>
      <link>https://arxiv.org/abs/2602.21436</link>
      <description>arXiv:2602.21436v1 Announce Type: cross 
Abstract: In this paper, we study last-iterate convergence of learning algorithms in bilinear saddle-point problems, a preferable notion of convergence that captures the day-to-day behavior of learning dynamics. We focus on the challenging setting where players select actions from compact convex sets and receive only bandit feedback. Our main contribution is the design of an uncoupled learning algorithm that guarantees last-iterate convergence to the Nash equilibrium with high probability. We establish a convergence rate of $\tilde{O}(T^{-1/4})$ up to polynomial factors in problem parameters. Crucially, our proposed algorithm is computationally efficient, requiring only an efficient linear optimization oracle over the players' compact action sets. The algorithm is obtained by combining techniques from experimental design and the classic Follow-The-Regularized-Leader (FTRL) framework, with a carefully chosen regularizer function tailored to the geometry of the action set of each learner.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21436v1</guid>
      <category>stat.ML</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arnab Maiti, Claire Jie Zhang, Kevin Jamieson, Jamie Heather Morgenstern, Ioannis Panageas, Lillian J. Ratliff</dc:creator>
    </item>
    <item>
      <title>Delegation in Strategic Environments and Equilibrium Uniqueness</title>
      <link>https://arxiv.org/abs/2602.21470</link>
      <description>arXiv:2602.21470v1 Announce Type: cross 
Abstract: We ask when a normal-form game yields a single equilibrium prediction, even if players can coordinate by delegating play to an intermediary such as a platform or a cartel. Delegation outcomes are modeled via coarse correlated equilibria (CCE) when the intermediary cannot punish deviators, and via the set of individually rational correlated profiles (IRCP) when it can. We characterize games in which the IRCP or the CCE is unique, uncovering a structural link between these solution concepts. Our analysis also provides new conditions for the uniqueness of classical correlated and Nash equilibria that do not rely on the existence of dominant strategies. The resulting equilibria are robust to players' information about the environment, payoff perturbations, pre-play communication, equilibrium selection, and learning dynamics. We apply these results to collusion-proof mechanism design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21470v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fedor Sandomirskiy, Ben Wincelberg</dc:creator>
    </item>
    <item>
      <title>Power and Limitations of Aggregation in Compound AI Systems</title>
      <link>https://arxiv.org/abs/2602.21556</link>
      <description>arXiv:2602.21556v1 Announce Type: cross 
Abstract: When designing compound AI systems, a common approach is to query multiple copies of the same model and aggregate the responses to produce a synthesized output. Given the homogeneity of these models, this raises the question of whether aggregation unlocks access to a greater set of outputs than querying a single model. In this work, we investigate the power and limitations of aggregation within a stylized principal-agent framework. This framework models how the system designer can partially steer each agent's output through its reward function specification, but still faces limitations due to prompt engineering ability and model capabilities. Our analysis uncovers three natural mechanisms -- feasibility expansion, support expansion, and binding set contraction -- through which aggregation expands the set of outputs that are elicitable by the system designer. We prove that any aggregation operation must implement one of these mechanisms in order to be elicitability-expanding, and that strengthened versions of these mechanisms provide necessary and sufficient conditions that fully characterize elicitability-expansion. Finally, we provide an empirical illustration of our findings for LLMs deployed in a toy reference-generation task. Altogether, our results take a step towards characterizing when compound AI systems can overcome limitations in model capabilities and in prompt engineering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21556v1</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nivasini Ananthakrishnan, Meena Jagadeesan</dc:creator>
    </item>
    <item>
      <title>Perpetually Fair Assignments Via Balanced Sequences of Permutations</title>
      <link>https://arxiv.org/abs/2602.21687</link>
      <description>arXiv:2602.21687v1 Announce Type: cross 
Abstract: There is a set of n indivisible items (or chores), and a set of n players. Each day, a single item should be assigned to each player. We want to ensure that all players feel that they have been treated fairly, not only after the last day, but after every single day. We present two 'balance' conditions on sequences of permutations. One condition can always be satisfied, but is arguably too weak; a second condition is strong, and can be satisfied for all n &lt;= 11, but cannot be satisfied for some larger values of n, including all n&gt;61.
  We then relate the 'balance' condition to the requirement that the cumulative assignment is proportional up to one item (PROP1), where proportionality holds in a strong ordinal sense -- for every valuations that are consistent with the item ranking. We present a third balance condition that implies ordinal PROP1. We show that a sequence guaranteeing this balance condition exists for all n &lt;= 12, but might not exist when n=6k for any k &gt;= 19.
  Finally, we present a fourth, weaker balance condition on a sequence, that guarantees ordinal proportionality up to two items (PROP2). Whether or not this condition can be satisfied for all n remains an open question.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21687v1</guid>
      <category>math.CO</category>
      <category>cs.GT</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Terrence Adams, Erel Segal-Halevi</dc:creator>
    </item>
    <item>
      <title>Private and Robust Contribution Evaluation in Federated Learning</title>
      <link>https://arxiv.org/abs/2602.21721</link>
      <description>arXiv:2602.21721v1 Announce Type: cross 
Abstract: Cross-silo federated learning allows multiple organizations to collaboratively train machine learning models without sharing raw data, but client updates can still leak sensitive information through inference attacks. Secure aggregation protects privacy by hiding individual updates, yet it complicates contribution evaluation, which is critical for fair rewards and detecting low-quality or malicious participants. Existing marginal-contribution methods, such as the Shapley value, are incompatible with secure aggregation, and practical alternatives, such as Leave-One-Out, are crude and rely on self-evaluation.
  We introduce two marginal-difference contribution scores compatible with secure aggregation. Fair-Private satisfies standard fairness axioms, while Everybody-Else eliminates self-evaluation and provides resistance to manipulation, addressing a largely overlooked vulnerability. We provide theoretical guarantees for fairness, privacy, robustness, and computational efficiency, and evaluate our methods on multiple medical image datasets and CIFAR10 in cross-silo settings. Our scores consistently outperform existing baselines, better approximate Shapley-induced client rankings, and improve downstream model performance as well as misbehavior detection. These results demonstrate that fairness, privacy, robustness, and practical utility can be achieved jointly in federated contribution evaluation, offering a principled solution for real-world cross-silo deployments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21721v1</guid>
      <category>cs.CR</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Delio Jaramillo Velez, Gergely Biczok, Alexandre Graell i Amat, Johan Ostman, Balazs Pejo</dc:creator>
    </item>
    <item>
      <title>JSAM: Privacy Straggler-Resilient Joint Client Selection and Incentive Mechanism Design in Differentially Private Federated Learning</title>
      <link>https://arxiv.org/abs/2602.21844</link>
      <description>arXiv:2602.21844v1 Announce Type: cross 
Abstract: Differentially private federated learning faces a fundamental tension: privacy protection mechanisms that safeguard client data simultaneously create quantifiable privacy costs that discourage participation, undermining the collaborative training process. Existing incentive mechanisms rely on unbiased client selection, forcing servers to compensate even the most privacy-sensitive clients ("privacy stragglers"), leading to systemic inefficiency and suboptimal resource allocation. We introduce JSAM (Joint client Selection and privacy compensAtion Mechanism), a Bayesian-optimal framework that simultaneously optimizes client selection probabilities and privacy compensation to maximize training effectiveness under budget constraints. Our approach transforms a complex 2N-dimensional optimization problem into an efficient three-dimensional formulation through novel theoretical characterization of optimal selection strategies. We prove that servers should preferentially select privacy-tolerant clients while excluding high-sensitivity participants, and uncover the counter-intuitive insight that clients with minimal privacy sensitivity may incur the highest cumulative costs due to frequent participation. Extensive evaluations on MNIST and CIFAR-10 demonstrate that JSAM achieves up to 15% improvement in test accuracy compared to existing unbiased selection mechanisms while maintaining cost efficiency across varying data heterogeneity levels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21844v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.GT</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruichen Xu, Ying-Jun Angela Zhang, Jianwei Huang</dc:creator>
    </item>
    <item>
      <title>Weakly-Popular and Super-Popular Matchings with Ties and Their Connection to Stable Matchings</title>
      <link>https://arxiv.org/abs/2310.12269</link>
      <description>arXiv:2310.12269v4 Announce Type: replace 
Abstract: The efficient computation of large matchings with desirable guarantees is a crucial objective in market design. However, even in simple two-sided matching markets with weak ordinal preferences, finding a maximum-size stable matching is NP-hard. Alternatively, popular matchings can be of larger size, but their existence is not guaranteed. In this paper, we study a new definition of popularity with two-sided weak preferences, where agents are only indifferent between two matchings if they receive the same partner. We show that this alternative definition of popularity, which we call weak popularity, guarantees the existence of such matchings. Unfortunately, finding a maximum-size weakly popular matching turns out to be NP-hard even with one-sided ties. However, we provide a polynomial-time algorithm to find a weakly popular matching that has at least $\frac{3}{4}$ times the size of a maximum-size weakly popular matching. We complement our approximation results with an Integer Linear Programming formulation that solves the maximum-size weakly popular matching problem exactly. We evaluate our algorithms on both randomly generated and real-world instances. Our experiments demonstrate that weakly popular matchings can be significantly larger than stable matchings, often covering all agents. Furthermore, we show that our approximation algorithm performs nearly optimally in practice. Finally, we show that maximum-size weakly popular matchings can have very few blocking edges, suggesting that weak popularity offers a desirable trade-off between size and stability. We also study a model more general than weak popularity, where for each edge, we can specify for both agents the size of improvement the agent needs to vote in favor of a new matching. We show that even in this more general model, a so-called $\gamma$-popular matching always exists, and our approximation algorithm applies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.12269v4</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gergely Cs\'aji, Frederik Glitzner</dc:creator>
    </item>
    <item>
      <title>Random-Restart Best-Response Dynamics for Large-Scale Integer Programming Games and Their Applications</title>
      <link>https://arxiv.org/abs/2409.04078</link>
      <description>arXiv:2409.04078v3 Announce Type: replace 
Abstract: This paper presents scalable algorithms for computing pure Nash equilibria (PNEs) in large-scale integer programming games (IPGs), where existing exact methods typically handle only small numbers of players. Motivated by a county-level aquatic invasive species (AIS) prevention problem with 84 decision makers, we develop and analyze random-restart best-response dynamics (RR-BRD), a randomized search framework for PNEs. For IPGs with finite action sets, we model RR-BRD as a Markov chain on the best-response state graph and show that, whenever a PNE exists and the restart law has positive probability of reaching a PNE within the round cap, RR-BRD finds a PNE almost surely. We also propose a Monte Carlo sampling-and-simulation procedure to estimate success behavior under a fixed round cap, which informs our instance-dependent performance characterization. We then embed RR-BRD as a randomized local-search subroutine within the zero-regret (ZR) framework, yielding BRD-incorporated zero-regret (BZR). Using solver callbacks, RR-BRD searches for and supplies PNEs, while ZR separates and adds equilibrium inequalities to tighten the formulation. We introduce edge-weighted budgeted maximum coverage (EBMC) games to model AIS prevention and establish PNE existence results for both selfish and locally altruistic utilities. Computational experiments on synthetic EBMC and knapsack problem game instances show that RR-BRD and BZR scale equilibrium computation up to $n \le 30$ players. We further solve a real-world EBMC game derived from the Minnesota AIS dataset with $n = 84$ county players.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04078v3</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hyunwoo Lee, Robert Hildebrand, Wenbo Cai, \.I. Esra B\"uy\"uktahtak{\i}n</dc:creator>
    </item>
    <item>
      <title>Multi-Fidelity Bayesian Optimization for Nash Equilibria with Black-Box Utilities</title>
      <link>https://arxiv.org/abs/2505.11265</link>
      <description>arXiv:2505.11265v2 Announce Type: replace 
Abstract: Modern open and softwarized systems -- such as O-RAN telecom networks and cloud computing platforms -- host independently developed applications with distinct, and potentially conflicting, objectives. Coordinating the behavior of such applications to ensure stable system operation poses significant challenges, especially when each application's utility is accessible only via costly, black-box evaluations. In this paper, we consider a centralized optimization framework in which a system controller suggests joint configurations to multiple strategic players, representing different applications, with the goal of aligning their incentives toward a stable outcome. This interaction is modeled as a learned optimization with an equilibrium constraint in which the central optimizer learns the utility functions through sequential, multi-fidelity evaluations with the goal of identifying a pure Nash equilibrium (PNE). To address this challenge, we propose MF-UCB-PNE, a novel multi-fidelity Bayesian optimization strategy that leverages a budget-constrained sampling process to approximate PNE solutions. MF-UCB-PNE systematically balances exploration across low-cost approximations with high-fidelity exploitation steps, enabling efficient convergence to incentive-compatible configurations. We provide theoretical and empirical insights into the trade-offs between query cost and equilibrium accuracy, demonstrating the effectiveness of MF-UCB-PNE in identifying effective equilibrium solutions under limited cost budgets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11265v2</guid>
      <category>cs.GT</category>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunchuan Zhang, Osvaldo Simeone, H. Vincent Poor</dc:creator>
    </item>
    <item>
      <title>Toward a Multi-Echelon Cyber Warfare Theory: A Meta-Game-Theoretic Paradigm for Defense and Dominance</title>
      <link>https://arxiv.org/abs/2509.08976</link>
      <description>arXiv:2509.08976v2 Announce Type: replace 
Abstract: Cyber warfare has become a central element of modern conflict, especially within multi-domain operations. As both a distinct and critical domain, cyber warfare requires integrating defensive and offensive technologies into coherent strategies. While prior research has emphasized isolated tactics or fragmented technologies, a holistic understanding is essential for effective resource deployment and risk mitigation. Game theory offers a unifying framework for this purpose. It not only models attacker-defender interactions but also provides quantitative tools for equilibrium analysis, risk assessment, and strategic reasoning. Integrated with modern AI techniques, game-theoretic models enable the design and optimization of strategies across multiple levels of cyber warfare, from policy and strategy to operations, tactics, and technical implementations. These models capture the paradoxical logic of conflict, where more resources do not always translate into greater advantage, and where nonlinear dynamics govern outcomes. To illustrate the approach, this chapter examines RedCyber, a synthetic cyber conflict, demonstrating how game-theoretic methods capture the interdependencies of cyber operations. The chapter concludes with directions for future research on resilience, cros-echelon planning, and the evolving role of AI in cyber warfare.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.08976v2</guid>
      <category>cs.GT</category>
      <category>cs.ET</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ya-Ting Yang, Quanyan Zhu</dc:creator>
    </item>
    <item>
      <title>Optimal Selection Using Algorithmic Rankings with Side Information</title>
      <link>https://arxiv.org/abs/2511.04867</link>
      <description>arXiv:2511.04867v3 Announce Type: replace 
Abstract: Motivated by online platforms such as job markets, we study an agent choosing from a list of candidates, each with a hidden quality that determines match value. The agent observes only a noisy ranking of the candidates plus a binary signal that indicates whether each candidate is "free" or "busy". Being busy is positively correlated with higher quality, but can also reduce value due to decreased availability. We study the agent's optimal selection problem in the presence of ranking noise and free-busy signals and ask how the accuracy of the ranking tool impacts outcomes. In a setting with one high-valued candidate and an arbitrary number of low-valued candidates, we show that increased accuracy of the ranking tool can result in suboptimal social outcomes. For example, increased accuracy may mean that agents may be more likely to make offers to busy candidates, and (counter-intuitively) may be more likely to select lower-ranked candidates. We further discuss conditions under which these results extend to more general settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04867v3</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kate Donahue, Nicole Immorlica, Brendan Lucier</dc:creator>
    </item>
    <item>
      <title>Maximin Share Guarantees via Limited Cost-Sensitive Sharing</title>
      <link>https://arxiv.org/abs/2602.20541</link>
      <description>arXiv:2602.20541v2 Announce Type: replace 
Abstract: We study the problem of fairly allocating indivisible goods when limited sharing is allowed, that is, each good may be allocated to up to $k$ agents, while incurring a cost for sharing. While classic maximin share (MMS) allocations may not exist in many instances, we demonstrate that allowing controlled sharing can restore fairness guarantees that are otherwise unattainable in certain scenarios. (1) Our first contribution shows that exact maximin share (MMS) allocations are guaranteed to exist whenever goods are allowed to be cost-sensitively shared among at least half of the agents and the number of agents is even; for odd numbers of agents, we obtain a slightly weaker MMS guarantee. (2) We further design a Shared Bag-Filling Algorithm that guarantees a $(1 - C)(k - 1)$-approximate MMS allocation, where $C$ is the maximum cost of sharing a good. Notably, when $(1 - C)(k - 1) \geq 1$, our algorithm recovers an exact MMS allocation. (3) We additionally introduce the Sharing Maximin Share (SMMS) fairness notion, a natural extension of MMS to the $k$-sharing setting. (4) We show that SMMS allocations always exist under identical utilities and for instances with two agents. (5) We construct a counterexample to show the impossibility of the universal existence of an SMMS allocation. (6) Finally, we establish a connection between SMMS and constrained MMS (CMMS), yielding approximation guarantees for SMMS via existing CMMS results. These contributions provide deep theoretical insights for the problem of fair resource allocation when a limited sharing of resources are allowed in multi-agent environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.20541v2</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.65109/LGSS5881</arxiv:DOI>
      <dc:creator>Hana Salavcova, Martin \v{C}ern\'y, Arpita Biswas</dc:creator>
    </item>
    <item>
      <title>Incentive-Aware Synthetic Control: Accurate Counterfactual Estimation via Incentivized Exploration</title>
      <link>https://arxiv.org/abs/2312.16307</link>
      <description>arXiv:2312.16307v3 Announce Type: replace-cross 
Abstract: Synthetic control methods (SCMs) are a canonical approach used to estimate treatment effects from panel data in the internet economy. We shed light on a frequently overlooked but ubiquitous assumption made in SCMs of "overlap": a treated unit can be written as some combination -- typically, convex or linear -- of the units that remain under control. We show that if units select their own interventions, and there is sufficiently large heterogeneity between units that prefer different interventions, overlap will not hold. We address this issue by proposing a recommender system which incentivizes units with different preferences to take interventions they would not normally consider. Specifically, leveraging tools from information design and online learning, we propose an SCM that incentivizes exploration in panel data settings by providing incentive-compatible intervention recommendations to units. We establish this estimator obtains valid counterfactual estimates without the need for an a priori overlap assumption. We extend our results to the setting of synthetic interventions, where the goal is to produce counterfactual outcomes under all interventions, not just control. Finally, we provide two hypothesis tests for determining whether unit overlap holds for a given panel dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.16307v3</guid>
      <category>econ.EM</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Ngo, Keegan Harris, Anish Agarwal, Vasilis Syrgkanis, Zhiwei Steven Wu</dc:creator>
    </item>
    <item>
      <title>Incentive-Aligned Multi-Source LLM Summaries</title>
      <link>https://arxiv.org/abs/2509.25184</link>
      <description>arXiv:2509.25184v2 Announce Type: replace-cross 
Abstract: Large language models (LLMs) are increasingly used in modern search and answer systems to synthesize multiple, sometimes conflicting, texts into a single response, yet current pipelines offer weak incentives for sources to be accurate and are vulnerable to adversarial content. We introduce Truthful Text Summarization (TTS), an incentive-aligned framework that improves factual robustness without ground-truth labels. TTS (i) decomposes a draft synthesis into atomic claims, (ii) elicits each source's stance on every claim, (iii) scores sources with an adapted multi-task peer-prediction mechanism that rewards informative agreement, and (iv) filters unreliable sources before re-summarizing. We establish formal guarantees that align a source's incentives with informative honesty, making truthful reporting the utility-maximizing strategy. Experiments show that TTS improves factual accuracy and robustness while preserving fluency, aligning exposure with informative corroboration and disincentivizing manipulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.25184v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yanchen Jiang, Zhe Feng, Aranyak Mehta</dc:creator>
    </item>
    <item>
      <title>Robust Mechanism Design with Anonymous Information</title>
      <link>https://arxiv.org/abs/2602.20429</link>
      <description>arXiv:2602.20429v2 Announce Type: replace-cross 
Abstract: In practice, auction data are often endogenously censored and anonymous, revealing only limited outcome statistics rather than full bid profiles. We study robust auction design when the seller observes only aggregated, anonymous order statistics and seeks to maximize worst-case expected revenue over all product distributions consistent with the observed statistic. We show that simple and widely used mechanisms are robustly optimal. Specifically, posted pricing is robustly optimal given the distribution of the highest value; the Myerson auction designed for the unique consistent i.i.d. distribution is robustly optimal given the lowest value distribution; and the second-price auction with an optimal reserve is robustly optimal when an intermediate order statistic is observed and the implied i.i.d. distribution is regular above its reserve. More generally, for a broad class of monotone symmetric mechanisms depending only on the top k order statistics, including multi-unit and position auctions, the worst-case revenue is attained under the i.i.d. distribution consistent with the observed k-th order statistic. Our results provide a tractable foundation for non-discriminatory auction design, where fairness and privacy are intrinsic consequences of the information structure rather than imposed constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.20429v2</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhihao Gavin Tang, Shixin Wang</dc:creator>
    </item>
  </channel>
</rss>
