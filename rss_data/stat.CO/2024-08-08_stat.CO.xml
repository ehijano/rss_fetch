<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 08 Aug 2024 05:25:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 08 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Automated Techniques for Efficient Sampling of Piecewise-Deterministic Markov Processes</title>
      <link>https://arxiv.org/abs/2408.03682</link>
      <description>arXiv:2408.03682v1 Announce Type: new 
Abstract: Piecewise deterministic Markov processes (PDMPs) are a class of continuous-time Markov processes that were recently used to develop a new class of Markov chain Monte Carlo algorithms. However, the implementation of the processes is challenging due to the continuous-time aspect and the necessity of integrating the rate function. Recently, Corbella, Spencer, and Roberts (2022) proposed a new algorithm to automate the implementation of the Zig-Zag sampler. However, the efficiency of the algorithm highly depends on a hyperparameter ($t_{\text{max}}$) that is fixed all along the run of the algorithm and needs preliminary runs to tune. In this work, we relax this assumption and propose a new variant of their algorithm that let this parameter change over time and automatically adapt to the target distribution. We also replace the Brent optimization algorithm by a grid-based method to compute the upper bound of the rate function. This method is more robust to the regularity of the function and gives a tighter upper bound while being quicker to compute. We also extend the algorithm to other PDMPs and provide a Python implementation of the algorithm based on JAX.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03682v1</guid>
      <category>stat.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Charly Andral, Kengo Kamatani</dc:creator>
    </item>
    <item>
      <title>A Novel Approximate Bayesian Inference Method for Compartmental Models in Epidemiology using Stan</title>
      <link>https://arxiv.org/abs/2408.03415</link>
      <description>arXiv:2408.03415v1 Announce Type: cross 
Abstract: Mechanistic compartmental models are widely used in epidemiology to study the dynamics of infectious disease transmission. These models have significantly contributed to designing and evaluating effective control strategies during pandemics. However, the increasing complexity and the number of parameters needed to describe rapidly evolving transmission scenarios present significant challenges for parameter estimation due to intractable likelihoods. To overcome this issue, likelihood-free methods have proven effective for accurately and efficiently fitting these models to data. In this study, we focus on approximate Bayesian computation (ABC) and synthetic likelihood methods for parameter inference. We develop a method that employs ABC to select the most informative subset of summary statistics, which are then used to construct a synthetic likelihood for posterior sampling. Posterior sampling is performed using Hamiltonian Monte Carlo as implemented in the Stan software. The proposed algorithm is demonstrated through simulation studies, showing promising results for inference in a simulated epidemic scenario.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03415v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xiahui Li, Ben Swallow, Fergus J. Chadwick</dc:creator>
    </item>
    <item>
      <title>Efficient estimation and correction of selection-induced bias with order statistics</title>
      <link>https://arxiv.org/abs/2309.03742</link>
      <description>arXiv:2309.03742v3 Announce Type: replace-cross 
Abstract: Model selection aims to identify a sufficiently well performing model that is possibly simpler than the most complex model among a pool of candidates. However, the decision-making process itself can inadvertently introduce non-negligible bias when the cross-validation estimates of predictive performance are marred by excessive noise. In finite data regimes, cross-validated estimates can encourage the statistician to select one model over another when it is not actually better for future data. While this bias remains negligible in the case of few models, when the pool of candidates grows, and model selection decisions are compounded (as in step-wise selection), the expected magnitude of selection-induced bias is likely to grow too. This paper introduces an efficient approach to estimate and correct selection-induced bias based on order statistics. Numerical experiments demonstrate the reliability of our approach in estimating both selection-induced bias and over-fitting along compounded model selection decisions, with specific application to forward search. This work represents a light-weight alternative to more computationally expensive approaches to correcting selection-induced bias, such as nested cross-validation and the bootstrap. Our approach rests on several theoretic assumptions, and we provide a diagnostic to help understand when these may not be valid and when to fall back on safer, albeit more computationally expensive approaches. The accompanying code facilitates its practical implementation and fosters further exploration in this area.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.03742v3</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s11222-024-10442-4</arxiv:DOI>
      <arxiv:journal_reference>Stat Comput 34, 132 (2024)</arxiv:journal_reference>
      <dc:creator>Yann McLatchie, Aki Vehtari</dc:creator>
    </item>
    <item>
      <title>A novel CFA+EFA model to detect aberrant respondents</title>
      <link>https://arxiv.org/abs/2311.15988</link>
      <description>arXiv:2311.15988v2 Announce Type: replace-cross 
Abstract: Aberrant respondents are common but yet extremely detrimental to the quality of social surveys or questionnaires. Recently, factor mixture models have been employed to identify individuals providing deceptive or careless responses. We propose a comprehensive factor mixture model for continuous outcomes that combines confirmatory and exploratory factor models to classify both the non-aberrant and aberrant respondents. The flexibility of the proposed {classification model} allows for the identification of two of the most common aberrant response styles, namely faking and careless responding. We validated our approach by means of two simulations and two case studies. The results indicate the effectiveness of the proposed model in dealing with aberrant responses in social and behavioural surveys.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.15988v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1093/jrsssc/qlae036</arxiv:DOI>
      <arxiv:journal_reference>Journal of the Royal Statistical Society Series C, Oxford University Press, 2024</arxiv:journal_reference>
      <dc:creator>Niccol\`o Cao, Livio Finos, Luigi Lombardi, Antonio Calcagn\`i</dc:creator>
    </item>
    <item>
      <title>Computationally efficient multi-level Gaussian process regression for functional data observed under completely or partially regular sampling designs</title>
      <link>https://arxiv.org/abs/2406.13691</link>
      <description>arXiv:2406.13691v2 Announce Type: replace-cross 
Abstract: Gaussian process regression is a frequently used statistical method for flexible yet fully probabilistic non-linear regression modeling. A common obstacle is its computational complexity which scales poorly with the number of observations. This is especially an issue when applying Gaussian process models to multiple functions simultaneously in various applications of functional data analysis.
  We consider a multi-level Gaussian process regression model where a common mean function and individual subject-specific deviations are modeled simultaneously as latent Gaussian processes. We derive exact analytic and computationally efficient expressions for the log-likelihood function and the posterior distributions in the case where the observations are sampled on either a completely or partially regular grid. This enables us to fit the model to large data sets that are currently computationally inaccessible using a standard implementation. We show through a simulation study that our analytic expressions are several orders of magnitude faster compared to a standard implementation, and we provide an implementation in the probabilistic programming language Stan.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13691v2</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adam Gorm Hoffmann, Claus Thorn Ekstr{\o}m, Andreas Kryger Jensen</dc:creator>
    </item>
  </channel>
</rss>
