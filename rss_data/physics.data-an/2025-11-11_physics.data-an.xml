<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 11 Nov 2025 05:01:06 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Reverse Stress Testing for Supply Chain Resilience</title>
      <link>https://arxiv.org/abs/2511.07289</link>
      <description>arXiv:2511.07289v1 Announce Type: new 
Abstract: Supply chains increasing globalization and complexity has resulted in recent unpredictable disruptions, ripple effects, and cascading resulting failures. Proposed practices for managing these concerns includes the advanced field of forward stress testing, where threats and predicted impacts to the supply chain are evaluated to harden the system against the most damaging scenarios. Such approaches are limited by the almost endless number of potential threat scenarios and cannot capture residual risk. In contrast to forward stress testing, this paper develops a reverse stress testing (RST) methodology that allows to probabilistically predict which changes across the supply chain network are most likely to cause a specified level of disruption in a specific country or company. The methodology was applied to the case of copper wire production in the USA, a simple good which may have significant implications for national security. Results show that Canada, Chile and Mexico are predicted to consistently be sources of disruptions at multiple loss levels. Other countries may contribute to overall losses during small disruptions but be less important if catastrophic losses are of concern for decision makers (e.g., Papua New Guinea). Yet some countries may be only important when catastrophic disruptions are considered (e.g., Chili). The probabilistic implementation of RST allows for robust and resilient supply chain design addressing both risk and resilience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07289v1</guid>
      <category>physics.data-an</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Madison Smith, Michael Gaiewski, Sam Dulin, Laurel Williams, Jeffrey Keisler, Andrew Jin, Igor Linkov</dc:creator>
    </item>
    <item>
      <title>A Centrality-independent Framework for Revealing Genuine Higher-Order Cumulants in Heavy-Ion Collisions</title>
      <link>https://arxiv.org/abs/2505.03666</link>
      <description>arXiv:2505.03666v2 Announce Type: replace 
Abstract: We propose a novel centrality definition-independent method for analyzing higher-order cumulants, specifically addressing the challenge of volume fluctuations that dominate in low-energy heavy-ion collisions. This method reconstructs particle number distributions using the Edgeworth expansion, with parameters optimized via a combination of differential evolution algorithm and Bayesian inference. Its effectiveness is validated using UrQMD model simulations and benchmarked against traditional approaches, including centrality definitions based on particle multiplicity. Our results show that the proposed framework yields cumulant patterns consistent with those obtained using number of participant nucleon ($N_{\text{part}}$) based centrality observables, while eliminating the conventional reliance on centrality determination. This consistency confirms the method's ability to extract genuine physical signals, thereby paving the way for probing the intrinsic thermodynamic properties of the produced medium through event-by-event fluctuations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03666v2</guid>
      <category>physics.data-an</category>
      <category>hep-ex</category>
      <category>hep-th</category>
      <category>nucl-ex</category>
      <category>nucl-th</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.physletb.2025.139984</arxiv:DOI>
      <arxiv:journal_reference>Physics Letters B 871, 139984 (2025)</arxiv:journal_reference>
      <dc:creator>Zhaohui Wang, Xiaofeng Luo</dc:creator>
    </item>
    <item>
      <title>The Hitchhiker's Guide to Differential Dynamic Microscopy</title>
      <link>https://arxiv.org/abs/2507.05058</link>
      <description>arXiv:2507.05058v2 Announce Type: replace-cross 
Abstract: Over nearly two decades, Differential Dynamic Microscopy (DDM) has become a standard technique for extracting dynamic correlation functions from time-lapse microscopy data, with applications spanning colloidal suspensions, polymer solutions, active fluids, and biological systems. In its most common implementation, DDM analyzes image sequences acquired with a conventional microscope equipped with a digital camera, yielding time- and wavevector-resolved information analogous to that obtained in multi-angle Dynamic Light Scattering (DLS). With a widening array of applications and a growing, heterogeneous user base, lowering the technical barrier to performing DDM has become a central objective. In this tutorial article, we provide a step-by-step guide to conducting DDM experiments -- from planning and acquisition to data analysis -- and introduce the open-source software package fastDDM, designed to efficiently process large image datasets. fastDDM employs optimized, parallel algorithms that reduce analysis times by up to four orders of magnitude on typical datasets (e.g., 10,000 frames), thereby enabling high-throughput workflows and making DDM more broadly accessible across disciplines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05058v2</guid>
      <category>cond-mat.soft</category>
      <category>physics.bio-ph</category>
      <category>physics.data-an</category>
      <category>physics.optics</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1063/5.0289471</arxiv:DOI>
      <arxiv:journal_reference>J. Chem. Phys. 163, 161501 (2025)</arxiv:journal_reference>
      <dc:creator>Enrico Lattuada, Fabian Krautgasser, Maxime Lavaud, Fabio Giavazzi, Roberto Cerbino</dc:creator>
    </item>
    <item>
      <title>On the Practical Use of Blaschke Decomposition in Nonstationary Signal Analysis</title>
      <link>https://arxiv.org/abs/2508.10861</link>
      <description>arXiv:2508.10861v2 Announce Type: replace-cross 
Abstract: The Blaschke decomposition-based algorithm, {\em Phase Dynamics Unwinding} (PDU), possesses several attractive theoretical properties, including fast convergence, effective decomposition, and multiscale analysis. However, its application to real-world signal decomposition tasks encounters notable challenges. In this work, we propose two techniques, divide-and-conquer via tapering and cumulative summation (cumsum), to handle complex trends and amplitude modulations and the mode-mixing caused by winding. The resulting method, termed {\em windowed PDU}, enhances PDU's performance in practical decomposition tasks. We validate our approach through both simulated and real-world signals, demonstrating its effectiveness across diverse scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10861v2</guid>
      <category>stat.ME</category>
      <category>math.CV</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ronald R. Coifman, Hau-Tieng Wu</dc:creator>
    </item>
    <item>
      <title>Lagrangian neural ODEs: Measuring the existence of a Lagrangian with Helmholtz metrics</title>
      <link>https://arxiv.org/abs/2510.06367</link>
      <description>arXiv:2510.06367v2 Announce Type: replace-cross 
Abstract: Neural ODEs are a widely used, powerful machine learning technique in particular for physics. However, not every solution is physical in that it is an Euler-Lagrange equation. We present Helmholtz metrics to quantify this resemblance for a given ODE and demonstrate their capabilities on several fundamental systems with noise. We combine them with a second order neural ODE to form a Lagrangian neural ODE, which allows to learn Euler-Lagrange equations in a direct fashion and with zero additional inference cost. We demonstrate that, using only positional data, they can distinguish Lagrangian and non-Lagrangian systems and improve the neural ODE solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06367v2</guid>
      <category>cs.LG</category>
      <category>math.DS</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luca Wolf, Tobias Buck, Bjoern Malte Schaefer</dc:creator>
    </item>
  </channel>
</rss>
