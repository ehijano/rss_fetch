<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 19 Feb 2025 18:14:23 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Mamute: high-performance computing for geophysical methods</title>
      <link>https://arxiv.org/abs/2502.12350</link>
      <description>arXiv:2502.12350v1 Announce Type: new 
Abstract: Due to their high computational cost, geophysical applications are typically designed to run in large computing systems. Because of that, such applications must implement several high-performance techniques to use the computational resources better. In this paper, we present Mamute, a software that delivers wave equation-based geophysical methods. Mamute implements two geophysical methods: seismic modeling and full waveform inversion (FWI). It also supports high-performance strategies such as fault tolerance, automatic parallel looping scheduling, and distributed systems workload balancing. We demonstrate Mamute's operation using both seismic modeling and FWI. Mamute is a C++ software readily available under the MIT license.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12350v1</guid>
      <category>cs.CE</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Jo\~ao B. Fernandes, Ant\^onio D. S. Oliveira, Mateus C. A. T. Silva, Felipe H. Santos-da-Silva, Vitor H. M. Rodrigues, Kleiton A. Schneider, Calebe P. Bianchini, Jo\~ao M. de Araujo, Tiago Barros, \'Italo A. S. Assis, Samuel Xavier-de-Souza</dc:creator>
    </item>
    <item>
      <title>Risk Assessment of Transmission Lines Against Grid-ignited Wildfires</title>
      <link>https://arxiv.org/abs/2502.12401</link>
      <description>arXiv:2502.12401v1 Announce Type: new 
Abstract: Wildfires ignited by the power lines have become increasingly common over the past decade. Enhancing the operational and financial resilience of power grids against wildfires involves a multifaceted approach. Key proactive measures include meticulous vegetation management, strategic grid hardening such as infrastructure undergrounding, preemptive de-energization, and disaster risk financing, among others. Each measure should be tailored to prioritize efforts in mitigating the consequences of wildfires. This paper proposes a transmission line risk assessment method for grid-ignited wildfires, identifying the transmission lines that could potentially lead to damage to the natural and built environment and to other transmission lines if igniting a wildfire. Grid, meteorological, and topological datasets are combined to enable a comprehensive analysis. Numerical analysis on the standard IEEE 30-bus system demonstrates the effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12401v1</guid>
      <category>cs.CE</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Saeed Nematshahi, Amin Khodaei, Ali Arabnya</dc:creator>
    </item>
    <item>
      <title>An Investment Prioritization Model for Wildfire Risk Mitigation Through Power Line Undergrounding</title>
      <link>https://arxiv.org/abs/2502.12405</link>
      <description>arXiv:2502.12405v1 Announce Type: new 
Abstract: Grid-ignited wildfires are one of the most destructive catastrophic events, profoundly affecting the built and natural environments. Burying power lines is an effective solution for mitigating the risk of wildfire ignition. However, it is a costly capital expenditure (CapEx) requiring meticulous planning and investment prioritization. This paper proposes a systematic approach to estimate the potential wildfire ignition damage associated with each transmission line and accordingly offers a priority list for undergrounding. The proposed approach allows electric utilities to make risk-informed decisions for grid modernization and resiliency improvement against wildfires. As a case study, we examine the likelihood of wildfire ignition for each line segment, i.e., between two high-voltage towers, under diverse weather conditions throughout the year. The studies on the standard IEEE 30-bus test system, simulated on 43,712 scenarios, demonstrate the effectiveness of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12405v1</guid>
      <category>cs.CE</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Saeed Nematshahi, Amin Khodaei, Ali Arabnya</dc:creator>
    </item>
    <item>
      <title>The Early Days of the Ethereum Blob Fee Market and Lessons Learnt</title>
      <link>https://arxiv.org/abs/2502.12966</link>
      <description>arXiv:2502.12966v1 Announce Type: new 
Abstract: Ethereum has adopted a rollup-centric roadmap to scale by making rollups (layer 2 scaling solutions) the primary method for handling transactions. The first significant step towards this goal was EIP-4844, which introduced blob transactions that are designed to meet the data availability needs of layer 2 protocols. This work constitutes the first rigorous and comprehensive empirical analysis of transaction- and mempool-level data since the institution of blobs on Ethereum on March 13, 2024. We perform a longitudinal study of the early days of the blob fee market analyzing the landscape and the behaviors of its participants. We identify and measure the inefficiencies arising out of suboptimal block packing, showing that at times it has resulted in up to 70% relative fee loss. We hone in and give further insight into two (congested) peak demand periods for blobs. Finally, we document a market design issue relating to subset bidding due to the inflexibility of the transaction structure on packing data as blobs and suggest possible ways to fix it. The latter market structure issue also applies more generally for any discrete objects included within transactions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12966v1</guid>
      <category>cs.CE</category>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lioba Heimbach, Jason Milionis</dc:creator>
    </item>
    <item>
      <title>Robust blue-green urban flood risk management optimised with a genetic algorithm for multiple rainstorm return periods</title>
      <link>https://arxiv.org/abs/2502.12174</link>
      <description>arXiv:2502.12174v1 Announce Type: cross 
Abstract: Flood risk managers seek to optimise Blue-Green Infrastructure (BGI) designs to maximise return on investment. Current systems often use optimisation algorithms and detailed flood models to maximise benefit-cost ratios for single rainstorm return periods. However, these schemes may lack robustness in mitigating flood risks across different storm magnitudes. For example, a BGI scheme optimised for a 100-year return period may differ from one optimised for a 10-year return period. This study introduces a novel methodology incorporating five return periods (T = 10, 20, 30, 50, and 100 years) into a multi-objective BGI optimisation framework. The framework combines a Non-dominated Sorting Genetic Algorithm II (NSGA-II) with a fully distributed hydrodynamic model to optimise the spatial placement and combined size of BGI features. For the first time, direct damage cost (DDC) and expected annual damage (EAD), calculated for various building types, are used as risk objective functions, transforming a many-objective problem into a multi-objective one. Performance metrics such as Median Risk Difference (MedRD), Maximum Risk Difference (MaxRD), and Area Under Pareto Front (AUPF) reveal that a 100-year optimised BGI design performs poorly when evaluated for other return periods, particularly shorter ones. In contrast, a BGI design optimised using composite return periods enhances performance metrics across all return periods, with the greatest improvements observed in MedRD (22%) and AUPF (73%) for the 20-year return period, and MaxRD (23%) for the 50-year return period. Furthermore, climate uplift stress testing confirms the robustness of the proposed design to future rainfall extremes. This study advocates a paradigm shift in flood risk management, moving from single maximum to multiple rainstorm return period-based designs to enhance resilience and adaptability to future climate extremes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12174v1</guid>
      <category>cs.NE</category>
      <category>cs.CE</category>
      <category>cs.CY</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Asid Ur Rehman, Vassilis Glenis, Elizabeth Lewis, Chris Kilsby, Claire Walsh</dc:creator>
    </item>
    <item>
      <title>Scientific Machine Learning of Flow Resistance Using Universal Shallow Water Equations with Differentiable Programming</title>
      <link>https://arxiv.org/abs/2502.12396</link>
      <description>arXiv:2502.12396v1 Announce Type: cross 
Abstract: Shallow water equations (SWEs) are the backbone of most hydrodynamics models for flood prediction, river engineering, and many other water resources applications. The estimation of flow resistance, i.e., the Manning's roughness coefficient $n$, is crucial for ensuring model accuracy, and has been previously determined using empirical formulas or tables. To better account for temporal and spatial variability in channel roughness, inverse modeling of $n$ using observed flow data is more reliable and adaptable; however, it is challenging when using traditional SWE solvers. Based on the concept of universal differential equation (UDE), which combines physics-based differential equations with neural networks (NNs), we developed a universal SWEs (USWEs) solver, Hydrograd, for hybrid hydrodynamics modeling. It can do accurate forward simulations, support automatic differentiation (AD) for gradient-based sensitivity analysis and parameter inversion, and perform scientific machine learning for physics discovery. In this work, we first validated the accuracy of its forward modeling, then applied a real-world case to demonstrate the ability of USWEs to capture model sensitivity (gradients) and perform inverse modeling of Manning's $n$. Furthermore, we used a NN to learn a universal relationship between $n$, hydraulic parameters, and flow in a real river channel. Unlike inverse modeling using surrogate models, Hydrograd uses a two-dimensional SWEs solver as its physics backbone, which eliminates the need for data-intensive pretraining and resolves the generalization problem when applied to out-of-sample scenarios. This differentiable modeling approach, with seamless integration with NNs, provides a new pathway for solving complex inverse problems and discovering new physics in hydrodynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12396v1</guid>
      <category>physics.flu-dyn</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xiaofeng Liu, Yalan Song</dc:creator>
    </item>
    <item>
      <title>Patient-specific coronary angioplasty simulations -- a mixed-dimensional finite element modeling approach</title>
      <link>https://arxiv.org/abs/2407.13276</link>
      <description>arXiv:2407.13276v3 Announce Type: replace 
Abstract: Coronary angioplasty with stent implantation is the most frequently used interventional treatment for coronary artery disease. However, reocclusion within the stent, referred to as in-stent restenosis, occurs in up to 10% of lesions. It is widely accepted that mechanical loads on the vessel wall strongly affect adaptive and maladaptive mechanisms. Yet, the role of procedural and lesion-specific influence on restenosis risk remains understudied. Computational modeling of the stenting procedure can provide new mechanistic insights, such as local stresses, that play a significant role in tissue growth and remodeling. Previous simulation studies often featured simplified artery and stent geometries and cannot be applied to real-world examples. Realistic simulations were computationally expensive since they featured fully resolved stenting device models. The aim of this work is to develop and present a mixed-dimensional formulation to simulate the patient-specific stenting procedure with a reduced-dimensional beam model for the stent and 3D models for the artery. In addition to presenting the numerical approach, we apply it to realistic cases to study the intervention's mechanical effect on the artery and correlate the findings with potential high-risk locations for in-stent restenosis. We found that high artery wall stresses develop during the coronary intervention in severely stenosed areas and at the stent boundaries. Herewith, we lay the groundwork for further studies towards preventing in-stent restenosis after coronary angioplasty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13276v3</guid>
      <category>cs.CE</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Janina C. Datz, Ivo Steinbrecher, Christoph Meier, Nora Hagmeyer, Leif-Christopher Engel, Alexander Popp, Martin R. Pfaller, Heribert Schunkert, Wolfgang A. Wall</dc:creator>
    </item>
    <item>
      <title>M2L Translation Operators for Kernel Independent Fast Multipole Methods on Modern Architectures</title>
      <link>https://arxiv.org/abs/2408.07436</link>
      <description>arXiv:2408.07436v2 Announce Type: replace 
Abstract: Algorithm design must focus on minimising data movement even at the cost of more FLOPs due to the growing disparity between FLOP availability and memory bandwidth on modern architectures. We review the requirements for the Multipole to Local (M2L) operation, a sub-routine of the Kernel Independent Fast Multipole Method (kiFMM) algorithm. The kiFMM is a variant of the popular Fast Multipole Method (FMM), which accelerates the evaluation of N-body potential problems. Naively implemented, the M2L can lead to bandwidth pressure, and is therefore a key bottleneck in an FMMs. Recent software packages for the kiFMM have relied on the Fast Fourier Transform (FFT) to accelerate M2L as it can be formulated as a convolution type operation. However, parallelly developed 'black box' FMMs formulate the M2L as a BLAS operation and use direct matrix compression techniques for further acceleration. The FFT approach requires careful implementation to overcome the low operational intensity of the element-wise product inherent in its formulation, whereas the BLAS approach provides a high operational intensity formulation if the M2L is written in terms of level 3 BLAS operations. We describe algorithmic simplifications for the BLAS-based M2L operation, and show that the BLAS version of the M2L can be competitive in practice with the Fast Fourier Transform (FFT) version. We have developed a carefully optimised software implementation that allows us to flexibly switch between M2L approaches and is optimised for ARM and x86 targets, allowing for a fair comparison between both.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07436v2</guid>
      <category>cs.CE</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Srinath Kailasa, Timo Betcke, Sarah El Kazdadi</dc:creator>
    </item>
    <item>
      <title>A Multiscale-Multiphysics Framework for Modeling Organ-scale Liver Regrowth</title>
      <link>https://arxiv.org/abs/2410.19529</link>
      <description>arXiv:2410.19529v2 Announce Type: replace 
Abstract: We present a framework for modeling liver regrowth on the organ scale that is based on three components: (1) a multiscale perfusion model that combines synthetic vascular tree generation with a multi-compartment homogenized flow model, including a homogenization procedure to obtain effective parameters; (2) a poroelastic finite growth model that acts on all compartments and the synthetic vascular tree structure; (3) an evolution equation for the local volumetric growth factor, driven by the homogenized flow rate into the microcirculation as a measure of local hyperperfusion and well-suited for calibration with available data. We apply our modeling framework to a prototypical benchmark and a full-scale patient-specific liver, for which we assume a common surgical cut. Our simulation results demonstrate that our model represents hyperperfusion as a consequence of partial resection and accounts for its reduction towards a homeostatic perfusion state, exhibiting overall regrowth dynamics that correspond well with clinical observations. In addition, our results show that our model also captures local hypoperfusion in the vicinity of orphan vessels, a key requirement for the prediction of ischemia or the preoperative identification of suitable cut patterns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19529v2</guid>
      <category>cs.CE</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adnan Ebrahem, Jannes Hohl, Etienne Jessen, Marco F. P. ten Eikelder, Dominik Schillinger</dc:creator>
    </item>
    <item>
      <title>Differentiable Physics-based System Identification for Robotic Manipulation of Elastoplastic Materials</title>
      <link>https://arxiv.org/abs/2411.00554</link>
      <description>arXiv:2411.00554v3 Announce Type: replace-cross 
Abstract: Robotic manipulation of volumetric elastoplastic deformable materials, from foods such as dough to construction materials like clay, is in its infancy, largely due to the difficulty of modelling and perception in a high-dimensional space. Simulating the dynamics of such materials is computationally expensive. It tends to suffer from inaccurately estimated physics parameters of the materials and the environment, impeding high-precision manipulation. Estimating such parameters from raw point clouds captured by optical cameras suffers further from heavy occlusions. To address this challenge, this work introduces a novel Differentiable Physics-based System Identification (DPSI) framework that enables a robot arm to infer the physics parameters of elastoplastic materials and the environment using simple manipulation motions and incomplete 3D point clouds, aligning the simulation with the real world. Extensive experiments show that with only a single real-world interaction, the estimated parameters, Young's modulus, Poisson's ratio, yield stress and friction coefficients, can accurately simulate visually and physically realistic deformation behaviours induced by unseen and long-horizon manipulation motions. Additionally, the DPSI framework inherently provides physically intuitive interpretations for the parameters in contrast to black-box approaches such as deep neural networks. The project is fully open-sourced via https://ianyangchina.github.io/SI4RP-data/.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00554v3</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xintong Yang, Ze Ji, Yu-Kun Lai</dc:creator>
    </item>
    <item>
      <title>FLAG-Trader: Fusion LLM-Agent with Gradient-based Reinforcement Learning for Financial Trading</title>
      <link>https://arxiv.org/abs/2502.11433</link>
      <description>arXiv:2502.11433v2 Announce Type: replace-cross 
Abstract: Large language models (LLMs) fine-tuned on multimodal financial data have demonstrated impressive reasoning capabilities in various financial tasks. However, they often struggle with multi-step, goal-oriented scenarios in interactive financial markets, such as trading, where complex agentic approaches are required to improve decision-making. To address this, we propose \textsc{FLAG-Trader}, a unified architecture integrating linguistic processing (via LLMs) with gradient-driven reinforcement learning (RL) policy optimization, in which a partially fine-tuned LLM acts as the policy network, leveraging pre-trained knowledge while adapting to the financial domain through parameter-efficient fine-tuning. Through policy gradient optimization driven by trading rewards, our framework not only enhances LLM performance in trading but also improves results on other financial-domain tasks. We present extensive empirical evidence to validate these enhancements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11433v2</guid>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>q-fin.TR</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Guojun Xiong, Zhiyang Deng, Keyi Wang, Yupeng Cao, Haohang Li, Yangyang Yu, Xueqing Peng, Mingquan Lin, Kaleb E Smith, Xiao-Yang Liu, Jimin Huang, Sophia Ananiadou, Qianqian Xie</dc:creator>
    </item>
    <item>
      <title>Tractable General Equilibrium</title>
      <link>https://arxiv.org/abs/2502.11449</link>
      <description>arXiv:2502.11449v2 Announce Type: replace-cross 
Abstract: We study Walrasian economies (or general equilibrium models) and their solution concept, the Walrasian equilibrium. A key challenge in this domain is identifying price-adjustment processes that converge to equilibrium. One such process, t\^atonnement, is an auction-like algorithm first proposed in 1874 by L\'eon Walras. While continuous-time variants of t\^atonnement are known to converge to equilibrium in economies satisfying the Weak Axiom of Revealed Preferences (WARP), the process fails to converge in a pathological Walrasian economy known as the Scarf economy. To address these issues, we analyze Walrasian economies using variational inequalities (VIs), an optimization framework. We introduce the class of mirror extragradient algorithms, which, under suitable Lipschitz-continuity-like assumptions, converge to a solution of any VI satisfying the Minty condition in polynomial time. We show that the set of Walrasian equilibria of any balanced economy-which includes among others Arrow-Debreu economies-corresponds to the solution set of an associated VI that satisfies the Minty condition but is generally discontinuous. Applying the mirror extragradient algorithm to this VI we obtain a class of t\^atonnement-like processes, which we call the mirror extrat\^atonnement process. While our VI formulation is generally discontinuous, it is Lipschitz-continuous in variationally stable Walrasian economies with bounded elasticity-including those satisfying WARP and the Scarf economy-thus establishing the polynomial-time convergence of mirror extrat\^atonnement in these economies. We validate our approach through experiments on large Arrow-Debreu economies with Cobb-Douglas, Leontief, and CES consumers, as well as the Scarf economy, demonstrating fast convergence in all cases without failure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11449v2</guid>
      <category>cs.GT</category>
      <category>cs.CE</category>
      <category>econ.TH</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Denizalp Goktas, Amy Greenwald</dc:creator>
    </item>
  </channel>
</rss>
