<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 18 Jun 2024 04:00:39 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 18 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Enhancing ACPF Analysis: Integrating Newton-Raphson Method with Gradient Descent and Computational Graphs</title>
      <link>https://arxiv.org/abs/2406.10390</link>
      <description>arXiv:2406.10390v1 Announce Type: new 
Abstract: This paper presents a new method for enhancing Alternating Current Power Flow (ACPF) analysis. The method integrates the Newton-Raphson (NR) method with Enhanced-Gradient Descent (GD) and computational graphs. The integration of renewable energy sources in power systems introduces variability and unpredictability, and this method addresses these challenges. It leverages the robustness of NR for accurate approximations and the flexibility of GD for handling variable conditions, all without requiring Jacobian matrix inversion. Furthermore, computational graphs provide a structured and visual framework that simplifies and systematizes the application of these methods. The goal of this fusion is to overcome the limitations of traditional ACPF methods and improve the resilience, adaptability, and efficiency of modern power grid analyses. We validate the effectiveness of our advanced algorithm through comprehensive testing on established IEEE benchmark systems. Our findings demonstrate that our approach not only speeds up the convergence process but also ensures consistent performance across diverse system states, representing a significant advancement in power flow computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10390v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Masoud Barati</dc:creator>
    </item>
    <item>
      <title>Methods of Nonconvex Optimization</title>
      <link>https://arxiv.org/abs/2406.10406</link>
      <description>arXiv:2406.10406v1 Announce Type: new 
Abstract: This book is devoted to finite-dimensional problems of non-convex non-smooth optimization and numerical methods for their solution. The problem of nonconvexity is studied in the book on two main models of nonconvex dependencies: these are the so-called generalized differentiable functions and locally Lipschitz functions. Non-smooth functions naturally arise in various applications. In addition, they often appear in the theory of extremal problems itself due to the operations of taking the maximum and minimum, decomposition techniques, exact non-smooth penalties, and duality. The considered models of nonconvexity are quite general and cover the majority of practically important optimization problems; they clearly show all the difficulties of non-convex optimization. The method of studying the generalized differentiable functions is that for these functions a generalization of the concept of gradient is introduced, a calculus is constructed, and various properties of nonconvex problems are studied in terms of generalized gradients. As for numerical methods, it is possible to extend the theory and algorithms of subgradient descent of convex optimization to problems with generalized differentiable functions. Methods for solving Lipschitz problems are characterized by the fact that the original functions are approximated by smoothed ones and iterative minimization procedures are applied to them. With this approach, it is possible to approximate the gradients of smoothed functions by stochastic finite differences and thus to construct methods without calculating gradients. A similar approach can be justified in generalized differentiable and Lipschitz stochastic programming. In these cases, various generalizations of the classical stochastic approximation and stochastic quasi-gradient method are obtained for solving constrained nonconvex nonsmooth stochastic programming problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10406v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>V. S. Mikhalevich, A. M. Gupal, V. I. Norkin</dc:creator>
    </item>
    <item>
      <title>Suboptimality bounds for trace-bounded SDPs enable a faster and scalable low-rank SDP solver SDPLR+</title>
      <link>https://arxiv.org/abs/2406.10407</link>
      <description>arXiv:2406.10407v1 Announce Type: new 
Abstract: Semidefinite programs (SDPs) and their solvers are powerful tools with many applications in machine learning and data science. Designing scalable SDP solvers is challenging because by standard the positive semidefinite decision variable is an $n \times n$ dense matrix, even though the input is often an $n \times n$ sparse matrix. However, the information in the solution may not correspond to a full-rank dense matrix as shown by Bavinok and Pataki. Two decades ago, Burer and Monterio developed an SDP solver $\texttt{SDPLR}$ that optimizes over a low-rank factorization instead of the full matrix. This greatly decreases the storage cost and works well for many problems. The original solver $\texttt{SDPLR}$ tracks only the primal infeasibility of the solution, limiting the technique's flexibility to produce moderate accuracy solutions. We use a suboptimality bound for trace-bounded SDP problems that enables us to track the progress better and perform early termination. We then develop $\texttt{SDPLR+}$, which starts the optimization with an extremely low-rank factorization and dynamically updates the rank based on the primal infeasibility and suboptimality. This further speeds up the computation and saves the storage cost. Numerical experiments on Max Cut, Minimum Bisection, Cut Norm, and Lov\'{a}sz Theta problems with many recent memory-efficient scalable SDP solvers demonstrate its scalability up to problems with million-by-million decision variables and it is often the fastest solver to a moderate accuracy of $10^{-2}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10407v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yufan Huang, David F. Gleich</dc:creator>
    </item>
    <item>
      <title>Synergizing Machine Learning with ACOPF: A Comprehensive Overview</title>
      <link>https://arxiv.org/abs/2406.10428</link>
      <description>arXiv:2406.10428v1 Announce Type: new 
Abstract: Alternative current optimal power flow (ACOPF) problems have been studied for over fifty years, and yet the development of an optimal algorithm to solve them remains a hot and challenging topic for researchers because of their nonlinear and nonconvex nature. A number of methods based on linearization and convexification have been proposed to solve to ACOPF problems, which result in near-optimal or local solutions, not optimal solutions. Nowadays, with the prevalence of machine learning, some researchers have begun to utilize this technology to solve ACOPF problems using the historical data generated by the grid operators. The present paper reviews the research on solving ACOPF problems using machine learning and neural networks and proposes future studies. This body of research is at the beginning of this area, and further exploration can be undertaken into the possibilities of solving ACOPF problems using machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10428v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Meng Zhao, Masoud Barati</dc:creator>
    </item>
    <item>
      <title>Machine Learning Methods for Large Population Games with Applications in Operations Research</title>
      <link>https://arxiv.org/abs/2406.10441</link>
      <description>arXiv:2406.10441v1 Announce Type: new 
Abstract: In this tutorial, we provide an introduction to machine learning methods for finding Nash equilibria in games with large number of agents. These types of problems are important for the operations research community because of their applicability to real life situations such as control of epidemics, optimal decisions in financial markets, electricity grid management, or traffic control for self-driving cars. We start the tutorial by introducing stochastic optimal control problems for a single agent, in discrete time and in continuous time. Then, we present the framework of dynamic games with finite number of agents. To tackle games with a very large number of agents, we discuss the paradigm of mean field games, which provides an efficient way to compute approximate Nash equilibria. Based on this approach, we discuss machine learning algorithms for such problems. First in the context of discrete time games, we introduce fixed point based methods and related methods based on reinforcement learning. Second, we discuss machine learning methods that are specific to continuous time problems, by building on optimality conditions phrased in terms of stochastic or partial differential equations. Several examples and numerical illustrations of problems arising in operations research are provided along the way.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10441v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gokce Dayanikli, Mathieu Lauriere</dc:creator>
    </item>
    <item>
      <title>Exploiting Overlap Information in Chance-constrained Program with Random Right-hand Side</title>
      <link>https://arxiv.org/abs/2406.10472</link>
      <description>arXiv:2406.10472v1 Announce Type: new 
Abstract: We consider the chance-constrained program (CCP) with random right-hand side under a finite discrete distribution. It is known that the standard mixed integer linear programming (MILP) reformulation of the CCP is generally difficult to solve by general-purpose solvers as the branch-and-cut search trees are enormously large, partly due to the weak linear programming relaxation. In this paper, we identify another reason for this phenomenon: the intersection of the feasible regions of the subproblems in the search tree could be nonempty, leading to a wasteful duplication of effort in exploring the uninteresting overlap in the search tree. To address the newly identified challenge and enhance the capability of the MILP-based approach in solving CCPs, we first show that the overlap in the search tree can be completely removed by a family of valid nonlinear if-then constraints, and then propose two practical approaches to tackle the highly nonlinear if-then constraints. In particular, we use the concept of dominance relations between different scenarios of the random variables, and propose a novel branching, called dominance-based branching, which is able to create a valid partition of the problem with a much smaller overlap than the classic variable branching. Moreover, we develop overlap-oriented node pruning and variable fixing techniques, applied at each node of the search tree, to remove more overlaps in the search tree. Computational results demonstrate the effectiveness of the proposed dominance-based branching and overlap-oriented node pruning and variable fixing techniques in reducing the search tree size and improving the overall solution efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10472v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei Lv, Wei-Kun Chen, Yu-Hong Dai, Xiao-Jiao Tong</dc:creator>
    </item>
    <item>
      <title>Statistical Robustness of Kernel Learning Estimator with Respect to Data Perturbation</title>
      <link>https://arxiv.org/abs/2406.10555</link>
      <description>arXiv:2406.10555v1 Announce Type: new 
Abstract: Inspired by the recent work [28] on the statistical robustness of empirical risks in reproducing kernel Hilbert space (RKHS) where the training data are potentially perturbed or even corrupted, we take a step further in this paper to investigate the statistical robustness of the kernel learning estimator (the regularized empirical risk minimizer or stationary point). We begin by deriving qualitative statistical robustness of the estimator of the regularized empirical risk minimizer for a broad class of convex cost functions when all of the training data are potentially perturbed under some topological structures, and then move on to consider the quantitative statistical robustness of the stationary solution for a specific case that the cost function is continuously differentiable but not necessarily convex. In the latter case, we derive the first-order optimality condition of the regularized expected risk minimization problem, which is essentially a stochastic variational inequality problem (SVIP) in RKHS, and then use the SVIP as a platform to investigate local and global Lipschitz continuity of the stationary solution against perturbation of the probability distribution under the Fortet-Mourier metric. A crucial assumption in the analysis is that the perturbed data are independent and identically distributed (iid). In some practical applications, this assumption may not be fulfilled when a small proportion of perceived data is seriously perturbed/contaminated. In this case, we use the influence function to investigate the impact of single data perturbation on the expected risk minimizer. Differing from [64, Chapter 10], we concentrate on constrained expected risk minimization problems. The research is essentially down to the derivation of the implicit function theorem of the SVIP in RKHS. Finally, we illustrate our theoretical analysis with a couple of academic examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10555v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sainan Zhang, Huifu Xu, Hailin Sun</dc:creator>
    </item>
    <item>
      <title>Variational Analysis in the Wasserstein Space</title>
      <link>https://arxiv.org/abs/2406.10676</link>
      <description>arXiv:2406.10676v1 Announce Type: new 
Abstract: We study optimization problems whereby the optimization variable is a probability measure. Since the probability space is not a vector space, many classical and powerful methods for optimization (e.g., gradients) are of little help. Thus, one typically resorts to the abstract machinery of infinite-dimensional analysis or other ad-hoc methodologies, not tailored to the probability space, which however involve projections or rely on convexity-type assumptions. We believe instead that these problems call for a comprehensive methodological framework for calculus in probability spaces. In this work, we combine ideas from optimal transport, variational analysis, and Wasserstein gradient flows to equip the Wasserstein space (i.e., the space of probability measures endowed with the Wasserstein distance) with a variational structure, both by combining and extending existing results and introducing novel tools. Our theoretical analysis culminates in very general necessary optimality conditions for optimality. Notably, our conditions (i) resemble the rationales of Euclidean spaces, such as the Karush-Kuhn-Tucker and Lagrange conditions, (ii) are intuitive, informative, and easy to study, and (iii) yield closed-form solutions or can be used to design computationally attractive algorithms. We believe this framework lays the foundation for new algorithmic and theoretical advancements in the study of optimization problems in probability spaces, which we exemplify with numerous case studies and applications to machine learning, drug discovery, and distributionally robust optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10676v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicolas Lanzetti, Antonio Terpin, Florian D\"orfler</dc:creator>
    </item>
    <item>
      <title>Symplectic Extra-gradient Type Method for Solving General Non-monotone Inclusion Problem</title>
      <link>https://arxiv.org/abs/2406.10793</link>
      <description>arXiv:2406.10793v1 Announce Type: new 
Abstract: In recent years, accelerated extra-gradient methods have attracted much attention by researchers, for solving monotone inclusion problems. A limitation of most current accelerated extra-gradient methods lies in their direct utilization of the initial point, which can potentially decelerate numerical convergence rate. In this work, we present a new accelerated extra-gradient method, by utilizing the symplectic acceleration technique. We establish the inverse of quadratic convergence rate by employing the Lyapunov function technique. Also, we demonstrate a faster inverse of quadratic convergence rate alongside its weak convergence property under stronger assumptions. To improve practical efficiency, we introduce a line search technique for our symplectic extra-gradient method. Theoretically, we prove the convergence of the symplectic extra-gradient method with line search. Numerical tests show that this adaptation exhibits faster convergence rates in practice compared to several existing extra-gradient type methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10793v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ya-xiang Yuan, Yi Zhang</dc:creator>
    </item>
    <item>
      <title>A parallel framework for graphical optimal transport</title>
      <link>https://arxiv.org/abs/2406.10849</link>
      <description>arXiv:2406.10849v1 Announce Type: new 
Abstract: We study multi-marginal optimal transport (MOT) problems where the underlying cost has a graphical structure. These graphical multi-marginal optimal transport problems have found applications in several domains including traffic flow control and regression problems in the Wasserstein space. MOT problem can be approached through two aspects: a single big MOT problem, or coupled minor OT problems. In this paper, we focus on the latter approach and demonstrate it has efficiency gain from the parallelization. For tree-structured MOT problems, we introduce a novel parallelizable algorithm that significantly reduces computational complexity. Additionally, we adapt this algorithm for general graphs, employing the modified junction trees to enable parallel updates. Our contributions, validated through numerical experiments, offer new avenues for MOT applications and establish benchmarks in computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10849v1</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiaojiao Fan, Isabel Haasler, Qinsheng Zhang, Johan Karlsson, Yongxin Chen</dc:creator>
    </item>
    <item>
      <title>Hamilton-Jacobi Based Policy-Iteration via Deep Operator Learning</title>
      <link>https://arxiv.org/abs/2406.10920</link>
      <description>arXiv:2406.10920v1 Announce Type: new 
Abstract: The framework of deep operator network (DeepONet) has been widely exploited thanks to its capability of solving high dimensional partial differential equations. In this paper, we incorporate DeepONet with a recently developed policy iteration scheme to numerically solve optimal control problems and the corresponding Hamilton--Jacobi--Bellman (HJB) equations. A notable feature of our approach is that once the neural network is trained, the solution to the optimal control problem and HJB equations with different terminal functions can be inferred quickly thanks to the unique feature of operator learning. Furthermore, a quantitative analysis of the accuracy of the algorithm is carried out via comparison principles of viscosity solutions. The effectiveness of the method is verified with various examples, including 10-dimensional linear quadratic regulator problems (LQRs).</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10920v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jae Yong Lee, Yeoneung Kim</dc:creator>
    </item>
    <item>
      <title>Tilt stability of Ky-Fan $\kappa$-norm composite optimization</title>
      <link>https://arxiv.org/abs/2406.10945</link>
      <description>arXiv:2406.10945v1 Announce Type: new 
Abstract: This paper concerns the tilt stability for the minimization of the sum of a twice continuously differentiable matrix-valued function and the Ky-Fan $\kappa$-norm. By using the expression of second subderivative of the Ky-Fan $\kappa$-norm, we derive a verifiable criterion to identify the tilt stability of a local minimum for this class of nonconvex and nonsmooth problems. As a byproduct, a practical criterion is achieved for the tilt stable solution of the nuclear-norm regularized minimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10945v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yulan Liu, Shaohua Pan, Wen Song</dc:creator>
    </item>
    <item>
      <title>City-LEO: Toward Transparent City Management Using LLM with End-to-End Optimization</title>
      <link>https://arxiv.org/abs/2406.10958</link>
      <description>arXiv:2406.10958v1 Announce Type: new 
Abstract: Existing operations research (OR) models and tools play indispensable roles in smart-city operations, yet their practical implementation is limited by the complexity of modeling and deficiencies in optimization proficiency. To generate more relevant and accurate solutions to users' requirements, we propose a large language model (LLM)-based agent ("City-LEO") that enhances the efficiency and transparency of city management through conversational interactions. Specifically, to accommodate diverse users' requirements and enhance computational tractability, City-LEO leverages LLM's logical reasoning capabilities on prior knowledge to scope down large-scale optimization problems efficiently. In the human-like decision process, City-LEO also incorporates End-to-end (E2E) model to synergize the prediction and optimization. The E2E framework be conducive to coping with environmental uncertainties and involving more query-relevant features, and then facilitates transparent and interpretable decision-making process. In case study, we employ City-LEO in the operations management of e-bike sharing (EBS) system. The numerical results demonstrate that City-LEO has superior performance when benchmarks against the full-scale optimization problem. With less computational time, City-LEO generates more satisfactory and relevant solutions to the users' requirements, and achieves lower global suboptimality without significantly compromising accuracy. In a broader sense, our proposed agent offers promise to develop LLM-embedded OR tools for smart-city operations management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10958v1</guid>
      <category>math.OC</category>
      <category>cs.CL</category>
      <category>cs.MA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zihao Jiao, Mengyi Sha, Haoyu Zhang, Xinyu Jiang</dc:creator>
    </item>
    <item>
      <title>On Convergence and Rate of Convergence of Policy Improvement Algorithms</title>
      <link>https://arxiv.org/abs/2406.10959</link>
      <description>arXiv:2406.10959v1 Announce Type: new 
Abstract: In this paper, we provide a simple proof from scratch for the convergence of the Policy Improvement Algorithm(PIA) for a continuous time entropy-regularized stochastic control problem. Such convergence has been established by Huang-Wang-Zhou(2023) by using sophisticated PDE estimates for the iterative PDEs involved in the PIA. Our approach builds on some Feynman-Kac type probabilistic representation formulae for solutions of PDEs and their derivatives. Moreover, in the infinite horizon model with a large discount factor and in the finite horizon model, we obtain the exponential rate of convergence with similar arguments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10959v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jin Ma, Gaozhan Wang, Jianfeng Zhang</dc:creator>
    </item>
    <item>
      <title>Causal feedback strategies for controlled stochastic Volterra systems: a unified treatment</title>
      <link>https://arxiv.org/abs/2406.11009</link>
      <description>arXiv:2406.11009v1 Announce Type: new 
Abstract: This paper is concerned with a unified treatment of linear quadratic control problem for stochastic Volterra integral equations (SVIEs), motivated by the various approaches and scattered results in the existing literature. A novel class of optimal causal feedback strategy is introduced and characterized by means of a new Riccati system. To this end, a fundamental function space and an appropriate multiplicative rule among functions are defined for the first time. In contrast with the existing works, our unified treatment not only provides a new approach, but also extends or improves the known conclusions in stochastic differential equations, convolution SVIEs, stochastic Volterra integro-differential equations (VIDEs), deterministic VIEs, deterministic VIDEs. In addition, an interesting phenomenon is reveal by the current study: for SVIEs the conventional structure of state feedback is replaced by a suitable causal form, and the original state process no longer plays indispensable role in the feedbacks while an auxiliary state process does.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.11009v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiayin Gong, Tianxiao Wang</dc:creator>
    </item>
    <item>
      <title>Modified Line Search Sequential Quadratic Methods for Equality-Constrained Optimization with Unified Global and Local Convergence Guarantees</title>
      <link>https://arxiv.org/abs/2406.11144</link>
      <description>arXiv:2406.11144v1 Announce Type: new 
Abstract: In this paper, we propose a method that has foundations in the line search sequential quadratic programming paradigm for solving general nonlinear equality constrained optimization problems. The method employs a carefully designed modified line search strategy that utilizes second-order information of both the objective and constraint functions, as required, to mitigate the Maratos effect. Contrary to classical line search sequential quadratic programming methods, our proposed method is endowed with global convergence and local superlinear convergence guarantees. Moreover, we extend the method and analysis to the setting in which the constraint functions are deterministic but the objective function is stochastic or can be represented as a finite-sum. We also design and implement a practical inexact matrix-free variant of the method. Finally, numerical results illustrate the efficiency and efficacy of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.11144v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Albert S. Berahas, Raghu Bollapragada, Jiahao Shi</dc:creator>
    </item>
    <item>
      <title>Two-Timescale Optimization Framework for Decentralized Linear-Quadratic Optimal Control</title>
      <link>https://arxiv.org/abs/2406.11168</link>
      <description>arXiv:2406.11168v1 Announce Type: new 
Abstract: This study investigates a decentralized linear-quadratic optimal control problem, and several approximate separable constrained optimization problems are formulated for the first time based on the selection of sparsity promoting functions. First, for the optimization problem with weighted $\ell_1$ sparsity promoting function, a two-timescale algorithm is adopted that is based on the BSUM (Block Successive Upper-bound Minimization) framework and a differential equation solver. Second, a piecewise quadratic sparsity promoting function is introduced, and the induced optimization problem demonstrates an accelerated convergence rate by performing the same two-timescale algorithm. Finally, the optimization problem with $\ell_0$ sparsity promoting function is considered that is nonconvex and discontinuous, and can be approximated by successive coordinatewise convex optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.11168v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lechen Feng, Yuan-Hua Ni, Xuebo Zhang</dc:creator>
    </item>
    <item>
      <title>Input-to-State Stabilization of 1-D Parabolic PDEs under Output Feedback Control</title>
      <link>https://arxiv.org/abs/2406.11264</link>
      <description>arXiv:2406.11264v1 Announce Type: new 
Abstract: This paper addresses the problem of input-to-state stabilization for a class of parabolic equations with time-varying coefficients, as well as Dirichlet and Robin boundary disturbances. By using time-invariant kernel functions, which can reduce the complexity in control design and implementation, an observer-based output feedback controller is designed via backstepping. By using the generalized Lyapunov method, which can be used to handle Dirichlet boundary terms, the input-to-state stability of the closed-loop system under output feedback control, as well as the state estimation error system, is established in the spatial $L^\infty$-norm. Numerical simulations are conducted to confirm the theoretical results and to illustrate the effectiveness of the proposed control scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.11264v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yongchun Bi, Jun Zheng, Guchuan Zhu</dc:creator>
    </item>
    <item>
      <title>Joint Distributed Generation Maximization and Radial Distribution Network Reconfiguration</title>
      <link>https://arxiv.org/abs/2406.11332</link>
      <description>arXiv:2406.11332v1 Announce Type: new 
Abstract: This paper studies an optimization problem for joint radial distribution system network reconfiguration and power dispatch for distributed generation (DG) maximization. We provide counterexamples to show that for DG maximization, standard techniques such as interior point method (as in Matpower), linear approximation and second order cone relaxation (e.g., by Jabr et.~al.~and by Farivar and Low) do not deliver the desired control. Instead, we propose a control decision model based on exact DistFlow equations bypassing relaxation and a solution approach based on spatial branch-and-bound algorithm. We justify our work with comparative studies and numerical demonstrations with benchmarks and a 533-bus real example, performing reconfiguration and power dispatch in a time scale relevant for control center applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.11332v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kin Cheong Sou, Gabriel Malmer, Lovisa Thorin, Olof Samuelsson</dc:creator>
    </item>
    <item>
      <title>From entropic transport to martingale transport, and applications to model calibration</title>
      <link>https://arxiv.org/abs/2406.11537</link>
      <description>arXiv:2406.11537v1 Announce Type: new 
Abstract: We propose a discrete time formulation of the semi martingale optimal transport problembased on multi-marginal entropic transport. This approach offers a new way to formulate and solve numerically the calibration problem proposed by Guo et al. 2022, using a multi-marginal extension of Sinkhorn algorithm as in Benamou, Carlier, and Nenna 2019; Carlier et al. 2017; Benamou et al. 2019. In the limit when the time step goes to zero we recover, as detailed in the companion paper Benamou et al. 2024, a semi-martingale process, solution to a semi-martingale optimal transport problem, with a cost function involving the so-called specific entropy introduced in Gantert 1991, see also F{\"o}llmer 2022 and Backhoff-Veraguas and Unterberger 2023.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.11537v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jean-David Benamou, Guillaume Chazareix, Gr\'egoire Loeper</dc:creator>
    </item>
    <item>
      <title>Computation and Control of Unstable Steady States for Mean Field Multiagent Systems</title>
      <link>https://arxiv.org/abs/2406.11725</link>
      <description>arXiv:2406.11725v1 Announce Type: new 
Abstract: We study interacting particle systems driven by noise, modeling phenomena such as opinion dynamics. We are interested in systems that exhibit phase transitions i.e. non-uniqueness of stationary states for the corresponding McKean-Vlasov PDE, in the mean field limit. We develop an efficient numerical scheme for identifying all steady states (both stable and unstable) of the mean field McKean-Vlasov PDE, based on a spectral Galerkin approximation combined with a deflated Newton's method to handle the multiplicity of solutions. Having found all possible equilibra, we formulate an optimal control strategy for steering the dynamics towards a chosen unstable steady state. The control is computed using iterated open-loop solvers in a receding horizon fashion. We demonstrate the effectiveness of the proposed steady state computation and stabilization methodology on several examples, including the noisy Hegselmann-Krause model for opinion dynamics and the Haken-Kelso-Bunz model from biophysics. The numerical experiments validate the ability of the approach to capture the rich self-organization landscape of these systems and to stabilize unstable configurations of interest. The proposed computational framework opens up new possibilities for understanding and controlling the collective behavior of noise-driven interacting particle systems, with potential applications in various fields such as social dynamics, biological synchronization, and collective behavior in physical and social systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.11725v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sara Bicego, Dante Kalise, Grigorios A. Pavliotis</dc:creator>
    </item>
    <item>
      <title>On the Differentiability of the Primal-Dual Interior-Point Method</title>
      <link>https://arxiv.org/abs/2406.11749</link>
      <description>arXiv:2406.11749v1 Announce Type: new 
Abstract: Primal-Dual Interior-Point methods are capable of solving constrained convex optimization problems to tight tolerances in a fast and robust manner. The derivatives of the primal-dual solution with respect to the problem matrices can be computed using the implicit function theorem, enabling efficient differentiation of these optimizers for a fraction of the cost of the total solution time. In the presence of active inequality constraints, this technique is only capable of providing discontinuous subgradients that present a challenge to algorithms that rely on the smoothness of these derivatives. This paper presents a technique for relaxing primal-dual solutions with a logarithmic barrier to provide smooth derivatives near active inequality constraints, with the ability to specify a uniform and consistent amount of smoothing. We pair this with an efficient primal-dual interior-point algorithm for solving an always-feasible $\ell_1$-penalized variant of a convex quadratic program, eliminating the issues surrounding learning potentially infeasible problems. This parallelizable and smoothly differentiable solver is demonstrated on a range of robotics tasks where smoothing is important. An open source implementation in JAX is available at www.github.com/kevin-tracy/qpax.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.11749v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kevin Tracy, Zachary Manchester</dc:creator>
    </item>
    <item>
      <title>Robust portfolio optimization for recommender systems considering uncertainty of estimated statistics</title>
      <link>https://arxiv.org/abs/2406.10250</link>
      <description>arXiv:2406.10250v1 Announce Type: cross 
Abstract: This paper is concerned with portfolio optimization models for creating high-quality lists of recommended items to balance the accuracy and diversity of recommendations. However, the statistics (i.e., expectation and covariance of ratings) required for mean--variance portfolio optimization are subject to inevitable estimation errors. To remedy this situation, we focus on robust optimization techniques that derive reliable solutions to uncertain optimization problems. Specifically, we propose a robust portfolio optimization model that copes with the uncertainty of estimated statistics based on the cardinality-based uncertainty sets. This robust portfolio optimization model can be reduced to a mixed-integer linear optimization problem, which can be solved exactly using mathematical optimization solvers. Experimental results using two publicly available rating datasets demonstrate that our method can improve not only the recommendation accuracy but also the diversity of recommendations compared with conventional mean--variance portfolio optimization models. Notably, our method has the potential to improve the recommendation quality of various rating prediction algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10250v1</guid>
      <category>cs.IR</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tomoya Yanagi, Shunnosuke Ikeda, Yuichi Takano</dc:creator>
    </item>
    <item>
      <title>Fast solution to the fair ranking problem using the Sinkhorn algorithm</title>
      <link>https://arxiv.org/abs/2406.10262</link>
      <description>arXiv:2406.10262v1 Announce Type: cross 
Abstract: In two-sided marketplaces such as online flea markets, recommender systems for providing consumers with personalized item rankings play a key role in promoting transactions between providers and consumers. Meanwhile, two-sided marketplaces face the problem of balancing consumer satisfaction and fairness among items to stimulate activity of item providers. Saito and Joachims (2022) devised an impact-based fair ranking method for maximizing the Nash social welfare based on fair division; however, this method, which requires solving a large-scale constrained nonlinear optimization problem, is very difficult to apply to practical-scale recommender systems. We thus propose a fast solution to the impact-based fair ranking problem. We first transform the fair ranking problem into an unconstrained optimization problem and then design a gradient ascent method that repeatedly executes the Sinkhorn algorithm. Experimental results demonstrate that our algorithm provides fair rankings of high quality and is about 1000 times faster than application of commercial optimization software.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10262v1</guid>
      <category>cs.IR</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuki Uehara, Shunnosuke Ikeda, Naoki Nishimura, Koya Ohashi, Yilin Li, Jie Yang, Deddy Jobson, Xingxia Zha, Takeshi Matsumoto, Noriyoshi Sukegawa, Yuichi Takano</dc:creator>
    </item>
    <item>
      <title>Multi-Objective Control Co-design Using Graph-Based Optimization for Offshore Wind Farm Grid Integration</title>
      <link>https://arxiv.org/abs/2406.10365</link>
      <description>arXiv:2406.10365v1 Announce Type: cross 
Abstract: Offshore wind farms have emerged as a popular renewable energy source that can generate substantial electric power with a low environmental impact. However, integrating these farms into the grid poses significant complexities. To address these issues, optimal-sized energy storage can provide potential solutions and help improve the reliability, efficiency, and flexibility of the grid. Nevertheless, limited studies have attempted to perform energy storage sizing while including design and operations (i.e., control co-design) for offshore wind farms. As a result, the present work develops a control co-design optimization formulation to optimize multiple objectives and identify Pareto optimal solutions. The graph-based optimization framework is proposed to address the complexity of the system, allowing the optimization problem to be decomposed for large power systems. The IEEE-9 bus system is treated as an onshore AC grid with two offshore wind farms connected via a multi-terminal DC grid for our use case. The developed methodology successfully identifies the Pareto front during the control co-design optimization, enabling decision-makers to select the best compromise solution for multiple objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10365v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Himanshu Sharma, Wei Wang, Bowen Huang, Thiagarajan Ramachandran, Veronica Adetola</dc:creator>
    </item>
    <item>
      <title>Constrained mean-variance investment-reinsurance under the Cram\'er-Lundberg model with random coefficients</title>
      <link>https://arxiv.org/abs/2406.10465</link>
      <description>arXiv:2406.10465v1 Announce Type: cross 
Abstract: In this paper, we study an optimal mean-variance investment-reinsurance problem for an insurer (she) under a Cram\'er-Lundberg model with random coefficients. At any time, the insurer can purchase reinsurance or acquire new business and invest her surplus in a security market consisting of a risk-free asset and multiple risky assets, subject to a general convex cone investment constraint. We reduce the problem to a constrained stochastic linear-quadratic control problem with jumps whose solution is related to a system of partially coupled stochastic Riccati equations (SREs). Then we devote ourselves to establishing the existence and uniqueness of solutions to the SREs by pure backward stochastic differential equation (BSDE) techniques. We achieve this with the help of approximation procedure, comparison theorems for BSDEs with jumps, log transformation and BMO martingales. The efficient investment-reinsurance strategy and efficient mean-variance frontier are explicitly given through the solutions of the SREs, which are shown to be a linear feedback form of the wealth process and a half-line, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10465v1</guid>
      <category>q-fin.PM</category>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaomin Shi, Zuo Quan Xu</dc:creator>
    </item>
    <item>
      <title>DCDILP: a distributed learning method for large-scale causal structure learning</title>
      <link>https://arxiv.org/abs/2406.10481</link>
      <description>arXiv:2406.10481v1 Announce Type: cross 
Abstract: This paper presents a novel approach to causal discovery through a divide-and-conquer framework. By decomposing the problem into smaller subproblems defined on Markov blankets, the proposed DCDILP method first explores in parallel the local causal graphs of these subproblems. However, this local discovery phase encounters systematic challenges due to the presence of hidden confounders (variables within each Markov blanket may be influenced by external variables). Moreover, aggregating these local causal graphs in a consistent global graph defines a large size combinatorial optimization problem. DCDILP addresses these challenges by: i) restricting the local subgraphs to causal links only related with the central variable of the Markov blanket; ii) formulating the reconciliation of local causal graphs as an integer linear programming method. The merits of the approach, in both terms of causal discovery accuracy and scalability in the size of the problem, are showcased by experiments and comparisons with the state of the art.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10481v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ME</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuyu Dong, Mich\`ele Sebag, Kento Uemura, Akito Fujii, Shuang Chang, Yusuke Koyanagi, Koji Maruhashi</dc:creator>
    </item>
    <item>
      <title>Fast Last-Iterate Convergence of Learning in Games Requires Forgetful Algorithms</title>
      <link>https://arxiv.org/abs/2406.10631</link>
      <description>arXiv:2406.10631v1 Announce Type: cross 
Abstract: Self-play via online learning is one of the premier ways to solve large-scale two-player zero-sum games, both in theory and practice. Particularly popular algorithms include optimistic multiplicative weights update (OMWU) and optimistic gradient-descent-ascent (OGDA). While both algorithms enjoy $O(1/T)$ ergodic convergence to Nash equilibrium in two-player zero-sum games, OMWU offers several advantages including logarithmic dependence on the size of the payoff matrix and $\widetilde{O}(1/T)$ convergence to coarse correlated equilibria even in general-sum games. However, in terms of last-iterate convergence in two-player zero-sum games, an increasingly popular topic in this area, OGDA guarantees that the duality gap shrinks at a rate of $O(1/\sqrt{T})$, while the best existing last-iterate convergence for OMWU depends on some game-dependent constant that could be arbitrarily large. This begs the question: is this potentially slow last-iterate convergence an inherent disadvantage of OMWU, or is the current analysis too loose? Somewhat surprisingly, we show that the former is true. More generally, we prove that a broad class of algorithms that do not forget the past quickly all suffer the same issue: for any arbitrarily small $\delta&gt;0$, there exists a $2\times 2$ matrix game such that the algorithm admits a constant duality gap even after $1/\delta$ rounds. This class of algorithms includes OMWU and other standard optimistic follow-the-regularized-leader algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10631v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Cai, Gabriele Farina, Julien Grand-Cl\'ement, Christian Kroer, Chung-Wei Lee, Haipeng Luo, Weiqiang Zheng</dc:creator>
    </item>
    <item>
      <title>Calibrating Neural Networks' parameters through Optimal Contraction in a Prediction Problem</title>
      <link>https://arxiv.org/abs/2406.10703</link>
      <description>arXiv:2406.10703v1 Announce Type: cross 
Abstract: This study introduces a novel approach to ensure the existence and uniqueness of optimal parameters in neural networks. The paper details how a recurrent neural networks (RNN) can be transformed into a contraction in a domain where its parameters are linear. It then demonstrates that a prediction problem modeled through an RNN, with a specific regularization term in the loss function, can have its first-order conditions expressed analytically. This system of equations is reduced to two matrix equations involving Sylvester equations, which can be partially solved. We establish that, if certain conditions are met, optimal parameters exist, are unique, and can be found through a straightforward algorithm to any desired precision. Also, as the number of neurons grows the conditions of convergence become easier to fulfill. Feedforward neural networks (FNNs) are also explored by including linear constraints on parameters. According to our model, incorporating loops (with fixed or variable weights) will produce loss functions that train easier, because it assures the existence of a region where an iterative method converges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10703v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Valdes Gonzalo</dc:creator>
    </item>
    <item>
      <title>Notch Filters without Transient Effects: A Constrained Optimization Design</title>
      <link>https://arxiv.org/abs/2406.10706</link>
      <description>arXiv:2406.10706v1 Announce Type: cross 
Abstract: Transient responses are an inherent property of recursive filters due to unknown or incorrectly selected initial conditions. Well-designed stable filters are less affected by transient responses, as the impact of initial conditions diminishes over time. However, applications that require very short data acquisition periods (for example, as short as ten seconds), such as biosignals recorded and processed by wearable technologies, can be significantly impacted by transient effects. But how feasible is it to design filters without transient responses?
  We propose a well-known filter design scheme based on constrained least squares (CLS) optimization to create zero-transient effect notch filters for powerline noise cancellation. We demonstrate that this filter is equivalent to the optimal Wiener smoother in the stationary case. We also discuss its limitations in removing powerline noise with nonstationary amplitude, where a Kalman filter-based formulation can be used instead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10706v1</guid>
      <category>eess.SP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Reza Sameni</dc:creator>
    </item>
    <item>
      <title>A Conditional Upper Bound for the Moving Sofa Problem</title>
      <link>https://arxiv.org/abs/2406.10725</link>
      <description>arXiv:2406.10725v1 Announce Type: cross 
Abstract: The moving sofa problem asks for the connected shape with the largest area $\mu_{\text{max}}$ that can move around the right-angled corner of a hallway $L$ with unit width. The best bounds currently known on $\mu_{\max}$ are summarized as $2.2195\ldots \leq \mu_{\max} \leq 2.37$. The lower bound $2.2195\ldots \leq \mu_{\max}$ comes from Gerver's sofa $S_G$ of area $\mu_G := 2.2195\ldots$. The upper bound $\mu_{\max} \leq 2.37$ was proved by Kallus and Romik using extensive computer assistance. It is conjectured that the equality $\mu_{\max} = \mu_G$ holds at the lower bound.
  We develop a new approach to the moving sofa problem by approximating it as an infinite-dimensional convex quadratic optimization problem. The problem is then explicitly solved using a calculus of variation based on the Brunn-Minkowski theory. Consequently, we prove that any moving sofa satisfying a property named the injectivity condition has an area of at most $1 + \pi^2/8 = 2.2337\dots$. The new conditional bound does not rely on any computer assistance, yet it is much closer to the lower bound $2.2195\ldots$ of Gerver than the computer-assisted upper bound $2.37$ of Kallus and Romik. Gerver's sofa $S_G$, the conjectured optimum, satisfies the injectivity condition in particular.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10725v1</guid>
      <category>math.MG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jineon Baek</dc:creator>
    </item>
    <item>
      <title>Finite-difference least square methods for solving Hamilton-Jacobi equations using neural networks</title>
      <link>https://arxiv.org/abs/2406.10758</link>
      <description>arXiv:2406.10758v1 Announce Type: cross 
Abstract: We present a simple algorithm to approximate the viscosity solution of Hamilton-Jacobi~(HJ) equations by means of an artificial deep neural network. The algorithm uses a stochastic gradient descent-based algorithm to minimize the least square principle defined by a monotone, consistent numerical scheme. We analyze the least square principle's critical points and derive conditions that guarantee that any critical point approximates the sought viscosity solution. The use of a deep artificial neural network on a finite difference scheme lifts the restriction of conventional finite difference methods that rely on computing functions on a fixed grid. This feature makes it possible to solve HJ equations posed in higher dimensions where conventional methods are infeasible. We demonstrate the efficacy of our algorithm through numerical studies on various canonical HJ equations across different dimensions, showcasing its potential and versatility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10758v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carlos Esteve-Yag\"ue, Richard Tsai, Alex Massucco</dc:creator>
    </item>
    <item>
      <title>Two-level overlapping additive Schwarz preconditioner for training scientific machine learning applications</title>
      <link>https://arxiv.org/abs/2406.10997</link>
      <description>arXiv:2406.10997v1 Announce Type: cross 
Abstract: We introduce a novel two-level overlapping additive Schwarz preconditioner for accelerating the training of scientific machine learning applications. The design of the proposed preconditioner is motivated by the nonlinear two-level overlapping additive Schwarz preconditioner. The neural network parameters are decomposed into groups (subdomains) with overlapping regions. In addition, the network's feed-forward structure is indirectly imposed through a novel subdomain-wise synchronization strategy and a coarse-level training step. Through a series of numerical experiments, which consider physics-informed neural networks and operator learning approaches, we demonstrate that the proposed two-level preconditioner significantly speeds up the convergence of the standard (LBFGS) optimizer while also yielding more accurate machine learning models. Moreover, the devised preconditioner is designed to take advantage of model-parallel computations, which can further reduce the training time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10997v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Youngkyu Lee, Alena Kopani\v{c}\'akov\'a, George Em Karniadakis</dc:creator>
    </item>
    <item>
      <title>How Neural Networks Learn the Support is an Implicit Regularization Effect of SGD</title>
      <link>https://arxiv.org/abs/2406.11110</link>
      <description>arXiv:2406.11110v1 Announce Type: cross 
Abstract: We investigate the ability of deep neural networks to identify the support of the target function. Our findings reveal that mini-batch SGD effectively learns the support in the first layer of the network by shrinking to zero the weights associated with irrelevant components of input. In contrast, we demonstrate that while vanilla GD also approximates the target function, it requires an explicit regularization term to learn the support in the first layer. We prove that this property of mini-batch SGD is due to a second-order implicit regularization effect which is proportional to $\eta / b$ (step size / batch size). Our results are not only another proof that implicit regularization has a significant impact on training optimization dynamics but they also shed light on the structure of the features that are learned by the network. Additionally, they suggest that smaller batches enhance feature interpretability and reduce dependency on initialization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.11110v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pierfrancesco Beneventano, Andrea Pinto, Tomaso Poggio</dc:creator>
    </item>
    <item>
      <title>Polygonal Faber-Krahn inequality: Local minimality via validated computing</title>
      <link>https://arxiv.org/abs/2406.11575</link>
      <description>arXiv:2406.11575v1 Announce Type: cross 
Abstract: The main result of the paper shows that the regular $n$-gon is a local minimizer for the first Dirichlet-Laplace eigenvalue among $n$-gons having fixed area for $n \in \{5,6\}$. The eigenvalue is seen as a function of the coordinates of the vertices in $\Bbb R^{2n}$. Relying on fine regularity results of the first eigenfunction in a convex polygon, an explicit a priori estimate is given for the eigenvalues of the Hessian matrix associated to the discrete problem, whose coefficients involve the solutions of some Poisson equations with singular right hand sides. The a priori estimates, in conjunction with certified finite element approximations of these singular PDEs imply the local minimality for $n \in \{5,6\}$. All computations, including the finite element computations, are realized using interval arithmetic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.11575v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Beniamin Bogosel, Dorin Bucur</dc:creator>
    </item>
    <item>
      <title>Simple matrix expressions for the curvatures of Grassmannian</title>
      <link>https://arxiv.org/abs/2406.11821</link>
      <description>arXiv:2406.11821v1 Announce Type: cross 
Abstract: We show that modeling a Grassmannian as symmetric orthogonal matrices $\operatorname{Gr}(k,\mathbb{R}^n) \cong\{Q \in \mathbb{R}^{n \times n} : Q^{\scriptscriptstyle\mathsf{T}} Q = I, \; Q^{\scriptscriptstyle\mathsf{T}} = Q,\; \operatorname{tr}(Q)=2k - n\}$ yields exceedingly simple matrix formulas for various curvatures and curvature-related quantities, both intrinsic and extrinsic. These include Riemann, Ricci, Jacobi, sectional, scalar, mean, principal, and Gaussian curvatures; Schouten, Weyl, Cotton, Bach, Pleba\'nski, cocurvature, nonmetricity, and torsion tensors; first, second, and third fundamental forms; Gauss and Weingarten maps; and upper and lower delta invariants. We will derive explicit, simple expressions for the aforementioned quantities in terms of standard matrix operations that are stably computable with numerical linear algebra. Many of these aforementioned quantities have never before been presented for the Grassmannian.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.11821v1</guid>
      <category>math.DG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zehua Lai, Lek-Heng Lim, Ke Ye</dc:creator>
    </item>
    <item>
      <title>PEPit: computer-assisted worst-case analyses of first-order optimization methods in Python</title>
      <link>https://arxiv.org/abs/2201.04040</link>
      <description>arXiv:2201.04040v2 Announce Type: replace 
Abstract: PEPit is a Python package aiming at simplifying the access to worst-case analyses of a large family of first-order optimization methods possibly involving gradient, projection, proximal, or linear optimization oracles, along with their approximate, or Bregman variants. In short, PEPit is a package enabling computer-assisted worst-case analyses of first-order optimization methods. The key underlying idea is to cast the problem of performing a worst-case analysis, often referred to as a performance estimation problem (PEP), as a semidefinite program (SDP) which can be solved numerically. To do that, the package users are only required to write first-order methods nearly as they would have implemented them. The package then takes care of the SDP modeling parts, and the worst-case analysis is performed numerically via a standard solver.</description>
      <guid isPermaLink="false">oai:arXiv.org:2201.04040v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Baptiste Goujaud, C\'eline Moucer, Fran\c{c}ois Glineur, Julien Hendrickx, Adrien Taylor, Aymeric Dieuleveut</dc:creator>
    </item>
    <item>
      <title>Convergence of Policy Iteration for Entropy-Regularized Stochastic Control Problems</title>
      <link>https://arxiv.org/abs/2209.07059</link>
      <description>arXiv:2209.07059v4 Announce Type: replace 
Abstract: For a general entropy-regularized stochastic control problem on an infinite horizon, we prove that a policy iteration algorithm (PIA) converges to an optimal relaxed control. Contrary to the standard stochastic control literature, classical H\"{o}lder estimates of value functions do not ensure the convergence of the PIA, due to the added entropy-regularizing term. To circumvent this, we carry out a delicate estimation by moving back and forth between appropriate H\"{o}lder and Sobolev spaces. This requires new Sobolev estimates designed specifically for the purpose of policy iteration and a nontrivial technique to contain the entropy growth. Ultimately, we obtain a uniform H\"{o}lder bound for the sequence of value functions generated by the PIA, thereby achieving the desired convergence result. Characterization of the optimal value function as the unique solution to an exploratory Hamilton-Jacobi-Bellman equation comes as a by-product. The PIA is numerically implemented in an example of optimal consumption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.07059v4</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu-Jui Huang, Zhenhua Wang, Zhou Zhou</dc:creator>
    </item>
    <item>
      <title>A cutting-surface consensus approach for distributed robust optimization of multi-agent systems</title>
      <link>https://arxiv.org/abs/2309.03519</link>
      <description>arXiv:2309.03519v2 Announce Type: replace 
Abstract: A novel and fully distributed optimization method is proposed for the distributed robust convex program (DRCP) over a time-varying unbalanced directed network under the uniformly jointly strongly connected (UJSC) assumption. Firstly, a tractable approximated DRCP (ADRCP) is introduced by discretizing the semi-infinite constraints into a finite number of inequality constraints and restricting the right-hand side of the constraints with a positive parameter. This problem is iteratively solved by a distributed projected gradient algorithm proposed in this paper, which is based on epigraphic reformulation and subgradient projected algorithms. Secondly, a cutting-surface consensus approach is proposed for locating an approximately optimal consensus solution of the DRCP with guaranteed feasibility. This approach is based on iteratively approximating the DRCP by successively reducing the restriction parameter of the right-hand constraints and populating the cutting-surfaces into the existing finite set of constraints. Thirdly, to ensure finite-time termination of the distributed optimization, a distributed termination algorithm is developed based on consensus and zeroth-order stopping conditions under UJSC graphs. Fourthly, it is proved that the cutting-surface consensus approach terminates finitely and yields a feasible and approximate optimal solution for each agent. Finally, the effectiveness of the approach is illustrated through a numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.03519v2</guid>
      <category>math.OC</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jun Fu, Xunhao Wu</dc:creator>
    </item>
    <item>
      <title>Structural Controllability of Bilinear Systems on $\mathbb{SE(n)}$</title>
      <link>https://arxiv.org/abs/2310.00589</link>
      <description>arXiv:2310.00589v3 Announce Type: replace 
Abstract: Structural controllability challenges arise from imprecise system modeling and system interconnections in large scale systems. In this paper, we study structural control of bilinear systems on the special Euclidean group. We employ graph theoretic methods to analyze the structural controllability problem for driftless bilinear systems and structural accessibility for bilinear systems with drift. This facilitates the identification of a sparsest pattern necessary for achieving structural controllability and discerning redundant connections. To obtain a graph theoretic characterization of structural controllability and accessibility on the special Euclidean group, we introduce a novel idea of solid and broken edges on graphs; subsequently, we use the notion of transitive closure of graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.00589v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>A. Sanand Amita Dilip, Chirayu D. Athalye</dc:creator>
    </item>
    <item>
      <title>MIP Relaxations in Factorable Programming</title>
      <link>https://arxiv.org/abs/2310.07168</link>
      <description>arXiv:2310.07168v3 Announce Type: replace 
Abstract: In this paper, we develop new discrete relaxations for nonlinear expressions in factorable programming. We utilize specialized convexification results as well as composite relaxations to develop mixed-integer programming (MIP) relaxations. Our relaxations rely on ideal formulations of convex hulls of outer-functions over a combinatorial structure that captures local inner-function structure. The resulting relaxations often require fewer variables and are tighter than currently prevalent ones. Finally, we provide computational evidence to demonstrate that our relaxations close approximately 60-70% of the gap relative to McCormick relaxations and significantly improves the relaxations used in a state-of-the-art solver on various instances involving polynomial functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.07168v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Taotao He, Mohit Tawarmalani</dc:creator>
    </item>
    <item>
      <title>Convexification Techniques for Fractional Programs</title>
      <link>https://arxiv.org/abs/2310.08424</link>
      <description>arXiv:2310.08424v2 Announce Type: replace 
Abstract: This paper develops a correspondence relating convex hulls of fractional functions with those of polynomial functions over the same domain. Using this result, we develop a number of new reformulations and relaxations for fractional programming problems. First, we relate 0-1 problems involving a ratio of affine functions with the boolean quadric polytope, and use inequalities for the latter to develop tighter formulations for the former. Second, we derive a new formulation to optimize a ratio of quadratic functions over a polytope using copositive programming. Third, we show that univariate fractional functions can be convexified using moment hulls. Fourth, we develop a new hierarchy of relaxations that converges finitely to the simultaneous convex hull of a collection of ratios of affine functions of 0-1 variables. Finally, we demonstrate theoretically and computationally that our techniques close a significant gap relative to state-of-the-art relaxations, require much less computational effort, and can solve larger problem instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.08424v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taotao He, Siyue Liu, Mohit Tawarmalani</dc:creator>
    </item>
    <item>
      <title>Splitting the Conditional Gradient Algorithm</title>
      <link>https://arxiv.org/abs/2311.05381</link>
      <description>arXiv:2311.05381v3 Announce Type: replace 
Abstract: We propose a novel generalization of the conditional gradient (CG / Frank-Wolfe) algorithm for minimizing a smooth function $f$ under an intersection of compact convex sets, using a first-order oracle for $\nabla f$ and linear minimization oracles (LMOs) for the individual sets. Although this computational framework presents many advantages, there are only a small number of algorithms which require one LMO evaluation per set per iteration; furthermore, these algorithms require $f$ to be convex. Our algorithm appears to be the first in this class which is proven to also converge in the nonconvex setting. Our approach combines a penalty method and a product-space relaxation. We show that one conditional gradient step is a sufficient subroutine for our penalty method to converge, and we provide several analytical results on the product-space relaxation's properties and connections to other problems in optimization. We prove that our average Frank-Wolfe gap converges at a rate of $\mathcal{O}(\ln t/\sqrt{t})$, -- only a log factor worse than the vanilla CG algorithm with one set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.05381v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zev Woodstock, Sebastian Pokutta</dc:creator>
    </item>
    <item>
      <title>On degenerate metric resolvent: local monotonicity, restricted maximality and beyond</title>
      <link>https://arxiv.org/abs/2401.08431</link>
      <description>arXiv:2401.08431v2 Announce Type: replace 
Abstract: We study the basic properties of resolvent equipped with degenerate metric, under local monotonicity and restricted maximality, and further propose several conditions for the well-defineness and convergence of the fixed point iterations. The results help to understand the behaviours of many operator splitting algorithms in the kernel space of degenerate metric.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.08431v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Feng Xue, Hui Zhang</dc:creator>
    </item>
    <item>
      <title>Kurdyka-{\L}ojasiewicz exponent via Hadamard parametrization</title>
      <link>https://arxiv.org/abs/2402.00377</link>
      <description>arXiv:2402.00377v2 Announce Type: replace 
Abstract: We consider a class of $\ell_1$-regularized optimization problems and the associated smooth "over-parameterized" optimization problems built upon the Hadamard parametrization, or equivalently, the Hadamard difference parametrization (HDP). We characterize the set of second-order stationary points of the HDP-based model and show that they correspond to some stationary points of the corresponding $\ell_1$-regularized model. More importantly, we show that the Kurdyka-Lojasiewicz (KL) exponent of the HDP-based model at a second-order stationary point can be inferred from that of the corresponding $\ell_1$-regularized model under suitable assumptions. Our assumptions are general enough to cover a wide variety of loss functions commonly used in $\ell_1$-regularized models, such as the least squares loss function and the logistic loss function. Since the KL exponents of many $\ell_1$-regularized models are explicitly known in the literature, our results allow us to leverage these known exponents to deduce the KL exponents at second-order stationary points of the corresponding HDP-based models, which were previously unknown. Finally, we demonstrate how these explicit KL exponents at second-order stationary points can be applied to deducing the explicit local convergence rate of a standard gradient descent method for minimizing the HDP-based model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.00377v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenqing Ouyang, Yuncheng Liu, Ting Kei Pong, Hao Wang</dc:creator>
    </item>
    <item>
      <title>Weakly Convex Regularisers for Inverse Problems: Convergence of Critical Points and Primal-Dual Optimisation</title>
      <link>https://arxiv.org/abs/2402.01052</link>
      <description>arXiv:2402.01052v2 Announce Type: replace 
Abstract: Variational regularisation is the primary method for solving inverse problems, and recently there has been considerable work leveraging deeply learned regularisation for enhanced performance. However, few results exist addressing the convergence of such regularisation, particularly within the context of critical points as opposed to global minimisers. In this paper, we present a generalised formulation of convergent regularisation in terms of critical points, and show that this is achieved by a class of weakly convex regularisers. We prove convergence of the primal-dual hybrid gradient method for the associated variational problem, and, given a Kurdyka-Lojasiewicz condition, an $\mathcal{O}(\log{k}/k)$ ergodic convergence rate. Finally, applying this theory to learned regularisation, we prove universal approximation for input weakly convex neural networks (IWCNN), and show empirically that IWCNNs can lead to improved performance of learned adversarial regularisers for computed tomography (CT) reconstruction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.01052v2</guid>
      <category>math.OC</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zakhar Shumaylov, Jeremy Budd, Subhadip Mukherjee, Carola-Bibiane Sch\"onlieb</dc:creator>
    </item>
    <item>
      <title>Trustworthiness of Optimality Condition Violation in Inverse Dynamic Game Methods Based on the Minimum Principle</title>
      <link>https://arxiv.org/abs/2402.03157</link>
      <description>arXiv:2402.03157v2 Announce Type: replace 
Abstract: In this work, we analyze the applicability of Inverse Dynamic Game (IDG) methods based on the Minimum Principle (MP). The IDG method determines unknown cost functions in a single- or multi-agent setting from observed system trajectories by minimizing the so-called residual error, i.e. the extent to which the optimality conditions of the MP are violated with a current guess of cost functions. The main assumption of the IDG method to recover cost functions such that the resulting trajectories match the observed ones is that the given trajectories are the result of a Dynamic Game (DG) problem with known parameterized cost function structures. However, in practice, when the IDG method is used to identify the behavior of unknown agents, e.g. humans, this assumption cannot be guaranteed. Hence, we introduce the notion of the trustworthiness of the residual error and provide necessary conditions for it to define when the IDG method based on the MP is applicable to such problems. From the necessary conditions, we conclude that the MP-based IDG method cannot be used to validate DG models for unknown agents but can yield under certain conditions robust parameter identifications, e.g. to measurement noise. Finally, we illustrate these conclusions by validating a DG model for the collision avoidance behavior between two mobile robots with human operators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.03157v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philipp Karg, Adrian Kienzle, Jonas Kaub, Balint Varga, S\"oren Hohmann</dc:creator>
    </item>
    <item>
      <title>$H_{\infty}$-Optimal Estimator Synthesis for Coupled Linear 2D PDEs using Convex Optimization</title>
      <link>https://arxiv.org/abs/2402.05061</link>
      <description>arXiv:2402.05061v3 Announce Type: replace 
Abstract: Any suitably well-posed PDE in two spatial dimensions can be represented as a Partial Integral Equation (PIE) -- with system dynamics parameterized using Partial Integral (PI) operators. Furthermore, $L_2$-gain analysis of PDEs with a PIE representation can be posed as a linear operator inequality, which can be solved using convex optimization. In this paper, these results are used to derive a convex-optimization-based test for constructing an $H_{\infty}$-optimal estimator for 2D PDEs. In particular, we first use PIEs to represent an arbitrary well-posed 2D PDE where sensor measurements occur along some boundary of the domain. An associated Luenberger-type estimator is then parameterized using a PI operator $\mathcal{L}$ as the observer gain. Examining the error dynamics of this estimator, it is proven that an upper bound on the $H_{\infty}$-norm of these error dynamics can be minimized by solving a linear operator inequality on PI operator variables. Finally, an analytical formula is proposed for inversion of a class of 2D PI operators, which is then used to reconstruct the Luenberger gain $\mathcal{L}$. Results are implemented in the PIETOOLS software suite -- applying the methodology and simulating the resulting observer for an unstable 2D heat equation with boundary observations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.05061v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Declan S. Jagt, Matthew M. Peet</dc:creator>
    </item>
    <item>
      <title>Model Predictive Bang-Bang Controller Synthesis via Approximate Value Functions</title>
      <link>https://arxiv.org/abs/2402.08148</link>
      <description>arXiv:2402.08148v2 Announce Type: replace 
Abstract: In this paper, we propose a novel method for addressing Optimal Control Problems (OCPs) with input-affine dynamics and cost functions. This approach adopts a Model Predictive Control (MPC) strategy, wherein a controller is synthesized to handle an approximated OCP within a finite time horizon. Upon reaching this horizon, the controller is re-calibrated to tackle another approximation of the OCP, with the approximation updated based on the final state and time information. To tackle each OCP instance, all non-polynomial terms are Taylor-expanded about the current time and state and the resulting Hamilton-Jacobi-Bellman (HJB) PDE is solved via Sum-of-Squares (SOS) programming, providing us with an approximate polynomial value function that can be used to synthesize a bang-bang controller.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08148v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Morgan Jones, Yuanbo Nie, Matthew M. Peet</dc:creator>
    </item>
    <item>
      <title>On Coupling Constraints in Linear Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2402.12191</link>
      <description>arXiv:2402.12191v2 Announce Type: replace 
Abstract: It is well-known that coupling constraints in linear bilevel optimization can lead to disconnected feasible sets, which is not possible without coupling constraints. However, there is no difference between linear bilevel problems with and without coupling constraints w.r.t. their complexity-theoretical hardness. In this note, we prove that, although there is a clear difference between these two classes of problems in terms of their feasible sets, the classes are equivalent on the level of optimal solutions. To this end, given a general linear bilevel problem with coupling constraints, we derive a respective problem without coupling constraints and prove that it has the same optimal solutions (when projected back to the original variable space).</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.12191v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dorothee Henke, Henri Lefebvre, Martin Schmidt, Johannes Th\"urauf</dc:creator>
    </item>
    <item>
      <title>Neural Control Systems</title>
      <link>https://arxiv.org/abs/2404.13967</link>
      <description>arXiv:2404.13967v2 Announce Type: replace 
Abstract: We propose a function-learning methodology with a control-theoretical foundation. We parametrise the approximating function as the solution to a control system on a reproducing-kernel Hilbert space, and propose several methods to find the set of controls which bring the initial function as close as possible to the target function. At first, we derive the expression for the gradient of the cost function with respect to the controls that parametrise the difference equations. This allows us to find the optimal controls by means of gradient descent. In addition, we show how to compute derivatives of the approximating functions with respect to the controls and describe two optimisation methods relying on linear approximations of the approximating functions. We show how the assumptions we make lead to results which are coherent with Pontryagin's maximum principle. We test the optimisation methods on two toy examples and on two higher-dimensional real-world problems, showing that the approaches succeed in learning from real data and are versatile enough to tackle learning tasks of different nature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13967v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paolo Colusso, Damir Filipovi\'c</dc:creator>
    </item>
    <item>
      <title>Schr\"{o}dinger Bridge with Quadratic State Cost is Exactly Solvable</title>
      <link>https://arxiv.org/abs/2406.00503</link>
      <description>arXiv:2406.00503v3 Announce Type: replace 
Abstract: Schr\"odinger bridge is a diffusion process that steers a given distribution to another in a prescribed time while minimizing the effort to do so. It can be seen as the stochastic dynamical version of the optimal mass transport, and has growing applications in generative diffusion models and stochastic optimal control. In this work, we propose a regularized variant of the Schr\"odinger bridge with a quadratic state cost-to-go that incentivizes the optimal sample paths to stay close to a nominal level. Unlike the conventional Schr\"odinger bridge, the regularization induces a state-dependent rate of killing and creation of probability mass, and its solution requires determining the Markov kernel of a reaction-diffusion partial differential equation. We derive this Markov kernel in closed form. Our solution recovers the heat kernel in the vanishing regularization (i.e., diffusion without reaction) limit, thereby recovering the solution of the conventional Schr\"odinger bridge. Our results enable the use of dynamic Sinkhorn recursion for computing the Schr\"odinger bridge with a quadratic state cost-to-go, which would otherwise be challenging to use in this setting. We deduce properties of the new kernel and explain its connections with certain exactly solvable models in quantum mechanics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00503v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexis M. H. Teter, Wenqing Wang, Abhishek Halder</dc:creator>
    </item>
    <item>
      <title>Provably Feasible and Stable White-Box Trajectory Optimization</title>
      <link>https://arxiv.org/abs/2406.01763</link>
      <description>arXiv:2406.01763v3 Announce Type: replace 
Abstract: We study the problem of Trajectory Optimization (TO) for a general class of stiff and constrained dynamic systems. We establish a set of mild assumptions, under which we show that TO converges numerically stably to a locally optimal and feasible solution up to arbitrary user-specified error tolerance. Our key observation is that all prior works use SQP as a black-box solver, where a TO problem is formulated as a Nonlinear Program (NLP) and the underlying SQP solver is not allowed to modify the NLP. Instead, we propose a white-box TO solver, where the SQP solver is informed with characteristics of the objective function and the dynamic system. It then uses these characteristics to derive approximate dynamic systems and customize the discretization schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01763v3</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zherong Pan, Yifan Zhu</dc:creator>
    </item>
    <item>
      <title>$\ell_1$DecNet+: A new architecture framework by $\ell_1$ decomposition and iteration unfolding for sparse feature segmentation</title>
      <link>https://arxiv.org/abs/2203.02690</link>
      <description>arXiv:2203.02690v2 Announce Type: replace-cross 
Abstract: $\ell_1$ based sparse regularization plays a central role in compressive sensing and image processing. In this paper, we propose $\ell_1$DecNet, as an unfolded network derived from a variational decomposition model incorporating $\ell_1$ related sparse regularization and solved by scaled alternating direction method of multipliers (ADMM). $\ell_1$DecNet effectively decomposes an input image into a sparse feature and a learned dense feature, and thus helps the subsequent sparse feature related operations. Based on this, we develop $\ell_1$DecNet+, a learnable architecture framework consisting of our $\ell_1$DecNet and a segmentation module which operates over extracted sparse features instead of original images. This architecture combines well the benefits of mathematical modeling and data-driven approaches. To our best knowledge, this is the first study to incorporate mathematical image prior into feature extraction in segmentation network structures. Moreover, our $\ell_1$DecNet+ framework can be easily extended to 3D case. We evaluate the effectiveness of $\ell_1$DecNet+ on two commonly encountered sparse segmentation tasks: retinal vessel segmentation in medical image processing and pavement crack detection in industrial abnormality identification. Experimental results on different datasets demonstrate that, our $\ell_1$DecNet+ architecture with various lightweight segmentation modules can achieve equal or better performance than their enlarged versions respectively. This leads to especially practical advantages on resource-limited devices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2203.02690v2</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yumeng Ren (School of Mathematical Sciences, Nankai University, Tianjin, China, Department of Mathematics, City University of Hong Kong, China), Yiming Gao (College of Science, Nanjing University of Aeronautics and Astronautics, Nanjing, China), Chunlin Wu (School of Mathematical Sciences, Nankai University, Tianjin, China), Xue-cheng Tai (Norwegian Research Centre)</dc:creator>
    </item>
    <item>
      <title>A New Computational Approach for Solving Linear Bilevel Programs Based on Parameter-Free Disjunctive Decomposition</title>
      <link>https://arxiv.org/abs/2203.06069</link>
      <description>arXiv:2203.06069v2 Announce Type: replace-cross 
Abstract: Linear bilevel programs (linear BLPs) have been widely used in computational mathematics and optimization in several applications. Single-level reformulation for linear BLPs replaces the lower-level linear program with its Karush-Kuhn-Tucker optimality conditions and linearizes the complementary slackness conditions using the big-M technique. Although the approach is straightforward, it requires finding the big-M whose computation is recently shown to be NP-hard. This paper presents a disjunctive-based decomposition algorithm which does not need finding the big-Ms whereas guaranteeing that obtained solution is optimal. Our experience shows promising performance of our algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2203.06069v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Saeed Mohammadi, Mohammad Reza Hesamzadeh, Steven A. Gabriel, Dina Khastieva</dc:creator>
    </item>
    <item>
      <title>Barycenters and a law of large numbers in Gromov hyperbolic spaces</title>
      <link>https://arxiv.org/abs/2211.00193</link>
      <description>arXiv:2211.00193v2 Announce Type: replace-cross 
Abstract: We investigate barycenters of probability measures on Gromov hyperbolic spaces, toward development of convex optimization in this class of metric spaces. We establish a contraction property (the Wasserstein distance between probability measures provides an upper bound of the distance between their barycenters), a deterministic approximation of barycenters of uniform distributions on finite points, and a kind of law of large numbers. These generalize the corresponding results on CAT(0)-spaces, up to additional terms depending on the hyperbolicity constant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.00193v2</guid>
      <category>math.MG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Rev. Mat. Iberoam. 40 (2024), 1185-1206</arxiv:journal_reference>
      <dc:creator>Shin-ichi Ohta</dc:creator>
    </item>
    <item>
      <title>A sparse approximation of the Lieb functional with moment constraints</title>
      <link>https://arxiv.org/abs/2306.00806</link>
      <description>arXiv:2306.00806v3 Announce Type: replace-cross 
Abstract: The aim of this paper is to present new sparsity results about the so-called Lieb functional, which is a key quantity in Density Functional Theory for electronic structure calculations of molecules. The Lieb functional was actually shown by Lieb to be a convexification of the so-called L\'evy-Lieb functional. Given an electronic density for a system of $N$ electrons, which may be seen as a probability density on $\mathbb{R}^3$, the value of the Lieb functional for this density is defined as the solution of a quantum multi-marginal optimal transport problem, which reads as a minimization problem defined on the set of trace-class operators acting on the space of electronic wave-functions that are anti-symmetric $L^2$ functions of $\mathbb{R}^{3N}$, with partial trace equal to the prescribed electronic density. We introduce a relaxation of this quantum optimal transport problem where the full partial trace constraint is replaced by a finite number of moment constraints on the partial trace of the set of operators. We show that, under mild assumptions on the electronic density, there exist sparse minimizers to the resulting moment constrained approximation of the Lieb (MCAL) functional that read as operators with rank at most equal to the number of moment constraints. We also prove under appropriate assumptions on the set of moment functions that the value of the MCAL functional converges to the value of the exact Lieb functional as the number of moments go to infinity. We also prove some rates of convergence on the associated approximation of the ground state energy. We finally study the mathematical properties of the associated dual problem and introduce a suitable numerical algorithm in order to solve some simple toy models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.00806v3</guid>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <category>math.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Virginie Ehrlacher, Luca Nenna</dc:creator>
    </item>
    <item>
      <title>On the Implicit Bias of Adam</title>
      <link>https://arxiv.org/abs/2309.00079</link>
      <description>arXiv:2309.00079v4 Announce Type: replace-cross 
Abstract: In previous literature, backward error analysis was used to find ordinary differential equations (ODEs) approximating the gradient descent trajectory. It was found that finite step sizes implicitly regularize solutions because terms appearing in the ODEs penalize the two-norm of the loss gradients. We prove that the existence of similar implicit regularization in RMSProp and Adam depends on their hyperparameters and the training stage, but with a different "norm" involved: the corresponding ODE terms either penalize the (perturbed) one-norm of the loss gradients or, conversely, impede its reduction (the latter case being typical). We also conduct numerical experiments and discuss how the proven facts can influence generalization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.00079v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matias D. Cattaneo, Jason M. Klusowski, Boris Shigida</dc:creator>
    </item>
    <item>
      <title>A connection between Tempering and Entropic Mirror Descent</title>
      <link>https://arxiv.org/abs/2310.11914</link>
      <description>arXiv:2310.11914v3 Announce Type: replace-cross 
Abstract: This paper explores the connections between tempering (for Sequential Monte Carlo; SMC) and entropic mirror descent to sample from a target probability distribution whose unnormalized density is known. We establish that tempering SMC corresponds to entropic mirror descent applied to the reverse Kullback-Leibler (KL) divergence and obtain convergence rates for the tempering iterates. Our result motivates the tempering iterates from an optimization point of view, showing that tempering can be seen as a descent scheme of the KL divergence with respect to the Fisher-Rao geometry, in contrast to Langevin dynamics that perform descent of the KL with respect to the Wasserstein-2 geometry. We exploit the connection between tempering and mirror descent iterates to justify common practices in SMC and derive adaptive tempering rules that improve over other alternative benchmarks in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.11914v3</guid>
      <category>stat.CO</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicolas Chopin, Francesca R. Crucinio, Anna Korba</dc:creator>
    </item>
    <item>
      <title>Improved High-Probability Bounds for the Temporal Difference Learning Algorithm via Exponential Stability</title>
      <link>https://arxiv.org/abs/2310.14286</link>
      <description>arXiv:2310.14286v2 Announce Type: replace-cross 
Abstract: In this paper we consider the problem of obtaining sharp bounds for the performance of temporal difference (TD) methods with linear function approximation for policy evaluation in discounted Markov decision processes. We show that a simple algorithm with a universal and instance-independent step size together with Polyak-Ruppert tail averaging is sufficient to obtain near-optimal variance and bias terms. We also provide the respective sample complexity bounds. Our proof technique is based on refined error bounds for linear stochastic approximation together with the novel stability result for the product of random matrices that arise from the TD-type recurrence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.14286v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sergey Samsonov, Daniil Tiapkin, Alexey Naumov, Eric Moulines</dc:creator>
    </item>
    <item>
      <title>Pointer Networks with Q-Learning for Combinatorial Optimization</title>
      <link>https://arxiv.org/abs/2311.02629</link>
      <description>arXiv:2311.02629v3 Announce Type: replace-cross 
Abstract: We introduce the Pointer Q-Network (PQN), a hybrid neural architecture that integrates model-free Q-value policy approximation with Pointer Networks (Ptr-Nets) to enhance the optimality of attention-based sequence generation, focusing on long-term outcomes. This integration proves particularly effective in solving combinatorial optimization (CO) tasks, especially the Travelling Salesman Problem (TSP), which is the focus of our study. We address this challenge by defining a Markov Decision Process (MDP) compatible with PQN, which involves iterative graph embedding, encoding and decoding by an LSTM-based recurrent neural network. This process generates a context vector and computes raw attention scores, which are dynamically adjusted by Q-values calculated for all available state-action pairs before applying softmax. The resulting attention vector is utilized as an action distribution, with actions selected hinged to exploration-exploitation dynamic adaptibility of PQN. Our empirical results demonstrate the efficacy of this approach, also testing the model in unstable environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.02629v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alessandro Barro</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning for Near-Optimal Design of Zero-Delay Codes for Markov Sources</title>
      <link>https://arxiv.org/abs/2311.12609</link>
      <description>arXiv:2311.12609v4 Announce Type: replace-cross 
Abstract: In the classical lossy source coding problem, one encodes long blocks of source symbols that enables the distortion to approach the ultimate Shannon limit. Such a block-coding approach introduces large delays, which is undesirable in many delay-sensitive applications. We consider the zero-delay case, where the goal is to encode and decode a finite-alphabet Markov source without any delay. It has been shown that this problem lends itself to stochastic control techniques, which lead to existence, structural, and general structural approximation results. However, these techniques so far have resulted only in computationally prohibitive algorithmic implementations for code design. To address this problem, we present a reinforcement learning design algorithm and rigorously prove its asymptotic optimality. In particular, we show that a quantized Q-learning algorithm can be used to obtain a near-optimal coding policy for this problem. The proof builds on recent results on quantized Q-learning for weakly Feller controlled Markov chains whose application necessitates the development of supporting technical results on regularity and stability properties, and relating the optimal solutions for discounted and average cost infinite horizon criteria problems. These theoretical results are supported by simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.12609v4</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Liam Cregg, Tamas Linder, Serdar Yuksel</dc:creator>
    </item>
    <item>
      <title>Quantum Algorithms for the Pathwise Lasso</title>
      <link>https://arxiv.org/abs/2312.14141</link>
      <description>arXiv:2312.14141v2 Announce Type: replace-cross 
Abstract: We present a novel quantum high-dimensional linear regression algorithm with an $\ell_1$-penalty based on the classical LARS (Least Angle Regression) pathwise algorithm. Similarly to available classical algorithms for Lasso, our quantum algorithm provides the full regularisation path as the penalty term varies, but quadratically faster per iteration under specific conditions. A quadratic speedup on the number of features $d$ is possible by using the quantum minimum-finding routine from D\"urr and Hoyer (arXiv'96) in order to obtain the joining time at each iteration. We then improve upon this simple quantum algorithm and obtain a quadratic speedup both in the number of features $d$ and the number of observations $n$ by using the approximate quantum minimum-finding routine from Chen and de Wolf (ICALP'23). As one of our main contributions, we construct a quantum unitary to approximately compute the joining times to be searched over by the approximate quantum minimum finding. Since the joining times are no longer exactly computed, it is no longer clear that the resulting approximate quantum algorithm obtains a good solution. As our second main contribution, we prove, via an approximate version of the KKT conditions and a duality gap, that the LARS algorithm (and thus our quantum algorithm) is robust to errors. This means that it still outputs a path that minimises the Lasso cost function up to a small error if the joining times are approximately computed. Moreover, we show that, when the observations are sampled from a Gaussian distribution, our quantum algorithm's complexity only depends polylogarithmically on $n$, exponentially better than the classical LARS algorithm, while keeping the quadratic improvement on $d$. Finally, we propose a dequantised algorithm that also retains the polylogarithmic dependence on $n$, albeit with the linear scaling on $d$ from the standard LARS algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.14141v2</guid>
      <category>quant-ph</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joao F. Doriguello, Debbie Lim, Chi Seng Pun, Patrick Rebentrost, Tushar Vaidya</dc:creator>
    </item>
    <item>
      <title>MADA: Meta-Adaptive Optimizers through hyper-gradient Descent</title>
      <link>https://arxiv.org/abs/2401.08893</link>
      <description>arXiv:2401.08893v3 Announce Type: replace-cross 
Abstract: Following the introduction of Adam, several novel adaptive optimizers for deep learning have been proposed. These optimizers typically excel in some tasks but may not outperform Adam uniformly across all tasks. In this work, we introduce Meta-Adaptive Optimizers (MADA), a unified optimizer framework that can generalize several known optimizers and dynamically learn the most suitable one during training. The key idea in MADA is to parameterize the space of optimizers and dynamically search through it using hyper-gradient descent during training. We empirically compare MADA to other popular optimizers on vision and language tasks, and find that MADA consistently outperforms Adam and other popular optimizers, and is robust against sub-optimally tuned hyper-parameters. MADA achieves a greater validation performance improvement over Adam compared to other popular optimizers during GPT-2 training and fine-tuning. We also propose AVGrad, a modification of AMSGrad that replaces the maximum operator with averaging, which is more suitable for hyper-gradient optimization. Finally, we provide a convergence analysis to show that parameterized interpolations of optimizers can improve their error bounds (up to constants), hinting at an advantage for meta-optimizers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.08893v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kaan Ozkara, Can Karakus, Parameswaran Raman, Mingyi Hong, Shoham Sabach, Branislav Kveton, Volkan Cevher</dc:creator>
    </item>
    <item>
      <title>Can We Remove the Square-Root in Adaptive Gradient Methods? A Second-Order Perspective</title>
      <link>https://arxiv.org/abs/2402.03496</link>
      <description>arXiv:2402.03496v5 Announce Type: replace-cross 
Abstract: Adaptive gradient optimizers like Adam(W) are the default training algorithms for many deep learning architectures, such as transformers. Their diagonal preconditioner is based on the gradient outer product which is incorporated into the parameter update via a square root. While these methods are often motivated as approximate second-order methods, the square root represents a fundamental difference. In this work, we investigate how the behavior of adaptive methods changes when we remove the root, i.e. strengthen their second-order motivation. Surprisingly, we find that such square-root-free adaptive methods close the generalization gap to SGD on convolutional architectures, while maintaining their root-based counterpart's performance on transformers. The second-order perspective also has practical benefits for developing non-diagonal adaptive methods through the concept of preconditioner invariance. In contrast to root-based methods like Shampoo, root-free counterparts work well and fast with half-precision since they do not require numerically unstable matrix root decompositions and inversions. This is useful to bridge the computation gap between diagonal and non-diagonal methods. Our findings provide new insights into the development of adaptive methods and raise important questions regarding the currently overlooked role of adaptivity for their success. (experiment code: https://github.com/yorkerlin/remove-the-square-root optimizer code: https://github.com/f-dangel/sirfshampoo)</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.03496v5</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Wu Lin, Felix Dangel, Runa Eschenhagen, Juhan Bae, Richard E. Turner, Alireza Makhzani</dc:creator>
    </item>
    <item>
      <title>To Cool or not to Cool? Temperature Network Meets Large Foundation Models via DRO</title>
      <link>https://arxiv.org/abs/2404.04575</link>
      <description>arXiv:2404.04575v3 Announce Type: replace-cross 
Abstract: The temperature parameter plays a profound role during training and/or inference with large foundation models (LFMs) such as large language models (LLMs) and CLIP models. Particularly, it adjusts the logits in the softmax function in LLMs, which is crucial for next token generation, and it scales the similarities in the contrastive loss for training CLIP models. A significant question remains: Is it viable to learn a neural network to predict a personalized temperature of any input data for enhancing LFMs"? In this paper, we present a principled framework for learning a small yet generalizable temperature prediction network (TempNet) to improve LFMs. Our solution is composed of a novel learning framework with a robust loss underpinned by constrained distributionally robust optimization (DRO), and a properly designed TempNet with theoretical inspiration. TempNet can be trained together with a large foundation model from scratch or learned separately given a pretrained foundation model. It is not only useful for predicting personalized temperature to promote the training of LFMs but also generalizable and transferable to new tasks. Our experiments on LLMs and CLIP models demonstrate that TempNet greatly improves the performance of existing solutions or models, e.g. Table 1. The code to reproduce the experimental results in this paper can be found at https://github.com/zhqiu/TempNet.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04575v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zi-Hao Qiu, Siqi Guo, Mao Xu, Tuo Zhao, Lijun Zhang, Tianbao Yang</dc:creator>
    </item>
    <item>
      <title>Existence and nonexistence of minimizers for classical capillarity problems in presence of nonlocal repulsion and gravity</title>
      <link>https://arxiv.org/abs/2406.02735</link>
      <description>arXiv:2406.02735v2 Announce Type: replace-cross 
Abstract: We investigate, under a volume constraint and among sets contained in a Euclidean half-space, the minimization problem of an energy functional given by the sum of a capillarity perimeter, a nonlocal repulsive term and a gravitational potential energy. The capillarity perimeter assigns a constant weight to the portion of the boundary touching the boundary of the half-space. The nonlocal term is represented by a double integral of a positive kernel $g$, while the gravitational term is represented by the integral of a positive potential $G$.
  We first establish existence of volume-constrained minimizers in the small mass regime, together with several qualitative properties of minimizers. The existence result holds even for rather general choices of kernels in the nonlocal term, including attractive-repulsive ones. When the nonlocal kernel $g(x)=1/|x|^\beta$ with $\beta \in (0,2]$, we also obtain nonexistence of volume constrained minimizers in the large mass regime. Finally, we prove a generalized existence result of minimizers holding for all masses, meaning that the infimum of the problem is realized by a finite disjoint union of sets thought located at "infinite distance" one from the other.
  These results stem from an application of quantitative isoperimetric inequalities for the capillarity problem in a half-space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02735v2</guid>
      <category>math.AP</category>
      <category>math.DG</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giulio Pascale</dc:creator>
    </item>
  </channel>
</rss>
