<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 30 Dec 2024 05:00:44 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>The Illusion-Illusion: Vision Language Models See Illusions Where There are None</title>
      <link>https://arxiv.org/abs/2412.18613</link>
      <description>arXiv:2412.18613v1 Announce Type: new 
Abstract: Illusions are entertaining, but they are also a useful diagnostic tool in cognitive science, philosophy, and neuroscience. A typical illusion shows a gap between how something "really is" and how something "appears to be", and this gap helps us understand the mental processing that lead to how something appears to be. Illusions are also useful for investigating artificial systems, and much research has examined whether computational models of perceptions fall prey to the same illusions as people. Here, I invert the standard use of perceptual illusions to examine basic processing errors in current vision language models. I present these models with illusory-illusions, neighbors of common illusions that should not elicit processing errors. These include such things as perfectly reasonable ducks, crooked lines that truly are crooked, circles that seem to have different sizes because they are, in fact, of different sizes, and so on. I show that many current vision language systems mistakenly see these illusion-illusions as illusions. I suggest that such failures are part of broader failures already discussed in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18613v1</guid>
      <category>q-bio.NC</category>
      <category>cs.CL</category>
      <category>cs.CV</category>
      <pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tomer Ullman</dc:creator>
    </item>
    <item>
      <title>Deep learning and whole-brain networks for biomarker discovery: modeling the dynamics of brain fluctuations in resting-state and cognitive tasks</title>
      <link>https://arxiv.org/abs/2412.19329</link>
      <description>arXiv:2412.19329v1 Announce Type: new 
Abstract: Background: Brain network models offer insights into brain dynamics, but the utility of model-derived bifurcation parameters as biomarkers remains underexplored. Objective: This study evaluates bifurcation parameters from a whole-brain network model as biomarkers for distinguishing brain states associated with resting-state and task-based cognitive conditions. Methods: Synthetic BOLD signals were generated using a supercritical Hopf brain network model to train deep learning models for bifurcation parameter prediction. Inference was performed on Human Connectome Project data, including both resting-state and task-based conditions. Statistical analyses assessed the separability of brain states based on bifurcation parameter distributions. Results: Bifurcation parameter distributions differed significantly across task and resting-state conditions ($p &lt; 0.0001$ for all but one comparison). Task-based brain states exhibited higher bifurcation values compared to rest. Conclusion: Bifurcation parameters effectively differentiate cognitive and resting states, warranting further investigation as biomarkers for brain state characterization and neurological disorder assessment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19329v1</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Facundo Roffet, Gustavo Deco, Claudio Delrieux, Gustavo Patow</dc:creator>
    </item>
    <item>
      <title>Signatures of prediction during natural listening in MEG data?</title>
      <link>https://arxiv.org/abs/2412.19622</link>
      <description>arXiv:2412.19622v1 Announce Type: new 
Abstract: The brain uses contextual information and prior knowledge to anticipate upcoming content during language comprehension. Recent research has shown predictive signals can be revealed in pre-onset ECoG activity during naturalistic narrative listening, by building encoding models based on word embeddings from Large Language Models (LLMs). Similarly, evidence for long-range predictive encoding has been observed in fMRI data, where incorporating embeddings for multiple upcoming words in a narrative improves alignment with brain activity. This study examines whether similar predictive information can be detected in MEG, a technique with higher temporal resolution than fMRI but a lower signal-to-noise ratio than ECoG. Our findings indicate that MEG captures pre-onset representations up to 1 second before word onset, consistent with ECoG results. However, unlike fMRI findings, incorporating future word embeddings did not enhance MEG encoding, even for one word into the future, which suggests that the pre-onset encoding may not reflect predictive processing. This work demonstrates that MEG combined with LLMs is a valuable approach for studying language processing in naturalistic narratives and highlights the need to study further what constitutes evidence for prediction during natural listening.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19622v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sahel Azizpour, Britta U. Westner, Jakub Szewczyk, Umut G\"u\c{c}l\"u, Linda Geerligs</dc:creator>
    </item>
    <item>
      <title>Revealing the Self: Brainwave-Based Human Trait Identification</title>
      <link>https://arxiv.org/abs/2412.19041</link>
      <description>arXiv:2412.19041v1 Announce Type: cross 
Abstract: People exhibit unique emotional responses. In the same scenario, the emotional reactions of two individuals can be either similar or vastly different. For instance, consider one person's reaction to an invitation to smoke versus another person's response to a query about their sleep quality. The identification of these individual traits through the observation of common physical parameters opens the door to a wide range of applications, including psychological analysis, criminology, disease prediction, addiction control, and more. While there has been previous research in the fields of psychometrics, inertial sensors, computer vision, and audio analysis, this paper introduces a novel technique for identifying human traits in real time using brainwave data. To achieve this, we begin with an extensive study of brainwave data collected from 80 participants using a portable EEG headset. We also conduct a statistical analysis of the collected data utilizing box plots. Our analysis uncovers several new insights, leading us to a groundbreaking unified approach for identifying diverse human traits by leveraging machine learning techniques on EEG data. Our analysis demonstrates that this proposed solution achieves high accuracy. Moreover, we explore two deep-learning models to compare the performance of our solution. Consequently, we have developed an integrated, real-time trait identification solution using EEG data, based on the insights from our analysis. To validate our approach, we conducted a rigorous user evaluation with an additional 20 participants. The outcomes of this evaluation illustrate both high accuracy and favorable user ratings, emphasizing the robust potential of our proposed method to serve as a versatile solution for human trait identification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19041v1</guid>
      <category>cs.LG</category>
      <category>eess.IV</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Md Mirajul Islam, Md Nahiyan Uddin, Maoyejatun Hasana, Debojit Pandit, Nafis Mahmud Rahman, Sriram Chellappan, Sami Azam, A. B. M. Alim Al Islam</dc:creator>
    </item>
    <item>
      <title>Neuromorphic Dual-channel Encoding of Luminance and Contrast</title>
      <link>https://arxiv.org/abs/2412.19365</link>
      <description>arXiv:2412.19365v1 Announce Type: cross 
Abstract: There is perceptual and physiological evidence that the retina registers and signals luminance and luminance contrast using dual-channel mechanisms. This process begins in the retina, wherein the luminance of a uniform zone and differentials of luminance in neighboring zones determine the degree of brightness or darkness of the zones. The neurons that process the information can be classified as "bright" or "dark" channels. The present paper provides an overview of these retinal mechanisms along with evidence that they provide brightness judgments that are log-linear across roughly seven orders of magnitude.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19365v1</guid>
      <category>eess.IV</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ernest Greene</dc:creator>
    </item>
    <item>
      <title>Direct estimates of irreversibility from time series</title>
      <link>https://arxiv.org/abs/2412.19772</link>
      <description>arXiv:2412.19772v1 Announce Type: cross 
Abstract: The arrow of time can be quantified through the Kullback-Leibler divergence ($D_{KL}$) between the distributions of forward and reverse trajectories in a system. Many approaches to estimate this rely on specific models, but the use of incorrect models can introduce uncontrolled errors. Here, we describe a model-free method that uses trajectory data directly to estimate the evidence for irreversibility over finite windows of time. To do this we build on previous work to identify and correct for errors that arise from limited sample size. Importantly, our approach accurately recovers $D_{KL} = 0$ in systems that adhere to detailed balance, and the correct nonzero $D_{KL}$ for data generated by well understood models of nonequilibrium systems. We apply our method to trajectories of neural activity in the retina as it responds to naturalistic inputs, and find evidence of irreversibility in single neurons, emphasizing the non-Markovian character of these data. These results open new avenues for investigating how the brain represents the arrow of time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19772v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>physics.bio-ph</category>
      <category>q-bio.NC</category>
      <category>stat.AP</category>
      <pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Trevor GrandPre, Gianluca Teza, William Bialek</dc:creator>
    </item>
    <item>
      <title>Hyperbolic embedding of brain networks detects regions disrupted by neurodegeneration in Alzheimer's disease</title>
      <link>https://arxiv.org/abs/2407.16589</link>
      <description>arXiv:2407.16589v2 Announce Type: replace 
Abstract: Graph theoretical methods have proven valuable for investigating alterations in both anatomical and functional brain connectivity networks during Alzheimer's disease (AD). Recent studies suggest that representing brain networks in a suitable geometric space can better capture their connectivity structure. This study introduces a novel approach to characterize brain connectivity changes using low-dimensional, informative representations of networks in a latent geometric space. Specifically, the networks are embedded in the Poincar\'e disk model of hyperbolic geometry. Here, we define a local measure of distortion of the geometric neighborhood of a node following a perturbation. The method is applied to a brain networks dataset of patients with AD and healthy participants, derived from DWI and fMRI scans. We show that, compared with standard graph measures, our method identifies more accurately the brain regions most affected by neurodegeneration. Notably, the abnormality detection in memory-related and frontal areas are robust across multiple brain parcellation scales. Finally, our findings suggest that the geometric perturbation score could serve as a potential biomarker for characterizing disease progression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16589v2</guid>
      <category>q-bio.NC</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alice Longhena, Martin Guillemaud, Fabrizio De Vico Fallani, Raffaella Lara Migliaccio, Mario Chavez</dc:creator>
    </item>
    <item>
      <title>Universal dimensions of visual representation</title>
      <link>https://arxiv.org/abs/2408.12804</link>
      <description>arXiv:2408.12804v2 Announce Type: replace 
Abstract: Do neural network models of vision learn brain-aligned representations because they share architectural constraints and task objectives with biological vision or because they learn universal features of natural image processing? We characterized the universality of hundreds of thousands of representational dimensions from visual neural networks with varied construction. We found that networks with varied architectures and task objectives learn to represent natural images using a shared set of latent dimensions, despite appearing highly distinct at a surface level. Next, by comparing these networks with human brain representations measured with fMRI, we found that the most brain-aligned representations in neural networks are those that are universal and independent of a network's specific characteristics. Remarkably, each network can be reduced to fewer than ten of its most universal dimensions with little impact on its representational similarity to the human brain. These results suggest that the underlying similarities between artificial and biological vision are primarily governed by a core set of universal image representations that are convergently learned by diverse systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12804v2</guid>
      <category>q-bio.NC</category>
      <category>cs.CV</category>
      <pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zirui Chen, Michael F. Bonner</dc:creator>
    </item>
    <item>
      <title>Broken detailed balance and entropy production in directed networks</title>
      <link>https://arxiv.org/abs/2402.19157</link>
      <description>arXiv:2402.19157v5 Announce Type: replace-cross 
Abstract: The structure of a complex network plays a crucial role in determining its dynamical properties. In this work, we show that the the degree to which a network is directed and hierarchically organised is closely associated with the degree to which its dynamics break detailed balance and produce entropy. We consider a range of dynamical processes and show how different directed network features affect their entropy production rate. We begin with an analytical treatment of a 2-node network followed by numerical simulations of synthetic networks using the preferential attachment and Erd\"os-Renyi algorithms. Next, we analyse a collection of 97 empirical networks to determine the effect of complex real-world topologies. Finally, we present a simple method for inferring broken detailed balance and directed network structure from multivariate time-series and apply our method to identify non-equilibrium dynamics and hierarchical organisation in both human neuroimaging and financial time-series. Overall, our results shed light on the consequences of directed network structure on non-equilibrium dynamics and highlight the importance and ubiquity of hierarchical organisation and non-equilibrium dynamics in real-world systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.19157v5</guid>
      <category>physics.soc-ph</category>
      <category>cond-mat.stat-mech</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1103/PhysRevE.110.034313</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. E 110, 034313 (2024) Erratum: Phys. Rev. E 110, 069901 (2024)</arxiv:journal_reference>
      <dc:creator>Ram\'on Nartallo-Kaluarachchi, Malbor Asllani, Gustavo Deco, Morten L. Kringelbach, Alain Goriely, Renaud Lambiotte</dc:creator>
    </item>
    <item>
      <title>A Mathematical Framework for the Problem of Security for Cognition in Neurotechnology</title>
      <link>https://arxiv.org/abs/2403.07945</link>
      <description>arXiv:2403.07945v3 Announce Type: replace-cross 
Abstract: The rapid advancement in neurotechnology in recent years has created an emerging critical intersection between neurotechnology and security. Implantable devices, non-invasive monitoring, and non-invasive therapies all carry with them the prospect of violating the privacy and autonomy of individuals' cognition. A growing number of scientists and physicians have made calls to address this issue, but applied efforts have been relatively limited. A major barrier hampering scientific and engineering efforts to address these security issues is the lack of a clear means of describing and analyzing relevant problems. In this paper we develop Cognitive Neurosecurity, a mathematical framework which enables such description and analysis by drawing on methods and results from multiple fields. We demonstrate certain statistical properties which have significant implications for Cognitive Neurosecurity, and then present descriptions of the algorithmic problems faced by attackers attempting to violate privacy and autonomy, and defenders attempting to obstruct such attempts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07945v3</guid>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bryce Allen Bagley, Claudia K Petritsch</dc:creator>
    </item>
    <item>
      <title>RTify: Aligning Deep Neural Networks with Human Behavioral Decisions</title>
      <link>https://arxiv.org/abs/2411.03630</link>
      <description>arXiv:2411.03630v2 Announce Type: replace-cross 
Abstract: Current neural network models of primate vision focus on replicating overall levels of behavioral accuracy, often neglecting perceptual decisions' rich, dynamic nature. Here, we introduce a novel computational framework to model the dynamics of human behavioral choices by learning to align the temporal dynamics of a recurrent neural network (RNN) to human reaction times (RTs). We describe an approximation that allows us to constrain the number of time steps an RNN takes to solve a task with human RTs. The approach is extensively evaluated against various psychophysics experiments. We also show that the approximation can be used to optimize an "ideal-observer" RNN model to achieve an optimal tradeoff between speed and accuracy without human data. The resulting model is found to account well for human RT data. Finally, we use the approximation to train a deep learning implementation of the popular Wong-Wang decision-making model. The model is integrated with a convolutional neural network (CNN) model of visual processing and evaluated using both artificial and natural image stimuli. Overall, we present a novel framework that helps align current vision models with human behavior, bringing us closer to an integrated model of human vision.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03630v2</guid>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yu-Ang Cheng, Ivan Felipe Rodriguez, Sixuan Chen, Kohitij Kar, Takeo Watanabe, Thomas Serre</dc:creator>
    </item>
    <item>
      <title>Psycho Gundam: Electroencephalography based real-time robotic control system with deep learning</title>
      <link>https://arxiv.org/abs/2411.06414</link>
      <description>arXiv:2411.06414v3 Announce Type: replace-cross 
Abstract: The Psycho Frame, a sophisticated system primarily used in Universal Century (U.C.) series mobile suits for NEWTYPE pilots, has evolved as an integral component in harnessing the latent potential of mental energy. Its ability to amplify and resonate with the pilot's psyche enables real-time mental control, creating unique applications such as psychomagnetic fields and sensory-based weaponry. This paper presents the development of a novel robotic control system inspired by the Psycho Frame, combining electroencephalography (EEG) and deep learning for real-time control of robotic systems. By capturing and interpreting brainwave data through EEG, the system extends human cognitive commands to robotic actions, reflecting the seamless synchronization of thought and machine, much like the Psyco Frame's integration with a Newtype pilot's mental faculties. This research demonstrates how modern AI techniques can expand the limits of human-machine interaction, potentially transcending traditional input methods and enabling a deeper, more intuitive control of complex robotic systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06414v3</guid>
      <category>cs.RO</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chi-Sheng Chen, Wei-Sheng Wang</dc:creator>
    </item>
  </channel>
</rss>
