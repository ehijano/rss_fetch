<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 20 Feb 2026 05:00:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Entropy Regularization as Robustness under Bayesian Drift Uncertainty</title>
      <link>https://arxiv.org/abs/2602.16862</link>
      <description>arXiv:2602.16862v1 Announce Type: new 
Abstract: We study entropy-regularized mean-variance portfolio optimization under Bayesian drift uncertainty. Gaussian policies remain optimal under partial information, the value function is quadratic in wealth, and belief-dependent coefficients admit closed-form solutions. The mean control is identical to deterministic Bayesian Markowitz feedback; entropy regularization affects only the policy variance. Additionally, this variance does not affect information gain, and instead provides belief-dependent robustness. Notably, optimal policy variance increases with posterior conviction $|m_t|$, forcing greater action randomization when mean position is most aggressive.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16862v1</guid>
      <category>math.OC</category>
      <category>q-fin.PM</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Andy Au</dc:creator>
    </item>
    <item>
      <title>Dynamics of Nesterov's Accelerated Gradient Descent in Quadratic Games</title>
      <link>https://arxiv.org/abs/2602.16982</link>
      <description>arXiv:2602.16982v1 Announce Type: new 
Abstract: We analyze Nesterov's accelerated gradient descent (NAGD) for Nash equilibrium seeking in $N$-player quadratic games. While the continuous-time NAGD dynamics, specifically the Su-Boyd-Cand\`{e}s ODE, are well understood for convex optimization, their behavior with non-symmetric pseudo-gradient matrices arising in games has not been previously studied. We establish sharp spectral characterizations: stability holds if and only if all eigenvalues of the pseudo-gradient matrix $G$ lie in $\mathbb{R}_{\geq 0}$, with the convergence direction additionally requiring diagonalizability of $G$. Remarkably, complex eigenvalues with positive real parts, which ensure stability for first-order gradient dynamics, induce exponential instability in NAGD. This reveals that the momentum mechanism enabling $O(1/t^2)$ convergence in optimization can be detrimental for equilibrium seeking in non-potential games, providing theoretical guidance for algorithm selection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16982v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jay Paek</dc:creator>
    </item>
    <item>
      <title>Formalization of Two Fixed-Point Algorithms in Hilbert Spaces</title>
      <link>https://arxiv.org/abs/2602.17064</link>
      <description>arXiv:2602.17064v1 Announce Type: new 
Abstract: Iterative algorithms are fundamental tools for approximating fixed-points of nonexpansive operators in real Hilbert spaces. Among them, Krasnosel'ski\u{\i}--Mann iteration and Halpern iteration are two widely used schemes. In this work, we formalize the convergence of these two fixed-point algorithms in the interactive theorem prover Lean4 based on type dependent theory. To this end, weak convergence and topological properties in the infinite-dimensional real Hilbert space are formalized. Definition and properties of nonexpansive operators are also provided. As a useful tool in convex analysis, we then formalize the Fej\'{e}r monotone sequence. Building on these foundations, we verify the convergence of both the iteration schemes. Our formalization provides reusable components for machine-checked convergence analysis of fixed-point iterations and theories of convex analysis in real Hilbert spaces. Our code is available at https://github.com/TTony2019/fixed-point-iterations-in-lean.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17064v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yifan Bai, Yantao Li, Jian Yu, Jingwei Liang</dc:creator>
    </item>
    <item>
      <title>Adjoint-based gradient methods for inverse design in a multiple fragmentation model</title>
      <link>https://arxiv.org/abs/2602.17138</link>
      <description>arXiv:2602.17138v1 Announce Type: new 
Abstract: We study an inverse design problem for the linear multiple fragmentation equation arising in particle dynamics. Our objective is to reconstruct an unknown initial size distribution that evolves, under a prescribed fragmentation law, into a desired size distribution at a specified final time. We first establish the existence of global mass-conserving solutions for a broad class of fragmentation kernels with unbounded rates, and subsequently prove the continuous dependence and uniqueness of these solutions under additional assumptions on the fragmentation kernels. We then formulate the inverse design problem as an optimal control problem constrained by the fragmentation dynamics and prove the existence of the optimal control problem. Also derive the corresponding continuous adjoint equation and propose a gradient-type iterative reconstruction method. For the numerical implementation, we develop finite volume schemes for both the forward and adjoint equations, including a weighted finite volume scheme designed to enhance mass conservation and accuracy. Two benchmark problems, involving linear and nonlinear fragmentation rates with known analytical solutions, are used to assess the accuracy and efficiency of the proposed approach and to compare the performance of the two discretizations in both forward simulations and inverse reconstructions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17138v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arijit Das</dc:creator>
    </item>
    <item>
      <title>Stackelberg Dynamic Location Planning under Cumulative Demand</title>
      <link>https://arxiv.org/abs/2602.17392</link>
      <description>arXiv:2602.17392v1 Announce Type: new 
Abstract: Dynamic facility location problems predominantly suppose a monopoly over the service or product provided. Nonetheless, this premise can be a severe oversimplification in the presence of market competitors, as customers may prefer facilities installed by one of them. The monopolistic assumption can particularly worsen planning performance when demand depends on prior location decisions of the market participants, namely, when unmet demand from one period carries over to the next. Such a demand behaviour creates an intrinsic relationship between customer demand and location decisions of all market participants, and requires the decision-maker to anticipate the competitor's response. This work studies a novel competitive facility location problem that combines cumulative demand and market competition to devise high-quality solutions. We propose bilevel mixed-integer programming formulations for two variants of our problem, prove that the optimistic variant is $\Sigma^{p}_{2}$-hard, and develop branch-and-cut algorithms with tightened value-function cuts that significantly outperform general-purpose bilevel solvers. Our results quantify the severe cost of planning under a monopolistic assumption (profit drops by half on average) and the gains from cooperation over competition (6% more joint profit), while drawing managerial guidelines on how instance attributes and duopolistic modelling choices shape robust location schedules.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17392v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Warley Almeida Silva, Margarida Carvalho, Sanjay Dominik Jena</dc:creator>
    </item>
    <item>
      <title>Optimization Problems with Difference of Tangentially Convex Functions under Uncertainty</title>
      <link>https://arxiv.org/abs/2602.17405</link>
      <description>arXiv:2602.17405v1 Announce Type: new 
Abstract: This paper investigates a specific class of nonsmooth nonconvex optimization problems in the face of data uncertainty, namely, robust optimization problems, where the given objective function can be expressed as a difference of two tangentially convex (DTC) functions. More precisely, we develop a range of nonsmooth calculus rules to establish relationships between Frechet and limiting subdifferentials for a particular maximum function and the tangential subdifferential of its constituent functions. Subsequently, we derive optimality conditions for problems involving DTC functions, employing generalized constraint qualifications within the framework of the tangential subdifferential concept. Several illustrative examples are presented to demonstrate the obtained results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17405v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Feryal Mashkoorzadeh, Nooshin Movahedian</dc:creator>
    </item>
    <item>
      <title>A variational mean field game of controls with free final time and pairwise interactions</title>
      <link>https://arxiv.org/abs/2602.17447</link>
      <description>arXiv:2602.17447v1 Announce Type: new 
Abstract: This article considers a mean field game model inspired by crowd motion models in which agents aim at reaching a given target set and wish to minimize a cost consisting of an individual running cost, an individual cost depending on the arrival time at the target set, and an interaction running cost, which takes the form of pairwise interactions with other agents through both positions and velocities. We subsume this game under a more general class of games on abstract Polish spaces with pairwise interactions, and prove that the latter games have a variational structure (in the sense that their equilibria can be characterized as critical points of some potential functional) and admit equilibria. We also discuss two a priori distinct notions of equilibria, providing a sufficient condition under which both notions coincide. The results for the games in abstract Polish spaces are applied to our mean field game model, and a numerical illustration concludes the paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17447v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guilherme Mazanti, Laurent Pfeiffer, Saeed Sadeghi Arjmand</dc:creator>
    </item>
    <item>
      <title>Adaptive Decentralized Composite Optimization via Three-Operator Splitting</title>
      <link>https://arxiv.org/abs/2602.17545</link>
      <description>arXiv:2602.17545v1 Announce Type: new 
Abstract: The paper studies decentralized optimization over networks, where agents minimize a sum of {\it locally} smooth (strongly) convex losses and plus a nonsmooth convex extended value term. We propose decentralized methods wherein agents {\it adaptively} adjust their stepsize via local backtracking procedures coupled with lightweight min-consensus protocols. Our design stems from a three-operator splitting factorization applied to an equivalent reformulation of the problem. The reformulation is endowed with a new BCV preconditioning metric (Bertsekas-O'Connor-Vandenberghe), which enables efficient decentralized implementation and local stepsize adjustments. We establish robust convergence guarantees. Under mere convexity, the proposed methods converge with a sublinear rate. Under strong convexity of the sum-function, and assuming the nonsmooth component is partly smooth, we further prove linear convergence. Numerical experiments corroborate the theory and highlight the effectiveness of the proposed adaptive stepsize strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17545v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaokai Chen, Ilya Kuruzov, Gesualdo Scutari</dc:creator>
    </item>
    <item>
      <title>Optimal control of stochastic Volterra integral equations with completely monotone kernels and stochastic differential equations on Hilbert spaces with unbounded control and diffusion operators</title>
      <link>https://arxiv.org/abs/2602.17578</link>
      <description>arXiv:2602.17578v1 Announce Type: new 
Abstract: The dynamic programming approach is one of the most powerful ones in optimal control. However, when dealing with optimal control problems of stochastic Volterra integral equations (SVIEs) with completely monotone kernels, deep mathematical difficulties arise and it is still not understood. These very classical problems have applications in most fields and have now become even more popular due to their applications in mathematical finance under rough volatility. In this article, we consider a class of optimal control problems of SVIEs with completely monotone kernels. Via a recent Markovian lift \cite{FGW2024}, the problem can be reformulated as an optimal control problem of stochastic differential equations (SDEs) on suitable Hilbert spaces, which due to the roughness of the kernel, presents a generator of an analytic semigroup and unbounded control and diffusion operators.
  This analysis leads us to study a general class of optimal control problems of abstract SDEs on Hilbert spaces with unbounded control and diffusion operators. This class includes optimal control problems of SVIEs with completely monotone kernels, but it is also motivated by other models. We analyze the regularity of the associated Ornstein-Uhlenbeck transition semigroup. We prove that the semigroup exhibits a new smoothing property in control directions through a general observation operator $\Gamma$, which we call $\Gamma$-smoothing. This allows us to establish existence and uniqueness of mild solutions of the Hamilton-Jacobi-Bellman equation, establish a verification theorem, and construct optimal feedback controls. We apply these results to optimal control problems of SVIEs with completely monotone kernels. To the best of our knowledge these are the first results of this kind for this abstract class of infinite dimensional problems and for the optimal control of SVIEs with completely monotone kernels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17578v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.PR</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriele Bolli, Filippo de Feo</dc:creator>
    </item>
    <item>
      <title>Efficient Tail-Aware Generative Optimization via Flow Model Fine-Tuning</title>
      <link>https://arxiv.org/abs/2602.16796</link>
      <description>arXiv:2602.16796v1 Announce Type: cross 
Abstract: Fine-tuning pre-trained diffusion and flow models to optimize downstream utilities is central to real-world deployment. Existing entropy-regularized methods primarily maximize expected reward, providing no mechanism to shape tail behavior. However, tail control is often essential: the lower tail determines reliability by limiting low-reward failures, while the upper tail enables discovery by prioritizing rare, high-reward outcomes. In this work, we present Tail-aware Flow Fine-Tuning (TFFT), a principled and efficient distributional fine-tuning algorithm based on the Conditional Value-at-Risk (CVaR). We address two distinct tail-shaping goals: right-CVaR for seeking novel samples in the high-reward tail and left-CVaR for controlling worst-case samples in the low-reward tail. Unlike prior approaches that rely on non-linear optimization, we leverage the variational dual formulation of CVaR to decompose it into a decoupled two-stage procedure: a lightweight one-dimensional threshold optimization step, and a single entropy-regularized fine-tuning process via a specific pseudo-reward. This decomposition achieves CVaR fine-tuning efficiently with computational cost comparable to standard expected fine-tuning methods. We demonstrate the effectiveness of TFFT across illustrative experiments, high-dimensional text-to-image generation, and molecular design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16796v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zifan Wang, Riccardo De Santi, Xiaoyu Mo, Michael M. Zavlanos, Andreas Krause, Karl H. Johansson</dc:creator>
    </item>
    <item>
      <title>On the Mechanism and Dynamics of Modular Addition: Fourier Features, Lottery Ticket, and Grokking</title>
      <link>https://arxiv.org/abs/2602.16849</link>
      <description>arXiv:2602.16849v1 Announce Type: cross 
Abstract: We present a comprehensive analysis of how two-layer neural networks learn features to solve the modular addition task. Our work provides a full mechanistic interpretation of the learned model and a theoretical explanation of its training dynamics. While prior work has identified that individual neurons learn single-frequency Fourier features and phase alignment, it does not fully explain how these features combine into a global solution. We bridge this gap by formalizing a diversification condition that emerges during training when overparametrized, consisting of two parts: phase symmetry and frequency diversification. We prove that these properties allow the network to collectively approximate a flawed indicator function on the correct logic for the modular addition task. While individual neurons produce noisy signals, the phase symmetry enables a majority-voting scheme that cancels out noise, allowing the network to robustly identify the correct sum. Furthermore, we explain the emergence of these features under random initialization via a lottery ticket mechanism. Our gradient flow analysis proves that frequencies compete within each neuron, with the "winner" determined by its initial spectral magnitude and phase alignment. From a technical standpoint, we provide a rigorous characterization of the layer-wise phase coupling dynamics and formalize the competitive landscape using the ODE comparison lemma. Finally, we use these insights to demystify grokking, characterizing it as a three-stage process involving memorization followed by two generalization phases, driven by the competition between loss minimization and weight decay.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16849v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jianliang He, Leda Wang, Siyu Chen, Zhuoran Yang</dc:creator>
    </item>
    <item>
      <title>Adam Improves Muon: Adaptive Moment Estimation with Orthogonalized Momentum</title>
      <link>https://arxiv.org/abs/2602.17080</link>
      <description>arXiv:2602.17080v1 Announce Type: cross 
Abstract: Efficient stochastic optimization typically integrates an update direction that performs well in the deterministic regime with a mechanism adapting to stochastic perturbations. While Adam uses adaptive moment estimates to promote stability, Muon utilizes the weight layers' matrix structure via orthogonalized momentum, showing superior performance in large language model training. We propose a new optimizer and a diagonal extension, NAMO and NAMO-D, providing the first principled integration of orthogonalized momentum with norm-based Adam-type noise adaptation. NAMO scales orthogonalized momentum using a single adaptive stepsize, preserving orthogonality while improving upon Muon at negligible additional cost. NAMO-D instead right-multiplies orthogonalized momentum by a diagonal matrix with clamped entries. This design enables neuron-wise noise adaptation and aligns with the common near block-diagonal Hessian structure. Under standard assumptions, we establish optimal convergence rates for both algorithms in the deterministic setting and show that, in the stochastic setting, their convergence guarantees adapt to the noise level of stochastic gradients. Experiments on pretraining GPT-2 models demonstrate improved performance of both NAMO and NAMO-D compared to the AdamW and Muon baselines, with NAMO-D achieving further gains over NAMO via an additional clamping hyperparameter that balances the competing goals of maintaining a well-conditioned update direction and leveraging fine-grained noise adaptation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17080v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minxin Zhang, Yuxuan Liu, Hayden Scheaffer</dc:creator>
    </item>
    <item>
      <title>Convergence Analysis of Two-Layer Neural Networks under Gaussian Input Masking</title>
      <link>https://arxiv.org/abs/2602.17423</link>
      <description>arXiv:2602.17423v1 Announce Type: cross 
Abstract: We investigate the convergence guarantee of two-layer neural network training with Gaussian randomly masked inputs. This scenario corresponds to Gaussian dropout at the input level, or noisy input training common in sensor networks, privacy-preserving training, and federated learning, where each user may have access to partial or corrupted features. Using a Neural Tangent Kernel (NTK) analysis, we demonstrate that training a two-layer ReLU network with Gaussian randomly masked inputs achieves linear convergence up to an error region proportional to the mask's variance. A key technical contribution is resolving the randomness within the non-linear activation, a problem of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17423v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Afroditi Kolomvaki, Fangshuo Liao, Evan Dramko, Ziyun Guang, Anastasios Kyrillidis</dc:creator>
    </item>
    <item>
      <title>Design of low-energy transfers in cislunar space using sequences of lobe dynamics</title>
      <link>https://arxiv.org/abs/2602.17444</link>
      <description>arXiv:2602.17444v1 Announce Type: cross 
Abstract: Dynamical structures in the circular restricted three-body problem (CR3BP) are fundamental for designing low-energy transfers, as they aid in analyzing phase space transport and designing desirable trajectories. This study focuses on lobe dynamics to exploit local chaotic transport around celestial bodies, and proposes a new method for systematically designing low-energy transfers by combining multiple lobe dynamics. A graph-based framework is constructed to explore possible transfer paths between departure and arrival orbits, reducing the complexity of the combinatorial optimization problem for designing fuel-efficient transfers. Based on this graph, low-energy transfer trajectories are constructed by connecting chaotic orbits within lobes. The resulting optimal trajectory in the Earth--Moon CR3BP is then converted into an optimal transfer in the bicircular restricted four-body problem using multiple shooting. The obtained transfer is compared with existing optimal solutions to demonstrate the effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17444v1</guid>
      <category>nlin.CD</category>
      <category>astro-ph.IM</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <category>physics.class-ph</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Naoki Hiraiwa, Mai Bando, Yuzuru Sato, Shinji Hokamoto</dc:creator>
    </item>
    <item>
      <title>Linear Convergence in Games with Delayed Feedback via Extra Prediction</title>
      <link>https://arxiv.org/abs/2602.17486</link>
      <description>arXiv:2602.17486v1 Announce Type: cross 
Abstract: Feedback delays are inevitable in real-world multi-agent learning. They are known to severely degrade performance, and the convergence rate under delayed feedback is still unclear, even for bilinear games. This paper derives the rate of linear convergence of Weighted Optimistic Gradient Descent-Ascent (WOGDA), which predicts future rewards with extra optimism, in unconstrained bilinear games. To analyze the algorithm, we interpret it as an approximation of the Extra Proximal Point (EPP), which is updated based on farther future rewards than the classical Proximal Point (PP). Our theorems show that standard optimism (predicting the next-step reward) achieves linear convergence to the equilibrium at a rate $\exp(-\Theta(t/m^{5}))$ after $t$ iterations for delay $m$. Moreover, employing extra optimism (predicting farther future reward) tolerates a larger step size and significantly accelerates the rate to $\exp(-\Theta(t/(m^{2}\log m)))$. Our experiments also show accelerated convergence driven by the extra optimism and are qualitatively consistent with our theorems. In summary, this paper validates that extra optimism is a promising countermeasure against performance degradation caused by feedback delays.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17486v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuma Fujimoto, Kenshi Abe, Kaito Ariu</dc:creator>
    </item>
    <item>
      <title>On the Linearization of Flat Multi-Input Systems via Prolongations</title>
      <link>https://arxiv.org/abs/2602.17562</link>
      <description>arXiv:2602.17562v1 Announce Type: cross 
Abstract: We examine when differentially flat nonlinear control systems with more than two inputs can be rendered static feedback linearizable by prolongations of suitably chosen inputs after applying a static input transformation. Building on the structure of the time derivatives of a flat output, we derive sufficient conditions that guarantee such prolongations yield a static feedback linearizable system. In the two-input case, prior work established precise links between relative degrees, the highest derivative orders occurring in a flat parameterization, and the minimal dimension of a linearizing dynamic extension, leading to necessary and sufficient criteria for systems that become static feedback linearizable after at most two prolongations of such suitably chosen inputs. This work extends this analysis to systems with more than two inputs and derives particular results for the three-input case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17562v1</guid>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Georg Hartl, Conrad Gst\"ottner, Markus Sch\"oberl</dc:creator>
    </item>
    <item>
      <title>The Hidden Nature of Non-Markovianity</title>
      <link>https://arxiv.org/abs/2602.17631</link>
      <description>arXiv:2602.17631v1 Announce Type: cross 
Abstract: The theory of open quantum systems served as a tool to prepare entanglement at the beginning stage of quantum technology and more recently provides an important tool for state preparation. Dynamics given by time dependent Lindbladians are Markovian and lead to decoherence, decay of correlation and convergence to equilibrium. In contrast Non-Markovian evolutions can outperform their Markovian counterparts by enhancing memory. In this letter we compare the trajectories of Markovian and Non-Markovian evolutions starting from a fixed initial value. It turns out that under mild assumptions every trajectory can be obtained from a family of time dependent Lindbladians. Hence Non-Markovianity is invisible if single trajectories are concerned.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17631v1</guid>
      <category>quant-ph</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jihong Cai, Advith Govindarajan, Marius Junge</dc:creator>
    </item>
    <item>
      <title>On structural contraction of biological interaction networks</title>
      <link>https://arxiv.org/abs/2307.13678</link>
      <description>arXiv:2307.13678v4 Announce Type: replace 
Abstract: Biological networks are customarily described as structurally robust. This means that they often function extremely well under large forms of perturbations affecting both the concentrations and the kinetic parameters. In order to explain this property, various mathematical notions have been proposed in the literature. In this paper, we propose the notion of structural contractivity, building on the previous work of the authors. That previous work characterized the long-term dynamics of classes of Biological Interaction Networks (BINs), based on "rate-dependent Lyapunov functions". Here, we show that stronger notions of convergence can be established by proving structural contractivity with respect to non-standard polyhedral $\ell_\infty$-norms. In particular, we show that such networks are nonexpansive. With additional verifiable conditions, we show that they are strictly contractive over arbitrary positive compact sets. In addition, we show that such networks entrain to periodic inputs. We illustrate our theory with examples drawn from the modeling of intracellular signaling pathways.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.13678v4</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <category>q-bio.MN</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>M. Ali Al-Radhawi, David Angeli, Eduardo Sontag</dc:creator>
    </item>
    <item>
      <title>Asymptotic Value in Zero-Sum Stochastic Games with Vanishing Stage Duration and Public Signals</title>
      <link>https://arxiv.org/abs/2403.07467</link>
      <description>arXiv:2403.07467v3 Announce Type: replace 
Abstract: We study $\lambda$-discounted zero-sum games as the discount factor $\lambda$ approaches $0$ (that is, the players are more and more patient), in the context of games with stage duration. In stochastic games with stage duration $h$, players act at times $0, h, 2h$, and so on. The payoff and leaving probabilities are proportional to $h$. When $h$ tends to $0$, such discrete-time games approximate games played in continuous time. The asymptotic behavior of the values (when both $\lambda$ and $h$ tend to $0$) has already been studied for stochastic games with full state observation and for state-blind games. We consider the same question for the case of stochastic games with deterministic public signals on the state. We construct a stochastic game with public signals, with no asymptotic value (as the discount factor $\lambda$ goes to $0$) if the stage duration is $1$, but with an asymptotic value when the stage duration $h$ and the discount factor $\lambda$ both tend to $0$. Informally, this means that the asymptotic value in discrete time does not exist, whereas it does exist in continuous time. This situation cannot occur in stochastic games with full state observation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07467v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ivan Novikov</dc:creator>
    </item>
    <item>
      <title>A Computational Study for Solving Decision-Dependent Robust Problems as Bilevel Optimization Problems</title>
      <link>https://arxiv.org/abs/2503.01559</link>
      <description>arXiv:2503.01559v3 Announce Type: replace 
Abstract: Both bilevel and robust optimization are established fields of mathematical optimization and operations research. However, only until recently, the similarities in their mathematical structure has neither been studied theoretically nor exploited computationally. Based on the recent results by Goerigk et al. (2025), this paper is the first one that provides an extensive computational study for solving strictly robust optimization problems with decision-dependent uncertainty sets as equivalent bilevel optimization problems. If the uncertainty set can be dualized, the respective bilevel techniques to obtain a single-level reformulation are very similar compared with the classic dualization techniques used in robust optimization but lead to larger single-level problems to be solved. Our numerical study shows that this usually leads to larger computation times. For the more challenging case of decision-dependent uncertainty sets represented by mixed-integer linear models, one cannot apply classic dualization techniques from robust optimization. Thus, we compare the presented bilevel approach with an established method from the literature, which is based on quantified mixed-integer linear programs. Our numerical results indicate that, for the problem class of decision-dependent robust optimization problems with mixed-integer linear uncertainty sets, the bilevel approach performs better in terms of computation times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01559v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Henri Lefebvre, Martin Schmidt, Simon Stevens, Johannes Th\"urauf</dc:creator>
    </item>
    <item>
      <title>Optimization techniques for modeling with piecewise-linear functions</title>
      <link>https://arxiv.org/abs/2503.10405</link>
      <description>arXiv:2503.10405v3 Announce Type: replace 
Abstract: In this paper we aim to construct piecewise-linear (PWL) approximations for functions of multiple variables and to build compact mixed-integer linear programming (MILP) formulations to represent the resulting PWL function. On the one hand, we describe a simple heuristic to iteratively construct a triangulation with a small number of triangles, while decreasing the error of the piecewise-linear approximation. On the other hand, we extend known techniques for modeling PWLs in MILPs more efficiently than state-of-the-art methods permit. The crux of our method is that the MILP model is a result of solving some hard combinatorial optimization problems, for which we present heuristic algorithms. The effectiveness of our techniques is demonstrated by a series of computational experiments including a short-term hydropower scheduling problem</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10405v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>P\'eter Dobrovoczki, Tam\'as Kis</dc:creator>
    </item>
    <item>
      <title>Biobjective optimization with M-convex functions</title>
      <link>https://arxiv.org/abs/2507.23423</link>
      <description>arXiv:2507.23423v2 Announce Type: replace 
Abstract: In this paper, we deal with two ingredients that, as far as we know, have not been combined until now: multiobjective optimization and discrete convex analysis. First, we show that the entire Pareto optimal value set can be obtained in polynomial time for biobjective optimization problems with discrete convex functions, in particular, involving an M$^\natural$-convex function and a linear function with binary coefficients. We also observe that a more efficient algorithm can be obtained in the special case where the M$^\natural$-convex function is M-convex. Additionally, we present a polynomial-time method for biobjective optimization problems that combine M$^\natural$-convex function minimization with lexicographic optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23423v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ellen H. Fukuda, Satoru Iwata, Itsuki Nakagawa</dc:creator>
    </item>
    <item>
      <title>Ringleader ASGD: The First Asynchronous SGD with Optimal Time Complexity under Data Heterogeneity</title>
      <link>https://arxiv.org/abs/2509.22860</link>
      <description>arXiv:2509.22860v3 Announce Type: replace 
Abstract: Asynchronous stochastic gradient methods are central to scalable distributed optimization, particularly when devices differ in computational capabilities. Such settings arise naturally in federated learning, where training takes place on smartphones and other heterogeneous edge devices. In addition to varying computation speeds, these devices often hold data from different distributions. However, existing asynchronous SGD methods struggle in such heterogeneous settings and face two key limitations. First, many rely on unrealistic assumptions of similarity across workers' data distributions. Second, methods that relax this assumption still fail to achieve theoretically optimal performance under heterogeneous computation times. We introduce Ringleader ASGD, the first asynchronous SGD algorithm that attains the theoretical lower bounds for parallel first-order stochastic methods in the smooth nonconvex regime, thereby achieving optimal time complexity under data heterogeneity and without restrictive similarity assumptions. Our analysis further establishes that Ringleader ASGD remains optimal under arbitrary and even time-varying worker computation speeds, closing a fundamental gap in the theory of asynchronous optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22860v3</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>The Fourteenth International Conference on Learning Representations (ICLR 2026)</arxiv:journal_reference>
      <dc:creator>Artavazd Maranjyan, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>On the convergence rate of the boosted Difference-of-Convex Algorithm (DCA)</title>
      <link>https://arxiv.org/abs/2510.16569</link>
      <description>arXiv:2510.16569v2 Announce Type: replace 
Abstract: The difference-of-convex algorithm (DCA) is a well-established nonlinear programming technique that solves successive convex optimization problems. These sub-problems are obtained from the difference-of-convex~(DC) decompositions of the objective and constraint functions. We investigate the worst-case performance of the unconstrained DCA, with and without boosting, where boosting simply performs an additional step in the direction generated by the usual DCA method. We show that, for certain classes of DC decompositions, the boosted DCA is provably better in the worst-case than the usual DCA. While several numerical studies have reported that boosted DCA outperforms classical DCA, a theoretical explanation for this behavior has, to the best of our knowledge, not been given until now. Our proof technique relies on semidefinite programming (SDP) performance estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16569v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hadi Abbaszadehpeivasti, Etienne de Klerk, Adrien Taylor</dc:creator>
    </item>
    <item>
      <title>On Intensity of Preference Rank Reversal in the AHP</title>
      <link>https://arxiv.org/abs/2512.11622</link>
      <description>arXiv:2512.11622v3 Announce Type: replace 
Abstract: The analytic hierarchy process (AHP) is one of the most widely used multicriteria decision-making methods, with applications from agriculture to space engineering. Despite its popularity, AHP has been repeatedly criticised for rank reversal, a phenomenon in which the ranking of alternatives changes after the addition or removal of an irrelevant or duplicate alternative.
  This paper introduces a new type of rank reversal in AHP, arising when the intensity of preferences is uniformly increased. We show that even when all pairwise preferences preserve their direction and are intensified identically, the eigenvector method may produce a different ordering of alternatives. In contrast, the geometric mean (GM) method is robust to this intensity-of-preference (IOP) rank reversal.
  The applicability of this result is shown through a real decision-making problem taken from a NASA manual concerning capability prioritisation for the planned lunar Gateway orbital station.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11622v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Jiri Mazurek, Luis \'Angel Calvo</dc:creator>
    </item>
    <item>
      <title>On Computing and Pricing of Adjustable Robust Chemical Process Designs</title>
      <link>https://arxiv.org/abs/2512.15318</link>
      <description>arXiv:2512.15318v2 Announce Type: replace 
Abstract: Model-based process simulation can be used to derive designs and operating conditions of chemical processes that optimally balance multiple objectives, such as quality, costs, or environmental impacts. This work focuses on identifying designs that hedge against uncertainties in model parameters to ensure feasibility, taking the possibility to adjust operating conditions into account. An adaptive scheme is proposed to pinpoint the relevant scenarios in a discretized uncertainty space; these scenarios are then fed into a multi-objective adjustable robust optimization framework reducing the computational burden compared to the consideration of all potential scenarios. Furthermore, we propose a method to quantify the cost or price of robustness, i.e., the compromise which has to be made in comparison to the nominal design case in order to hedge against uncertainty. The conceptual findings are illustrated with an industrially relevant case study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15318v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jan Schwientek, Katrin Teichert, Jan Schr\"oder, Johannes H\"oller, Patrick Schwartz, Norbert Asprion, Pascal Sch\"afer, Martin Wlotzka, Michael Bortz</dc:creator>
    </item>
    <item>
      <title>Gradient Testing and Estimation by Comparisons</title>
      <link>https://arxiv.org/abs/2405.11454</link>
      <description>arXiv:2405.11454v2 Announce Type: replace-cross 
Abstract: We study gradient testing and gradient estimation of smooth functions using only a comparison oracle that, given two points, indicates which one has the larger function value. For any smooth $f\colon\mathbb R^n\to\mathbb R$, $\mathbf{x}\in\mathbb R^n$, and $\varepsilon&gt;0$, we design a gradient testing algorithm that determines whether the normalized gradient $\nabla f(\mathbf{x})/\|\nabla f(\mathbf{x})\|$ is $\varepsilon$-close or $2\varepsilon$-far from a given unit vector $\mathbf{v}$ using $O(1)$ queries, as well as a gradient estimation algorithm that outputs an $\varepsilon$-estimate of $\nabla f(\mathbf{x})/\|\nabla f(\mathbf{x})\|$ using $O(n\log(1/\varepsilon))$ queries which we prove to be optimal. Furthermore, we study gradient estimation in the quantum comparison oracle model where queries can be made in superpositions, and develop a quantum algorithm using $O(\log (n/\varepsilon))$ queries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11454v2</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiwen Tao, Chenyi Zhang, Helin Wang, Yexin Zhang, Tongyang Li</dc:creator>
    </item>
    <item>
      <title>Uniform-in-time propagation of chaos for Consensus-Based Optimization</title>
      <link>https://arxiv.org/abs/2505.08669</link>
      <description>arXiv:2505.08669v2 Announce Type: replace-cross 
Abstract: We study the derivative-free global optimization algorithm Consensus-Based Optimization (CBO), establishing uniform-in-time propagation of chaos as well as an almost uniform-in-time stability result for the microscopic particle system. Moreover, we prove almost sure exponential convergence of the microscopic CBO system around a point close to the global minimizer. The proof of these results is based on a novel stability estimate for the weighted mean and on a quantitative concentration inequality for the microscopic particle system around the empirical mean. Our propagation of chaos result recovers the classical Monte Carlo rate, with a prefactor that depends explicitly on the parameters of the problem. Notably, in the case of CBO with anisotropic noise, this prefactor is independent of the problem dimension.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08669v2</guid>
      <category>math.PR</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolai Gerber, Franca Hoffmann, Dohyeon Kim, Urbain Vaes</dc:creator>
    </item>
    <item>
      <title>Nonlinear Model Order Reduction of Dynamical Systems in Process Engineering: Review and Comparison</title>
      <link>https://arxiv.org/abs/2506.12819</link>
      <description>arXiv:2506.12819v2 Announce Type: replace-cross 
Abstract: Computationally cheap yet accurate dynamical models are a key requirement for real-time capable nonlinear optimization and model-based control. When given a computationally expensive high-order prediction model, a reduction to a lower-order simplified model can enable such real-time applications. Herein, we review nonlinear model order reduction methods and provide a comparison of method characteristics. Additionally, we discuss both general-purpose methods and tailored approaches for chemical process systems and we identify similarities and differences between these methods. As machine learning manifold-Galerkin approaches currently do not account for inputs in the construction of the reduced state subspace, we extend these methods to dynamical systems with inputs. In a comparative case study, we apply eight established model order reduction methods to an air separation process model: POD-Galerkin, nonlinear-POD-Galerkin, manifold-Galerkin, dynamic mode decomposition, Koopman theory, manifold learning with latent predictor, compartment modeling, and model aggregation. Herein, we do not investigate hyperreduction, i.e., reduction of floating point operations. Based on our findings, we discuss strengths and weaknesses of the model order reduction methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.12819v2</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.DG</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jan C. Schulze, Alexander Mitsos</dc:creator>
    </item>
    <item>
      <title>Slicing Wasserstein Over Wasserstein Via Functional Optimal Transport</title>
      <link>https://arxiv.org/abs/2509.22138</link>
      <description>arXiv:2509.22138v2 Announce Type: replace-cross 
Abstract: Wasserstein distances define a metric between probability measures on arbitrary metric spaces, including meta-measures (measures over measures). The resulting Wasserstein over Wasserstein (WoW) distance is a powerful, but computationally costly tool for comparing datasets or distributions over images and shapes. Existing sliced WoW accelerations rely on parametric meta-measures or the existence of high-order moments, leading to numerical instability. As an alternative, we propose to leverage the isometry between the 1d Wasserstein space and the quantile functions in the function space $L_2([0,1])$. For this purpose, we introduce a general sliced Wasserstein framework for arbitrary Banach spaces. Due to the 1d Wasserstein isometry, this framework defines a sliced distance between 1d meta-measures via infinite-dimensional $L_2$-projections, parametrized by Gaussian processes. Combining this 1d construction with classical integration over the Euclidean unit sphere yields the double-sliced Wasserstein (DSW) metric for general meta-measures. We show that DSW minimization is equivalent to WoW minimization for discretized meta-measures, while avoiding unstable higher-order moments and computational savings. Numerical experiments on datasets, shapes, and images validate DSW as a scalable substitute for the WoW distance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22138v2</guid>
      <category>cs.LG</category>
      <category>math.MG</category>
      <category>math.OC</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Moritz Piening, Robert Beinert</dc:creator>
    </item>
    <item>
      <title>The Wasserstein gradient flow of the Sinkhorn divergence between Gaussian distributions</title>
      <link>https://arxiv.org/abs/2602.10726</link>
      <description>arXiv:2602.10726v2 Announce Type: replace-cross 
Abstract: We study the Wasserstein gradient flow of the Sinkhorn divergence when both the source and the target are Gaussian distributions. We prove the existence of a flow that stays in the class of Gaussian distributions, and is unique in the larger class of measures with strongly-concave and smooth log-densities. We prove that the flow globally converges toward the target measure when the source's covariance matrix is not singular, and provide counter-examples to global convergence when it is, giving a first answer to an open question raised in [Carlier et al. 2024, \S4.2]. When the covariance matrix of the source distribution commutes with that of the target, we derive more quantitative results that showcase exponential convergence toward the target when the source and the target share their support, but dropping to linear rates (O(t^{-1})) if the target is concentrated on a strict subspace of the source's support.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10726v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mathis Hardion (LIGM), Th\'eo Lacombe (LIGM)</dc:creator>
    </item>
    <item>
      <title>Trading in CEXs and DEXs with Priority Fees and Stochastic Delays</title>
      <link>https://arxiv.org/abs/2602.10798</link>
      <description>arXiv:2602.10798v2 Announce Type: replace-cross 
Abstract: We develop a mixed control framework that combines absolutely continuous controls with impulse interventions subject to stochastic execution delays. The model extends current impulse control formulations by allowing (i) the controller to choose the mean of the stochastic delay of their impulses, and allowing (ii) for multiple pending orders, so that several impulses can be submitted and executed asynchronously at random times. The framework is motivated by an optimal trading problem between centralized (CEX) and decentralized (DEX) exchanges. In DEXs, traders control the distribution of the execution delay through the priority fee paid, introducing a fundamental trade-off between delays, uncertainty, and costs. We study the optimal trading problem of an agent exploiting trading signals in CEXs and DEXs. From a mathematical perspective, we derive the associated dynamic programming principle of this new class of impulse control problems, and establish the viscosity properties of the corresponding quasi-variational inequalities. From a financial perspective, our model provides insights on how to carry out execution across CEXs and DEXs, highlighting how traders manage latency risk optimally through priority fee selection. We show that employing the optimal priority fee has a significant outperformance over non-strategic fee selection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10798v2</guid>
      <category>q-fin.TR</category>
      <category>math.OC</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Philippe Bergault, Yadh Hafsi, Leandro S\'anchez-Betancourt</dc:creator>
    </item>
    <item>
      <title>Stability Analysis of Geometric Control for a Canonical Class of Underactuated Aerial Vehicles with Spurious Forces</title>
      <link>https://arxiv.org/abs/2602.10961</link>
      <description>arXiv:2602.10961v3 Announce Type: replace-cross 
Abstract: Standard geometric control relies on force-moment decoupling, an assumption that breaks down in many aerial platforms due to spurious forces naturally induced by control moments. While strategies for such coupled systems have been validated experimentally, a rigorous theoretical certification of their stability is currently missing. This work fills this gap by providing the first formal stability analysis for a generic class of floating rigid bodies subject to spurious forces. We introduce a canonical model and construct a Lyapunov-based proof establishing local exponential stability of the hovering equilibrium. Crucially, the analysis explicitly addresses the structural challenges - specifically the induced non-minimum-phase behavior - that prevent the application of standard cascade arguments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10961v3</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simone Orelli, Mirko Mizzoni, Antonio Franchi</dc:creator>
    </item>
  </channel>
</rss>
