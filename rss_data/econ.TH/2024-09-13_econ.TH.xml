<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.TH</link>
    <description>econ.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 13 Sep 2024 04:00:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Inertial Coordination Games</title>
      <link>https://arxiv.org/abs/2409.08145</link>
      <description>arXiv:2409.08145v1 Announce Type: new 
Abstract: We analyze inertial coordination games: dynamic coordination games with an endogenously changing state that depends on (i) a persistent fundamental that players privately learn about; and (ii) past play. We give a tight characterization of how the speed of learning shapes equilibrium dynamics: the risk-dominant action is selected in the limit if and only if learning is slow such that posterior precisions grow sub-quadratically. This generalizes results from static global games and endows them with an alternate learning foundation. Conversely, when learning is fast, equilibrium dynamics exhibit persistence and limit play is shaped by initial play. Whenever the risk dominant equilibrium is selected, the path of play undergoes a sudden transition when signals are precise, and a gradual transition when signals are noisy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08145v1</guid>
      <category>econ.TH</category>
      <category>cs.MA</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew Koh, Ricky Li, Kei Uzui</dc:creator>
    </item>
    <item>
      <title>Private Private Information</title>
      <link>https://arxiv.org/abs/2112.14356</link>
      <description>arXiv:2112.14356v4 Announce Type: replace 
Abstract: Private signals model noisy information about an unknown state. Although these signals are called "private," they may still carry information about each other. Our paper introduces the concept of private private signals, which contain information about the state but not about other signals. To achieve privacy, signal quality may need to be sacrificed. We study the informativeness of private private signals and characterize those that are optimal in the sense that they cannot be made more informative without violating privacy. We discuss implications for privacy in recommendation systems, information design, causal inference, and mechanism design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2112.14356v4</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <category>math.PR</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kevin He, Fedor Sandomirskiy, Omer Tamuz</dc:creator>
    </item>
    <item>
      <title>Algorithmic collusion under competitive design</title>
      <link>https://arxiv.org/abs/2312.02644</link>
      <description>arXiv:2312.02644v3 Announce Type: replace 
Abstract: We study a simple model of algorithmic collusion in which Q-learning algorithms are designed in a strategic fashion. We let players (\textit{designers}) choose their exploration policy simultaneously prior to letting their algorithms repeatedly play a prisoner's dilemma. We prove that, in equilibrium, collusive behavior is reached with positive probability. Our numerical simulations indicate symmetry of the equilibria and give insight for how they are affected by a parameter of interest. We also investigate general profiles of exploration policies. We characterize the behavior of the system for extreme profiles (fully greedy and fully explorative) and use numerical simulations and clustering methods to measure the likelihood of collusive behavior in general cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.02644v3</guid>
      <category>econ.TH</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ivan Conjeaud</dc:creator>
    </item>
    <item>
      <title>Predictive Enforcement</title>
      <link>https://arxiv.org/abs/2405.04764</link>
      <description>arXiv:2405.04764v2 Announce Type: replace 
Abstract: We study law enforcement guided by data-informed predictions of "hot spots" for likely criminal offenses. Such "predictive" enforcement could lead to data being selectively and disproportionately collected from neighborhoods targeted for enforcement by the prediction. Predictive enforcement that fails to account for this endogenous "datafication" may lead to the over-policing of traditionally high-crime neighborhoods and performs poorly, in particular, in some cases as poorly as if no data were used. Endogenizing the incentives for criminal offenses identifies additional deterrence benefits from the informationally efficient use of data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04764v2</guid>
      <category>econ.TH</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yeon-Koo Che, Jinwoo Kim, Konrad Mierendorff</dc:creator>
    </item>
  </channel>
</rss>
