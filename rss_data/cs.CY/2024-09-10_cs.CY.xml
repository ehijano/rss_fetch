<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CY updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CY</link>
    <description>cs.CY updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CY" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 11 Sep 2024 04:00:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Using Process Mining to Improve Digital Service Delivery</title>
      <link>https://arxiv.org/abs/2409.05869</link>
      <description>arXiv:2409.05869v1 Announce Type: new 
Abstract: We present a case study of Process Mining (PM) for personnel security screening in the Canadian government. We consider customer (process time) and organizational (cost) perspectives. Furthermore, in contrast to most published case studies, we assess the full process improvement lifecycle: pre-intervention analyses pointed out initial bottlenecks, and post-intervention analyses identified the intervention impact and remaining areas for improvement. Using PM techniques, we identified frequent exceptional scenarios (e.g., applications requiring amendment), time-intensive loops (e.g., employees forgetting tasks), and resource allocation issues (e.g., involvement of non-security personnel). Subsequent process improvement interventions, implemented using a flexible low-code digital platform, reduced security briefing times from around 7 days to 46 hours, and overall process time from around 31 days to 26 days, on average. From a cost perspective, the involvement of hiring managers and security screening officers was significantly reduced. These results demonstrate how PM can become part of a broader digital transformation framework to improve public service delivery. The success of these interventions motivated subsequent government PM projects, and inspired a PM methodology, currently under development, for use in large organizational contexts such as governments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.05869v1</guid>
      <category>cs.CY</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jacques Trottier, William Van Woensel, Xiaoyang Wang, Kavya Mallur, Najah El-Gharib, Daniel Amyot</dc:creator>
    </item>
    <item>
      <title>Exploring and Visualizing COVID-19 Trends in India: Vulnerabilities and Mitigation Strategies</title>
      <link>https://arxiv.org/abs/2409.05876</link>
      <description>arXiv:2409.05876v1 Announce Type: new 
Abstract: Visualizing data plays a pivotal role in portraying important scientific information. Hence, visualization techniques aid in displaying relevant graphical interpretations from the varied structures of data, which is found otherwise. In this paper, we explore the COVID-19 pandemic influence trends in the subcontinent of India in the context of how far the infection rate spiked in the year 2020 and how the public health division of the country India has helped to curb the spread of the novel virus by installing vaccination centers across the diaspora of the country. The paper contributes to the empirical study of understanding the impact caused by the novel virus to the country by doing extensive explanatory data analysis of the data collected from the official government portal. Our work contributes to the understanding that data visualization is prime in understanding public health problems and beyond and taking necessary measures to curb the existing pandemic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.05876v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Swayamjit Saha, Kuntal Ghosh, Garga Chatterjee, J. Edward Swan II</dc:creator>
    </item>
    <item>
      <title>Integrating the Expected Future: Schedule Based Energy Forecasting</title>
      <link>https://arxiv.org/abs/2409.05884</link>
      <description>arXiv:2409.05884v1 Announce Type: new 
Abstract: Power grid operators depend on accurate and reliable energy forecasts, aiming to minimize cases of extreme errors, as these outliers are particularly challenging to manage during operation. Incorporating planning information -- such as known data about users' future behavior or scheduled events -- has the potential to significantly enhance the accuracy and specificity of forecasts. Although there have been attempts to integrate such expected future behavior, these efforts consistently rely on conventional regression models to process this information. These models often lack the flexibility and capability to effectively incorporate both dynamic, forward-looking contextual inputs and historical data. To address this challenge, we conceptualize this combined forecasting and regression challenge as a sequence-to-sequence modeling problem and demonstrate, with three distinct models, that our contextually enhanced transformer models excel in this task. By leveraging schedule-based contextual information from the Swiss railway traction network, our proposed method significantly improved the average forecasting accuracy of nationwide railway energy consumption. Specifically, enhancing the transformer models with contextual information resulted in an average reduction of mean absolute error by 40.6\% , whereas other state-of-the-art methods did not demonstrate any significant improvement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.05884v1</guid>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Raffael Theiler, Olga Fink</dc:creator>
    </item>
    <item>
      <title>Automating the Practice of Science -- Opportunities, Challenges, and Implications</title>
      <link>https://arxiv.org/abs/2409.05890</link>
      <description>arXiv:2409.05890v1 Announce Type: new 
Abstract: Automation transformed various aspects of our human civilization, revolutionizing industries and streamlining processes. In the domain of scientific inquiry, automated approaches emerged as powerful tools, holding promise for accelerating discovery, enhancing reproducibility, and overcoming the traditional impediments to scientific progress. This article evaluates the scope of automation within scientific practice and assesses recent approaches. Furthermore, it discusses different perspectives to the following questions: Where do the greatest opportunities lie for automation in scientific practice?; What are the current bottlenecks of automating scientific practice?; and What are significant ethical and practical consequences of automating scientific practice? By discussing the motivations behind automated science, analyzing the hurdles encountered, and examining its implications, this article invites researchers, policymakers, and stakeholders to navigate the rapidly evolving frontier of automated scientific practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.05890v1</guid>
      <category>cs.CY</category>
      <category>physics.soc-ph</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sebastian Musslick, Laura K. Bartlett, Suyog H. Chandramouli, Marina Dubova, Fernand Gobet, Thomas L. Griffiths, Jessica Hullman, Ross D. King, J. Nathan Kutz, Christopher G. Lucas, Suhas Mahesh, Franco Pestilli, Sabina J. Sloman, William R. Holmes</dc:creator>
    </item>
    <item>
      <title>Insuring Uninsurable Risks from AI: The State as Insurer of Last Resort</title>
      <link>https://arxiv.org/abs/2409.06672</link>
      <description>arXiv:2409.06672v1 Announce Type: new 
Abstract: Many experts believe that AI systems will sooner or later pose uninsurable risks, including existential risks. This creates an extreme judgment-proof problem: few if any parties can be held accountable ex post in the event of such a catastrophe. This paper proposes a novel solution: a government-provided, mandatory indemnification program for AI developers. The program uses risk-priced indemnity fees to induce socially optimal levels of care. Risk-estimates are determined by surveying experts, including indemnified developers. The Bayesian Truth Serum mechanism is employed to incent honest and effortful responses. Compared to alternatives, this approach arguably better leverages all private information, and provides a clearer signal to indemnified developers regarding what risks they must mitigate to lower their fees. It's recommended that collected fees be used to help fund the safety research developers need, employing a fund matching mechanism (Quadratic Financing) to induce an optimal supply of this public good. Under Quadratic Financing, safety research projects would compete for private contributions from developers, signaling how much each is to be supplemented with public funds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06672v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cristian Trout</dc:creator>
    </item>
    <item>
      <title>Liability and Insurance for Catastrophic Losses: the Nuclear Power Precedent and Lessons for AI</title>
      <link>https://arxiv.org/abs/2409.06673</link>
      <description>arXiv:2409.06673v1 Announce Type: new 
Abstract: As AI systems become more autonomous and capable, experts warn of them potentially causing catastrophic losses. Drawing on the successful precedent set by the nuclear power industry, this paper argues that developers of frontier AI models should be assigned limited, strict, and exclusive third party liability for harms resulting from Critical AI Occurrences (CAIOs) - events that cause or easily could have caused catastrophic losses. Mandatory insurance for CAIO liability is recommended to overcome developers' judgment-proofness, mitigate winner's curse dynamics, and leverage insurers' quasi-regulatory abilities. Based on theoretical arguments and observations from the analogous nuclear power context, insurers are expected to engage in a mix of causal risk-modeling, monitoring, lobbying for stricter regulation, and providing loss prevention guidance in the context of insuring against heavy-tail risks from AI. While not a substitute for regulation, clear liability assignment and mandatory insurance can help efficiently allocate resources to risk-modeling and safe design, facilitating future regulatory efforts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06673v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cristian Trout</dc:creator>
    </item>
    <item>
      <title>Privacy-Preserving Data Linkage Across Private and Public Datasets for Collaborative Agriculture Research</title>
      <link>https://arxiv.org/abs/2409.06069</link>
      <description>arXiv:2409.06069v1 Announce Type: cross 
Abstract: Digital agriculture leverages technology to enhance crop yield, disease resilience, and soil health, playing a critical role in agricultural research. However, it raises privacy concerns such as adverse pricing, price discrimination, higher insurance costs, and manipulation of resources, deterring farm operators from sharing data due to potential misuse. This study introduces a privacy-preserving framework that addresses these risks while allowing secure data sharing for digital agriculture. Our framework enables comprehensive data analysis while protecting privacy. It allows stakeholders to harness research-driven policies that link public and private datasets. The proposed algorithm achieves this by: (1) identifying similar farmers based on private datasets, (2) providing aggregate information like time and location, (3) determining trends in price and product availability, and (4) correlating trends with public policy data, such as food insecurity statistics. We validate the framework with real-world Farmer's Market datasets, demonstrating its efficacy through machine learning models trained on linked privacy-preserved data. The results support policymakers and researchers in addressing food insecurity and pricing issues. This work significantly contributes to digital agriculture by providing a secure method for integrating and analyzing data, driving advancements in agricultural technology and development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06069v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Osama Zafar, Rosemarie Santa Gonzalez, Gabriel Wilkins, Alfonso Morales, Erman Ayday</dc:creator>
    </item>
    <item>
      <title>Can Large Language Models Unlock Novel Scientific Research Ideas?</title>
      <link>https://arxiv.org/abs/2409.06185</link>
      <description>arXiv:2409.06185v1 Announce Type: cross 
Abstract: "An idea is nothing more nor less than a new combination of old elements" (Young, J.W.). The widespread adoption of Large Language Models (LLMs) and publicly available ChatGPT have marked a significant turning point in the integration of Artificial Intelligence (AI) into people's everyday lives. This study explores the capability of LLMs in generating novel research ideas based on information from research papers. We conduct a thorough examination of 4 LLMs in five domains (e.g., Chemistry, Computer, Economics, Medical, and Physics). We found that the future research ideas generated by Claude-2 and GPT-4 are more aligned with the author's perspective than GPT-3.5 and Gemini. We also found that Claude-2 generates more diverse future research ideas than GPT-4, GPT-3.5, and Gemini 1.0. We further performed a human evaluation of the novelty, relevancy, and feasibility of the generated future research ideas. This investigation offers insights into the evolving role of LLMs in idea generation, highlighting both its capability and limitations. Our work contributes to the ongoing efforts in evaluating and utilizing language models for generating future research ideas. We make our datasets and codes publicly available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06185v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sandeep Kumar, Tirthankar Ghosal, Vinayak Goyal, Asif Ekbal</dc:creator>
    </item>
    <item>
      <title>Watching TV with the Second-Party: A First Look at Automatic Content Recognition Tracking in Smart TVs</title>
      <link>https://arxiv.org/abs/2409.06203</link>
      <description>arXiv:2409.06203v1 Announce Type: cross 
Abstract: Smart TVs implement a unique tracking approach called Automatic Content Recognition (ACR) to profile viewing activity of their users. ACR is a Shazam-like technology that works by periodically capturing the content displayed on a TV's screen and matching it against a content library to detect what content is being displayed at any given point in time. While prior research has investigated third-party tracking in the smart TV ecosystem, it has not looked into second-party ACR tracking that is directly conducted by the smart TV platform. In this work, we conduct a black-box audit of ACR network traffic between ACR clients on the smart TV and ACR servers. We use our auditing approach to systematically investigate whether (1) ACR tracking is agnostic to how a user watches TV (e.g., linear vs. streaming vs. HDMI), (2) privacy controls offered by smart TVs have an impact on ACR tracking, and (3) there are any differences in ACR tracking between the UK and the US. We perform a series of experiments on two major smart TV platforms: Samsung and LG. Our results show that ACR works even when the smart TV is used as a "dumb" external display, opting-out stops network traffic to ACR servers, and there are differences in how ACR works across the UK and the US.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06203v1</guid>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <category>cs.NI</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gianluca Anselmi, Yash Vekaria, Alexander D'Souza, Patricia Callejo, Anna Maria Mandalari, Zubair Shafiq</dc:creator>
    </item>
    <item>
      <title>"The struggle is a part of the experience": Engaging Discontents in the Design of Family Meal Technologies</title>
      <link>https://arxiv.org/abs/2409.06627</link>
      <description>arXiv:2409.06627v1 Announce Type: cross 
Abstract: Meals are a central (and messy) part of family life. Previous design framings for mealtime technologies have focused on supporting dietary needs or social and celebratory interactions at the dinner table; however, family meals involve the coordination of many activities and complicated family dynamics. In this paper, we report on findings from interviews and design sessions with 18 families from the Midwestern United States (including both partners/parents and children) to uncover important family differences and tensions that arise around domestic meal experiences. Drawing on feminist theory, we unpack the work of feeding a family as a form of care, drawing attention to the social and emotional complexity of family meals. Critically situating our data within current design narratives, we propose the sensitizing concepts of generative and systemic discontents as a productive way towards troubling the design space of family-food interaction to contend with the struggles that are a part of everyday family meal experiences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06627v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3687016</arxiv:DOI>
      <arxiv:journal_reference>Proc. ACM Hum.-Comput. Interact 8, CSCW2, Article 477 (November 2024), 33 pages</arxiv:journal_reference>
      <dc:creator>Yuxing Wu, Andrew D Miller, Chia-Fang Chung, Elizabeth Kaziunas</dc:creator>
    </item>
    <item>
      <title>Designing Resource Allocation Tools to Promote Fair Allocation: Do Visualization and Information Framing Matter?</title>
      <link>https://arxiv.org/abs/2409.06688</link>
      <description>arXiv:2409.06688v1 Announce Type: cross 
Abstract: Studies on human decision-making focused on humanitarian aid have found that cognitive biases can hinder the fair allocation of resources. However, few HCI and Information Visualization studies have explored ways to overcome those cognitive biases. This work investigates whether the design of interactive resource allocation tools can help to promote allocation fairness. We specifically study the effect of presentation format (using text or visualization) and a specific framing strategy (showing resources allocated to groups or individuals). In our three crowdsourced experiments, we provided different tool designs to split money between two fictional programs that benefit two distinct communities. Our main finding indicates that individual-framed visualizations and text may be able to curb unfair allocations caused by group-framed designs. This work opens new perspectives that can motivate research on how interactive tools and visualizations can be engineered to combat cognitive biases that lead to inequitable decisions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06688v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3544548.3580739</arxiv:DOI>
      <arxiv:journal_reference>Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems, pp. 1-16. 2023</arxiv:journal_reference>
      <dc:creator>Arnav Verma, Luiz Morais, Pierre Dragicevic, Fanny Chevalier</dc:creator>
    </item>
    <item>
      <title>Particip-AI: A Democratic Surveying Framework for Anticipating Future AI Use Cases, Harms and Benefits</title>
      <link>https://arxiv.org/abs/2403.14791</link>
      <description>arXiv:2403.14791v4 Announce Type: replace 
Abstract: General purpose AI, such as ChatGPT, seems to have lowered the barriers for the public to use AI and harness its power. However, the governance and development of AI still remain in the hands of a few, and the pace of development is accelerating without a comprehensive assessment of risks. As a first step towards democratic risk assessment and design of general purpose AI, we introduce PARTICIP-AI, a carefully designed framework for laypeople to speculate and assess AI use cases and their impacts. Our framework allows us to study more nuanced and detailed public opinions on AI through collecting use cases, surfacing diverse harms through risk assessment under alternate scenarios (i.e., developing and not developing a use case), and illuminating tensions over AI development through making a concluding choice on its development. To showcase the promise of our framework towards informing democratic AI development, we run a medium-scale study with inputs from 295 demographically diverse participants. Our analyses show that participants' responses emphasize applications for personal life and society, contrasting with most current AI development's business focus. We also surface diverse set of envisioned harms such as distrust in AI and institutions, complementary to those defined by experts. Furthermore, we found that perceived impact of not developing use cases significantly predicted participants' judgements of whether AI use cases should be developed, and highlighted lay users' concerns of techno-solutionism. We conclude with a discussion on how frameworks like PARTICIP-AI can further guide democratic AI development and governance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14791v4</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jimin Mun, Liwei Jiang, Jenny Liang, Inyoung Cheong, Nicole DeCario, Yejin Choi, Tadayoshi Kohno, Maarten Sap</dc:creator>
    </item>
    <item>
      <title>Past, Present, and Future of Citation Practices in HCI</title>
      <link>https://arxiv.org/abs/2405.16526</link>
      <description>arXiv:2405.16526v4 Announce Type: replace-cross 
Abstract: Science is a complex system comprised of many scientists who individually make collective decisions that, due to the size and nature of the academic system, largely do not affect the system as a whole. However, certain decisions at the meso-level of research communities, such as the Human-Computer Interaction (HCI) community, may result in deep and long-lasting behavioral changes in scientists. In this article, we provide evidence on how a change in editorial policies introduced at the ACM CHI Conference in 2016 launched the CHI community on an expansive path, denoted by a year-by-year increase in the mean number of references included in CHI articles. If this near-linear trend continues undisrupted, an article in CHI 2030 will include on average almost 130 references. The trend towards more citations reflects a citation culture where quantity is prioritized over quality, contributing to both author and peer reviewer fatigue. This article underscores the profound impact that meso-level policy adjustments have on the evolution of scientific fields and disciplines, urging stakeholders to carefully consider the broader implications of such changes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16526v4</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <category>cs.DL</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonas Oppenlaender</dc:creator>
    </item>
  </channel>
</rss>
