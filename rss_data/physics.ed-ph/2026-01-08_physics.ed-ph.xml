<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.ed-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.ed-ph</link>
    <description>physics.ed-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.ed-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 08 Jan 2026 05:00:31 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Feedback Indices to Evaluate LLM Responses to Rebuttals for Multiple Choice Type Questions</title>
      <link>https://arxiv.org/abs/2601.03285</link>
      <description>arXiv:2601.03285v1 Announce Type: new 
Abstract: We present a systematic framework of indices designed to characterize Large Language Model (LLM) responses when challenged with rebuttals during a chat. Assessing how LLMs respond to user dissent is crucial for understanding their reliability and behavior patterns, yet the complexity of human-LLM interactions makes systematic evaluation challenging. Our approach employs a fictitious-response rebuttal method that quantifies LLM behavior when presented with multiple-choice questions followed by deliberate challenges to their fictitious previous response. The indices are specifically designed to detect and measure what could be characterized as sycophantic behavior (excessive agreement with user challenges) or stubborn responses (rigid adherence to the fictitious response in the chat history) from LLMs. These metrics allow investigation of the relationships between sycophancy, stubbornness, and the model's actual mastery of the subject matter. We demonstrate the utility of these indices using two physics problems as test scenarios with various OpenAI models. The framework is intentionally generalizable to any multiple-choice format question, including on topics without universally accepted correct answers. Our results reveal measurable differences across OpenAI model generations, with trends indicating that newer models and those employing greater "Reasoning Effort" exhibit reduced sycophantic behavior. The FR pairing method combined with our proposed indices provides a practical, adaptable toolkit for systematically comparing LLM dialogue behaviors across different models and contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03285v1</guid>
      <category>physics.ed-ph</category>
      <category>cs.AI</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Justin C. Dunlap, Anne-Simone Parent, Ralf Widenhorn</dc:creator>
    </item>
    <item>
      <title>Visualizing Mathieu-Type Dynamics in a Tabletop Magnetic Trap: A Coil-Driven Parametric Oscillator</title>
      <link>https://arxiv.org/abs/2601.03409</link>
      <description>arXiv:2601.03409v1 Announce Type: cross 
Abstract: We present a tabletop demonstration of dynamic stabilization and ponderomotive-like trapping using a pair of sinusoidally-driven anti-Helmholtz coils and a suspended permanent magnet. The oscillating field produces a rapid micromotion superimposed on a slower secular oscillation, with micromotion amplitude increasing with displacement and peaking near the turning points. This behavior reveals a ponderomotive-like mechanism: a spatial gradient of micromotion amplitude that drives slow secular motion. The time-averaged effect provides a time-averaged harmonic (ponderomotive) restoring force that confines the magnet between the coils. Driving at 12-18 Hz places the system in a small-q regime where the two time scales are clearly separated and directly visible to the eye. Video tracking (included with this article) quantifies the motion and reveals a stability edge as the drive frequency is lowered (near 6-7 Hz in our apparatus). From trajectories in the 12-18 Hz range, we extract an effective Mathieu parameter q ~ 0.16 from the measured timescale separation of the secular versus drive frequencies. The apparatus uses inexpensive, readily available parts, and we provide a concise materials list, analysis code, field-gradient calibration data, and demonstration videos.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03409v1</guid>
      <category>physics.atom-ph</category>
      <category>physics.app-ph</category>
      <category>physics.ed-ph</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>William Ho, Anna Klales, Daniel Davis, Jieping Fan, Robert Hart, Ali Kurmus, Louis Deslauriers</dc:creator>
    </item>
    <item>
      <title>A Minimal Thermo-Fluid Model for Pressure-Driven Extraction in a Moka Pot</title>
      <link>https://arxiv.org/abs/2601.03663</link>
      <description>arXiv:2601.03663v1 Announce Type: cross 
Abstract: The moka pot provides a familiar example of a thermally driven flow system in which heating, vapor pressure generation, and fluid extraction are strongly coupled. We present a minimal, dimensionless dynamical model describing the evolution of temperature, pressure, and extracted volume during moka pot brewing. The model consists of a small set of coupled ordinary differential equations incorporating constant heating, heat loss, vapor pressure buildup, and pressure-driven flow through the coffee bed. The heating stage of the model is quantitatively compared with published experimental temperature time data, allowing the characteristic thermal timescale to be fixed independently. Using the experimentally constrained temperature evolution as input, the model predicts the pressure rise and identifies the onset of extraction without additional fitting parameters. Despite its simplicity, the model exhibits several qualitatively distinct extraction regimes, including delayed onset of flow, smooth extraction, and rapid extraction driven by nonlinear feedback between temperature and pressure. These regimes are governed by a small number of dimensionless parameters with clear physical interpretation. Rather than providing detailed quantitative predictions for specific devices, the model is intended as a transparent pedagogical framework for illustrating how physicists construct, simplify, and test coupled thermo-fluid models using experimentally accessible data in an everyday physical system in an everyday physical context.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03663v1</guid>
      <category>physics.flu-dyn</category>
      <category>physics.ed-ph</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Syahril Siregar</dc:creator>
    </item>
    <item>
      <title>Dissecting Physics Reasoning in Small Language Models: A Multi-Dimensional Analysis from an Educational Perspective</title>
      <link>https://arxiv.org/abs/2505.20707</link>
      <description>arXiv:2505.20707v2 Announce Type: replace-cross 
Abstract: Small Language Models (SLMs) offer privacy and efficiency for educational deployment, yet their utility depends on reliable multistep reasoning. Existing benchmarks often prioritize final answer accuracy, obscuring 'right answer, wrong procedure' failures that can reinforce student misconceptions. This work investigates SLM physics reasoning reliability, stage wise failure modes, and robustness under paired contextual variants. We introduce Physbench, comprising of 3,162 high school and AP level physics questions derived from OpenStax in a structured reference solution format with Bloom's Taxonomy annotations, plus 2,700 paired culturally contextualized variants. Using P-REFS, a stage wise evaluation rubric, we assess 10 SLMs across 58,000 responses. Results reveal substantial reliability gap: among final answer correct solutions, 75 to 98% contain at least one reasoning error. Failure modes shift with model capability; weaker models fail primarily at interpretation or modeling while stronger models often fail during execution. Paired contextual variations have minimal impact on top models but degrade the performance of mid-tier models. These findings demonstrate that safe educational AI requires evaluation paradigms that prioritize reasoning fidelity over final-answer correctness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20707v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>physics.ed-ph</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Nicy Scaria, Silvester John Joseph Kennedy, Krishna Agarwal, Diksha Seth, Deepak Subramani</dc:creator>
    </item>
  </channel>
</rss>
