<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>astro-ph.IM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/astro-ph.IM</link>
    <description>astro-ph.IM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/astro-ph.IM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 05 Jun 2024 01:55:20 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 04 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Optimizing Photometric Light Curve Analysis: Evaluating Scipy's Minimize Function for Eclipse Mapping of Cataclysmic Variables</title>
      <link>https://arxiv.org/abs/2406.00071</link>
      <description>arXiv:2406.00071v1 Announce Type: new 
Abstract: With a particular focus on Scipy's minimize function the eclipse mapping method is thoroughly researched and implemented utilizing Python and essential libraries. Many optimization techniques are used, including Sequential Least Squares Programming (SLSQP), Nelder-Mead, and Conjugate Gradient (CG). However, for the purpose of examining photometric light curves these methods seek to solve the maximum entropy equation under a chi-squared constraint. Therefore, these techniques are first evaluated on two-dimensional Gaussian data without a chi-squared restriction, and then they are used to map the accretion disc and uncover the Gaussian structure of the Cataclysmic Variable KIC 201325107. Critical analysis is performed on the code structure to find possible faults and design problems. Additionally, the analysis shows how several factors impacting computing time and image quality are included including the variance in Gaussian weighting, disc image resolution, number of data points in the light curve, and degree of constraint.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00071v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.SR</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.52783/jes.4079</arxiv:DOI>
      <dc:creator>Anoop Kumar, Madan Mohan Tito Ayyalasomayajula, Dheerendra Panwar, Yeshwanth Vasa</dc:creator>
    </item>
    <item>
      <title>DECam Multi-Messenger Astrophysics Pipeline. I. from Raw Data to Single-Exposure Candidates</title>
      <link>https://arxiv.org/abs/2406.00110</link>
      <description>arXiv:2406.00110v1 Announce Type: new 
Abstract: We introduce a pipeline that performs rapid image subtraction and source selection to detect transients, with a focus on identifying gravitational wave optical counterparts using the Dark Energy Camera (DECam). In this work, we present the pipeline steps from processing raw data to identification of astrophysical transients on individual exposures. We process DECam data and build difference images using the Vera C. Rubin Observatory Legacy Survey of Space and Time (LSST) Science Pipelines software, and we use flags and principal component analysis to select transients on a per-exposure basis, without associating the results from different exposures. Those candidates will be sent to brokers for further classification and alert distribution. We validate our pipeline using archival exposures that cover various types of objects, and the tested targets include a kilonova (GW170817), supernovae, stellar flares, variable stars (in a resolved galaxy or the Milky Way Bulge), and serendipitous objects. Overall, the data processing produces clean light curves that are comparable with published results, demonstrating the photometric quality of our pipeline. Real transients can be well selected by our pipeline when sufficiently bright (S/N $\gtrsim15$). This pipeline is intended to serve as a tool for the broader research community. Although this pipeline is designed for DECam, our method can be easily applied to other instruments and future LSST observations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00110v1</guid>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shenming Fu, Thomas Matheson, Aaron Meisner, Yuanyuan Zhang, Sebasti\'an Vicencio, Destry Saul</dc:creator>
    </item>
    <item>
      <title>Cassiop\'ee, towards technological development for XAO on ELT: the e-APD infrared detector</title>
      <link>https://arxiv.org/abs/2406.00547</link>
      <description>arXiv:2406.00547v1 Announce Type: new 
Abstract: The Cassiop\'ee project aims to develop the key technologies that will be used to deploy very high-performance Adaptive Optics for future ELTs. The ultimate challenge is to detect earth-like planets and characterize the composition of their atmosphere. For this, imaging contrasts of the order of 109 are required, implying a leap forward in adaptive optics performance, with high density deformable mirrors (120x120 actuators), low-noise cameras and the control of the loop at few kHz. The project brings together 2 industrial partners: First Light Imaging and ALPAO, and 2 academic partners: ONERA and LAM, who will work together to develop a new camera for wavefront sensing, a new deformable mirror and their implementation in an adaptive optics loop. This paper will present the development of the fast large infrared e-APD camera which will be used in the wavefront sensor of the system. The camera will integrate the latest 512x512 Leonardo e-APD array and will benefit from the heritage of the first-light imaging's C-RED One camera. The most important challenges for the application are the autonomous operation, vibration control, background limitation, compactness, acquisition speed and latency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00547v1</guid>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jean-Luc Gach, Piero Bruno, Julien Charton, Philippe Feautrier, Thierry Fusco, Benoit Neichel, Jean-Fran\c{c}ois Sauvage</dc:creator>
    </item>
    <item>
      <title>Modeling the refractive index profile n(z) of polar ice for ultra-high energy neutrino experiments</title>
      <link>https://arxiv.org/abs/2406.00857</link>
      <description>arXiv:2406.00857v1 Announce Type: new 
Abstract: We develop an in-situ index of refraction profile using the transit time of radio signals broadcast from an englacial transmitter to 2-5 km distant radio-frequency receivers, deployed at depths up to 200 m. Maxwell's equations generally admit two ray propagation solutions from a given transmitter, corresponding to a direct path (D) and a refracted path (R); the measured D vs. R (dt(D,R)) timing differences provide constraints on the index of refraction profile near South Pole, where the Askaryan Radio Array (ARA) neutrino observatory is located. We constrain the refractive index profile by simulating D and R ray paths via ray tracing and comparing those to measured dt(D,R) signals. Using previous ice density data as a proxy for n(z), we demonstrate that our data strongly favors a glaciologically-motivated three-phase densification model rather than a single exponential scale height model. Simulations show that the single exponential model overestimates ARA neutrino sensitivity compared to the three-phase model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00857v1</guid>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>S. Ali, P. Allison, S. Archambault, J. J. Beatty, D. Z. Besson, A. Bishop, P. Chen, Y. C. Chen, B. A. Clark, W. Clay, A. Connolly, K. Couberly, L. Cremonesi, A. Cummings, P. Dasgupta, R. Debolt, S. de Kockere, K. D. de Vries, C. Deaconu, M. A. DuVernois, J. Flaherty, E. Friedman, R. Gaior, P. Giri, J. Hanson, N. Harty, K. D. Hoffman, J. J. Huang, M. -H. Huang, K. Hughes, A. Ishihara, A. Karle, J. L. Kelley, K. -C. Kim, M. -C. Kim, I. Kravchenko, R. Krebs, C. Y. Kuo, K. Kurusu, U. A. Latif, C. H Liu, T. C. Liu, W. Luszczak, K. Mase, M. S. Muzio, J. Nam, R. J. Nichol, A. Novikov, A. Nozdrina, E. Oberla, Y. Pan, C. Pfendner, N. Punsuebsay, J. Roth, A. Salcedo-Gomez, D. Seckel, M. F. H. Seikh, Y. -S. Shaio, D. Smith, S. Toscano, J. Torres, J. Touart, N. van Eijndhoven, G. S. Varner, A. Vieregg, M. -Z. Wang, S. -H. Wang, S. A. Wissel, C. Xie, S. Yoshida, R. Young</dc:creator>
    </item>
    <item>
      <title>VERTECS: A COTS-based payload interface board to enable next generation astronomical imaging payloads</title>
      <link>https://arxiv.org/abs/2406.00935</link>
      <description>arXiv:2406.00935v1 Announce Type: new 
Abstract: Due to advances in observation and imaging technologies, modern astronomical satellites generate large volumes of data. This necessitates efficient onboard data processing and high-speed data downlink. Reflecting this trend is the VERTECS 6U Astronomical Nanosatellite. Designed for the observation of Extragalactic Background Light (EBL), this mission is expected to generate a substantial amount of image data, particularly within the confines of CubeSat capabilities. This paper introduces the VERTECS Camera Control Board (CCB), an open-source payload interface board leveraging Commercial Off-The-Shelf (COTS) components, with a Raspberry Pi Compute Module 4 at its core. The VERTECS CCB hardware and software have been designed from the ground up to serve as the sole interface between the VERTECS bus system and astronomical imaging payload, while providing compute capability not usually seen in nanosatellites of this class. Responsible for mission data processing, it will facilitate high-speed data transfer from the imaging payload via gigabit Ethernet, while also providing a high-bitrate serial connection to the payload X-band transmitter for mission data downlink. Additional interfaces for secondary payloads are provided via USB-C and standard 15-pin camera connectors. The Raspberry Pi embedded within the VERTECS CCB operates on a standard Linux distribution, streamlining the software development process. Beyond addressing the current mission's payload control and data handling requirements, the CCB sets the stage for future missions with heightened data demands. Furthermore, it supports the adoption of machine learning and other compute-intensive applications in orbit. This paper delves into the development of the VERTECS CCB, offering insights into the design and validation of this next-generation payload interface, to ensure that it can survive the rigors of space flight.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00935v1</guid>
      <category>astro-ph.IM</category>
      <category>cs.AR</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>physics.ins-det</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ezra Fielding, Victor H. Schulz, Keenan A. A. Chatar, Kei Sano, Akitoshi Hanazawa</dc:creator>
    </item>
    <item>
      <title>All-sky Guide Star Catalog for CSST</title>
      <link>https://arxiv.org/abs/2406.00972</link>
      <description>arXiv:2406.00972v1 Announce Type: new 
Abstract: The China Space Station Telescope (CSST) is a two-meter space telescope with multiple back-end instruments. The Fine Guidance Sensor (FGS) is an essential subsystem of the CSST Precision Image Stability System to ensure the required absolute pointing accuracy and line-of-sight stabilization. In this study, we construct the Main Guide Star Catalog for FGS. To accomplish this, we utilize the information about the FGS and object information from the Gaia Data Release 3. We provide an FGS instrument magnitude and exclude variables, binaries, and high proper motion stars from the catalog to ensure uniform FGS guidance capabilities. Subsequently, we generate a HEALPix index, which provides a hierarchical tessellation of the celestial sphere, and employ the Voronoi algorithm to achieve a homogeneous distribution of stars across the catalog. This distribution ensures adequate coverage and sampling of the sky. The performance of the CSST guide star catalog was assessed by simulating the field of view of the FGS according to the CSST mock survey strategy catalog. The analysis of the results indicates that this catalog provides adequate coverage and accuracy. The catalog's performance meets the FGS requirements, ensuring the functioning of the FGS and its guidance capabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00972v1</guid>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1088/1674-4527/ad26b6</arxiv:DOI>
      <dc:creator>Hui-Mei Feng, Zi-Huang Cao, Man I Lam, Ran Li, Hao Tian, Da-Yi Yin, Yuan-Yu Yang, Xin Zhang, Dong-Wei Fan, Yi-Qiao Dong, Xin-Feng Li, Wei Wang, Long Li, Hugh R. A. Jones, Yi-Han Tao, Jia-Lu Nie, Pei-Pei Wang, Mao-Yuan Liu, He-jun Yang, Chao Liu</dc:creator>
    </item>
    <item>
      <title>PolyCLEAN: When H\"ogbom meets Bayes -- Fast Super-Resolution Imaging with Bayesian MAP Estimation</title>
      <link>https://arxiv.org/abs/2406.01342</link>
      <description>arXiv:2406.01342v1 Announce Type: new 
Abstract: Aims: We address two issues for the adoption of convex optimization in radio interferometric imaging. First, a method for a fine resolution setup is proposed which scales naturally in terms of memory usage and reconstruction speed. Second, a new tool to localize a region of uncertainty is developed, paving the way for quantitative imaging in radio interferometry. Methods: The classical $\ell_1$ penalty is used to turn the inverse problem into a sparsity-promoting optimization. For efficient implementation, the so-called Frank-Wolfe algorithm is used together with a \textit{polyatomic} refinement. The algorithm naturally produces sparse images at each iteration, leveraged to reduce memory and computational requirements. In that regard, PolyCLEAN reproduces the numerical behavior of CLEAN while guaranteeing that it solves the minimization problem of interest. Additionally, we introduce the dual certificate image, which appears as a numerical byproduct of the Frank-Wolfe algorithm. This image is proposed as a tool for uncertainty quantification on the location of the recovered sources. Results: PolyCLEAN demonstrates good scalability performance, in particular for fine-resolution grids. On simulations, the Python-based implementation is competitive with the fast numerically-optimized CLEAN solver. This acceleration does not affect image reconstruction quality: PolyCLEAN images are consistent with CLEAN-obtained ones for both point sources and diffuse emission recovery. We also highlight PolyCLEAN reconstruction capabilities on observed radio measurements. Conclusions: PolyCLEAN can be considered as an alternative to CLEAN in the radio interferometric imaging pipeline, as it enables the use of Bayesian priors without impacting the scalability and numerical performance of the imaging method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01342v1</guid>
      <category>astro-ph.IM</category>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Adrian Jarret, Sepand Kashani, Joan Ru\'e-Queralt, Paul Hurley, Julien Fageot, Matthieu Simeoni</dc:creator>
    </item>
    <item>
      <title>Knowledge Graph in Astronomical Research with Large Language Models: Quantifying Driving Forces in Interdisciplinary Scientific Discovery</title>
      <link>https://arxiv.org/abs/2406.01391</link>
      <description>arXiv:2406.01391v1 Announce Type: new 
Abstract: Identifying and predicting the factors that contribute to the success of interdisciplinary research is crucial for advancing scientific discovery. However, there is a lack of methods to quantify the integration of new ideas and technological advancements in astronomical research and how these new technologies drive further scientific breakthroughs. Large language models, with their ability to extract key concepts from vast literature beyond keyword searches, provide a new tool to quantify such processes. In this study, we extracted concepts in astronomical research from 297,807 publications between 1993 and 2024 using large language models, resulting in a set of 24,939 concepts. These concepts were then used to form a knowledge graph, where the link strength between any two concepts was determined by their relevance through the citation-reference relationships. By calculating this relevance across different time periods, we quantified the impact of numerical simulations and machine learning on astronomical research. The knowledge graph demonstrates two phases of development: a phase where the technology was integrated and another where the technology was explored in scientific discovery. The knowledge graph reveals that despite machine learning has made much inroad in astronomy, there is currently a lack of new concept development at the intersection of AI and Astronomy, which may be the current bottleneck preventing machine learning from further transforming the field of astronomy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01391v1</guid>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zechang Sun, Yuan-Sen Ting, Yaobo Liang, Nan Duan, Song Huang, Zheng Cai</dc:creator>
    </item>
    <item>
      <title>The High-Resolution Far- to Near-Infrared Anharmonic Absorption Spectra of Cyano-Substituted Polycyclic Aromatic Hydrocarbons from 300-6200 cm$^{-1}$</title>
      <link>https://arxiv.org/abs/2406.00088</link>
      <description>arXiv:2406.00088v1 Announce Type: cross 
Abstract: Cyano-substituted polycyclic aromatic hydrocarbons (CN-PAHs) may contribute to the emission detected in the 7 - 9 $\mu$m (1430 - 1100 cm$^{-1}$) and 11 - 15 $\mu$m (900 - 670 cm$^{-1}$) regions of astronomical IR spectra. Anharmonic quantum chemical computations of 17 CN-PAH isomers for 4 small PAHs and Benzene reveal strong, broad absorption features across the entire 300 - 6200 cm$^{-1}$ (33 - 1.6 $\mu$m) frequency range. In particular, when a FWHM of 15 cm$^{-1}$ is applied, the composite CN-PAH spectrum is almost indistinguishable from the unsubstituted-PAH spectrum. At high resolution, however, the infrared absorption spectra reveal unique, identifiable features of CN-PAHs in the 700 - 950, 1100 - 1300, 2000 - 2500, and 3400 - 3600 cm$^{-1}$ ranges. The in-plane and out-of-plane CH bending vibrational frequencies of CN-PAHs are shifted when comparing isomers and to their unsubstituted counterparts, making their differentiation in mixed laboratory experiments possible. The overall aromatic CH stretch fundamental (2950 - 3200 cm$^{-1}$) and first overtone (5950 - 6200 cm$^{-1}$) regions are relatively unaffected by the cyano-substitution, with changes only to the breadth and intensity of the bands. Detailed spectroscopic data on the normal mode components of each state reported herein provide the means to directly assign future laboratory spectra and to guide direct IR observations of astronomical regions with, e.g., JWST.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00088v1</guid>
      <category>astro-ph.GA</category>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Vincent J. Esposito, Ryan C. Fortenberry, Christiaan Boersma, Louis J. Allamandola</dc:creator>
    </item>
    <item>
      <title>Direct Imaging Detection of the Protoplanet AB Aurigae b at Wavelengths Covering Pa$\beta$: Rebuttal to Biddle et al. (2024)</title>
      <link>https://arxiv.org/abs/2406.00107</link>
      <description>arXiv:2406.00107v1 Announce Type: cross 
Abstract: Recently, Biddle et al. (2024) claimed a non-detection of the protoplanet AB Aurigae b in Keck/NIRC2 Pa$\beta$ imaging. I reprocess these newly-public data and compare them to data from the extreme AO platform (SCExAO/CHARIS) used to discover AB Aur b. AB Aur b is decisively imaged with SCExAO/CHARIS at wavelengths covering Pa$\beta$. The Biddle et al. non detection of AB Aur b results from a far poorer image quality that is non competitive with SCExAO/CHARIS. Their contrast limits and thus constraints on accretion are overestimated due to an inaccurate AB Aur b source model. Consequentially, the revised Pa$\beta$ 2-$\sigma$ upper limit from these data is about three times higher than previously reported. Irrespective of image quality, single-band Pa$\beta$ imaging is ill suited to conclusively identifying accretion onto AB Aur b. Instead, high-resolution H$\alpha$ spectroscopy may provide accretion signatures. Aside from PDS 70, AB Aurigae remains the system with the strongest evidence for having a directly-imaged protoplanet.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00107v1</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thayne Currie</dc:creator>
    </item>
    <item>
      <title>Accurate and Model Independent Radius Determination of Single FGK and M Dwarfs Using Gaia DR3 Data</title>
      <link>https://arxiv.org/abs/2406.00229</link>
      <description>arXiv:2406.00229v1 Announce Type: cross 
Abstract: Measuring fundamental stellar parameters is key to fully comprehending the evolution of stars. However, current theoretical models over-predict effective temperatures, and under-predict radii, compared to observations of K and M dwarfs (radius inflation problem). In this work, we developed a model independent method to infer precise radii of single FGK and M dwarfs using Gaia DR3 parallaxes and photometry, and we used it to study the radius inflation problem. We calibrated nine surface brightness-color relations for the three Gaia magnitudes and colors using a sample of stars with angular diameter measurements. We achieved an accuracy of 4% in our angular diameter estimations, which Gaia's parallaxes allow us to convert to a physical radii. We validated our method by comparing our radius measurements with literature samples and the Gaia DR3 catalog, which confirmed the accuracy of our method and revealed systematic offsets in the Gaia measurements. Moreover, we used a sample with measured Halpha equivalent width (HaEW), a magnetic activity indicator, to study the radius inflation problem. We demonstrated that active stars have larger radii than inactive stars, showing that radius inflation is correlated with magnetic activity. We found a correlation between the radius inflation of active stars and HaEW for the mass bin 0.5&lt;M[Msun]&lt;= 0.6, but we found no correlation for lower masses. This could be due to lack of precision in our radius estimation or a physical reason. Radius measurements with smaller uncertainties are necessary to distinguish between the two scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00229v1</guid>
      <category>astro-ph.SR</category>
      <category>astro-ph.EP</category>
      <category>astro-ph.GA</category>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rocio Kiman (California Institute of Technology, Kavli Institute for Theoretical Physics, University of California, Santa Barbara), Timothy D. Brandt (Space Telescope Science Institute, University of California, Santa Barbara), Jacqueline K. Faherty (American Museum of Natural History), Mark Popinchalk (American Museum of Natural History, Hunter College, City University of New York)</dc:creator>
    </item>
    <item>
      <title>Residual neural networks to classify the high frequency emission in core-collapse supernova gravitational waves</title>
      <link>https://arxiv.org/abs/2406.00422</link>
      <description>arXiv:2406.00422v1 Announce Type: cross 
Abstract: We present the results of a detailed study on the detectability of the High Frequency Feature (HFF) in core-collapse supernova (CCSN) gravitational wave (GW) signals. We applied Residual Neural Networks (ResNet50), one of the state-of-the-art deep learning architectures in computer vision, to perform a multi-class classification of image samples built from time-frequency Morlet wavelet scalograms of LIGO-Virgo noise plus CCSN GW signals. We consider three target labels for three consecutive and mutually exclusive intervals in which the (first-order) slope of the HFF can be located. We optimized, trained, and tested the ResNet50 model with phenomenological waveforms. Next, we tested the optimized ResNet50 model with GW signals from CCSN simulations. At galactic distances of $1$Kpc and $5$Kpc with H1 and L1 data and $1$Kpc with V1 data, we obtained highly accurate results (test accuracies from $0.8933$ to $0.9867$), which show the feasibility of our methodology. In the case of further distances, we observed declines in test performance until $0.8000$ with H1 and L1 data at $10$Kpc and until $0.5933$ with V1 data at $10$Kpc. Without assuming the continuity and/or discontinuity of the HFF slope values, our methodology is general enough to address, at an early stage, the characterization of the HFF.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00422v1</guid>
      <category>astro-ph.HE</category>
      <category>astro-ph.IM</category>
      <category>gr-qc</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Manuel D. Morales, Javier M. Antelis, Claudia Moreno</dc:creator>
    </item>
    <item>
      <title>Efficient Massive Black Hole Binary parameter estimation for LISA using Sequential Neural Likelihood</title>
      <link>https://arxiv.org/abs/2406.00565</link>
      <description>arXiv:2406.00565v1 Announce Type: cross 
Abstract: LISA (Laser Interferometer Space Antenna) is a space mission that has recently entered the implementation phase. The main goal of LISA is to survey, for the first time, the observable universe by detecting low-frequency gravitational waves (GWs). One of the main GW sources that LISA will detect is the coalescence and merger of Massive Black Hole Binaries (MBHBs). In this work, we explore the application of Sequential Neural Likelihood, a simulation-based inference algorithm, to the detection and parameter estimation of MBHBs signals in the LISA data. Instead of sampling from the conventional likelihood function, which typically relies on the assumptions of Gaussianity and stationarity of the noise and requires a forward simulation for each evaluation, this method constructs a surrogate likelihood that is ultimately described by a neural network trained from a dataset of simulations (noise + MBHB). Since the likelihood is independent of the priors, we can iteratively train models that target specific observations in a fraction of the time and computational cost that other traditional and machine learning-based strategies would require. One key aspect of the method is the compression of the data. Because of the iterative nature of the method, we are able to train models to obtain qualitatively similar posteriors with less than 2% of the simulator calls that Markov Chain Monte Carlo methods would require. We compare these posteriors with those obtained from standard techniques and discuss the differences that appear, some of which can be identified as caused by the loss of information from the data compression we use. We also discuss future improvements to this method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00565v1</guid>
      <category>gr-qc</category>
      <category>astro-ph.HE</category>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Iv\'an Mart\'in V\'ilchez, Carlos F. Sopuerta</dc:creator>
    </item>
    <item>
      <title>General relativistic self-gravitating equilibrium disks around rotating neutron stars</title>
      <link>https://arxiv.org/abs/2406.00945</link>
      <description>arXiv:2406.00945v1 Announce Type: cross 
Abstract: In modeling a relativistic disk around a compact object, the self-gravity of the disk is often neglected while it needs to be incorporated for more accurate descriptions in several circumstances. Extending the Komatsu-Eriguchi-Hachisu self-consistent field method, we present numerical models of a rapidly rotating neutron star with a self-gravitating disk in stationary equilibrium. In particular, our approach allows us to obtain numerical solutions involving a massive disk with the rest mass $O(10^{-1})-O(10^0) M_\odot$ closely attached to a rotating neutron star. We also assess the impact of self-gravity on the internal structure of the disk and the neutron star. These axisymmetric, stationary solutions can be employed for simulations involving the neutron star-disk system in the context of high-energy transients and gravitational wave emissions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00945v1</guid>
      <category>astro-ph.HE</category>
      <category>astro-ph.IM</category>
      <category>gr-qc</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yoonsoo Kim, Jinho Kim, Hee Il Kim, Hyung Mok Lee</dc:creator>
    </item>
    <item>
      <title>Advancements in Glitch Subtraction Systems for Enhancing Gravitational Wave Data Analysis: A Brief Review</title>
      <link>https://arxiv.org/abs/2406.01318</link>
      <description>arXiv:2406.01318v1 Announce Type: cross 
Abstract: Glitches are transitory noise artifacts that degrade the detection sensitivity and accuracy of interferometric observatories such as LIGO and Virgo in gravitational wave astronomy. Reliable glitch subtraction techniques are essential for separating genuine gravitational wave signals from background noise and improving the accuracy of astrophysical investigations. This review study summarizes the main glitch subtraction methods used in the industry. We talk about the efficacy of classic time-domain techniques in real-time applications, like matched filtering and regression methods. The robustness of frequency-domain approaches, such as wavelet transformations and spectral analysis, in detecting and mitigating non-stationary glitches is assessed. We also investigate sophisticated machine learning methods, demonstrating great potential in automatically identifying and eliminating intricate glitch patterns. We hope to provide a thorough understanding of these approaches' uses, difficulties, and potential for future development in gravitational wave data analysis by contrasting their advantages and disadvantages. Researchers looking to enhance glitch subtraction procedures and raise the accuracy of gravitational wave detections will find great value in this paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01318v1</guid>
      <category>gr-qc</category>
      <category>astro-ph.IM</category>
      <category>physics.space-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Abu Thaher Chowdhury</dc:creator>
    </item>
    <item>
      <title>The TEMPO Survey II: Science Cases Leveraged from a Proposed 30-Day Time Domain Survey of the Orion Nebula with the Nancy Grace Roman Space Telescope</title>
      <link>https://arxiv.org/abs/2406.01492</link>
      <description>arXiv:2406.01492v1 Announce Type: cross 
Abstract: The TEMPO (Transiting Exosatellites, Moons, and Planets in Orion) Survey is a proposed 30-day observational campaign using the Nancy Grace Roman Space Telescope. By providing deep, high-resolution, short-cadence infrared photometry of a dynamic star-forming region, TEMPO will investigate the demographics of exosatellites orbiting free-floating planets and brown dwarfs -- a largely unexplored discovery space. Here, we present the simulated detection yields of three populations: extrasolar moon analogs orbiting free-floating planets, exosatellites orbiting brown dwarfs, and exoplanets orbiting young stars. Additionally, we outline a comprehensive range of anticipated scientific outcomes accompanying such a survey. These science drivers include: obtaining observational constraints to test prevailing theories of moon, planet, and star formation; directly detecting widely separated exoplanets orbiting young stars; investigating the variability of young stars and brown dwarfs; constraining the low-mass end of the stellar initial mass function; constructing the distribution of dust in the Orion Nebula and mapping evolution in the near-infrared extinction law; mapping emission features that trace the shocked gas in the region; constructing a dynamical map of Orion members using proper motions; and searching for extragalactic sources and transients via deep extragalactic observations reaching a limiting magnitude of $m_{AB}=29.7$\,mag (F146 filter).</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01492v1</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <category>astro-ph.SR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Melinda Soares-Furtado, Mary Anne Limbach, Andrew Vanderburg, John Bally, Juliette Becker, Anna L. Rosen, Luke G. Bouma, Johanna M. Vos, Steve B. Howell, Thomas G. Beatty, William M. J. Best, Anne Marie Cody, Adam Distler, Elena D'Onghia, Ren\'e Heller, Brandon S. Hensley, Natalie R. Hinkel, Brian Jackson, Marina Kounkel, Adam Kraus, Andrew W. Mann, Nicholas T. Marston, Massimo Robberto, Joseph E. Rodriguez, Jason H. Steffen, Johanna K. Teske, Richard Townsend, Ricardo Yarza, Allison Youngblood</dc:creator>
    </item>
    <item>
      <title>Gradient Technique Theory: Tracing magnetic field and obtaining magnetic field strength</title>
      <link>https://arxiv.org/abs/2406.01545</link>
      <description>arXiv:2406.01545v1 Announce Type: cross 
Abstract: The gradient technique is a promising tool with theoretical foundations based on the fundamental properties of MHD turbulence and turbulent reconnection. Its various incarnations use spectroscopic, synchrotron, and intensity data to trace the magnetic field and measure the media magnetization in terms of Alfven Mach number. We provide an analytical theory of gradient measurements and quantify the effects of averaging gradients along the line of sight and over the plane of the sky. We derive analytical expressions that relate the properties of gradient distribution with the Alfven Mach number $M_A$. We show that these measurements can be combined with measures of sonic Mach number or line broadening to obtain the magnetic field strength. The corresponding technique has advantages to Davis-Chandrasekhar-Fermi way of obtaining the magnetic field strength.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01545v1</guid>
      <category>astro-ph.GA</category>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alex Lazarian, Ka Ho Yuen, Dmitri Pogosyan</dc:creator>
    </item>
    <item>
      <title>Impact of Bayesian Priors on the Inferred Masses of Quasi-Circular Intermediate-Mass Black Hole Binaries</title>
      <link>https://arxiv.org/abs/2309.01683</link>
      <description>arXiv:2309.01683v2 Announce Type: replace-cross 
Abstract: Observation of gravitational waves from inspiralling binary black holes has offered a unique opportunity to study the physical parameters of the component black holes. To infer these parameters, Bayesian methods are employed in conjunction with general relativistic waveform models that describe the source's inspiral, merger, and ringdown. The results depend not only on the accuracy of the waveform models but also on the underlying fiducial prior distribution used for the analysis. In particular, when the pre-merger phase of the signal is barely observable within the detectors' bandwidth, as is currently the case with intermediate-mass black hole binary signals in ground-based gravitational wave detectors, different prior assumptions can lead to different interpretations. In this study, we utilise the gravitational-wave inference library, $\texttt{Parallel Bilby}$, to evaluate the impact of mass prior choices on the parameter estimation of intermediate-mass black hole binary signals. While previous studies focused primarily on analysing event data, we offer a broader, more controlled study by using simulations. Our findings suggest that the posteriors in total mass, mass ratio and luminosity distance are contingent on the assumed mass prior distribution used during the inference process. This is especially true when the signal lacks sufficient pre-merger information and/or has inadequate power in the higher-order radiation multipoles. In conclusion, our study underscores the importance of thoroughly investigating similarly heavy events in current detector sensitivity using a diverse choice of priors. Absent such an approach, adopting a flat prior on the binary's redshifted total mass and mass ratio emerges as a reasonable choice, preventing biases in the detector-frame mass posteriors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.01683v2</guid>
      <category>gr-qc</category>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1103/PhysRevD.109.104031</arxiv:DOI>
      <dc:creator>Koustav Chandra, Archana Pai, Samson H. W. Leong, Juan Calder\'on Bustillo</dc:creator>
    </item>
    <item>
      <title>JWST-TST High Contrast: Achieving direct spectroscopy of faint substellar companions next to bright stars with the NIRSpec IFU</title>
      <link>https://arxiv.org/abs/2310.09902</link>
      <description>arXiv:2310.09902v2 Announce Type: replace-cross 
Abstract: The JWST NIRSpec integral field unit (IFU) presents a unique opportunity to observe directly imaged exoplanets from 3-5 um at moderate spectral resolution (R~2,700) and thereby better constrain the composition, disequilibrium chemistry, and cloud properties of their atmospheres. In this work, we present the first NIRSpec IFU high-contrast observations of a substellar companion that requires starlight suppression techniques. We develop specific data reduction strategies to study faint companions around bright stars, and assess the performance of NIRSpec at high contrast. First, we demonstrate an approach to forward model the companion signal and the starlight directly in the detector images, which mitigates the effects of NIRSpec's spatial undersampling. We demonstrate a sensitivity to planets that are 3e-6 fainter than their stars at 1'', or 3e-5 at 0.3''. Then, we implement a reference star point spread function (PSF) subtraction and a spectral extraction that does not require spatially and spectrally regularly sampled spectral cubes. This allows us to extract a moderate resolution (R~2,700) spectrum of the faint T-dwarf companion HD 19467 B from 2.9-5.2 um with signal-to-noise ratio (S/N)~10 per resolution element. Across this wavelength range, HD~19467~B has a flux ratio varying between 1e-5-1e-4 and a separation relative to its star of 1.6''. A companion paper by Hoch et al. more deeply analyzes the atmospheric properties of this companion based on the extracted spectrum. Using the methods developed here, NIRSpec's sensitivity may enable direct detection and spectral characterization of relatively old (~1 Gyr), cool (~250 K), and closely separated (~3-5 au) exoplanets that are less massive than Jupiter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.09902v2</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jean-Baptiste Ruffio, Marshall D. Perrin, Kielan K. W. Hoch, Jens Kammerer, Quinn M. Konopacky, Laurent Pueyo, Alex Madurowicz, Emily Rickman, Christopher A. Theissen, Shubh Agrawal, Alexandra Z. Greenbaum, Brittany E. Miles, Travis S. Barman, William O. Balmer, Jorge Llop-Sayson, Julien H. Girard, Isabel Rebollido, R\'emi Soummer, Natalie H. Allen, Jay Anderson, Charles A. Beichman, Andrea Bellini, Geoffrey Bryden, N\'estor Espinoza, Ana Glidden, Jingcheng Huang, Nikole K. Lewis, Mattia Libralato, Dana R. Louie, Sangmo Tony Sohn, Sara Seager, Roeland P. van der Marel, Hannah R. Wakeford, Laura L. Watkins, Marie Ygouf, C. Matt Mountai</dc:creator>
    </item>
    <item>
      <title>Global Analysis of LISA Data with Galactic Binaries and Massive Black Hole Binaries</title>
      <link>https://arxiv.org/abs/2403.15318</link>
      <description>arXiv:2403.15318v3 Announce Type: replace-cross 
Abstract: The Laser Interferometer Space Antenna (LISA) is a planned space-based observatory to measure gravitational waves in the millihertz frequency band. This frequency band is expected to be dominated by signals from millions of Galactic binaries and tens of merging massive black hole binaries. The LISA Data Challenge 2a is focused on robust signal extraction from a blend of these two types of gravitational wave signals. Here, we introduce a novel high performance and cost-effective global fit pipeline extracting and characterizing galactic binary and massive black hole binary signals and estimate the noise of the residual. We perform the pipeline in a time-evolving weekly analysis starting with an observation time of 1 week until we reach a full year. As expected we detect more galactic binaries and massive black hole binaries bringing the noise estimate of the residual closer to the instrument noise with each week of additional observation time. Furthermore, we present a novel maximum likelihood estimate-based algorithm for extracting multiple massive black hole binaries. Additionally, we demonstrate a massive black hole binary signal extraction with a more accurate LISA response, considering higher harmonic modes, in a noisy data set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15318v3</guid>
      <category>gr-qc</category>
      <category>astro-ph.HE</category>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stefan H. Strub, Luigi Ferraioli, C\'edric Schmelzbach, Simon C. St\"ahler, Domenico Giardini</dc:creator>
    </item>
    <item>
      <title>Physical Properties of Type II Supernovae Inferred from ZTF and ATLAS Photometric Data</title>
      <link>https://arxiv.org/abs/2404.12620</link>
      <description>arXiv:2404.12620v3 Announce Type: replace-cross 
Abstract: We report an analysis of a sample of 186 spectroscopically confirmed Type II supernova (SN) light curves (LCs) obtained from a combination of Zwicky Transient Facility (ZTF) and Asteroid Terrestrial-impact Last Alert System (ATLAS) observations. We implement a method to infer physical parameters from these LCs using hydrodynamic models that take into account the progenitor mass, the explosion energy, and the presence of circumstellar matter (CSM). The CSM is modelled via the mass loss rate, wind acceleration at the surface of the progenitor star with a $\beta$ velocity law, and the CSM radius. We also infer the time of explosion, attenuation (A$_V$), and the redshift for each SN. Our results favor low-mass progenitor stars (M$_{ZAMS}$\,$&lt;$14\,$M_\odot$) with a dense CSM ($\dot{M}$ $&gt;$ 10$^{-3}$ [M$_\odot$ yr$^{-1}$], a CSM radius of $\sim$ 10$^{15}$ cm, and $\beta$ $&gt;$ 2). Additionally, we find that the redshift inferred from the supernova LCs is significantly more accurate than that inferred using the host galaxy photometric redshift, suggesting that this method could be used to infer more accurate host galaxy redshifts from large samples of SNe II in the LSST era. Lastly, we compare our results with similar works from the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12620v3</guid>
      <category>astro-ph.HE</category>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Javier Silva-Farf\'an, Francisco F\"orster, Takashi J. Moriya, L. Hern\'andez-Garc\'ia, A. M. Mu\~noz Arancibia, P. S\'anchez-S\'aez, Joseph P. Anderson, John L. Tonry, Alejandro Clocchiatti</dc:creator>
    </item>
    <item>
      <title>Is machine learning good or bad for the natural sciences?</title>
      <link>https://arxiv.org/abs/2405.18095</link>
      <description>arXiv:2405.18095v2 Announce Type: replace-cross 
Abstract: Machine learning (ML) methods are having a huge impact across all of the sciences. However, ML has a strong ontology - in which only the data exist - and a strong epistemology - in which a model is considered good if it performs well on held-out training data. These philosophies are in strong conflict with both standard practices and key philosophies in the natural sciences. Here we identify some locations for ML in the natural sciences at which the ontology and epistemology are valuable. For example, when an expressive machine learning model is used in a causal inference to represent the effects of confounders, such as foregrounds, backgrounds, or instrument calibration parameters, the model capacity and loose philosophy of ML can make the results more trustworthy. We also show that there are contexts in which the introduction of ML introduces strong, unwanted statistical biases. For one, when ML models are used to emulate physical (or first-principles) simulations, they amplify confirmation biases. For another, when expressive regressions are used to label datasets, those labels cannot be used in downstream joint or ensemble analyses without taking on uncontrolled biases. The question in the title is being asked of all of the natural sciences; that is, we are calling on the scientific communities to take a step back and consider the role and value of ML in their fields; the (partial) answers we give here come from the particular perspective of physics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18095v2</guid>
      <category>stat.ML</category>
      <category>astro-ph.IM</category>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David W. Hogg (NYU, MPIA, Flatiron), Soledad Villar (JHU, Flatiron)</dc:creator>
    </item>
  </channel>
</rss>
