<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 20 Mar 2025 04:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>The Verification Problem for the Subgame Perfect Equilibrium and the Nash Equilibrium in Finite-Horizon Probabilistic Concurrent Game Systems</title>
      <link>https://arxiv.org/abs/2503.14690</link>
      <description>arXiv:2503.14690v1 Announce Type: new 
Abstract: Finite-horizon probabilistic multiagent concurrent game systems, also known as finite multiplayer stochastic games, are a well-studied model in artificial intelligence due to their ability to represent a wide range of real-world scenarios involving strategic interactions among agents over a finite amount of iterations (given by the finite-horizon). The analysis of these games typically focuses on evaluating and computing which strategy profiles (functions that represent the behavior of each agent) qualify as equilibria. The two most prominent equilibrium concepts are the \emph{Nash equilibrium} and the \emph{subgame perfect equilibrium}, with the latter considered a conceptual refinement of the former. However, computing these equilibria from scratch is often computationally infeasible. Therefore, recent attention has shifted to the verification problem, where a given strategy profile must be evaluated to determine whether it satisfies equilibrium conditions. In this paper, we demonstrate that the verification problem for subgame perfect equilibria lies in PSPACE, while for Nash equilibria, it is EXPTIME-complete. This is a highly counterintuitive result since the subgame equilibria are often seen as a strict strengthening of the Nash equilibrium and are intuitively seen as more complicated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14690v1</guid>
      <category>cs.GT</category>
      <category>cs.LO</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Senthil Rajasekaran, Moshe Y. Vardi</dc:creator>
    </item>
    <item>
      <title>Bribery for Coalitions in Parliamentary Elections</title>
      <link>https://arxiv.org/abs/2503.14707</link>
      <description>arXiv:2503.14707v1 Announce Type: new 
Abstract: We study the computational complexity of bribery in parliamentary voting, in settings where the briber is (also) interested in the success of an entire set of political parties - a ``coalition'' - rather than an individual party. We introduce two variants of the problem: the Coalition-Bribery Problem (CB) and the Coalition-Bribery-with-Preferred-party Problem (CBP). In CB, the goal is to maximize the total number of seats held by a coalition, while in CBP, there are two objectives: to maximize the votes for the preferred party, while also ensuring that the total number of seats held by the coalition is above the target support (e.g. majority).
  We study the complexity of these bribery problems under two positional scoring functions - Plurality and Borda - and for multiple bribery types - $1$-bribery, $\$$-bribery, swap-bribery, and coalition-shift-bribery. We also consider both the case where seats are only allotted to parties whose number of votes passes some minimum support level and the case with no such minimum. We provide polynomial-time algorithms to solve some of these problems and prove that the others are NP-hard.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14707v1</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hodaya Barr, Yonatan Aumann, Sarit Kraus</dc:creator>
    </item>
    <item>
      <title>Role-Selection Game in Block Production under Proposer-Builder Separation</title>
      <link>https://arxiv.org/abs/2503.15184</link>
      <description>arXiv:2503.15184v1 Announce Type: new 
Abstract: To address the risks of validator centralization, the Ethereum community introduced Proposer-Builder Separation (PBS), which divides the roles of block building and block proposing to foster a more equitable environment for blockchain participants. PBS creates a two-sided market, wherein searchers provide valuable bundles with bids to builders with the demand for their inclusion in a block, and builders vie for order flows from searchers to secure victory in the block-building auction. In this work, we propose a novel co-evolutionary framework to analyze the behavior of participants in the aforementioned two-sided market. Leveraging agent-based simulations enables us to observe the strategy evolution results of autonomous agents and understand how each profit-seeking actor can benefit from the block-building process under different market conditions. We observe that searchers and builders can develop distinct bidding and rebate strategies under varying conditions (conflict probabilities between bundles), with searchers learning to differentiate their bids based on the rebates offered by different builders. Through empirical game-theoretic analysis, we compute the dynamic equilibrium solution of agents' strategies under two meta-strategies, which predicts the frequency at which agents employ block building and bundle sharing strategies in the two-sided market. Our analysis reveals that agents achieve a dynamic equilibrium as searchers when the probability of conflict between bundles is low. As this conflict probability rises to a certain critical level, the dynamic equilibrium transitions to favor agents becoming builders.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15184v1</guid>
      <category>cs.GT</category>
      <category>cs.DC</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yanzhen Li, Zining Wang</dc:creator>
    </item>
    <item>
      <title>Playing against a stationary opponent</title>
      <link>https://arxiv.org/abs/2503.15346</link>
      <description>arXiv:2503.15346v1 Announce Type: new 
Abstract: This paper investigates properties of Blackwell $\epsilon$-optimal strategies in zero-sum stochastic games when the adversary is restricted to stationary strategies, motivated by applications to robust Markov decision processes. For a class of absorbing games, we show that Markovian Blackwell $\epsilon$-optimal strategies may fail to exist, yet we prove the existence of Blackwell $\epsilon$-optimal strategies that can be implemented by a two-state automaton whose internal transitions are independent of actions. For more general absorbing games, however, there need not exist Blackwell $\epsilon$-optimal strategies that are independent of the adversary's decisions. Our findings point to a contrast between absorbing games and generalized Big Match games, and provide new insights into the properties of optimal policies for robust Markov decision processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15346v1</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julien Grand-Cl\'ement, Nicolas Vieille</dc:creator>
    </item>
    <item>
      <title>More Information is Not Always Better: Connections between Zero-Sum Local Nash Equilibria in Feedback and Open-Loop Information Patterns</title>
      <link>https://arxiv.org/abs/2503.15486</link>
      <description>arXiv:2503.15486v1 Announce Type: new 
Abstract: Non-cooperative dynamic game theory provides a principled approach to modeling sequential decision-making among multiple noncommunicative agents. A key focus has been on finding Nash equilibria in two-agent zero-sum dynamic games under various information structures. A well-known result states that in linear-quadratic games, unique Nash equilibria under feedback and open-loop information structures yield identical trajectories. Motivated by two key perspectives -- (i) many real-world problems extend beyond linear-quadratic settings and lack unique equilibria, making only local Nash equilibria computable, and (ii) local open-loop Nash equilibria (OLNE) are easier to compute than local feedback Nash equilibria (FBNE) -- it is natural to ask whether a similar result holds for local equilibria in zero-sum games. To this end, we establish that for a broad class of zero-sum games with potentially nonconvex-nonconcave objectives and nonlinear dynamics: (i) the state/control trajectory of a local FBNE satisfies local OLNE first-order optimality conditions, and vice versa, (ii) a local FBNE trajectory satisfies local OLNE second-order necessary conditions, (iii) a local FBNE trajectory satisfying feedback sufficiency conditions also constitutes a local OLNE, and (iv) with additional hard constraints on agents' actuations, a local FBNE where strict complementarity holds also satisfies local OLNE first-order optimality conditions, and vice versa.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15486v1</guid>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kushagra Gupta, Ross Allen, David Fridovich-Keil, Ufuk Topcu</dc:creator>
    </item>
    <item>
      <title>A New Benchmark for Online Learning with Budget-Balancing Constraints</title>
      <link>https://arxiv.org/abs/2503.14796</link>
      <description>arXiv:2503.14796v1 Announce Type: cross 
Abstract: The adversarial Bandit with Knapsack problem is a multi-armed bandits problem with budget constraints and adversarial rewards and costs. In each round, a learner selects an action to take and observes the reward and cost of the selected action. The goal is to maximize the sum of rewards while satisfying the budget constraint. The classical benchmark to compare against is the best fixed distribution over actions that satisfies the budget constraint in expectation. Unlike its stochastic counterpart, where rewards and costs are drawn from some fixed distribution (Badanidiyuru et al., 2018), the adversarial BwK problem does not admit a no-regret algorithm for every problem instance due to the "spend-or-save" dilemma (Immorlica et al., 2022).
  A key problem left open by existing works is whether there exists a weaker but still meaningful benchmark to compare against such that no-regret learning is still possible. In this work, we present a new benchmark to compare against, motivated both by real-world applications such as autobidding and by its underlying mathematical structure. The benchmark is based on the Earth Mover's Distance (EMD), and we show that sublinear regret is attainable against any strategy whose spending pattern is within EMD $o(T^2)$ of any sub-pacing spending pattern.
  As a special case, we obtain results against the "pacing over windows" benchmark, where we partition time into disjoint windows of size $w$ and allow the benchmark strategies to choose a different distribution over actions for each window while satisfying a pacing budget constraint. Against this benchmark, our algorithm obtains a regret bound of $\tilde{O}(T/\sqrt{w}+\sqrt{wT})$. We also show a matching lower bound, proving the optimality of our algorithm in this important special case. In addition, we provide further evidence of the necessity of the EMD condition for obtaining a sublinear regret.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14796v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mark Braverman, Jingyi Liu, Jieming Mao, Jon Schneider, Eric Xue</dc:creator>
    </item>
    <item>
      <title>A Game of Pawns</title>
      <link>https://arxiv.org/abs/2305.04096</link>
      <description>arXiv:2305.04096v4 Announce Type: replace 
Abstract: We introduce and study pawn games, a class of two-player zero-sum turn-based graph games. A turn-based graph game proceeds by placing a token on an initial vertex, and whoever controls the vertex on which the token is located, chooses its next location. This leads to a path in the graph, which determines the winner. Traditionally, the control of vertices is predetermined and fixed. The novelty of pawn games is that control of vertices changes dynamically throughout the game as follows. Each vertex of a pawn game is owned by a pawn. In each turn, the pawns are partitioned between the two players, and the player who controls the pawn that owns the vertex on which the token is located, chooses the next location of the token. Control of pawns changes dynamically throughout the game according to a fixed mechanism. Specifically, we define several grabbing-based mechanisms in which control of at most one pawn transfers at the end of each turn. We study the complexity of solving pawn games, where we focus on reachability objectives and parameterize the problem by the mechanism that is being used and by restrictions on pawn ownership of vertices. On the positive side, even though pawn games are exponentially-succinct turn-based games, we identify several natural classes that can be solved in PTIME. On the negative side, we identify several EXPTIME-complete classes, where our hardness proofs are based on a new class of games called Lock &amp; Key games, which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.04096v4</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guy Avni, Pranav Ghorpade, Shibashis Guha</dc:creator>
    </item>
    <item>
      <title>Algorithmic Collusion And The Minimum Price Markov Game</title>
      <link>https://arxiv.org/abs/2407.03521</link>
      <description>arXiv:2407.03521v3 Announce Type: replace 
Abstract: This paper introduces the Minimum Price Markov Game (MPMG), a theoretical model that reasonably approximates real-world first-price markets following the minimum price rule, such as public auctions. The goal is to provide researchers and practitioners with a framework to study market fairness and regulation in both digitized and non-digitized public procurement processes, amid growing concerns about algorithmic collusion in online markets. Using multi-agent reinforcement learning-driven artificial agents, we demonstrate that (i) the MPMG is a reliable model for first-price market dynamics, (ii) the minimum price rule is generally resilient to non-engineered tacit coordination among rational actors, and (iii) when tacit coordination occurs, it relies heavily on self-reinforcing trends. These findings contribute to the ongoing debate about algorithmic pricing and its implications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03521v3</guid>
      <category>cs.GT</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Igor Sadoune, Marcelin Joanis, Andrea Lodi</dc:creator>
    </item>
    <item>
      <title>Learning to Negotiate via Voluntary Commitment</title>
      <link>https://arxiv.org/abs/2503.03866</link>
      <description>arXiv:2503.03866v2 Announce Type: replace-cross 
Abstract: The partial alignment and conflict of autonomous agents lead to mixed-motive scenarios in many real-world applications. However, agents may fail to cooperate in practice even when cooperation yields a better outcome. One well known reason for this failure comes from non-credible commitments. To facilitate commitments among agents for better cooperation, we define Markov Commitment Games (MCGs), a variant of commitment games, where agents can voluntarily commit to their proposed future plans. Based on MCGs, we propose a learnable commitment protocol via policy gradients. We further propose incentive-compatible learning to accelerate convergence to equilibria with better social welfare. Experimental results in challenging mixed-motive tasks demonstrate faster empirical convergence and higher returns for our method compared with its counterparts. Our code is available at https://github.com/shuhui-zhu/DCL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03866v2</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shuhui Zhu, Baoxiang Wang, Sriram Ganapathi Subramanian, Pascal Poupart</dc:creator>
    </item>
  </channel>
</rss>
