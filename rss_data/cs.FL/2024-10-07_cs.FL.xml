<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.FL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.FL</link>
    <description>cs.FL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.FL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 08 Oct 2024 04:01:38 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Non-deterministic asynchronous automata games and their undecidability</title>
      <link>https://arxiv.org/abs/2410.04420</link>
      <description>arXiv:2410.04420v1 Announce Type: new 
Abstract: We propose a new model of a distributed game, called an ATS game, which is played on a non-deterministic asynchronous transition system -- a natural distributed finite-state device working on Mazurkiewicz traces. This new partial-information game is played between an environment and a distributed system comprising multiple processes.
  A distributed strategy uses causal past to make the next move. The key algorithmic question is to solve the game, that is, to decide the existence of a distributed winning strategy.
  It turns out ATS games are equivalent to asynchronous games, which are known to be undecidable. We prove that ATS games are undecidable in this article.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04420v1</guid>
      <category>cs.FL</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bharat Adsul, Nehul Jain</dc:creator>
    </item>
    <item>
      <title>On the Complexity of Computing the Co-lexicographic Width of a Regular Language</title>
      <link>https://arxiv.org/abs/2410.04771</link>
      <description>arXiv:2410.04771v1 Announce Type: new 
Abstract: Co-lex partial orders were recently introduced in (Cotumaccio et al., SODA 2021 and JACM 2023) as a powerful tool to index finite state automata, with applications to regular expression matching. They generalize Wheeler orders (Gagie et al., Theoretical Computer Science 2017) and naturally reflect the co-lexicographic order of the strings labeling source-to-node paths in the automaton. Briefly, the co-lex width $p$ of a finite-state automaton measures how sortable its states are with respect to the co-lex order among the strings they accept. Automata of co-lex width $p$ can be compressed to $O(\log p)$ bits per edge and admit regular expression matching algorithms running in time proportional to $p^2$ per matched character.
  The deterministic co-lex width of a regular language $\mathcal L$ is the smallest width of such a co-lex order, among all DFAs recognizing $\mathcal L$. Since languages of small co-lex width admit efficient solutions to automata compression and pattern matching, computing the co-lex width of a language is relevant in these applications. The paper introducing co-lex orders determined that the deterministic co-lex width $p$ of a language $\mathcal L$ can be computed in time proportional to $m^{O(p)}$, given as input any DFA $\mathcal A$ for $\mathcal L$, of size (number of transitions) $m =|\mathcal A|$.
  In this paper, using new techniques, we show that it is possible to decide in $O(m^p)$ time if the deterministic co-lex width of the language recognized by a given minimum DFA is strictly smaller than some integer $p\ge 2$. We complement this upper bound with a matching conditional lower bound based on the Strong Exponential Time Hypothesis. The problem is known to be PSPACE-complete when the input is an NFA (D'Agostino et al., Theoretical Computer Science 2023); thus, together with that result, our paper essentially settles the complexity of the problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04771v1</guid>
      <category>cs.FL</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruben Becker, Davide Cenzato, Sung-Hwan Kim, Tomasz Kociumaka, Bojana Kodric, Alberto Policriti, Nicola Prezza</dc:creator>
    </item>
    <item>
      <title>Admissibility Over Winning: A New Approach to Reactive Synthesis in Robotics</title>
      <link>https://arxiv.org/abs/2410.04573</link>
      <description>arXiv:2410.04573v1 Announce Type: cross 
Abstract: Reactive synthesis is a framework for modeling and automatically synthesizing strategies in robotics, typically through computing a \emph{winning} strategy in a 2-player game between the robot and the environment. Winning strategies, however, do not always exist, even in some simple cases. In such situations, it is still desirable for the robot to attempt its task rather than "giving up". In this work, we explore the notion of admissibility to define strategies beyond winning, tailored specifically for robotic systems. We introduce an ordering of admissible strategies and define \emph{admissibly rational strategies}, which aim to be winning and cooperative when possible, and non-violating and hopeful when necessary. We present an efficient synthesis algorithm and demonstrate that admissibly rational strategies produce desirable behaviors through case studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04573v1</guid>
      <category>cs.RO</category>
      <category>cs.FL</category>
      <category>cs.GT</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Karan Muvvala, Morteza Lahijanian</dc:creator>
    </item>
    <item>
      <title>Equations in wreath products</title>
      <link>https://arxiv.org/abs/2410.04905</link>
      <description>arXiv:2410.04905v1 Announce Type: cross 
Abstract: We survey solvability of equations in wreath products of groups, and prove that the quadratic diophantine problem is solvable in wreath products of Abelian groups. We consider the related question of determining commutator width, and prove that the quadratic diophantine problem is also solvable in Baumslag's finitely presented metabelian group. This text is a short version of an extensive article by the first-named authors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04905v1</guid>
      <category>math.GR</category>
      <category>cs.FL</category>
      <category>math.LO</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Laurent Bartholdi, Ruiwen Dong, Leon Pernak, Jan Philipp W\"achter</dc:creator>
    </item>
    <item>
      <title>A Usage-Aware Sequent Calculus for Differential Dynamic Logic</title>
      <link>https://arxiv.org/abs/2309.01180</link>
      <description>arXiv:2309.01180v3 Announce Type: replace 
Abstract: Ensuring that safety-critical applications behave as intended is an important yet challenging task. Modeling languages like differential dynamic logic (dL) have proof calculi capable of proving guarantees for such applications. However, dL programmers may unintentionally over-specify assumptions and program statements, which results in overly constrained models that yield weak or vacuous guarantees. In hybrid systems models, such constraints are ubiquitous; they may appear as assumptions, conditions on control switches, and evolution domain constraints in systems of differential equations which makes it nontrivial to systematically detect which ones are over-specified. Existing approaches are limited, either lacking formal correctness guarantees or the granularity to detect all kinds of bugs arising in a given formula.
  As a remedy, we present a novel proof-based technique that detects which constraints in a dL formula are vacuous or over-specified and suggests ways in which these components could be mutated while preserving correctness proofs. When properties follow entirely from constraints uninfluenced by program statements, this analysis spots outright flaws in models. Otherwise, it helps make models more flexible by identifying specific ways in which they may be generalized. The resulting analysis is thorough, catching bugs at a fine-grained level and proposing mutations that could be applied in combination. We prove soundness and completeness with respect to dL to ensure the correctness of suggested mutations and general applicability of our technique.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.01180v3</guid>
      <category>cs.FL</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Myra Dotzel, Stefan Mitsch, Andr\'e Platzer</dc:creator>
    </item>
    <item>
      <title>Context-free graphs and their transition groups</title>
      <link>https://arxiv.org/abs/2408.13070</link>
      <description>arXiv:2408.13070v2 Announce Type: replace-cross 
Abstract: We define a new class of groups arising from context-free inverse graphs. We provide closure properties, prove that their co-word problems are context-free, study the torsion elements, and realize them as subgroups of the asynchronous rational group. Furthermore, we use a generalized version of the free product of graphs and prove that such a product is context-free inverse closed. We also exhibit an example of a group in our class that is not residually finite and one that is not poly-context-free. These properties make them interesting candidates to disprove both the Lehnert conjecture (which characterizes co-context-free groups as all subgroups of Thompson's group V) and the Brough conjecture (which characterizes finitely generated poly-context-free groups as virtual finitely generated subgroups of direct products of free groups).</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13070v2</guid>
      <category>math.GR</category>
      <category>cs.FL</category>
      <category>math.CO</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniele D'Angeli, Francesco Matucci, Davide Perego, Emanuele Rodaro</dc:creator>
    </item>
    <item>
      <title>Revisiting Weighted Information Extraction: A Simpler and Faster Algorithm for Ranked Enumeration</title>
      <link>https://arxiv.org/abs/2409.18563</link>
      <description>arXiv:2409.18563v2 Announce Type: replace-cross 
Abstract: Information extraction from textual data, where the query is represented by a finite transducer and the task is to enumerate all results without repetition, and its extension to the weighted case, where each output element has a weight and the output elements are to be enumerated sorted by their weights, are important and well studied problems in database theory. On the one hand, the first framework already covers the well-known case of regular document spanners, while the latter setting covers several practically relevant tasks that cannot be described in the unweighted setting.
  It is known that in the unweighted case this problem can be solved with linear time preprocessing $O(|D|)$ and output-linear delay $O(|s|)$ in data complexity, where $D$ is the input data and $s$ is the current output element. For the weighted case, Bourhis, Grez, Jachiet, and Riveros [ICDT 2021] recently designed an algorithm with linear time preprocessing, but the delay of $O(|s| \cdot \log|\mathsf{D}|)$ depends on the size of the data.
  We first show how to leverage the existing results on enumerating shortest paths to obtain a simple alternative algorithm with linear preprocessing and a delay of $O(|s_i| + \min\{ \log i, \log|\mathsf{D}|\})$ for the $i^{\text{th}}$ output element $s_i$ (in data complexity); thus, substantially improving the previous algorithm. Next, we develop a technically involved rounding technique that allows us to devise an algorithm with linear time preprocessing and output-linear delay $O(|s|)$ with high probability. To this end, we combine tools from algebra, high-dimensional geometry, and linear programming.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18563v2</guid>
      <category>cs.DS</category>
      <category>cs.DB</category>
      <category>cs.FL</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pawel Gawrychowski, Florin Manea, Markus L. Schmid</dc:creator>
    </item>
  </channel>
</rss>
