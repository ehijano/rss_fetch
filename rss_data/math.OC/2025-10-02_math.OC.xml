<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 02 Oct 2025 04:00:40 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Attack Detection in Dynamic Games with Quadratic Measurements</title>
      <link>https://arxiv.org/abs/2510.00241</link>
      <description>arXiv:2510.00241v1 Announce Type: new 
Abstract: This paper studies attack detection for discrete-time linear systems with stochastic process noise that produce both a vulnerable (i.e., attackable) linear measurement and a secured (i.e., unattackable) quadratic measurement. The motivating application of this model is a dynamic-game setting where the quadratic measurement is interpreted as a system-level utility or reward, and control inputs into the linear system are interpreted as control policies that, once applied, are known to all game participants and which steer the system towards a game-theoretic equilibrium (e.g., Nash equilibrium). To detect attacks on the linear channel, we develop a novel quadratic-utility-aware observer that leverages the secured quadratic output and enforces measurement consistency via a projection step. We establish three properties for this observer: feasibility of the true state, prox-regularity of the quadratic-constraint set, and a monotone error-reduction guarantee in the noise-free case. To detect adversarial manipulation, we compare linear and quadratic observer trajectories using a wild bootstrap maximum mean discrepancy (MMD) test that provides valid inference under temporal dependence. We validate our framework using numerical experiments of a pursuit-evasion game, where the quadratic observer preserves estimation accuracy under linear-sensor attacks, while the statistical test detects distributional divergence between the observers' trajectories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00241v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Muyan Jiang, Anil Aswani</dc:creator>
    </item>
    <item>
      <title>Asynchronous Nonlinear Sheaf Diffusion for Multi-Agent Coordination</title>
      <link>https://arxiv.org/abs/2510.00270</link>
      <description>arXiv:2510.00270v1 Announce Type: new 
Abstract: Cellular sheaves and sheaf Laplacians provide a far-reaching generalization of graphs and graph Laplacians, resulting in a wide array of applications ranging from machine learning to multi-agent control. In the context of multi-agent systems, so called coordination sheaves provide a unifying formalism that models heterogeneous agents and coordination goals over undirected communication topologies, and applying sheaf diffusion drives agents to achieve their coordination goals. Existing literature on sheaf diffusion assumes that agents can communicate and compute updates synchronously, which is an unrealistic assumption in many scenarios where communication delays or heterogeneous agents with different compute capabilities cause disagreement among agents. To address these challenges, we introduce asynchronous nonlinear sheaf diffusion. Specifically, we show that under mild assumptions on the coordination sheaf and bounded delays in communication and computation, nonlinear sheaf diffusion converges to a minimizer of the Dirichlet energy of the coordination sheaf at a linear rate proportional to the delay bound. We further show that this linear convergence is attained from arbitrary initial conditions and the analysis depends on the spectrum of the sheaf Laplacian in a manner that generalizes the standard graph Laplacian case. We provide several numerical simulations to validate our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00270v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yichen Zhao, Tyler Hanks, Hans Riess, Samuel Cohen, Matthew Hale, James Fairbanks</dc:creator>
    </item>
    <item>
      <title>Malliavin Calculus with Weak Derivatives for Counterfactual Stochastic Optimization</title>
      <link>https://arxiv.org/abs/2510.00297</link>
      <description>arXiv:2510.00297v1 Announce Type: new 
Abstract: We study counterfactual stochastic optimization of conditional loss functionals under misspecified and noisy gradient information. The difficulty is that when the conditioning event has vanishing or zero probability, naive Monte Carlo estimators are prohibitively inefficient; kernel smoothing, though common, suffers from slow convergence. We propose a two-stage kernel-free methodology. First, we show using Malliavin calculus that the conditional loss functional of a diffusion process admits an exact representation as a Skorohod integral, yielding variance comparable to classical Monte-Carlo variance. Second, we establish that a weak derivative estimate of the conditional loss functional with respect to model parameters can be evaluated with constant variance, in contrast to the widely used score function method whose variance grows linearly in the sample path length. Together, these results yield an efficient framework for counterfactual conditional stochastic gradient algorithms in rare-event regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00297v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vikram Krishnamurthy, Luke Snow</dc:creator>
    </item>
    <item>
      <title>The Non-Attainment Phenomenon in Robust SOCPs</title>
      <link>https://arxiv.org/abs/2510.00318</link>
      <description>arXiv:2510.00318v1 Announce Type: new 
Abstract: A fundamental theorem of linear programming states that a feasible linear program is solvable if and only if its objective function is copositive with respect to the recession cone of its feasible set. This paper demonstrates that this crucial guarantee does not extend to Second-Order Cone Programs (SOCPs), a workhorse model in robust and convex optimization. We construct and analyze a rigorous counterexample derived from a robust linear optimization problem with ellipsoidal uncertainty. The resulting SOCP possesses a non-empty feasible set, a bounded objective, and an objective function that is copositive on its recession cone. Despite satisfying these classical conditions for solvability, the problem admits no optimal solution; its infimum is finite but unattainable. We trace this pathology directly to the non-polyhedral geometry of the second-order cone, which causes the image of the feasible set under the linear objective to be non-closed. We interpret the example explicitly within the context of robust optimization, discuss its significant practical implications for modeling and computation, and propose effective mitigation strategies via polyhedral approximation or regularization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00318v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Vinh Nguyen</dc:creator>
    </item>
    <item>
      <title>End-to-end Training of High-Dimensional Optimal Control with Implicit Hamiltonians via Jacobian-Free Backpropagation</title>
      <link>https://arxiv.org/abs/2510.00359</link>
      <description>arXiv:2510.00359v1 Announce Type: new 
Abstract: Neural network approaches that parameterize value functions have succeeded in approximating high-dimensional optimal feedback controllers when the Hamiltonian admits explicit formulas. However, many practical problems, such as the space shuttle reentry problem and bicycle dynamics, among others, may involve implicit Hamiltonians that do not admit explicit formulas, limiting the applicability of existing methods. Rather than directly parameterizing controls, which does not leverage the Hamiltonian's underlying structure, we propose an end-to-end implicit deep learning approach that directly parameterizes the value function to learn optimal control laws. Our method enforces physical principles by ensuring trained networks adhere to the control laws by exploiting the fundamental relationship between the optimal control and the value function's gradient; this is a direct consequence of the connection between Pontryagin's Maximum Principle and dynamic programming. Using Jacobian-Free Backpropagation (JFB), we achieve efficient training despite temporal coupling in trajectory optimization. We show that JFB produces descent directions for the optimal control objective and experimentally demonstrate that our approach effectively learns high-dimensional feedback controllers across multiple scenarios involving implicit Hamiltonians, which existing methods cannot address.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00359v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eric Gelphman, Deepanshu Verma, Nicole Tianjiao Yang, Stanley Osher, Samy Wu Fung</dc:creator>
    </item>
    <item>
      <title>Progressively Sampled Equality-Constrained Optimization</title>
      <link>https://arxiv.org/abs/2510.00417</link>
      <description>arXiv:2510.00417v1 Announce Type: new 
Abstract: An algorithm is proposed, analyzed, and tested for solving continuous nonlinear-equality-constrained optimization problems where the constraints are defined by an expectation or an average over a large (finite) number of terms. The main idea of the algorithm is to solve a sequence of equality-constrained problems, each involving a finite sample of constraint-function terms, over which the sample set grows progressively. Under assumptions about the constraint functions and their first- and second-order derivatives that are reasonable in some real-world settings of interest, it is shown that -- with a sufficiently large initial sample -- solving a sequence of problems defined through progressive sampling yields a better worst-case sample complexity bound compared to solving a single problem with a full set of samples. The results of numerical experiments with a set of test problems demonstrate that the proposed approach can be effective in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00417v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Frank E. Curtis, Lingjun Guo, Daniel P. Robinson</dc:creator>
    </item>
    <item>
      <title>A primal-dual splitting algorithm with convex combination and larger step sizes for composite monotone inclusion problems</title>
      <link>https://arxiv.org/abs/2510.00437</link>
      <description>arXiv:2510.00437v1 Announce Type: new 
Abstract: The primal-dual splitting algorithm (PDSA) by Chambolle and Pock is efficient for solving structured convex optimization problems. It adopts an extrapolation step and achieves convergence under certain step size condition. Chang and Yang recently proposed a modified PDSA for bilinear saddle point problems, integrating a convex combination step to enable convergence with extended step sizes. In this paper, we focus on composite monotone inclusion problems (CMIPs), a generalization of convex optimization problems. While Vu extended PDSA to CMIPs, whether the modified PDSA can be directly adapted to CMIPs remains an open question. This paper introduces a new PDSA for CMIPs, featuring the inclusion of both an extrapolation step and a convex combination step. The proposed algorithm is reformulated as a fixed-point iteration by leveraging an extended firmly nonexpansive operator. Under a significantly relaxed step size condition, both its convergence and sublinear convergence rate results are rigorously established. For structured convex optimization problem, we establish its sublinear convergence rate results measured by function value gap and constraint violations. Moreover, we show through a concrete example that our condition on the involved parameters cannot be relaxed. Numerical experiments on image denoising, inpainting, matrix games, and LASSO problems are conducted to compare the proposed algorithm with state-of-the-art counterparts, demonstrating the efficiency of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00437v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>published in SIAM Journal on Imaging Sciences,2025</arxiv:journal_reference>
      <dc:creator>Xiaokai Chang, Junfeng Yang, Jianchao Bai, Jianxiong Cao</dc:creator>
    </item>
    <item>
      <title>Annealed Ensemble Kalman Inversion for Constrained Nonlinear Model Predictive Control: An ADMM Approach</title>
      <link>https://arxiv.org/abs/2510.00559</link>
      <description>arXiv:2510.00559v1 Announce Type: new 
Abstract: This work proposes a novel Alternating Direction Method of Multipliers (ADMM)-based Ensemble Kalman Inversion (EKI) algorithm for solving constrained nonlinear model predictive control (NMPC) problems. First, the stage-wise nonlinear inequality constraints in the NMPC problem are embedded via an augmented Lagrangian with nonnegative slack variables. We then show that the unconstrained augmented Lagrangian formulation of the NMPC admits a Bayesian interpretation: under a Gaussian observation model, its minimizers coincide with MAP estimators, enabling solution via EKI. However, since the nonnegativity constraint on the slacks cannot be enforced via Gaussian noise, our proposed algorithm results in a two-block ADMM that alternates between (i) a primal step that minimizes the unconstrained augmented Lagrangian, (ii) a nonnegativity projection for the slacks, and (iii) a dual ascent step. To balance exploration and convergence, an annealing schedule tempers covariances and penalty weights, thereby encouraging global search early and precise constraint satisfaction later. To demonstrate the performance of the proposed method, we compare it with another iterative sampling-based approach based on Model Predictive Path Integral (MPPI) control, called DIAL-MPC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00559v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmed Khalil, Mohamed Safwat, Efstathios Bakolas</dc:creator>
    </item>
    <item>
      <title>Control of Conservation Laws in the Nonlocal-to-Local Limit</title>
      <link>https://arxiv.org/abs/2510.00677</link>
      <description>arXiv:2510.00677v1 Announce Type: new 
Abstract: We analyze a class of control problems where the initial datum acts as a control and the state is given by the entropy solution of (local) conservation laws by a nonlocal-to-local limiting strategy. In particular we characterize the limit up to subsequence of minimizers to nonlocal control problems as minimizer of the corresponding local ones. Moreover, we also prove an analogous result at a discrete level by means of a Eulerian-Lagrangian scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00677v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jan Friedrich, Michael Herty, Claudia Nocita</dc:creator>
    </item>
    <item>
      <title>Fragility Analysis of Data-Driven Feedback Gains</title>
      <link>https://arxiv.org/abs/2510.00717</link>
      <description>arXiv:2510.00717v1 Announce Type: new 
Abstract: For linear time-invariant systems, input-state data collected during an open-loop experiment can remedy the lack of knowledge of system parameters. However, such data do not contain information about other system uncertainties such as feedback perturbations. In this paper, we study the effect of additive perturbations on control parameters in a data-based setting. To this end, we parameterize the set of quadratically stabilizing feedback gains obtained from noisy input-state data. We study the case where a stabilizing data-driven feedback gain is extremely sensitive to feedback perturbations, i.e., a small perturbation in the control parameters, no matter how small, could destabilize the unknown true system. We refer to this case as extreme fragility for which we provide a full characterization. We also present necessary and sufficient conditions for the case where the closed-loop system is completely immune to feedback perturbations. For the general case where the feedback gain is neither extremely fragile nor immune, we provide a measure by which one can quantize the control fragility directly based on the collected data. We also study the problem of designing the least fragile data-driven feedback gain. The results are presented either in closed-form, or in terms of linear matrix inequalities and semi-definite programs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00717v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yongzhang Li, Amir Shakouri, M. Kanat Camlibel</dc:creator>
    </item>
    <item>
      <title>Economic Bidding Strategy of Electric Vehicles in Real-Time Electricity Markets based on Marginal Opportunity Value</title>
      <link>https://arxiv.org/abs/2510.00744</link>
      <description>arXiv:2510.00744v1 Announce Type: new 
Abstract: The participation of electric vehicle (EV) aggregators in real-time electricity markets offers promising revenue opportunities through price-responsive energy arbitrage. A central challenge in economic bidding lies in quantifying the marginal opportunity value of EVs' charging and discharging decisions. This value is implicitly defined and dynamically shaped by uncertainties in electricity prices and availability of EV resources. In this paper, we propose an efficient bidding strategy that enables EV aggregators to generate market-compliant bids based on the underlying marginal value of energy. The approach first formulates the EV aggregator's power scheduling problem as a Markov decision process, linking the opportunity value of energy to the value function. Building on this formulation, we derive the probability distributions of marginal opportunity values across EVs' different energy states under stochastic electricity prices. These are then used to construct closed-form expressions for marginal charging values and discharging costs under both risk-neutral and risk-averse preferences. The resulting expressions support a fully analytical bid construction procedure that transforms marginal valuations into stepwise price-quantity bids without redundant computation. Case studies using real-world EV charging data and market prices demonstrate the effectiveness and adaptability of the proposed strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00744v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhen Zhu, Hongcai Zhang, Yonghua Song</dc:creator>
    </item>
    <item>
      <title>A semi-Lagrangian method for solving state constraint Mean Field Games in Macroeconomics</title>
      <link>https://arxiv.org/abs/2510.00768</link>
      <description>arXiv:2510.00768v1 Announce Type: new 
Abstract: We study continuous-time heterogeneous agent models cast as Mean Field Games, in the Aiyagari-Bewley-Huggett framework. The model couples a Hamilton-Jacobi-Bellman equation for individual optimization with a Fokker-Planck-Kolmogorov equation for the wealth distribution. We establish a comparison principle for constrained viscosity solutions of the HJB equation and propose a semi-Lagrangian (SL) scheme for its numerical solution, proving convergence via the Barles-Souganidis method. A policy iteration algorithm handles state constraints, and a dual SL scheme is used for the FPK equation. Numerical methods are presented in a fully discrete, implementable form.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00768v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabio Camilli, Qing Tang, Yong-shen Zhou</dc:creator>
    </item>
    <item>
      <title>Global convergence of Oja's component flow for general square matrices and its applications</title>
      <link>https://arxiv.org/abs/2510.00801</link>
      <description>arXiv:2510.00801v1 Announce Type: new 
Abstract: This paper establishes the global convergence properties of the Oja flow, a continuous-time algorithm for principal component extraction, for general square matrices. The Oja flow is a matrix differential equation on the Stiefel manifold designed to extract a dominant subspace. While its analysis has traditionally been restricted to symmetric positive-definite matrices, where it acts as a gradient flow, recent applications have extended its use to general matrices. In this non-symmetric case, the flow extracts the invariant subspace corresponding to the eigenvalues with the largest real parts. However, prior convergence results have been purely local, leaving the global behavior as an open problem. This paper fills this gap by providing a comprehensive global convergence analysis, establishing that the flow converges exponentially for almost all initial conditions. We also propose a modification to the algorithm that enhances its numerical stability. As an application of this theory, we develop novel methods for the model reduction of linear dynamical systems and the synthesis of low-rank stabilizing controllers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00801v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daiki Tsuzuki, Kentaro Ohki</dc:creator>
    </item>
    <item>
      <title>Non-Euclidean Broximal Point Method: A Blueprint for Geometry-Aware Optimization</title>
      <link>https://arxiv.org/abs/2510.00823</link>
      <description>arXiv:2510.00823v1 Announce Type: new 
Abstract: The recently proposed Broximal Point Method (BPM) [Gruntkowska et al., 2025] offers an idealized optimization framework based on iteratively minimizing the objective function over norm balls centered at the current iterate. It enjoys striking global convergence guarantees, converging linearly and in a finite number of steps for proper, closed and convex functions. However, its theoretical analysis has so far been confined to the Euclidean geometry. At the same time, emerging trends in deep learning optimization, exemplified by algorithms such as Muon [Jordan et al., 2024] and Scion [Pethick et al., 2025], demonstrate the practical advantages of minimizing over balls defined via non-Euclidean norms which better align with the underlying geometry of the associated loss landscapes. In this note, we ask whether the convergence theory of BPM can be extended to this more general, non-Euclidean setting. We give a positive answer, showing that most of the elegant guarantees of the original method carry over to arbitrary norm geometries. Along the way, we clarify which properties are preserved and which necessarily break down when leaving the Euclidean realm. Our analysis positions Non-Euclidean BPM as a conceptual blueprint for understanding a broad class of geometry-aware optimization algorithms, shedding light on the principles behind their practical effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00823v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Kaja Gruntkowska, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>Probability Density Estimation via Optimal Control</title>
      <link>https://arxiv.org/abs/2510.00835</link>
      <description>arXiv:2510.00835v1 Announce Type: new 
Abstract: We employ optimal control theory to study the problem of estimating the probability density function from a data set originating from an unknown probability distribution. The original variational problem is reformulated as a multi-stage optimal control problem and the associated maximum principle, or conditions of optimality, is reduced to a two-point boundary-value problem with interior conditions. A numerical scheme is proposed to solve the discretization of this problem. Estimates of density functions for synthetic and real data are computed using the proposed approach. The real data come from the Old Faithful geyser and the speeds of a group of galaxies. Comparisons are made with the popular statistics software R.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00835v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Markus Hegland, C. Yal\c{c}{\i}n Kaya</dc:creator>
    </item>
    <item>
      <title>Assortment Optimization and the Sample Average Approximation</title>
      <link>https://arxiv.org/abs/2510.00850</link>
      <description>arXiv:2510.00850v1 Announce Type: new 
Abstract: We consider a simple approach to solving assortment optimization under the random utility maximization model. The approach uses Monte-Carlo simulation to construct a ranking-based choice model that serves as a proxy for the true choice model, followed by finding an assortment that is optimal with respect to that proxy. In this paper, we make that approach more viable by developing faster algorithms for finding assortments that are optimal under ranking-based choice models. Our algorithms are based on mixed-integer programming and consist of stronger formulations as well as new structural and algorithmic results related to Benders cuts. We demonstrate that our algorithms - without any heuristics or parameter tuning - can offer more than a 20x speedup in real-world settings with thousands of products and samples. Equipped with our algorithms, we showcase the value of using the sample average approximation to solve assortment optimization problems for which no practically efficient algorithms are known.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00850v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hassaan Khalid, Bradley Sturt</dc:creator>
    </item>
    <item>
      <title>Digital Twins: McKean-Pontryagin Control for Partially Observed Physical Twins</title>
      <link>https://arxiv.org/abs/2510.00937</link>
      <description>arXiv:2510.00937v1 Announce Type: new 
Abstract: Optimal control for fully observed diffusion processes is well established and has led to numerous numerical implementations based on, for example, Bellman's principle, model free reinforcement learning, Pontryagin's maximum principle, and model predictive control. On the contrary, much fewer algorithms are available for optimal control of partially observed processes. However, this scenario is central to the digital twin paradigm where a physical twin is partially observed and control laws are derived based on a digital twin. In this paper, we contribute to this challenge by combining data assimilation in the form of the ensemble Kalman filter with the recently proposed McKean-Pontryagin approach to stochastic optimal control. We derive forward evolving mean-field evolution equations for states and co-states which simultaneously allow for an online assimilation of data as well as an online computation of control laws. The proposed methodology is therefore perfectly suited for real time applications of digital twins. We present numerical results for a controlled Lorenz-63 system and an inverted pendulum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00937v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manfred Opper, Sebastian Reich</dc:creator>
    </item>
    <item>
      <title>Flexible-step MPC for Unknown Linear Time-Invariant Systems</title>
      <link>https://arxiv.org/abs/2510.00961</link>
      <description>arXiv:2510.00961v1 Announce Type: new 
Abstract: We propose a novel flexible-step model predictive control algorithm for unknown linear time-invariant discrete-time systems. The goal is to asymptotically stabilize the system without relying on a pre-collected dataset that describes its behavior in advance. In particular, we aim to avoid a potentially harmful initial open-loop exploration phase for identification, since full identification is often not necessary for stabilization. Instead, the proposed control scheme explores and learns the unknown system online through measurements of inputs and states. The measurement results are used to update the prediction model in the finite-horizon optimal control problem. If the current prediction model yields an infeasible optimal control problem, then persistently exciting inputs are applied until feasibility is reestablished. The proposed flexible-step approach allows for a flexible number of implemented optimal input values in each iteration, which is beneficial for simultaneous exploration and exploitation. A generalized control Lyapunov function is included into the constraints of the optimal control problem to enforce stability. This way, the problem of optimization is decoupled from the problem of stabilization. For an asymptotically stabilizable unknown control system, we prove that the proposed flexible-step algorithm can lead to global convergence of the system state to the origin.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00961v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Markus Pietschner, Christian Ebenbauer, Bahman Gharesifard, Raik Suttner</dc:creator>
    </item>
    <item>
      <title>Funnel control for passive infinite-dimensional systems</title>
      <link>https://arxiv.org/abs/2510.01027</link>
      <description>arXiv:2510.01027v1 Announce Type: new 
Abstract: We consider funnel control for linear infinite-dimensional systems that are impedance passive, meaning that they satisfy an energy balance in which the stored energy equals the squared norm of the state and the supplied power is the inner product of input and output. For the analysis we employ the system node approach, which offers a unified framework for infinite-dimensional systems with boundary and distributed control and observation. The resulting closed-loop dynamics are governed by a nonlinear evolution equation; we establish its solvability and hence the applicability of funnel control to this class. The applicability is illustrated by an Euler-Bernoulli beam, which is studied in two distinct scenarios: once with boundary control and once with distributed control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01027v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.FA</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thavamani Govindaraj, Anthony Hastir, Lassi Paunonen, Timo Reis</dc:creator>
    </item>
    <item>
      <title>Networked Control and Mean Field Problems Under Diagonal Dominance: Decentralized and Social Optimality</title>
      <link>https://arxiv.org/abs/2510.01067</link>
      <description>arXiv:2510.01067v1 Announce Type: new 
Abstract: In this article, we employ an input-output approach to expand the study of cooperative multi-agent control and optimization problems characterized by mean-field interactions that admit decentralized and selfish solutions. The setting involves $n$ independent agents that interact solely through a shared cost function, which penalizes deviations of each agent from the group's average collective behavior. Building on our earlier results established for homogeneous agents, we extend the framework to nonidentical agents and show that, under a diagonal dominant interaction of the collective dynamics, with bounded local open-loop dynamics, the optimal controller for $H_\infty$ and $H_2$ norm minimization remains decentralized and selfish in the limit as the number of agents $n$ grows to infinity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01067v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vivek Khatana, Duo Wang, Petros Voulgaris, Nicola Elia, Naira Hovakimyan</dc:creator>
    </item>
    <item>
      <title>Vulnerability Analysis Evaluating Bilevel Optimal Power Flow Approaches for Multiple Load Cases</title>
      <link>https://arxiv.org/abs/2510.01073</link>
      <description>arXiv:2510.01073v1 Announce Type: new 
Abstract: This work presents two methodologies to enhance vulnerability assessment in power systems using bilevel attacker-defender network interdiction models. First, we introduce a systematic evaluation procedure for comparing different optimal power flow formulations in the lower-level problem. We demonstrate the procedure for a comparison of the widely used DC approximation and a linearized AC optimal power flow model. Second, we propose a novel scoring methodology to identify and prioritize critical attack vectors across diverse load and generation scenarios. Both methodologies go beyond traditional worst-case analysis. Case studies on a SimBench high-voltage test grid show that the DC approach fails to detect a significant portion of critical vulnerabilities. The scoring methodology further demonstrates the dependency of vulnerabilities on the considered load case and time step, highlighting the importance of assessing multiple scenarios and going beyond worst-case solutions. The proposed methodologies enhance power system vulnerability assessment and can support the effective development of robust defense strategies for future power systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01073v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eric T\"onges, Martin Braun, Philipp H\"artel</dc:creator>
    </item>
    <item>
      <title>A first-order method for constrained nonconvex--nonconcave minimax problems under a local Kurdyka-{\L}ojasiewicz condition</title>
      <link>https://arxiv.org/abs/2510.01168</link>
      <description>arXiv:2510.01168v1 Announce Type: new 
Abstract: We study a class of constrained nonconvex--nonconcave minimax problems in which the inner maximization involves potentially complex constraints. Under the assumption that the inner problem of a novel lifted minimax problem satisfies a local Kurdyka-{\L}ojasiewicz (KL) condition, we show that the maximal function of the original problem enjoys a local H\"older smoothness property. We also propose a sequential convex programming (SCP) method for solving constrained optimization problems and establish its convergence rate under a local KL condition. Leveraging these results, we develop an inexact proximal gradient method for the original minimax problem, where the inexact gradient of the maximal function is computed via the SCP method applied to a locally KL-structured subproblem. Finally, we establish complexity guarantees for the proposed method in computing an approximate stationary point of the original minimax problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01168v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaosong Lu, Xiangyuan Wang</dc:creator>
    </item>
    <item>
      <title>Muon Outperforms Adam in Tail-End Associative Memory Learning</title>
      <link>https://arxiv.org/abs/2509.26030</link>
      <description>arXiv:2509.26030v1 Announce Type: cross 
Abstract: The Muon optimizer is consistently faster than Adam in training Large Language Models (LLMs), yet the mechanism underlying its success remains unclear. This paper demystifies this mechanism through the lens of associative memory. By ablating the transformer components optimized by Muon, we reveal that the associative memory parameters of LLMs, namely the Value and Output (VO) attention weights and Feed-Forward Networks (FFNs), are the primary contributors to Muon's superiority. Motivated by this associative memory view, we then explain Muon's superiority on real-world corpora, which are intrinsically heavy-tailed: a few classes (tail classes) appear far less frequently than others. The superiority is explained through two key properties: (i) its update rule consistently yields a more isotropic singular spectrum than Adam; and as a result, (ii) on heavy-tailed data, it optimizes tail classes more effectively than Adam. Beyond empirical evidence, we theoretically confirm these findings by analyzing a one-layer associative memory model under class-imbalanced data. We prove that Muon consistently achieves balanced learning across classes regardless of feature embeddings, whereas Adam can induce large disparities in learning errors depending on embedding properties. In summary, our empirical observations and theoretical analyses reveal Muon's core advantage: its update rule aligns with the outer-product structure of linear associative memories, enabling more balanced and effective learning of tail classes in heavy-tailed distributions than Adam.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.26030v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shuche Wang, Fengzhuo Zhang, Jiaxiang Li, Cunxiao Du, Chao Du, Tianyu Pang, Zhuoran Yang, Mingyi Hong, Vincent Y. F. Tan</dc:creator>
    </item>
    <item>
      <title>A Bayesian Characterization of Ensemble Kalman Updates</title>
      <link>https://arxiv.org/abs/2510.00158</link>
      <description>arXiv:2510.00158v1 Announce Type: cross 
Abstract: The update in the Ensemble Kalman Filter (EnKF), called the Ensemble Kalman Update (EnKU), is widely used for Bayesian inference in inverse problems and data assimilation. At each filtering step, it approximates the solution to a likelihood-free Bayesian inversion from an ensemble of particles $(X_i,Y_i)\sim\pi$ sampled from a joint measure $\pi$ and an observation $y_\ast\in\mathbb{R}^m$. The posterior ${\pi}_{X|Y=y_\ast}$ is approximated by transporting $(X_i,Y_i)$ through an affine map $L^{\mathrm{EnKU}}_{y_\ast}(x,y)$ determined by the Kalman gain. While the EnKU is exact for Gaussian joints $\pi$ in the mean-field limit, exactness alone does not fix the update: infinitely many affine maps $L_{y_\ast}$ push a Gaussian $\pi$ to $\pi_{X|Y=y_\ast}$. This raises a question: which affine map should estimate the posterior? We provide a characterization of the EnKU among all such maps. First, we describe the set $\mathrm{E}^{\mathrm{EnKU}}$ of laws where the EnKU yields exact conditioning, showing it is larger than the Gaussian family. Next, we prove that, except for a small class of highly symmetric distributions in $\mathrm{E}^{\mathrm{EnKU}}$ (including Gaussians), the EnKU is the unique exact affine conditioning map. Finally, we ask for the largest possible set $\mathrm{F}$ where any measure-dependent affine transport could be exact; after characterizing $\mathrm{F}$, we show the EnKU's exactness set is almost maximal: $\mathrm{F}=\mathrm{E}^{\mathrm{EnKU}}\cup\mathrm{S}_{\mathrm{nl-dec}}$, where $\mathrm{S}_{\mathrm{nl-dec}}$ is a small symmetry class. Thus, among affine transports, the EnKU is near-optimal for exact conditioning beyond Gaussians and is the unique affine update achieving exactness for any measure in $\mathrm{F}$ except a subclass of strongly symmetric laws.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00158v1</guid>
      <category>math.ST</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Frederic J. N. Jorgensen, Youssef M. Marzouk</dc:creator>
    </item>
    <item>
      <title>Robust Attitude Control of Nonlinear Multi-Rotor Dynamics with LFT Models and $\mathcal{H}_\infty$ Performance</title>
      <link>https://arxiv.org/abs/2510.00208</link>
      <description>arXiv:2510.00208v1 Announce Type: cross 
Abstract: Attitude stabilization of unmanned aerial vehicles in uncertain environments presents significant challenges due to nonlinear dynamics, parameter variations, and sensor limitations. This paper presents a comparative study of $\mathcal{H}_\infty$ and classical PID controllers for multi-rotor attitude regulation in the presence of wind disturbances and gyroscope noise. The flight dynamics are modeled using a linear parameter-varying (LPV) framework, where nonlinearities and parameter variations are systematically represented as structured uncertainties within a linear fractional transformation formulation. A robust controller based on $\mathcal{H}_\infty$ formulation is designed using only gyroscope measurements to ensure guaranteed performance bounds. Nonlinear simulation results demonstrate the effectiveness of the robust controllers compared to classical PID control, showing significant improvement in attitude regulation under severe wind disturbances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00208v1</guid>
      <category>eess.SY</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tanay Kumar, Raktim Bhattacharya</dc:creator>
    </item>
    <item>
      <title>An Interpolation-based Scheme for Rapid Frequency-Domain System Identification</title>
      <link>https://arxiv.org/abs/2510.00525</link>
      <description>arXiv:2510.00525v1 Announce Type: cross 
Abstract: We present a frequency-domain system identification scheme based on barycentric interpolation and weight optimization. The scheme is related to the Adaptive Antoulas-Anderson (AAA) algorithm for model reduction, but uses an adaptive algorithm for selection of frequency points for interrogating the system response, as would be required in identification versus model reduction. The scheme is particularly suited for systems in which any one sinusoidal response run is long or expensive, and thus there is an incentive to reduce the total number of such runs. Two key features of our algorithm are the use of transient data in sinusoidal runs to both optimize the barycentric weights, and automated next-frequency selection on an adaptive grid. Both are done with error criteria that are proxies for a system's $H^2$ and $H^\infty$ norms respectively. Furthermore, the optimization problem we formulate is convex, and can optionally guarantee stability of the identified system. Computational results on a high-order, lightly damped structural system highlights the efficacy of this scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00525v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jared Jonas, Bassam Bamieh</dc:creator>
    </item>
    <item>
      <title>Guaranteed Noisy CP Tensor Recovery via Riemannian Optimization on the Segre Manifold</title>
      <link>https://arxiv.org/abs/2510.00569</link>
      <description>arXiv:2510.00569v1 Announce Type: cross 
Abstract: Recovering a low-CP-rank tensor from noisy linear measurements is a central challenge in high-dimensional data analysis, with applications spanning tensor PCA, tensor regression, and beyond. We exploit the intrinsic geometry of rank-one tensors by casting the recovery task as an optimization problem over the Segre manifold, the smooth Riemannian manifold of rank-one tensors. This geometric viewpoint yields two powerful algorithms: Riemannian Gradient Descent (RGD) and Riemannian Gauss-Newton (RGN), each of which preserves feasibility at every iteration. Under mild noise assumptions, we prove that RGD converges at a local linear rate, while RGN exhibits an initial local quadratic convergence phase that transitions to a linear rate as the iterates approach the statistical noise floor. Extensive synthetic experiments validate these convergence guarantees and demonstrate the practical effectiveness of our methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00569v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ke Xu, Yuefeng Han</dc:creator>
    </item>
    <item>
      <title>Error Feedback for Muon and Friends</title>
      <link>https://arxiv.org/abs/2510.00643</link>
      <description>arXiv:2510.00643v1 Announce Type: cross 
Abstract: Recent optimizers like Muon, Scion, and Gluon have pushed the frontier of large-scale deep learning by exploiting layer-wise linear minimization oracles (LMOs) over non-Euclidean norm balls, capturing neural network structure in ways traditional algorithms cannot. Yet, no principled distributed framework exists for these methods, and communication bottlenecks remain unaddressed. The very few distributed variants are heuristic, with no convergence guarantees in sight. We introduce EF21-Muon, the first communication-efficient, non-Euclidean LMO-based optimizer with rigorous convergence guarantees. EF21-Muon supports stochastic gradients, momentum, and bidirectional compression with error feedback-marking the first extension of error feedback beyond the Euclidean setting. It recovers Muon/Scion/Gluon when compression is off and specific norms are chosen, providing the first efficient distributed implementation of this powerful family. Our theory covers non-Euclidean smooth and the more general $(L^0, L^1)$-smooth setting, matching best-known Euclidean rates and enabling faster convergence under suitable norm choices. We further extend the analysis to layer-wise (generalized) smoothness regimes, capturing the anisotropic structure of deep networks. Experiments on NanoGPT benchmarking EF21-Muon against uncompressed Muon/Scion/Gluon demonstrate up to $7\times$ communication savings with no accuracy degradation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00643v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Kaja Gruntkowska, Alexander Gaponov, Zhirayr Tovmasyan, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>Provably Optimal Quantum Circuits with Mixed-Integer Programming</title>
      <link>https://arxiv.org/abs/2510.00649</link>
      <description>arXiv:2510.00649v1 Announce Type: cross 
Abstract: We present a depth-aware optimization framework for quantum circuit compilation that unifies provable optimality with scalable heuristics. For exact synthesis of a target unitary, we formulate a mixed-integer linear program (MILP) that linearly handles global-phase equivalence and uses explicit parallel scheduling variables to certify depth-optimal solutions for small-to-medium circuits. Domain-specific valid constraints, including identity ordering, commuting-gate pruning, short-sequence redundancy cuts, and Hermitian-conjugate linkages, significantly accelerate branch-and-bound, yielding speedups up to 43x on standard benchmarks. The framework supports hardware-aware objectives, enabling fault-tolerant (e.g. T-count) and NISQ-era (e.g. entangling gates) devices. For approximate synthesis, we propose 3 objectives: (i) exact, but non-convex, phase-invariant fidelity maximization; (ii) a linear surrogate that maximizes the real trace overlap, yielding a tight lower bound to fidelity; and (iii) a convex quadratic function that minimizes the circuit's Frobenius error.
  To scale beyond exact MILP, we propose a novel rolling-horizon optimization (RHO) that rolls primarily in time, caps the active-qubits, and enforces per-qubit closure while globally optimizing windowed segments. This preserves local context, reduces the Hilbert-space dimension, and enables iterative improvements without ancillas. On a 142-gate seed circuit, RHO yields 116 gates, an 18.3% reduction from the seed, while avoiding the trade-off between myopic passes and long run times. Empirically, our exact compilation framework achieves certified depth-optimal circuits on standard targets, high-fidelity Fibonacci-anyon weaves, and a 36% gate-count reduction on multi-body parity circuits. All methods are in the open-source QuantumCircuitOpt, providing a single framework that bridges exact certification and scalable synthesis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00649v1</guid>
      <category>quant-ph</category>
      <category>cs.MS</category>
      <category>math.OC</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Harsha Nagarajan, Zsolt Szab\'o</dc:creator>
    </item>
    <item>
      <title>Approximate mean curvature flows of a general varifold, and their limit spacetime Brakke flow</title>
      <link>https://arxiv.org/abs/2510.00746</link>
      <description>arXiv:2510.00746v1 Announce Type: cross 
Abstract: We propose a construction of mean curvature flows by approximation for very general initial data, in the spirit of the works of Brakke and of Kim &amp; Tonegawa based on the theory of varifolds. Given a general varifold, we construct by iterated push-forwards an approximate time-discrete mean curvature flow depending on both a given time step and an approximation parameter. We show that, as the time step tends to $0$, this time-discrete flow converges to a unique limit flow, which we call the approximate mean curvature flow. An interesting feature of our approach is its generality, as it provides an approximate notion of mean curvature flow for very general structures of any dimension and codimension, ranging from continuous surfaces to discrete point clouds. We prove that our approximate mean curvature flow satisfies several properties: stability, uniqueness, Brakke-type equality, mass decay. By coupling this approximate flow with the canonical time measure, we prove convergence, as the approximation parameter tends to $0$, to a spacetime limit measure whose generalized mean curvature is bounded. Under an additional rectifiability assumption, we further prove that this limit measure is a spacetime Brakke flow.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00746v1</guid>
      <category>math.DG</category>
      <category>math.OC</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Blanche Buet, Gian Paolo Leonardi, Simon Masnou, Abdelmouksit Sagueni</dc:creator>
    </item>
    <item>
      <title>A Technique Based on Trade-off Maps to Visualise and Analyse Relationships Between Objectives in Optimisation Problems</title>
      <link>https://arxiv.org/abs/2510.00877</link>
      <description>arXiv:2510.00877v1 Announce Type: cross 
Abstract: Understanding the relationships between objectives in a multiobjective optimisation problem is important for developing tailored and efficient solving techniques. In particular, when tackling combinatorial optimisation problems with many objectives, that arise in real-world logistic scenarios, better support for the decision maker can be achieved through better understanding of the often complex fitness landscape. This paper makes a contribution in this direction by presenting a technique that allows a visualisation and analysis of the local and global relationships between objectives in optimisation problems with many objectives. The proposed technique uses four steps: First, the global pairwise relationships are analysed using the Kendall correlation method; then, the ranges of the values found on the given Pareto front are estimated and assessed; next, these ranges are used to plot a map using Gray code, similar to Karnaugh maps, that has the ability to highlight the trade-offs between multiple objectives; and finally, local relationships are identified using scatter plots. Experiments are presented for three combinatorial optimisation problems: multiobjective multidimensional knapsack problem, multiobjective nurse scheduling problem, and multiobjective vehicle routing problem with time windows . Results show that the proposed technique helps in the gaining of insights into the problem difficulty arising from the relationships between objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00877v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>math.OC</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1002/mcda.1604</arxiv:DOI>
      <dc:creator>Rodrigo Lankaites Pinheiro, Dario Landa-Silva, Jason Atkin</dc:creator>
    </item>
    <item>
      <title>Test-Time Search in Neural Graph Coarsening Procedures for the Capacitated Vehicle Routing Problem</title>
      <link>https://arxiv.org/abs/2510.00958</link>
      <description>arXiv:2510.00958v1 Announce Type: cross 
Abstract: The identification of valid inequalities, such as the rounded capacity inequalities (RCIs), is a key component of cutting plane methods for the Capacitated Vehicle Routing Problem (CVRP). While a deep learning-based separation method can learn to find high-quality cuts, our analysis reveals that the model produces fewer cuts than expected because it is insufficiently sensitive to generate a diverse set of generated subsets. This paper proposes an alternative: enhancing the performance of a trained model at inference time through a new test-time search with stochasticity. First, we introduce stochastic edge selection into the graph coarsening procedure, replacing the previously proposed greedy approach. Second, we propose the Graph Coarsening History-based Partitioning (GraphCHiP) algorithm, which leverages coarsening history to identify not only RCIs but also, for the first time, the Framed capacity inequalities (FCIs). Experiments on randomly generated CVRP instances demonstrate the effectiveness of our approach in reducing the dual gap compared to the existing neural separation method. Additionally, our method discovers effective FCIs on a specific instance, despite the challenging nature of identifying such cuts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00958v1</guid>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yoonju Sim, Hyeonah Kim, Changhyun Kwon</dc:creator>
    </item>
    <item>
      <title>Predictive Control Barrier Functions for Discrete-Time Linear Systems with Unmodeled Delays</title>
      <link>https://arxiv.org/abs/2510.01059</link>
      <description>arXiv:2510.01059v1 Announce Type: cross 
Abstract: This paper introduces a predictive control barrier function (PCBF) framework for enforcing state constraints in discrete-time systems with unknown relative degree, which can be caused by input delays or unmodeled input dynamics. Existing discrete-time CBF formulations typically require the construction of auxiliary barrier functions when the relative degree is greater than one, which complicates implementation and may yield conservative safe sets. The proposed PCBF framework addresses this challenge by extending the prediction horizon to construct a CBF for an associated system with relative degree one. As a result, the superlevel set of the PCBF coincides with the safe set, simplifying constraint enforcement and eliminating the need for auxiliary functions. The effectiveness of the proposed method is demonstrated on a discrete-time double integrator with input delay and a bicopter system with position constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01059v1</guid>
      <category>eess.SY</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juan Augusto Paredes Salazar, James Usevitch, Ankit Goel</dc:creator>
    </item>
    <item>
      <title>On the Benefits of Weight Normalization for Overparameterized Matrix Sensing</title>
      <link>https://arxiv.org/abs/2510.01175</link>
      <description>arXiv:2510.01175v1 Announce Type: cross 
Abstract: While normalization techniques are widely used in deep learning, their theoretical understanding remains relatively limited. In this work, we establish the benefits of (generalized) weight normalization (WN) applied to the overparameterized matrix sensing problem. We prove that WN with Riemannian optimization achieves linear convergence, yielding an exponential speedup over standard methods that do not use WN. Our analysis further demonstrates that both iteration and sample complexity improve polynomially as the level of overparameterization increases. To the best of our knowledge, this work provides the first characterization of how WN leverages overparameterization for faster convergence in matrix sensing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01175v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yudong Wei, Liang Zhang, Bingcong Li, Niao He</dc:creator>
    </item>
    <item>
      <title>Gauges and Accelerated Optimization over Smooth and/or Strongly Convex Sets</title>
      <link>https://arxiv.org/abs/2303.05037</link>
      <description>arXiv:2303.05037v4 Announce Type: replace 
Abstract: We consider feasibility and constrained optimization problems defined over smooth and/or strongly convex sets. These notions mirror their popular function counterparts but are much less explored in the first-order optimization literature. We propose new scalable, projection-free, accelerated first-order methods in these settings. Our methods avoid linear optimization or projection oracles, only using cheap one-dimensional linesearches and normal vector computations. Despite this, we derive optimal accelerated convergence guarantees of $O(1/T)$ for strongly convex problems, $O(1/T^2)$ for smooth problems, and accelerated linear convergence given both. Our algorithms and analysis are based on novel characterizations of the Minkowski gauge of smooth and/or strongly convex sets, which may be of independent interest: although the gauge is neither smooth nor strongly convex, we show the gauge squared inherits any structure present in the set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.05037v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ning Liu, Benjamin Grimmer</dc:creator>
    </item>
    <item>
      <title>Online Non-convex Optimization with Long-term Non-convex Constraints</title>
      <link>https://arxiv.org/abs/2311.02426</link>
      <description>arXiv:2311.02426v4 Announce Type: replace 
Abstract: A novel Follow-the-Perturbed-Leader type algorithm is proposed and analyzed for solving general long-term constrained optimization problems in an online manner, where the target and constraint functions are oblivious adversarially generated and not necessarily convex. The algorithm is based on Lagrangian reformulation and innovatively integrates random perturbations and regularizations in primal and dual directions: 1). exponentially distributed random perturbations in the primal direction to handle non-convexity, and 2). strongly concave logarithmic regularizations in the dual space to handle constraint violations. Based on a proposed expected static cumulative regret, and under mild Lipschitz continuity assumption, the algorithm demonstrates the online learnability, achieving the first sublinear cumulative regret complexity for this class of problems. The proposed algorithm is applied to tackle a long-term (extreme value) constrained river pollutant source identification problem, validate the theoretical results and exhibit superior performance compared to existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.02426v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shijie Pan, Jianyu Xu, Wenjie Huang</dc:creator>
    </item>
    <item>
      <title>Global Convergence Analysis of the Power Proximal Point and Augmented Lagrangian Method</title>
      <link>https://arxiv.org/abs/2312.12205</link>
      <description>arXiv:2312.12205v3 Announce Type: replace 
Abstract: In this paper we study an unconventional inexact Augmented Lagrangian Method (ALM) for convex optimization problems, as first proposed by Bertsekas, wherein the penalty term is a potentially non-Euclidean norm raised to a power between one and two. We analyze the algorithm through the lens of a nonlinear Proximal Point Method (PPM), as originally introduced by Luque, applied to the dual problem. While Luque analyzes the order of local convergence of the scheme with Euclidean norms our focus is on the non-Euclidean case which prevents us from using standard tools for the analysis such as the nonexpansiveness of the proximal mapping. To allow for errors in the primal update, we derive two implementable stopping criteria under which we analyze both the global and the local convergence rates of the algorithm. More specifically, we show that the method enjoys a fast sublinear global rate in general and a local superlinear rate under suitable growth assumptions. We also highlight that the power ALM can be interpreted as classical ALM with an implicitly defined penalty-parameter schedule, reducing its parameter dependence. Our experiments on a number of relevant problems suggest that for certain powers the method performs similarly to a classical ALM with fine-tuned adaptive penalty rule, despite involving fewer parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.12205v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Konstantinos A. Oikonomidis, Alexander Bodard, Emanuel Laude, Panagiotis Patrinos</dc:creator>
    </item>
    <item>
      <title>Norm-induced Cuts: Outer Approximation for Lipschitzian Constraint Functions</title>
      <link>https://arxiv.org/abs/2403.11546</link>
      <description>arXiv:2403.11546v3 Announce Type: replace 
Abstract: In this paper, we consider a finite-dimensional optimization problem minimizing a continuous objective on a compact domain subject to a multi-dimensional constraint function. For the latter, we assume the availability of a global Lipschitz constant. In recent literature, methods based on non-convex outer approximation are proposed for tackling one-dimensional equality constraints that are Lipschitz with respect to the maximum norm. To the best of our knowledge, however, there does not exist a non-convex outer approximation method for a general problem class. We introduce a meta-level solution framework to solve such problems and tackle the underlying theoretical foundations. Considering the feasible domain without the constraint function as manageable, our method relaxes the multidimensional constraint and iteratively refines the feasible region by means of norm-induced cuts, relying on an oracle for the resulting subproblems. We show the method's correctness and investigate the problem complexity. In order to account for discussions about functionality, limits, and extensions, we present computational examples including illustrations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11546v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adrian G\"o{\ss}, Alexander Martin, Sebastian Pokutta, Kartikey Sharma</dc:creator>
    </item>
    <item>
      <title>Sparse Extended Mean-Variance-CVaR Portfolios with Short-selling</title>
      <link>https://arxiv.org/abs/2404.00605</link>
      <description>arXiv:2404.00605v2 Announce Type: replace 
Abstract: This paper introduces a novel penalty decomposition algorithm customized for addressing the non-differentiable and nonconvex problem of extended mean-variance-CVaR portfolio optimization with short-selling and cardinality constraints. The proposed algorithm solves a sequence of penalty subproblems using a block coordinate descent (BCD) method while striving to fully exploit each component of the objective function or constraints. Through rigorous analysis, the well-posed nature of each subproblem of the BCD method is established, and closed-form solutions are derived where possible. A comprehensive theoretical convergence analysis is provided to confirm the efficacy of the introduced algorithm in reaching a local minimizer of this intractable optimization problem in finance, whereas generic optimization techniques either only capture a partial minimum or are not efficient. Numerical experiments conducted on real-world datasets validate the practical applicability, effectiveness, and robustness of the introduced algorithm across various criteria. Notably, the existence of closed-form solutions within the BCD subproblems prominently underscores the efficiency of our algorithm when compared to state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00605v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmad Mousavi, Maziar Salahi, Zois Boukouvalas</dc:creator>
    </item>
    <item>
      <title>Generalized Smooth Stochastic Variational Inequalities: Almost Sure Convergence and Convergence Rates</title>
      <link>https://arxiv.org/abs/2410.12334</link>
      <description>arXiv:2410.12334v2 Announce Type: replace 
Abstract: This paper focuses on solving a stochastic variational inequality (SVI) problem under relaxed smoothness assumption for a class of structured non-monotone operators. The SVI problem has attracted significant interest in the machine learning community due to its immediate application to adversarial training and multi-agent reinforcement learning. In many such applications, the resulting operators do not satisfy the smoothness assumption. To address this issue, we focus on a weaker generalized smoothness assumption called $\alpha$-symmetric. Under $p$-quasi sharpness and $\alpha$-symmetric assumptions on the operator, we study clipped projection (gradient descent-ascent) and clipped Korpelevich (extragradient) methods. For these clipped methods, we provide the first almost-sure convergence results without making any assumptions on the boundedness of either the stochastic operator or the stochastic samples. We also provide the first in-expectation unbiased convergence rate results for these methods under a relaxed smoothness assumption for $\alpha \leq \frac{1}{2}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12334v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniil Vankov, Angelia Nedich, Lalitha Sankar</dc:creator>
    </item>
    <item>
      <title>Stability Bounds for the Unfolded Forward-Backward Algorithm</title>
      <link>https://arxiv.org/abs/2412.17888</link>
      <description>arXiv:2412.17888v2 Announce Type: replace 
Abstract: We consider a neural network architecture designed to solve inverse problems where the degradation operator is linear and known. This architecture is constructed by unrolling a forward-backward algorithm derived from the minimization of an objective function that combines a data-fidelity term, a Tikhonov-type regularization term, and a potentially nonsmooth convex penalty. The robustness of this inversion method to input perturbations is analyzed theoretically. Ensuring robustness complies with the principles of inverse problem theory, as it ensures both the continuity of the inversion method and the resilience to small noise - a critical property given the known vulnerability of deep neural networks to adversarial perturbations. A key novelty of our work lies in examining the robustness of the proposed network to perturbations in its bias, which represents the observed data in the inverse problem. Additionally, we provide numerical illustrations of the analytical Lipschitz bounds derived in our analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17888v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s10851-025-01258-6</arxiv:DOI>
      <arxiv:journal_reference>Journal of Mathematical Imaging and Vision, 67 (48), 2025</arxiv:journal_reference>
      <dc:creator>Emilie Chouzenoux, Cecile Della Valle, Jean-Christophe Pesquet</dc:creator>
    </item>
    <item>
      <title>A Globally Convergent Method for Computing B-stationary Points of Mathematical Programs with Equilibrium Constraints</title>
      <link>https://arxiv.org/abs/2501.13835</link>
      <description>arXiv:2501.13835v3 Announce Type: replace 
Abstract: This paper introduces a computationally efficient method that globally converges to B-stationary points of mathematical programs with equilibrium constraints (MPECs) in a finite number of iterations. B-stationarity is necessary for optimality and means that no feasible first-order direction can improve the objective. Given a feasible point of an MPEC, B-stationarity can be certified by solving a linear program with equilibrium constraints (LPCC) constructed at this point. The proposed method solves a sequence of LPCCs, which either certify B-stationarity or provide an active-set estimate for the complementarity constraints, along with nonlinear programs (NLPs) -- referred to as branch NLPs (BNLPs) -- obtained by fixing the active set in the MPEC. A BNLP is more regular than the original MPEC, easier to solve, and with the correct active set, its solution coincides with that of the MPEC. We show that, unless the current iterate is B-stationary, these combinatorial LPCCs need not be solved to optimality; for convergence, it suffices to compute a nonzero feasible point, yielding significant computational savings. The method proceeds in two phases: the first identifies a feasible BNLP or a {stationary point of a constraint infeasibility minimization problem, and the second solves a finite sequence of BNLPs until a B-stationary point of the MPEC is found. We established finite convergence under the MPEC-MFCQ. Numerical experiments and an open-source software implementation show that the proposed method is more robust and faster than relaxation-based and mixed-integer NLP approaches, even on medium to large-scale instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13835v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Armin Nurkanovi\'c, Sven Leyffer</dc:creator>
    </item>
    <item>
      <title>Integrating Sequential Hypothesis Testing into Adversarial Games: A Sun Zi-Inspired Framework</title>
      <link>https://arxiv.org/abs/2502.13462</link>
      <description>arXiv:2502.13462v2 Announce Type: replace 
Abstract: This paper investigates the interplay between sequential hypothesis testing (SHT) and adversarial decision-making in partially observable games, focusing on the deceptive strategies of red and blue teams. Inspired by Sun Zi's The Art of War and its emphasis on deception, we develop a novel framework to both deceive adversaries and counter their deceptive tactics. We model this interaction as a Stackelberg game where the blue team, as the follower, optimizes its controls to achieve its goals while misleading the red team into forming incorrect beliefs on its intentions. The red team, as the leader, strategically constructs and instills false beliefs through the blue team's envisioned SHT to manipulate the blue team's behavior and reveal its true objectives. The blue team's optimization problem balances the fulfillment of its primary objectives and the level of misdirection, while the red team coaxes the blue team into behaving consistently with its actual intentions. We derive a semi-explicit solution for the blue team's control problem within a linear-quadratic framework, and illustrate how the red team leverages leaked information from the blue team to counteract deception. Numerical experiments validate the model, showcasing the effectiveness of deception-driven strategies in adversarial systems. These findings integrate ancient strategic insights with modern control and game theory, providing a foundation for further exploration in adversarial decision-making, such as cybersecurity, autonomous systems, and financial markets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13462v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haosheng Zhou, Daniel Ralston, Xu Yang, Ruimeng Hu</dc:creator>
    </item>
    <item>
      <title>Grassmann and Flag Varieties in Linear Algebra, Optimization, and Statistics: An Algebraic Perspective</title>
      <link>https://arxiv.org/abs/2505.15969</link>
      <description>arXiv:2505.15969v2 Announce Type: replace 
Abstract: Grassmann and flag varieties lead many lives in pure and applied mathematics. Here we focus on the algebraic complexity of solving various problems in linear algebra and statistics as optimization problems over these varieties. The measure of the algebraic complexity is the amount of complex critical points of the corresponding optimization problem. After an exposition of different realizations of these manifolds as algebraic varieties we present a sample of optimization problems over them and we compute their algebraic complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.15969v2</guid>
      <category>math.OC</category>
      <category>math.AG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hannah Friedman, Serkan Ho\c{s}ten</dc:creator>
    </item>
    <item>
      <title>Vulnerability-Based Optimal Grid Defense Strategies for Enhancing Cyber-Physical Energy System Resilience</title>
      <link>https://arxiv.org/abs/2506.09766</link>
      <description>arXiv:2506.09766v2 Announce Type: replace 
Abstract: An approach is proposed to identify optimal asset protection strategies based on vulnerability assessment outcomes. Traditional bilevel attacker-defender models emphasize worst-case scenarios but offer limited defensive guidance. In contrast, trilevel models introduce high computational complexity and rely on fixed network configurations. The proposed critical-components method leverages vulnerability assessment results to determine protection strategies, effectively outsourcing the upper-level defense decision. This enables adaptability to diverse network topologies, assessment techniques, and cyber-physical energy systems without the overhead of multi-level optimization. Case studies demonstrate the potential for improved system resilience across varying operational conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09766v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eric T\"onges, Martin Braun, Philipp H\"artel</dc:creator>
    </item>
    <item>
      <title>Stochastically Structured Reservoir Computers for Financial and Economic System Identification</title>
      <link>https://arxiv.org/abs/2507.17115</link>
      <description>arXiv:2507.17115v2 Announce Type: replace 
Abstract: This paper introduces a methodology for identifying and simulating financial and economic systems using stochastically structured reservoir computers (SSRCs). The framework combines structure-preserving embeddings with graph-informed coupling matrices to model inter-agent dynamics while enhancing interpretability. A constrained optimization scheme guarantees compliance with both stochastic and structural constraints. Two empirical case studies, a nonlinear stochastic dynamic model and regional inflation network dynamics, demonstrate the effectiveness of the approach in capturing complex nonlinear patterns and enabling interpretable predictive analysis under uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17115v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>econ.TH</category>
      <category>eess.SY</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lendy Banegas, Fredy Vides</dc:creator>
    </item>
    <item>
      <title>Moment Constrained Optimal Transport for Thermostatically Controlled Loads</title>
      <link>https://arxiv.org/abs/2508.20059</link>
      <description>arXiv:2508.20059v2 Announce Type: replace 
Abstract: Controlling large populations of thermostatically controlled loads (TCLs), such as water heaters, poses significant challenges due to the need to balance global constraints (e.g., grid stability) with individual requirements (e.g., physical limits and quality of service). In this work, we introduce a novel framework based on Moment Constrained Optimal Transport (MCOT) for distributed control of TCLs. By formulating the control problem as an optimal transport problem with moment constraints, our approach integrates global consumption constraints and physical feasibility conditions into the control design. This problem with high (or infinite) dimensionality can be reduced to a much lower finite-dimensional problem. The structure of this problem allows for computing the gradient with Monte Carlo methods by generating trajectories of TCLs. Contrary to all previous work, in our MCOT framework, it is possible to choose the sampling law, which considerably speeds up the calculations. This algorithm mitigates the need for extensive state-space discretization and significantly reduces computational complexity compared to existing methods. Numerical experiments in a water heater case study demonstrate that our MCOT-based method effectively coordinates TCLs under various constraints. We further extend our approach to an online setting, illustrating its practical applicability on simulated data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20059v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas Le Corre, Julien Cardinal, Ana Bu\v{s}i\'c</dc:creator>
    </item>
    <item>
      <title>Towards understanding Accelerated Stein Variational Gradient Flow -- Analysis of Generalized Bilinear Kernels for Gaussian target distributions</title>
      <link>https://arxiv.org/abs/2509.04008</link>
      <description>arXiv:2509.04008v2 Announce Type: replace 
Abstract: Stein variational gradient descent (SVGD) is a kernel-based and non-parametric particle method for sampling from a target distribution, such as in Bayesian inference and other machine learning tasks. Different from other particle methods, SVGD does not require estimating the score, which is the gradient of the log-density. However, in practice, SVGD can be slow compared to score-estimation-based sampling algorithms. To design a fast and efficient high-dimensional sampling algorithm with the advantages of SVGD, we introduce accelerated SVGD (ASVGD), based on an accelerated gradient flow in a metric space of probability densities following Nesterov's method. We then derive a momentum-based discrete-time sampling algorithm, which evolves a set of particles deterministically. To stabilize the particles' position update, we also include a Wasserstein metric regularization. This paper extends the conference version \cite{SL2025}. For the bilinear kernel and Gaussian target distributions, we study the kernel parameter and damping parameters with an optimal convergence rate of the proposed dynamics. This is achieved by analyzing the linearized accelerated gradient flows at the equilibrium. Interestingly, the optimal parameter is a constant, which does not depend on the covariance of the target distribution. For the generalized kernel functions, such as the Gaussian kernel, numerical examples with varied target distributions demonstrate the effectiveness of ASVGD compared to SVGD and other popular sampling methods. Furthermore, we show that in the setting of Bayesian neural networks, ASVGD outperforms SVGD significantly in terms of log-likelihood and total iteration times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04008v2</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Viktor Stein, Wuchen Li</dc:creator>
    </item>
    <item>
      <title>Regularized Overestimated Newton</title>
      <link>https://arxiv.org/abs/2509.21684</link>
      <description>arXiv:2509.21684v2 Announce Type: replace 
Abstract: We propose Regularized Overestimated Newton (RON), a Newton-type method with low per-iteration cost and strong global and local convergence guarantees for smooth convex optimization. RON interpolates between gradient descent and globally regularized Newton, with behavior determined by the largest Hessian overestimation error. Globally, when the optimality gap of the objective is large, RON achieves an accelerated $O(n^{-2})$ convergence rate; when small, its rate becomes $O(n^{-1})$. Locally, RON converges superlinearly and linearly when the overestimation is exact and inexact, respectively, toward possibly non-isolated minima under the local Quadratic Growth (QG) condition. The linear rate is governed by an improved effective condition number depending on the overestimation error. Leveraging a recent randomized rank-$k$ Hessian approximation algorithm, we obtain a practical variant with $O(\text{dim}\cdot k^2)$ cost per iteration. When the Hessian rank is uniformly below $k$, RON achieves a per-iteration cost comparable to that of first-order methods while retaining the superior convergence rates even in degenerate local landscapes. We validate our theoretical findings through experiments on entropic optimal transport and inverse problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21684v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Danny Duan, Hanbaek Lyu</dc:creator>
    </item>
    <item>
      <title>Approximating value functions via corner Benders' cuts</title>
      <link>https://arxiv.org/abs/2509.21758</link>
      <description>arXiv:2509.21758v2 Announce Type: replace 
Abstract: We introduce a novel technique to generate Benders' cuts from a conic relaxation ("corner") derived from a basis of a higher-dimensional polyhedron that we aim to outer approximate in a lower-dimensional space. To generate facet-defining inequalities for the epigraph associated to this corner, we develop a computationally-efficient algorithm based on a compact reverse polar formulation and a row generation scheme that handles the redundant inequalities. Via a known connection between arc-flow and path-flow formulations, we show that our method can recover the linear programming bound of a Dantzig-Wolfe formulation using multiple cuts in the projected space. In computational experiments, our generic technique enhances the performance of a problem-specific state-of-the-art algorithm for the vehicle routing problem with stochastic demands, a well-studied variant of the classic capacitated vehicle routing problem that accounts for customer demand uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21758v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matheus J. Ota, Ricardo Fukasawa, Aleksandr M. Kazachkov</dc:creator>
    </item>
    <item>
      <title>On the Relationships among GPU-Accelerated First-Order Methods for Solving Linear Programming</title>
      <link>https://arxiv.org/abs/2509.23903</link>
      <description>arXiv:2509.23903v2 Announce Type: replace 
Abstract: This paper aims to understand the relationships among recently developed GPU-accelerated first-order methods (FOMs) for linear programming (LP), with particular emphasis on HPR-LP -- a Halpern Peaceman--Rachford (HPR) method for LP. Our findings can be summarized as follows: (i) the base algorithm of cuPDLPx, a recently released GPU solver, is a special case of the base algorithm of HPR-LP, thereby showing that cuPDLPx is another concrete implementation instance of HPR-LP; (ii) once the active sets have been identified, HPR-LP and EPR-LP -- an ergodic PR method for LP -- become equivalent under the same initialization; and (iii) extensive numerical experiments on benchmark datasets demonstrate that HPR-LP achieves the best overall performance among current GPU-accelerated LP solvers. These findings provide a strong motivation for using the HPR method as a baseline to further develop GPU-accelerated LP solvers and beyond.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23903v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaihuang Chen, Defeng Sun, Yancheng Yuan, Guojun Zhang, Xinyuan Zhao</dc:creator>
    </item>
    <item>
      <title>A Single-Loop Gradient Algorithm for Pessimistic Bilevel Optimization via Smooth Approximation</title>
      <link>https://arxiv.org/abs/2509.26240</link>
      <description>arXiv:2509.26240v2 Announce Type: replace 
Abstract: Bilevel optimization has garnered significant attention in the machine learning community recently, particularly regarding the development of efficient numerical methods. While substantial progress has been made in developing efficient algorithms for optimistic bilevel optimization, the study of methods for solving Pessimistic Bilevel Optimization (PBO) remains relatively less explored, especially the design of fully first-order, single-loop gradient-based algorithms. This paper aims to bridge this research gap. We first propose a novel smooth approximation to the PBO problem, using penalization and regularization techniques. Building upon this approximation, we then propose SiPBA (Single-loop Pessimistic Bilevel Algorithm), a new gradient-based method specifically designed for PBO which avoids second-order derivative information or inner-loop iterations for subproblem solving. We provide theoretical validation for the proposed smooth approximation scheme and establish theoretical convergence for the algorithm SiPBA. Numerical experiments on synthetic examples and practical applications demonstrate the effectiveness and efficiency of SiPBA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.26240v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qichao Cao, Shangzhi Zeng, Jin Zhang</dc:creator>
    </item>
    <item>
      <title>Mean-Covariance Robust Risk Measurement</title>
      <link>https://arxiv.org/abs/2112.09959</link>
      <description>arXiv:2112.09959v3 Announce Type: replace-cross 
Abstract: We introduce a universal framework for mean-covariance robust risk measurement and portfolio optimization. We model uncertainty in terms of the Gelbrich distance on the mean-covariance space, along with prior structural information about the population distribution. Our approach is related to the theory of optimal transport and exhibits superior statistical and computational properties than existing models. We find that, for a large class of risk measures, mean-covariance robust portfolio optimization boils down to the Markowitz model, subject to a regularization term given in closed form. This includes the finance standards, value-at-risk and conditional value-at-risk, and can be solved highly efficiently.</description>
      <guid isPermaLink="false">oai:arXiv.org:2112.09959v3</guid>
      <category>q-fin.PM</category>
      <category>math.OC</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Viet Anh Nguyen, Soroosh Shafiee, Damir Filipovi\'c, Daniel Kuhn</dc:creator>
    </item>
    <item>
      <title>Learning linear dynamical systems under convex constraints</title>
      <link>https://arxiv.org/abs/2303.15121</link>
      <description>arXiv:2303.15121v4 Announce Type: replace-cross 
Abstract: We consider the problem of finite-time identification of linear dynamical systems from $T$ samples of a single trajectory. Recent results have predominantly focused on the setup where either no structural assumption is made on the system matrix $A^* \in \mathbb{R}^{n \times n}$, or specific structural assumptions (e.g. sparsity) are made on $A^*$. We assume prior structural information on $A^*$ is available, which can be captured in the form of a convex set $\mathcal{K}$ containing $A^*$. For the solution of the ensuing constrained least squares estimator, we derive non-asymptotic error bounds in the Frobenius norm that depend on the local size of $\mathcal{K}$ at $A^*$. To illustrate the usefulness of these results, we instantiate them for four examples, namely when (i) $A^*$ is sparse and $\mathcal{K}$ is a suitably scaled $\ell_1$ ball; (ii) $\mathcal{K}$ is a subspace; (iii) $\mathcal{K}$ consists of matrices each of which is formed by sampling a bivariate convex function on a uniform $n \times n$ grid (convex regression); (iv) $\mathcal{K}$ consists of matrices each row of which is formed by uniform sampling (with step size $1/T$) of a univariate Lipschitz function. In all these situations, we show that $A^*$ can be reliably estimated for values of $T$ much smaller than what is needed for the unconstrained setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.15121v4</guid>
      <category>math.ST</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hemant Tyagi, Denis Efimov</dc:creator>
    </item>
    <item>
      <title>An Equilibrium Model for Schedule-Based Transit Networks with Hard Vehicle Capacities</title>
      <link>https://arxiv.org/abs/2406.17153</link>
      <description>arXiv:2406.17153v2 Announce Type: replace-cross 
Abstract: Modelling passenger assignments in public transport networks is a fundamental task for city planners, especially when deliberating network infrastructure decisions. A key aspect of a realistic model is to integrate passengers' selfish routing behaviour under limited vehicle capacities. We formulate a side-constrained user equilibrium model in a schedule-based transit network, where passengers are modelled via a continuum of non-atomic agents that travel from their origin to their destination. An agent's route may comprise several rides along given lines, each using vehicles with hard loading capacities. We give a characterization of (side-constrained) user equilibria via a quasi-variational inequality and prove their existence for fixed departure times by generalizing a well-known result of Bernstein and Smith (Transp. Sci., 1994). We further derive a polynomial time algorithm for single-commodity instances with fixed departure times. For the multi-commodity case with departure time choice, we show that deciding whether an equilibrium exists is NP-hard, and we devise an exponential-time algorithm that computes an equilibrium if it exists, and signals non-existence otherwise. Using our quasi-variational characterization, we formulate a heuristic for computing multi-commodity user equilibria in practice, which is tested on multiple real-world instances. In terms of social cost, the computed user-equilibria are quite efficient compared to a system optimum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17153v2</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tobias Harks, Sven J\"ager, Michael Markl, Philine Schiewe</dc:creator>
    </item>
    <item>
      <title>Graphon Particle Systems, Part II: Dynamics of Distributed Stochastic Continuum Optimization</title>
      <link>https://arxiv.org/abs/2407.02765</link>
      <description>arXiv:2407.02765v3 Announce Type: replace-cross 
Abstract: We study the distributed optimization problem over a graphon with a continuum of nodes, which is regarded as the limit of the distributed networked optimization as the number of nodes goes to infinity. Each node has a private local cost function. The global cost function, which all nodes cooperatively minimize, is the integral of the local cost functions on the node set. We propose stochastic gradient descent and gradient tracking algorithms over the graphon. We establish a general lemma for the upper bound estimation related to a class of time-varying differential inequalities with negative linear terms, based upon which, we prove that for both kinds of algorithms, the second moments of the nodes' states are uniformly bounded. Especially, for the stochastic gradient tracking algorithm, we transform the convergence analysis into the asymptotic property of coupled nonlinear differential inequalities with time-varying coefficients and develop a decoupling method. For both kinds of algorithms, we show that by choosing the time-varying algorithm gains properly, all nodes' states achieve $\mathcal{L}^{\infty}$-consensus for a connected graphon. Furthermore, if the local cost functions are strongly convex, then all nodes' states converge to the minimizer of the global cost function and the auxiliary states in the stochastic gradient tracking algorithm converge to the gradient value of the global cost function at the minimizer uniformly in mean square.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02765v3</guid>
      <category>eess.SY</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yan Chen, Tao Li, Xiaofeng Zong</dc:creator>
    </item>
    <item>
      <title>Almost Sure Convergence of Networked Policy Gradient over Time-Varying Networks in Markov Potential Games</title>
      <link>https://arxiv.org/abs/2410.20075</link>
      <description>arXiv:2410.20075v2 Announce Type: replace-cross 
Abstract: We propose networked policy gradient play for solving Markov potential games with continuous and/or discrete state-action pairs. During the game, agents use parametrized and differentiable policies that depend on the current state and the policy parameters of other agents. During training, agents update their policy parameters following stochastic gradients. The gradient estimation involves two consecutive episodes, generating unbiased estimators of reward and policy score functions. In addition, it involves keeping estimates of others' parameters using consensus steps given local estimates received through a time-varying communication network. In Markov potential games, there exists a potential value function among agents with gradients corresponding to the gradients of local value functions. Using this structure, we prove almost sure convergence to a stationary point of the potential value function with rate $O(1/\epsilon^2)$. Compared to previous works, our results do not require bounded policy gradients or initial agreement on the values of individual policy parameters. Numerical experiments on a dynamic multi-agent newsvendor problem verify the convergence of local beliefs and gradients. It further shows that networked policy gradient play converges as fast as independent policy gradient updates, while collecting higher rewards.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20075v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sarper Aydin, Ceyhun Eksin</dc:creator>
    </item>
    <item>
      <title>Fractional Sobolev paths on Wasserstein spaces and their energy-minimizing particle representations</title>
      <link>https://arxiv.org/abs/2502.12068</link>
      <description>arXiv:2502.12068v4 Announce Type: replace-cross 
Abstract: We study a generalization of the Monge--Kantorovich optimal transport problem. Given a prescribed family of time-dependent probability measures $(\mu_t)$, we aim to find, among all path-continuous stochastic processes whose one-dimensional time marginals coincide with $(\mu_t)$ (if there is any), a process that minimizes a given energy. After discussing a sufficient condition for the energy to ensure the existence of a minimizer, we investigate fractional Sobolev energies. Given a deterministic path $(\mu_t)$ on a $p$-Wasserstein space with fractional Sobolev regularity $W^{\alpha,p}$, where $1/p &lt; \alpha &lt; 1$, we provide conditions under which we prove the existence of a process that minimizes the energy and construct a process that realizes the regularity of $(\mu_t)$. While continuous paths of low regularity on Wasserstein spaces naturally appear in stochastic analysis, they can also arise deterministically as solutions to the continuity equation. This paper is devoted to the deterministic setting to gain some understanding of the required conditions. The subsequent companion paper (arXiv:2503.10859) focuses on the stochastic setting and applications to SPDEs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12068v4</guid>
      <category>math.MG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ehsan Abedi</dc:creator>
    </item>
    <item>
      <title>Construct to Commitment: The Effect of Narratives on Economic Growth</title>
      <link>https://arxiv.org/abs/2504.21060</link>
      <description>arXiv:2504.21060v3 Announce Type: replace-cross 
Abstract: We study how government-led narratives through mass media evolve from construct, a mechanism for framing expectations, into commitment, a sustainable pillar for growth. We propose the "Narratives-Construct-Commitment (NCC)" framework outlining the mechanism and institutionalization of narratives, and formalize it as a dynamic Bayesian game. Using the Innovation-Driven Development Strategy (2016) as a case study, we identify the narrative shock from high-frequency financial data and trace its impact using local projection method. By shaping expectations, credible narratives institutionalize investment incentives, channel resources into R&amp;D, and facilitate sustained improvements in total factor productivity (TFP). Our findings strive to provide insights into the New Quality Productive Forces initiative, highlighting the role of narratives in transforming vision into tangible economic growth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.21060v3</guid>
      <category>physics.soc-ph</category>
      <category>cs.GT</category>
      <category>cs.SI</category>
      <category>econ.EM</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hanyuan Jiang, Yi Man</dc:creator>
    </item>
    <item>
      <title>Pinching-Antenna Systems (PASS): Power Radiation Model and Optimal Beamforming Design</title>
      <link>https://arxiv.org/abs/2505.00218</link>
      <description>arXiv:2505.00218v2 Announce Type: replace-cross 
Abstract: Pinching-antenna systems (PASS) improve wireless links by configuring the locations of activated pinching antennas along dielectric waveguides, namely pinching beamforming. In this paper, a novel adjustable power radiation model is proposed for PASS, where power radiation ratios of pinching antennas can be flexibly controlled by tuning the spacing between pinching antennas and waveguides. A closed-form pinching antenna spacing arrangement strategy is derived to achieve the commonly assumed equal-power radiation. Based on this, a practical PASS framework relying on discrete activation is considered, where pinching antennas can only be activated among a set of predefined locations. A transmit power minimization problem is formulated, which jointly optimizes the transmit beamforming, pinching beamforming, and the numbers of activated pinching antennas, subject to each user's minimum rate requirement. (1) To solve the resulting highly coupled mixed-integer nonlinear programming (MINLP) problem, branch-and-bound (BnB)-based algorithms are proposed for both single-user and multi-user scenarios, which is guaranteed to converge to globally optimal solutions. (2) A low-complexity many-to-many matching algorithm is further developed. Combined with the Karush-Kuhn-Tucker (KKT) theory, locally optimal and pairwise-stable solutions are obtained within polynomial-time complexity. Simulation results demonstrate that: (i) PASS significantly outperforms conventional multi-antenna architectures, particularly when the number of users and the spatial range increase; and (ii) The proposed matching-based algorithm achieves near-optimal performance, resulting in only a slight performance loss while significantly reducing computational overheads. Code is available at https://github.com/xiaoxiaxusummer/PASS_Discrete</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00218v2</guid>
      <category>eess.SP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoxia Xu, Xidong Mu, Zhaolin Wang, Yuanwei Liu, Arumugam Nallanathan</dc:creator>
    </item>
    <item>
      <title>Entropic Risk Optimization in Discounted MDPs: Sample Complexity Bounds with a Generative Model</title>
      <link>https://arxiv.org/abs/2506.00286</link>
      <description>arXiv:2506.00286v2 Announce Type: replace-cross 
Abstract: In this paper, we analyze the sample complexities of learning the optimal state-action value function $Q^*$ and an optimal policy $\pi^*$ in a finite discounted Markov decision process (MDP) where the agent has recursive entropic risk-preferences with risk-parameter $\beta\neq 0$ and where a generative model of the MDP is available. We provide and analyze a simple model based approach which we call model-based risk-sensitive $Q$-value-iteration (MB-RS-QVI) which leads to $(\varepsilon,\delta)$-PAC-bounds on $\|Q^*-Q^k\|$, and $\|V^*-V^{\pi_k}\|$ where $Q_k$ is the output of MB-RS-QVI after k iterations and $\pi_k$ is the greedy policy with respect to $Q_k$. Both PAC-bounds have exponential dependence on the effective horizon $\frac{1}{1-\gamma}$ and the strength of this dependence grows with the learners risk-sensitivity $|\beta|$. We also provide two lower bounds which shows that exponential dependence on $|\beta|\frac{1}{1-\gamma}$ is unavoidable in both cases. The lower bounds reveal that the PAC-bounds are tight in the parameters $S,A,\delta,\varepsilon$ and that unlike in the classical setting it is not possible to have polynomial dependence in all model parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00286v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Oliver Mortensen, Mohammad Sadegh Talebi</dc:creator>
    </item>
  </channel>
</rss>
