<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 24 Jan 2025 05:00:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Scalability Analysis of 5G-TSN Applications in Indoor Factory Settings</title>
      <link>https://arxiv.org/abs/2501.13138</link>
      <description>arXiv:2501.13138v1 Announce Type: new 
Abstract: While technologies such as Time-Sensitive Networking (TSN) improve deterministic behaviour, real-time functionality, and robustness of Ethernet, there is a drive for future industrial networks to be increasingly wireless. While wireless networks facilitate mobility, reduce cost, and simplify deployment, they do not always provide stringent latency constraints and highly dependable data transmission as required by many manufacturing systems. The advent of 5G, with its Ultra-Reliable Low-Latency Communication (URLLC) capabilities, offers potential for wireless industrial networks. 5G guarantees elevated data throughput, very low latency, and negligible jitter. As 5G networks typically include wired connections from the base station to the core network, integration of 5G with time-sensitive networking is essential to provide rigorous QoS standards. The paper assesses the scalability of 5G-TSN for various indoor factory applications and conditions using OMNET++ simulation. Our research shows that 5G-TSN has the potential to provide bounded delay for latency-sensitive applications in scalable indoor factory settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13138v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kouros Zanbouri, Md. Noor-A-Rahim, Dirk Pesch</dc:creator>
    </item>
    <item>
      <title>GWEn -- An Open-Source Wireless Physical-Layer Evaluation Platform</title>
      <link>https://arxiv.org/abs/2501.13144</link>
      <description>arXiv:2501.13144v1 Announce Type: new 
Abstract: Wireless physical layer assessment, such as measuring antenna radiation patterns, is complex and cost-intensive. Researchers often require a stationary setup with antennas surrounding the device under test. There remains a need for more cost-effective and open-source platforms that facilitate such research, particularly in automated testing contexts. This paper introduces the Gimbal-based platform for Wireless Evaluation (GWEn), a lightweight multi-axis positioner designed to portably evaluate wireless systems in real-world scenarios with minimal RF interference. We present an evaluation workflow that utilizes GWEn and show how it supports different types of wireless devices and communication systems, including Ultra-wideband, mmWave, and acoustic communication. GWEn is open-source, combining 3D-printed components with off-the-shelf parts, thus allowing researchers globally to replicate, utilize, and adapt the system according to their specific needs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13144v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Heinrich, Florentin Putz, S\"oren Krollmann, Bastian Loss, Waqar Ahmed, Matthias Hollick</dc:creator>
    </item>
    <item>
      <title>Time-Dependent Network Topology Optimization for LEO Satellite Constellations</title>
      <link>https://arxiv.org/abs/2501.13280</link>
      <description>arXiv:2501.13280v1 Announce Type: new 
Abstract: Today's Low Earth Orbit (LEO) satellite networks, exemplified by SpaceX's Starlink, play a crucial role in delivering global internet access to millions of users. However, managing the dynamic and expansive nature of these networks poses significant challenges in designing optimal satellite topologies over time. In this paper, we introduce the \underline{D}ynamic Time-Expanded Graph (DTEG)-based \underline{O}ptimal \underline{T}opology \underline{D}esign (DoTD) algorithm to tackle these challenges effectively. We first formulate a novel space network topology optimization problem encompassing a multi-objective function -- maximize network capacity, minimize latency, and mitigate link churn -- under key inter-satellite link constraints. Our proposed approach addresses this optimization problem by transforming the objective functions and constraints into a time-dependent scoring function. This empowers each LEO satellite to assess potential connections based on their dynamic performance scores, ensuring robust network performance over time without scalability issues. Additionally, we provide proof of the score function's boundary to prove that it will not approach infinity, thus allowing each satellite to consistently evaluate others over time. For evaluation purposes, we utilize a realistic Mininet-based LEO satellite emulation tool that leverages Starlink's Two-Line Element (TLE) data. Comparative evaluation against two baseline methods -- Greedy and $+$Grid, demonstrates the superior performance of our algorithm in optimizing network efficiency and resilience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13280v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dara Ron, Faisal Ahmed Yusufzai, Sebastian Kwakye, Satyaki Roy, Nishanth Sastry, Vijay K. Shah</dc:creator>
    </item>
    <item>
      <title>Optimizing the Trade-off Between Throughput and PAoI Outage Exponents</title>
      <link>https://arxiv.org/abs/2501.13431</link>
      <description>arXiv:2501.13431v1 Announce Type: new 
Abstract: This paper investigates the trade-off between throughput and peak age of information (PAoI) outage probability in a multi-sensor information collection system. Each sensor monitors a physical process, periodically samples its status, and transmits the updates to a central access point over a shared radio resource. The trade-off arises from the interplay between each sensor's sampling frequency and the allocation of the shared resource. To optimize this trade-off, we formulate a joint optimization problem for each sensor's sampling delay and resource allocation, aiming to minimize a weighted sum of sampling delay costs (representing a weighted sum of throughput) while satisfying PAoI outage probability exponent constraints. We derive an optimal solution and particularly propose a closed-form approximation for large-scale systems. This approximation provides an explicit expression for an approximately optimal trade-off, laying a foundation for designing resource-constrained systems in applications that demand frequent updates and also stringent statistical timeliness guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13431v1</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tai-Chun Yeh, Yu-Pin Hsu</dc:creator>
    </item>
    <item>
      <title>IoT Performance for Maritime Passenger Evacuation</title>
      <link>https://arxiv.org/abs/2501.13508</link>
      <description>arXiv:2501.13508v1 Announce Type: new 
Abstract: The safe and swift evacuation of passengers from Maritime Vessels, requires an effective Internet of Things(IoT) as well as an information and communication technology(ICT) infrastructure. However, during emergencies, delays in IoT and ICT systems that guide evacuees, can impair the evacuation process. This paper presents explores the impact of the key IoT and ICT elements. The methodology builds upon the deadline-aware adaptive navigation strategy (ANT), which offers the path segment that minimizes the evacuation time for each evacuee at each decision instant. The simulations on a real cruise ship configuration, show that delays in the delivery of correct instructions to evacuees can significantly hinder the effectiveness of the evacuation. Our findings stress the need to design robust and computationally fast IoT and ICT systems to support the evacuation of passengers in ships, and underscores the key role played by the IoT in the success of passenger evacuation and safety.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13508v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1109/WF-IoT62078.2024.10811235</arxiv:DOI>
      <arxiv:journal_reference>2024 IEEE 10th World Forum on Internet of Things (WF-IoT). IEEE, 2024: 1-6</arxiv:journal_reference>
      <dc:creator>Yuting Ma, Erol Gelenbe, Kezhong Liu</dc:creator>
    </item>
    <item>
      <title>Occamy: A Preemptive Buffer Management for On-chip Shared-memory Switches</title>
      <link>https://arxiv.org/abs/2501.13570</link>
      <description>arXiv:2501.13570v1 Announce Type: new 
Abstract: Today's high-speed switches employ an on-chip shared packet buffer. The buffer is becoming increasingly insufficient as it cannot scale with the growing switching capacity. Nonetheless, the buffer needs to face highly intense bursts and meet stringent performance requirements for datacenter applications. This imposes rigorous demand on the Buffer Management (BM) scheme, which dynamically allocates the buffer across queues. However, the de facto BM scheme, designed over two decades ago, is ill-suited to meet the requirements of today's network. In this paper, we argue that shallow-buffer switches, intense bursts, along with dynamic traffic call for a highly agile BM that can quickly adjust the buffer allocation as traffic changes. However, the agility of the current BM is fundamentally limited by its non-preemptive nature. Nonetheless, we find that preemptive BM, considered unrealizable in history, is now feasible on modern switch chips. We propose Occamy, a preemptive BM that can quickly adjust buffer allocation. Occamy utilizes the redundant memory bandwidth to actively reclaim and reallocate the over-allocated buffer. Testbed experiments and large-scale simulations show that Occamy can improve the end-to-end performance by up to ~55%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13570v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Danfeng Shan, Yunguang Li, Jinchao Ma, Zhenxing Zhang, Zeyu Liang, Xinyu Wen, Hao Li, Wanchun Jiang, Nan Li, Fengyuan Ren</dc:creator>
    </item>
    <item>
      <title>Combined Routing Protocol (CRP) for ad hoc networks: Combining strengths of location-based and AODV-based schemes</title>
      <link>https://arxiv.org/abs/2501.13671</link>
      <description>arXiv:2501.13671v1 Announce Type: new 
Abstract: The work proposes a new Combined Routing Protocol (CRP) for ad hoc networks that combines the benefits and annihilates the shortcomings of two well-known on-demand routing protocols in ad hoc networks: AODV (which provides a high probability of successfully discovering and maintaining a reliable route) and GPSR (which enables fast on-the-fly transmission based on the geographical coordinates of the destination node). The main idea of the new routing scheme applied in CRP is to use AODV protocol as a solution to the "perimeter problem" of GPSR. And vice versa we apply GPSR for moving the starting point of the AODV route discovering closer to the destination point, decreasing the number of hops and route building time, making the resultant route more stable. As the key result we see decreasing of the average packet delivery time in ad hoc networks with is extremely important for latency-critical applications, such as video streaming or command traffic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13671v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Anton Sergeev, Victor Minchenkov, Aleksei Soldatov, Yaroslav Mazikov</dc:creator>
    </item>
    <item>
      <title>A Comprehensive Framework for Building Highly Secure, Network-Connected Devices: Chip to App</title>
      <link>https://arxiv.org/abs/2501.13716</link>
      <description>arXiv:2501.13716v1 Announce Type: new 
Abstract: The rapid expansion of connected devices has amplified the need for robust and scalable security frameworks. This paper proposes a holistic approach to securing network-connected devices, covering essential layers: hardware, firmware, communication, and application. At the hardware level, we focus on secure key management, reliable random number generation, and protecting critical assets. Firmware security is addressed through mechanisms like cryptographic integrity validation and secure boot processes. For secure communication, we emphasize TLS 1.3 and optimized cipher suites tailored for both standard and resource-constrained devices. To overcome the challenges of IoT, compact digital certificates, such as CBOR, are recommended to reduce overhead and enhance performance. Additionally, the paper explores forward-looking solutions, including post-quantum cryptography, to future-proof systems against emerging threats. This framework provides actionable guidelines for manufacturers and system administrators to build secure devices that maintain confidentiality, integrity, and availability throughout their lifecycle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13716v1</guid>
      <category>cs.NI</category>
      <category>cs.CR</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Khan Reaz, Gerhard Wunder</dc:creator>
    </item>
    <item>
      <title>Centralized Versus Distributed Routing for Large-Scale Satellite Networks</title>
      <link>https://arxiv.org/abs/2501.13744</link>
      <description>arXiv:2501.13744v1 Announce Type: new 
Abstract: An important choice in the design of satellite networks is whether the routing decisions are made in a distributed manner onboard the satellite, or centrally on a ground-based controller. We study the tradeoff between centralized and distributed routing in large-scale satellite networks. In particular, we consider a centralized routing scheme that has access to global but delayed network state information and a distributed routing scheme that has access to local but real-time network state information. For both routing schemes, we analyze the throughput and delay performance of shortest-path algorithms in networks with and without buffers onboard the satellites. We show that distributed routing outperforms centralized routing when the rate of changes in the network link state is comparable to the inherent propagation and transmission delays. In particular, we show that in highly dynamic networks without buffers, the distributed scheme achieves higher throughput than a centralized scheme. In networks with buffers, the distributed scheme achieves lower delays with the same throughput.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13744v1</guid>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rudrapatna Vallabh Ramakanth, Eytan Modiano</dc:creator>
    </item>
    <item>
      <title>A Multi-stage Optimisation Approach to Design Relocation Strategies in One-way Car-sharing Systems with Stackable Cars</title>
      <link>https://arxiv.org/abs/2501.13843</link>
      <description>arXiv:2501.13843v1 Announce Type: new 
Abstract: One of the main operational challenges faced by the operators of one-way car-sharing systems is to ensure vehicle availability across the regions of the service areas with uneven patterns of rental requests. Fleet balancing strategies are required to maximise the demand served while minimising the relocation costs. However, the design of optimal relocation policies is a complex problem, and global optimisation solutions are often limited to very small network sizes for computational reasons. In this work, we propose a multi-stage decision support system for vehicle relocation that decomposes the general relocation problem into three independent decision stages to allow scalable solutions. Furthermore, we adopt a rolling horizon control strategy to cope with demand uncertainty. Our approach is highly modular and flexible, and we leverage it to design user-based, operator-based and robotic relocation schemes. Besides, we formulate the relocation problem considering both conventional cars and a new class of compact stackable vehicles that can be driven in a road train. We compare the proposed relocation schemes with two recognised benchmarks using a large data set of taxi trips in New York. Our results show that our approach is scalable and outperforms the benchmark schemes in terms of quality of service, vehicle utilisation and relocation efficiency. Furthermore, we find that stackable vehicles can achieve a relocation performance close to that of autonomous cars, even with a small workforce of relocators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13843v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TITS.2022.3164989</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Intelligent Transportation Systems, vol. 23, no. 10, pp. 17048-17061, Oct. 2022</arxiv:journal_reference>
      <dc:creator>Riccardo Iacobucci, Raffaele Bruno, Chiara Boldrini</dc:creator>
    </item>
    <item>
      <title>Joint Task Offloading and User Scheduling in 5G MEC under Jamming Attacks</title>
      <link>https://arxiv.org/abs/2501.13227</link>
      <description>arXiv:2501.13227v1 Announce Type: cross 
Abstract: In this paper, we propose a novel joint task offloading and user scheduling (JTO-US) framework for 5G mobile edge computing (MEC) systems under security threats from jamming attacks. The goal is to minimize the delay and the ratio of dropped tasks, taking into account both communication and computation delays. The system model includes a 5G network equipped with MEC servers and an adversarial on-off jammer that disrupts communication. The proposed framework optimally schedules tasks and users to minimize the impact of jamming while ensuring that high-priority tasks are processed efficiently. Genetic algorithm (GA) is used to solve the optimization problem, and the results are compared with benchmark methods such as GA without considering jamming effect, Shortest Job First (SJF), and Shortest Deadline First (SDF). The simulation results demonstrate that the proposed JTO-US framework achieves the lowest drop ratio and effectively manages priority tasks, outperforming existing methods. Particularly, when the jamming probability is 0.8, the proposed framework mitigates the jammer's impact by reducing the drop ratio to 63%, compared to 89% achieved by the next best method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13227v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mohammadreza Amini, Burak Kantarci, Claude D'Amours, Melike Erol-Kantarci</dc:creator>
    </item>
    <item>
      <title>POPS: From History to Mitigation of DNS Cache Poisoning Attacks</title>
      <link>https://arxiv.org/abs/2501.13540</link>
      <description>arXiv:2501.13540v1 Announce Type: cross 
Abstract: We present a novel yet simple and comprehensive DNS cache POisoning Prevention System (POPS), designed to integrate as a module in Intrusion Prevention Systems (IPS). POPS addresses statistical DNS poisoning attacks, including those documented from 2002 to the present, and offers robust protection against similar future threats. It consists of two main components: a detection module that employs three simple rules, and a mitigation module that leverages the TC flag in the DNS header to enhance security. Once activated, the mitigation module has zero false positives or negatives, correcting any such errors on the side of the detection module.
  We first analyze POPS against historical DNS services and attacks, showing that it would have mitigated all network-based statistical poisoning attacks, yielding a success rate of only 0.0076% for the adversary. We then simulate POPS on traffic benchmarks (PCAPs) incorporating current potential network-based statistical poisoning attacks, and benign PCAPs; the simulated attacks still succeed with a probability of 0.0076%. This occurs because five malicious packets go through before POPS detects the attack and activates the mitigation module. In addition, POPS completes its task using only 20%-50% of the time required by other tools (e.g., Suricata or Snort), and after examining just 5%-10% as many packets. Furthermore, it successfully identifies DNS cache poisoning attacks-such as fragmentation attacks-that both Suricata and Snort fail to detect, underscoring its superiority in providing comprehensive DNS protection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13540v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yehuda Afek, Harel Berger, Anat Bremler-Barr</dc:creator>
    </item>
    <item>
      <title>Minimizing Queue Length Regret for Arbitrarily Varying Channels</title>
      <link>https://arxiv.org/abs/2501.13551</link>
      <description>arXiv:2501.13551v1 Announce Type: cross 
Abstract: We consider an online channel scheduling problem for a single transmitter-receiver pair equipped with $N$ arbitrarily varying wireless channels. The transmission rates of the channels might be non-stationary and could be controlled by an oblivious adversary. At every slot, incoming data arrives at an infinite-capacity data queue located at the transmitter. A scheduler, which is oblivious to the current channel rates, selects one of the $N$ channels for transmission. At the end of the slot, the scheduler only gets to know the transmission rate of the selected channel. The objective is to minimize the queue length regret, defined as the difference between the queue length at some time $T$ achieved by an online policy and the queue length obtained by always transmitting over the single best channel in hindsight. We propose a weakly adaptive Multi-Armed Bandit (MAB) algorithm for minimizing the queue length regret in this setup. Unlike previous works, we do not make any stability assumptions about the queue or the arrival process. Hence, our result holds even when the queueing process is unstable. Our main observation is that the queue length regret can be upper bounded by the regret of a MAB policy that competes against the best channel in hindsight uniformly over all sub-intervals of $[T]$. As a technical contribution of independent interest, we then propose a weakly adaptive adversarial MAB policy which achieves $\tilde{O}(\sqrt{N}T^{\frac{3}{4}})$ regret with high probability, implying the same bound for queue length regret.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13551v1</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>G Krishnakumar, Abhishek Sinha</dc:creator>
    </item>
    <item>
      <title>Two Step SOVA-Based Decoding Algorithm for Tailbiting Codes</title>
      <link>https://arxiv.org/abs/2501.13606</link>
      <description>arXiv:2501.13606v1 Announce Type: cross 
Abstract: In this work we propose a novel decoding algorithm for tailbiting convolutional codes and evaluate its performance over different channels. The proposed method consists on a fixed two-step Viterbi decoding of the received data. In the first step, an estimation of the most likely state is performed based on a SOVA decoding. The second step consists of a conventional Viterbi decoding that employs the state estimated in the previous step as the initial and final states of the trellis. Simulations results show a performance close to that of maximum-likelihood decoding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13606v1</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/LCOMM.2009.090810</arxiv:DOI>
      <arxiv:journal_reference>IEEE Communications Letters, volume: 13, issue: 7, July 2009</arxiv:journal_reference>
      <dc:creator>Jorge Ortin, Paloma Garcia, Fernando Gutierrez, Antonio Valdovinos</dc:creator>
    </item>
    <item>
      <title>A Hybrid Reactive Routing Protocol for Decentralized UAV Networks</title>
      <link>https://arxiv.org/abs/2407.02929</link>
      <description>arXiv:2407.02929v2 Announce Type: replace 
Abstract: Wireless networks consisting of low SWaP, FW-UAVs are used in many applications, such as monitoring, search and surveillance of inaccessible areas. A decentralized and autonomous approach ensures robustness to failures; the UAVs explore and sense within the area and forward their information, in a multihop manner, to nearby aerial gateway nodes. However, the unpredictable nature of the events, relatively high speed of UAVs, and dynamic UAV trajectories cause the network topology to change significantly over time, resulting in frequent route breaks. A holistic routing approach is needed to support multiple traffic flows in these networks to provide mobility- and congestion-aware, high-quality routes when needed, with low control and computational overheads, using the information collected in a distributed manner. Existing routing schemes do not address all the mentioned issues.
  We present a hybrid reactive routing protocol for decentralized UAV networks. Our scheme searches routes on-demand, monitors a region around the selected route (the pipe), and proactively switches to an alternative route before the current route's quality degrades below a threshold. We empirically evaluate the impact of pipe width and node density on our ability to find alternate high-quality routes within the pipe and the overhead required to maintain the pipe. Compared to existing reactive routing schemes, our approach achieves higher throughput and reduces the number of route discoveries, overhead, and resulting flow interruptions at different traffic loads, node densities and speeds. Despite having limited network topology information, and low overhead and route computation complexity, our proposed scheme achieves superior throughput to proactive optimized link state routing scheme at different network and traffic settings. We also evaluate the relative performance of reactive and proactive routing schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02929v2</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shivam Garg, Alexander Ihler, Elizabeth Serena Bentley, Sunil Kumar</dc:creator>
    </item>
    <item>
      <title>Adversarial Evasion Attacks Practicality in Networks: Testing the Impact of Dynamic Learning</title>
      <link>https://arxiv.org/abs/2306.05494</link>
      <description>arXiv:2306.05494v3 Announce Type: replace-cross 
Abstract: Machine Learning (ML) has become ubiquitous, and its deployment in Network Intrusion Detection Systems (NIDS) is inevitable due to its automated nature and high accuracy compared to traditional models in processing and classifying large volumes of data. However, ML has been found to have several flaws, most importantly, adversarial attacks, which aim to trick ML models into producing faulty predictions. While most adversarial attack research focuses on computer vision datasets, recent studies have explored the suitability of these attacks against ML-based network security entities, especially NIDS, due to the wide difference between different domains regarding the generation of adversarial attacks.
  To further explore the practicality of adversarial attacks against ML-based NIDS in-depth, this paper presents three distinct contributions: identifying numerous practicality issues for evasion adversarial attacks on ML-NIDS using an attack tree threat model, introducing a taxonomy of practicality issues associated with adversarial attacks against ML-based NIDS, and investigating how the dynamicity of some real-world ML models affects adversarial attacks against NIDS. Our experiments indicate that continuous re-training, even without adversarial training, can reduce the effectiveness of adversarial attacks. While adversarial attacks can compromise ML-based NIDSs, our aim is to highlight the significant gap between research and real-world practicality in this domain, warranting attention.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.05494v3</guid>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Mohamed elShehaby, Ashraf Matrawy</dc:creator>
    </item>
    <item>
      <title>What If We Had Used a Different App? Reliable Counterfactual KPI Analysis in Wireless Systems</title>
      <link>https://arxiv.org/abs/2410.00150</link>
      <description>arXiv:2410.00150v3 Announce Type: replace-cross 
Abstract: In modern wireless network architectures, such as Open Radio Access Network (O-RAN), the operation of the radio access network (RAN) is managed by applications, or apps for short, deployed at intelligent controllers. These apps are selected from a given catalog based on current contextual information. For instance, a scheduling app may be selected on the basis of current traffic and network conditions. Once an app is chosen and run, it is no longer possible to directly test the key performance indicators (KPIs) that would have been obtained with another app. In other words, we can never simultaneously observe both the actual KPI, obtained by the selected app, and the counterfactual KPI, which would have been attained with another app, for the same network condition, making individual-level counterfactual KPIs analysis particularly challenging. This what-if analysis, however, would be valuable to monitor and optimize the network operation, e.g., to identify suboptimal app selection strategies. This paper addresses the problem of estimating the values of KPIs that would have been obtained if a different app had been implemented by the RAN. To this end, we propose a conformal-prediction-based counterfactual analysis method for wireless systems that provides reliable error bars for the estimated KPIs, despite the inherent covariate shift between logged and test data. Experimental results for medium access control-layer apps and for physical-layer apps demonstrate the merits of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00150v3</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiushuo Hou, Sangwoo Park, Matteo Zecchin, Yunlong Cai, Guanding Yu, Osvaldo Simeone</dc:creator>
    </item>
  </channel>
</rss>
