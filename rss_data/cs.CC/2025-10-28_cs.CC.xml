<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 29 Oct 2025 01:47:37 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>NP-Completeness Proofs of All or Nothing and Water Walk Using the T-Metacell Framework</title>
      <link>https://arxiv.org/abs/2510.21938</link>
      <description>arXiv:2510.21938v1 Announce Type: new 
Abstract: All or Nothing and Water Walk are pencil puzzles that involve constructing a continuous loop on a rectangular grid under specific constraints. In this paper, we analyze their computational complexity using the T-metacell framework developed by Tang and MIT Hardness Group. We establish that both puzzles are NP-complete by providing reductions from the problem of finding a Hamiltonian cycle in a maximum-degree-3 spanning subgraph of a rectangular grid graph.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21938v1</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pakapim Eua-anant, Papangkorn Apinyanon, Thunyatorn Jirachaisri, Nantapong Ruangsuksriwong, Suthee Ruangwises</dc:creator>
    </item>
    <item>
      <title>A Critique of Quigley's "A Polynomial Time Algorithm for 3SAT"</title>
      <link>https://arxiv.org/abs/2510.22985</link>
      <description>arXiv:2510.22985v1 Announce Type: new 
Abstract: In this paper, we examine Quigley's "A Polynomial Time Algorithm for 3SAT" [Qui24]. Quigley claims to construct an algorithm that runs in polynomial time and determines whether a boolean formula in 3CNF form is satisfiable. Such a result would prove that 3SAT $\in \text{P}$ and thus $\text{P} = \text{NP}$. We show Quigley's argument is flawed by providing counterexamples to several lemmas he attempts to use to justify the correctness of his algorithm. We also provide an infinite class of 3CNF formulas that are unsatisfiable but are classified as satisfiable by Quigley's algorithm. In doing so, we prove that Quigley's algorithm fails on certain inputs, and thus his claim that $\text{P} = \text{NP}$ is not established by his paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22985v1</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicholas DeJesse, Spencer Lyudovyk, Dhruv Pai</dc:creator>
    </item>
    <item>
      <title>Computational Hardness of Reinforcement Learning with Partial $q^{\pi}$-Realizability</title>
      <link>https://arxiv.org/abs/2510.21888</link>
      <description>arXiv:2510.21888v1 Announce Type: cross 
Abstract: This paper investigates the computational complexity of reinforcement learning in a novel linear function approximation regime, termed partial $q^{\pi}$-realizability. In this framework, the objective is to learn an $\epsilon$-optimal policy with respect to a predefined policy set $\Pi$, under the assumption that all value functions for policies in $\Pi$ are linearly realizable. The assumptions of this framework are weaker than those in $q^{\pi}$-realizability but stronger than those in $q^*$-realizability, providing a practical model where function approximation naturally arises. We prove that learning an $\epsilon$-optimal policy in this setting is computationally hard. Specifically, we establish NP-hardness under a parameterized greedy policy set (argmax) and show that - unless NP = RP - an exponential lower bound (in feature vector dimension) holds when the policy set contains softmax policies, under the Randomized Exponential Time Hypothesis. Our hardness results mirror those in $q^*$-realizability and suggest computational difficulty persists even when $\Pi$ is expanded beyond the optimal policy. To establish this, we reduce from two complexity problems, $\delta$-Max-3SAT and $\delta$-Max-3SAT(b), to instances of GLinear-$\kappa$-RL (greedy policy) and SLinear-$\kappa$-RL (softmax policy). Our findings indicate that positive computational results are generally unattainable in partial $q^{\pi}$-realizability, in contrast to $q^{\pi}$-realizability under a generative access model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21888v1</guid>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shayan Karimi, Xiaoqi Tan</dc:creator>
    </item>
    <item>
      <title>Noisy nonlinear information and entropy numbers</title>
      <link>https://arxiv.org/abs/2510.23213</link>
      <description>arXiv:2510.23213v1 Announce Type: cross 
Abstract: It is impossible to recover a vector from $\mathbb{R}^m$ with less than $m$ linear measurements, even if the measurements are chosen adaptively. Recently, it has been shown that one can recover vectors from $\mathbb{R}^m$ with arbitrary precision using only $O(\log m)$ continuous (even Lipschitz) adaptive measurements, resulting in an exponential speed-up of continuous information compared to linear information for various approximation problems. In this note, we characterize the quality of optimal (dis-)continuous information that is disturbed by deterministic noise in terms of entropy numbers. This shows that in the presence of noise the potential gain of continuous over linear measurements is limited, but significant in some cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23213v1</guid>
      <category>math.NA</category>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Krieg, Erich Novak, Leszek Plaskota, Mario Ullrich</dc:creator>
    </item>
    <item>
      <title>Problems from Optimization and Computational Algebra Equivalent to Hilbert's Nullstellensatz</title>
      <link>https://arxiv.org/abs/2510.19704</link>
      <description>arXiv:2510.19704v2 Announce Type: replace 
Abstract: Efficient algorithms for many problems in optimization and computational algebra often arise from casting them as systems of polynomial equations. Blum, Shub, and Smale formalized this as Hilbert's Nullstellensatz Problem $HN_R$: given multivariate polynomials over a ring $R$, decide whether they have a common solution in $R$. We can also view $HN_R$ as a complexity class by taking the downward closure of the problem $HN_R$ under polynomial-time many-one reductions. In this work, we show that many important problems from optimization and algebra are complete or hard for this class.
  We first consider the Affine Polynomial Projection Problem: given polynomials $f,g$, does an affine projection of the variables transform $f$ into $g$? We show that this problem is at least as hard as $HN_F$ for any field $F$. Then we consider the Sparse Shift Problem: given a polynomial, can its number of monomials be reduced by an affine shift of the variables? Prior $HN_R$-hardness for this problem was known for non-field integral domains $R$, which we extend to fields.
  For the special case of the real field, HN captures the existential theory of the reals and its complement captures the universal theory of the reals. We prove that the problems of deciding real stability, convexity, and hyperbolicity of a given polynomial are all complete for the universal theory of the reals, thereby pinning down their exact complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19704v2</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Markus Bl\"aser, Sagnik Dutta, Gorav Jindal</dc:creator>
    </item>
    <item>
      <title>Subset Sum in Near-Linear Pseudopolynomial Time and Polynomial Space</title>
      <link>https://arxiv.org/abs/2508.04726</link>
      <description>arXiv:2508.04726v3 Announce Type: replace-cross 
Abstract: Given a multiset $A = \{a_1, \dots, a_n\}$ of positive integers and a target integer $t$, the Subset Sum problem asks if there is a subset of $A$ that sums to $t$. Bellman's [1957] classical dynamic programming algorithm runs in $O(nt)$ time and $O(t)$ space. Since then, much work has been done to reduce both the time and space usage.
  Notably, Bringmann [SODA 2017] uses a two-step color-coding technique to obtain a randomized algorithm that runs in $\tilde{O}(n+t)$ time and $\tilde{O}(t)$ space. Jin, Vyas and Williams [SODA 2021] build upon the algorithm given by Bringmann, using a clever algebraic trick first seen in Kane's Logspace algorithm, to obtain an $\tilde{O}(nt)$ time and $\tilde{O}(\log(nt))$ space randomized algorithm. A SETH-based lower-bound established by Abboud et al. [SODA 2019] shows that Bringmann's algorithm is likely to have near-optimal time complexity.
  We build on the techniques used by Jin et al. to obtain a randomized algorithm running in $\tilde{O}(n+t)$ time and $\tilde{O}(n^2 + n \log^2 t)$ space, resulting in an algorithm with near-optimal runtime that also runs in polynomial space. We use a multipoint evaluation-based approach to speed up a bottleneck step in their algorithm.
  We also provide a simple polynomial space deterministic algorithm that runs in $\tilde{O}(n^2t)$ time and $\tilde{O}(n \log^2 t)$ space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04726v3</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Thejas Radhika Sajith</dc:creator>
    </item>
  </channel>
</rss>
