<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 22 Sep 2025 04:00:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Decentralized Estimation and Control for Leader-Follower Networked Systems with Asymmetric Information Structure</title>
      <link>https://arxiv.org/abs/2509.15467</link>
      <description>arXiv:2509.15467v1 Announce Type: new 
Abstract: In this paper, the decentralized estimation and linear quadratic (LQ) control problem for a leader-follower networked system (LFNS) is studied from the perspective of asymmetric information. Specifically, for a leader-follower network, the follower agent will be affected by the leader agent, while the follower agent will not affect the leader agent. Hence, the information sets accessed by the control variables of the leader agent and the follower agent are asymmetric, which will bring essential difficulties in finding the optimal control strategy. To this end, the orthogonal decomposition method is adopted to achieve the main results. The main contributions of this paper can be summarized as follows: Firstly, the optimal iterative estimation is derived using the conditional independence property established in this paper. Secondly, the optimal decentralized control strategy is derived by decoupling the forward-backward stochastic difference equations (FBSDEs), based on the derived optimal iterative estimation. Thirdly, the necessary and sufficient conditions for the feedback stabilization of the LFNS in infinite-horizon are derived. Finally, the proposed theoretical results are applied to solve the decentralized control problem of a leader-follower autonomous underwater vehicle (LF-AUV) system. The optimal control inputs for the AUVs are provided, and simulation results verify the effectiveness of the obtained results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15467v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiting Luo, Wei Wang, Qingyuan Qi, Yang Liu, Jian Xu</dc:creator>
    </item>
    <item>
      <title>Introducing the method of ellipcenters, a new first order technique for unconstrained optimization</title>
      <link>https://arxiv.org/abs/2509.15471</link>
      <description>arXiv:2509.15471v1 Announce Type: new 
Abstract: In this paper, we introduce the Method of Ellipcenters (ME) for unconstrained minimization. At the cost of two gradients per iteration and a line search, we compute the next iterate by setting it as the center of an elliptical interpolation. The idea behind the ellipse built in each step is to emulate the original level curve of the objective function constrained to a suitable two-dimensional affine space, which is determined by the current iterate and two appropriate gradient vectors. We present the method for general unconstrained minimization and carry out a convergence analysis for the case where the objective function is quadratic. In this context, ME enjoys linear convergence with the rate being at least as good as the linear rate of the steepest descent (gradient) method with optimal step. In our experiments, however, ME was much faster than the gradient method with optimal step size. Moreover, ME seems highly competitive in comparison to several well established algorithms, including Nesterov's accelerated gradient, Barzilai-Borwein, and conjugate gradient. The efficiency in terms of both time and number of iterations is stressed even more for ill-conditioned problems. A theoretical feature that might be a reason for this is that ME coincides with Newton for quadratic programs in two-dimensional Euclidean spaces, solving them in one single step. In our numerical tests, convergence in one iteration only was also observed for much larger problem sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15471v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roger Behling, Ramyro Aquines Correa, Eduarda Ferreira Zanatta, Vincent Guigues</dc:creator>
    </item>
    <item>
      <title>Time-inconsistent reinsurance and investment optimization problem with delay under random risk aversion</title>
      <link>https://arxiv.org/abs/2509.15506</link>
      <description>arXiv:2509.15506v1 Announce Type: new 
Abstract: This paper considers a newly delayed reinsurance and investment optimization problem incorporating random risk aversion, in which an insurer pursues maximization of the expected certainty equivalent of her/his terminal wealth and the cumulative delayed information of the wealth over a period. Specially, the insurer's surplus dynamics are approximated using a drifted Brownian motion, while the financial market is described by the Black-Scholes model. Moreover, the performance-linked capital flow feature is incorporated and the wealth process is formulated via a stochastic delay differential equation (SDDE). By adopting a game-theoretic approach, a verification theorem with rigorous proofs is established to capture the equilibrium reinsurance and investment strategy along with the equilibrium value function. Furthermore, for the cases of exponential utility and power utility, analytical or semi-analytical equilibrium reinsurance and investment strategies together with their equilibrium value functions are obtained under mild conditions. Finally, several numerical experiments are conducted to analyze the behavioral characteristics of the freshly-derived equilibrium reinsurance and investment strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15506v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jian-hao Kang, Zhun Gou, Nan-jing Huang</dc:creator>
    </item>
    <item>
      <title>Uniform Sampling from the Reachable Set Using Optimal Transport</title>
      <link>https://arxiv.org/abs/2509.15571</link>
      <description>arXiv:2509.15571v1 Announce Type: new 
Abstract: Finding the reachable set of a system has a wide range of applications, but is a fundamental challenge in control theory, especially when controls are bounded. Although one can simply integrate the system samples forward in time by applying random admissible control to approximate the reachable set, the samples typically cluster near an attractor (if one is present) -- yielding a poor representation of the reachable set. A better representation can be found by applying controls that specifically lead to a uniform terminal state distribution, however, finding such controls is non-trivial. To find such controls, one must solve an Optimal Transport (OT) problem with uniform measure as the target distribution, which is difficult since the reachable set is not know \emph{a priori}.
  We can overcome this difficulty by softening the terminal measure constraint via the introduction of a $L_2$-entropy function in the objective and can further reduce this infinite-dimensional regularized OT to a finite-dimensional particle-based optimal control problem by using a nonlocal kernel regularization of the entropy. This leads to a hierarchy of optimization problems whose solutions converge to the original reachability sampling OT problem, as proved by $\Gamma$-convergence. The effectiveness of this entropy-regularized particle-based approach for uniform sampling of reachable set is demonstrated using numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15571v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karthik Elamvazhuthi, Sachin Shivakumar</dc:creator>
    </item>
    <item>
      <title>Bridging Batch and Streaming Estimations to System Identification under Adversarial Attacks</title>
      <link>https://arxiv.org/abs/2509.15794</link>
      <description>arXiv:2509.15794v1 Announce Type: new 
Abstract: System identification in modern engineering systems faces emerging challenges from unanticipated adversarial attacks beyond existing detection mechanisms. In this work, we obtain a provably accurate estimate of the Markov parameter matrix of order $k$ to identify partially observed linear systems, in which the probability of having an attack at each time is $O(1/k)$. We show that given the batch data accumulated up to time $T^*$, the $\ell_2$-norm estimator achieves an error decaying exponentially as $k$ grows. We then propose a stochastic projected subgradient descent algorithm on streaming data that produces an estimate at each time $t&lt;T^*$, in which case the expected estimation error proves to be the larger of $O(k/\sqrt{t})$ and an exponentially decaying term in $k$. This stochastic approach illustrates how non-smooth estimators can leverage first-order methods despite lacking recursive formulas. Finally, we integrate batch and streaming estimations to recover the Hankel matrix using the appropriate estimates of the Markov parameter matrix, which enables the synthesis of a robust adaptive controller based on the estimated balanced truncated model under adversarial attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15794v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jihun Kim, Javad Lavaei</dc:creator>
    </item>
    <item>
      <title>Escaping saddle points without Lipschitz smoothness: the power of nonlinear preconditioning</title>
      <link>https://arxiv.org/abs/2509.15817</link>
      <description>arXiv:2509.15817v1 Announce Type: new 
Abstract: We study generalized smoothness in nonconvex optimization, focusing on $(L_0, L_1)$-smoothness and anisotropic smoothness. The former was empirically derived from practical neural network training examples, while the latter arises naturally in the analysis of nonlinearly preconditioned gradient methods. We introduce a new sufficient condition that encompasses both notions, reveals their close connection, and holds in key applications such as phase retrieval and matrix factorization. Leveraging tools from dynamical systems theory, we then show that nonlinear preconditioning -- including gradient clipping -- preserves the saddle point avoidance property of classical gradient descent. Crucially, the assumptions required for this analysis are actually satisfied in these applications, unlike in classical results that rely on restrictive Lipschitz smoothness conditions. We further analyze a perturbed variant that efficiently attains second-order stationarity with only logarithmic dependence on dimension, matching similar guarantees of classical gradient methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15817v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alexander Bodard, Panagiotis Patrinos</dc:creator>
    </item>
    <item>
      <title>An optimal-control framework for reaction diffusion systems with application to synthetic developmental biology</title>
      <link>https://arxiv.org/abs/2509.15889</link>
      <description>arXiv:2509.15889v1 Announce Type: new 
Abstract: Reaction-diffusion systems offer a powerful framework for understanding self-organized patterns in biological systems, yet controlling these patterns remains a significant challenge. As a consequence, we present a rigorous framework of optimal control for a class of coupled reaction-diffusion systems. The couplings are justified by the shared regulatory mechanisms encountered in synthetic biology. Furthermore, we introduce inputs and polynomial input-gain functions to guarantee well-posedness of the control system while maintaining biological relevance. As a result, we formulate an optimal control problem and derive necessary optimality conditions. We demonstrate our framework on an instance of such equations modeling the Nodal-Lefty interactions in mammalian cells. Numerical simulations showcase the effectiveness in directing pattern towards diverse targeted ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15889v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohamed Amine Ouchdiri, Hamza Faquir, Saad Benjelloun, Mohamed Adlene Maghenem, Irene Otero-Muras, Adnane Saoud</dc:creator>
    </item>
    <item>
      <title>Enforcing Convergence in Sensitivity-based Distributed Programming via Transformed Primal-Dual Updates</title>
      <link>https://arxiv.org/abs/2509.15938</link>
      <description>arXiv:2509.15938v1 Announce Type: new 
Abstract: Sensitivity-based distributed programming (SBDP) is an algorithm for solving large-scale, nonlinear programs over graph-structured networks. However, its convergence depends on the coupling strength and structure between subsystems. To address this limitation, we develop an algorithmic variant: SBDP+. The proposed method utilizes first-order sensitivities and primal decomposition to formulate low-dimensional, decoupled subproblems, which are solved in parallel with neighbor-to-neighbor communication. SBDP+ differs from SBDP by enforcing convergence for all coupling structures through a carefully designed primal-dual update. It retains a low communication effort and handles couplings in the objective and constraints. We establish sufficient conditions for local convergence in the non-convex case. The effectiveness of the method is shown by solving various distributed optimization problems, including statistical learning, with a comparison to state-of-the-art algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15938v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maximilian Pierer von Esch, Andreas V\"olz, Knut Graichen</dc:creator>
    </item>
    <item>
      <title>Extremal Steklov-Neumann Eigenvalues</title>
      <link>https://arxiv.org/abs/2509.15975</link>
      <description>arXiv:2509.15975v1 Announce Type: new 
Abstract: Let $\Omega$ be a bounded open planar domain with smooth connected boundary, $\Gamma$, that has been partitioned into two disjoint components, $\Gamma = \Gamma_S \sqcup \Gamma_N$. We consider the Steklov-Neumann eigenproblem on $\Omega$, where a harmonic function is sought that satisfies the Steklov boundary condition on $\Gamma_S$ and the Neumann boundary condition on $\Gamma_N$. We pose the extremal eigenvalue problems (EEPs) of minimizing/maximizing the $k$-th non-trivial Steklov-Neumann eigenvalue among boundary partitions of prescribed measure. We formulate a relaxation of these EEPs in terms of weighted Steklov eigenvalues where an $L^\infty(\Gamma)$ density replaces the boundary partition. For these relaxed EEPs, we establish existence, prove optimality conditions, show that the maximization problem is convex for $k=1$ and non-convex for $k\geq 2$, and establish symmetry properties for the maximizing densities for $k=1$. We also prove a homogenization result that allows us to use solutions to the relaxed EEPs to infer properties of solutions to the original EEPs. For a disk, we provide numerical and asymptotic evidence that the minimizing arrangement of $\Gamma_S\sqcup \Gamma_N$ for the $k$-th eigenvalue consists of $k+1$ connected components that are symmetrically arranged on the boundary. For a disk, we prove that for $k = 1$, the constant density is a maximizer for the relaxed problem; we also provide numerical and asymptotic evidence that for $k\ge 2$, the maximizing density for the relaxed problem is a non-trivial function; a sequence of rapidly oscillating Steklov/Neumann boundary conditions approach the supremum value.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15975v1</guid>
      <category>math.OC</category>
      <category>math.SP</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Chiu-Yen Kao, Braxton Osting, Chee Han Tan, Robert Viator</dc:creator>
    </item>
    <item>
      <title>A generalized canonical metric for optimization on the indefinite Stiefel manifold</title>
      <link>https://arxiv.org/abs/2509.16113</link>
      <description>arXiv:2509.16113v1 Announce Type: new 
Abstract: Various tasks in scientific computing can be modeled as an optimization problem on the indefinite Stiefel manifold. We address this using the Riemannian approach, which basically consists of equipping the feasible set with a Riemannian metric, preparing geometric tools such as orthogonal projections, formulae for Riemannian gradient, retraction and then extending an unconstrained optimization algorithm on the Euclidean space to the established manifold. The choice for the metric undoubtedly has a great influence on the method. In the previous work [D.V. Tiep and N.T. Son, A Riemannian gradient descent method for optimization on the indefinite Stiefel manifold, arXiv:2410.22068v2[math.OC]], a tractable metric, which is indeed a family of Riemannian metrics defined by a symmetric positive-definite matrix depending on the contact point, has been used. In general, it requires solving a Lyapunov matrix equation every time when the gradient of the cost function is needed, which might significantly contribute to the computational cost. To address this issue, we propose a new Riemannian metric for the indefinite Stiefel manifold. Furthermore, we construct the associated geometric structure, including a so-called quasi-geodesic and propose a retraction based on this curve. We then numerically verify the performance of the Riemannian gradient descent method associated with the new geometry and compare it with the previous work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.16113v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dinh Van Tiep, Duong Thi Viet An, Nguyen Thi Ngoc Oanh, Nguyen Thanh Son</dc:creator>
    </item>
    <item>
      <title>Classical and Quantum Heuristics for the Binary Paint Shop Problem</title>
      <link>https://arxiv.org/abs/2509.15294</link>
      <description>arXiv:2509.15294v1 Announce Type: cross 
Abstract: The Binary Paint Shop Problem (BPSP) is an $\mathsf{APX}$-hard optimisation problem in automotive manufacturing: given a sequence of $2n$ cars, comprising $n$ distinct models each appearing twice, the task is to decide which of two colours to paint each car so that the two occurrences of each model are painted differently, while minimising consecutive colour swaps. The key performance metric is the paint swap ratio, the average number of colour changes per car, which directly impacts production efficiency and cost. Prior work showed that the Quantum Approximate Optimisation Algorithm (QAOA) at depth $p=7$ achieves a paint swap ratio of $0.393$, outperforming the classical Recursive Greedy (RG) heuristic with an expected ratio of $0.4$ [Phys. Rev. A 104, 012403 (2021)]. More recently, the classical Recursive Star Greedy (RSG) heuristic was conjectured to achieve an expected ratio of $0.361$. In this study, we develop the theoretical foundations for applying QAOA to BPSP through a reduction of BPSP to weighted MaxCut, and use this framework to benchmark two state-of-the-art low-depth QAOA variants, eXpressive QAOA (XQAOA) and Recursive QAOA (RQAOA), at $p=1$ (denoted XQAOA$_1$ and RQAOA$_1$), against the strongest classical heuristics known to date. Across instances ranging from $2^7$ to $2^{12}$ cars, XQAOA$_1$ achieves an average ratio of $0.357$, surpassing RQAOA$_1$ and all classical heuristics, including the conjectured performance of RSG. Surprisingly, RQAOA$_1$ shows diminishing performance as size increases: despite using provably optimal QAOA$_1$ parameters at each recursion, it is outperformed by RSG on most $2^{11}$-car instances and all $2^{12}$-car instances. To our knowledge, this is the first study to report RQAOA$_1$'s performance degradation at scale. In contrast, XQAOA$_1$ remains robust, indicating strong potential to asymptotically surpass all known heuristics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15294v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.ET</category>
      <category>math.OC</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>V Vijendran, Dax Enshan Koh, Ping Koy Lam, Syed M Assad</dc:creator>
    </item>
    <item>
      <title>Adaptive Algorithms with Sharp Convergence Rates for Stochastic Hierarchical Optimization</title>
      <link>https://arxiv.org/abs/2509.15399</link>
      <description>arXiv:2509.15399v1 Announce Type: cross 
Abstract: Hierarchical optimization refers to problems with interdependent decision variables and objectives, such as minimax and bilevel formulations. While various algorithms have been proposed, existing methods and analyses lack adaptivity in stochastic optimization settings: they cannot achieve optimal convergence rates across a wide spectrum of gradient noise levels without prior knowledge of the noise magnitude. In this paper, we propose novel adaptive algorithms for two important classes of stochastic hierarchical optimization problems: nonconvex-strongly-concave minimax optimization and nonconvex-strongly-convex bilevel optimization. Our algorithms achieve sharp convergence rates of $\widetilde{O}(1/\sqrt{T} + \sqrt{\bar{\sigma}}/T^{1/4})$ in $T$ iterations for the gradient norm, where $\bar{\sigma}$ is an upper bound on the stochastic gradient noise. Notably, these rates are obtained without prior knowledge of the noise level, thereby enabling automatic adaptivity in both low and high-noise regimes. To our knowledge, this work provides the first adaptive and sharp convergence guarantees for stochastic hierarchical optimization. Our algorithm design combines the momentum normalization technique with novel adaptive parameter choices. Extensive experiments on synthetic and deep learning tasks demonstrate the effectiveness of our proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15399v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaochuan Gong, Jie Hao, Mingrui Liu</dc:creator>
    </item>
    <item>
      <title>Hierarchical Reinforcement Learning with Low-Level MPC for Multi-Agent Control</title>
      <link>https://arxiv.org/abs/2509.15799</link>
      <description>arXiv:2509.15799v1 Announce Type: cross 
Abstract: Achieving safe and coordinated behavior in dynamic, constraint-rich environments remains a major challenge for learning-based control. Pure end-to-end learning often suffers from poor sample efficiency and limited reliability, while model-based methods depend on predefined references and struggle to generalize. We propose a hierarchical framework that combines tactical decision-making via reinforcement learning (RL) with low-level execution through Model Predictive Control (MPC). For the case of multi-agent systems this means that high-level policies select abstract targets from structured regions of interest (ROIs), while MPC ensures dynamically feasible and safe motion. Tested on a predator-prey benchmark, our approach outperforms end-to-end and shielding-based RL baselines in terms of reward, safety, and consistency, underscoring the benefits of combining structured learning with model-based control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15799v1</guid>
      <category>eess.SY</category>
      <category>cs.AI</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Max Studt, Georg Schildbach</dc:creator>
    </item>
    <item>
      <title>Regularity properties of distributions of correspondences without countable generation: applications to large games</title>
      <link>https://arxiv.org/abs/2509.15898</link>
      <description>arXiv:2509.15898v1 Announce Type: cross 
Abstract: We show that each of the regularity properties of regular conditional distributions of correspondences (convexity, closedness, compactness, and preservation of closed graphs) is equivalent to the condition of nowhere equivalence. This result does not require any countable-generation assumptions. As an application, we establish the existence of a pure-strategy equilibrium for large games with general trait spaces. The trait space may be an arbitrary measurable space. As a corollary, we obtain the existence of a pure-strategy equilibrium in semi-anonymous settings in which payoffs depend, in addition to agents' own actions, on the joint distribution over the space of agents and actions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15898v1</guid>
      <category>math.PR</category>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Motoki Otsuka</dc:creator>
    </item>
    <item>
      <title>An MPC framework for efficient navigation of mobile robots in cluttered environments</title>
      <link>https://arxiv.org/abs/2509.15917</link>
      <description>arXiv:2509.15917v1 Announce Type: cross 
Abstract: We present a model predictive control (MPC) framework for efficient navigation of mobile robots in cluttered environments. The proposed approach integrates a finite-segment shortest path planner into the finite-horizon trajectory optimization of the MPC. This formulation ensures convergence to dynamically selected targets and guarantees collision avoidance, even under general nonlinear dynamics and cluttered environments. The approach is validated through hardware experiments on a small ground robot, where a human operator dynamically assigns target locations. The robot successfully navigated through complex environments and reached new targets within 2-3 seconds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15917v1</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johannes K\"ohler, Daniel Zhang, Raffaele Soloperto, Andrea Carron, Melanie Zeilinger</dc:creator>
    </item>
    <item>
      <title>Localmax dynamics for attention in transformers and its asymptotic behavior</title>
      <link>https://arxiv.org/abs/2509.15958</link>
      <description>arXiv:2509.15958v1 Announce Type: cross 
Abstract: We introduce a new discrete-time attention model, termed the localmax dynamics, which interpolates between the classic softmax dynamics and the hardmax dynamics, where only the tokens that maximize the influence toward a given token have a positive weight. As in hardmax, uniform weights are determined by a parameter controlling neighbor influence, but the key extension lies in relaxing neighborhood interactions through an alignment-sensitivity parameter, which allows controlled deviations from pure hardmax behavior. As we prove, while the convex hull of the token states still converges to a convex polytope, its structure can no longer be fully described by a maximal alignment set, prompting the introduction of quiescent sets to capture the invariant behavior of tokens near vertices. We show that these sets play a key role in understanding the asymptotic behavior of the system, even under time-varying alignment sensitivity parameters. We further show that localmax dynamics does not exhibit finite-time convergence and provide results for vanishing, nonzero, time-varying alignment-sensitivity parameters, recovering the limiting behavior of hardmax as a by-product. Finally, we adapt Lyapunov-based methods from classical opinion dynamics, highlighting their limitations in the asymmetric setting of localmax interactions and outlining directions for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15958v1</guid>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Henri Cimeti\`ere, Maria Teresa Chiri, Bahman Gharesifard</dc:creator>
    </item>
    <item>
      <title>Viscosity and minimax solutions for path-dependent Hamilton-Jacobi equations in infinite dimensions and related differential games</title>
      <link>https://arxiv.org/abs/2509.16015</link>
      <description>arXiv:2509.16015v1 Announce Type: cross 
Abstract: We establish new results for path-dependent Hamilton-Jacobi equations with nonlinear monotone, and coercive operators on Hilbert space, which were initially studied in Bayraktar and Keller [J. Funct. Anal., 275 (8) (2018), pp. 2096-2161]. Under more general assumptions than in the cited paper (and more general than in the finite-dimensional case as well), we prove the uniqueness of a minimax solution of a terminal-value problem for the equation under consideration and the existence of such a solution on the whole path space. We introduce a new notion of a viscosity solution for this problem and show the equivalence of this notion to the notion of a minimax solution, which implies the corresponding existence and uniqueness theorem for viscosity solutions. In addition, we obtain a stability result for viscosity solutions using the half-relaxed limits method. As applications, we prove two theorems on the existence and characterization of value of a zero-sum differential game for a time-delay (path-dependent) evolution equation. The first theorem pertains to the case of non-anticipative (Elliott-Kalton) strategies and is related to the results on viscosity solutions, and the second theorem deals with the case of feedback (Krasovskii-Subbotin) strategies and is based on the results on minimax solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.16015v1</guid>
      <category>math.AP</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erhan Bayraktar, Mikhail Gomoyunov, Christian Keller</dc:creator>
    </item>
    <item>
      <title>On the Number of Control Nodes of Threshold and XOR Boolean Networks</title>
      <link>https://arxiv.org/abs/2509.16077</link>
      <description>arXiv:2509.16077v1 Announce Type: cross 
Abstract: Boolean networks (BNs) are important models for gene regulatory networks and many other biological systems. In this paper, we study the minimal controllability problem of threshold and XOR BNs with degree constraints. Firstly, we derive lower-bound-related inequalities and some upper bounds for the number of control nodes of several classes of controllable majority-type threshold BNs. Secondly, we construct controllable majority-type BNs and BNs involving Boolean threshold functions with both positive and negative coefficients such that these BNs are associated with a small number of control nodes. Thirdly, we derive a linear-algebraic necessary and sufficient condition for the controllability of general XOR-BNs, whose update rules are based on the XOR logical operator, and construct polynomial-time algorithms for computing control-node sets and control signals for general XOR-BNs. Lastly, we use ring theory and linear algebra to establish a few best-case upper bounds for a type of degree-constrainted XOR-BNs called $k$-$k$-XOR-BNs. In particular, we show that for any positive integer $m \geq 2$ and any odd integer $k \in [3, 2^{m} - 1]$, there exists a $2^{m}$-node controllable $k$-$k$-XOR-BN with 1 control node. Our results offer theoretical insights into minimal interventions in networked systems such as gene regulatory networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.16077v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christopher H. Fok, Liangjie Sun, Tatsuya Akutsu, Wai-Ki Ching</dc:creator>
    </item>
    <item>
      <title>A Universal Birkhoff Theory for Fast Trajectory Optimization</title>
      <link>https://arxiv.org/abs/2308.01400</link>
      <description>arXiv:2308.01400v3 Announce Type: replace 
Abstract: Over the last two decades, pseudospectral methods based on Lagrange interpolants have flourished in solving trajectory optimization problems and their flight implementations. In a seemingly unjustified departure from these highly successful methods, a new starting point for trajectory optimization is proposed. This starting point is based on the recently-developed concept of universal Birkhoff interpolants. The new approach offers a substantial computational upgrade to the Lagrange theory in completely flattening the rapid growth of the condition numbers from O(N2) to O(1), where N is the number of grid points. In addition, the Birkhoff-specific primal-dual computations are isolated to a well-conditioned linear system even for nonlinear, nonconvex problems. This is part I of a two-part paper. In part I, a new theory is developed on the basis of two hypotheses. Other than these hypotheses, the theoretical development makes no assumptions on the choices of basis functions or the selection of grid points. Several covector mapping theorems are proved to establish the mathematical equivalence between direct and indirect Birkhoff methods. In part II of this paper (with Proulx), it is shown that a select family of Gegenbauer grids satisfy the two hypotheses required for the theory to hold. Numerical examples in part II illustrate the power and utility of the new theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.01400v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.2514/1.G007737</arxiv:DOI>
      <arxiv:journal_reference>journal = {Journal of Guidance, Control, and Dynamics}, volume = {47}, number = {12}, pages = {2468-2481}, year = {2024}</arxiv:journal_reference>
      <dc:creator>I. M. Ross</dc:creator>
    </item>
    <item>
      <title>The Riemannian geometry of Sinkhorn divergences</title>
      <link>https://arxiv.org/abs/2405.04987</link>
      <description>arXiv:2405.04987v2 Announce Type: replace 
Abstract: We propose a new metric between probability measures on a compact metric space that mirrors the Riemannian manifold-like structure of quadratic optimal transport but includes entropic regularization. Its metric tensor is given by the Hessian of the Sinkhorn divergence, a debiased variant of entropic optimal transport. We precisely identify the tangent space it induces, which turns out to be related to a Reproducing Kernel Hilbert Space (RKHS). As usual in Riemannian geometry, the distance is built by looking for shortest paths. We prove that our distance is geodesic, metrizes the weak-star topology, and is equivalent to a RKHS norm. Still it retains the geometric flavor of optimal transport: as a paradigmatic example, translations are geodesics for the quadratic cost on $\mathbb{R}^d$. We also show two negative results on the Sinkhorn divergence that may be of independent interest: that it is not jointly convex, and that its square root is not a distance because it fails to satisfy the triangle inequality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04987v2</guid>
      <category>math.OC</category>
      <category>math.MG</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hugo Lavenant, Jonas Luckhardt, Gilles Mordant, Bernhard Schmitzer, Luca Tamanini</dc:creator>
    </item>
    <item>
      <title>Contextual Stochastic Optimization for Omnichannel Multi-Courier Order Fulfillment Under Delivery Time Uncertainty</title>
      <link>https://arxiv.org/abs/2409.06918</link>
      <description>arXiv:2409.06918v3 Announce Type: replace 
Abstract: The paper studies a large-scale order fulfillment problem for a leading e-commerce company in the United States. The challenge involves selecting fulfillment centers and shipping carriers with observational data only to efficiently process orders from a vast network of physical stores and warehouses. The company's current practice relies on heuristic rules that choose the cheapest fulfillment and shipping options for each unit, without considering opportunities for batching items or the reliability of carriers in meeting expected delivery dates. The paper develops a data-driven Contextual Stochastic Optimization (CSO) framework that integrates distributional forecasts of delivery time deviations with stochastic and robust order fulfillment optimization models. The framework optimizes the selection of fulfillment centers and carriers, accounting for item consolidation and delivery time uncertainty. Validated on a real-world data set containing tens of thousands of products, each with hundreds to thousands of fulfillment options, the proposed CSO framework significantly enhances the accuracy of meeting customer-expected delivery dates compared to current practices. It provides a flexible balance between reducing fulfillment costs and managing delivery time deviation risks, emphasizing the importance of contextual information and distributional forecasts in order fulfillment. This is the first paper that studies the omnichannel multi-courier order fulfillment problem with delivery time uncertainty through the lens of contextual optimization, fusing machine learning and optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06918v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tinghan Ye, Sikai Cheng, Amira Hijazi, Pascal Van Hentenryck</dc:creator>
    </item>
    <item>
      <title>Under the hood of a carbon footprint calculator</title>
      <link>https://arxiv.org/abs/2501.06251</link>
      <description>arXiv:2501.06251v2 Announce Type: replace 
Abstract: We explain the mathematical theory of the Input-Output method for carbon footprints computations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.06251v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Indira Chatterji, Ariadna Fossas Tenas, Elise Raphael</dc:creator>
    </item>
    <item>
      <title>Exploratory Randomization for Discrete-Time Linear Exponential Quadratic Gaussian (LEQG) Problem</title>
      <link>https://arxiv.org/abs/2501.06275</link>
      <description>arXiv:2501.06275v2 Announce Type: replace 
Abstract: We investigate exploratory randomization for an extended linear-exponential-quadratic-Gaussian (LEQG) control problem in discrete time. This extended control problem is related to the structure of risk-sensitive investment management applications. We introduce exploration through a randomization of the control. Next, we apply the duality between free energy and relative entropy to reduce the LEQG problem to an equivalent risk-neutral LQG control problem with an entropy regularization term, see, e.g. Dai Pra et al. (1996), for which we present a solution approach based on Dynamic Programming. Our approach, based on the energy-entropy duality may also be considered as leading to a justification for the use, in the literature, of an entropy regularization when applying a randomized control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.06275v2</guid>
      <category>math.OC</category>
      <category>q-fin.PM</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sebastien Lleo, Wolfgang Runggaldier</dc:creator>
    </item>
    <item>
      <title>A Framework for Stochastic Fairness in Dominant Resource Allocation with Cloud Computing Applications</title>
      <link>https://arxiv.org/abs/2501.18051</link>
      <description>arXiv:2501.18051v3 Announce Type: replace 
Abstract: Allocation of limited resources under uncertain requirements often necessitates fairness considerations, with applications in computer systems, health systems, and humanitarian logistics. This paper introduces a distributionally robust (DR) stochastic fairness framework for multi-resource allocation, leveraging rough estimates of the mean and variance of resource requirement distributions. The framework employs a sampled approximation DR (SA-DR) model to develop the concept of stochastic fairness, satisfying key properties such as stochastic Pareto efficiency, stochastic sharing incentive, and stochastic envy-freeness under suitable conditions. We show the convergence of the SA-DR model to the DR model and propose a finitely convergent algorithm to solve the SA-DR model. We empirically evaluate the performance of our moment-based SA-DR model -- which uses only rough estimates of the mean and variance of the resource requirement distribution -- against alternative resource allocation models under varying levels of information availability. We demonstrate that our moment-based partial-information SA-DR model can achieve performance closer to the full-information model than the worst-case information model. Convergence of the sampled approximation model and comparisons across models are illustrated using data from cloud computing applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18051v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiaqi Lei, Akhil Singla, Sanjay Mehrotra</dc:creator>
    </item>
    <item>
      <title>Designing efficient interventions for pre-disease states using control theory</title>
      <link>https://arxiv.org/abs/2507.18269</link>
      <description>arXiv:2507.18269v2 Announce Type: replace 
Abstract: To extend healthy life expectancy in an aging society, it is crucial to prevent various diseases at pre-disease states. Although dynamical network biomarker theory has been developed for pre-disease detection, mathematical frameworks for pre-disease treatment have not been well established. Here I propose a control theory-based approach for pre-disease treatment, named Markov chain sparse control (MCSC), where time evolution of a probability distribution on a Markov chain is described as a discrete-time linear system. By designing a sparse controller, a few candidate states for intervention are identified. The validity of MCSC is demonstrated using numerical simulations and real-data analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18269v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Makito Oku</dc:creator>
    </item>
    <item>
      <title>Accelerated Gradient Methods with Biased Gradient Estimates: Risk Sensitivity, High-Probability Guarantees, and Large Deviation Bounds</title>
      <link>https://arxiv.org/abs/2509.13628</link>
      <description>arXiv:2509.13628v2 Announce Type: replace 
Abstract: We study trade-offs between convergence rate and robustness to gradient errors in the context of first-order methods. Our focus is on generalized momentum methods (GMMs)--a broad class that includes Nesterov's accelerated gradient, heavy-ball, and gradient descent methods--for minimizing smooth strongly convex objectives. We allow stochastic gradient errors that may be adversarial and biased, and quantify robustness of these methods to gradient errors via the risk-sensitive index (RSI) from robust control theory. For quadratic objectives with i.i.d. Gaussian noise, we give closed form expressions for RSI in terms of solutions to 2x2 matrix Riccati equations, revealing a Pareto frontier between RSI and convergence rate over the choice of step-size and momentum parameters. We then prove a large-deviation principle for time-averaged suboptimality in the large iteration limit and show that the rate function is, up to a scaling, the convex conjugate of the RSI function. We further show that the rate function and RSI are linked to the $H_\infty$-norm--a measure of robustness to the worst-case deterministic gradient errors--so that stronger worst-case robustness (smaller $H_\infty$-norm) leads to sharper decay of the tail probabilities for the average suboptimality. Beyond quadratics, under potentially biased sub-Gaussian gradient errors, we derive non-asymptotic bounds on a finite-time analogue of the RSI, yielding finite-time high-probability guarantees and non-asymptotic large-deviation bounds for the averaged iterates. In the case of smooth strongly convex functions, we also observe an analogous trade-off between RSI and convergence-rate bounds. To our knowledge, these are the first non-asymptotic guarantees for GMMs with biased gradients and the first risk-sensitive analysis of GMMs. Finally, we provide numerical experiments on a robust regression problem to illustrate our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13628v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mert G\"urb\"uzbalaban, Yasa Syed, Necdet Serhat Aybat</dc:creator>
    </item>
    <item>
      <title>Model-Free and Real-Time Unicycle-Based Source Seeking with Differential Wheeled Robotic Experiments</title>
      <link>https://arxiv.org/abs/2501.02184</link>
      <description>arXiv:2501.02184v5 Announce Type: replace-cross 
Abstract: Many autonomous robots aimed at source-seeking are studied, and their controls designed, using unicycle modeling and formulation. This is true not only for model-based controllers, but also for model-free, real-time control methods such as extremum seeking control (ESC). In this paper, we propose a unicycle-based ESC design applicable to differential wheeled robots that: (1) is very simple design, based on one simple control-affine law, and without state integrators; (2) attenuates oscillations known to persist in ESC designs (i.e., fully stop at the source); and (3) operates in a model-free, real-time setting, tolerating environmental/sensor noise. We provide simulation and real-world robotic experimental results for fixed and moving light source seeking by a differential wheeled robot using our proposed design. Results indicate clear advantages of our proposed design when compared to the literature, including attenuation of undesired oscillations, improved convergence speed, and better handling of noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02184v5</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmed A. Elgohary, Sameh A. Eisa, Shivam Bajpai</dc:creator>
    </item>
    <item>
      <title>Faster Convergence of Riemannian Stochastic Gradient Descent with Increasing Batch Size</title>
      <link>https://arxiv.org/abs/2501.18164</link>
      <description>arXiv:2501.18164v4 Announce Type: replace-cross 
Abstract: We theoretically analyzed the convergence behavior of Riemannian stochastic gradient descent (RSGD) and found that using an increasing batch size leads to faster convergence than using a constant batch size, not only with a constant learning rate but also with a decaying learning rate, such as cosine annealing decay and polynomial decay. The convergence rate improves from $O(T^{-1}+C)$ with a constant batch size to $O(T^{-1})$ with an increasing batch size, where $T$ denotes the total number of iterations and $C$ is a constant. Using principal component analysis and low-rank matrix completion, we investigated, both theoretically and numerically, how an increasing batch size affects computational time as quantified by stochastic first-order oracle (SFO) complexity. An increasing batch size was found to reduce the SFO complexity of RSGD. Furthermore, an increasing batch size was found to offer the advantages of both small and large constant batch sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18164v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kanata Oowada, Hideaki Iiduka</dc:creator>
    </item>
    <item>
      <title>Analog In-memory Training on General Non-ideal Resistive Elements: The Impact of Response Functions</title>
      <link>https://arxiv.org/abs/2502.06309</link>
      <description>arXiv:2502.06309v3 Announce Type: replace-cross 
Abstract: As the economic and environmental costs of training and deploying large vision or language models increase dramatically, analog in-memory computing (AIMC) emerges as a promising energy-efficient solution. However, the training perspective, especially its training dynamic, is underexplored. In AIMC hardware, the trainable weights are represented by the conductance of resistive elements and updated using consecutive electrical pulses. While the conductance changes by a constant in response to each pulse, in reality, the change is scaled by asymmetric and non-linear \textit{response functions}, leading to a non-ideal training dynamic. This paper provides a theoretical foundation for gradient-based training on AIMC hardware with non-ideal response functions. We demonstrate that asymmetric response functions negatively impact Analog SGD by imposing an implicit penalty on the objective. To overcome the issue, we propose Residual Learning algorithm, which provably converges exactly to a critical point by solving a bilevel optimization problem. We demonstrate that the proposed method can be extended to address other hardware imperfections, such as limited response granularity. As we know, it is the first paper to investigate the impact of a class of generic non-ideal response functions. The conclusion is supported by simulations validating our theoretical insights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06309v3</guid>
      <category>cs.LG</category>
      <category>cs.AR</category>
      <category>math.OC</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaoxian Wu, Quan Xiao, Tayfun Gokmen, Omobayode Fagbohungbe, Tianyi Chen</dc:creator>
    </item>
    <item>
      <title>Gaussian process policy iteration with additive Schwarz acceleration for forward and inverse HJB and mean field game problems</title>
      <link>https://arxiv.org/abs/2505.00909</link>
      <description>arXiv:2505.00909v2 Announce Type: replace-cross 
Abstract: We propose a Gaussian Process (GP)-based policy iteration framework for addressing both forward and inverse problems in Hamilton--Jacobi--Bellman (HJB) equations and mean field games (MFGs). Policy iteration is formulated as an alternating procedure between solving the value function under a fixed control policy and updating the policy based on the resulting value function. By exploiting the linear structure of GPs for function approximation, each policy evaluation step admits an explicit closed-form solution, eliminating the need for numerical optimization. To improve convergence, we incorporate the additive Schwarz acceleration as a preconditioning step following each policy update. Numerical experiments demonstrate the effectiveness of Schwarz acceleration in improving computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00909v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xianjin Yang, Jingguo Zhang</dc:creator>
    </item>
    <item>
      <title>Both Asymptotic and Non-Asymptotic Convergence of Quasi-Hyperbolic Momentum using Increasing Batch Size</title>
      <link>https://arxiv.org/abs/2506.23544</link>
      <description>arXiv:2506.23544v3 Announce Type: replace-cross 
Abstract: Momentum methods were originally introduced for their superiority to stochastic gradient descent (SGD) in deterministic settings with convex objective functions. However, despite their widespread application to deep neural networks -- a representative case of stochastic nonconvex optimization -- the theoretical justification for their effectiveness in such settings remains limited. Quasi-hyperbolic momentum (QHM) is an algorithm that generalizes various momentum methods and has been studied to better understand the class of momentum-based algorithms as a whole. In this paper, we provide both asymptotic and non-asymptotic convergence results for mini-batch QHM with an increasing batch size. We show that achieving asymptotic convergence requires either a decaying learning rate or an increasing batch size. Since a decaying learning rate adversely affects non-asymptotic convergence, we demonstrate that using mini-batch QHM with an increasing batch size -- without decaying the learning rate -- can be a more effective strategy. Our experiments show that even a finite increase in batch size can provide benefits for training neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23544v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kento Imaizumi, Hideaki Iiduka</dc:creator>
    </item>
    <item>
      <title>LiMuon: Light and Fast Muon Optimizer for Large Models</title>
      <link>https://arxiv.org/abs/2509.14562</link>
      <description>arXiv:2509.14562v2 Announce Type: replace-cross 
Abstract: Large models recently are widely applied in artificial intelligence, so efficient training of large models has received widespread attention. More recently, a useful Muon optimizer is specifically designed for matrix-structured parameters of large models. Although some works have begun to studying Muon optimizer, the existing Muon and its variants still suffer from high sample complexity or high memory for large models. To fill this gap, we propose a light and fast Muon (LiMuon) optimizer for training large models, which builds on the momentum-based variance reduced technique and randomized Singular Value Decomposition (SVD). Our LiMuon optimizer has a lower memory than the current Muon and its variants. Moreover, we prove that our LiMuon has a lower sample complexity of $O(\epsilon^{-3})$ for finding an $\epsilon$-stationary solution of non-convex stochastic optimization under the smooth condition. Recently, the existing convergence analysis of Muon optimizer mainly relies on the strict Lipschitz smooth assumption, while some artificial intelligence tasks such as training large language models (LLMs) do not satisfy this condition. We also proved that our LiMuon optimizer has a sample complexity of $O(\epsilon^{-3})$ under the generalized smooth condition. Numerical experimental results on training DistilGPT2 and ViT models verify efficiency of our LiMuon optimizer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14562v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Feihu Huang, Yuning Luo, Songcan Chen</dc:creator>
    </item>
  </channel>
</rss>
