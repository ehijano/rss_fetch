<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.HC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.HC</link>
    <description>cs.HC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.HC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 13 Jun 2024 01:47:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 12 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Vibrotactile versus Visual Stimulation in Learning the Piano</title>
      <link>https://arxiv.org/abs/2406.06720</link>
      <description>arXiv:2406.06720v1 Announce Type: new 
Abstract: Vibrotactile stimulation has been explored to accelerate the acquisition of motor skills involving finger movements (Gemicioglu et al. 22, Markow et al. 2010, Seim et al. 17). This study evaluates the effectiveness of vibrotactile stimulation compared to visual feedback in learning a 14-note one-handed tune on the piano. In the experiment, 14 subjects with no prior piano experience were exposed to both vibrotactile and visual stimulation to determine which was more effective. Subjects were randomized 1:1 in a group that first receives vibrotactile stimulation, then visual stimulation or in a group that first receives visual stimulation, then vibrotactile stimulation. Effectiveness was measured by evaluating the timing error and accuracy. Results from our study indicated that the timing error for vibrotactile stimulation was 12.1% (SD 6.0%), while the equivalent for visual stimulation was 22.3% (SD 10.3%). The accuracy for vibrotactile stimulation was 69.2% (SD 27.2%), while the equivalent for visual stimulation was 91.3% (SD 13.5%). It was observed that vibrotactile stimulation was generally more effective at minimizing the timing error at which the notes were hit compared to visual stimulation, and no statistically significant differences were found in accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06720v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matteo A. Coscia, Mazen Al Borno</dc:creator>
    </item>
    <item>
      <title>Wearable Device-Based Physiological Signal Monitoring: An Assessment Study of Cognitive Load Across Tasks</title>
      <link>https://arxiv.org/abs/2406.07147</link>
      <description>arXiv:2406.07147v1 Announce Type: new 
Abstract: This study employs cutting-edge wearable monitoring technology to conduct high-precision, high-temporal-resolution cognitive load assessment on EEG data from the FP1 channel and heart rate variability (HRV) data of secondary vocational students(SVS). By jointly analyzing these two critical physiological indicators, the research delves into their application value in assessing cognitive load among SVS students and their utility across various tasks. The study designed two experiments to validate the efficacy of the proposed approach: Initially, a random forest classification model, developed using the N-BACK task, enabled the precise decoding of physiological signal characteristics in SVS students under different levels of cognitive load, achieving a classification accuracy of 97%. Subsequently, this classification model was applied in a cross-task experiment involving the National Computer Rank Examination, demonstrating the method's significant applicability and cross-task transferability in diverse learning contexts. Conducted with high portability, this research holds substantial theoretical and practical significance for optimizing teaching resource allocation in secondary vocational education, as well as for cognitive load assessment methods and monitoring. Currently, the research findings are undergoing trial implementation in the school.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07147v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ling He, Yanxin Chen, Wenqi Wang, Shuting He, Xiaoqiang Hu</dc:creator>
    </item>
    <item>
      <title>EEG classification for visual brain decoding with spatio-temporal and transformer based paradigms</title>
      <link>https://arxiv.org/abs/2406.07153</link>
      <description>arXiv:2406.07153v1 Announce Type: new 
Abstract: In this work, we delve into the EEG classification task in the domain of visual brain decoding via two frameworks, involving two different learning paradigms. Considering the spatio-temporal nature of EEG data, one of our frameworks is based on a CNN-BiLSTM model. The other involves a CNN-Transformer architecture which inherently involves the more versatile attention based learning paradigm. In both cases, a special 1D-CNN feature extraction module is used to generate the initial embeddings with 1D convolutions in the time and the EEG channel domains. Considering the EEG signals are noisy, non stationary and the discriminative features are even less clear (than in semantically structured data such as text or image), we also follow a window-based classification followed by majority voting during inference, to yield labels at a signal level. To illustrate how brain patterns correlate with different image classes, we visualize t-SNE plots of the BiLSTM embeddings alongside brain activation maps for the top 10 classes. These visualizations provide insightful revelations into the distinct neural signatures associated with each visual category, showcasing the BiLSTM's capability to capture and represent the discriminative brain activity linked to visual stimuli. We demonstrate the performance of our approach on the updated EEG-Imagenet dataset with positive comparisons with state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07153v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Akanksha Sharma, Jyoti Nigam, Abhishek Rathore, Arnav Bhavsar</dc:creator>
    </item>
    <item>
      <title>Haptic Repurposing with GenAI</title>
      <link>https://arxiv.org/abs/2406.07228</link>
      <description>arXiv:2406.07228v1 Announce Type: new 
Abstract: Mixed Reality aims to merge the digital and physical worlds to create immersive human-computer interactions. Despite notable advancements, the absence of realistic haptic feedback often breaks the immersive experience by creating a disconnect between visual and tactile perceptions. This paper introduces Haptic Repurposing with GenAI, an innovative approach to enhance MR interactions by transforming any physical objects into adaptive haptic interfaces for AI-generated virtual assets. Utilizing state-of-the-art generative AI models, this system captures both 2D and 3D features of physical objects and, through user-directed prompts, generates corresponding virtual objects that maintain the physical form of the original objects. Through model-based object tracking, the system dynamically anchors virtual assets to physical props in real time, allowing objects to visually morph into any user-specified virtual object. This paper details the system's development, presents findings from usability studies that validate its effectiveness, and explores its potential to significantly enhance interactive MR environments. The hope is this work can lay a foundation for further research into AI-driven spatial transformation in immersive and haptic technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07228v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Haoyu Wang</dc:creator>
    </item>
    <item>
      <title>Personalisation of d'Hondt's algorithm and its use in recommender ecosystems</title>
      <link>https://arxiv.org/abs/2406.07264</link>
      <description>arXiv:2406.07264v1 Announce Type: new 
Abstract: In the area of recommender systems, we are dealing with aggregations and potential of personalisation in ecosystems. Personalisation is based on separate aggregation models for each user. This approach reveals differences in user preferences, especially when they are in strict disagreement with global preferences. Hybrid models are based on combination of global and personalised model of weights for d'Hondt's voting algorithm. This paper shows that personalisation combined with hybridisation on case-by-case basis outperforms non-personalised d'Hondt's algorithm on datasets RetailRocket and SLANTour. By taking into account voices of minorities we achieved better click through rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07264v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stepan Balcar, Ladislav Peska, Peter Vojtas</dc:creator>
    </item>
    <item>
      <title>Should XAI Nudge Human Decisions with Explanation Biasing?</title>
      <link>https://arxiv.org/abs/2406.07323</link>
      <description>arXiv:2406.07323v1 Announce Type: new 
Abstract: This paper reviews our previous trials of Nudge-XAI, an approach that introduces automatic biases into explanations from explainable AIs (XAIs) with the aim of leading users to better decisions, and it discusses the benefits and challenges. Nudge-XAI uses a user model that predicts the influence of providing an explanation or emphasizing it and attempts to guide users toward AI-suggested decisions without coercion. The nudge design is expected to enhance the autonomy of users, reduce the risk associated with an AI making decisions without users' full agreement, and enable users to avoid AI failures. To discuss the potential of Nudge-XAI, this paper reports a post-hoc investigation of previous experimental results using cluster analysis. The results demonstrate the diversity of user behavior in response to Nudge-XAI, which supports our aim of enhancing user autonomy. However, it also highlights the challenge of users who distrust AI and falsely make decisions contrary to AI suggestions, suggesting the need for personalized adjustment of the strength of nudges to make this approach work more generally.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07323v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yosuke Fukuchi, Seiji Yamada</dc:creator>
    </item>
    <item>
      <title>AI.vs.Clinician: Unveiling Intricate Interactions Between AI and Clinicians through an Open-Access Database</title>
      <link>https://arxiv.org/abs/2406.07362</link>
      <description>arXiv:2406.07362v1 Announce Type: new 
Abstract: Artificial Intelligence (AI) plays a crucial role in medical field and has the potential to revolutionize healthcare practices. However, the success of AI models and their impacts hinge on the synergy between AI and medical specialists, with clinicians assuming a dominant role. Unfortunately, the intricate dynamics and interactions between AI and clinicians remain undiscovered and thus hinder AI from being translated into medical practice. To address this gap, we have curated a groundbreaking database called AI.vs.Clinician. This database is the first of its kind for studying the interactions between AI and clinicians. It derives from 7,500 collaborative diagnosis records on a life-threatening medical emergency -- Sepsis -- from 14 medical centers across China. For the patient cohorts well-chosen from MIMIC databases, the AI-related information comprises the model property, feature input, diagnosis decision, and inferred probabilities of sepsis onset presently and within next three hours. The clinician-related information includes the viewed examination data and sequence, viewed time, preliminary and final diagnosis decisions with or without AI assistance, and recommended treatment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07362v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Wanling Gao, Yuan Liu, Zhuoming Yu, Dandan Cui, Wenjing Liu, Xiaoshuang Liang, Jiahui Zhao, Jiyue Xie, Hao Li, Li Ma, Ning Ye, Yumiao Kang, Dingfeng Luo, Peng Pan, Wei Huang, Zhongmou Liu, Jizhong Hu, Fan Huang, Gangyuan Zhao, Chongrong Jiang, Tianyi Wei, Zhifei Zhang, Yunyou Huang, Jianfeng Zhan</dc:creator>
    </item>
    <item>
      <title>A qualitative field study on explainable AI for lay users subjected to AI cyberattacks</title>
      <link>https://arxiv.org/abs/2406.07369</link>
      <description>arXiv:2406.07369v1 Announce Type: new 
Abstract: In this paper we present results from a qualitative field study on explainable AI (XAI) for lay users (n = 18) who were subjected to AI cyberattacks. The study was based on a custom-built smart heating application called Squid and was conducted over seven weeks in early 2023. Squid combined a smart radiator valve installed in participant homes with a web application that implemented an AI feature known as setpoint learning, which is commonly available in consumer smart thermostats. Development of Squid followed the XAI principle of interpretability-by-design where the AI feature was implemented using a simple glass-box machine learning model with the model subsequently exposed to users via the web interface (e.g. as interactive visualisations). AI attacks on users were simulated by injecting malicious training data and by manipulating data used for model predictions. Research data consisted of semi-structured interviews, researcher field notes, participant diaries, and application logs. In our analysis we reflect on the impact of XAI on user satisfaction and user comprehension as well as its use as a tool for diagnosing AI attacks. Our results show only limited engagement with XAI features and suggest that, for Squid users, common assumptions found in the XAI literature were not aligned to reality. On the positive side, users appear to have developed better mental models of the AI feature compared to previous work, and there is evidence that users did make some use of XAI as a diagnostic tool.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07369v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kevin McAreavey, Weiru Liu, Kim Bauters, Dennis Ivory, George Loukas, Manos Panaousis, Hsueh-Ju Chen, Rea Gill, Rachael Payler, Asimina Vasalou</dc:creator>
    </item>
    <item>
      <title>Politics in Games -- An Overview and Classification</title>
      <link>https://arxiv.org/abs/2406.07379</link>
      <description>arXiv:2406.07379v1 Announce Type: new 
Abstract: The representation of politics in media influences societal perceptions and attitudes. Video games, as a pervasive form of media, contribute significantly to this phenomenon. In this work, we explore political themes within video games by analyzing politically-themed games on game distribution platforms including Steam. We conducted a statistical examination of games with political context to identify patterns and use this as a basis to introduce a first taxonomy to categorize and better understand the interplay between politics and video games. This taxonomy offers a first framework for analyzing political content in games and also sets a foundation for future research in this field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07379v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lisa Gutwenger, Stephan Keller, Martin Dolezal, Bernhard Schn\"ogl, Sebastian Rous, Klaus Poier, Johanna Pirker</dc:creator>
    </item>
    <item>
      <title>PITCH: Productivity and Mental Well-being Coaching through Daily Conversational Interaction</title>
      <link>https://arxiv.org/abs/2406.07485</link>
      <description>arXiv:2406.07485v1 Announce Type: new 
Abstract: Efficient task planning is essential for productivity and mental well-being, yet individuals often struggle to create realistic plans and reflect upon their productivity. Leveraging the advancement in artificial intelligence (AI), conversational agents have emerged as a promising tool for enhancing productivity. Our work focuses on externalizing plans through conversation, aiming to solidify intentions and foster focused action, thereby positively impacting their productivity and mental well-being. We share our plan of designing a conversational agent to offer insightful questions and reflective prompts for increasing plan adherence by leveraging the social interactivity of natural conversations. Previous studies have shown the effectiveness of such agents, but many interventions remain static, leading to decreased user engagement over time. To address this limitation, we propose a novel rotation and context-aware prompting strategy, providing users with varied interventions daily. Our system, PITCH, utilizes large language models (LLMs) to facilitate externalization and reflection on daily plans. Through this study, we investigate the impact of externalizing tasks with conversational agents on productivity and mental well-being, and the effectiveness of a rotation strategy in maintaining user engagement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07485v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adnan Abbas, Sang Won Lee</dc:creator>
    </item>
    <item>
      <title>Exploring Human-AI Perception Alignment in Sensory Experiences: Do LLMs Understand Textile Hand?</title>
      <link>https://arxiv.org/abs/2406.06587</link>
      <description>arXiv:2406.06587v1 Announce Type: cross 
Abstract: Aligning large language models (LLMs) behaviour with human intent is critical for future AI. An important yet often overlooked aspect of this alignment is the perceptual alignment. Perceptual modalities like touch are more multifaceted and nuanced compared to other sensory modalities such as vision. This work investigates how well LLMs align with human touch experiences using the "textile hand" task. We created a "Guess What Textile" interaction in which participants were given two textile samples -- a target and a reference -- to handle. Without seeing them, participants described the differences between them to the LLM. Using these descriptions, the LLM attempted to identify the target textile by assessing similarity within its high-dimensional embedding space. Our results suggest that a degree of perceptual alignment exists, however varies significantly among different textile samples. For example, LLM predictions are well aligned for silk satin, but not for cotton denim. Moreover, participants didn't perceive their textile experiences closely matched by the LLM predictions. This is only the first exploration into perceptual alignment around touch, exemplified through textile hand. We discuss possible sources of this alignment variance, and how better human-AI perceptual alignment can benefit future everyday tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06587v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shu Zhong, Elia Gatti, Youngjun Cho, Marianna Obrist</dc:creator>
    </item>
    <item>
      <title>Anna Karenina Strikes Again: Pre-Trained LLM Embeddings May Favor High-Performing Learners</title>
      <link>https://arxiv.org/abs/2406.06599</link>
      <description>arXiv:2406.06599v1 Announce Type: cross 
Abstract: Unsupervised clustering of student responses to open-ended questions into behavioral and cognitive profiles using pre-trained LLM embeddings is an emerging technique, but little is known about how well this captures pedagogically meaningful information. We investigate this in the context of student responses to open-ended questions in biology, which were previously analyzed and clustered by experts into theory-driven Knowledge Profiles (KPs). Comparing these KPs to ones discovered by purely data-driven clustering techniques, we report poor discoverability of most KPs, except for the ones including the correct answers. We trace this "discoverability bias" to the representations of KPs in the pre-trained LLM embeddings space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06599v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.IR</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abigail Gurin Schleifer, Beata Beigman Klebanov, Moriah Ariely, Giora Alexandron</dc:creator>
    </item>
    <item>
      <title>Benchmarking Neural Decoding Backbones towards Enhanced On-edge iBCI Applications</title>
      <link>https://arxiv.org/abs/2406.06626</link>
      <description>arXiv:2406.06626v1 Announce Type: cross 
Abstract: Traditional invasive Brain-Computer Interfaces (iBCIs) typically depend on neural decoding processes conducted on workstations within laboratory settings, which prevents their everyday usage. Implementing these decoding processes on edge devices, such as the wearables, introduces considerable challenges related to computational demands, processing speed, and maintaining accuracy. This study seeks to identify an optimal neural decoding backbone that boasts robust performance and swift inference capabilities suitable for edge deployment. We executed a series of neural decoding experiments involving nonhuman primates engaged in random reaching tasks, evaluating four prospective models, Gated Recurrent Unit (GRU), Transformer, Receptance Weighted Key Value (RWKV), and Selective State Space model (Mamba), across several metrics: single-session decoding, multi-session decoding, new session fine-tuning, inference speed, calibration speed, and scalability. The findings indicate that although the GRU model delivers sufficient accuracy, the RWKV and Mamba models are preferable due to their superior inference and calibration speeds. Additionally, RWKV and Mamba comply with the scaling law, demonstrating improved performance with larger data sets and increased model sizes, whereas GRU shows less pronounced scalability, and the Transformer model requires computational resources that scale prohibitively. This paper presents a thorough comparative analysis of the four models in various scenarios. The results are pivotal in pinpointing an optimal backbone that can handle increasing data volumes and is viable for edge implementation. This analysis provides essential insights for ongoing research and practical applications in the field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06626v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhou Zhou, Guohang He, Zheng Zhang, Luziwei Leng, Qinghai Guo, Jianxing Liao, Xuan Song, Ran Cheng</dc:creator>
    </item>
    <item>
      <title>Controlling Counterfactual Harm in Decision Support Systems Based on Prediction Sets</title>
      <link>https://arxiv.org/abs/2406.06671</link>
      <description>arXiv:2406.06671v1 Announce Type: cross 
Abstract: Decision support systems based on prediction sets help humans solve multiclass classification tasks by narrowing down the set of potential label values to a subset of them, namely a prediction set, and asking them to always predict label values from the prediction sets. While this type of systems have been proven to be effective at improving the average accuracy of the predictions made by humans, by restricting human agency, they may cause harm$\unicode{x2014}$a human who has succeeded at predicting the ground-truth label of an instance on their own may have failed had they used these systems. In this paper, our goal is to control how frequently a decision support system based on prediction sets may cause harm, by design. To this end, we start by characterizing the above notion of harm using the theoretical framework of structural causal models. Then, we show that, under a natural, albeit unverifiable, monotonicity assumption, we can estimate how frequently a system may cause harm using only predictions made by humans on their own. Further, we also show that, under a weaker monotonicity assumption, which can be verified experimentally, we can bound how frequently a system may cause harm again using only predictions made by humans on their own. Building upon these assumptions, we introduce a computational framework to design decision support systems based on prediction sets that are guaranteed to cause harm less frequently than a user-specified value using conformal risk control. We validate our framework using real human predictions from two different human subject studies and show that, in decision support systems based on prediction sets, there is a trade-off between accuracy and counterfactual harm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06671v1</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>stat.ME</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eleni Straitouri, Suhas Thejaswi, Manuel Gomez Rodriguez</dc:creator>
    </item>
    <item>
      <title>Coprocessor Actor Critic: A Model-Based Reinforcement Learning Approach For Adaptive Brain Stimulation</title>
      <link>https://arxiv.org/abs/2406.06714</link>
      <description>arXiv:2406.06714v1 Announce Type: cross 
Abstract: Adaptive brain stimulation can treat neurological conditions such as Parkinson's disease and post-stroke motor deficits by influencing abnormal neural activity. Because of patient heterogeneity, each patient requires a unique stimulation policy to achieve optimal neural responses. Model-free reinforcement learning (MFRL) holds promise in learning effective policies for a variety of similar control tasks, but is limited in domains like brain stimulation by a need for numerous costly environment interactions. In this work we introduce Coprocessor Actor Critic, a novel, model-based reinforcement learning (MBRL) approach for learning neural coprocessor policies for brain stimulation. Our key insight is that coprocessor policy learning is a combination of learning how to act optimally in the world and learning how to induce optimal actions in the world through stimulation of an injured brain. We show that our approach overcomes the limitations of traditional MFRL methods in terms of sample efficiency and task success and outperforms baseline MBRL approaches in a neurologically realistic model of an injured brain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06714v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michelle Pan, Mariah Schrum, Vivek Myers, Erdem B{\i}y{\i}k, Anca Dragan</dc:creator>
    </item>
    <item>
      <title>Analyzing user archetypes in Singapore's Telegram groups on COVID-19 and climate change</title>
      <link>https://arxiv.org/abs/2406.06717</link>
      <description>arXiv:2406.06717v1 Announce Type: cross 
Abstract: Social media platforms, particularly Telegram, play a pivotal role in shaping public perceptions and opinions on global and national issues. Unlike traditional news media, Telegram allows for the proliferation of user-generated content with minimal oversight, making it a significant venue for the spread of controversial and misinformative content. During the COVID-19 pandemic, Telegram's popularity surged in Singapore, a country with one of the highest rates of social media use globally. We leverage Singapore-based Telegram data to analyze information flows within groups focused on COVID-19 and climate change. Using k-means clustering, we identified distinct user archetypes, including Skeptic, Engaged Advocate, Observer, and Analyst, each contributing uniquely to the discourse. We developed a model to classify users into these clusters (Precision: Climate change: 0.99; COVID-19: 0.95). By identifying these user archetypes and examining their contributions to information dissemination, we sought to uncover patterns to inform effective strategies for combating misinformation and enhancing public discourse on pressing global issues.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06717v1</guid>
      <category>cs.SI</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Val Alvern Cueco Ligo, Lan Tianxiang, Ying Zeng, Lam Yin Cheung, Pi Zonooz, Roy Ka-Wei Lee, Koustuv Saha, Edson C. Tandoc Jr., Navin Kumar</dc:creator>
    </item>
    <item>
      <title>Ollabench: Evaluating LLMs' Reasoning for Human-centric Interdependent Cybersecurity</title>
      <link>https://arxiv.org/abs/2406.06863</link>
      <description>arXiv:2406.06863v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) have the potential to enhance Agent-Based Modeling by better representing complex interdependent cybersecurity systems, improving cybersecurity threat modeling and risk management. However, evaluating LLMs in this context is crucial for legal compliance and effective application development. Existing LLM evaluation frameworks often overlook the human factor and cognitive computing capabilities essential for interdependent cybersecurity. To address this gap, I propose OllaBench, a novel evaluation framework that assesses LLMs' accuracy, wastefulness, and consistency in answering scenario-based information security compliance and non-compliance questions. OllaBench is built on a foundation of 24 cognitive behavioral theories and empirical evidence from 38 peer-reviewed papers. OllaBench was used to evaluate 21 LLMs, including both open-weight and commercial models from OpenAI, Anthropic, Google, Microsoft, Meta and so on. The results reveal that while commercial LLMs have the highest overall accuracy scores, there is significant room for improvement. Smaller low-resolution open-weight LLMs are not far behind in performance, and there are significant differences in token efficiency and consistency among the evaluated models. OllaBench provides a user-friendly interface and supports a wide range of LLM platforms, making it a valuable tool for researchers and solution developers in the field of human-centric interdependent cybersecurity and beyond.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06863v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tam n. Nguyen</dc:creator>
    </item>
    <item>
      <title>Joint Demonstration and Preference Learning Improves Policy Alignment with Human Feedback</title>
      <link>https://arxiv.org/abs/2406.06874</link>
      <description>arXiv:2406.06874v1 Announce Type: cross 
Abstract: Aligning human preference and value is an important requirement for building contemporary foundation models and embodied AI. However, popular approaches such as reinforcement learning with human feedback (RLHF) break down the task into successive stages, such as supervised fine-tuning (SFT), reward modeling (RM), and reinforcement learning (RL), each performing one specific learning task. Such a sequential approach results in serious issues such as significant under-utilization of data and distribution mismatch between the learned reward model and generated policy, which eventually lead to poor alignment performance. We develop a single stage approach named Alignment with Integrated Human Feedback (AIHF), capable of integrating both human preference and demonstration to train reward models and the policy. The proposed approach admits a suite of efficient algorithms, which can easily reduce to, and leverage, popular alignment algorithms such as RLHF and Directly Policy Optimization (DPO), and only requires minor changes to the existing alignment pipelines. We demonstrate the efficiency of the proposed solutions with extensive experiments involving alignment problems in LLMs and robotic control problems in MuJoCo. We observe that the proposed solutions outperform the existing alignment algorithms such as RLHF and DPO by large margins, especially when the amount of high-quality preference data is relatively limited.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06874v1</guid>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.RO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenliang Li, Siliang Zeng, Zeyi Liao, Jiaxiang Li, Dongyeop Kang, Alfredo Garcia, Mingyi Hong</dc:creator>
    </item>
    <item>
      <title>Person Transfer in the Field: Examining Real World Sequential Human-Robot Interaction Between Two Robots</title>
      <link>https://arxiv.org/abs/2406.06904</link>
      <description>arXiv:2406.06904v1 Announce Type: cross 
Abstract: With more robots being deployed in the world, users will likely interact with multiple robots sequentially when receiving services. In this paper, we describe an exploratory field study in which unsuspecting participants experienced a ``person transfer'' -- a scenario in which they first interacted with one stationary robot before another mobile robot joined to complete the interaction. In our 7-hour study spanning 4 days, we recorded 18 instances of person transfers with 40+ individuals. We also interviewed 11 participants after the interaction to further understand their experience. We used the recorded video and interview data to extract interesting insights about in-the-field sequential human-robot interaction, such as mobile robot handovers, trust in person transfer, and the importance of the robots' positions. Our findings expose pitfalls and present important factors to consider when designing sequential human-robot interaction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06904v1</guid>
      <category>cs.RO</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xiang Zhi Tan, Elizabeth J. Carter, Aaron Steinfeld</dc:creator>
    </item>
    <item>
      <title>CAAP: Context-Aware Action Planning Prompting to Solve Computer Tasks with Front-End UI Only</title>
      <link>https://arxiv.org/abs/2406.06947</link>
      <description>arXiv:2406.06947v1 Announce Type: cross 
Abstract: Software robots have long been deployed in Robotic Process Automation (RPA) to automate mundane and repetitive computer tasks. The advent of Large Language Models (LLMs) with advanced reasoning capabilities has set the stage for these agents to now undertake more complex and even previously unseen tasks. However, the LLM-based automation techniques in recent literature frequently rely on HTML source codes for input, limiting their application to web environments. Moreover, the information contained in HTML codes is often inaccurate or incomplete, making the agent less reliable for practical applications. We propose an LLM-based agent that functions solely on the basis of screenshots for recognizing environments, while leveraging in-context learning to eliminate the need for collecting large datasets of human demonstration. Our strategy, named Context-Aware Action Planning (CAAP) prompting encourages the agent to meticulously review the context in various angles. Through our proposed methodology, we achieve a success rate of 94.4% on 67~types of MiniWoB++ problems, utilizing only 1.48~demonstrations per problem type. Our method offers the potential for broader applications, especially for tasks that require inter-application coordination on computers or smartphones, showcasing a significant advancement in the field of automation agents. Codes and models are accessible at https://github.com/caap-agent/caap-agent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06947v1</guid>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junhee Cho, Jihoon Kim, Daseul Bae, Jinho Choo, Youngjune Gwon, Yeong-Dae Kwon</dc:creator>
    </item>
    <item>
      <title>Towards Human-AI Collaboration in Healthcare: Guided Deferral Systems with Large Language Models</title>
      <link>https://arxiv.org/abs/2406.07212</link>
      <description>arXiv:2406.07212v1 Announce Type: cross 
Abstract: Large language models (LLMs) present a valuable technology for various applications in healthcare, but their tendency to hallucinate introduces unacceptable uncertainty in critical decision-making situations. Human-AI collaboration (HAIC) can mitigate this uncertainty by combining human and AI strengths for better outcomes. This paper presents a novel guided deferral system that provides intelligent guidance when AI defers cases to human decision-makers. We leverage LLMs' verbalisation capabilities and internal states to create this system, demonstrating that fine-tuning smaller LLMs with data from larger models enhances performance while maintaining computational efficiency. A pilot study showcases the effectiveness of our deferral system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07212v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua Strong, Qianhui Men, Alison Noble</dc:creator>
    </item>
    <item>
      <title>INDCOR white paper 4: Evaluation of Interactive Narrative Design For Complexity Representations</title>
      <link>https://arxiv.org/abs/2306.09817</link>
      <description>arXiv:2306.09817v4 Announce Type: replace 
Abstract: While a strength of Interactive Digital Narratives (IDN) is its support for multiperspectivity, this also poses a substantial challenge to its evaluation. Moreover, evaluation has to assess the system's ability to represent a complex reality as well as the user's understanding of that complex reality as a result of the experience of interacting with the system. This is needed to measure an IDN's efficiency and effectiveness in representing the chosen complex phenomenon. We here present some empirical methods employed by INDCOR members in their research including UX toolkits and scales. Particularly, we consider the impact of IDN on transformative learning and its evaluation through self-reporting and other alternatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.09817v4</guid>
      <category>cs.HC</category>
      <category>cs.MM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian Roth, Breanne Pitt, L\=asma \v{S}\c{k}estere, Jonathan Barbara, Agnes Karolina Bakk, Kirsty Dunlop, Maria del Mar Grandio, Miguel Barreda, Despoina Sampatakou, Michael Schlauch</dc:creator>
    </item>
    <item>
      <title>Visual Highlighting for Situated Brushing and Linking</title>
      <link>https://arxiv.org/abs/2403.15321</link>
      <description>arXiv:2403.15321v3 Announce Type: replace 
Abstract: Brushing and linking is widely used for visual analytics in desktop environments. However, using this approach to link many data items between situated (e.g., a virtual screen with data) and embedded views (e.g., highlighted objects in the physical environment) is largely unexplored. To this end, we study the effectiveness of visual highlighting techniques in helping users identify and link physical referents to brushed data marks in a situated scatterplot. In an exploratory virtual reality user study (N=20), we evaluated four highlighting techniques under different physical layouts and tasks. We discuss the effectiveness of these techniques, as well as implications for the design of brushing and linking operations in situated analytics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15321v3</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1111/cgf.15105</arxiv:DOI>
      <dc:creator>Nina Doerr, Benjamin Lee, Katarina Baricova, Dieter Schmalstieg, Michael Sedlmair</dc:creator>
    </item>
    <item>
      <title>Spin-Wave Voices: Sonification of Nanoscale Spin Waves as an Engagement and Research Tool</title>
      <link>https://arxiv.org/abs/2405.03506</link>
      <description>arXiv:2405.03506v2 Announce Type: replace 
Abstract: Magnonics is an emerging research field that addresses the use of spin waves (magnons), purely magnetic waves, for information transport and processing. Spin waves are a potential replacement for electric current in modern computational devices that would make them more compact and energy efficient. The field is yet little known, even among physicists. Additionally, with the development of new measuring techniques and computational physics, the obtained magnetic data becomes more complex, in some cases including 3D vector fields and time-resolution. This work presents an approach to the audio-visual representation of the spin waves and discusses its use as a tool for science communication exhibits and possible data analysis tool. The work also details an instance of such an exhibit presented at the annual international digital art exhibition Ars Electronica Festival in 2022.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03506v2</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Santa Pile, Oleg Lesota, Silvan David Peter, Christina Humer, Martin Gasser</dc:creator>
    </item>
    <item>
      <title>WEIRD ICWSM: How Western, Educated, Industrialized, Rich, and Democratic is Social Computing Research?</title>
      <link>https://arxiv.org/abs/2406.02090</link>
      <description>arXiv:2406.02090v2 Announce Type: replace 
Abstract: Much of the research in social computing analyzes data from social media platforms, which may inherently carry biases. An overlooked source of such bias is the over-representation of WEIRD (Western, Educated, Industrialized, Rich, and Democratic) populations, which might not accurately mirror the global demographic diversity. We evaluated the dependence on WEIRD populations in research presented at the AAAI ICWSM conference; the only venue whose proceedings are fully dedicated to social computing research. We did so by analyzing 494 papers published from 2018 to 2022, which included full research papers, dataset papers and posters. After filtering out papers that analyze synthetic datasets or those lacking clear country of origin, we were left with 420 papers from which 188 participants in a crowdsourcing study with full manual validation extracted data for the WEIRD scores computation. This data was then used to adapt existing WEIRD metrics to be applicable for social media data. We found that 37% of these papers focused solely on data from Western countries. This percentage is significantly less than the percentages observed in research from CHI (76%) and FAccT (84%) conferences, suggesting a greater diversity of dataset origins within ICWSM. However, the studies at ICWSM still predominantly examine populations from countries that are more Educated, Industrialized, and Rich in comparison to those in FAccT, with a special note on the 'Democratic' variable reflecting political freedoms and rights. This points out the utility of social media data in shedding light on findings from countries with restricted political freedoms. Based on these insights, we recommend extensions of current "paper checklists" to include considerations about the WEIRD bias and call for the community to broaden research inclusivity by encouraging the use of diverse datasets from underrepresented regions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02090v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ali Akbar Septiandri, Marios Constantinides, Daniele Quercia</dc:creator>
    </item>
    <item>
      <title>Open-Ended Multi-Modal Relational Reasoning for Video Question Answering</title>
      <link>https://arxiv.org/abs/2012.00822</link>
      <description>arXiv:2012.00822v4 Announce Type: replace-cross 
Abstract: In this paper, we introduce a robotic agent specifically designed to analyze external environments and address participants' questions. The primary focus of this agent is to assist individuals using language-based interactions within video-based scenes. Our proposed method integrates video recognition technology and natural language processing models within the robotic agent. We investigate the crucial factors affecting human-robot interactions by examining pertinent issues arising between participants and robot agents. Methodologically, our experimental findings reveal a positive relationship between trust and interaction efficiency. Furthermore, our model demonstrates a 2\% to 3\% performance enhancement in comparison to other benchmark methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2012.00822v4</guid>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.RO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/RO-MAN57019.2023.10309342</arxiv:DOI>
      <dc:creator>Haozheng Luo, Ruiyang Qin, Chenwei Xu, Guo Ye, Zening Luo</dc:creator>
    </item>
  </channel>
</rss>
