<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 06 Jan 2025 05:00:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Heisenberg-esque Uncertainty Principle for Simultaneous (Machine) Learning and Error Assessment?</title>
      <link>https://arxiv.org/abs/2501.01475</link>
      <description>arXiv:2501.01475v1 Announce Type: new 
Abstract: A highly cited and inspiring article by Bates et al (2024) demonstrates that the prediction errors estimated through cross-validation, Bootstrap or Mallow's $C_P$ can all be independent of the actual prediction errors. This essay hypothesizes that these occurrences signify a broader, Heisenberg-like uncertainty principle for learning: optimizing learning and assessing actual errors using the same data are fundamentally at odds. Only suboptimal learning preserves untapped information for actual error assessments, and vice versa, reinforcing the `no free lunch' principle. To substantiate this intuition, a Cramer-Rao-style lower bound is established under the squared loss, which shows that the relative regret in learning is bounded below by the square of the correlation between any unbiased error assessor and the actual learning error. Readers are invited to explore generalizations, develop variations, or even uncover genuine `free lunches.' The connection with the Heisenberg uncertainty principle is more than metaphorical, because both share an essence of the Cramer-Rao inequality: marginal variations cannot manifest individually to arbitrary degrees when their underlying co-variation is constrained, whether the co-variation is about individual states or their generating mechanisms, as in the quantum realm. A practical takeaway of such a learning principle is that it may be prudent to reserve some information specifically for error assessment rather than pursue full optimization in learning, particularly when intentional randomness is introduced to mitigate overfitting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01475v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xiao-Li Meng</dc:creator>
    </item>
    <item>
      <title>A Topological Proof of the Archimedean Axiom for Archimedean Copulas</title>
      <link>https://arxiv.org/abs/2501.01769</link>
      <description>arXiv:2501.01769v1 Announce Type: new 
Abstract: Archimedean copulas are a popular type of copulas in which a variant of the Archimedean axiom apply. We provide a topological proof of the Archimedean Axiom which is applicable for non-continuous distribution functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01769v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Victory Idowu</dc:creator>
    </item>
    <item>
      <title>Nonparametric estimation of a factorizable density using diffusion models</title>
      <link>https://arxiv.org/abs/2501.01783</link>
      <description>arXiv:2501.01783v1 Announce Type: new 
Abstract: In recent years, diffusion models, and more generally score-based deep generative models, have achieved remarkable success in various applications, including image and audio generation. In this paper, we view diffusion models as an implicit approach to nonparametric density estimation and study them within a statistical framework to analyze their surprising performance. A key challenge in high-dimensional statistical inference is leveraging low-dimensional structures inherent in the data to mitigate the curse of dimensionality. We assume that the underlying density exhibits a low-dimensional structure by factorizing into low-dimensional components, a property common in examples such as Bayesian networks and Markov random fields. Under suitable assumptions, we demonstrate that an implicit density estimator constructed from diffusion models adapts to the factorization structure and achieves the minimax optimal rate with respect to the total variation distance. In constructing the estimator, we design a sparse weight-sharing neural network architecture, where sparsity and weight-sharing are key features of practical architectures such as convolutional neural networks and recurrent neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01783v1</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hyeok Kyu Kwon, Dongha Kim, Ilsang Ohn, Minwoo Chae</dc:creator>
    </item>
    <item>
      <title>On robust recovery of signals from indirect observations</title>
      <link>https://arxiv.org/abs/2501.01935</link>
      <description>arXiv:2501.01935v1 Announce Type: new 
Abstract: We consider an uncertain linear inverse problem as follows. Given observation $\omega=Ax_*+\zeta$ where $A\in {\bf R}^{m\times p}$ and $\zeta\in {\bf R}^{m}$ is observation noise, we want to recover unknown signal $x_*$, known to belong to a convex set ${\cal X}\subset{\bf R}^{n}$. As opposed to the "standard" setting of such problem, we suppose that the model noise $\zeta$ is "corrupted" -- contains an uncertain (deterministic dense or singular) component. Specifically, we assume that $\zeta$ decomposes into $\zeta=N\nu_*+\xi$ where $\xi$ is the random noise and $N\nu_*$ is the "adversarial contamination" with known $\cal N\subset {\bf R}^n$ such that $\nu_*\in \cal N$ and $N\in {\bf R}^{m\times n}$. We consider two "uncertainty setups" in which $\cal N$ is either a convex bounded set or is the set of sparse vectors (with at most $s$ nonvanishing entries). We analyse the performance of "uncertainty-immunized" polyhedral estimates -- a particular class of nonlinear estimates as introduced in [15, 16] -- and show how "presumably good" estimates of the sort may be constructed in the situation where the signal set is an ellitope (essentially, a symmetric convex set delimited by quadratic surfaces) by means of efficient convex optimization routines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01935v1</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yannis Bekri, Anatoli Juditsky, Arkadi Nemirovski</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning for Respondent-Driven Sampling</title>
      <link>https://arxiv.org/abs/2501.01505</link>
      <description>arXiv:2501.01505v1 Announce Type: cross 
Abstract: Respondent-driven sampling (RDS) is widely used to study hidden or hard-to-reach populations by incentivizing study participants to recruit their social connections. The success and efficiency of RDS can depend critically on the nature of the incentives, including their number, value, call to action, etc. Standard RDS uses an incentive structure that is set a priori and held fixed throughout the study. Thus, it does not make use of accumulating information on which incentives are effective and for whom. We propose a reinforcement learning (RL) based adaptive RDS study design in which the incentives are tailored over time to maximize cumulative utility during the study. We show that these designs are more efficient, cost-effective, and can generate new insights into the social structure of hidden populations. In addition, we develop methods for valid post-study inference which are non-trivial due to the adaptive sampling induced by RL as well as the complex dependencies among subjects due to latent (unobserved) social network structure. We provide asymptotic regret bounds and illustrate its finite sample behavior through a suite of simulation experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01505v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Justin Weltz, Angela Yoon, Yichi Zhang, Alexander Volfovsky, Eric Laber</dc:creator>
    </item>
    <item>
      <title>Multivariate Time Series Anomaly Detection using DiffGAN Model</title>
      <link>https://arxiv.org/abs/2501.01591</link>
      <description>arXiv:2501.01591v1 Announce Type: cross 
Abstract: In recent years, some researchers have applied diffusion models to multivariate time series anomaly detection. The partial diffusion strategy, which depends on the diffusion steps, is commonly used for anomaly detection in these models. However, different diffusion steps have an impact on the reconstruction of the original data, thereby impacting the effectiveness of anomaly detection. To address this issue, we propose a novel method named DiffGAN, which adds a generative adversarial network component to the denoiser of diffusion model. This addition allows for the simultaneous generation of noisy data and prediction of diffusion steps. Compared to multiple state-of-the-art reconstruction models, experimental results demonstrate that DiffGAN achieves superior performance in anomaly detection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01591v1</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guangqiang Wu, Fu Zhang</dc:creator>
    </item>
    <item>
      <title>Parallelized Midpoint Randomization for Langevin Monte Carlo</title>
      <link>https://arxiv.org/abs/2402.14434</link>
      <description>arXiv:2402.14434v3 Announce Type: replace 
Abstract: We study the problem of sampling from a target probability density function in frameworks where parallel evaluations of the log-density gradient are feasible. Focusing on smooth and strongly log-concave densities, we revisit the parallelized randomized midpoint method and investigate its properties using recently developed techniques for analyzing its sequential version. Through these techniques, we derive upper bounds on the Wasserstein distance between sampling and target densities. These bounds quantify the substantial runtime improvements achieved through parallel processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.14434v3</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lu Yu, Arnak Dalalyan</dc:creator>
    </item>
    <item>
      <title>Rates of convergence and normal approximations for estimators of local dependence random graph models</title>
      <link>https://arxiv.org/abs/2404.11464</link>
      <description>arXiv:2404.11464v2 Announce Type: replace 
Abstract: Local dependence random graph models are a class of block models for network data which allow for dependence among edges under a local dependence assumption defined around the block structure of the network. Since being introduced by Schweinberger and Handcock (2015), research in the statistical network analysis and network science literatures have demonstrated the potential and utility of this class of models. In this work, we provide the first theory for estimation and inference which ensures consistent and valid inference of parameter vectors of local dependence random graph models. This is accomplished by deriving convergence rates of estimation and inference procedures for local dependence random graph models based on a single observation of the graph, allowing both the number of model parameters and the sizes of blocks to tend to infinity. First, we derive non-asymptotic bounds on the $\ell_2$-error of maximum likelihood estimators with convergence rates, outlining conditions under which these rates are minimax optimal. Second, and more importantly, we derive non-asymptotic bounds on the error of the multivariate normal approximation. These theoretical results are the first to achieve both optimal rates of convergence and non-asymptotic bounds on the error of the multivariate normal approximation for parameter vectors of local dependence random graph models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11464v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonathan R. Stewart</dc:creator>
    </item>
    <item>
      <title>Matching-Based Policy Learning</title>
      <link>https://arxiv.org/abs/2407.08468</link>
      <description>arXiv:2407.08468v2 Announce Type: replace 
Abstract: The beneficial effects of treatments vary across individuals in most studies. Treatment heterogeneity motivates practitioners to search for the optimal policy based on personal characteristics. A long-standing common practice in policy learning has been estimating and maximizing the value function using weighting techniques. Matching is widely used in many applied disciplines to infer causal effects, which is intuitively appealing because the observed covariates are directly balanced across different treatment groups. Nevertheless, matching is rarely explored in policy learning. In this work, we propose a matching-based policy learning framework. We adapt standard and bias-corrected matching methods to estimate an alternative form of the value function: the advantage function, which can be interpreted as the expected improvement achieved by implementing a given policy compared to the equiprobable random policy. We then learn the optimal policy over a restricted policy class by maximizing the matching estimator of the advantage function. We derive a non-asymptotic high probability bound for the regret of the learned optimal policy. Moreover, we show that the learned policy is almost rate-optimal. The competitive finite sample performance of the proposed method compared to weighting-based and outcome modeling-based learning methods is demonstrated in extensive simulation studies and a real data application.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08468v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xuqiao Li, Ying Yan</dc:creator>
    </item>
    <item>
      <title>Nonparametric Estimation of Ordinary Differential Equations: Snake and Stubble</title>
      <link>https://arxiv.org/abs/2407.14989</link>
      <description>arXiv:2407.14989v2 Announce Type: replace 
Abstract: We study nonparametric estimation in dynamical systems described by ordinary differential equations (ODEs). Specifically, we focus on estimating the unknown function $f \colon \mathbb{R}^d \to \mathbb{R}^d$ that governs the system dynamics through the ODE $\dot{u}(t) = f(u(t))$, where observations $Y_{j,i} = u_j(t_{j,i}) + \varepsilon_{j,i}$ of solutions $u_j$ of the ODE are made at times $t_{j,i}$ with independent noise $\varepsilon_{j,i}$.
  We introduce two novel models -- the Stubble model and the Snake model -- to mitigate the issue of observation location dependence on $f$, an inherent difficulty in nonparametric estimation of ODE systems. In the Stubble model, we observe many short solutions with initial conditions that adequately cover the domain of interest. Here, we study an estimator based on multivariate local polynomial regression and univariate polynomial interpolation. In the Snake model we observe few long trajectories that traverse the domain on interest. Here, we study an estimator that combines univariate local polynomial estimation with multivariate polynomial interpolation.
  For both models, we establish error bounds of order $n^{-\frac{\beta}{2(\beta +1)+d}}$ for $\beta$-smooth functions $f$ in an infinite dimensional function class of H\"older-type and establish minimax optimality for the Stubble model in general and for the Snake model under some conditions via comparison to lower bounds from parallel work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14989v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christof Sch\"otz</dc:creator>
    </item>
    <item>
      <title>On kernel mode estimation under RLT and WOD model</title>
      <link>https://arxiv.org/abs/2412.07874</link>
      <description>arXiv:2412.07874v2 Announce Type: replace 
Abstract: Let $(X_N)_{N\geq 1}$ denote a sequence of real random variables and let $\vartheta$ be the mode of the random variable of interest $X$. In this paper, we study the kernel mode estimator (say) $\vartheta_n$ when the data are widely orthant dependent (WOD) and subject to Random Left Truncation (RLT) mechanism. We establish the uniform consistency rate of the density estimator (say) $f_n$ of the underlying density $f$ as well as the almost sure convergence rate of $\vartheta_n$. The performance of the estimators are illustrated via some simulation studies and applied on a real dataset of car brake pads.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.07874v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohamed Kaber El Alem, Zohra Guessoum, Abdelkader Tatachak</dc:creator>
    </item>
  </channel>
</rss>
