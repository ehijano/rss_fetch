<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 13 Mar 2024 04:00:07 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 13 Mar 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Whiteness-based bilevel learning of regularization parameters in imaging</title>
      <link>https://arxiv.org/abs/2403.07026</link>
      <description>arXiv:2403.07026v1 Announce Type: new 
Abstract: We consider an unsupervised bilevel optimization strategy for learning regularization parameters in the context of imaging inverse problems in the presence of additive white Gaussian noise. Compared to supervised and semi-supervised metrics relying either on the prior knowledge of reference data and/or on some (partial) knowledge on the noise statistics, the proposed approach optimizes the whiteness of the residual between the observed data and the observation model with no need of ground-truth data.We validate the approach on standard Total Variation-regularized image deconvolution problems which show that the proposed quality metric provides estimates close to the mean-square error oracle and to discrepancy-based principles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07026v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>eess.IV</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carlo Santambrogio, Monica Pragliola, Alessandro Lanza, Marco Donatelli, Luca Calatroni</dc:creator>
    </item>
    <item>
      <title>Advanced-Step Real-time Iterations with Four Levels -- New Error Bounds and Fast Implementation in acados</title>
      <link>https://arxiv.org/abs/2403.07101</link>
      <description>arXiv:2403.07101v1 Announce Type: new 
Abstract: The Real-Time Iteration (RTI) is an online nonlinear model predictive control algorithm that performs a single Sequential Quadratic Programming (SQP) per sampling time. The algorithm is split into a preparation and a feedback phase, where the latter one performs as little computations as possible solving a single prepared quadratic program. To further improve the accuracy of this method, the Advanced-Step RTI (AS-RTI) performs additional Multi-Level Iterations (MLI) in the preparation phase, such as inexact or zero-order SQP iterations on a problem with a predicted state estimate. This paper extends and streamlines the existing analysis of AS-RTI, such as analyzing MLI of level A and B for the first time, and significantly simplifying the proofs for levels C and D. Moreover, this paper provides an efficient open-source implementation in acados, making it widely accessible to practitioners.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07101v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonathan Frey, Armin Nurkanovic, Moritz Diehl</dc:creator>
    </item>
    <item>
      <title>Stochastic Extragradient with Random Reshuffling: Improved Convergence for Variational Inequalities</title>
      <link>https://arxiv.org/abs/2403.07148</link>
      <description>arXiv:2403.07148v1 Announce Type: new 
Abstract: The Stochastic Extragradient (SEG) method is one of the most popular algorithms for solving finite-sum min-max optimization and variational inequality problems (VIPs) appearing in various machine learning tasks. However, existing convergence analyses of SEG focus on its with-replacement variants, while practical implementations of the method randomly reshuffle components and sequentially use them. Unlike the well-studied with-replacement variants, SEG with Random Reshuffling (SEG-RR) lacks established theoretical guarantees. In this work, we provide a convergence analysis of SEG-RR for three classes of VIPs: (i) strongly monotone, (ii) affine, and (iii) monotone. We derive conditions under which SEG-RR achieves a faster convergence rate than the uniform with-replacement sampling SEG. In the monotone setting, our analysis of SEG-RR guarantees convergence to an arbitrary accuracy without large batch sizes, a strong requirement needed in the classical with-replacement SEG. As a byproduct of our results, we provide convergence guarantees for Shuffle Once SEG (shuffles the data only at the beginning of the algorithm) and the Incremental Extragradient (does not shuffle the data). We supplement our analysis with experiments validating empirically the superior performance of SEG-RR over the classical with-replacement sampling SEG.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07148v1</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Konstantinos Emmanouilidis, Ren\'e Vidal, Nicolas Loizou</dc:creator>
    </item>
    <item>
      <title>Exploring iterative and non-iterative Fourier series-based methods of control optimization in application to a discontinuous capsule drive model</title>
      <link>https://arxiv.org/abs/2403.07208</link>
      <description>arXiv:2403.07208v1 Announce Type: new 
Abstract: The paper explains iterative and non-iterative approaches to control optimization with use of the Fourier series-based method. Both variants of the presented algorithm are used to numerically approximate optimal control of a discontinuous pendulum capsule drive. Firstly, the general algorithm and its two realizations (iterative and non-iterative) are presented. It is shown that the iterative variant assures non-decreasing quality of solutions in subsequent repetitions of the procedure and the background of such guarantees is explained. A numerical example follows: control of a self-propelled capsule drive is optimized using both approaches. Results are compared and discussed. It is expected that the presented methods can be useful in optimal control estimation for complex systems, particularly discontinuous ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07208v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sandra Zarychta, Marek Balcerzak, Jerzy Wojewoda</dc:creator>
    </item>
    <item>
      <title>Long-term Hydrothermal Bid-based Market Simulator</title>
      <link>https://arxiv.org/abs/2403.07270</link>
      <description>arXiv:2403.07270v1 Announce Type: new 
Abstract: Simulating long-term hydrothermal bid-based markets considering strategic agents is a challenging task. The representation of strategic agents considering inter-temporal constraints within a stochastic framework brings additional complexity to the already difficult single-period bilevel, thus, non-convex, optimal bidding problem. Thus, we propose a simulation methodology that effectively addresses these challenges for large-scale hydrothermal power systems. We demonstrate the effectiveness of the framework through a case study with real data from the large-scale Brazilian power system. In the case studies, we show the effects of market concentration in power systems and how contracts can be used to mitigate them. In particular, we show how market power might affect the current setting in Brazil. The developed method can strongly benefit policy makers, market monitors, and market designers as simulations can be used to understand existing power systems and experiment with alternative designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07270v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joaquim Dias Garcia, Alexandre Street, Mario Veiga Pereira</dc:creator>
    </item>
    <item>
      <title>Anderson acceleration for iteratively reweighted $\ell_1$ algorithm</title>
      <link>https://arxiv.org/abs/2403.07271</link>
      <description>arXiv:2403.07271v1 Announce Type: new 
Abstract: Iteratively reweighted L1 (IRL1) algorithm is a common algorithm for solving sparse optimization problems with nonconvex and nonsmooth regularization. The development of its acceleration algorithm, often employing Nesterov acceleration, has sparked significant interest. Nevertheless, the convergence and complexity analysis of these acceleration algorithms consistently poses substantial challenges. Recently, Anderson acceleration has gained prominence owing to its exceptional performance for speeding up fixed-point iteration, with numerous recent studies applying it to gradient-based algorithms. Motivated by the powerful impact of Anderson acceleration, we propose an Anderson-accelerated IRL1 algorithm and establish its local linear convergence rate. We extend this convergence result, typically observed in smooth settings, to a nonsmooth scenario. Importantly, our theoretical results do not depend on the Kurdyka-Lojasiewicz condition, a necessary condition in existing Nesterov acceleration-based algorithms. Furthermore, to ensure global convergence, we introduce a globally convergent Anderson accelerated IRL1 algorithm by incorporating a classical nonmonotone line search condition. Experimental results indicate that our algorithm outperforms existing Nesterov acceleration-based algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07271v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kexin Li</dc:creator>
    </item>
    <item>
      <title>Improved Algebraic Inverter Modelling for Four-Wire Power Flow Optimization</title>
      <link>https://arxiv.org/abs/2403.07285</link>
      <description>arXiv:2403.07285v1 Announce Type: new 
Abstract: This paper discusses the modeling of inverters used in distributed energy resources in steady state. Modeling the interaction between distribution grids and inverter-based resources is crucial to understand the consequences for the network's operational and planning processes. This work highlights the limitations of existing models and emphasizes the need for better representations of inverters and their control laws in decision-making contexts. Improved steady-state grid-following and grid-forming inverter models are presented, including both three-leg and four-leg converter variants. The advantages of these improved models in mathematical optimization contexts are showcased by investigating the power quality improvement capabilities of the inverters. Numerical studies integrating the proposed inverter models in a four-wire unbalanced optimal power flow engine are presented, and trade-offs between modeling detail and computational intensity are illustrated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07285v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rahmat Heidari, Frederik Geth</dc:creator>
    </item>
    <item>
      <title>Tight error bounds for log-determinant cones without constraint qualifications</title>
      <link>https://arxiv.org/abs/2403.07295</link>
      <description>arXiv:2403.07295v1 Announce Type: new 
Abstract: In this paper, without requiring any constraint qualifications, we establish tight error bounds for the log-determinant cone, which is the closure of the hypograph of the perspective function of the log-determinant function. This error bound is obtained using the recently developed framework based on one-step facial residual functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07295v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ying Lin, Scott B. Lindstrom, Bruno F. Louren\c{c}o, Ting Kei Pong</dc:creator>
    </item>
    <item>
      <title>Zero-Sum Stochastic Games with Vanishing Stage Duration and Public Signals</title>
      <link>https://arxiv.org/abs/2403.07467</link>
      <description>arXiv:2403.07467v1 Announce Type: new 
Abstract: We consider the behaviour of $\lambda$-discounted zero-sum games as the discount factor $\lambda$ tends to 0 (that is, the players are more and more patient), in the context of games with stage duration. In stochastic games with stage duration h, players act at times 0, h, 2h, ..., and the payoff and leaving probabilities are proportional to h. When h tends to 0, such games approximate games in continuous time. The asymptotic behavior of the values (when both $\lambda$ and h tend to 0) was already studied in the case of stochastic games with perfect observation of the state and in the state-blind case. We consider the same question for the case of stochastic games with imperfect observation of the state. In such games, players are given at each stage a public signal that depends only on the current state. Our main result states that there exists a stochastic game with public signals, with no limit value (as the discount factor $\lambda$ goes to 0) if stage duration is 1, but with a limit value when stage duration h and discount factor $\lambda$ both tend to 0. Informally speaking, it means that the limit value in discrete time does not exist, but the limit value in continuous time (i.e., when h tends to 0) exists. Such a situation is impossible in the case of stochastic games with perfect observation of the state.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07467v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ivan Novikov (CEREMADE)</dc:creator>
    </item>
    <item>
      <title>PMBO: Enhancing Black-Box Optimization through Multivariate Polynomial Surrogates</title>
      <link>https://arxiv.org/abs/2403.07485</link>
      <description>arXiv:2403.07485v1 Announce Type: new 
Abstract: We introduce a surrogate-based black-box optimization method, termed Polynomial-model-based optimization (PMBO). The algorithm alternates polynomial approximation with Bayesian optimization steps, using Gaussian processes to model the error between the objective and its polynomial fit. We describe the algorithmic design of PMBO and compare the results of the performance of PMBO with several optimization methods for a set of analytic test functions.
  The results show that PMBO outperforms the classic Bayesian optimization and is robust with respect to the choice of its correlation function family and its hyper-parameter setting, which, on the contrary, need to be carefully tuned in classic Bayesian optimization. Remarkably, PMBO performs comparably with state-of-the-art evolutionary algorithms such as the Covariance Matrix Adaptation -- Evolution Strategy (CMA-ES). This finding suggests that PMBO emerges as the pivotal choice among surrogate-based optimization methods when addressing low-dimensional optimization problems. Hereby, the simple nature of polynomials opens the opportunity for interpretation and analysis of the inferred surrogate model, providing a macroscopic perspective on the landscape of the objective function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07485v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.MS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Janina Schreiber, Pau Batlle, Damar Wicaksono, Michael Hecht</dc:creator>
    </item>
    <item>
      <title>Comments on characterizing demand flexibility to provide power grid services</title>
      <link>https://arxiv.org/abs/2403.07529</link>
      <description>arXiv:2403.07529v1 Announce Type: new 
Abstract: Many loads have flexibility in demand that can be used to provide ancillary services to power grids. A large body of literature exists on designing algorithms to coordinate actions of many loads to provide such a service. The topic of characterizing the flexibility of one or a collection of loads - to determine what kinds of demand deviation from the baseline is feasible - has also been studied. However, there is a large diversity in definitions of flexibility and methods proposed to characterize flexibility. As a result there are several gaps in the literature on flexibility characterization. Some approaches on flexibility characterization are based on ad-hoc approximations that lead to highly conservative estimates. In this paper we point out some of these issues and their implications, with the hope to encourage additional research to address them.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07529v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Prabir Barooah</dc:creator>
    </item>
    <item>
      <title>Consensus under Persistence Excitation</title>
      <link>https://arxiv.org/abs/2403.07549</link>
      <description>arXiv:2403.07549v1 Announce Type: new 
Abstract: We prove that a first-order cooperative system of interacting agents converges to consensus if the so-called Persistence Excitation condition holds. This condition requires that the interaction function between any pair of agents satisfies an integral lower bound. The interpretation is that the interaction needs to ensure a minimal amount of service.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07549v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabio Ancona, Mohamed Bentaibi, Francesco Rossi</dc:creator>
    </item>
    <item>
      <title>On Weakly Contracting Dynamics for Convex Optimization</title>
      <link>https://arxiv.org/abs/2403.07572</link>
      <description>arXiv:2403.07572v1 Announce Type: new 
Abstract: We investigate the convergence characteristics of dynamics that are \emph{globally weakly} and \emph{locally strongly contracting}. Such dynamics naturally arise in the context of convex optimization problems with a unique minimizer. We show that convergence to the equilibrium is \emph{linear-exponential}, in the sense that the distance between each solution and the equilibrium is upper bounded by a function that first decreases linearly and then exponentially. As we show, the linear-exponential dependency arises naturally in certain dynamics with saturations. Additionally, we provide a sufficient condition for local input-to-state stability. Finally, we illustrate our results on, and propose a conjecture for, continuous-time dynamical systems solving linear programs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07572v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Veronica Centorrino, Alexander Davydov, Anand Gokhale, Giovanni Russo, Francesco Bullo</dc:creator>
    </item>
    <item>
      <title>Optimal control of stochastic cylinder flow using data-driven compressive sensing method</title>
      <link>https://arxiv.org/abs/2403.07656</link>
      <description>arXiv:2403.07656v1 Announce Type: new 
Abstract: A stochastic optimal control problem for incompressible Newtonian channel flow past a circular cylinder is used as a prototype optimal control problem for the stochastic Navier-Stokes equations. The inlet flow and the rotation speed of the cylinder are allowed to have stochastic perturbations. The control acts on the cylinder via adjustment of the rotation speed. Possible objectives of the control include, among others, tracking a desired (given) velocity field or minimizing the kinetic energy, enstrophy, or the drag of the flow over a given body. Owing to the high computational requirements, the direct application of the classical Monte Carlo methods for our problem is limited. To overcome the difficulty, we use a multi-fidelity data-driven compressive sensing based polynomial chaos expansions (MDCS-PCE). An effective gradient-based optimization for the discrete optimality systems resulted from the MDCS-PCE discretization is developed. The strategy can be applied broadly to many stochastic flow control problems. Numerical tests are performed to validate our methodology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07656v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liuhong Chen, Ju Ming, Max D. Gunzburger</dc:creator>
    </item>
    <item>
      <title>Tightly Bounded Polynomials via Flexible Discretizations for Dynamic Optimization Problems</title>
      <link>https://arxiv.org/abs/2403.07707</link>
      <description>arXiv:2403.07707v1 Announce Type: new 
Abstract: Polynomials are widely used to represent the trajectories of states and/or inputs. It has been shown that a polynomial can be bounded by its coefficients, when expressed in the Bernstein basis. However, in general, the bounds provided by the Bernstein coefficients are not tight. We propose a method for obtaining numerical solutions to dynamic optimization problems, where a flexible discretization is used to achieve tight polynomial bounds. The proposed method is used to solve a constrained cart-pole swing-up optimal control problem. The flexible discretization eliminates the conservatism of the Bernstein bounds and enables a lower cost, in comparison with non-flexible discretizations. A theoretical result on obtaining tight polynomial bounds with a finite discretization is presented. In some applications with linear dynamics, the non-convexity introduced by the flexible discretization may be a drawback.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07707v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eduardo M. G. Vila, Eric C. Kerrigan</dc:creator>
    </item>
    <item>
      <title>Tightening big Ms in integer programming formulations for support vector machines with ramp loss</title>
      <link>https://arxiv.org/abs/2403.07736</link>
      <description>arXiv:2403.07736v1 Announce Type: new 
Abstract: This paper considers various models of support vector machines with ramp loss, these being an efficient and robust tool in supervised classification for the detection of outliers. The exact solution approaches for the resulting optimization problem are of high demand for large datasets. Hence, the goal of this paper is to develop algorithms that provide efficient methodologies to exactly solve these optimization problems. These approaches are based on three strategies for obtaining tightened values of the big M parameters included in the formulation of the problem. Two of them require solving a sequence of continuous problems, while the third uses the Lagrangian relaxation to tighten the bounds. The proposed resolution methods are valid for the l1-norm and l2-norm ramp loss formulations. They were tested and compared with existing solution methods in simulated and real-life datasets, showing the efficiency of the developed methodology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07736v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ejor.2020.03.023</arxiv:DOI>
      <arxiv:journal_reference>European Journal of Operational Research, 286, (2020), 84-100</arxiv:journal_reference>
      <dc:creator>Marta Baldomero-Naranjo, Luisa I. Mart\'inez-Merino, Antonio M. Rodr\'iguez-Ch\'ia</dc:creator>
    </item>
    <item>
      <title>A robust SVM-based approach with feature selection and outliers detection for classification problems</title>
      <link>https://arxiv.org/abs/2403.07753</link>
      <description>arXiv:2403.07753v1 Announce Type: new 
Abstract: This paper proposes a robust classification model, based on support vector machine (SVM), which simultaneously deals with outliers detection and feature selection. The classifier is built considering the ramp loss margin error and it includes a budget constraint to limit the number of selected features. The search of this classifier is modeled using a mixed-integer formulation with big M parameters. Two different approaches (exact and heuristic) are proposed to solve the model. The heuristic approach is validated by comparing the quality of the solutions provided by this approach with the exact approach. In addition, the classifiers obtained with the heuristic method are tested and compared with existing SVM-based models to demonstrate their efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07753v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.eswa.2021.115017</arxiv:DOI>
      <arxiv:journal_reference>Expert Systems With Applications 178 (2021) 115017</arxiv:journal_reference>
      <dc:creator>Marta Baldomero-Naranjo, Luisa I. Mart\'inez-Merino, Antonio M. Rodr\'iguez-Ch\'ia</dc:creator>
    </item>
    <item>
      <title>Pediatric vaccine tender scheduling in low- and middle-income countries</title>
      <link>https://arxiv.org/abs/2403.07755</link>
      <description>arXiv:2403.07755v1 Announce Type: new 
Abstract: Effective and efficient scheduling of vaccine distribution can significantly impact vaccine uptake, which is critical to controlling the spread of infectious diseases. Ineffective scheduling can lead to waste, delays, and low vaccine coverage, potentially weakening the efforts to protect the public. Organizations such as UNICEF (United Nations Children's Fund), PAHO (Pan American Health Organization), and GAVI (Gavi, the Vaccine Alliance) coordinate vaccine tenders to ensure that enough supply is available on the international market at the lowest possible prices. Scheduling vaccine tenders over a planning horizon in a way that is equitable, efficient, and accessible is a complex problem that involves trade-offs between multiple objectives while ensuring that vaccine availability, demand, and logistical constraints are met. The current method for scheduling tenders is generally reactive and over short planning horizons. Vaccine tenders are scheduled when supply is insufficient to cover demand. We propose an optimization model to dynamically and proactively generate vaccine tender schedules over long planning horizons. This model helps us address the following research questions: What should the optimal sequencing and scheduling of vaccine tenders be to enhance affordability and profit over long time horizons? What is the optimal tender procurement schedule for single or multiple antigen scenarios? We use several real-life data sources to validate the model and address our research questions. Results from our analysis show when to schedule vaccine tenders, what volumes manufacturers should commit to, and the optimal tender lengths to satisfy demand. We show that vaccine tenders tend towards maximum lengths, generally converge over long time horizons, and are robust to changes in varying conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07755v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicholas Uhorchak, Ruben A. Proano, Sandra Eksioglu, Fatih Cengil, Burak Eksioglu</dc:creator>
    </item>
    <item>
      <title>The probabilistic p-center problem: Planning service for potential customers</title>
      <link>https://arxiv.org/abs/2403.07775</link>
      <description>arXiv:2403.07775v1 Announce Type: new 
Abstract: This work deals with the probabilistic p-center problem, which aims at minimizing the expected maximum distance between any site with demand and its center, considering that each site has demand with a specific probability. The problem is of interest when emergencies may occur at predefined sites with known probabilities. For this problem we propose and analyze different formulations as well as a Variable Neighborhood Search heuristic. Computational tests are reported, showing the potentials and limits of each formulation, the impact of their enhancements, and the effectiveness of the heuristic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07775v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ejor.2017.03.043</arxiv:DOI>
      <arxiv:journal_reference>European Journal of Operational Research 262 (2017) 509-520</arxiv:journal_reference>
      <dc:creator>Luisa I. Mart\'inez-Merino, Maria Albareda-Sambola, Antonio M. Rodr\'iguez-Ch\'ia</dc:creator>
    </item>
    <item>
      <title>Multi-period stochastic covering location problems: Modeling framework and solution approach</title>
      <link>https://arxiv.org/abs/2403.07785</link>
      <description>arXiv:2403.07785v1 Announce Type: new 
Abstract: This paper introduces a very general discrete covering location model that accounts for uncertainty and time-dependent aspects. A MILP formulation is proposed for the problem. Afterwards, it is observed that most of the models existing in the literature related with covering location can be considered as particular cases of this formulation. In order to tackle large instances of this problem a Lagrangian relaxation based heuristic is developed. A computational study is addressed to check the potentials and limits of the formulation and some variants proposed for the problem, as well as to evaluate the heuristic. Finally, different measures to report the relevance of considering a multi-period stochastic setting are studied.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07785v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ejor.2018.01.040</arxiv:DOI>
      <arxiv:journal_reference>European Journal of Operational Research 268 (2018) 432-449</arxiv:journal_reference>
      <dc:creator>Alfredo Mar\'in, Luisa I. Mart\'inez-Merio, Antonio M. Rodr\'iguez-Ch\'ia, Francisco Saldanha-da-Gama</dc:creator>
    </item>
    <item>
      <title>A Stochastic GDA Method With Backtracking For Solving Nonconvex (Strongly) Concave Minimax Problems</title>
      <link>https://arxiv.org/abs/2403.07806</link>
      <description>arXiv:2403.07806v1 Announce Type: new 
Abstract: We propose a stochastic GDA (gradient descent ascent) method with backtracking (SGDA-B) to solve nonconvex-(strongly) concave (NCC) minimax problems $\min_x \max_y \sum_{i=1}^N g_i(x_i)+f(x,y)-h(y)$, where $h$ and $g_i$ for $i = 1, \ldots, N$ are closed, convex functions, $f$ is $L$-smooth and $\mu$-strongly concave in $y$ for some $\mu\geq 0$. We consider two scenarios: (i) the deterministic setting where we assume one can compute $\nabla f$ exactly, and (ii) the stochastic setting where we have only access to $\nabla f$ through an unbiased stochastic oracle with a finite variance. While most of the existing methods assume knowledge of the Lipschitz constant $L$, SGDA-B is agnostic to $L$. Moreover, SGDA-B can support random block-coordinate updates. In the deterministic setting, SGDA-B can compute an $\epsilon$-stationary point within $\mathcal{O}(L\kappa^2/\epsilon^2)$ and $\mathcal{O}(L^3/\epsilon^4)$ gradient calls when $\mu&gt;0$ and $\mu=0$, respectively, where $\kappa=L/\mu$. In the stochastic setting, for any $p \in (0, 1)$ and $\epsilon &gt;0$, it can compute an $\epsilon$-stationary point with high probability, which requires $\mathcal{O}(L\kappa^3\epsilon^{-4}\log(1/p))$ and $\tilde{\mathcal{O}}(L^4\epsilon^{-7}\log(1/p))$ stochastic oracle calls, with probability at least $1-p$, when $\mu&gt;0$ and $\mu=0$, respectively. To our knowledge, SGDA-B is the first GDA-type method with backtracking to solve NCC minimax problems and achieves the best complexity among the methods that are agnostic to $L$. We also provide numerical results for SGDA-B on a distributionally robust learning problem illustrating the potential performance gains that can be achieved by SGDA-B.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07806v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiushui Xu, Xuan Zhang, Necdet Serhat Aybat, Mert G\"urb\"uzbalaban</dc:creator>
    </item>
    <item>
      <title>Mesh Refinement with Early Termination for Dynamic Feasibility Problems</title>
      <link>https://arxiv.org/abs/2403.07811</link>
      <description>arXiv:2403.07811v1 Announce Type: new 
Abstract: We propose a novel early-terminating mesh refinement strategy using an integrated residual method to solve dynamic feasibility problems. As a generalization of direct collocation, the integrated residual method is used to approximate an infinite-dimensional problem into a sequence of finite-dimensional optimization subproblems. Each subproblem in the sequence is a finer approximation of the previous. It is shown that these subproblems need not be solved to a high precision; instead, an early termination procedure can determine when mesh refinement should be performed. The new refinement strategy, applied to an inverted pendulum swing-up problem, outperforms a conventional refinement method by up to a factor of three in function evaluations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07811v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ifacol.2023.10.676</arxiv:DOI>
      <arxiv:journal_reference>IFAC-PapersOnLine Volume 56, Issue 2, 2023, Pages 10576-10581</arxiv:journal_reference>
      <dc:creator>Eduardo M. G. Vila, Eric C. Kerrigan, Paul Bruce</dc:creator>
    </item>
    <item>
      <title>Convex cones, assessment functions, balanced attributes</title>
      <link>https://arxiv.org/abs/2403.07829</link>
      <description>arXiv:2403.07829v1 Announce Type: new 
Abstract: We investigate a class of polyhedral convex cones, with $R^k_+$ (the nonegative orthant in $\mathbb{R}^k$) as a special case. We start with the observation that for convex cones contained in $\mathbb{R}^k$, the respective cone efficiency is inconsistent with the Pareto efficiency, the latter being deeply rooted in economics, the decision theory, and the multiobjective optimization theory. Despite that, we argue that convex cones contained in $\mathbb{R}^k$ and the respective cone efficiency are also relevant to these domains.
  To demonstrate this, we interpret polyhedral convex cones of the investigated class in terms of assessment functions, i.e., functions that aggregate multiple numerical attributes into single numbers.
  Further, we observe that all assessment functions in the current use share the same limitation; that is, they do not take explicitly into account attribute proportionality. In consequence, the issue of {\em attribute balance} (meaning {\it the balance of attribute values}) escapes them. In contrast, assessment functions defined by polyhedral convex cones of the investigated class, contained in $\mathbb{R}^k$, enforce the attribute balance. However, enforcing the attribute balance is, in general, inconsistent with the well-established paradigm of Pareto efficiency. We give a practical example where such inconsistency is meaningful.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07829v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ignacy Kaliszewski</dc:creator>
    </item>
    <item>
      <title>Convergence of Some Convex Message Passing Algorithms to a Fixed Point</title>
      <link>https://arxiv.org/abs/2403.07004</link>
      <description>arXiv:2403.07004v1 Announce Type: cross 
Abstract: A popular approach to the MAP inference problem in graphical models is to minimize an upper bound obtained from a dual linear programming or Lagrangian relaxation by (block-)coordinate descent. Examples of such algorithms are max-sum diffusion and sequential tree-reweighted message passing. Convergence properties of these methods are currently not fully understood. They have been proved to converge to the set characterized by local consistency of active constraints, with unknown convergence rate; however, it was not clear if the iterates converge at all (to any single point). We prove a stronger result (which was conjectured before but never proved): the iterates converge to a fixed point of the algorithm. Moreover, we show that they achieve precision $\varepsilon&gt;0$ in $\mathcal{O}(1/\varepsilon)$ iterations.
  We first prove this for a version of coordinate descent applied to a general piecewise-affine convex objective, using a novel proof technique. Then we demonstrate the generality of this approach by reducing some popular coordinate-descent algorithms to this problem. Finally we show that, in contrast to our main result, a similar version of coordinate descent applied to a constrained optimization problem need not converge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07004v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vaclav Voracek, Tomas Werner</dc:creator>
    </item>
    <item>
      <title>An Efficient Learning-based Solver Comparable to Metaheuristics for the Capacitated Arc Routing Problem</title>
      <link>https://arxiv.org/abs/2403.07028</link>
      <description>arXiv:2403.07028v1 Announce Type: cross 
Abstract: Recently, neural networks (NN) have made great strides in combinatorial optimization. However, they face challenges when solving the capacitated arc routing problem (CARP) which is to find the minimum-cost tour covering all required edges on a graph, while within capacity constraints. In tackling CARP, NN-based approaches tend to lag behind advanced metaheuristics, since they lack directed arc modeling and efficient learning methods tailored for complex CARP. In this paper, we introduce an NN-based solver to significantly narrow the gap with advanced metaheuristics while exhibiting superior efficiency. First, we propose the direction-aware attention model (DaAM) to incorporate directionality into the embedding process, facilitating more effective one-stage decision-making. Second, we design a supervised reinforcement learning scheme that involves supervised pre-training to establish a robust initial policy for subsequent reinforcement fine-tuning. It proves particularly valuable for solving CARP that has a higher complexity than the node routing problems (NRPs). Finally, a path optimization method is proposed to adjust the depot return positions within the path generated by DaAM. Experiments illustrate that our approach surpasses heuristics and achieves decision quality comparable to state-of-the-art metaheuristics for the first time while maintaining superior efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07028v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Runze Guo, Feng Xue, Anlong Ming, Nicu Sebe</dc:creator>
    </item>
    <item>
      <title>Quantitative 2D propagation of smallness and control for 1D heat equations with power growth potentials</title>
      <link>https://arxiv.org/abs/2403.07643</link>
      <description>arXiv:2403.07643v1 Announce Type: cross 
Abstract: We study the relation between propagation of smallness in the plane and control for heat equations. The former has been proved by Zhu who showed how the value of solutions in some small set propagates to a larger domain. By reviewing his proof, we establish a quantitative version with the explicit dependence of parameters. Using this explicit version, we establish new exact null-controllability results of 1D heat equations with any nonnegative power growth potentials $V\in\mathcal{C}(\mathbb{R})$. As a key ingredient, new spectral inequalities are established. The control set $\Omega$ that we consider satisfy \begin{equation*}
  \left|\Omega\cap [x-L\langle x\rangle ^{-s},x+L\langle x\rangle ^{-s}]\right|\ge \gamma^{\langle x\rangle^\tau}2L\langle x\rangle^{-s} \end{equation*} for some $\gamma\in(0,1)$, $L&gt;0$, $\tau,s\ge 0$, and $\langle x\rangle:=(1+|x|^2)^{1 /2} $. In particular, the null-controllability result for the case of thick sets that allow the decay of the density (\textit{i.e.}, $s=0$ and $\tau\ge 0$) is included. These extend the Zhu-Zhuge's results from $\Omega$ being the union of equidistributive open sets to thick sets in the 1-dimensional case, and Su-Sun-Yuan's result from bounded potentials to certain unbounded ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07643v1</guid>
      <category>math.AP</category>
      <category>math.CA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunlei Wang</dc:creator>
    </item>
    <item>
      <title>On the Last-Iterate Convergence of Shuffling Gradient Methods</title>
      <link>https://arxiv.org/abs/2403.07723</link>
      <description>arXiv:2403.07723v1 Announce Type: cross 
Abstract: Shuffling gradient methods, which are also known as stochastic gradient descent (SGD) without replacement, are widely implemented in practice, particularly including three popular algorithms: Random Reshuffle (RR), Shuffle Once (SO), and Incremental Gradient (IG). Compared to the empirical success, the theoretical guarantee of shuffling gradient methods was not well-understanding for a long time. Until recently, the convergence rates had just been established for the average iterate for convex functions and the last iterate for strongly convex problems (using squared distance as the metric). However, when using the function value gap as the convergence criterion, existing theories cannot interpret the good performance of the last iterate in different settings (e.g., constrained optimization). To bridge this gap between practice and theory, we prove last-iterate convergence rates for shuffling gradient methods with respect to the objective value even without strong convexity. Our new results either (nearly) match the existing last-iterate lower bounds or are as fast as the previous best upper bounds for the average iterate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07723v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zijian Liu, Zhengyuan Zhou</dc:creator>
    </item>
    <item>
      <title>Quotients of M-convex sets and M-convex functions</title>
      <link>https://arxiv.org/abs/2403.07751</link>
      <description>arXiv:2403.07751v1 Announce Type: cross 
Abstract: We unify the study of quotients of matroids, polymatroids, valuated matroids and strong maps of submodular functions in the framework of Murota's discrete convex analysis. As a main result, we compile a list of ten equivalent characterizations of quotients for M-convex sets, generalizing existing formulations for (poly)matroids and submodular functions. We also initiate the study of quotients of M-convex functions, constructing a hierarchy of four separate characterizations. Our investigations yield new insights into the fundamental operation of induction, as well as the structure of linking sets and linking functions, which are generalizations of linking systems and bimatroids.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07751v1</guid>
      <category>math.CO</category>
      <category>math.AG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marie-Charlotte Brandenburg, Georg Loho, Ben Smith</dc:creator>
    </item>
    <item>
      <title>Variational structures for the Fokker--Planck equation with general Dirichlet boundary conditions</title>
      <link>https://arxiv.org/abs/2403.07803</link>
      <description>arXiv:2403.07803v1 Announce Type: cross 
Abstract: We prove convergence of a modified Jordan--Kinderlehrer--Otto scheme to a solution to the Fokker--Planck equation in $\Omega \Subset \mathbb{R}^d$ with spatially nonconstant Dirichlet boundary conditions. We work under mild assumptions on the domain, on the drift, and on the initial datum. In the special case where $\Omega$ is an interval in $\mathbb{R}^1$, we prove that such a solution is a gradient flow -- curve of maximal slope -- within a suitable space of measures, endowed with a modified Wasserstein distance. Our discrete scheme and modified distance draw inspiration from contributions by A. Figalli and N. Gigli [J. Math. Pures Appl. 94, (2010), pp. 107--130], and J. Morales [J. Math. Pures Appl. 112, (2018), pp. 41--88] on an optimal-transport approach to evolution equations with Dirichlet boundary conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07803v1</guid>
      <category>math.AP</category>
      <category>math.MG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Filippo Quattrocchi</dc:creator>
    </item>
    <item>
      <title>Affine Gateaux Differentials and the von Mises Statistical Calculus</title>
      <link>https://arxiv.org/abs/2403.07827</link>
      <description>arXiv:2403.07827v1 Announce Type: cross 
Abstract: This paper presents a general study of one-dimensional differentiability for functionals on convex domains that are not necessarily open. The local approximation is carried out by affine functionals, rather than linear ones as in standard Gateaux differentiability. This affine notion of differentiability naturally arises in many applications and, here and there, it appeared in the literature. Our systematic analysis aims to give a general perspective on it.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07827v1</guid>
      <category>math.FA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simone Cerreia-Vioglio, Fabio Maccheroni, Massimo Marinacci, Luigi Montrucchio, Lorenzo Stanca</dc:creator>
    </item>
    <item>
      <title>Equilibrium strategies in time-inconsistent stochastic control problems with constraints: necessary conditions</title>
      <link>https://arxiv.org/abs/2105.01473</link>
      <description>arXiv:2105.01473v3 Announce Type: replace 
Abstract: This paper is concerned with a time-inconsistent recursive stochastic control problems where the forward state process is constrained through an additional recursive utility system. By adapting the Ekeland variational principle, necessary conditions for equilibrium strategies are presented concerning a second-order Hamiltonian function defined by pairs of backward stochastic differential equations. At last, we consider a finite horizon state constrained investment-consumption problem with non-exponential actualisation as an example to show the application in finance. The class of constraints investigated here includes the possibility of imposing a risk bound on the terminal value of the wealth process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2105.01473v3</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Elisa Mastrogiacomo, Marco Tarsia</dc:creator>
    </item>
    <item>
      <title>Stochastic Mirror Descent for Convex Optimization with Consensus Constraints</title>
      <link>https://arxiv.org/abs/2201.08642</link>
      <description>arXiv:2201.08642v3 Announce Type: replace 
Abstract: The mirror descent algorithm is known to be effective in situations where it is beneficial to adapt the mirror map to the underlying geometry of the optimization model. However, the effect of mirror maps on the geometry of distributed optimization problems has not been previously addressed. In this paper we study an exact distributed mirror descent algorithm in continuous-time under additive noise. We establish a linear convergence rate of the proposed dynamics for the setting of convex optimization. Our analysis draws motivation from the Augmented Lagrangian and its relation to gradient tracking. To further explore the benefits of mirror maps in a distributed setting we present a preconditioned variant of our algorithm with an additional mirror map over the Lagrangian dual variables. This allows our method to adapt to both the geometry of the primal variables, as well as to the geometry of the consensus constraint. We also propose a Gauss-Seidel type discretization scheme for the proposed method and establish its linear convergence rate. For certain classes of problems we identify mirror maps that mitigate the effect of the graph's spectral properties on the convergence rate of the algorithm. Using numerical experiments we demonstrate the efficiency of the methodology on convex models, both with and without constraints. Our findings show that the proposed method outperforms other methods, especially in scenarios where the model's geometry is not captured by the standard Euclidean norm</description>
      <guid isPermaLink="false">oai:arXiv.org:2201.08642v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anastasia Borovykh, Nikolas Kantas, Panos Parpas, Grigorios A. Pavliotis</dc:creator>
    </item>
    <item>
      <title>Turnpilke property for infinite-dimensional generalized LQ problem</title>
      <link>https://arxiv.org/abs/2208.00307</link>
      <description>arXiv:2208.00307v3 Announce Type: replace 
Abstract: We deduce a sufficient condition of the exponential (integral) turnpike property for infinite dimensional generalized linear-quadratic optimal control problems in terms of structural properties of the control system, such as exponential stabilizability and detectability. The proof relies on the analysis of the exponential convergence of solutions to the differential Riccati equations to the algebraic counterpart, and on a necessary condition for exponential stabilizability in terms of a closed range test.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.00307v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhuqing Li, Roberto Guglielmi</dc:creator>
    </item>
    <item>
      <title>Exploiting higher-order derivatives in convex optimization methods</title>
      <link>https://arxiv.org/abs/2208.13190</link>
      <description>arXiv:2208.13190v3 Announce Type: replace 
Abstract: Exploiting higher-order derivatives in convex optimization is known at least since 1970's. In each iteration higher-order (also called tensor) methods minimize a regularized Taylor expansion of the objective function, which leads to faster convergence rates if the corresponding higher-order derivative is Lipschitz-continuous. Recently a series of lower iteration complexity bounds for such methods were proved, and a gap between upper an lower complexity bounds was revealed. Moreover, it was shown that such methods can be implementable since the appropriately regularized Taylor expansion of a convex function is also convex and, thus, can be minimized in polynomial time. Only very recently an algorithm with optimal convergence rate $1/k^{(3p+1)/2}$ was proposed for minimizing convex functions with Lipschitz $p$-th derivative. For convex functions with Lipschitz third derivative, these developments allowed to propose a second-order method with convergence rate $1/k^5$, which is faster than the rate $1/k^{3.5}$ of existing second-order methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.13190v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dmitry Kamzolov, Alexander Gasnikov, Pavel Dvurechensky, Artem Agafonov, Martin Tak\'a\v{c}</dc:creator>
    </item>
    <item>
      <title>Improved microgrid resiliency through distributionally robust optimization under a policy-mode framework</title>
      <link>https://arxiv.org/abs/2210.12586</link>
      <description>arXiv:2210.12586v2 Announce Type: replace 
Abstract: Critical energy infrastructure are constantly understress due to the ever increasing disruptions caused by wildfires, hurricanes, other weather related extreme events and cyber-attacks. Hence it becomes important to make critical infrastructure resilient to threats from such cyber-physical events. Such events are however hard to predict and numerous in nature and type, making it infeasible to become resilient to all possible cyber-physical event as such an approach would make the system operation overly conservative. Furthermore, distributions of such events are hard to predict and historical data available on such events is sparse. To deal with these issues, we present a policy-mode framework that enumerates and predicts the probability of various cyber-physical events on top of a distributionally robust optimization (DRO) that is robust to the sparsity of the available historical data. The proposed algorithm is illustrated on an islanded microgrid example: a modified IEEE 123-node feeder with distributed energy resources (DERs) and energy storage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.12586v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nawaf Nazir, Thiagarajan Ramachandaran, Soumya Kundu, Veronica Adetola</dc:creator>
    </item>
    <item>
      <title>From approximate to exact integer programming</title>
      <link>https://arxiv.org/abs/2211.03859</link>
      <description>arXiv:2211.03859v3 Announce Type: replace 
Abstract: Approximate integer programming is the following: For a convex body $K \subseteq \mathbb{R}^n$, either determine whether $K \cap \mathbb{Z}^n$ is empty, or find an integer point in the convex body scaled by $2$ from its center of gravity $c$. Approximate integer programming can be solved in time $2^{O(n)}$ while the fastest known methods for exact integer programming run in time $2^{O(n)} \cdot n^n$. So far, there are no efficient methods for integer programming known that are based on approximate integer programming. Our main contribution are two such methods, each yielding novel complexity results.
  First, we show that an integer point $x^* \in (K \cap \mathbb{Z}^n)$ can be found in time $2^{O(n)}$, provided that the remainders of each component $x_i^* \mod{\ell}$ for some arbitrarily fixed $\ell \geq 5(n+1)$ of $x^*$ are given. The algorithm is based on a cutting-plane technique, iteratively halving the volume of the feasible set. The cutting planes are determined via approximate integer programming. Enumeration of the possible remainders gives a $2^{O(n)}n^n$ algorithm for general integer programming. This matches the current best bound of an algorithm by Dadush (2012) that is considerably more involved. Our algorithm also relies on a new asymmetric approximate Carath\'eodory theorem that might be of interest on its own.
  Our second method concerns integer programming problems in equation-standard form $Ax = b, 0 \leq x \leq u, \, x \in \mathbb{Z}^n$ . Such a problem can be reduced to the solution of $\prod_i O(\log u_i +1)$ approximate integer programming problems. This implies, for example that knapsack or subset-sum problems with polynomial variable range $0 \leq x_i \leq p(n)$ can be solved in time $(\log n)^{O(n)}$. For these problems, the best running time so far was $n^n \cdot 2^{O(n)}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.03859v3</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Dadush, Friedrich Eisenbrand, Thomas Rothvoss</dc:creator>
    </item>
    <item>
      <title>Sharpened Lazy Incremental Quasi-Newton Method</title>
      <link>https://arxiv.org/abs/2305.17283</link>
      <description>arXiv:2305.17283v3 Announce Type: replace 
Abstract: The problem of minimizing the sum of $n$ functions in $d$ dimensions is ubiquitous in machine learning and statistics. In many applications where the number of observations $n$ is large, it is necessary to use incremental or stochastic methods, as their per-iteration cost is independent of $n$. Of these, Quasi-Newton (QN) methods strike a balance between the per-iteration cost and the convergence rate. Specifically, they exhibit a superlinear rate with $O(d^2)$ cost in contrast to the linear rate of first-order methods with $O(d)$ cost and the quadratic rate of second-order methods with $O(d^3)$ cost. However, existing incremental methods have notable shortcomings: Incremental Quasi-Newton (IQN) only exhibits asymptotic superlinear convergence. In contrast, Incremental Greedy BFGS (IGS) offers explicit superlinear convergence but suffers from poor empirical performance and has a per-iteration cost of $O(d^3)$. To address these issues, we introduce the Sharpened Lazy Incremental Quasi-Newton Method (SLIQN) that achieves the best of both worlds: an explicit superlinear convergence rate, and superior empirical performance at a per-iteration $O(d^2)$ cost. SLIQN features two key changes: first, it incorporates a hybrid strategy of using both classic and greedy BFGS updates, allowing it to empirically outperform both IQN and IGS. Second, it employs a clever constant multiplicative factor along with a lazy propagation strategy, which enables it to have a cost of $O(d^2)$. Additionally, our experiments demonstrate the superiority of SLIQN over other incremental and stochastic Quasi-Newton variants and establish its competitiveness with second-order incremental methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.17283v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aakash Lahoti, Spandan Senapati, Ketan Rajawat, Alec Koppel</dc:creator>
    </item>
    <item>
      <title>Effects of Geopolitical Strain on Global Pharmaceutical Supply Chain Design and Drug Shortages</title>
      <link>https://arxiv.org/abs/2308.07434</link>
      <description>arXiv:2308.07434v2 Announce Type: replace 
Abstract: Emerging geopolitical risks have begun to threaten global supply chains, including those that produce life-saving drugs. Export bans may prevent a company from shipping products internationally, and it is unclear how these new dynamics may affect company plans and persistent, worldwide drug shortages. To address these questions, we present a global pharmaceutical supply chain design model that considers the risk of export bans that are induced by capacity disruptions and corresponding price increases. The model takes the company's perspective as a decision-maker looking to locate plants and distribute drugs globally. It is a two-stage stochastic program that includes uncertainty in capacity, ability-to-export, and demand. The model is solved by integrating the Sample Average Approximation and L-shaped methods. We present conditions related to when demand will be met and a case study of a generic oncology drug. We find that preparing for geopolitical strain may increase resilience and costs as well as reduce shortages in the short term. At baseline, expected global shortages are high (21%) with disparities across country income levels (3.1%, 3.7%, 95.2%, and 98.7% for high, upper-middle, lower-middle, and low income countries, respectively). Pricing policies may improve drug access overall, back-shoring may improve access for the country of interest, and bilateral alliances may not be effective at improving access.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.07434v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Martha L. Sabogal De La Pava (Industrial Engineering Department, Clemson University, Clemson, United States), Emily L. Tucker (Industrial Engineering Department, Clemson University, Clemson, United States, School of Health Research, Clemson University, Clemson, United States)</dc:creator>
    </item>
    <item>
      <title>Decentralized Riemannian Conjugate Gradient Method on the Stiefel Manifold</title>
      <link>https://arxiv.org/abs/2308.10547</link>
      <description>arXiv:2308.10547v3 Announce Type: replace 
Abstract: The conjugate gradient method is a crucial first-order optimization method that generally converges faster than the steepest descent method, and its computational cost is much lower than that of second-order methods. However, while various types of conjugate gradient methods have been studied in Euclidean spaces and on Riemannian manifolds, there is little study for those in distributed scenarios. This paper proposes a decentralized Riemannian conjugate gradient descent (DRCGD) method that aims at minimizing a global function over the Stiefel manifold. The optimization problem is distributed among a network of agents, where each agent is associated with a local function, and the communication between agents occurs over an undirected connected graph. Since the Stiefel manifold is a non-convex set, a global function is represented as a finite sum of possibly non-convex (but smooth) local functions. The proposed method is free from expensive Riemannian geometric operations such as retractions, exponential maps, and vector transports, thereby reducing the computational complexity required by each agent. To the best of our knowledge, DRCGD is the first decentralized Riemannian conjugate gradient algorithm to achieve global convergence over the Stiefel manifold.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.10547v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>International Conference on Learning Representations, 2024</arxiv:journal_reference>
      <dc:creator>Jun Chen, Haishan Ye, Mengmeng Wang, Tianxin Huang, Guang Dai, Ivor W. Tsang, Yong Liu</dc:creator>
    </item>
    <item>
      <title>Decentralized and Equitable Optimal Transport</title>
      <link>https://arxiv.org/abs/2403.04259</link>
      <description>arXiv:2403.04259v2 Announce Type: replace 
Abstract: This paper considers the decentralized (discrete) optimal transport (D-OT) problem. In this setting, a network of agents seeks to design a transportation plan jointly, where the cost function is the sum of privately held costs for each agent. We reformulate the D-OT problem as a constraint-coupled optimization problem and propose a single-loop decentralized algorithm with an iteration complexity of O(1/{\epsilon}) that matches existing centralized first-order approaches. Moreover, we propose the decentralized equitable optimal transport (DE-OT) problem. In DE-OT, in addition to cooperatively designing a transportation plan that minimizes transportation costs, agents seek to ensure equity in their individual costs. The iteration complexity of the proposed method to solve DE-OT is also O(1/{\epsilon}). This rate improves existing centralized algorithms, where the best iteration complexity obtained is O(1/{\epsilon}^2).</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04259v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ivan Lau, Shiqian Ma, C\'esar A. Uribe</dc:creator>
    </item>
    <item>
      <title>Fine-tuning of diffusion models via stochastic control: entropy regularization and beyond</title>
      <link>https://arxiv.org/abs/2403.06279</link>
      <description>arXiv:2403.06279v2 Announce Type: replace 
Abstract: This paper aims to develop and provide a rigorous treatment to the problem of entropy regularized fine-tuning in the context of continuous-time diffusion models, which was recently proposed by Uehara et al. (arXiv:2402.15194, 2024). The idea is to use stochastic control for sample generation, where the entropy regularizer is introduced to mitigate reward collapse. We also show how the analysis can be extended to fine-tuning involving a general $f$-divergence regularizer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06279v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenpin Tang</dc:creator>
    </item>
    <item>
      <title>Learning and Decision-Making with Data: Optimal Formulations and Phase Transitions</title>
      <link>https://arxiv.org/abs/2109.06911</link>
      <description>arXiv:2109.06911v3 Announce Type: replace-cross 
Abstract: We study the problem of designing optimal learning and decision-making formulations when only historical data is available. Prior work typically commits to a particular class of data-driven formulation and subsequently tries to establish out-of-sample performance guarantees. We take here the opposite approach. We define first a sensible yard stick with which to measure the quality of any data-driven formulation and subsequently seek to find an optimal such formulation. Informally, any data-driven formulation can be seen to balance a measure of proximity of the estimated cost to the actual cost while guaranteeing a level of out-of-sample performance. Given an acceptable level of out-of-sample performance, we construct explicitly a data-driven formulation that is uniformly closer to the true cost than any other formulation enjoying the same out-of-sample performance. We show the existence of three distinct out-of-sample performance regimes (a superexponential regime, an exponential regime and a subexponential regime) between which the nature of the optimal data-driven formulation experiences a phase transition. The optimal data-driven formulations can be interpreted as a classically robust formulation in the superexponential regime, an entropic distributionally robust formulation in the exponential regime and finally a variance penalized formulation in the subexponential regime. This final observation unveils a surprising connection between these three, at first glance seemingly unrelated, data-driven formulations which until now remained hidden.</description>
      <guid isPermaLink="false">oai:arXiv.org:2109.06911v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amine Bennouna, Bart P. G. Van Parys</dc:creator>
    </item>
    <item>
      <title>Majorization-minimization for Sparse Nonnegative Matrix Factorization with the $\beta$-divergence</title>
      <link>https://arxiv.org/abs/2207.06316</link>
      <description>arXiv:2207.06316v4 Announce Type: replace-cross 
Abstract: This article introduces new multiplicative updates for nonnegative matrix factorization with the $\beta$-divergence and sparse regularization of one of the two factors (say, the activation matrix). It is well known that the norm of the other factor (the dictionary matrix) needs to be controlled in order to avoid an ill-posed formulation. Standard practice consists in constraining the columns of the dictionary to have unit norm, which leads to a nontrivial optimization problem. Our approach leverages a reparametrization of the original problem into the optimization of an equivalent scale-invariant objective function. From there, we derive block-descent majorization-minimization algorithms that result in simple multiplicative updates for either $\ell_{1}$-regularization or the more "aggressive" log-regularization. In contrast with other state-of-the-art methods, our algorithms are universal in the sense that they can be applied to any $\beta$-divergence (i.e., any value of $\beta$) and that they come with convergence guarantees. We report numerical comparisons with existing heuristic and Lagrangian methods using various datasets: face images, an audio spectrogram, hyperspectral data, and song play counts. We show that our methods obtain solutions of similar quality at convergence (similar objective values) but with significantly reduced CPU times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.06316v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TSP.2023.3266939</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Signal Processing 2023</arxiv:journal_reference>
      <dc:creator>Arthur Marmin, Jos\'e Henrique de Morais Goulart, C\'edric F\'evotte</dc:creator>
    </item>
    <item>
      <title>Dissipative Feedback Switching for Quantum Stabilization</title>
      <link>https://arxiv.org/abs/2209.11709</link>
      <description>arXiv:2209.11709v2 Announce Type: replace-cross 
Abstract: Switching controlled dynamics allows for fast, flexible control design methods for quantum stabilization of pure states and subspaces, which naturally include both Hamiltonian and dissipative control actions. A novel approach to measurement-based, dissipative feedback design is introduced, and extends the applicability of switching techniques with respect to previously proposed ones, as it does not need stringent invariance assumptions, while it still avoids undesired chattering or Zeno effects by modulating the control intensity. When the switching dynamics do leave the target invariant, on the other hand, we show that exponential convergence to the target can be enforced without modulation, and switching times that can be either fixed or stochastic with hysteresis to avoid chattering. The effectiveness of the proposed methods is illustrated via numerical simulations of simple yet paradigmatic examples, demonstrating how switching strategies converge faster than open-loop engineered dissipation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.11709v2</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weichao Liang, Tommaso Grigoletto, Francesco Ticozzi</dc:creator>
    </item>
    <item>
      <title>Steiner Cut Dominants</title>
      <link>https://arxiv.org/abs/2209.14802</link>
      <description>arXiv:2209.14802v2 Announce Type: replace-cross 
Abstract: For a subset T of nodes of an undirected graph G, a T-Steiner cut is a cut \delta(S) where S intersects both T and the complement of T. The T-Steiner cut dominant} of G is the dominant CUT_+(G,T) of the convex hull of the incidence vectors of the T-Steiner cuts of G. For T={s,t}, this is the well-understood s-t-cut dominant. Choosing T as the set of all nodes of G, we obtain the \emph{cut dominant}, for which an outer description in the space of the original variables is still not known. We prove that, for each integer \tau, there is a finite set of inequalities such that for every pair (G,T) with |T|\ &lt;= \tau the non-trivial facet-defining inequalities of CUT_+(G,T) are the inequalities that can be obtained via iterated applications of two simple operations, starting from that set. In particular, the absolute values of the coefficients and of the right-hand-sides in a description of CUT_+(G,T) by integral inequalities can be bounded from above by a function of |T|. For all |T| &lt;= 5 we provide descriptions of CUT_+(G,T) by facet defining inequalities, extending the known descriptions of s-t-cut dominants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.14802v2</guid>
      <category>math.CO</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michele Conforti, Volker Kaibel</dc:creator>
    </item>
    <item>
      <title>QLABGrad: a Hyperparameter-Free and Convergence-Guaranteed Scheme for Deep Learning</title>
      <link>https://arxiv.org/abs/2302.00252</link>
      <description>arXiv:2302.00252v2 Announce Type: replace-cross 
Abstract: The learning rate is a critical hyperparameter for deep learning tasks since it determines the extent to which the model parameters are updated during the learning course. However, the choice of learning rates typically depends on empirical judgment, which may not result in satisfactory outcomes without intensive try-and-error experiments. In this study, we propose a novel learning rate adaptation scheme called QLABGrad. Without any user-specified hyperparameter, QLABGrad automatically determines the learning rate by optimizing the Quadratic Loss Approximation-Based (QLAB) function for a given gradient descent direction, where only one extra forward propagation is required. We theoretically prove the convergence of QLABGrad with a smooth Lipschitz condition on the loss function. Experiment results on multiple architectures, including MLP, CNN, and ResNet, on MNIST, CIFAR10, and ImageNet datasets, demonstrate that QLABGrad outperforms various competing schemes for deep learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.00252v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minghan Fu, Fang-Xiang Wu</dc:creator>
    </item>
    <item>
      <title>Approximation theorem for the Kawahara operator and its application in control theory</title>
      <link>https://arxiv.org/abs/2305.12089</link>
      <description>arXiv:2305.12089v2 Announce Type: replace-cross 
Abstract: Control properties of the Kawahara equation are considered when the equation is posed on an unbounded domain. Precisely, the paper's main results are related to an approximation theorem that ensures the exact (internal) controllability in $(0,+\infty)$. Following Rosier SIAM Simon (2000), the problem is reduced to prove an approximate theorem which is achieved thanks to a global Carleman estimate for the Kawahara operator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.12089v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Roberto de A. Capistrano Filho, Luan S. de Sousa, Fernando A. Gallego</dc:creator>
    </item>
    <item>
      <title>Revisiting the Last-Iterate Convergence of Stochastic Gradient Methods</title>
      <link>https://arxiv.org/abs/2312.08531</link>
      <description>arXiv:2312.08531v2 Announce Type: replace-cross 
Abstract: In the past several years, the last-iterate convergence of the Stochastic Gradient Descent (SGD) algorithm has triggered people's interest due to its good performance in practice but lack of theoretical understanding. For Lipschitz convex functions, different works have established the optimal $O(\log(1/\delta)\log T/\sqrt{T})$ or $O(\sqrt{\log(1/\delta)/T})$ high-probability convergence rates for the final iterate, where $T$ is the time horizon and $\delta$ is the failure probability. However, to prove these bounds, all the existing works are either limited to compact domains or require almost surely bounded noises. It is natural to ask whether the last iterate of SGD can still guarantee the optimal convergence rate but without these two restrictive assumptions. Besides this important question, there are still lots of theoretical problems lacking an answer. For example, compared with the last-iterate convergence of SGD for non-smooth problems, only few results for smooth optimization have yet been developed. Additionally, the existing results are all limited to a non-composite objective and the standard Euclidean norm. It still remains unclear whether the last-iterate convergence can be provably extended to wider composite optimization and non-Euclidean norms. In this work, to address the issues mentioned above, we revisit the last-iterate convergence of stochastic gradient methods and provide the first unified way to prove the convergence rates both in expectation and in high probability to accommodate general domains, composite objectives, non-Euclidean norms, Lipschitz conditions, smoothness, and (strong) convexity simultaneously. Additionally, we extend our analysis to obtain the last-iterate convergence under heavy-tailed noises.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.08531v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zijian Liu, Zhengyuan Zhou</dc:creator>
    </item>
  </channel>
</rss>
