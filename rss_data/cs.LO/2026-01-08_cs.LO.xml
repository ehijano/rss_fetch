<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 08 Jan 2026 05:00:24 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>130k Lines of Formal Topology in Two Weeks: Simple and Cheap Autoformalization for Everyone?</title>
      <link>https://arxiv.org/abs/2601.03298</link>
      <description>arXiv:2601.03298v1 Announce Type: new 
Abstract: This is a brief description of a project that has already autoformalized a large portion of the general topology from the Munkres textbook (which has in total 241 pages in 7 chapters and 39 sections). The project has been running since November 21, 2025 and has as of January 4, 2026, produced 160k lines of formalized topology. Most of it (about 130k lines) have been done in two weeks,from December 22 to January 4, for an LLM subscription cost of about \$100. This includes a 3k-line proof of Urysohn's lemma, a 2k-line proof of Urysohn's Metrization theorem, over 10k-line proof of the Tietze extension theorem, and many more (in total over 1.5k lemmas/theorems). The approach is quite simple and cheap: build a long-running feedback loop between an LLM and a reasonably fast proof checker equipped with a core foundational library. The LLM is now instantiated as ChatGPT (mostly 5.2) or Claude Sonnet (4.5) run through the respective Codex or Claude Code command line interfaces. The proof checker is Chad Brown's higher-order set theory system Megalodon, and the core library is Brown's formalization of basic set theory and surreal numbers (including reals, etc). The rest is some prompt engineering and technical choices which we describe here. Based on the fast progress, low cost, virtually unknown ITP/library, and the simple setup available to everyone, we believe that (auto)formalization may become quite easy and ubiquitous in 2026, regardless of which proof assistant is used.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03298v1</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <category>cs.SC</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Josef Urban</dc:creator>
    </item>
    <item>
      <title>Chronology as a Consistency Invariant in Composable Information Systems</title>
      <link>https://arxiv.org/abs/2601.03330</link>
      <description>arXiv:2601.03330v1 Announce Type: new 
Abstract: We formalize a minimal setting in which a chronology (a strict partial order on events) is forced by consistency of distributed information under local composability. The system maintains distributed records interpreted as constraints over a global possibility space (Omega, Sigma), optionally with a measure mu. Events act locally by monotonically tightening records, and independent events commute (diamond/trace semantics), yielding schedule invariance. We define operational influence without assuming primitive time: e influences f if executing e can change what constraint f writes on a shared site. Influence cycles alone need not imply inconsistency, so we distinguish weak influence (dependence) from strong influence (exclusive branching on an observable predicate). Assuming global satisfiability of all reachable record states, the diamond property, monotone information writing, and a mild branch-determinacy axiom for witnessed exclusivity, we prove that strong influence is acyclic and therefore induces an intrinsic chronology. We also show trace invariance and minimality of the derived order, introduce a monotone information clock based on -log mu(feasible set), and give an escape taxonomy: any model that admits strong-influence cycles without inconsistency must violate global consistency, local composability, monotone writing, or branch determinacy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03330v1</guid>
      <category>cs.LO</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anherutowa Calvo, Dante K. Calvo</dc:creator>
    </item>
    <item>
      <title>Extracting Policies from Quantified Answer Set Programs</title>
      <link>https://arxiv.org/abs/2601.03835</link>
      <description>arXiv:2601.03835v1 Announce Type: new 
Abstract: Quantified Answer Set Programming (QASP) extends Answer Set Programming (ASP) by allowing quantification over propositional variables, similar to Quantified Boolean Formulas (QBF). In this paper, we interpret models of QASP formulas in terms of policies, which represent decision-making strategies that determine how existentially quantified variables should be assigned, given the conditions set by universally quantified variables. As a main contribution, we present an algorithm for policy extraction under QASP semantics, inspired by the Equilibrium Logic semantics for general ASP theories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03835v1</guid>
      <category>cs.LO</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.439.16</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 439, 2026, pp. 224-237</arxiv:journal_reference>
      <dc:creator>Mart\'in Di\'eguez (University of Angers), Igor St\'ephan (University of Angers)</dc:creator>
    </item>
    <item>
      <title>Fixpoint Semantics for DatalogMTL with Negation</title>
      <link>https://arxiv.org/abs/2601.03841</link>
      <description>arXiv:2601.03841v1 Announce Type: new 
Abstract: DatalogMTL with negation is an extension of Datalog with metric temporal operators enriched with unstratifiable negation. In this paper, we define the stable, well-founded, Kripke-Kleene, and supported model semantics for DatalogMTL with negation in a very simple and straightforward way, by using the solid mathematical formalism of Approximation Fixpoint Theory (AFT). Moreover, we prove that the stable model semantics obtained via AFT coincides with  the one defined in previous work, through the employment of pairs of interpretations stemming from the logic of here-and-there. </description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03841v1</guid>
      <category>cs.LO</category>
      <category>cs.DB</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.439.19</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 439, 2026, pp. 263-277</arxiv:journal_reference>
      <dc:creator>Samuele Pollaci</dc:creator>
    </item>
    <item>
      <title>On the Trap Space Semantics of Normal Logic Programs</title>
      <link>https://arxiv.org/abs/2601.03842</link>
      <description>arXiv:2601.03842v1 Announce Type: new 
Abstract: The logical semantics of normal logic programs has traditionally been based on the notions of Clark's completion and two-valued or three-valued canonical models, including supported, stable, regular, and well-founded models. Two-valued interpretations can also be seen as states evolving under a program's update operator, producing a transition graph whose fixed points and cycles capture stable and oscillatory behaviors, respectively. We refer to this view as dynamical semantics since it characterizes the program's meaning in terms of state-space trajectories, as first introduced in the stable (supported) class semantics. Recently, we have established a formal connection between Datalog^\neg programs (i.e., normal logic programs without function symbols) and Boolean networks, leading to the introduction of the trap space concept for Datalog^\neg programs. In this paper, we generalize the trap space concept to arbitrary normal logic programs, introducing trap space semantics as a new approach to their interpretation. This new semantics admits both model-theoretic and dynamical characterizations, providing a comprehensive approach to understanding program behavior. We establish the foundational properties of the trap space semantics and systematically relate it to the established model-theoretic semantics, including the stable (supported), stable (supported) partial, regular, and L-stable model semantics, as well as to the dynamical stable (supported) class semantics. Our results demonstrate that the trap space semantics offers a unified and precise framework for proving the existence of supported classes, strict stable (supported) classes, and regular models, in addition to uncovering and formalizing deeper relationships among the existing semantics of normal logic programs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03842v1</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.439.21</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 439, 2026, pp. 294-319</arxiv:journal_reference>
      <dc:creator>Van-Giang Trinh (Inria Saclay, EP Lifeware, Palaiseau, France), Sylvain Soliman (Inria Saclay, EP Lifeware, Palaiseau, France), Fran\c{c}ois Fages (Inria Saclay, EP Lifeware, Palaiseau, France), Belaid Benhamou (LIRICA team, LIS, Aix-Marseille University, Marseille, France)</dc:creator>
    </item>
    <item>
      <title>Implementing the First-Order Logic of Here and There</title>
      <link>https://arxiv.org/abs/2601.03848</link>
      <description>arXiv:2601.03848v1 Announce Type: new 
Abstract: We present automated theorem provers for the first-order logic of here and there (HT). They are based on a native sequent calculus for the logic of HT and an axiomatic embedding of the logic of HT into intuitionistic logic. The analytic proof search in the sequent calculus is optimized by using free variables and skolemization. The embedding is used in combination with sequent, tableau and connection calculi for intuitionistic first-order logic. All provers are evaluated on a large benchmark set of first-order formulas, providing a foundation for the development of more efficient HT provers.
</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03848v1</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <category>cs.PL</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.439.31</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 439, 2026, pp. 453-468</arxiv:journal_reference>
      <dc:creator>Jens Otten (University of Pernambuco), Torsten Schaub (University of Potsdam)</dc:creator>
    </item>
    <item>
      <title>Automated Theorem Proving for Prolog Verification</title>
      <link>https://arxiv.org/abs/2601.03849</link>
      <description>arXiv:2601.03849v1 Announce Type: new 
Abstract: LPTP (Logic Program Theorem Prover) is an interactive natural-deduction-based theorem  prover for pure Prolog programs with negation as failure, unification with the occurs check, and a restricted but extensible set of built-in predicates. With LPTP, one can formally prove termination  and partial correctness of such Prolog programs. LPTP was designed in the mid-1990's by Robert F. Staerk.  It is written in ISO-Prolog and comes with an Emacs user-interface. 
  From a theoretical point of view, in his publications about LPTP, Staerk associates a set of first-order axioms IND(P) to the considered Prolog program P.  IND(P) contains the Clark's equality theory for P,  definitions of success, failure and termination for each user-defined logic procedure in P,  axioms relating these three points of view, and an axiom schema for  proving inductive properties. LPTP is thus a dedicated proof editor where these axioms are hard-wired. 
  We propose to translate these axioms as first-order formulas (FOFs), and apply automated theorem provers to  check the property of interest. Using  FOF  as an intermediary language, we experiment the use of automated theorem  provers for Prolog program verification. We evaluate the approach over  a benchmark of about 400 properties of Prolog  programs from the library available with LPTP. Both the  compiler which generates a set of FOF files from a given input  Prolog program together with its properties and the benchmark are publicly available.
</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03849v1</guid>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.439.32</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 439, 2026, pp. 469-481</arxiv:journal_reference>
      <dc:creator>Fred Mesnard (LIM, universit\'e de La R\'eunion), Thierry Marianne (LIM, universit\'e de La R\'eunion), \'Etienne Payet (LIM, universit\'e de La R\'eunion)</dc:creator>
    </item>
    <item>
      <title>On Zeno-like Behaviors in the Event Calculus with Goal-directed Answer Set Programming</title>
      <link>https://arxiv.org/abs/2601.03852</link>
      <description>arXiv:2601.03852v1 Announce Type: new 
Abstract: It has been argued that Event Calculus (EC) is suitable for modeling high-level specifications of safety-critical cyber-physical systems. The primary advantage lies in the rather small semantic gap between EC models and requirements expressed in a semi-formal natural language. Moreover, its use of continuous time and variables avoids imprecision that stems from discretization. In the past, we have shown that a goal-directed ASP system can be used for implementing these EC models. However, precise representation of time as an infinitesimally divisible continuous quantity leads to Zeno-like behaviors and to non-termination in such a system. In this work, we model a number of well-known example problems from the literature to systematically study various natural EC modeling patterns that yield these Zeno-like behaviors, and propose ways to deal with them. Moreover, we also propose a technique to automatically detect all such cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03852v1</guid>
      <category>cs.LO</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.439.34</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 439, 2026, pp. 496-510</arxiv:journal_reference>
      <dc:creator>Ond\v{r}ej Va\v{s}\'i\v{c}ek (Brno University of Technology), Joaquin Arias (CETINIA, Universidad Rey Juan Carlos), Jan Fiedor (Brno University of Technology,Honeywell International s.r.o), Gopal Gupta (The University of Texas at Dallas), Brendan Hall (Ardent Innovation Labs), Bohuslav K\v{r}ena (Brno University of Technology), Brian Larson (Multitude Corporation), Tom\'a\v{s} Vojnar (Masaryk University,Brno University of Technology)</dc:creator>
    </item>
    <item>
      <title>Introducing The Maximum Common Bigraph Problem</title>
      <link>https://arxiv.org/abs/2601.03898</link>
      <description>arXiv:2601.03898v1 Announce Type: new 
Abstract: Bigraph reactive systems offer a powerful and flexible mathematical framework for modelling both spatial and non-spatial relationships between agents, with practical applications in domains such as smart technologies, networks, sensor systems, and biology. While bigraphs theoretically support the identification of bisimilar agents, by simulating and comparing their corresponding minimal contextual transition systems, no known algorithm exists for computing the maximum shared structure between two bigraphs, an essential prerequisite for determining the set of possible transitions for a given agent state. In this work, we provide a definition of the maximum common bigraph problem, and present an adaptation of the McSplit maximum common induced subgraph algorithm to compute the maximum common bigraph between two bigraph states. Our approach opens a path toward supporting bisimulation checking in bigraph-based tools, which have been leveraged in other modelling paradigms for simplification, optimisation, and verification of models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03898v1</guid>
      <category>cs.LO</category>
      <category>cs.MA</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.440.3</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 440, 2026, pp. 13-35</arxiv:journal_reference>
      <dc:creator>Kyle Burns, Michele Sevegnani, Ciaran McCreesh, James Trimble</dc:creator>
    </item>
    <item>
      <title>Recursive Program Synthesis from Sketches and Mixed-Quantifier Properties</title>
      <link>https://arxiv.org/abs/2601.04045</link>
      <description>arXiv:2601.04045v1 Announce Type: new 
Abstract: We present a novel approach to the automatic synthesis of recursive programs from mixed-quantifier first-order logic properties. Our approach uses Skolemization to reduce the mixed-quantifier synthesis problem to a $\forall^*$-synthesis problem, synthesizing witness-generating functions for introduced Skolem symbols alongside the target program. We tackle $\forall^*$-synthesis using a sketching-based, enumerative, counterexample-guided approach. Our algorithm learns syntactic constraints from counterexamples to prune the candidate space and employs a prophylactic pruning technique to avoid enumerating invalid candidates altogether. We evaluate our technique on 42 benchmarks, demonstrating that both counterexample generalization and prophylactic pruning significantly improve performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.04045v1</guid>
      <category>cs.LO</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Derek Egolf, Stavros Tripakis</dc:creator>
    </item>
    <item>
      <title>Craig Interpolation for HT with a Variation of Mints' Sequent System</title>
      <link>https://arxiv.org/abs/2601.04080</link>
      <description>arXiv:2601.04080v1 Announce Type: new 
Abstract: We present a Maehara-style construction of Craig interpolants for the three-valued propositional logic of here and there (HT), also known as G\"odel's $G_3$. The method adapts a recent interpolation technique that operates on classically encoded logic programs to a variation of a sequent calculus for HT by Mints. The approach is characterized by two stages: First, a preliminary interpolant is constructed, a formula that is an interpolant in some sense, but not yet the desired HT formula. In the second stage, an actual HT interpolant is obtained from this preliminary interpolant. With the classical encoding, the preliminary interpolant is a classical Craig interpolant for classical encodings of the two input HT formulas. In the presented adaptation, the sequent system operates directly on HT formulas, and the preliminary interpolant is in a nonclassical logic that generalizes HT by an additional logic operator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.04080v1</guid>
      <category>cs.LO</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christoph Wernhard</dc:creator>
    </item>
    <item>
      <title>Algorithm and Strategy Construction for Sure-Almost-Sure Stochastic Parity Games</title>
      <link>https://arxiv.org/abs/2601.03381</link>
      <description>arXiv:2601.03381v1 Announce Type: cross 
Abstract: We consider turn-based stochastic two-player games with a combination of a parity condition that must hold surely, that is in all possible outcomes, and of a parity condition that must hold almost-surely, that is with probability 1. The problem of deciding the existence of a winning strategy in such games is central in the framework of synthesis beyond worst-case where a hard requirement that must hold surely is combined with a softer requirement. Recent works showed that the problem is coNP-complete, and infinite-memory strategies are necessary in general, even in one-player games (i.e., Markov decision processes). However, memoryless strategies are sufficient for the opponent player. Despite these comprehensive results, the known algorithmic solution enumerates all memoryless strategies of the opponent, which is exponential in all cases, and does not construct a winning strategy when one exists.
  We present a recursive algorithm, based on a characterisation of the winning region, that gives a deeper insight into the problem. In particular, we show how to construct a winning strategy to achieve the combination of sure and almost-sure parity, and we derive new complexity and memory bounds for special classes of the problem, defined by fixing the index of either of the two parity conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03381v1</guid>
      <category>cs.GT</category>
      <category>cs.LO</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Laurent Doyen, Shibashis Guha</dc:creator>
    </item>
    <item>
      <title>Duality for Constructive Modal Logics: from Sahqlvist to Goldblatt-Thomason</title>
      <link>https://arxiv.org/abs/2601.03762</link>
      <description>arXiv:2601.03762v1 Announce Type: cross 
Abstract: We carry out a semantic study of the constructive modal logic CK. We provide a categorical duality linking the algebraic and birelational semantics of the logic. We then use this to prove Sahlqvist style correspondence and completeness results, as well as a Goldblatt-Thomason style theorem on definability of classes of frames.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03762v1</guid>
      <category>math.LO</category>
      <category>cs.LO</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Jim de Groot, Ian Shillito, Ranald Clouston</dc:creator>
    </item>
    <item>
      <title>Logic Programming with Extensible Types</title>
      <link>https://arxiv.org/abs/2601.03836</link>
      <description>arXiv:2601.03836v1 Announce Type: cross 
Abstract: Logic programming languages present clear advantages in terms of declarativeness and conciseness. However, the ideas of logic programming have been met with resistance in other programming communities, and have not generally been adopted by other paradigms and languages. This paper proposes a novel way to incorporate logic programming in an existing codebase in a typed functional programming language. Our approach integrates with the host language without sacrificing static typing, and leverages strengths of typed functional programming such as polymorphism and higher-order. We do so by combining three ideas. First, we use the extensible types technique to allow values of the host language to contain logic variables. Second, we implement a unification algorithm that works for any data structure that supports certain operations.Third, we introduce a domain-specific language to define and query predicates. We demonstrate our proposal via a series of examples, and provide aids to make the notation convenient for users, showing that the proposed approach is not just technically possible but also practical. Our ideas have been implemented in the language Haskell with very good results.
</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03836v1</guid>
      <category>cs.PL</category>
      <category>cs.LO</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.439.18</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 439, 2026, pp. 248-262</arxiv:journal_reference>
      <dc:creator>Ivan Perez (KBR @ NASA Ames Research Center), Angel Herranz (Universidad Politecnica de Madrid)</dc:creator>
    </item>
    <item>
      <title>Logic Tensor Network-Enhanced Generative Adversarial Network</title>
      <link>https://arxiv.org/abs/2601.03839</link>
      <description>arXiv:2601.03839v1 Announce Type: cross 
Abstract: In this paper, we introduce Logic Tensor Network-Enhanced Generative Adversarial Network (LTN-GAN), a novel framework that enhances Generative Adversarial Networks (GANs) by incorporating Logic Tensor Networks (LTNs) to enforce domain-specific logical constraints during the sample generation process. Although GANs have shown remarkable success in generating realistic data, they often lack mechanisms to incorporate prior knowledge or enforce logical consistency, limiting their applicability in domains requiring rule adherence. LTNs provide a principled way to integrate first-order logic with neural networks, enabling models to reason over and satisfy logical constraints. By combining the strengths of GANs for realistic data synthesis with LTNs for logical reasoning, we gain valuable insights into how logical constraints influence the generative process while improving both the diversity and logical consistency of the generated samples. We evaluate LTN-GAN across multiple datasets, including synthetic datasets (gaussian, grid, rings) and the MNIST dataset, demonstrating that our model significantly outperforms traditional GANs in terms of adherence to predefined logical constraints while maintaining the quality and diversity of generated samples. This work highlights the potential of neuro-symbolic approaches to enhance generative modeling in knowledge-intensive domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03839v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.439.8</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 439, 2026, pp. 89-113</arxiv:journal_reference>
      <dc:creator>Nijesh Upreti (The University of Edinburgh), Vaishak Belle (The University of Edinburgh)</dc:creator>
    </item>
    <item>
      <title>Defeasible Conditionals using Answer Set Programming</title>
      <link>https://arxiv.org/abs/2601.03840</link>
      <description>arXiv:2601.03840v1 Announce Type: cross 
Abstract: Defeasible entailment is concerned with drawing plausible conclusions from incomplete information. A foundational framework for modelling defeasible entailment is the KLM framework. Introduced by Kraus, Lehmann, and Magidor, the KLM framework outlines several key properties for defeasible entailment. One of the most prominent algorithms within this framework is Rational Closure (RC). This paper presents a declarative definition for computing RC using Answer Set Programming (ASP). Our approach enables the automatic construction of the minimal ranked model from a given knowledge base and supports entailment checking for specified queries. We formally prove the correctness of our ASP encoding and conduct empirical evaluations to compare the performance of our implementation with that of existing imperative implementations, specifically the InfOCF solver. The results demonstrate that our ASP-based approach adheres to RC's theoretical foundations and offers improved computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03840v1</guid>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.439.15</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 439, 2026, pp. 206-223</arxiv:journal_reference>
      <dc:creator>Racquel Dennison, Jesse Heyninck, Thomas Meyer</dc:creator>
    </item>
    <item>
      <title>Formally Explaining Decision Tree Models with Answer Set Programming</title>
      <link>https://arxiv.org/abs/2601.03845</link>
      <description>arXiv:2601.03845v1 Announce Type: cross 
Abstract: Decision tree models, including random forests and gradient-boosted decision trees, are widely used in machine learning due to their high predictive performance.  However, their complex structures often make them difficult to interpret, especially in safety-critical applications where model decisions require formal justification.  Recent work has demonstrated that logical and abductive explanations can be derived through automated reasoning techniques.  In this paper, we propose a method for generating various types of explanations, namely, sufficient, contrastive, majority, and tree-specific explanations, using Answer Set Programming (ASP).  Compared to SAT-based approaches, our ASP-based method offers greater flexibility in encoding user preferences and supports enumeration of all possible explanations.  We empirically evaluate the approach on a diverse set of datasets and demonstrate its effectiveness and limitations compared to existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03845v1</guid>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.439.29</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 439, 2026, pp. 420-437</arxiv:journal_reference>
      <dc:creator>Akihiro Takemura (National Institute of Informatics, Tokyo, Japan), Masayuki Otani (Tokyo Institute of Technology, Tokyo, Japan), Katsumi Inoue (National Institute of Informatics, Tokyo, Japan)</dc:creator>
    </item>
    <item>
      <title>Inductive First-Order Formula Synthesis by ASP: A Case Study in Invariant Inference</title>
      <link>https://arxiv.org/abs/2601.03854</link>
      <description>arXiv:2601.03854v1 Announce Type: cross 
Abstract: We present a framework for synthesising formulas in first-order logic (FOL) from examples, which unifies and advances state-of-the-art approaches for inference of transition system invariants. To do so, we study and categorise the existing methodologies, encoding techniques in their formula synthesis via answer set programming (ASP). Based on the derived categorisation, we propose orthogonal slices, a new technique for formula enumeration that partitions the search space into manageable chunks, enabling two approaches for incremental candidate pruning. Using a combination of existing techniques for first-order (FO) invariant synthesis and the orthogonal slices implemented in our framework FORCE, we significantly accelerate a state-of-the-art algorithm for distributed system invariant inference. We also show that our approach facilitates composition of different invariant inference frameworks, allowing for novel optimisations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03854v1</guid>
      <category>cs.PL</category>
      <category>cs.LO</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.439.35</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 439, 2026, pp. 511-527</arxiv:journal_reference>
      <dc:creator>Ziyi Yang, George P\^irlea, Ilya Sergey</dc:creator>
    </item>
    <item>
      <title>The most natural paradefinite logic relative to classical logic</title>
      <link>https://arxiv.org/abs/2601.04081</link>
      <description>arXiv:2601.04081v1 Announce Type: cross 
Abstract: A paradefinite logic is a logic that can serve as the underlying logic for theories that are inconsistent or incomplete. A well-known paradefinite logic is Belnap-Dunn logic. Various expansions of Belnap-Dunn logic have been studied in the literature. In this note, it is argued that the most natural paradefinite logic relative to classical logic is the expansion of Belnap-Dunn logic with a falsity connective and an implication connective for which the standard deduction theorem holds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.04081v1</guid>
      <category>math.LO</category>
      <category>cs.LO</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>C. A. Middelburg</dc:creator>
    </item>
    <item>
      <title>A Strongly Normalising System of Dependent Types for Transparent and Opaque Probabilistic Computation</title>
      <link>https://arxiv.org/abs/2406.17082</link>
      <description>arXiv:2406.17082v5 Announce Type: replace 
Abstract: We define an extension of lambda-calculus with dependents types that enables us to encode transparent and opaque probabilistic programs and prove a strong normalisation result for it by a reducibility technique. While transparent nondeterministic programs are formalised by rather usual techniques, opaque nondeterministic programs are formalised by introducing in the syntax oracle constants, the behaviour of which is governed by oracular functions. The generality of these functions and the fact that their values are determined by the form of the whole term inside which the relative oracle occurs also enable us to simulate learning-like behaviours. We then extend the calculus in order to define a computational trustworthiness predicate. The extension of the calculus does not only enable us to precisely formalise a notion of trustworthiness and to encode the procedures required to test it on programs, but also to reason, by means of the type system, on the behaviour of programs with respect to trustworthiness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17082v5</guid>
      <category>cs.LO</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francesco A. Genco</dc:creator>
    </item>
    <item>
      <title>VECSR: Virtually Embodied Common Sense Reasoning System</title>
      <link>https://arxiv.org/abs/2505.02144</link>
      <description>arXiv:2505.02144v2 Announce Type: replace 
Abstract: The development of autonomous agents has seen a revival of enthusiasm due to the emergence of LLMs, such as GPT-4o. Deploying these agents in environments where they coexist with humans (e.g., as domestic assistants) requires special attention to trustworthiness and explainability. However, the use of LLMs and other deep learning models still does not resolve these key issues. Deep learning systems may hallucinate, be unable to justify their decisions as black boxes, or perform badly on unseen scenarios. In this work, we propose the use of s(CASP), a goal-directed common sense reasoner based on Answer Set Programming, to break down the high-level tasks of an autonomous agent into mid-level instructions while justifying the selection of these instructions. To validate its use in real applications we present a framework that integrates the reasoner into the VirtualHome simulator and compares its accuracy with GPT-4o, running some of the "real" use cases available in the domestic environments of VirtualHome. Additionally, since experiments with VirtualHome have shown the need to reduce the response time (which increases as the agent's decision space grows), we have proposed and evaluated a series of optimizations based on program analysis that exploit the advantages of the top-down execution of s(CASP).</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02144v2</guid>
      <category>cs.LO</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.439.7</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 439, 2026, pp. 76-88</arxiv:journal_reference>
      <dc:creator>Alexis R. Tudor (University of Texas at Dallas, USA), Joaqu\'in Arias (CETINIA, Universidad Rey Juan Carlos, Spain), Gopal Gupta (University of Texas at Dallas, USA)</dc:creator>
    </item>
    <item>
      <title>A Simple and Effective ASP-Based Tool for Enumerating Minimal Hitting Sets</title>
      <link>https://arxiv.org/abs/2507.09194</link>
      <description>arXiv:2507.09194v3 Announce Type: replace 
Abstract: The hitting set problem is a fundamental problem in computer science and mathematics. Given a family of sets over a universe of elements, a minimal hitting set is a subset-minimal collection of elements that intersects each set in the family. Enumerating all minimal hitting sets is crucial in various real-world applications.
  In this paper, we address the full enumeration of all minimal hitting sets for a given family of sets. We formulate the problem using Answer Set Programming (ASP) and leverage existing ASP solvers for efficient enumeration. We propose an ASP-based tool, MinHit-ASP, and our empirical evaluation shows that it effectively enumerates minimal hitting sets across benchmarks from diverse problem domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09194v3</guid>
      <category>cs.LO</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.439.17</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 439, 2026, pp. 238-247</arxiv:journal_reference>
      <dc:creator>Mohimenul Kabir (National University of Singapore), Kuldeep S Meel (Georgia Institute of Technology)</dc:creator>
    </item>
    <item>
      <title>A framework for Conditional Reasoning in Answer Set Programming</title>
      <link>https://arxiv.org/abs/2506.03997</link>
      <description>arXiv:2506.03997v3 Announce Type: replace-cross 
Abstract: In this paper we introduce a Conditional Answer Set Programming framework (Conditional ASP) for the definition of conditional extensions of Answer Set Programming (ASP). The approach builds on a conditional logic with typicality, and on the combination of a conditional knowledge base with an ASP program, and allows for conditional reasoning over the answer sets of the program. The formalism relies on a multi-preferential semantics, and on the KLM preferential semantics, as a special case. Conditional entailment is encoded in ASP and a complexity upper-bound is provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03997v3</guid>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.439.13</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 439, 2026, pp. 188-201</arxiv:journal_reference>
      <dc:creator>Mario Alviano (Universit\'a della Calabria), Laura Giordano (Universit\'a del Piemonte Orientale), Daniele Theseider Dupr\'e (Universit\'a del Piemonte Orientale)</dc:creator>
    </item>
    <item>
      <title>Machine Learning Model Integration with Open World Temporal Logic for Process Automation</title>
      <link>https://arxiv.org/abs/2506.17776</link>
      <description>arXiv:2506.17776v3 Announce Type: replace-cross 
Abstract: Recent advances in Machine Learning (ML) have produced models that extract structured information from complex data. However, a significant challenge lies in translating these perceptual or extractive outputs into actionable and explainable decisions within complex operational workflows. To address these challenges, this paper introduces a novel approach that integrates the outputs of various machine learning models directly with the PyReason framework, an open-world temporal logic programming reasoning engine. PyReason's foundation in generalized annotated logic allows for the incorporation of real-valued outputs (e.g., probabilities, confidence scores) from a diverse set of ML models, treating them as truth intervals within its logical framework. Crucially, PyReason provides mechanisms, implemented in Python, to continuously poll ML model outputs, convert them into logical facts, and dynamically recompute the minimal model to enable decision-making in real-time. Furthermore, its native support for temporal reasoning, knowledge graph integration, and fully explainable interface traces enables an analysis of time-sensitive process data and existing organizational knowledge. By combining the strengths of perception and extraction from ML models with the logical deduction and transparency of PyReason, we aim to create a powerful system for automating complex processes. This integration is well suited for use cases in numerous domains, including manufacturing, healthcare, and business operations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.17776v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.439.4</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 439, 2026, pp. 34-46</arxiv:journal_reference>
      <dc:creator>Dyuman Aditya (Syracuse University, Syracuse, NY USA), Colton Payne (Arizona State University, Tempe, AZ USA), Mario Leiva (Universidad Nacional del Sur, BA, Argentina), Paulo Shakarian (Syracuse University, Syracuse, NY USA)</dc:creator>
    </item>
    <item>
      <title>An ASP-Based Framework for MUSes</title>
      <link>https://arxiv.org/abs/2507.03929</link>
      <description>arXiv:2507.03929v2 Announce Type: replace-cross 
Abstract: Given an unsatisfiable formula, understanding the core reason for unsatisfiability is crucial in several applications. One effective way to capture this is through the minimal unsatisfiable subset (MUS), the subset-minimal set of clauses that remains unsatisfiable. Current research broadly focuses on two directions: (i) enumerating as many MUSes as possible within a given time limit, and (ii) counting the total number of MUSes for a given unsatisfiable formula.
  In this paper, we introduce an answer set programming-based framework, named MUS-ASP, designed for online enumeration of MUSes. ASP is a powerful tool for its strengths in knowledge representation and is particularly suitable for specifying complex combinatorial problems. By translating MUS enumeration into answer set solving, MUS-ASP leverages the computational efficiency of state-of-the-art ASP systems. Our extensive experimental evaluation demonstrates the effectiveness of MUS-ASP and highlights the acceleration in both MUS enumeration and counting tasks, particularly when integrated within hybrid solvers, including the framework proposed in this paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03929v2</guid>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.439.3</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 439, 2026, pp. 18-33</arxiv:journal_reference>
      <dc:creator>Mohimenul Kabir (National University of Singapore), Kuldeep S Meel (Georgia Institute of Technology)</dc:creator>
    </item>
    <item>
      <title>Navigating Taxonomic Expansions of Entity Sets Driven by Knowledge Bases</title>
      <link>https://arxiv.org/abs/2512.16953</link>
      <description>arXiv:2512.16953v2 Announce Type: replace-cross 
Abstract: Recognizing similarities among entities is central to both human cognition and computational intelligence. Within this broader landscape, Entity Set Expansion is one prominent task aimed at taking an initial set of (tuples of) entities and identifying additional ones that share relevant semantic properties with the former -- potentially repeating the process to form increasingly broader sets. However, this ``linear'' approach does not unveil the richer ``taxonomic'' structures present in knowledge resources. A recent logic-based framework introduces the notion of an expansion graph: a rooted directed acyclic graph where each node represents a semantic generalization labeled by a logical formula, and edges encode strict semantic inclusion. This structure supports taxonomic expansions of entity sets driven by knowledge bases. Yet, the potentially large size of such graphs may make full materialization impractical in real-world scenarios. To overcome this, we formalize reasoning tasks that check whether two tuples belong to comparable, incomparable, or the same nodes in the graph. Our results show that, under realistic assumptions -- such as bounding the input or limiting entity descriptions -- these tasks can be implemented efficiently. This enables local, incremental navigation of expansion graphs, supporting practical applications without requiring full graph construction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.16953v2</guid>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giovanni Amendola, Pietro Cofone, Marco Manna, Aldo Ricioppo</dc:creator>
    </item>
  </channel>
</rss>
