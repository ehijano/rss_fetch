<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 15 May 2025 01:21:23 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>MACH: Multi-Agent Coordination for RSU-centric Handovers</title>
      <link>https://arxiv.org/abs/2505.07827</link>
      <description>arXiv:2505.07827v1 Announce Type: new 
Abstract: This paper introduces MACH, a novel approach for optimizing task handover in vehicular computing scenarios. To ensure fast and latency-aware placement of tasks, the decision-making -- where and when should tasks be offloaded -- is carried out decentralized at the Road Side Units (RSUs) who also execute the tasks. By shifting control to the network edge, MACH moves away from the traditional centralized or vehicle-based handover method. Still, it focuses on contextual factors, such as the current RSU load and vehicle trajectories. Thus, MACH improves the overall Quality of Service (QoS) while fairly balancing computational loads between RSUs. To evaluate the effectiveness of our approach, we develop a robust simulation environment composed of real-world traffic data, dynamic network conditions, and different infrastructure capacities. For scenarios that demand low latency and high reliability, our experimental results demonstrate how MACH significantly improves the adaptability and efficiency of vehicular computations. By decentralizing control to the network edge, MACH effectively reduces communication overhead and optimizes resource utilization, offering a robust framework for task handover management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07827v1</guid>
      <category>cs.NI</category>
      <category>cs.MA</category>
      <pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nikolaus Spring, Andrea Morichetta, Boris Sedlak, Schahram Dustdar</dc:creator>
    </item>
    <item>
      <title>ai.txt: A Domain-Specific Language for Guiding AI Interactions with the Internet</title>
      <link>https://arxiv.org/abs/2505.07834</link>
      <description>arXiv:2505.07834v1 Announce Type: new 
Abstract: We introduce ai.txt, a novel domain-specific language (DSL) designed to explicitly regulate interactions between AI models, agents, and web content, addressing critical limitations of the widely adopted robots.txt standard. As AI increasingly engages with online materials for tasks such as training, summarization, and content modification, existing regulatory methods lack the necessary granularity and semantic expressiveness to ensure ethical and legal compliance. ai.txt extends traditional URL-based access controls by enabling precise element-level regulations and incorporating natural language instructions interpretable by AI systems. To facilitate practical deployment, we provide an integrated development environment with code autocompletion and automatic XML generation. Furthermore, we propose two compliance mechanisms: XML-based programmatic enforcement and natural language prompt integration, and demonstrate their effectiveness through preliminary experiments and case studies. Our approach aims to aid the governance of AI-Internet interactions, promoting responsible AI use in digital ecosystems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07834v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <category>cs.PL</category>
      <pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuekang Li, Wei Song, Bangshuo Zhu, Dong Gong, Yi Liu, Gelei Deng, Chunyang Chen, Lei Ma, Jun Sun, Toby Walsh, Jingling Xue</dc:creator>
    </item>
    <item>
      <title>Intelligent Product 3.0: Decentralised AI Agents and Web3 Intelligence Standards</title>
      <link>https://arxiv.org/abs/2505.07835</link>
      <description>arXiv:2505.07835v2 Announce Type: new 
Abstract: Twenty-five years ago, the specification of the Intelligent Product was established, envisaging real-time connectivity that not only enables products to gather accurate data about themselves but also allows them to assess and influence their own destiny. Early work by the Auto-ID project focused on creating a single, open-standard repository for storing and retrieving product information, laying a foundation for scalable connectivity. A decade later, the approach was revisited in light of low-cost RFID systems that promised a low-cost link between physical goods and networked information environments. Since then, advances in blockchain, Web3, and artificial intelligence have introduced unprecedented levels of resilience, consensus, and autonomy. By leveraging decentralised identity, blockchain-based product information and history, and intelligent AI-to-AI collaboration, this paper examines these developments and outlines a new specification for the Intelligent Product 3.0, illustrating how decentralised and AI-driven capabilities facilitate seamless interaction between physical AI and everyday products.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07835v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alex C. Y. Wong, Duncan McFarlane, C. Ellarby, M. Lee, M. Kuok</dc:creator>
    </item>
    <item>
      <title>ML-Enabled Eavesdropper Detection in Beyond 5G IIoT Networks</title>
      <link>https://arxiv.org/abs/2505.07837</link>
      <description>arXiv:2505.07837v1 Announce Type: new 
Abstract: Advanced fifth generation (5G) and beyond (B5G) communication networks have revolutionized wireless technologies, supporting ultra-high data rates, low latency, and massive connectivity. However, they also introduce vulnerabilities, particularly in decentralized Industrial Internet of Things (IIoT) environments. Traditional cryptographic methods struggle with scalability and complexity, leading researchers to explore Artificial Intelligence (AI)-driven physical layer techniques for secure communications. In this context, this paper focuses on the utilization of Machine and Deep Learning (ML/DL) techniques to tackle with the common problem of eavesdropping detection. To this end, a simulated industrial B5G heterogeneous wireless network is used to evaluate the performance of various ML/DL models, including Random Forests (RF), Deep Convolutional Neural Networks (DCNN), and Long Short-Term Memory (LSTM) networks. These models classify users as either legitimate or malicious ones based on channel state information (CSI), position data, and transmission power. According to the presented numerical results, DCNN and RF models achieve a detection accuracy approaching 100\% in identifying eavesdroppers with zero false alarms. In general, this work underlines the great potential of combining AI and Physical Layer Security (PLS) for next-generation wireless networks in order to address evolving security threats.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07837v1</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maria-Lamprini A. Bartsioka, Ioannis A. Bartsiokas, Panagiotis K. Gkonis, Dimitra I. Kaklamani, Iakovos S. Venieris</dc:creator>
    </item>
    <item>
      <title>Token Communication-Driven Multimodal Large Models in Resource-Constrained Multiuser Networks</title>
      <link>https://arxiv.org/abs/2505.07841</link>
      <description>arXiv:2505.07841v1 Announce Type: new 
Abstract: The proliferation of intelligent applications at the wireless edge, alongside the exponential growth of multimodal data, poses challenges for deploying multimodal large models (MLMs) in resource-constrained networks. These constraints manifest as limited bandwidth, computational capacity, and stringent latency requirements, particularly under low signal-to-noise ratio (SNR) conditions. To overcome these limitations, we propose a token communication paradigm that facilitates the decentralized deployment of MLMs across user devices and edge infrastructure (e.g., base stations). In this paradigm, task-relevant tokens are extracted from multimodal inputs and serve as the primary medium for communication between distributed model components. To align semantics and optimize transmission efficiency, we propose a dual-pronged approach: 1) We design a contrastive split fine-tuning method to project heterogeneous modalities into a shared feature space, enabling seamless interaction between model components while preserving modal-specific semantics. 2) We employ a lightweight compression technique to reduce the size of transmitted tokens, minimizing bandwidth consumption without sacrificing task-critical information. The proposed framework integrates collaborative fine-tuning of both the foundation model and multimodal transceivers, ensuring that token generation and utilization are tailored to specific downstream tasks. Simulation experiments conducted under different SNR conditions demonstrate that our method results in a $13.7\%$ improvement in test accuracy. Furthermore, our approach exhibits quicker convergence rates, even with reduced token lengths, highlighting the promise of token communication for facilitating more scalable and resilient MLM implementations in practical multiuser networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07841v1</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junhe Zhang, Wanli Ni, Pengwei Wang, Dongyu Wang</dc:creator>
    </item>
    <item>
      <title>Intelligent Load Balancing Systems using Reinforcement Learning System</title>
      <link>https://arxiv.org/abs/2505.07844</link>
      <description>arXiv:2505.07844v1 Announce Type: new 
Abstract: Load Balancing is a fundamental technology for scaling cloud infrastructure. It enables systems to distribute incoming traffic across backend servers using predefined algorithms such as round robin, weighted round robin, least connections, weighted least connections, resource based, weighted response time, source IP hash, and URL hash.
  This approach has helped software developers, infrastructure engineers, and system administrators address many internet traffic related challenges across modern software architectures ranging from monolithic systems and traditional three tier models to microservices based applications.
  However, traditional traffic balancing techniques are increasingly becoming inadequate in optimizing distribution times. Existing algorithms are struggling to meet the rising demands of internet traffic, often resulting in degraded user experiences.
  To proactively address these issues particularly in areas like response time, distribution latency, and system uptime, we need to rethink how load balancing is implemented. Key challenges include traffic management, congestion control, intelligent scheduling, and the ability to determine when and when not to apply load balancing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07844v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Raju Singh</dc:creator>
    </item>
    <item>
      <title>Revenue Optimization in Video Caching Networks with Privacy-Preserving Demand Predictions</title>
      <link>https://arxiv.org/abs/2505.07872</link>
      <description>arXiv:2505.07872v1 Announce Type: new 
Abstract: Performance of video streaming, which accounts for most of the traffic in wireless communication, can be significantly improved by caching popular videos at the wireless edge. Determining the cache content that optimizes performance (defined via a revenue function) is thus an important task, and prediction of the future demands based on past history can make this process much more efficient. However, since practical video caching networks involve various parties (e.g., users, isp, and csp) that do not wish to reveal information such as past history to each other, privacy-preserving solutions are required. Motivated by this, we propose a proactive caching method based on users' privacy-preserving multi-slot future demand predictions -- obtained from a trained Transformer -- to optimize revenue. Specifically, we first use a privacy-preserving fl algorithm to train a Transformer to predict multi-slot future demands of the users. However, prediction accuracy is not perfect and decreases the farther into the future the prediction is done. We model the impact of prediction errors invoking the file popularities, based on which we formulate a long-term system revenue optimization to make the cache placement decisions. As the formulated problem is NP-hard, we use a greedy algorithm to efficiently obtain an approximate solution. Simulation results validate that (i) the fl solution achieves results close to the centralized (non-privacy-preserving) solution and (ii) optimization of revenue may provide different solutions than the classical chr criterion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07872v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yijing Zhang, Ferdous Pervej, Andreas F. Molisch</dc:creator>
    </item>
    <item>
      <title>Efficient Telecom Specific LLM: TSLAM-Mini with QLoRA and Digital Twin Data</title>
      <link>https://arxiv.org/abs/2505.07877</link>
      <description>arXiv:2505.07877v1 Announce Type: new 
Abstract: General-purpose large language models (LLMs), despite their broad capabilities accrued from open-world data, frequently exhibit suboptimal performance when confronted with the nuanced and specialized demands inherent in real-time telecommunications applications. This investigation addresses this critical limitation through the meticulous fine-tuning of TSLAM-Mini developed by NetoAI, a compact (3.8-billion parameter) causal language model architecturally derived from Phi-4 Mini Instruct 4B. The fine-tuning regimen leverages a bespoke dataset comprising 100,000 samples, strategically engineered to address 20 pivotal telecommunications use-cases, encompassing domains such as Network Fundamentals, IP Routing, MPLS, Network Security, Automation, OSS/BSS, RAN, Mobile Core, Satellite Communications, and Ethical AI. This dataset was curated utilizing NetoAI's DigiTwin platform, enriched with granular insights from venerated network Subject Matter Experts (SMEs) and authoritative RFC documents, thereby capturing high-fidelity representations of real-world network dynamics through simulations inspired by digital twin paradigms. Employing Quantized Low-Rank Adaptation (QLoRA), a state-of-the-art Parameter Efficient Fine-Tuning (PEFT) technique, we achieved substantial training efficiency and enabled prospective deployment on resource-constrained hardware. A novel evaluation framework, predicated on a high-capacity LLM (Qwen3-235B-A22B) functioning as an automated adjudicator, was instituted to rigorously assess instruction-following fidelity and response quality across the specified telecom use-cases. Empirical results unequivocally demonstrate TSLAM-Mini's superior aptitude in telecom-centric applications, underscoring the profound efficacy of domain-specific datasets and PEFT methodologies for advancing intelligent network management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07877v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Vignesh Ethiraj, Divya Vijay, Sidhanth Menon, Heblin Berscilla</dc:creator>
    </item>
    <item>
      <title>VoI-Driven Joint Optimization of Control and Communication in Vehicular Digital Twin Network</title>
      <link>https://arxiv.org/abs/2505.07892</link>
      <description>arXiv:2505.07892v1 Announce Type: new 
Abstract: The vision of sixth-generation (6G) wireless networks paves the way for the seamless integration of digital twins into vehicular networks, giving rise to a Vehicular Digital Twin Network (VDTN). The large amount of computing resources as well as the massive amount of spatial-temporal data in Digital Twin (DT) domain can be utilized to enhance the communication and control performance of Internet of Vehicle (IoV) systems. In this article, we first propose the architecture of VDTN, emphasizing key modules that center on functions related to the joint optimization of control and communication. We then delve into the intricacies of the multitimescale decision process inherent in joint optimization in VDTN, specifically investigating the dynamic interplay between control and communication. To facilitate the joint optimization, we define two Value of Information (VoI) concepts rooted in control performance. Subsequently, utilizing VoI as a bridge between control and communication, we introduce a novel joint optimization framework, which involves iterative processing of two Deep Reinforcement Learning (DRL) modules corresponding to control and communication to derive the optimal policy. Finally, we conduct simulations of the proposed framework applied to a platoon scenario to demonstrate its effectiveness in ensu</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07892v1</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/MNET.2024.3522588</arxiv:DOI>
      <dc:creator>Lei Lei (Sherman), Kan Zheng (Sherman), Jie Mei (Sherman),  Xuemin (Sherman),  Shen</dc:creator>
    </item>
    <item>
      <title>Channel Fingerprint Construction for Massive MIMO: A Deep Conditional Generative Approach</title>
      <link>https://arxiv.org/abs/2505.07893</link>
      <description>arXiv:2505.07893v1 Announce Type: new 
Abstract: Accurate channel state information (CSI) acquisition for massive multiple-input multiple-output (MIMO) systems is essential for future mobile communication networks. Channel fingerprint (CF), also referred to as channel knowledge map, is a key enabler for intelligent environment-aware communication and can facilitate CSI acquisition. However, due to the cost limitations of practical sensing nodes and test vehicles, the resulting CF is typically coarse-grained, making it insufficient for wireless transceiver design. In this work, we introduce the concept of CF twins and design a conditional generative diffusion model (CGDM) with strong implicit prior learning capabilities as the computational core of the CF twin to establish the connection between coarse- and fine-grained CFs. Specifically, we employ a variational inference technique to derive the evidence lower bound (ELBO) for the log-marginal distribution of the observed fine-grained CF conditioned on the coarse-grained CF, enabling the CGDM to learn the complicated distribution of the target data. During the denoising neural network optimization, the coarse-grained CF is introduced as side information to accurately guide the conditioned generation of the CGDM. To make the proposed CGDM lightweight, we further leverage the additivity of network layers and introduce a one-shot pruning approach along with a multi-objective knowledge distillation technique. Experimental results show that the proposed approach exhibits significant improvement in reconstruction performance compared to the baselines. Additionally, zero-shot testing on reconstruction tasks with different magnification factors further demonstrates the scalability and generalization ability of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07893v1</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zhenzhou Jin, Li You, Xudong Li, Zhen Gao, Yuanwei Liu, Xiang-Gen Xia, Xiqi Gao</dc:creator>
    </item>
    <item>
      <title>EnvCDiff: Joint Refinement of Environmental Information and Channel Fingerprints via Conditional Generative Diffusion Model</title>
      <link>https://arxiv.org/abs/2505.07894</link>
      <description>arXiv:2505.07894v1 Announce Type: new 
Abstract: The paradigm shift from environment-unaware communication to intelligent environment-aware communication is expected to facilitate the acquisition of channel state information for future wireless communications. Channel Fingerprint (CF), as an emerging enabling technology for environment-aware communication, provides channel-related knowledge for potential locations within the target communication area. However, due to the limited availability of practical devices for sensing environmental information and measuring channel-related knowledge, most of the acquired environmental information and CF are coarse-grained, insufficient to guide the design of wireless transmissions. To address this, this paper proposes a deep conditional generative learning approach, namely a customized conditional generative diffusion model (CDiff). The proposed CDiff simultaneously refines environmental information and CF, reconstructing a fine-grained CF that incorporates environmental information, referred to as EnvCF, from its coarse-grained counterpart. Experimental results show that the proposed approach significantly improves the performance of EnvCF construction compared to the baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07894v1</guid>
      <category>cs.NI</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zhenzhou Jin, Li You, Xiang-Gen Xia, Xiqi Gao</dc:creator>
    </item>
    <item>
      <title>Online Learning-based Adaptive Beam Switching for 6G Networks: Enhancing Efficiency and Resilience</title>
      <link>https://arxiv.org/abs/2505.08032</link>
      <description>arXiv:2505.08032v1 Announce Type: new 
Abstract: Adaptive beam switching in 6G networks is challenged by high frequencies, mobility, and blockage. We propose an Online Learning framework using Deep Reinforcement Learning (DRL) with an enhanced state representation (velocity and blockage history), a GRU architecture, and prioritized experience replay for real-time beam optimization. Validated via Nvidia Sionna under time-correlated blockage, our approach significantly enhances resilience in SNR, throughput, and accuracy compared to a conventional heuristic. Furthermore, the enhanced DRL agent outperforms a reactive Multi-Armed Bandit (MAB) baseline by leveraging temporal dependencies, achieving lower performance variability. This demonstrates the benefits of memory and prioritized learning for robust 6G beam management, while confirming MAB as a strong baseline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08032v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seyed Bagher Hashemi Natanzi, Zhicong Zhu, Bo Tang</dc:creator>
    </item>
    <item>
      <title>Mobile Jamming Mitigation in 5G Networks: A MUSIC-Based Adaptive Beamforming Approach</title>
      <link>https://arxiv.org/abs/2505.08046</link>
      <description>arXiv:2505.08046v1 Announce Type: new 
Abstract: Mobile jammers pose a critical threat to 5G networks, particularly in military communications. We propose an intelligent anti-jamming framework that integrates Multiple Signal Classification (MUSIC) for high-resolution Direction-of-Arrival (DoA) estimation, Minimum Variance Distortionless Response (MVDR) beamforming for adaptive interference suppression, and machine learning (ML) to enhance DoA prediction for mobile jammers. Extensive simulations in a realistic highway scenario demonstrate that our hybrid approach achieves an average Signal-to-Noise Ratio (SNR) improvement of 9.58 dB (maximum 11.08 dB) and up to 99.8% DoA estimation accuracy. The framework's computational efficiency and adaptability to dynamic jammer mobility patterns outperform conventional anti-jamming techniques, making it a robust solution for securing 5G communications in contested environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08046v1</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Olivia Holguin, Rachel Donati, Seyed bagher Hashemi Natanzi, Bo Tang</dc:creator>
    </item>
    <item>
      <title>Graph-Based Floor Separation Using Node Embeddings and Clustering of WiFi Trajectories</title>
      <link>https://arxiv.org/abs/2505.08088</link>
      <description>arXiv:2505.08088v1 Announce Type: new 
Abstract: Indoor positioning systems (IPSs) are increasingly vital for location-based services in complex multi-storey environments. This study proposes a novel graph-based approach for floor separation using Wi-Fi fingerprint trajectories, addressing the challenge of vertical localization in indoor settings. We construct a graph where nodes represent Wi-Fi fingerprints, and edges are weighted by signal similarity and contextual transitions. Node2Vec is employed to generate low-dimensional embeddings, which are subsequently clustered using K-means to identify distinct floors. Evaluated on the Huawei University Challenge 2021 dataset, our method outperforms traditional community detection algorithms, achieving an accuracy of 68.97%, an F1- score of 61.99%, and an Adjusted Rand Index of 57.19%. By publicly releasing the preprocessed dataset and implementation code, this work contributes to advancing research in indoor positioning. The proposed approach demonstrates robustness to signal noise and architectural complexities, offering a scalable solution for floor-level localization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08088v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rabia Yasa Kostas, Kahraman Kostas</dc:creator>
    </item>
    <item>
      <title>Hybrid Wi-Fi/PDR Indoor Localization with Fingerprint Matching</title>
      <link>https://arxiv.org/abs/2505.08258</link>
      <description>arXiv:2505.08258v1 Announce Type: new 
Abstract: Indoor position technology has become one of the research highlights in the Internet of Things (IoT), but there is still a lack of universal, low-cost, and high-precision solutions. This paper conducts research on indoor position technology based on location fingerprints and proposes a practical hybrid indoor positioning system. In this experiment, the location fingerprint database is established by using RSS signal in the offline stage, the location algorithm is improved and innovated in the online stage. The weighted k-nearest neighbor algorithm is used for location fingerprint matching and pedestrian dead reckoning technology is used for trajectory tracking. This paper designs and implements an indoor position system that performs the functions of data collection, positioning, and position tracking. Through the test, it is found that it can meet the requirements of indoor positioning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08258v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chunyi Zhang, Zongwei Li, Xiaoqi Li</dc:creator>
    </item>
    <item>
      <title>AI-Driven Digital Twins: Optimizing 5G/6G Network Slicing with NTNs</title>
      <link>https://arxiv.org/abs/2505.08328</link>
      <description>arXiv:2505.08328v1 Announce Type: new 
Abstract: Network slicing in 5G/6G Non-Terrestrial Network (NTN) is confronted with mobility and traffic variability. An artificial intelligence (AI)-based digital twin (DT) architecture with deep reinforcement learning (DRL) using Deep deterministic policy gradient (DDPG) is proposed for dynamic optimization of resource allocation. DT virtualizes network states to enable predictive analysis, while DRL changes bandwidth for eMBB slice. Simulations show a 25\% latency reduction compared to static methods, with enhanced resource utilization. This scalable solution supports 5G/6G NTN applications like disaster recovery and urban blockage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08328v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Afan Ali, Huseyin Arslan</dc:creator>
    </item>
    <item>
      <title>Optimizing Intra-Container Communication with Memory Protection Keys: A Novel Approach to Secure and Efficient Microservice Interaction</title>
      <link>https://arxiv.org/abs/2505.07836</link>
      <description>arXiv:2505.07836v1 Announce Type: cross 
Abstract: In modern cloud-native applications, microservices are commonly deployed in containerized environments to ensure scalability and flexibility. However, inter-process communication (IPC) between co-located microservices often suffers from significant overhead, especially when traditional networking protocols are employed within containers. This paper introduces a novel approach, MPKLink, leveraging Intel Memory Protection Keys (MPK) to enhance intra-container communication efficiency while ensuring security. By utilizing shared memory with MPK-based access control, we eliminate unnecessary networking latencies, leading to reduced resource consumption and faster response times. We present a comprehensive evaluation of MPKLink, demonstrating its superior performance over conventional methods such as REST and gRPC within microservice architectures. Furthermore, we explore the integration of this approach with existing container orchestration platforms, showcasing its seamless adoption in real-world deployment scenarios. This work provides a transformative solution for developers looking to optimize communication in microservices while maintaining the integrity and security of containerized applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07836v1</guid>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <category>cs.PF</category>
      <category>cs.SE</category>
      <pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fnu Yashu, Shubham Malhotra, Muhammad Saqib</dc:creator>
    </item>
    <item>
      <title>Multi-Layer Hierarchical Federated Learning with Quantization</title>
      <link>https://arxiv.org/abs/2505.08145</link>
      <description>arXiv:2505.08145v1 Announce Type: cross 
Abstract: Almost all existing hierarchical federated learning (FL) models are limited to two aggregation layers, restricting scalability and flexibility in complex, large-scale networks. In this work, we propose a Multi-Layer Hierarchical Federated Learning framework (QMLHFL), which appears to be the first study that generalizes hierarchical FL to arbitrary numbers of layers and network architectures through nested aggregation, while employing a layer-specific quantization scheme to meet communication constraints. We develop a comprehensive convergence analysis for QMLHFL and derive a general convergence condition and rate that reveal the effects of key factors, including quantization parameters, hierarchical architecture, and intra-layer iteration counts. Furthermore, we determine the optimal number of intra-layer iterations to maximize the convergence rate while meeting a deadline constraint that accounts for both communication and computation times. Our results show that QMLHFL consistently achieves high learning accuracy, even under high data heterogeneity, and delivers notably improved performance when optimized, compared to using randomly selected values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08145v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Seyed Mohammad Azimi-Abarghouyi, Carlo Fischione</dc:creator>
    </item>
    <item>
      <title>SIRD: A Sender-Informed, Receiver-Driven Datacenter Transport Protocol</title>
      <link>https://arxiv.org/abs/2312.15403</link>
      <description>arXiv:2312.15403v5 Announce Type: replace 
Abstract: Datacenter congestion control protocols are challenged to navigate the throughput-buffering trade-off while relative packet buffer capacity is trending lower year-over-year. In this context, receiver-driven protocols -- which schedule packet transmissions instead of reacting to congestion -- excel when the bottleneck lies at the ToR-to-receiver link. However, when multiple receivers must use a shared link (e.g., ToR to Spine), their independent schedules can conflict. We present SIRD, a receiver-driven congestion control protocol designed around the simple insight that single-owner links should be scheduled, while shared links should be managed with reactive control algorithms. The approach allows receivers to both precisely schedule their downlinks and to coordinate over shared bottlenecks. Critically, SIRD also treats sender uplinks as shared links, enabling the flow of congestion feedback from senders to receivers, which then adapt their scheduling to each sender's real-time capacity. This results in tight scheduling, enabling high bandwidth utilization with little contention, and thus minimal latency-inducing buffering in the fabric. We implement SIRD on top of the Caladan stack and show that SIRD's asymmetric design can deliver 100Gbps in software while keeping network queuing minimal. We further compare SIRD to state-of-the-art receiver-driven protocols (Homa, dcPIM, and ExpressPass) and production-grade reactive protocols (Swift and DCTCP) and show that SIRD is uniquely able to simultaneously maximize link utilization, minimize queuing, and obtain near-optimal latency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.15403v5</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Konstantinos Prasopoulos, Ryan Kosta, Edouard Bugnion, Marios Kogias</dc:creator>
    </item>
    <item>
      <title>PACIFISTA: Conflict Evaluation and Management in Open RAN</title>
      <link>https://arxiv.org/abs/2405.04395</link>
      <description>arXiv:2405.04395v4 Announce Type: replace 
Abstract: The O-RAN ALLIANCE is defining architectures, interfaces, operations, and security requirements for cellular networks based on Open Radio Access Network (RAN) principles. In this context, O-RAN introduced the RAN Intelligent Controllers (RICs) to enable dynamic control of cellular networks via data-driven applications referred to as rApps and xApps. RICs enable for the first time truly intelligent and self-organizing cellular networks. However, enabling the execution of many Artificial Intelligence (AI) algorithms making autonomous control decisions to fulfill diverse (and possibly conflicting) goals poses unprecedented challenges. For instance, the execution of one xApp aiming at maximizing throughput and one aiming at minimizing energy consumption would inevitably result in diametrically opposed resource allocation strategies. Therefore, conflict management becomes a crucial component of any functional intelligent O-RAN system. This article studies the problem of conflict mitigation in O-RAN and proposes PACIFISTA, a framework to detect, characterize, and mitigate conflicts generated by O-RAN applications that control RAN parameters. PACIFISTA leverages a profiling pipeline to tests O-RAN applications in a sandbox environment, and combines hierarchical graphs with statistical models to detect the existence of conflicts and evaluate their severity. Experiments on Colosseum and OpenRAN Gym demonstrate PACIFISTA's ability to predict conflicts and provide valuable information before conflicting xApps are deployed on production. We demonstrate that users can experience a 16% throughput loss even in the case of xApps with similar goals, and that applications with conflicting goals might cause instability and result in up to 30% performance degradation. We also show that PACIFISTA can help operators to identify conflicting applications and maintain performance degradation at bay.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04395v4</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pietro Brach del Prever, Salvatore D'Oro, Leonardo Bonati, Michele Polese, Maria Tsampazi, Heiko Lehmann, Tommaso Melodia</dc:creator>
    </item>
    <item>
      <title>CoRa: A Collision-Resistant LoRa Symbol Detector of Low Complexity</title>
      <link>https://arxiv.org/abs/2412.13930</link>
      <description>arXiv:2412.13930v2 Announce Type: replace 
Abstract: Long range communication with LoRa has become popular as it avoids the complexity of multi-hop communication at low cost and low energy consumption. LoRa is openly accessible, but its packets are particularly vulnerable to collisions due to long time on air in a shared band. This degrades communication performance. Existing techniques for demodulating LoRa symbols under collisions face challenges such as high computational complexity, reliance on accurate symbol boundary information, or error-prone peak detection methods. In this paper, we introduce CoRa , a symbol detector for demodulating LoRa symbols under severe collisions. CoRa employs a Bayesian classifier to accurately identify the true symbol amidst interference from other LoRa transmissions, leveraging empirically derived features from raw symbol data. Evaluations using real-world and simulated packet traces demonstrate that CoRa clearly outperforms the related state-of-the-art, i.e., up to 29% better decoding performance than TnB and 178% better than CIC. Compared to the LoRa baseline demodulator, CoRa magnifies the packet reception rate by up to 11.53x. CoRa offers a significant reduction in computational complexity compared to existing solutions by only adding a constant overhead to the baseline demodulator, while also eliminating the need for peak detection and accurately identifying colliding frames.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13930v2</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jos\'e \'Alamos, Thomas C. Schmidt, Matthias W\"ahlisch</dc:creator>
    </item>
    <item>
      <title>Governance of Ledger-Anchored Decentralized Identifiers</title>
      <link>https://arxiv.org/abs/2503.16972</link>
      <description>arXiv:2503.16972v2 Announce Type: replace 
Abstract: A Decentralized Identifier (DID) empowers an entity to prove control over a unique and self-issued identifier without relying on any identity provider. The public key material for the proof is encoded into an associated DID document (DDO). This is preferable shared via a distributed ledger because it guarantees algorithmically that everyone has access to the latest state of any tamper-proof DDO but only the entities in control of a DID are able to update theirs. Yet, it is possible to grant deputies the authority to update the DDO on behalf of the DID owner. However, the DID specification leaves largely open on how authorizations over a DDO are managed and enforced among multiple deputies. This article investigates what it means to govern a DID and discusses various forms of how a DID can be controlled by potentially more than one entity. It also presents a prototype of a DID-conform identifier management system where a selected set of governance policies are deployed as Smart Contracts. The article highlights the critical role of governance for the trustworthy and flexible deployment of ledger-anchored DIDs across various domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16972v2</guid>
      <category>cs.NI</category>
      <category>cs.CR</category>
      <pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sandro Rodriguez Garzon, Carlo Segat, Axel K\"upper</dc:creator>
    </item>
    <item>
      <title>Asynchronous Traffic Shaping and Redundancy: Avoiding Unbounded Latencies in In-Car Networks</title>
      <link>https://arxiv.org/abs/2504.01946</link>
      <description>arXiv:2504.01946v2 Announce Type: replace 
Abstract: Time-Sensitive Networking enhances Ethernet-based In-Vehicle Networks (IVNs) with real-time capabilities. Different traffic shaping algorithms have been proposed for time-critical communication, of which the Asynchronous Traffic Shaper (ATS) is an upcoming candidate. However, recent research has shown that ATS can introduce unbounded latencies when shaping traffic from non-FIFO systems. This impacts the applicability of ATS in IVNs, as these networks often use redundancy mechanisms, i.e. Frame Replication and Elimination for Reliability (FRER), that can cause non-FIFO behavior. In this paper, we approach the problem of accumulated delays from ATS by analyzing the scenarios that generate latency and by devising placement and configuration methods for ATS schedulers to prevent this behavior. We evaluate our approach in a simulation environment and show how it prevents conditions of unbounded delays. In an IVN simulation case study, we demonstrate the occurrence of unbounded latencies in a realistic scenario and validate the effectiveness of our solutions in avoiding them.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01946v2</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Teresa L\"ubeck, Philipp Meyer, Timo H\"ackel, Franz Korf, Thomas C. Schmidt</dc:creator>
    </item>
    <item>
      <title>Coordinated Spatial Reuse Scheduling With Machine Learning in IEEE 802.11 MAPC Networks</title>
      <link>https://arxiv.org/abs/2505.07278</link>
      <description>arXiv:2505.07278v2 Announce Type: replace 
Abstract: The densification of Wi-Fi deployments means that fully distributed random channel access is no longer sufficient for high and predictable performance. Therefore, the upcoming IEEE 802.11bn amendment introduces multi-access point coordination (MAPC) methods. This paper addresses a variant of MAPC called coordinated spatial reuse (C-SR), where devices transmit simultaneously on the same channel, with the power adjusted to minimize interference. The C-SR scheduling problem is selecting which devices transmit concurrently and with what settings. We provide a theoretical upper bound model, optimized for either throughput or fairness, which finds the best possible transmission schedule using mixed-integer linear programming. Then, a practical, probing-based approach is proposed which uses multi-armed bandits (MABs), a type of reinforcement learning, to solve the C-SR scheduling problem. We validate both classical (flat) MAB and hierarchical MAB (H-MAB) schemes with simulations and in a testbed. Using H-MABs for C-SR improves aggregate throughput over legacy IEEE 802.11 (on average by 80\% in random scenarios), without reducing the number of transmission opportunities per station. Finally, our framework is lightweight and ready for implementation in Wi-Fi devices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07278v2</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maksymilian Wojnar, Wojciech Ci\k{e}\.zobka, Artur Tomaszewski, Piotr Cho{\l}da, Krzysztof Rusek, Katarzyna Kosek-Szott, Jetmir Haxhibeqiri, Jeroen Hoebeke, Boris Bellalta, Anatolij Zubow, Falko Dressler, Szymon Szott</dc:creator>
    </item>
  </channel>
</rss>
