<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 25 Mar 2024 04:00:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 25 Mar 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Joint Planning of Charging Stations and Power Systems for Heavy-Duty Drayage Trucks</title>
      <link>https://arxiv.org/abs/2403.14866</link>
      <description>arXiv:2403.14866v1 Announce Type: new 
Abstract: As global concerns about climate change intensify, the transition towards zero-emission freight is becoming increasingly vital. Drayage is an important segment of the freight system, typically involving the transport of goods from seaports or intermodal terminals to nearby warehouses. This sector significantly contributes to not only greenhouse gas emissions, but also pollution in densely populated areas. This study presents a holistic optimization model designed for an efficient transition to zero-emission drayage, offering cost-effective strategies for the coordinated investment planning for power systems, charging infrastructure, and electric drayage trucks. The model is validated in the Greater Los Angeles area, where regulatory goals are among the most ambitious. Furthermore, the model's design allows for easy adaptation to other regions. By focusing on drayage trucks, this study also paves the way for future research into other freight categories, establishing a foundation for a more extensive exploration in this field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14866v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zuzhao Ye, Nanpeng Yu, Ran Wei</dc:creator>
    </item>
    <item>
      <title>Network Learning with Directional Sign Patterns</title>
      <link>https://arxiv.org/abs/2403.14915</link>
      <description>arXiv:2403.14915v1 Announce Type: new 
Abstract: Complex systems can be effectively modeled via graphs that encode networked interactions, where relations between entities or nodes are often quantified by signed edge weights, e.g., promotion/inhibition in gene regulatory networks, or encoding political of friendship differences in social networks. However, it is often the case that only an aggregate consequence of such edge weights that characterize relations may be directly observable, as in protein expression of in gene regulatory networks. Thus, learning edge weights poses a significant challenge that is further exacerbated for intricate and large-scale networks. In this article, we address a model problem to determine the strength of sign-indefinite relations that explain marginal distributions that constitute our data. To this end, we develop a paradigm akin to that of the Schr\"odinger bridge problem and an efficient Sinkhorn type algorithm (more properly, Schr\"odinger-Fortet-Sinkhorn algorithm) that allows fast convergence to parameters that minimize a relative entropy/likelihood criterion between the sought signed adjacency matrix and a prior. The formalism that we present represents a novel generalization of the earlier Schr\"odinger formalism in that marginal computations may incorporate weights that model directionality in underlying relations, and further, that it can be extended to high-order networks -- the Schr\"odinger-Fortet-Sinkhorn algorithm that we derive is applicable all the same and allows geometric convergence to a sought sign-indefinite adjacency matrix or tensor, for high-order networks. We demonstrate our framework with synthetic and real-world examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14915v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anqi Dong, Can Chen, Tryphon T. Georgiou</dc:creator>
    </item>
    <item>
      <title>Anderson acceleration of derivative-free projection methods for constrained monotone nonlinear equations</title>
      <link>https://arxiv.org/abs/2403.14924</link>
      <description>arXiv:2403.14924v1 Announce Type: new 
Abstract: The derivative-free projection method (DFPM) is an efficient algorithm for solving monotone nonlinear equations. As problems grow larger, there is a strong demand for speeding up the convergence of DFPM. This paper considers the application of Anderson acceleration (AA) to DFPM for constrained monotone nonlinear equations. By employing a nonstationary relaxation parameter and interleaving with slight modifications in each iteration, a globally convergent variant of AA for DFPM named as AA-DFPM is proposed. Further, the linear convergence rate is proved under some mild assumptions. Experiments on both mathematical examples and a real-world application show encouraging results of AA-DFPM and confirm the suitability of AA for accelerating DFPM in solving optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14924v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiachen Jin, Hongxia Wang, Kangkang Deng</dc:creator>
    </item>
    <item>
      <title>A Stochastic Model-Based Control Methodology for Glycemic Management in the Intensive Care Unit</title>
      <link>https://arxiv.org/abs/2403.14934</link>
      <description>arXiv:2403.14934v1 Announce Type: new 
Abstract: Intensive care unit (ICU) patients exhibit erratic blood glucose (BG) fluctuations, including hypoglycemic and hyperglycemic episodes, and require exogenous insulin delivery to keep their BG in healthy ranges. Glycemic control via glycemic management (GM) is associated with reduced mortality and morbidity in the ICU, but GM increases the cognitive load on clinicians. The availability of robust, accurate, and actionable clinical decision support (CDS) tools reduces this burden and assists in the decision-making process to improve health outcomes. Clinicians currently follow GM protocol flow charts for patient intravenous insulin delivery rate computations. We present a mechanistic model-based control algorithm that predicts the optimal intravenous insulin rate to keep BG within a target range; the goal is to develop this approach for eventual use within CDS systems. In this control framework, we employed a stochastic model representing BG dynamics in the ICU setting and used the linear quadratic Gaussian control methodology to develop a controller. We designed two experiments, one using virtual (simulated) patients and one using a real-world retrospective dataset. Using these, we evaluate the safety and efficacy of this model-based glycemic control methodology. The presented controller avoids hypoglycemia and hyperglycemia in virtual patients, maintaining BG levels in the target range more consistently than two existing GM protocols. Moreover, this methodology could theoretically prevent a large proportion of hypoglycemic and hyperglycemic events recorded in a real-world retrospective dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14934v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Melike Sirlanci, George Hripcsak, Cecilia C. Low Wang, J. N. Stroh, Yanran Wang, Tellen D. Bennett, Andrew M. Stuart, David J. Albers</dc:creator>
    </item>
    <item>
      <title>Data-Driven Predictive Control with Adaptive Disturbance Attenuation for Constrained Systems</title>
      <link>https://arxiv.org/abs/2403.14935</link>
      <description>arXiv:2403.14935v1 Announce Type: new 
Abstract: In this paper, we propose a novel data-driven predictive control approach for systems subject to time-domain constraints. The approach combines the strengths of H-infinity control for rejecting disturbances and MPC for handling constraints. In particular, the approach can dynamically adapt H-infinity disturbance attenuation performance depending on measured system state and forecasted disturbance level to satisfy constraints. We establish theoretical properties of the approach including robust guarantees of closed-loop stability, disturbance attenuation, constraint satisfaction under noisy data, as well as sufficient conditions for recursive feasibility, and illustrate the approach with a numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14935v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nan Li, Ilya Kolmanovsky, Hong Chen</dc:creator>
    </item>
    <item>
      <title>Model Construction for Convex-Constrained Derivative-Free Optimization</title>
      <link>https://arxiv.org/abs/2403.14960</link>
      <description>arXiv:2403.14960v1 Announce Type: new 
Abstract: We develop a new approximation theory for linear and quadratic interpolation models, suitable for use in convex-constrained derivative-free optimization (DFO). Most existing model-based DFO methods for constrained problems assume the ability to construct sufficiently accurate approximations via interpolation, but the standard notions of accuracy (designed for unconstrained problems) may not be achievable by only sampling feasible points, and so may not give practical algorithms. This work extends the theory of convex-constrained linear interpolation developed in [Hough &amp; Roberts, SIAM J. Optim, 32:4 (2022), pp. 2552-2579] to the case of linear regression models and underdetermined quadratic interpolation models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14960v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lindon Roberts</dc:creator>
    </item>
    <item>
      <title>Extragradient Sliding for Composite Non-Monotone Variational Inequalities</title>
      <link>https://arxiv.org/abs/2403.14981</link>
      <description>arXiv:2403.14981v1 Announce Type: new 
Abstract: Variational inequalities offer a versatile and straightforward approach to analyzing a broad range of equilibrium problems in both theoretical and practical fields. In this paper, we consider a composite generally non-monotone variational inequality represented as a sum of $L_q$-Lipschitz monotone and $L_p$-Lipschitz generally non-monotone operators. We applied a special sliding version of the classical Extragradient method to this problem and obtain better convergence results. In particular, to achieve $\varepsilon$-accuracy of the solution, the oracle complexity of the non-monotone operator $Q$ for our algorithm is $O\left(L_p^2/\varepsilon^2\right)$ in contrast to the basic Extragradient algorithm with $O\left((L_p+L_q)^2/\varepsilon^2\right)$. The results of numerical experiments confirm the theoretical findings and show the superiority of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14981v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roman Emelyanov, Andrey Tikhomirov, Aleksandr Beznosikov, Alexander Gasnikov</dc:creator>
    </item>
    <item>
      <title>Riemannian Optimization and the Hartree-Fock Method</title>
      <link>https://arxiv.org/abs/2403.15024</link>
      <description>arXiv:2403.15024v1 Announce Type: new 
Abstract: In the present work we studied a subfield of Applied Mathematics called Riemannian Optimization. The main goal of this subfield is to generalize algorithms, theorems and tools from Mathematical Optimization to the case in which the optimization problem is defined on a Riemannian manifold. As a case study, we implemented some of the main algorithms described in the literature (Gradient Descent, Newton-Raphson and Conjugate Gradient) to solve an optimization problem known as Hartree-Fock. This method is extremely important in the field of Computational Quantum Chemistry and it is a good case study because it is a problem somewhat hard to solve and, as a consequence of this, it requires many tools from Riemannian Optimization. Besides, it is also a good example to see how these algorithms perform in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15024v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Caio O. da Silva</dc:creator>
    </item>
    <item>
      <title>Optimal control of gradient flows via the Weighted Energy-Dissipation method</title>
      <link>https://arxiv.org/abs/2403.15055</link>
      <description>arXiv:2403.15055v1 Announce Type: new 
Abstract: We consider a general optimal control problem in the setting of gradient flows. Two approximations of the problem are presented, both relying on the variational reformulation of gradient-flow dynamics via the Weighted-Energy-Dissipation variational approach. This consists in the minimization of global-in-time functionals over trajectories, combined with a limit passage. We show that the original nonpenalized problem and the two successive approximations admits solutions. Moreover, resorting to a $\Gamma$-convergence analysis we show that penalised optimal controls converge to nonpenalized one as the approximation is removed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15055v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Takeshi Fukao, Ulisse Stefanelli, Riccardo Voso</dc:creator>
    </item>
    <item>
      <title>Perturbations in PDE-constrained optimal control decay exponentially in space</title>
      <link>https://arxiv.org/abs/2403.15056</link>
      <description>arXiv:2403.15056v1 Announce Type: new 
Abstract: For linear-quadratic optimal control problems (OCPs) governed by elliptic and parabolic partial differential equations (PDEs), we investigate the impact of perturbations on optimal solutions. Local perturbations may occur, e.g., due to discretization of the optimality system or disturbed problem data. Whereas these perturbations may exhibit global effects in the uncontrolled case, we prove that the ramifications are exponentially damped in space under stabilizability- and detectability-like conditions. To this end, we prove a bound on the optimality condition's solution operator that is uniform in the domain size. Then, this uniformity is used in a scaling argument to show the exponential decay of perturbations in space. We numerically validate and illustrate our results by solving OCPs involving Helmholtz, Poisson, and advection-diffusion-reaction equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15056v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Simone G\"ottlich, Manuel Schaller, Karl Worthmann</dc:creator>
    </item>
    <item>
      <title>Optimal Contract Design for End-of-Life Care Payments</title>
      <link>https://arxiv.org/abs/2403.15099</link>
      <description>arXiv:2403.15099v1 Announce Type: new 
Abstract: A large fraction of total healthcare expenditure occurs due to end-of-life (EOL) care, which means it is important to study the problem of more carefully incentivizing necessary versus unnecessary EOL care because this has the potential to reduce overall healthcare spending. This paper introduces a principal-agent model that integrates a mixed payment system of fee-for-service and pay-for-performance in order to analyze whether it is possible to better align healthcare provider incentives with patient outcomes and cost-efficiency in EOL care. The primary contributions are to derive optimal contracts for EOL care payments using a principal-agent framework under three separate models for the healthcare provider, where each model considers a different level of risk tolerance for the provider. We derive these optimal contracts by converting the underlying principal-agent models from a bilevel optimization problem into a single-level optimization problem that can be analytically solved. Our results are demonstrated using a simulation where an optimal contract is used to price intracranial pressure monitoring for traumatic brain injuries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15099v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Muyan Jiang, Ying Chen, Xin Chen, Javad Lavaei, Anil Aswani</dc:creator>
    </item>
    <item>
      <title>Paddy: Evolutionary Optimization Algorithm for Chemical Systems and Spaces</title>
      <link>https://arxiv.org/abs/2403.15101</link>
      <description>arXiv:2403.15101v1 Announce Type: new 
Abstract: Optimization of chemical systems and processes have been enhanced and enabled by the guidance of algorithms and analytical approaches. While many methods will systematically investigate how underlying variables govern a given outcome, there is often a substantial number of experiments needed to accurately model these relations. As chemical systems increase in complexity, inexhaustive processes must propose experiments that efficiently optimize the underlying objective, while ideally avoiding convergence on unsatisfactory local minima. We have developed the Paddy software package around the Paddy Field Algorithm, a biologically inspired evolutionary optimization algorithm that propagates parameters without direct inference of the underlying objective function. Benchmarked against the Tree of Parzen Estimator, a Bayesian algorithm implemented in the Hyperopt software Library, Paddy displays efficient optimization with lower runtime, and avoidance of early convergence. Herein we report these findings for the cases of: global optimization of a two-dimensional bimodal distribution, interpolation of an irregular sinusoidal function, hyperparameter optimization of an artificial neural network tasked with classification of solvent for reaction components, and targeted molecule generation via optimization of input vectors for a decoder network. We anticipate that the facile nature of Paddy will serve to aid in automated experimentation, where minimization of investigative trials and or diversity of suitable solutions is of high priority.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15101v1</guid>
      <category>math.OC</category>
      <category>physics.chem-ph</category>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Armen Beck, Jonathan Fine, Gaurav Chopra</dc:creator>
    </item>
    <item>
      <title>Near-optimal performance of stochastic economic MPC</title>
      <link>https://arxiv.org/abs/2403.15159</link>
      <description>arXiv:2403.15159v1 Announce Type: new 
Abstract: This paper presents first results for near optimality in expectation of the closed-loop solutions for stochastic economic MPC. The approach relies on a recently developed turnpike property for stochastic optimal control problems at an optimal stationary process, combined with techniques for analyzing time-varying economic MPC schemes. We obtain near optimality in finite time as well as overtaking and average near optimality on infinite time horizons.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15159v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonas Schie{\ss}l, Ruchuan Ou, Timm Faulwasser, Michael H. Baumann, Lars Gr\"une</dc:creator>
    </item>
    <item>
      <title>Pursuit-Evasion on a Sphere and When It Can Be Considered Flat</title>
      <link>https://arxiv.org/abs/2403.15188</link>
      <description>arXiv:2403.15188v1 Announce Type: new 
Abstract: In classical works on a planar differential pursuit-evasion game with a faster pursuer, the intercept point resulting from the equilibrium strategies lies on the Apollonius circle. This property was exploited for the construction of the equilibrium strategies for two faster pursuers against one evader. Extensions for planar multiple-pursuer single-evader scenarios have been considered. We study a pursuit-evasion game on a sphere and the relation of the equilibrium intercept point to the Apollonius domain on the sphere. The domain is a generalization of the planar Apollonius circle set. We find a condition resulting in the intercept point belonging to the Apollonius domain, which is the characteristic of the planar game solution. Finally, we use this characteristic to discuss pursuit and evasion strategies in the context of two pursuers and a single slower evader on the sphere and illustrate it using numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15188v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.AG</category>
      <category>math.DG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dejan Milutinovic, Alexander Von Moll, Satyanarayana G. Manyam, David W. Casbeer, Isaac E. Weintraub, Meir Pachter</dc:creator>
    </item>
    <item>
      <title>Robust Microgrid Dispatch with Real-Time Energy Sharing and Endogenous Uncertainty</title>
      <link>https://arxiv.org/abs/2403.15219</link>
      <description>arXiv:2403.15219v1 Announce Type: new 
Abstract: With the rising adoption of distributed energy resources (DERs), microgrid dispatch is facing new challenges: DER owners are independent stakeholders seeking to maximize their individual profits rather than being controlled centrally; and the dispatch of renewable generators may affect the microgrid's exposure to uncertainty. To address these challenges, this paper proposes a two-stage robust microgrid dispatch model with real-time energy sharing and endogenous uncertainty. In the day-ahead stage, the connection/disconnection of renewable generators is optimized, which influences the size and dimension of the uncertainty set. As a result, the uncertainty set is endogenously given. In addition, non-anticipative operational bounds for energy storage (ES) are derived to enable the online operation of ES in real-time. In the real-time stage, DER owners (consumers and prosumers) share energy with each other via a proposed energy sharing mechanism, which forms a generalized Nash game. To solve the robust microgrid dispatch model, we develop an equivalent optimization model to compute the real-time energy sharing equilibrium. Based on this, a projection-based column-and-constraint generation (C&amp;CG) method is proposed to handle the endogenous uncertainty. Numerical experiments show the effectiveness and advantages of the proposed model and method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15219v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Meng Yang, Rui Xie, Yongjun Zhang, Yue Chen</dc:creator>
    </item>
    <item>
      <title>On moment relaxations for linear state feedback controller synthesis with non-convex quadratic costs and constraints</title>
      <link>https://arxiv.org/abs/2403.15228</link>
      <description>arXiv:2403.15228v1 Announce Type: new 
Abstract: We present a simple and effective way to account for non-convex costs and constraints~in~state feedback synthesis, and an interpretation for the variables in which state feedback synthesis is typically convex. We achieve this by deriving the controller design using moment matrices of state and input. It turns out that this approach allows the consideration of non-convex constraints by relaxing them as expectation constraints, and that the variables in which state feedback synthesis is typically convexified can be identified with blocks of these moment matrices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15228v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dennis Gramlich, Sheng Gao, Hao Zhang, Carsten W. Scherer, Christian Ebenbauer</dc:creator>
    </item>
    <item>
      <title>A data-driven approach to PDE-constrained optimization in inverse problems</title>
      <link>https://arxiv.org/abs/2403.15292</link>
      <description>arXiv:2403.15292v1 Announce Type: new 
Abstract: Inverse problems are ubiquitous in science and engineering. Many of these are naturally formulated as a PDE-constrained optimization problem. These non-linear, large-scale, constrained optimization problems know many challenges, of which the inherent non-linearity of the problem is an important one. As an alternative to this physics-driven approach, data-driven methods have been proposed. These methods come with their own set of challenges, and it appears that, ideally, one would devise hybrid methods that combine the best of both worlds. In this paper, we propose one way of combining PDE-constrained optimization with recently proposed data-driven reduced-order models. Starting from an infinite-dimensional formulation of the inverse problem with discrete data, we propose a general framework for the analysis and discretisation of such problems. The proposed approach is based on a relaxed formulation of the PDE-constrained optimization problem, which reduces to a weighted non-linear least-squares problem. The weight matrix turns out to be the Gram matrix of solutions of the PDE, and it can be estimated directly from the measurements. We provide a number of representative case studies and numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15292v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tristan van Leeuwen, Yunan Yang</dc:creator>
    </item>
    <item>
      <title>Nonlinear Reachable Set Computation and Model Predictive Control for Safe Hypersonic Re-entry of Atmospheric Vehicles</title>
      <link>https://arxiv.org/abs/2403.15294</link>
      <description>arXiv:2403.15294v1 Announce Type: new 
Abstract: This paper investigates the application of reachability analysis to the re-entry problem faced by vehicles entering Earth's atmosphere. The study delves into the time evolution of reachable sets for the system, particularly when subject to nonlinear implicit controls, given the potential damage from the intense heat generated during hypersonic re-entry. Our proposed methodology leverages zonotopes and constrained zonotopes to ensure compliance with safety specifications. Furthermore, we utilize Model Predictive Control for detailed trajectory planning. To substantiate our methodology, we provide detailed simulations that not only tackle nonlinear re-entry scenarios but also illustrate trajectory planning using MPC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15294v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinaykumar Patel, Kamesh Subbarao</dc:creator>
    </item>
    <item>
      <title>Optimal Exploration Strategy for Regret Minimization in Unconstrained Scalar Optimization Problems</title>
      <link>https://arxiv.org/abs/2403.15344</link>
      <description>arXiv:2403.15344v1 Announce Type: new 
Abstract: We study the problem of determining the optimal exploration strategy in an unconstrained scalar optimization problem depending on an unknown parameter to be learned from online collected noisy data. An optimal trade-off between exploration and exploitation is crucial for effective optimization under uncertainties, and to achieve this we consider a cumulative regret minimization approach over a finite horizon, with each time instant in the horizon characterized by a stochastic exploration signal, whose variance has to be designed. In this setting, under an idealized assumption on an appropriately defined information function associated with the excitation, we are able to show that the optimal exploration strategy is either to use no exploration at all (called lazy exploration) or adding an exploration excitation only at the first time instant of the horizon (called immediate exploration). A quadratic numerical example is used to illustrate the results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15344v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ying Wang, Mirko Pasquini, K\'evin Colin, H{\aa}kan Hjalmarsson</dc:creator>
    </item>
    <item>
      <title>CASPER: Carbon-Aware Scheduling and Provisioning for Distributed Web Services</title>
      <link>https://arxiv.org/abs/2403.14792</link>
      <description>arXiv:2403.14792v1 Announce Type: cross 
Abstract: There has been a significant societal push towards sustainable practices, including in computing. Modern interactive workloads such as geo-distributed web-services exhibit various spatiotemporal and performance flexibility, enabling the possibility to adapt the location, time, and intensity of processing to align with the availability of renewable and low-carbon energy. An example is a web application hosted across multiple cloud regions, each with varying carbon intensity based on their local electricity mix. Distributed load-balancing enables the exploitation of low-carbon energy through load migration across regions, reducing web applications carbon footprint. In this paper, we present CASPER, a carbon-aware scheduling and provisioning system that primarily minimizes the carbon footprint of distributed web services while also respecting their Service Level Objectives (SLO). We formulate CASPER as an multi-objective optimization problem that considers both the variable carbon intensity and latency constraints of the network. Our evaluation reveals the significant potential of CASPER in achieving substantial reductions in carbon emissions. Compared to baseline methods, CASPER demonstrates improvements of up to 70% with no latency performance degradation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14792v1</guid>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <category>cs.PF</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3634769.3634812</arxiv:DOI>
      <arxiv:journal_reference>The 14th international Green and Sustainable Computing Conference (IGSC'23), October 28--29, 2023</arxiv:journal_reference>
      <dc:creator>Abel Souza, Shruti Jasoria, Basundhara Chakrabarty, Alexander Bridgwater, Axel Lundberg, Filip Skogh, Ahmed Ali-Eldin, David Irwin, Prashant Shenoy</dc:creator>
    </item>
    <item>
      <title>Non-Convex Robust Hypothesis Testing using Sinkhorn Uncertainty Sets</title>
      <link>https://arxiv.org/abs/2403.14822</link>
      <description>arXiv:2403.14822v1 Announce Type: cross 
Abstract: We present a new framework to address the non-convex robust hypothesis testing problem, wherein the goal is to seek the optimal detector that minimizes the maximum of worst-case type-I and type-II risk functions. The distributional uncertainty sets are constructed to center around the empirical distribution derived from samples based on Sinkhorn discrepancy. Given that the objective involves non-convex, non-smooth probabilistic functions that are often intractable to optimize, existing methods resort to approximations rather than exact solutions. To tackle the challenge, we introduce an exact mixed-integer exponential conic reformulation of the problem, which can be solved into a global optimum with a moderate amount of input data. Subsequently, we propose a convex approximation, demonstrating its superiority over current state-of-the-art methodologies in literature. Furthermore, we establish connections between robust hypothesis testing and regularized formulations of non-robust risk functions, offering insightful interpretations. Our numerical study highlights the satisfactory testing performance and computational efficiency of the proposed framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14822v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jie Wang, Rui Gao, Yao Xie</dc:creator>
    </item>
    <item>
      <title>Adapprox: Adaptive Approximation in Adam Optimization via Randomized Low-Rank Matrices</title>
      <link>https://arxiv.org/abs/2403.14958</link>
      <description>arXiv:2403.14958v1 Announce Type: cross 
Abstract: As deep learning models exponentially increase in size, optimizers such as Adam encounter significant memory consumption challenges due to the storage of first and second moment data. Current memory-efficient methods like Adafactor and CAME often compromise accuracy with their matrix factorization techniques. Addressing this, we introduce Adapprox, a novel approach that employs randomized low-rank matrix approximation for a more effective and accurate approximation of Adam's second moment. Adapprox features an adaptive rank selection mechanism, finely balancing accuracy and memory efficiency, and includes an optional cosine similarity guidance strategy to enhance stability and expedite convergence. In GPT-2 training and downstream tasks, Adapprox surpasses AdamW by achieving 34.5% to 49.9% and 33.8% to 49.9% memory savings for the 117M and 345M models, respectively, with the first moment enabled, and further increases these savings without the first moment. Besides, it enhances convergence speed and improves downstream task performance relative to its counterparts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14958v1</guid>
      <category>cs.LG</category>
      <category>cs.CL</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pengxiang Zhao, Ping Li, Yingjie Gu, Yi Zheng, Stephan Ludger K\"olker, Zhefeng Wang, Xiaoming Yuan</dc:creator>
    </item>
    <item>
      <title>Hybrid integrator-gain system based integral resonant controllers for negative imaginary systems</title>
      <link>https://arxiv.org/abs/2403.15140</link>
      <description>arXiv:2403.15140v1 Announce Type: cross 
Abstract: We introduce a hybrid control system called a hybrid integrator-gain system (HIGS) based integral resonant controller (IRC) to stabilize negative imaginary (NI) systems. A HIGS-based IRC has a similar structure to an IRC, with the integrator replaced by a HIGS. We show that a HIGS-based IRC is an NI system. Also, for a SISO NI system with a minimal realization, we show there exists a HIGS-based IRC such that their closed-loop interconnection is asymptotically stable. Also, we propose a proportional-integral-double-integral resonant controller and a HIGS-based proportional-integral-double-integral resonant controller and show that both of them can be applied to asymptotically stabilize an NI system. An example is provided to illustrate the proposed results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15140v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kanghong Shi, Ian R. Petersen</dc:creator>
    </item>
    <item>
      <title>On the Convergence of Adam under Non-uniform Smoothness: Separability from SGDM and Beyond</title>
      <link>https://arxiv.org/abs/2403.15146</link>
      <description>arXiv:2403.15146v1 Announce Type: cross 
Abstract: This paper aims to clearly distinguish between Stochastic Gradient Descent with Momentum (SGDM) and Adam in terms of their convergence rates. We demonstrate that Adam achieves a faster convergence compared to SGDM under the condition of non-uniformly bounded smoothness. Our findings reveal that: (1) in deterministic environments, Adam can attain the known lower bound for the convergence rate of deterministic first-order optimizers, whereas the convergence rate of Gradient Descent with Momentum (GDM) has higher order dependence on the initial function value; (2) in stochastic setting, Adam's convergence rate upper bound matches the lower bounds of stochastic first-order optimizers, considering both the initial function value and the final error, whereas there are instances where SGDM fails to converge with any learning rate. These insights distinctly differentiate Adam and SGDM regarding their convergence rates. Additionally, by introducing a novel stopping-time based technique, we further prove that if we consider the minimum gradient norm during iterations, the corresponding convergence rate can match the lower bounds across all problem hyperparameters. The technique can also help proving that Adam with a specific hyperparameter scheduler is parameter-agnostic, which hence can be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15146v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bohan Wang, Huishuai Zhang, Qi Meng, Ruoyu Sun, Zhi-Ming Ma, Wei Chen</dc:creator>
    </item>
    <item>
      <title>A Stochastic Quasi-Newton Method for Non-convex Optimization with Non-uniform Smoothness</title>
      <link>https://arxiv.org/abs/2403.15244</link>
      <description>arXiv:2403.15244v1 Announce Type: cross 
Abstract: Classical convergence analyses for optimization algorithms rely on the widely-adopted uniform smoothness assumption. However, recent experimental studies have demonstrated that many machine learning problems exhibit non-uniform smoothness, meaning the smoothness factor is a function of the model parameter instead of a universal constant. In particular, it has been observed that the smoothness grows with respect to the gradient norm along the training trajectory. Motivated by this phenomenon, the recently introduced $(L_0, L_1)$-smoothness is a more general notion, compared to traditional $L$-smoothness, that captures such positive relationship between smoothness and gradient norm. Under this type of non-uniform smoothness, existing literature has designed stochastic first-order algorithms by utilizing gradient clipping techniques to obtain the optimal $\mathcal{O}(\epsilon^{-3})$ sample complexity for finding an $\epsilon$-approximate first-order stationary solution. Nevertheless, the studies of quasi-Newton methods are still lacking. Considering higher accuracy and more robustness for quasi-Newton methods, in this paper we propose a fast stochastic quasi-Newton method when there exists non-uniformity in smoothness. Leveraging gradient clipping and variance reduction, our algorithm can achieve the best-known $\mathcal{O}(\epsilon^{-3})$ sample complexity and enjoys convergence speedup with simple hyperparameter tuning. Our numerical experiments show that our proposed algorithm outperforms the state-of-the-art approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15244v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhenyu Sun, Ermin Wei</dc:creator>
    </item>
    <item>
      <title>Quantitative propagation of smallness and spectral estimates for the Schr\"odinger operator</title>
      <link>https://arxiv.org/abs/2403.15299</link>
      <description>arXiv:2403.15299v1 Announce Type: cross 
Abstract: In this paper, we investigate quantitative propagation of smallness properties for the Schr\"odinger operator on a bounded domain in $\mathbb R^d$. We extend Logunov, Malinnikova's results concerning propagation of smallness for $A$-harmonic functions to solutions of divergence elliptic equations perturbed by a bounded zero order term. We also prove similar results for gradient of solutions to some particular equations. This latter result enables us to follow the recent strategy of Burq, Moyano for the obtaining of spectral estimates on rough sets for the Schr\"odinger operator. Applications to observability estimates and to the null-controllability of associated parabolic equations posed on compact manifolds or the whole euclidean space are then considered.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15299v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <category>math.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>K\'evin Le Balc'h, J\'er\'emy Martin</dc:creator>
    </item>
    <item>
      <title>Reducing non-negativity over general semialgebraic sets to non-negativity over simple sets</title>
      <link>https://arxiv.org/abs/1909.06689</link>
      <description>arXiv:1909.06689v5 Announce Type: replace 
Abstract: A non-negativity certificate (NNC) is a way to write a polynomial so that its non-negativity on a semialgebraic set becomes evident. Positivstellens\"atze (Ps\"atze) guarantee the existence of NNCs. Both, NNCs and Ps\"atze underlie powerful algorithmic techniques for optimization. This paper proposes a universal approach to derive new Ps\"atze for general semialgebraic sets from ones developed for simpler sets, such as a box, a simplex, or the non-negative orthant. We provide several results illustrating the approach. First, by considering Handelman's Positivstellensatz (Psatz) over a box, we construct non-SOS Schm\"{u}dgen-type Ps\"atze over any compact semialgebraic set. That is, a family of Ps\"atze that follow the structure of the fundamental Schm\"{u}dgen's Psatz, but where instead of SOS polynomials, any class of polynomials containing the non-negative constants can be used, such as SONC, DSOS/SDSOS, hyperbolic or sums of AM/GM polynomials. Secondly, by considering the simplex as the simple set, we derive a sparse Psatz over general compact sets, which does not require any structural assumptions of the set. Finally, by considering P\'olya's Psatz over the non-negative orthant, we derive a new non-SOS Psatz over unbounded sets which satisfy some generic conditions. All these results contribute to the literature regarding the use of non-SOS polynomials and sparse NNCs to derive Ps\"atze over compact and unbounded sets. Throughout the article, we illustrate our results with relevant examples and numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:1909.06689v5</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Olga Kuryatnikova, Juan C. Vera, Luis F. Zuluaga</dc:creator>
    </item>
    <item>
      <title>Optimal First-Order Algorithms as a Function of Inequalities</title>
      <link>https://arxiv.org/abs/2110.11035</link>
      <description>arXiv:2110.11035v2 Announce Type: replace 
Abstract: In this work, we present a novel algorithm design methodology that finds the optimal algorithm as a function of inequalities. Specifically, we restrict convergence analyses of algorithms to use a prespecified subset of inequalities, rather than utilizing all true inequalities, and find the optimal algorithm subject to this restriction. This methodology allows us to design algorithms with certain desired characteristics. As concrete demonstrations of this methodology, we find new state-of-the-art accelerated first-order gradient methods using randomized coordinate updates and backtracking line searches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2110.11035v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Chanwoo Park, Ernest K. Ryu</dc:creator>
    </item>
    <item>
      <title>A Finitely Convergent Cutting Plane, and a Bender's Decomposition Algorithm for Mixed-Integer Convex and Two-Stage Convex Programs using Cutting Planes</title>
      <link>https://arxiv.org/abs/2112.04160</link>
      <description>arXiv:2112.04160v2 Announce Type: replace 
Abstract: We present a finitely convergent cutting-plane algorithm for solving a general mixed-integer convex programs given an oracle for solving general convex programs. This method is extended to solve a family of two-stage mixed-integer convex programs using cutting planes, with applications to solving distributionally-robust two-stage stochastic mixed-integer convex programs. Since algorithms purely using cutting planes are not very practical for implementation, we combined the cut generation with a branch-and-union scheme to develop a more practical algorithm. Analysis is also given for the case where convex programming oracle provides an $\epsilon-$optimal solution. Computational results on generated test problems show the practicality of our algorithm. Specifically, results show that addition of cuts speed up solution times by nearly 10-fold on the largest test problems that are solved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2112.04160v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fengqiao Luo, Sanjay Mehrotra</dc:creator>
    </item>
    <item>
      <title>Graph-structured tensor optimization for nonlinear density control and mean field games</title>
      <link>https://arxiv.org/abs/2112.05645</link>
      <description>arXiv:2112.05645v3 Announce Type: replace 
Abstract: In this work we develop a numerical method for solving a type of convex graph-structured tensor optimization problems. This type of problems, which can be seen as a generalization of multi-marginal optimal transport problems with graph-structured costs, appear in many applications. Examples are unbalanced optimal transport and multi-species potential mean field games, where the latter is a class of nonlinear density control problems. The method we develop is based on coordinate ascent in a Lagrangian dual, and under mild assumptions we prove that the algorithm converges globally. Moreover, under a set of stricter assumptions, the algorithm converges R-linearly. To perform the coordinate ascent steps one has to compute projections of the tensor, and doing so by brute force is in general not computationally feasible. Nevertheless, for certain graph structures it is possible to derive efficient methods for computing these projections, and here we specifically consider the graph structure that occurs in multi-species potential mean field games. We also illustrate the methodology on a numerical example from this problem class.</description>
      <guid isPermaLink="false">oai:arXiv.org:2112.05645v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Axel Ringh, Isabel Haasler, Yongxin Chen, Johan Karlsson</dc:creator>
    </item>
    <item>
      <title>Modeling and Contractivity of Neural-Synaptic Networks with Hebbian Learning</title>
      <link>https://arxiv.org/abs/2204.05382</link>
      <description>arXiv:2204.05382v4 Announce Type: replace 
Abstract: This paper is concerned with the modeling and analysis of two of the most commonly used recurrent neural network models (i.e., Hopfield neural network and firing-rate neural network) with dynamic recurrent connections undergoing Hebbian learning rules. To capture the synaptic sparsity of neural circuits we propose a low dimensional formulation. We then characterize certain key dynamical properties. First, we give biologically-inspired forward invariance results. Then, we give sufficient conditions for the non-Euclidean contractivity of the models. Our contraction analysis leads to stability and robustness of time-varying trajectories -- for networks with both excitatory and inhibitory synapses governed by both Hebbian and anti-Hebbian rules. For each model, we propose a contractivity test based upon biologically meaningful quantities, e.g., neural and synaptic decay rate, maximum in-degree, and the maximum synaptic strength. Then, we show that the models satisfy Dale's Principle. Finally, we illustrate the effectiveness of our results via a numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2204.05382v4</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Veronica Centorrino, Francesco Bullo, Giovanni Russo</dc:creator>
    </item>
    <item>
      <title>Markov Decision Process Design: A Framework for Integrating Strategic and Operational Decisions</title>
      <link>https://arxiv.org/abs/2304.03765</link>
      <description>arXiv:2304.03765v4 Announce Type: replace 
Abstract: We consider the problem of optimally designing a system for repeated use under uncertainty. We develop a modeling framework that integrates design and operational phases, which are represented by a mixed-integer program and discounted-cost infinite-horizon Markov decision processes, respectively. We seek to simultaneously minimize the design costs and the subsequent expected operational costs. This problem setting arises naturally in several application areas, as we illustrate through examples. We derive a bilevel mixed-integer linear programming formulation for the problem and perform a computational study to demonstrate that realistic instances can be solved numerically.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.03765v4</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seth Brown, Saumya Sinha, Andrew J Schaefer</dc:creator>
    </item>
    <item>
      <title>The role of individual compensation and acceptance decisions in crowdsourced delivery</title>
      <link>https://arxiv.org/abs/2305.01317</link>
      <description>arXiv:2305.01317v3 Announce Type: replace 
Abstract: One of the recent innovations in urban distribution is crowdsourced delivery, where deliveries are made by occasional drivers who wish to utilize their surplus resources (unused transport capacity) by making deliveries in exchange for some compensation. The potential benefits of crowdsourced delivery include reduced delivery costs and increased flexibility (by scaling delivery capacity up and down as needed). The use of occasional drivers poses new challenges because (unlike traditional couriers) neither their availability nor their behavior in accepting delivery offers is certain. The relationship between the compensation offered to occasional drivers and the probability that they will accept a task has been largely neglected in the scientific literature. Therefore, we consider a setting in which compensation-dependent acceptance probabilities are explicitly considered in the process of assigning delivery tasks to occasional drivers. We propose a mixed-integer nonlinear model that minimizes the expected delivery costs while identifying optimal assignments of tasks to a mix of professional and occasional drivers and their compensation. We propose an exact two-stage solution algorithm that allows to decompose compensation and assignment decisions for generic acceptance probability functions and show that the runtime of this algorithm is polynomial under mild conditions. Finally, we also study a more general case of the considered problem setting, show that it is NP-hard and propose an approximate linearization scheme of our mixed-integer nonlinear model. The results of our computational study show clear advantages of our new approach over existing ones. They also indicate that these advantages remain in dynamic settings when tasks and drivers are revealed over time and in which case our method constitutes a fast, yet powerful heuristic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.01317v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alim Bu\u{g}ra \c{C}{\i}nar, Wout Dullaert, Markus Leitner, Rosario Paradiso, Stefan Waldherr</dc:creator>
    </item>
    <item>
      <title>Turnpike and dissipativity in generalized discrete-time stochastic linear-quadratic optimal control</title>
      <link>https://arxiv.org/abs/2309.05422</link>
      <description>arXiv:2309.05422v2 Announce Type: replace 
Abstract: We investigate different turnpike phenomena of generalized discrete-time stochastic linear-quadratic optimal control problems. Our analysis is based on a novel strict dissipativity notion for such problems, in which a stationary stochastic process replaces the optimal steady state of the deterministic setting. We show that from this time-varying dissipativity notion, we can conclude turnpike behaviors concerning different objects like distributions, moments, or sample paths of the stochastic system and that the distributions of the stationary pair can be characterized by a stationary optimization problem. The analytical findings are illustrated by numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.05422v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonas Schie{\ss}l, Ruchuan Ou, Timm Faulwasser, Michael Heinrich Baumann, Lars Gr\"une</dc:creator>
    </item>
    <item>
      <title>Solution-Set Geometry and Regularization Path of a Nonconvexly Regularized Convex Sparse Model</title>
      <link>https://arxiv.org/abs/2311.18438</link>
      <description>arXiv:2311.18438v2 Announce Type: replace 
Abstract: The generalized minimax concave (GMC) penalty is a nonconvex sparse regularizer which can preserve the overall-convexity of the regularized least-squares problem. In this paper, we focus on a significant instance of the GMC model termed scaled GMC (sGMC), and present various notable findings on its solution-set geometry and regularization path. Our investigation indicates that while the sGMC penalty is a nonconvex extension of the LASSO penalty (i.e., the $\ell_1$-norm), the sGMC model preserves many celebrated properties of the LASSO model, hence can serve as a less biased surrogate of LASSO without losing its advantages. Specifically, for a fixed regularization parameter $\lambda$, we show that the solution-set geometry, solution uniqueness and sparseness of the sGMC model can be characterized in a similar elegant way to the LASSO model (see, e.g., Osborne et al. 2000, R. J. Tibshirani 2013). For a varying $\lambda$, we prove that the sGMC solution set is a continuous polytope-valued mapping of $\lambda$. Most noticeably, our study indicates that similar to LASSO, the minimum $\ell_2$-norm regularization path of the sGMC model is continuous and piecewise linear in $\lambda$. Based on these theoretical results, an efficient regularization path algorithm is proposed for the sGMC model, extending the well-known least angle regression (LARS) algorithm for LASSO. We prove the correctness and finite termination of the proposed algorithm under a mild assumption, and confirm its correctness-in-general-situation, efficiency, and practical utility through numerical experiments. Many results in this study also contribute to the theoretical research of LASSO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.18438v2</guid>
      <category>math.OC</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi Zhang, Isao Yamada</dc:creator>
    </item>
    <item>
      <title>Fast Nonlinear Two-Time-Scale Stochastic Approximation: Achieving $O(1/k)$ Finite-Sample Complexity</title>
      <link>https://arxiv.org/abs/2401.12764</link>
      <description>arXiv:2401.12764v3 Announce Type: replace 
Abstract: This paper proposes to develop a new variant of the two-time-scale stochastic approximation to find the roots of two coupled nonlinear operators, assuming only noisy samples of these operators can be observed. Our key idea is to leverage the classic Ruppert-Polyak averaging technique to dynamically estimate the operators through their samples. The estimated values of these averaging steps will then be used in the two-time-scale stochastic approximation updates to find the desired solution. Our main theoretical result is to show that under the strongly monotone condition of the underlying nonlinear operators the mean-squared errors of the iterates generated by the proposed method converge to zero at an optimal rate $O(1/k)$, where $k$ is the number of iterations. Our result significantly improves the existing result of two-time-scale stochastic approximation, where the best known finite-time convergence rate is $O(1/k^{2/3})$. We illustrate this result by applying the proposed method to develop new reinforcement learning algorithms with improved performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.12764v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thinh T. Doan</dc:creator>
    </item>
    <item>
      <title>Mathematical Opportunities in Digital Twins (MATH-DT)</title>
      <link>https://arxiv.org/abs/2402.10326</link>
      <description>arXiv:2402.10326v2 Announce Type: replace 
Abstract: The report describes the discussions from the Workshop on Mathematical Opportunities in Digital Twins (MATH-DT) from December 11-13, 2023, George Mason University.
  It illustrates that foundational Mathematical advances are required for Digital Twins (DTs) that are different from traditional approaches. A traditional model, in biology, physics, engineering or medicine, starts with a generic physical law (e.g., equations) and is often a simplification of reality. A DT starts with a specific ecosystem, object or person (e.g., personalized care) representing reality, requiring multi -scale, -physics modeling and coupling. Thus, these processes begin at opposite ends of the simulation and modeling pipeline, requiring different reliability criteria and uncertainty assessments. Additionally, unlike existing approaches, a DT assists humans to make decisions for the physical system, which (via sensors) in turn feeds data into the DT, and operates for the life of the physical system.
  While some of the foundational mathematical research can be done without a specific application context, one must also keep specific applications in mind for DTs. E.g., modeling a bridge or a biological system (a patient), or a socio-technical system (a city) is very different. The models range from differential equations (deterministic/uncertain) in engineering, to stochastic in biology, including agent-based. These are multi-scale hybrid models or large scale (multi-objective) optimization problems under uncertainty. There are no universal models or approaches. For e.g., Kalman filters for forecasting might work in engineering, but can fail in biomedical domain. Ad hoc studies, with limited systematic work, have shown that AI/ML methods can fail for simple engineering systems and can work well for biomedical problems.
  A list of `Mathematical Opportunities and Challenges' concludes the report.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.10326v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Harbir Antil</dc:creator>
    </item>
    <item>
      <title>The stochastic Ravine accelerated gradient method with general extrapolation coefficients</title>
      <link>https://arxiv.org/abs/2403.04860</link>
      <description>arXiv:2403.04860v2 Announce Type: replace 
Abstract: In a real Hilbert space domain setting, we study the convergence properties of the stochastic Ravine accelerated gradient method for convex differentiable optimization. We consider the general form of this algorithm where the extrapolation coefficients can vary with each iteration, and where the evaluation of the gradient is subject to random errors. This general treatment models a breadth of practical algorithms and numerical implementations. We show that, under a proper tuning of the extrapolation parameters, and when the error variance associated with the gradient evaluations or the step-size sequences vanish sufficiently fast, the Ravine method provides fast convergence of the values both in expectation and almost surely. We also improve the convergence rates from O(.) to o(.). Moreover, we show almost sure summability property of the gradients, which implies the fast convergence of the gradients towards zero. This property reflects the fact that the high-resolution ODE of the Ravine method includes a Hessian-driven damping term. When the space is also separable, our analysis allows also to establish almost sure weak convergence of the sequence of iterates provided by the algorithm. We finally specialize the analysis to consider different parameter choices, including vanishing and constant (heavy ball method with friction) damping parameter, and present a comprehensive landscape of the tradeoffs in speed and accuracy associated with these parameter choices and statistical properties on the sequence of errors in the gradient computations. We provide a thorough discussion of the similarities and differences with the Nesterov accelerated gradient which satisfies similar asymptotic convergence rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04860v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hedy Attouch, Jalal Fadili, Vyacheslav Kungurtsev</dc:creator>
    </item>
    <item>
      <title>On Some Mean Field Games and Master Equations through the lens of conservation laws</title>
      <link>https://arxiv.org/abs/2208.10360</link>
      <description>arXiv:2208.10360v4 Announce Type: replace-cross 
Abstract: In this manuscript we derive a new nonlinear transport equation written on the space of probability measures that allows to study a class of deterministic mean field games and master equations, where the interaction of the agents happens only at the terminal time. The point of view via this transport equation has two important consequences. First, this equation reveals a new monotonicity condition that is sufficient both for the uniqueness of MFG Nash equilibria and for the global in time well-posedness of master equations. Interestingly, this condition is in general in dichotomy with both the Lasry--Lions and displacement monotonicity conditions, studied so far in the literature. Second, in the absence of monotonicity, the conservative form of the transport equation can be used to define weak entropy solutions to the master equation. We construct several concrete examples to demonstrate that MFG Nash equilibria, whether or not they actually exist, may not be selected by the entropy solutions of the master equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.10360v4</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>P. Jameson Graber, Alp\'ar R. M\'esz\'aros</dc:creator>
    </item>
    <item>
      <title>Mean viability theorems and second-order Hamilton-Jacobi equations</title>
      <link>https://arxiv.org/abs/2208.13276</link>
      <description>arXiv:2208.13276v4 Announce Type: replace-cross 
Abstract: We introduce the notion of mean viability for controlled stochastic differential equations and establish counterparts of Nagumo's classical viability theorems (necessary and sufficient conditions for mean viability). As an application, we provide a purely probabilistic proof of a comparison principle and of existence for contingent and viscosity solutions of second-order fully nonlinear path-dependent Hamilton-Jacobi-Bellman equations. We do not use compactness and optimal stopping arguments, which are usually employed in the literature on viscosity solutions for second-order path-dependent PDEs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.13276v4</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian Keller</dc:creator>
    </item>
    <item>
      <title>Coherent Equalization of Linear Quantum Systems</title>
      <link>https://arxiv.org/abs/2211.06003</link>
      <description>arXiv:2211.06003v2 Announce Type: replace-cross 
Abstract: This paper introduces a $H_\infty$-like methodology of coherent filtering for equalization of passive linear quantum systems to help mitigate degrading effects of quantum communication channels. For such systems, which include a wide range of linear quantum optical devices and signals, we seek to find a near optimal equalizing filter which is itself a passive quantum system. The problem amounts to solving an optimization problem subject to constraints dictated by the requirement for the equalizer to be physically realizable. By formulating these constraints in the frequency domain, we show that the problem admits a convex $H_\infty$-like formulation. This allows us to derive a set of suboptimal coherent equalizers using $J$-spectral factorization. An additional semidefinite relaxation combined with the Nevanlinna-Pick interpolation is shown to lead to a tractable algorithm for the design of a near optimal coherent equalizer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.06003v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <category>quant-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.automatica.2024.111630</arxiv:DOI>
      <arxiv:journal_reference>Automatica, 164, 111630, 2024</arxiv:journal_reference>
      <dc:creator>V. Ugrinovskii, M. R. James</dc:creator>
    </item>
    <item>
      <title>Gaussian Cooling and Dikin Walks: The Interior-Point Method for Logconcave Sampling</title>
      <link>https://arxiv.org/abs/2307.12943</link>
      <description>arXiv:2307.12943v4 Announce Type: replace-cross 
Abstract: The connections between (convex) optimization and (logconcave) sampling have been considerably enriched in the past decade with many conceptual and mathematical analogies. For instance, the Langevin algorithm can be viewed as a sampling analogue of gradient descent and has condition-number-dependent guarantees on its performance. In the early 1990s, Nesterov and Nemirovski developed the Interior-Point Method (IPM) for convex optimization based on self-concordant barriers, providing efficient algorithms for structured convex optimization, often faster than the general method. This raises the following question: can we develop an analogous IPM for structured sampling problems?
  In 2012, Kannan and Narayanan proposed the Dikin walk for uniformly sampling polytopes, and an improved analysis was given in 2020 by Laddha-Lee-Vempala. The Dikin walk uses a local metric defined by a self-concordant barrier for linear constraints. Here we generalize this approach by developing and adapting IPM machinery together with the Dikin walk for poly-time sampling algorithms. Our IPM-based sampling framework provides an efficient warm start and goes beyond uniform distributions and linear constraints. We illustrate the approach on important special cases, in particular giving the fastest algorithms to sample uniform, exponential, or Gaussian distributions on a truncated PSD cone. The framework is general and can be applied to other sampling algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.12943v4</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yunbum Kook, Santosh S. Vempala</dc:creator>
    </item>
    <item>
      <title>From Complexity to Clarity: Analytical Expressions of Deep Neural Network Weights via Clifford's Geometric Algebra and Convexity</title>
      <link>https://arxiv.org/abs/2309.16512</link>
      <description>arXiv:2309.16512v4 Announce Type: replace-cross 
Abstract: In this paper, we introduce a novel analysis of neural networks based on geometric (Clifford) algebra and convex optimization. We show that optimal weights of deep ReLU neural networks are given by the wedge product of training samples when trained with standard regularized loss. Furthermore, the training problem reduces to convex optimization over wedge product features, which encode the geometric structure of the training dataset. This structure is given in terms of signed volumes of triangles and parallelotopes generated by data vectors. The convex problem finds a small subset of samples via $\ell_1$ regularization to discover only relevant wedge product features. Our analysis provides a novel perspective on the inner workings of deep neural networks and sheds light on the role of the hidden layers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.16512v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mert Pilanci</dc:creator>
    </item>
    <item>
      <title>Computationally Efficient Chance Constrained Covariance Control with Output Feedback</title>
      <link>https://arxiv.org/abs/2310.02485</link>
      <description>arXiv:2310.02485v2 Announce Type: replace-cross 
Abstract: This paper studies the problem of developing computationally efficient solutions for steering the distribution of the state of a stochastic, linear dynamical system between two boundary Gaussian distributions in the presence of chance-constraints on the state and control input. It is assumed that the state is only partially available through a measurement model corrupted with noise. The filtered state is reconstructed with a Kalman filter, the chance constraints are reformulated as difference of convex (DC) constraints, and the resulting covariance control problem is reformulated as a DC program, which is solved using successive convexification. The efficiency of the proposed method is illustrated on a double integrator example with varying time horizons, and is compared to other state-of-the-art chance constrained covariance control methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.02485v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua Pilipovsky, Panagiotis Tsiotras</dc:creator>
    </item>
    <item>
      <title>Stabilizing reinforcement learning control: A modular framework for optimizing over all stable behavior</title>
      <link>https://arxiv.org/abs/2310.14098</link>
      <description>arXiv:2310.14098v2 Announce Type: replace-cross 
Abstract: We propose a framework for the design of feedback controllers that combines the optimization-driven and model-free advantages of deep reinforcement learning with the stability guarantees provided by using the Youla-Kucera parameterization to define the search domain. Recent advances in behavioral systems allow us to construct a data-driven internal model; this enables an alternative realization of the Youla-Kucera parameterization based entirely on input-output exploration data. Perhaps of independent interest, we formulate and analyze the stability of such data-driven models in the presence of noise. The Youla-Kucera approach requires a stable "parameter" for controller design. For the training of reinforcement learning agents, the set of all stable linear operators is given explicitly through a matrix factorization approach. Moreover, a nonlinear extension is given using a neural network to express a parameterized set of stable operators, which enables seamless integration with standard deep learning libraries. Finally, we show how these ideas can also be applied to tune fixed-structure controllers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.14098v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.automatica.2024.111642</arxiv:DOI>
      <arxiv:journal_reference>Automatica 2024</arxiv:journal_reference>
      <dc:creator>Nathan P. Lawrence, Philip D. Loewen, Shuyuan Wang, Michael G. Forbes, R. Bhushan Gopaluni</dc:creator>
    </item>
    <item>
      <title>Positive Competitive Networks for Sparse Reconstruction</title>
      <link>https://arxiv.org/abs/2311.03821</link>
      <description>arXiv:2311.03821v3 Announce Type: replace-cross 
Abstract: We propose and analyze a continuous-time firing-rate neural network, the positive firing-rate competitive network (\pfcn), to tackle sparse reconstruction problems with non-negativity constraints. These problems, which involve approximating a given input stimulus from a dictionary using a set of sparse (active) neurons, play a key role in a wide range of domains, including for example neuroscience, signal processing, and machine learning. First, by leveraging the theory of proximal operators, we relate the equilibria of a family of continuous-time firing-rate neural networks to the optimal solutions of sparse reconstruction problems. Then, we prove that the \pfcn is a positive system and give rigorous conditions for the convergence to the equilibrium. Specifically, we show that the convergence: (i) only depends on a property of the dictionary; (ii) is linear-exponential, in the sense that initially the convergence rate is at worst linear and then, after a transient, it becomes exponential. We also prove a number of technical results to assess the contractivity properties of the neural dynamics of interest. Our analysis leverages contraction theory to characterize the behavior of a family of firing-rate competitive networks for sparse reconstruction with and without non-negativity constraints. Finally, we validate the effectiveness of our approach via a numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.03821v3</guid>
      <category>q-bio.NC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Veronica Centorrino, Anand Gokhale, Alexander Davydov, Giovanni Russo, Francesco Bullo</dc:creator>
    </item>
    <item>
      <title>Quantum Langevin Dynamics for Optimization</title>
      <link>https://arxiv.org/abs/2311.15587</link>
      <description>arXiv:2311.15587v2 Announce Type: replace-cross 
Abstract: We initiate the study of utilizing Quantum Langevin Dynamics (QLD) to solve optimization problems, particularly those non-convex objective functions that present substantial obstacles for traditional gradient descent algorithms. Specifically, we examine the dynamics of a system coupled with an infinite heat bath. This interaction induces both random quantum noise and a deterministic damping effect to the system, which nudge the system towards a steady state that hovers near the global minimum of objective functions. We theoretically prove the convergence of QLD in convex landscapes, demonstrating that the average energy of the system can approach zero in the low temperature limit with an exponential decay rate correlated with the evolution time. Numerically, we first show the energy dissipation capability of QLD by retracing its origins to spontaneous emission. Furthermore, we conduct detailed discussion of the impact of each parameter. Finally, based on the observations when comparing QLD with classical Fokker-Plank-Smoluchowski equation, we propose a time-dependent QLD by making temperature and $\hbar$ time-dependent parameters, which can be theoretically proven to converge better than the time-independent case and also outperforms a series of state-of-the-art quantum and classical optimization algorithms in many non-convex landscapes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.15587v2</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zherui Chen, Yuchen Lu, Hao Wang, Yizhou Liu, Tongyang Li</dc:creator>
    </item>
    <item>
      <title>Inferring solar differential rotation and viscosity via passive imaging with inertial waves</title>
      <link>https://arxiv.org/abs/2403.00488</link>
      <description>arXiv:2403.00488v2 Announce Type: replace-cross 
Abstract: The recent discovery of inertial waves on the surface of the Sun offers new possibilities to learn about the solar interior. These waves are long-lived with a period on the order of the Sun rotation period ($\sim$27 days) and are sensitive to parameters deep inside the Sun. They are excited by turbulent convection, leading to a passive imaging problem. In this work, we present the forward and inverse problem of reconstructing viscosity and differential rotation on the Sun from cross-covariance observations of these inertial waves.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00488v2</guid>
      <category>astro-ph.SR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tram Thi Ngoc Nguyen, Thorsten Hohage, Damien Fournier, Laurent Gizon</dc:creator>
    </item>
  </channel>
</rss>
