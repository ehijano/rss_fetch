<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 23 Jun 2025 04:00:41 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Fair Contracts in Principal-Agent Games with Heterogeneous Types</title>
      <link>https://arxiv.org/abs/2506.15887</link>
      <description>arXiv:2506.15887v1 Announce Type: new 
Abstract: Fairness is desirable yet challenging to achieve within multi-agent systems, especially when agents differ in latent traits that affect their abilities. This hidden heterogeneity often leads to unequal distributions of wealth, even when agents operate under the same rules. Motivated by real-world examples, we propose a framework based on repeated principal-agent games, where a principal, who also can be seen as a player of the game, learns to offer adaptive contracts to agents. By leveraging a simple yet powerful contract structure, we show that a fairness-aware principal can learn homogeneous linear contracts that equalize outcomes across agents in a sequential social dilemma. Importantly, this fairness does not come at the cost of efficiency: our results demonstrate that it is possible to promote equity and stability in the system while preserving overall performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15887v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jakub T{\l}uczek, Victor Villin, Christos Dimitrakakis</dc:creator>
    </item>
    <item>
      <title>Solving Zero-Sum Convex Markov Games</title>
      <link>https://arxiv.org/abs/2506.16120</link>
      <description>arXiv:2506.16120v1 Announce Type: new 
Abstract: We contribute the first provable guarantees of global convergence to Nash equilibria (NE) in two-player zero-sum convex Markov games (cMGs) by using independent policy gradient methods. Convex Markov games, recently defined by Gemp et al. (2024), extend Markov decision processes to multi-agent settings with preferences that are convex over occupancy measures, offering a broad framework for modeling generic strategic interactions. However, even the fundamental min-max case of cMGs presents significant challenges, including inherent nonconvexity, the absence of Bellman consistency, and the complexity of the infinite horizon.
  We follow a two-step approach. First, leveraging properties of hidden-convex--hidden-concave functions, we show that a simple nonconvex regularization transforms the min-max optimization problem into a nonconvex-proximal Polyak-Lojasiewicz (NC-pPL) objective. Crucially, this regularization can stabilize the iterates of independent policy gradient methods and ultimately lead them to converge to equilibria. Second, building on this reduction, we address the general constrained min-max problems under NC-pPL and two-sided pPL conditions, providing the first global convergence guarantees for stochastic nested and alternating gradient descent-ascent methods, which we believe may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16120v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fivos Kalogiannis, Emmanouil-Vasileios Vlatakis-Gkaragkounis, Ian Gemp, Georgios Piliouras</dc:creator>
    </item>
    <item>
      <title>Bidder Feedback in First-Price Auctions for Video Advertising</title>
      <link>https://arxiv.org/abs/2506.17058</link>
      <description>arXiv:2506.17058v1 Announce Type: new 
Abstract: In first-price auctions for display advertising, exchanges typically communicate the "minimum-bid-to-win" to bidders after the auction as feedback for their bidding algorithms. For a winner, this is the second-highest bid, while for losing bidders it is the highest bid. In this paper we investigate the generalization of this concept to general combinatorial auctions, motivated by the domain of video advertising. In a video pod auction, ad slots during an advertising break in a video stream are auctioned all at once, under several kinds of allocation constraints such as a constraint on total ad duration. We cast the problem in terms of computing bid updates (discounts and raises) that maintain the optimality of the current allocation. Our main result characterizes the set of joint bid updates with this property as the core of an associated bicooperative game. In the case of the assignment problem--a special case of video pod auctions--we provide a linear programming characterization of this bicooperative core. Our characterization leads to several candidates for a generalized minimum-bid-to-win. Drawing on video pod auction data from a real ad exchange, we perform an empirical analysis to understand the bidding dynamics they induce and their convergence properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.17058v1</guid>
      <category>cs.GT</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>S\'ebastien Lahaie, Benjamin Schaeffer, Yuanjun Zhou</dc:creator>
    </item>
    <item>
      <title>A Vision for Trustworthy, Fair, and Efficient Socio-Technical Control using Karma Economies</title>
      <link>https://arxiv.org/abs/2506.17115</link>
      <description>arXiv:2506.17115v1 Announce Type: new 
Abstract: Control systems will play a pivotal role in addressing societal-scale challenges as they drive the development of sustainable future smart cities. At the heart of these challenges is the trustworthy, fair, and efficient allocation of scarce public resources, including renewable energy, transportation, data, computation, etc.. Historical evidence suggests that monetary control -- the prototypical mechanism for managing resource scarcity -- is not always well-accepted in socio-technical resource contexts. In this vision article, we advocate for karma economies as an emerging non-monetary mechanism for socio-technical control. Karma leverages the repetitive nature of many socio-technical resources to jointly attain trustworthy, fair, and efficient allocations; by budgeting resource consumption over time and letting resource users ``play against their future selves.'' To motivate karma, we review related concepts in economics through a control systems lens, and make a case for a) shifting the viewpoint of resource allocations from single-shot and static to repeated and dynamic games; and b) adopting long-run Nash welfare as the formalization of ``fairness and efficiency'' in socio-technical contexts. We show that in many dynamic resource settings, karma Nash equilibria maximize long-run Nash welfare. Moreover, we discuss implications for a future smart city built on multi-karma economies: by choosing whether to combine different socio-technical resources, e.g., electricity and transportation, in a single karma economy, or separate into resource-specific economies, karma provides new flexibility to design the scope of fairness and efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.17115v1</guid>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ezzat Elokda, Andrea Censi, Emilio Frazzoli, Florian D\"orfler, Saverio Bolognani</dc:creator>
    </item>
    <item>
      <title>Alternates, Assemble! Selecting Optimal Alternates for Citizens' Assemblies</title>
      <link>https://arxiv.org/abs/2506.15716</link>
      <description>arXiv:2506.15716v1 Announce Type: cross 
Abstract: An increasingly influential form of deliberative democracy centers on citizens' assemblies, where randomly selected people discuss policy questions. The legitimacy of these panels hinges on their representation of the broader population, but panelists often drop out, leading to an unbalanced composition. Although participant attrition is mitigated in practice by alternates, their selection is not taken into account by existing methods. To address this gap, we introduce an optimization framework for alternate selection. Our algorithmic approach, which leverages learning-theoretic machinery, estimates dropout probabilities using historical data and selects alternates to minimize expected misrepresentation. We establish theoretical guarantees for our approach, including worst-case bounds on sample complexity (with implications for computational efficiency) and on loss when panelists' probabilities of dropping out are mis-estimated. Empirical evaluation using real-world data demonstrates that, compared to the status quo, our method significantly improves representation while requiring fewer alternates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15716v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Angelos Assos, Carmel Baharav, Bailey Flanigan, Ariel Procaccia</dc:creator>
    </item>
    <item>
      <title>Modeling society with a responsible elite</title>
      <link>https://arxiv.org/abs/2506.15877</link>
      <description>arXiv:2506.15877v1 Announce Type: cross 
Abstract: Within the framework of the ViSE (Voting in a Stochastic Environment) model, we examine the dynamics in a society, part of which can be considered an elite. The model allows us to analyze the influence of social attitudes, such as collectivism, individualism, altruism on the well-being of agents. The dynamics is determined by collective decisions and changes in the structure of society, in particular, by the formation of groups of cooperating agents. It is found that the presence of a "responsible elite", combining the support of other agents with limited concern for their own benefit, stabilizes society and eliminates the "pit of losses" paradox. The benefit to society from having a responsible elite is comparable to that from having a prosocial group of the same size. If the elite radically increases the weight of the group component in its combined voting strategy, then its incomes rise sharply, while society's incomes decline. If, in response to the selfish transformation of the elite, a new responsible elite emerges, proportionally larger than the previous one, then society will stabilize again, and the old elite will lose its dominant position. This process can be repeated as long as the size of society allows the formation of new responsible elites of the required size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15877v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.31737/22212264_2025_1_12-35</arxiv:DOI>
      <arxiv:journal_reference>Journal of the New Economic Association, 2025, 1 (66), 12-35 (in Russian)</arxiv:journal_reference>
      <dc:creator>Yana Tsodikova, Pavel Chebotarev</dc:creator>
    </item>
    <item>
      <title>Autocratic strategies in Cournot oligopoly game</title>
      <link>https://arxiv.org/abs/2506.16038</link>
      <description>arXiv:2506.16038v1 Announce Type: cross 
Abstract: An oligopoly is a market in which the price of a goods is controlled by a few firms. Cournot introduced the simplest game-theoretic model of oligopoly, where profit-maximizing behavior of each firm results in market failure. Furthermore, when the Cournot oligopoly game is infinitely repeated, firms can tacitly collude to monopolize the market. Such tacit collusion is realized by the same mechanism as direct reciprocity in the repeated prisoner's dilemma game, where mutual cooperation can be realized whereas defection is favorable for both prisoners in one-shot game. Recently, in the repeated prisoner's dilemma game, a class of strategies called zero-determinant strategies attracts much attention in the context of direct reciprocity. Zero-determinant strategies are autocratic strategies which unilaterally control payoffs of players. There were many attempts to find zero-determinant strategies in other games and to extend them so as to apply them to broader situations. In this paper, first, we show that zero-determinant strategies exist even in the repeated Cournot oligopoly game. Especially, we prove that an averagely unbeatable zero-determinant strategy exists, which is guaranteed to obtain the average payoff of the opponents. Second, we numerically show that the averagely unbeatable zero-determinant strategy can be used to promote collusion when it is used against an adaptively learning player, whereas it cannot promote collusion when it is used against two adaptively learning players. Our findings elucidate some negative impact of zero-determinant strategies in oligopoly market.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16038v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Masahiko Ueda, Shoma Yagi, Genki Ichinose</dc:creator>
    </item>
    <item>
      <title>Optimal Online Bookmaking for Any Number of Outcomes</title>
      <link>https://arxiv.org/abs/2506.16253</link>
      <description>arXiv:2506.16253v1 Announce Type: cross 
Abstract: We study the Online Bookmaking problem, where a bookmaker dynamically updates betting odds on the possible outcomes of an event. In each betting round, the bookmaker can adjust the odds based on the cumulative betting behavior of gamblers, aiming to maximize profit while mitigating potential loss. We show that for any event and any number of betting rounds, in a worst-case setting over all possible gamblers and outcome realizations, the bookmaker's optimal loss is the largest root of a simple polynomial. Our solution shows that bookmakers can be as fair as desired while avoiding financial risk, and the explicit characterization reveals an intriguing relation between the bookmaker's regret and Hermite polynomials. We develop an efficient algorithm that computes the optimal bookmaking strategy: when facing an optimal gambler, the algorithm achieves the optimal loss, and in rounds where the gambler is suboptimal, it reduces the achieved loss to the optimal opportunistic loss, a notion that is related to subgame perfect Nash equilibrium. The key technical contribution to achieve these results is an explicit characterization of the Bellman-Pareto frontier, which unifies the dynamic programming updates for Bellman's value function with the multi-criteria optimization framework of the Pareto frontier in the context of vector repeated games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16253v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hadar Tal, Oron Sabag</dc:creator>
    </item>
    <item>
      <title>Optimism Without Regularization: Constant Regret in Zero-Sum Games</title>
      <link>https://arxiv.org/abs/2506.16736</link>
      <description>arXiv:2506.16736v1 Announce Type: cross 
Abstract: This paper studies the optimistic variant of Fictitious Play for learning in two-player zero-sum games. While it is known that Optimistic FTRL -- a regularized algorithm with a bounded stepsize parameter -- obtains constant regret in this setting, we show for the first time that similar, optimal rates are also achievable without regularization: we prove for two-strategy games that Optimistic Fictitious Play (using any tiebreaking rule) obtains only constant regret, providing surprising new evidence on the ability of non-no-regret algorithms for fast learning in games. Our proof technique leverages a geometric view of Optimistic Fictitious Play in the dual space of payoff vectors, where we show a certain energy function of the iterates remains bounded over time. Additionally, we also prove a regret lower bound of $\Omega(\sqrt{T})$ for Alternating Fictitious Play. In the unregularized regime, this separates the ability of optimism and alternation in achieving $o(\sqrt{T})$ regret.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16736v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>John Lazarsfeld, Georgios Piliouras, Ryann Sim, Stratis Skoulakis</dc:creator>
    </item>
    <item>
      <title>Fair Distribution of Delivery Orders</title>
      <link>https://arxiv.org/abs/2305.00040</link>
      <description>arXiv:2305.00040v4 Announce Type: replace 
Abstract: We initiate the study of fair distribution of delivery tasks among a set of agents wherein delivery jobs are placed along the vertices of a graph. Our goal is to fairly distribute delivery costs (modeled as a submodular function) among a fixed set of agents while satisfying some desirable notions of economic efficiency. We adopt well-established fairness concepts -- such as envy-freeness up to one item (EF1) and minimax share (MMS) -- to our setting and show that fairness is often incompatible with the efficiency notion of social optimality. We then characterize instances that admit fair and socially optimal solutions by exploiting graph structures. We further show that achieving fairness along with Pareto optimality is computationally intractable. We complement this by designing an XP algorithm (parameterized by the number of agents) for finding MMS and Pareto optimal solutions on every tree instance, and show that the same algorithm can be modified to find efficient solutions along with EF1, when such solutions exist. The latter crucially relies on an intriguing result that in our setting EF1 and Pareto optimality jointly imply MMS. We conclude by theoretically and experimentally analyzing the price of fairness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.00040v4</guid>
      <category>cs.GT</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hadi Hosseini, Shivika Narang, Tomasz W\k{a}s</dc:creator>
    </item>
    <item>
      <title>Strategy Complexity of B\"uchi and Transience Objectives in Concurrent Stochastic Games</title>
      <link>https://arxiv.org/abs/2404.15483</link>
      <description>arXiv:2404.15483v3 Announce Type: replace 
Abstract: We study 2-player zero-sum concurrent (i.e., simultaneous move) stochastic B\"uchi games and Transience games on countable graphs. Two players, Max and Min, seek respectively to maximize and minimize the probability of satisfying the game objective. The B\"uchi objective is to visit a given set of target states infinitely often. This can be seen as a special case of maximizing the expected $\limsup$ of the daily rewards, where all daily rewards are in $\{0,1\}$. The Transience objective is to visit no state infinitely often, i.e., every finite subset of the states is eventually left forever. Transience can only be met in infinite game graphs. We show that in B\"uchi games there always exist $\varepsilon$-optimal Max strategies that use just a step counter (discrete clock) plus 1 bit of public memory. This upper bound holds for all countable graphs, but it is a new result even for the special case of finite graphs. The upper bound is tight in the sense that Max strategies that use just a step counter, or just finite memory, are not sufficient even on finite game graphs. This upper bound is a consequence of a slightly stronger new result: $\varepsilon$-optimal Max strategies for the combined B\"uchi and Transience objective require just 1 bit of public memory (but cannot be memoryless). Our proof techniques also yield a closely related result, that $\varepsilon$-optimal Max strategies for the Transience objective alone can be chosen as memoryless.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15483v3</guid>
      <category>cs.GT</category>
      <category>math.PR</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stefan Kiefer, Richard Mayr, Mahsa Shirmohammadi, Patrick Totzke</dc:creator>
    </item>
    <item>
      <title>Incentivize Contribution and Learn Parameters Too: Federated Learning with Strategic Data Owners</title>
      <link>https://arxiv.org/abs/2505.12010</link>
      <description>arXiv:2505.12010v2 Announce Type: replace 
Abstract: Classical federated learning (FL) assumes that the clients have a limited amount of noisy data with which they voluntarily participate and contribute towards learning a global, more accurate model in a principled manner. The learning happens in a distributed fashion without sharing the data with the center. However, these methods do not consider the incentive of an agent for participating and contributing to the process, given that data collection and running a distributed algorithm is costly for the clients. The question of rationality of contribution has been asked recently in the literature and some results exist that consider this problem. This paper addresses the question of simultaneous parameter learning and incentivizing contribution, which distinguishes it from the extant literature. Our first mechanism incentivizes each client to contribute to the FL process at a Nash equilibrium and simultaneously learn the model parameters. However, this equilibrium outcome can be away from the optimal, where clients contribute with their full data and the algorithm learns the optimal parameters. We propose a second mechanism with monetary transfers that is budget balanced and enables the full data contribution along with optimal parameter learning. Large scale experiments with real (federated) datasets (CIFAR-10, FeMNIST, and Twitter) show that these algorithms converge quite fast in practice, yield good welfare guarantees, and better model performance for all agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12010v2</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Drashthi Doshi, Aditya Vema Reddy Kesari, Swaprava Nath, Avishek Ghosh, Suhas S Kowshik</dc:creator>
    </item>
    <item>
      <title>Cooperation and the Design of Public Goods</title>
      <link>https://arxiv.org/abs/2506.05251</link>
      <description>arXiv:2506.05251v2 Announce Type: replace 
Abstract: We consider the cooperative elements that arise in the design of public goods, such as transportation policies and infrastructure. These involve a variety of stakeholders: governments, businesses, advocates, and users. Their eventual deployment depends on the decision maker's ability to garner sufficient support from each of these groups; we formalize these strategic requirements from the perspective of cooperative game theory. Specifically, we introduce non-transferable utility, linear production (NTU LP) games, which combine the game-theoretic tensions inherent in public decision-making with the modeling flexibility of linear programming. We derive structural properties regarding the non-emptiness, representability and complexity of the core, a solution concept that models the viability of cooperation. In particular, we provide fairly general sufficient conditions under which the core of an NTU LP game is guaranteed to be non-empty, prove that determining membership in the core is co-NP-complete, and develop a cutting plane algorithm to optimize various social welfare objectives subject to core membership. Lastly, we apply these results in a data-driven case study on service plan optimization for the Chicago bus system. As our study illustrates, cooperation is necessary for the successful deployment of transportation service plans and similar public goods, but it may also have adverse or counterintuitive distributive implications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05251v2</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>J. Carlos Mart\'inez Mori, Alejandro Toriello</dc:creator>
    </item>
    <item>
      <title>Understanding and Reducing the Class-Dependent Effects of Data Augmentation with A Two-Player Game Approach</title>
      <link>https://arxiv.org/abs/2407.03146</link>
      <description>arXiv:2407.03146v4 Announce Type: replace-cross 
Abstract: Data augmentation is widely applied and has shown its benefits in different machine learning tasks. However, as recently observed, it may have an unfair effect in multi-class classification. While data augmentation generally improves the overall performance (and therefore is beneficial for many classes), it can actually be detrimental for other classes, which can be problematic in some application domains. In this paper, to counteract this phenomenon, we propose CLAM, a CLAss-dependent Multiplicative-weights method. To derive it, we first formulate the training of a classifier as a non-linear optimization problem that aims at simultaneously maximizing the individual class performances and balancing them. By rewriting this optimization problem as an adversarial two-player game, we propose a novel multiplicative weight algorithm, for which we prove the convergence. Interestingly, our formulation also reveals that the class-dependent effects of data augmentation is not due to data augmentation only, but is in fact a general phenomenon. Our empirical results over six datasets demonstrate that the performance of learned classifiers is indeed more fairly distributed over classes, with only limited impact on the average accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03146v4</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yunpeng Jiang, Yutong Ban, Paul Weng</dc:creator>
    </item>
    <item>
      <title>Computing and Learning Stationary Mean Field Equilibria with Scalar Interactions: Algorithms and Applications</title>
      <link>https://arxiv.org/abs/2502.12024</link>
      <description>arXiv:2502.12024v2 Announce Type: replace-cross 
Abstract: Mean field equilibrium (MFE) has emerged as a computationally tractable solution concept for large dynamic games. However, computing MFE remains challenging due to nonlinearities and the absence of contraction properties, limiting its reliability for counterfactual analysis and comparative statics. This paper focuses on MFE in dynamic models where agents interact through a scalar function of the population distribution, referred to as the scalar interaction function. Such models naturally arise in a wide range of applications involving market dynamics and strategic competition. The main contribution of this paper is to introduce iterative algorithms that leverage the scalar interaction structure and are guaranteed to converge to the MFE under mild assumptions. Leveraging this structure, we also establish an MFE existence result for non-compact state spaces and analytical comparative statics. To the best of our knowledge, these are the first algorithms with global convergence guarantees in such settings. Unlike existing approaches, our algorithms do not rely on monotonicity or contraction properties, significantly broadening their applicability. Furthermore, we provide a model-free algorithm that learns the MFE via simulation and reinforcement learning techniques such as Q-learning and policy gradient methods without requiring prior knowledge of payoff or transition functions. We apply our algorithms to classic models of dynamic competition, such as capacity competition, and to competitive models motivated by online marketplaces, including ridesharing and inventory competition, as well as to social learning models. We show how key market parameters influence equilibrium outcomes through reliable comparative statics in these representative models, providing insights into the design of competitive systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12024v2</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bar Light</dc:creator>
    </item>
  </channel>
</rss>
