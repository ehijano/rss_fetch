<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 12 Sep 2025 04:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Fingerprinting Deep Packet Inspection Devices by Their Ambiguities</title>
      <link>https://arxiv.org/abs/2509.09081</link>
      <description>arXiv:2509.09081v1 Announce Type: new 
Abstract: Users around the world face escalating network interference such as censorship, throttling, and interception, largely driven by the commoditization and growing availability of Deep Packet Inspection (DPI) devices. Once reserved for a few well-resourced nation-state actors, the ability to interfere with traffic at scale is now within reach of nearly any network operator. Despite this proliferation, our understanding of DPIs and their deployments on the Internet remains limited -- being network intermediary leaves DPI unresponsive to conventional host-based scanning tools, and DPI vendors actively obscuring their products further complicates measurement efforts.
  In this work, we present a remote measurement framework, dMAP (DPI Mapper), that derives behavioral fingerprints for DPIs to differentiate and cluster these otherwise indistinguishable middleboxes at scale, as a first step toward active reconnaissance of DPIs on the Internet. Our key insight is that parsing and interpreting traffic as network intermediaries inherently involves ambiguities -- from under-specified protocol behaviors to differing RFC interpretations -- forcing DPI vendors into independent implementation choices that create measurable variance among DPIs. Based on differential fuzzing, dMAP systematically discovers, selects, and deploys specialized probes that translate DPI internal parsing behaviors into externally observable fingerprints. Applying dMAP to DPI deployments globally, we demonstrate its practical feasibility, showing that even a modest set of 20-40 discriminative probes reliably differentiates a wide range of DPI implementations, including major nation-state censorship infrastructures and commercial DPI products. We discuss how our fingerprinting methodology generalizes beyond censorship to other forms of targeted interference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09081v1</guid>
      <category>cs.NI</category>
      <category>cs.CR</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3719027.3765145</arxiv:DOI>
      <dc:creator>Diwen Xue, Armin Huremagic, Wayne Wang, Ram Sundara Raman, Roya Ensafi</dc:creator>
    </item>
    <item>
      <title>AI Reasoning for Wireless Communications and Networking: A Survey and Perspectives</title>
      <link>https://arxiv.org/abs/2509.09193</link>
      <description>arXiv:2509.09193v1 Announce Type: new 
Abstract: Artificial Intelligence (AI) techniques play a pivotal role in optimizing wireless communication networks. However, traditional deep learning approaches often act as closed boxes, lacking the structured reasoning abilities needed to tackle complex, multi-step decision problems. This survey provides a comprehensive review and outlook of reasoning-enabled AI in wireless communication networks, with a focus on Large Language Models (LLMs) and other advanced reasoning paradigms. In particular, LLM-based agents can combine reasoning with long-term planning, memory, tool utilization, and autonomous cross-layer control to dynamically optimize network operations with minimal human intervention. We begin by outlining the evolution of intelligent wireless networking and the limitations of conventional AI methods. We then introduce emerging AI reasoning techniques. Furthermore, we establish a classification system applicable to wireless network tasks. We also present a layer-by-layer examination for AI reasoning, covering the physical, data link, network, transport, and application layers. For each part, we identify key challenges and illustrate how AI reasoning methods can improve AI-based wireless communication performance. Finally, we discuss key research directions for AI reasoning toward future wireless communication networks. By combining insights from both communications and AI, this survey aims to chart a path for integrating reasoning techniques into the next-generation wireless networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09193v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Haoxiang Luo, Yu Yan, Yanhui Bian, Wenjiao Feng, Ruichen Zhang, Yinqiu Liu, Jiacheng Wang, Gang Sun, Dusit Niyato, Hongfang Yu, Abbas Jamalipour, Shiwen Mao</dc:creator>
    </item>
    <item>
      <title>Joint Optimisation of Load Balancing and Energy Efficiency for O-RAN Deployments</title>
      <link>https://arxiv.org/abs/2509.09343</link>
      <description>arXiv:2509.09343v1 Announce Type: new 
Abstract: Open Radio Access Network (O-RAN) architecture provides an intrinsic capability to exploit key performance monitoring (KPM) within Radio Intelligence Controller (RIC) to derive network optimisation through xApps. These xApps can leverage KPM knowledge to dynamically switch on/off the associated RUs where such a function is supported over the E2 interface. Several existing studies employ artificial intelligence (AI)/Machine Learning (ML) based approaches to realise such dynamic sleeping for increased energy efficiency (EE). Nevertheless, most of these approaches rely upon offloading user equipment (UE) to carve out a sleeping opportunity. Such an approach inherently creates load imbalance across the network. Such load imbalance may impact the throughput performance of offloaded UEs as they might be allocated a lower number of physical resource blocks (PRBs). Maintaining the same PRB allocation while addressing the EE at the network level is a challenging task. To that end, in this article, we present a comprehensive ML-based framework for joint optimisation of load balancing and EE for ORAN deployments. We formulate the problem as a multi-class classification system that predictively evaluates potential RU configurations before optimising the EE, mapping network conditions to three load balance categories (Well Balanced, Moderately Balanced, Imbalanced). Our multi-threshold approach (Conservative, Moderate, Aggressive) accommodates different operational priorities between energy savings and performance assurance. Experimental evaluation using 4.26 million real network measurements from simulations demonstrates that our Random Forest model achieves 98.3% F1-macro performance, representing 195% improvement over traditional baseline strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09343v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammed M. H. Qazzaz, Abdelaziz Salama, Maryam Hafeez, Syed A. R. Zaidi</dc:creator>
    </item>
    <item>
      <title>Toward quantum-safe scalable networks: an open, standards-aware key management framework</title>
      <link>https://arxiv.org/abs/2509.09453</link>
      <description>arXiv:2509.09453v1 Announce Type: new 
Abstract: With the advent of quantum computing, the increasing threats to security poses a great challenge to communication networks. Recent innovations in this field resulted in promising technologies such as Quantum Key Distribution (QKD), which enables the generation of unconditionally secure keys, establishing secure communications between remote nodes. Additionally, QKD networks enable the interconnection of multinode architectures, extending the point-to-point nature of QKD. However, due to the limitations of the current state of technology, the scalability of QKD networks remains a challenge toward feasible implementations. When it comes to long-distance implementations, trusted relay nodes partially solve the distance issue through the forwarding of the distributed keys, allowing applications that do not have a direct QKD link to securely share key material. Even though the relay procedure itself has been extensively studied, the establishment of the relaying node path still lacks a solution. This paper proposes an innovative network architecture that solves the challenges of Key Management System (KMS) identification, relay path discovery, and scalability of QKD networks by integrating Software-Defined Networking (SDN) principles, and establishing high-level virtual KMSs (vKMS) in each node and creating a new entity called the Quantum Security Controller (QuSeC). The vKMS serves the end-user key requests, managing the multiple KMSs within the node and abstracting the user from discovering the correct KMS. Additionally, based on the high-level view of the network topology and status, the QuSeC serves the path discovery requests from vKMSs, computing the end-to-end (E2E) relay path and applying security policies. The paper also provides a security analysis of the proposal, identifying the security levels of the architecture and analyzing the core networking security properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09453v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ane Sanz, Asier Atutxa, David Franco, Jasone Astorga, Eduardo Jacob, Diego L\'opez</dc:creator>
    </item>
    <item>
      <title>PARROT: Portable Android Reproducible traffic Observation Tool</title>
      <link>https://arxiv.org/abs/2509.09537</link>
      <description>arXiv:2509.09537v1 Announce Type: new 
Abstract: The rapid evolution of mobile security protocols and limited availability of current datasets constrains research in app traffic analysis. This paper presents PARROT, a reproducible and portable traffic capture system for systematic app traffic collection using Android Virtual Devices. The system provides automated environment setup, configurable Android versions, traffic recording management, and labeled captures extraction with human-in-the-loop app interaction. PARROT integrates mitmproxy for optional traffic decryption with automated SSL/TLS key extraction, supporting flexible capture modes with or without traffic interception. We collected a dataset of 80 apps selected from the MAppGraph dataset list, providing traffic captures with corresponding SSL keys for decryption analysis. Our comparative analysis between the MAppGraph dataset (2021) and our dataset (2025) reveals app traffic pattern evolution across 50 common apps. Key findings include migration from TLSv1.2 to TLSv1.3 protocol, with TLSv1.3 comprising 90.0\% of TCP encrypted traffic in 2025 compared to 6.7\% in 2021. QUIC protocol adoption increased substantially, with all 50 common apps generating QUIC traffic under normal network conditions compared to 30 apps in 2021. DNS communications evolved from predominantly unencrypted Do53 protocol (91.0\% in 2021) to encrypted DoT protocol (81.1\% in 2025). The open-source PARROT system enables reproducible app traffic capture for research community adoption and provides insights into app security protocol evolution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09537v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Andrea Jimenez-Berenguel, Celeste Campo, Marta Moure-Garrido, Carlos Garcia-Rubio, Daniel D\'iaz-Sanchez, Florina Almenares</dc:creator>
    </item>
    <item>
      <title>A Cyber-Twin Based Honeypot for Gathering Threat Intelligence</title>
      <link>https://arxiv.org/abs/2509.09222</link>
      <description>arXiv:2509.09222v1 Announce Type: cross 
Abstract: Critical Infrastructure (CI) is prone to cyberattacks. Several techniques have been developed to protect CI against such attacks. In this work, we describe a honeypot based on a cyber twin for a water treatment plant. The honeypot is intended to serve as a realistic replica of a water treatment plant that attracts potential attackers. The attacks launched on the honeypot are recorded and analyzed for threat intelligence. The intelligence so obtained is shared with the management of water treatment plants, who in turn may use it to improve plant protection systems. The honeypot used here is operational and has been attacked on several occasions using, for example, a ransomware attack that is described in detail.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09222v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muhammad Azmi Umer, Zhan Xuna, Yan Lin Aung, Aditya P. Mathur, Jianying Zhou</dc:creator>
    </item>
    <item>
      <title>What You Code Is What We Prove: Translating BLE App Logic into Formal Models with LLMs for Vulnerability Detection</title>
      <link>https://arxiv.org/abs/2509.09291</link>
      <description>arXiv:2509.09291v1 Announce Type: cross 
Abstract: The application layer of Bluetooth Low Energy (BLE) is a growing source of security vulnerabilities, as developers often neglect to implement critical protections such as encryption, authentication, and freshness. While formal verification offers a principled way to check these properties, the manual effort of constructing formal models makes it impractical for large-scale analysis. This paper introduces a key insight: BLE application security analysis can be reframed as a semantic translation problem, i.e., from real-world code to formal models. We leverage large language models (LLMs) not to directly detect vulnerabilities, but to serve as translators that convert BLE-specific code into process models verifiable by tools like ProVerif. We implement this idea in VerifiaBLE, a system that combines static analysis, prompt-guided LLM translation, and symbolic verification to check three core security features: encryption, randomness, and authentication. Applied to 1,050 Android BLE apps, VerifiaBLE uncovers systemic weaknesses: only 10.2\% of apps implement all three protections, while 53.9\% omit them entirely. Our work demonstrates that using LLMs as structured translators can lower the barrier to formal methods, unlocking scalable verification across security-critical domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09291v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Biwei Yan, Yue Zhang, Minghui Xu, Runyu Pan, Jinku Li, Xiuzhen Cheng</dc:creator>
    </item>
    <item>
      <title>Towards A High-Performance Quantum Data Center Network Architecture</title>
      <link>https://arxiv.org/abs/2509.09653</link>
      <description>arXiv:2509.09653v1 Announce Type: cross 
Abstract: Quantum Data Centers (QDCs) are needed to support large-scale quantum processing for both academic and commercial applications. While large-scale quantum computers are constrained by technological and financial barriers, a modular approach that clusters small quantum computers offers an alternative. This approach, however, introduces new challenges in network scalability, entanglement generation, and quantum memory management. In this paper, we propose a three-layer fat-tree network architecture for QDCs, designed to address these challenges. Our architecture features a unique leaf switch and an advanced swapping spine switch design, optimized to handle high volumes of entanglement requests as well as a queue scheduling mechanism that efficiently manages quantum memory to prevent decoherence. Through queuing-theoretical models and simulations in NetSquid, we demonstrate the proposed architecture's scalability and effectiveness in maintaining high entanglement fidelity, offering a practical path forward for modular QDC networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09653v1</guid>
      <category>quant-ph</category>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yufeng Xin, Liang Zhang</dc:creator>
    </item>
    <item>
      <title>Generative Artificial Intelligence for Beamforming in Low-Altitude Economy</title>
      <link>https://arxiv.org/abs/2504.15079</link>
      <description>arXiv:2504.15079v3 Announce Type: replace 
Abstract: The growth of low-altitude economy (LAE) has driven a rising demand for efficient and secure communication. However, conventional beamforming optimization techniques struggle in the complex LAE environments. In this context, generative artificial intelligence (GenAI) methods provide a promising solution. In this article, we first introduce the core concepts of LAE and the roles of beamforming in advanced communication technologies for LAE. We then examine their interrelation, followed by an analysis of the limitations of conventional beamforming methods. Next, we provide an overview of how GenAI methods enhance the process of beamforming, with a focus on its applications in LAE. Furthermore, we present a case study using a generative diffusion model (GDM)-based algorithm to enhance the performance of aerial collaborative beamforming-enabled remote secure communications in LAE and simulation results verified the effectiveness of the proposed algorithms. Finally, promising research opportunities are identified.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15079v3</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Geng Sun, Jia Qi, Chuang Zhang, Xuejie Liu, Jiacheng Wang, Dusit Niyato, Yuanwei Liu, Dong In Kim</dc:creator>
    </item>
    <item>
      <title>To Theoretically Understand Transformer-Based In-Context Learning for Optimizing CSMA</title>
      <link>https://arxiv.org/abs/2508.09146</link>
      <description>arXiv:2508.09146v4 Announce Type: replace-cross 
Abstract: The binary exponential backoff scheme is widely used in WiFi 7 and still incurs poor throughput performance under dynamic channel environments. Recent model-based approaches (e.g., non-persistent and $p$-persistent CSMA) simply optimize backoff strategies under a known and fixed node density, still leading to a large throughput loss due to inaccurate node density estimation. This paper is the first to propose LLM transformer-based in-context learning (ICL) theory for optimizing channel access. We design a transformer-based ICL optimizer to pre-collect collision-threshold data examples and a query collision case. They are constructed as a prompt as the input for the transformer to learn the pattern, which then generates a predicted contention window threshold (CWT). To train the transformer for effective ICL, we develop an efficient algorithm and guarantee a near-optimal CWT prediction within limited training steps. As it may be hard to gather perfect data examples for ICL in practice, we further extend to allow erroneous data input in the prompt. We prove that our optimizer maintains minimal prediction and throughput deviations from the optimal values. Experimental results on NS-3 further demonstrate our approach's fast convergence and near-optimal throughput over existing model-based and DRL-based approaches under unknown node densities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09146v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shugang Hao, Hongbo Li, Lingjie Duan</dc:creator>
    </item>
    <item>
      <title>3GPP NR V2X Mode 2d: Analysis of Distributed Scheduling for Groupcast using ns-3 5G LENA Simulator</title>
      <link>https://arxiv.org/abs/2508.09708</link>
      <description>arXiv:2508.09708v2 Announce Type: replace-cross 
Abstract: Vehicle-to-everything (V2X) communication is a key technology for enabling intelligent transportation systems (ITS) that can improve road safety, traffic efficiency, and environmental sustainability. Among the various V2X applications, platooning is one of the most promising ones, as it allows a group of vehicles to travel closely together at high speeds, reducing fuel consumption and emissions. However, it poses significant challenges for wireless communication, such as high reliability and low latency. In this paper, we evaluate the benefits of group scheduling, also referred to as Mode 2d, which is based on a distributed and scheduled resource allocation scheme that allows the group of cars to select resources from a configured pool without network assistance. We evaluated the scheme through simulations, and the results show that this approach can meet the reliability, low latency, and data rate requirements for platooning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09708v2</guid>
      <category>eess.SP</category>
      <category>cs.NI</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Fehrenbach, Luis Omar Ortiz Abrego, Cornelius Hellge, Thomas Schierl, J\"org Ott</dc:creator>
    </item>
  </channel>
</rss>
