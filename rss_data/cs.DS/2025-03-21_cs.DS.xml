<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 21 Mar 2025 04:00:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A parallel algorithm for the odd two-face shortest k-disjoint path problem</title>
      <link>https://arxiv.org/abs/2503.16336</link>
      <description>arXiv:2503.16336v1 Announce Type: new 
Abstract: The shortest Disjoint Path problem (SDPP) requires us to find pairwise vertex disjoint paths between
  k designated pairs of terminal vertices such that the sum of the path lengths is minimum. The
  focus here is on SDPP restricted to planar graphs where all terminals are arbitrarily partitioned
  over two distinct faces with the additional restriction that each face is required to contain an odd
  number of terminals. We call this problem the Odd two-face planar SDPP. It is shown that this
  problem is solvable in randomized polynomial time and even in RNC. This is the first parallel (or
  even polynomial time) solution for the problem.
  Our algorithm combines ideas from the randomized solution for 2-SDPP by Bj\"orklund and
  Huslfeldt with its parallelization by Datta and Jaiswal along with the deterministic algorithm for
  One-face planar SDPP by Datta, Iyer, Kulkarni and Mukherjee.
  The proof uses a combination of two involutions to reduce a system of linear equations modulo a
  power of 2 to a system of triangular form that is, therefore, invertible. This, in turn, is proved by
  showing that the matrix of the equations, can be interpreted as (the adjacency matrix of) a directed
  acyclic graph (DAG). While our algorithm is primarily algebraic the proof remains combinatorial.
  We also give a parallel algorithm for the (A + B)-SDPP introduced by Hirai and Namba.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16336v1</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Srijan Chakraborty, Samir Datta</dc:creator>
    </item>
    <item>
      <title>Dispersion is (Almost) Optimal under (A)synchrony</title>
      <link>https://arxiv.org/abs/2503.16216</link>
      <description>arXiv:2503.16216v1 Announce Type: cross 
Abstract: The dispersion problem has received much attention recently in the distributed computing literature. In this problem, $k\leq n$ agents placed initially arbitrarily on the nodes of an $n$-node, $m$-edge anonymous graph of maximum degree $\Delta$ have to reposition autonomously to reach a configuration in which each agent is on a distinct node of the graph. Dispersion is interesting as well as important due to its connections to many fundamental coordination problems by mobile agents on graphs, such as exploration, scattering, load balancing, relocation of self-driven electric cars (robots) to recharge stations (nodes), etc. The objective has been to provide a solution that optimizes simultaneously time and memory complexities. There exist graphs for which the lower bound on time complexity is $\Omega(k)$. Memory complexity is $\Omega(\log k)$ per agent independent of graph topology. The state-of-the-art algorithms have (i) time complexity $O(k\log^2k)$ and memory complexity $O(\log(k+\Delta))$ under the synchronous setting [DISC'24] and (ii) time complexity $O(\min\{m,k\Delta\})$ and memory complexity $O(\log(k+\Delta))$ under the asynchronous setting [OPODIS'21]. In this paper, we improve substantially on this state-of-the-art. Under the synchronous setting as in [DISC'24], we present the first optimal $O(k)$ time algorithm keeping memory complexity $O(\log (k+\Delta))$. Under the asynchronous setting as in [OPODIS'21], we present the first algorithm with time complexity $O(k\log k)$ keeping memory complexity $O(\log (k+\Delta))$, which is time-optimal within an $O(\log k)$ factor despite asynchrony. Both results were obtained through novel techniques to quickly find empty nodes to settle agents, which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16216v1</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <category>cs.MA</category>
      <category>cs.RO</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ajay D. Kshemkalyani, Manish Kumar, Anisur Rahaman Molla, Gokarna Sharma</dc:creator>
    </item>
    <item>
      <title>Near-Linear Runtime for a Classical Matrix Preconditioning Algorithm</title>
      <link>https://arxiv.org/abs/2503.16312</link>
      <description>arXiv:2503.16312v1 Announce Type: cross 
Abstract: In 1960, Osborne proposed a simple iterative algorithm for matrix balancing with outstanding numerical performance. Today, it is the default preconditioning procedure before eigenvalue computation and other linear algebra subroutines in mainstream software packages such as Python, Julia, MATLAB, EISPACK, LAPACK, and more. Despite its widespread usage, Osborne's algorithm has long resisted theoretical guarantees for its runtime: the first polynomial-time guarantees were obtained only in the past decade, and recent near-linear runtimes remain confined to variants of Osborne's algorithm with important differences that make them simpler to analyze but empirically slower. In this paper, we address this longstanding gap between theory and practice by proving that Osborne's original algorithm -- the de facto preconditioner in practice -- in fact has a near-linear runtime. This runtime guarantee (1) is optimal in the input size up to at most a single logarithm, (2) is the first runtime for Osborne's algorithm that does not dominate the runtime of downstream tasks like eigenvalue computation, and (3) improves upon the theoretical runtimes for all other variants of Osborne's algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16312v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xufeng Cai, Jason M. Altschuler, Jelena Diakonikolas</dc:creator>
    </item>
    <item>
      <title>Do you know what q-means?</title>
      <link>https://arxiv.org/abs/2308.09701</link>
      <description>arXiv:2308.09701v2 Announce Type: replace-cross 
Abstract: Clustering is one of the most important tools for analysis of large datasets, and perhaps the most popular clustering algorithm is Lloyd's iteration for $k$-means. This iteration takes $n$ vectors $V=[v_1,\dots,v_n]\in\mathbb{R}^{n\times d}$ and outputs $k$ centroids $c_1,\dots,c_k\in\mathbb{R}^d$; these partition the vectors into clusters based on which centroid is closest to a particular vector. We present an overall improved version of the "$q$-means" algorithm, the quantum algorithm originally proposed by Kerenidis, Landman, Luongo, and Prakash (NeurIPS'19) which performs $\varepsilon$-$k$-means, an approximate version of $k$-means clustering. Our algorithm does not rely on quantum linear algebra primitives of prior work, but instead only uses QRAM to prepare simple states based on the current iteration's clusters and multivariate quantum amplitude estimation. The time complexity is $\widetilde{O}\big(\frac{\|V\|_F}{\sqrt{n}}\frac{k^{5/2}d}{\varepsilon}(\sqrt{k} + \log{n})\big)$ and maintains the logarithmic dependence on $n$ while improving the dependence on most of the other parameters. We also present a "dequantized" algorithm for $\varepsilon$-$k$-means which runs in $O\big(\frac{\|V\|_F^2}{n}\frac{k^{2}}{\varepsilon^2}(kd + \log{n})\big)$ time. Notably, this classical algorithm matches the logarithmic dependence on $n$ attained by the quantum algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.09701v2</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joao F. Doriguello, Alessandro Luongo, Ewin Tang</dc:creator>
    </item>
    <item>
      <title>Interpreting the Curse of Dimensionality from Distance Concentration and Manifold Effect</title>
      <link>https://arxiv.org/abs/2401.00422</link>
      <description>arXiv:2401.00422v3 Announce Type: replace-cross 
Abstract: The characteristics of data like distribution and heterogeneity, become more complex and counterintuitive as dimensionality increases. This phenomenon is known as curse of dimensionality, where common patterns and relationships (e.g., internal pattern and boundary pattern) that hold in low-dimensional space may be invalid in higher-dimensional space. It leads to a decreasing performance for the regression, classification, or clustering models or algorithms. Curse of dimensionality can be attributed to many causes. In this paper, we first summarize the potential challenges associated with manipulating high-dimensional data, and explains the possible causes for the failure of regression, classification, or clustering tasks. Subsequently, we delve into two major causes of the curse of dimensionality, distance concentration, and manifold effect, by performing theoretical and empirical analyses. The results demonstrate that, as the dimensionality increases, nearest neighbor search (NNS) using three classical distance measurements, Minkowski distance, Chebyshev distance, and cosine distance, becomes meaningless. Meanwhile, the data incorporates more redundant features, and the variance contribution of principal component analysis (PCA) is skewed towards a few dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.00422v3</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dehua Peng, Zhipeng Gui, Huayi Wu</dc:creator>
    </item>
  </channel>
</rss>
