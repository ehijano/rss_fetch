<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CY updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CY</link>
    <description>cs.CY updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CY" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 17 Dec 2025 05:00:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Writing in Symbiosis: Mapping Human Creative Agency in the AI Era</title>
      <link>https://arxiv.org/abs/2512.13697</link>
      <description>arXiv:2512.13697v1 Announce Type: new 
Abstract: The proliferation of Large Language Models (LLMs) raises a critical question about what it means to be human when we share an increasingly symbiotic relationship with persuasive and creative machines. This paper examines patterns of human-AI coevolution in creative writing, investigating how human craft and agency are adapting alongside machine capabilities. We challenge the prevailing notion of stylistic homogenization by examining diverse patterns in longitudinal writing data. Using a large-scale corpus spanning the pre- and post-LLM era, we observe patterns suggestive of a "Dual-Track Evolution": thematic convergence around AI-related topics, coupled with structured stylistic differentiation. Our analysis reveals three emergent adaptation patterns: authors showing increased similarity to AI style, those exhibiting decreased similarity, and those maintaining stylistic stability while engaging with AI-related themes. This Creative Archetype Map illuminates how authorship is coevolving with AI, contributing to discussions about human-AI collaboration, detection challenges, and the preservation of creative diversity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13697v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vivan Doshi, Mengyuan Li</dc:creator>
    </item>
    <item>
      <title>Adaptive Merit Framework: Merit-Anchored Fairness via SES Correction</title>
      <link>https://arxiv.org/abs/2512.13698</link>
      <description>arXiv:2512.13698v1 Announce Type: new 
Abstract: College admissions systems worldwide continue to face a structural tension between meritocracy and equity. Conventional fairness interventions--affirmative action, categorical quotas, and proxy-based targeting--often rely on coarse indicators (e.g., race or region), operate within fixed quotas that induce zero-sum trade-offs, and lack transparent decision rules. This paper introduces the Adaptive Merit Framework (AMF), a policy-engineered mechanism that recognizes latent potential while preserving merit-based thresholds. AMF integrates three components: (1) a merit-anchored architecture in which conditional admits must exceed the same threshold as regular admits, (2) a dynamic threshold anchored to the raw score of the last regular admit, and (3) direct, continuous SES measurement verified through administrative data.
  Empirical validation using the full PISA 2022 Korea dataset (N=6,377) shows that AMF identifies 4, 6, and 9 additional admits under alpha = 5, 10, and 15 respectively (0.06-0.14% of cohort). Population-weighted estimates using OECD sampling weights suggest that the real-world scale of conditional admits is modestly larger than the raw sample counts, yielding approximately 491, 603, and 760 additional admits under alpha = 5, 10, and 15. All conditional admits exceed the merit threshold by 0.16 to 6.14 points, indicating that AMF recognizes suppressed performance rather than relaxing standards.
  Beyond SES-based corrections, AMF provides a design template for unified admissions architectures that replace fragmented equity tracks and support multi-dimensional evaluation frameworks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13698v1</guid>
      <category>cs.CY</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jung-Ah Lee</dc:creator>
    </item>
    <item>
      <title>Us-vs-Them bias in Large Language Models</title>
      <link>https://arxiv.org/abs/2512.13699</link>
      <description>arXiv:2512.13699v1 Announce Type: new 
Abstract: This study investigates ``us versus them'' bias, as described by Social Identity Theory, in large language models (LLMs) under both default and persona-conditioned settings across multiple architectures (GPT-4.1, DeepSeek-3.1, Gemma-2.0, Grok-3.0, and LLaMA-3.1). Using sentiment dynamics, allotaxonometry, and embedding regression, we find consistent ingroup-positive and outgroup-negative associations across foundational LLMs. We find that adopting a persona systematically alters models' evaluative and affiliative language patterns. For the exemplar personas examined, conservative personas exhibit greater outgroup hostility, whereas liberal personas display stronger ingroup solidarity. Persona conditioning produces distinct clustering in embedding space and measurable semantic divergence, supporting the view that even abstract identity cues can shift models' linguistic behavior. Furthermore, outgroup-targeted prompts increased hostility bias by 1.19--21.76\% across models. These findings suggest that LLMs learn not only factual associations about social groups but also internalize and reproduce distinct ways of being, including attitudes, worldviews, and cognitive styles that are activated when enacting personas. We interpret these results as evidence of a multi-scale coupling between local context (e.g., the persona prompt), localizable representations (what the model ``knows''), and global cognitive tendencies (how it ``thinks''), which are at least reflected in the training data. Finally, we demonstrate ION, an ``us versus them'' bias mitigation approach using fine-tuning and direct preference optimization (DPO), which reduces sentiment divergence by up to 69\%, highlighting the potential for targeted mitigation strategies in future LLM development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13699v1</guid>
      <category>cs.CY</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tabia Tanzin Prama, Julia Witte Zimmerman, Christopher M. Danforth, Peter Sheridan Dodds</dc:creator>
    </item>
    <item>
      <title>Enhancing Transparency and Traceability in Healthcare AI: The AI Product Passport</title>
      <link>https://arxiv.org/abs/2512.13702</link>
      <description>arXiv:2512.13702v1 Announce Type: new 
Abstract: Objective: To develop the AI Product Passport, a standards-based framework improving transparency, traceability, and compliance in healthcare AI via lifecycle-based documentation. Materials and Methods: The AI Product Passport was developed within the AI4HF project, focusing on heart failure AI tools. We analyzed regulatory frameworks (EU AI Act, FDA guidelines) and existing standards to design a relational data model capturing metadata across AI lifecycle phases: study definition, dataset preparation, model generation/evaluation, deployment/monitoring, and passport generation. MLOps/ModelOps concepts were integrated for operational relevance. Co-creation involved feedback from AI4HF consortium and a Lisbon workshop with 21 diverse stakeholders, evaluated via Mentimeter polls. The open-source platform was implemented with Python libraries for automated provenance tracking. Results: The AI Product Passport was designed based on existing standards and methods with well-defined lifecycle management and role-based access. Its implementation is a web-based platform with a relational data model supporting auditable documentation. It generates machine- and human-readable reports, customizable for stakeholders. It aligns with FUTURE-AI principles (Fairness, Universality, Traceability, Usability, Robustness, Explainability), ensuring fairness, traceability, and usability. Exported passports detail model purpose, data provenance, performance, and deployment context. GitHub-hosted backend/frontend codebases enhance accessibility. Discussion and Conclusion: The AI Product Passport addresses transparency gaps in healthcare AI, meeting regulatory and ethical demands. Its open-source nature and alignment with standards foster trust and adaptability. Future enhancements include FAIR data principles and FHIR integration for improved interoperability, promoting responsible AI deployment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13702v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>A. Anil Sinaci, Senan Postaci, Dogukan Cavdaroglu, Machteld J. Boonstra, Okan Mercan, Kerem Yilmaz, Gokce B. Laleci Erturkmen, Folkert W. Asselbergs, Karim Lekadir</dc:creator>
    </item>
    <item>
      <title>Made-in China, Thinking in America:U.S. Values Persist in Chinese LLMs</title>
      <link>https://arxiv.org/abs/2512.13723</link>
      <description>arXiv:2512.13723v1 Announce Type: new 
Abstract: As large language models increasingly mediate access to information and facilitate decision-making, they are becoming instruments in soft power competitions between global actors such as the United States and China. So far, language models seem to be aligned with the values of Western countries, but evidence for this ethical bias comes mostly from models made by American companies. The current crop of state-of-the-art models includes several made in China, so we conducted the first large-scale investigation of how models made in China and the USA align with people from China and the USA. We elicited responses to the Moral Foundations Questionnaire 2.0 and the World Values Survey from ten Chinese models and ten American models, and we compared their responses to responses from thousands of Chinese and American people. We found that all models respond to both surveys more like American people than like Chinese people. This skew toward American values is only slightly mitigated when prompting the models in Chinese or imposing a Chinese persona on the models. These findings have important implications for a near future in which large language models generate much of the content people consume and shape normative influence in geopolitics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13723v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Haslett, Linus Ta-Lun Huang, Leila Khalatbari, Janet Hui-wen Hsiao, Antoni B. Chan</dc:creator>
    </item>
    <item>
      <title>Exploring the Modular Integration of "AI + Architecture" Pedagogy in Undergraduate Design Education: A Case Study of Architectural Design III/IV Courses at Zhejiang University</title>
      <link>https://arxiv.org/abs/2512.13730</link>
      <description>arXiv:2512.13730v1 Announce Type: new 
Abstract: This study investigates AI integration in architectural education through a teaching experiment in Zhejiang University's 2024-25 grade three undergraduate design studio. Adopting a dual-module framework (20-hour AI training + embedded ethics discussions), the course introduced deep learning models, LLMs, AIGC, LoRA, and ComfyUI while maintaining the original curriculum structure, supported by dedicated technical instructors. Findings demonstrate the effectiveness of phased guidance, balanced technical-ethical approaches, and institutional support. The model improved students' digital skills and strategic cognition while addressing AI ethics, providing a replicable approach combining technical and critical learning in design education.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13730v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wang Jiaqi, Lan Yi, Chen Xiang</dc:creator>
    </item>
    <item>
      <title>Instilling Organisational Values in Firefighters through Simulation-Based Training</title>
      <link>https://arxiv.org/abs/2512.13737</link>
      <description>arXiv:2512.13737v1 Announce Type: new 
Abstract: In firefighting and other emergency operations, decisions made under pressure carry profound ethical weight and can significantly impact incident outcomes and firefighter safety. Traditional training methods, while foundational, often fall short in adequately preparing firefighters for the complex ethical dilemmas and value conflicts inherent in chaotic emergency environments. This paper proposes a conceptual framework for enhancing firefighter training by systematically integrating departmental values into simulation-based training. This approach fosters deeper value internalisation and improves value-driven decision-making under pressure. Furthermore, the underlying tools can also be leveraged to evaluate and refine departmental operational protocols for better alignment with preferred values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13737v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nardine Osman, Manel Rodriguez-Soto, Jordi Sabater-Mir</dc:creator>
    </item>
    <item>
      <title>The algorithmic muse and the public domain: Why copyrights legal philosophy precludes protection for generative AI outputs</title>
      <link>https://arxiv.org/abs/2512.13750</link>
      <description>arXiv:2512.13750v1 Announce Type: new 
Abstract: Generative AI (GenAI) outputs are not copyrightable. This article argues why. We bypass conventional doctrinal analysis that focuses on black letter law notions of originality and authorship to re-evaluate copyright's foundational philosophy. GenAI fundamentally severs the direct human creative link to expressive form. Traditional theories utilitarian incentive, labor desert and personality fail to provide coherent justification for protection. The public domain constitutes the default baseline for intellectual creations. Those seeking copyright coverage for GenAI outputs bear the burden of proof. Granting copyright to raw GenAI outputs would not only be philosophically unsound but would also trigger an unprecedented enclosure of the digital commons, creating a legal quagmire and stifling future innovation. The paper advocates for a clear distinction: human creative contributions to AI-generated works may warrant protection, but the raw algorithmic output should remain in the public domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13750v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:journal_reference>Computer Law &amp; Security Review, Volume 58, September 2025, 106170</arxiv:journal_reference>
      <dc:creator>Ezieddin Elmahjub</dc:creator>
    </item>
    <item>
      <title>OpenProposal Platform for Transparent Research Funding Review</title>
      <link>https://arxiv.org/abs/2512.13754</link>
      <description>arXiv:2512.13754v1 Announce Type: new 
Abstract: Research funding allocation remains a critical bottleneck in scientific advancement, yet the review process for funding proposals lacks the transparency that has revolutionized academic paper peer review. Traditional funding agencies operate with closed review systems, limiting accountability and preventing systematic improvements. We present OpenProposal, a proof-of-concept web-based platform that explores how transparency principles from OpenReview might be adapted to research funding proposal evaluation. Built using modern web technologies including Next.js , React , and Prisma , OpenProposal demonstrates the technical feasibility of public reviews, author rebuttals, and transparent decision-making while attempting to protect sensitive information such as budgets. Our platform prototype addresses key limitations identified in current funding systems by providing mechanisms for community engagement, reviewer accountability, and potential data-driven insights into peer review processes. Through system design and implementation, we explore how transparent funding review could potentially enhance scientific integrity and improve research funding decisions, though empirical validation remains necessary. This work contributes a technical foundation for transparent funding review and identifies design considerations for future research on peer review mechanisms in funding contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13754v1</guid>
      <category>cs.CY</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Sakshi Ahuja, Subhankar Mishra</dc:creator>
    </item>
    <item>
      <title>Beyond Procedural Compliance: Human Oversight as a Dimension of Well-being Efficacy in AI Governance</title>
      <link>https://arxiv.org/abs/2512.13768</link>
      <description>arXiv:2512.13768v1 Announce Type: new 
Abstract: Major AI ethics guidelines and laws, including the EU AI Act, call for effective human oversight, but do not define it as a distinct and developable capacity. This paper introduces human oversight as a well-being capacity, situated within the emerging Well-being Efficacy framework. The concept integrates AI literacy, ethical discernment, and awareness of human needs, acknowledging that some needs may be conflicting or harmful. Because people inevitably project desires, fears, and interests into AI systems, oversight requires the competence to examine and, when necessary, restrain problematic demands.
  The authors argue that the sustainable and cost-effective development of this capacity depends on its integration into education at every level, from professional training to lifelong learning. The frame of human oversight as a well-being capacity provides a practical path from high-level regulatory goals to the continuous cultivation of human agency and responsibility essential for safe and ethical AI. The paper establishes a theoretical foundation for future research on the pedagogical implementation and empirical validation of well-being effectiveness in multiple contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13768v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yao Xie, Walter Cullen</dc:creator>
    </item>
    <item>
      <title>Assessing High-Risk Systems: An EU AI Act Verification Framework</title>
      <link>https://arxiv.org/abs/2512.13907</link>
      <description>arXiv:2512.13907v1 Announce Type: new 
Abstract: A central challenge in implementing the AI Act and other AI-relevant regulations in the EU is the lack of a systematic approach to verify their legal mandates. Recent surveys show that this regulatory ambiguity is perceived as a significant burden, leading to inconsistent readiness across Member States. This paper proposes a comprehensive framework designed to help close this gap by organising compliance verification along two fundamental dimensions: the type of method (controls vs. testing) and the target of assessment (data, model, processes, and final product). Additionally, our framework maps core legal requirements to concrete verification activities, serving as a vital bridge between policymakers and practitioners, and aligning legal text with technical standards and best practices. The proposed approach aims to reduce interpretive uncertainty, promote consistency in assessment practices, and support the alignment of regulatory, ethical, and technical perspectives across the AI lifecycle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13907v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alessio Buscemi, Tom Deckenbrunnen, Fahria Kabir, Nishat Mowla, Kateryna Mishchenko</dc:creator>
    </item>
    <item>
      <title>Research Opportunities and Challenges of the EU's Digital Services Act</title>
      <link>https://arxiv.org/abs/2512.14223</link>
      <description>arXiv:2512.14223v1 Announce Type: new 
Abstract: The Digital Services Act (DSA) introduced by the European Union in 2022 offers a landmark framework for platform transparency, with Article 40 enabling vetted researchers to access data from major online platforms. Yet significant legal, technical, and organizational barriers still hinder effective research on systemic online risks. This piece outlines the key challenges emerging from the Article 40 process and proposes practical measures to ensure that the DSA fulfills its transparency and accountability goals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14223v1</guid>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francesco Pierri, Theo Araujo, Sanne Kruikemeier, Philipp Lorenz-Spreen, Mariek M. P. Vanden Abeele, Laura Vandenbosch, Joana Gon\c{c}alves-Sa, Przemyslaw A. Grabowicz</dc:creator>
    </item>
    <item>
      <title>Criminal Liability in AI-Enabled Autonomous Vehicles: A Comparative Study</title>
      <link>https://arxiv.org/abs/2512.14330</link>
      <description>arXiv:2512.14330v1 Announce Type: new 
Abstract: AI revolutionizes transportation through autonomous vehicles (AVs) but introduces complex criminal liability issues regarding infractions. This study employs a comparative legal analysis of primary statutes, real-world liability claims, and academic literature across the US, Germany, UK, China, and India; jurisdictions selected for their technological advancement and contrasting regulatory approaches. The research examines the attribution of human error, AI moral agency, and the identification of primary offenders in AV incidents. Findings reveal fragmented regulatory landscapes: India and the US rely on loose networks of state laws, whereas the UK enacted the pioneering Automated and Electric Vehicles Act 2018. Germany enforces strict safety standards, distinguishing liability based on the vehicle's operating mode, while China similarly aims for a stringent liability regime. The study concludes that globally harmonized legal standards are essential to foster technological innovation while ensuring minimum risk and clear liability attribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14330v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Journal of University Institute of Legal Studies 18(1), 57-78 (2025)</arxiv:journal_reference>
      <dc:creator>Sahibpreet Singh, Manjit Singh</dc:creator>
    </item>
    <item>
      <title>From Framework to Practice: Designing a Real-World Telehealth Application for Palliative Care</title>
      <link>https://arxiv.org/abs/2512.13693</link>
      <description>arXiv:2512.13693v1 Announce Type: cross 
Abstract: As digital health solutions continue to reshape healthcare delivery, telehealth software applications have become vital for improving accessibility, continuity of care, and patient outcomes. This paper presents an analysis of designing a software application focused on Enhanced Telehealth Capabilities (ETHC) for palliative care, integrating across three socio-technical dimensions: quality, human values, and real-world. Designing for quality attributes -- such as performance, maintainability, safety, and security -- ensured that the system is technically robust and compliant with clinical standards. Designing for human values -- empathy, inclusivity, accessibility, and transparency -- helped enhance patient experience, trust, and ethical alignment. Designing for real-world -- through a multidisciplinary, experience-based co-design approach involving clinicians, patients, and carers that guided iterative cycles of prototyping, usability testing, and real-world evaluation -- ensured continuous refinement of features and alignment with clinical practice. The resulting telehealth software solution demonstrated that our socio-technical design framework was successful in producing a secure, equitable, and resilient digital health application. Our design approach can assist others designing software in health and other domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13693v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei Zhou, Rashina Hoda, Andy Li, Chris Bain, Laura Bird, Emmy Trinh, Peter Poon, Teresa O Brien, Mahima Kalla, Olivia Metcalf, Wendy Chapman, Joycelyn Ling, Sam Georgy, David Bevan</dc:creator>
    </item>
    <item>
      <title>Learning to Car-Follow Using an Inertia-Oriented Driving Technique: A Before-and-After Study on a Closed Circuit</title>
      <link>https://arxiv.org/abs/2512.13694</link>
      <description>arXiv:2512.13694v1 Announce Type: cross 
Abstract: For decades, car following and traffic flow models have assumed that drivers default driving strategy is to maintain a safe distance. Several previous studies have questioned whether the Driving to Keep Distance is a traffic invariant. Therefore, the acceleration deceleration torque asymmetry of drivers must necessarily determine the observed patterns of traffic oscillations. Those studies indicate that drivers can adopt alternative CF strategies, such as Driving to Keep Inertia, by following basic instructions. The present work extends the evidence from previous research by showing the effectiveness of a DI course that immediately translates into practice on a closed circuit. Twelve drivers were invited to follow a lead car that varied its speed on a real circuit. Then, the driver took a DI course and returned to the same real car following scenario. Drivers generally adopted DD as the default CF mode in the pretest, both in field and simulated PC conditions, yielding very similar results. After taking the full DI course, drivers showed significantly less acceleration, deceleration, and speed variability than did the pretest, both in the field and in the simulated conditions, which indicates that drivers adopted the DI strategy. This study is the first to show the potential of adopting a DI strategy in a real circuit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13694v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <category>cs.RO</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kostantinos Mattas, Antonio Lucas-Alba, Tomer Toledo, Oscar M. Melchor, Shlomo Bekhor, Biagio Ciuffo</dc:creator>
    </item>
    <item>
      <title>Juicy Text: Onomatopoeia and Semantic Text Effects for Juicy Player Experiences</title>
      <link>https://arxiv.org/abs/2512.13695</link>
      <description>arXiv:2512.13695v1 Announce Type: cross 
Abstract: Juiciness is visual pizzazz used to improve player experience and engagement in games. Most research has focused on juicy particle effects. However, text effects are also commonly used in games, albeit not always juiced up. One type is onomatopoeia, a well-defined element of human language that has been translated to visual media, such as comic books and games. Another is semantic text, often used to provide performance feedback in games. In this work, we explored the relationship between juiciness and text effects, aiming to replicate juicy user experiences with text-based juice and combining particle and text juice. We show in a multi-phase within-subjects experiment that users rate juicy text effects similarly to particles effects, with comparable performance, and more reliable feedback. We also hint at potential improvement in user experience when both are combined, and how text stimuli may be perceived differently than other visual ones. We contribute empirical findings on the juicy-text connection in the context of visual effects for interactive media.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13695v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3678957.3685755</arxiv:DOI>
      <arxiv:journal_reference>ICMI 2024</arxiv:journal_reference>
      <dc:creator>\'Emilie Fabre, Katie Seaborn, Adrien Alexandre Verhulst, Yuta Itoh, Jun Rekimoto</dc:creator>
    </item>
    <item>
      <title>The Impact Market to Save Conference Peer Review: Decoupling Dissemination and Credentialing</title>
      <link>https://arxiv.org/abs/2512.14104</link>
      <description>arXiv:2512.14104v1 Announce Type: cross 
Abstract: Top-tier academic conferences are failing under the strain of two irreconcilable roles: (1) rapid dissemination of all sound research and (2) scarce credentialing for prestige and career advancement. This conflict has created a reviewer roulette and anonymous tribunal model - a zero-cost attack system - characterized by high-stakes subjectivity, turf wars, and the arbitrary rejection of sound research (the equivalence class problem). We propose the Impact Market (IM), a novel three-phase system that decouples publication from prestige. Phase 1 (Publication): All sound and rigorous papers are accepted via a PC review, solving the "equivalence class" problem. Phase 2 (Investment): An immediate, scarce prestige signal is created via a futures market. Senior community members invest tokens into published papers, creating a transparent, crowdsourced Net Invested Score (NIS). Phase 3 (Calibration): A 3-year lookback mechanism validates these investments against a manipulation-resistant Multi-Vector Impact Score (MVIS). This MVIS adjusts each investor's future influence (their Investor Rating), imposing a quantifiable cost on bad actors and rewarding accurate speculation. The IM model replaces a hidden, zero-cost attack system with a transparent, accountable, and data-driven market that aligns immediate credentialing with long-term, validated impact. Agent-based simulations demonstrate that while a passive market matches current protocols in low-skill environments, introducing investor agency and conviction betting increases the retrieval of high-impact papers from 28% to over 85% under identical conditions, confirming that incentivized self-selection is the mechanism required to scale peer review.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14104v1</guid>
      <category>cs.GT</category>
      <category>cs.AR</category>
      <category>cs.CY</category>
      <category>cs.PL</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karthikeyan Sankaralingam</dc:creator>
    </item>
    <item>
      <title>Semantic Mismatch and Perceptual Degradation: A New Perspective on Image Editing Immunity</title>
      <link>https://arxiv.org/abs/2512.14320</link>
      <description>arXiv:2512.14320v1 Announce Type: cross 
Abstract: Text-guided image editing via diffusion models, while powerful, raises significant concerns about misuse, motivating efforts to immunize images against unauthorized edits using imperceptible perturbations. Prevailing metrics for evaluating immunization success typically rely on measuring the visual dissimilarity between the output generated from a protected image and a reference output generated from the unprotected original. This approach fundamentally overlooks the core requirement of image immunization, which is to disrupt semantic alignment with attacker intent, regardless of deviation from any specific output. We argue that immunization success should instead be defined by the edited output either semantically mismatching the prompt or suffering substantial perceptual degradations, both of which thwart malicious intent. To operationalize this principle, we propose Synergistic Intermediate Feature Manipulation (SIFM), a method that strategically perturbs intermediate diffusion features through dual synergistic objectives: (1) maximizing feature divergence from the original edit trajectory to disrupt semantic alignment with the expected edit, and (2) minimizing feature norms to induce perceptual degradations. Furthermore, we introduce the Immunization Success Rate (ISR), a novel metric designed to rigorously quantify true immunization efficacy for the first time. ISR quantifies the proportion of edits where immunization induces either semantic failure relative to the prompt or significant perceptual degradations, assessed via Multimodal Large Language Models (MLLMs). Extensive experiments show our SIFM achieves the state-of-the-art performance for safeguarding visual content against malicious diffusion-based manipulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14320v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuai Dong, Jie Zhang, Guoying Zhao, Shiguang Shan, Xilin Chen</dc:creator>
    </item>
    <item>
      <title>Dual Attention Guided Defense Against Malicious Edits</title>
      <link>https://arxiv.org/abs/2512.14333</link>
      <description>arXiv:2512.14333v1 Announce Type: cross 
Abstract: Recent progress in text-to-image diffusion models has transformed image editing via text prompts, yet this also introduces significant ethical challenges from potential misuse in creating deceptive or harmful content. While current defenses seek to mitigate this risk by embedding imperceptible perturbations, their effectiveness is limited against malicious tampering. To address this issue, we propose a Dual Attention-Guided Noise Perturbation (DANP) immunization method that adds imperceptible perturbations to disrupt the model's semantic understanding and generation process. DANP functions over multiple timesteps to manipulate both cross-attention maps and the noise prediction process, using a dynamic threshold to generate masks that identify text-relevant and irrelevant regions. It then reduces attention in relevant areas while increasing it in irrelevant ones, thereby misguides the edit towards incorrect regions and preserves the intended targets. Additionally, our method maximizes the discrepancy between the injected noise and the model's predicted noise to further interfere with the generation. By targeting both attention and noise prediction mechanisms, DANP exhibits impressive immunity against malicious edits, and extensive experiments confirm that our method achieves state-of-the-art performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14333v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jie Zhang, Shuai Dong, Shiguang Shan, Xilin Chen</dc:creator>
    </item>
    <item>
      <title>Towards Transferable Defense Against Malicious Image Edits</title>
      <link>https://arxiv.org/abs/2512.14341</link>
      <description>arXiv:2512.14341v1 Announce Type: cross 
Abstract: Recent approaches employing imperceptible perturbations in input images have demonstrated promising potential to counter malicious manipulations in diffusion-based image editing systems. However, existing methods suffer from limited transferability in cross-model evaluations. To address this, we propose Transferable Defense Against Malicious Image Edits (TDAE), a novel bimodal framework that enhances image immunity against malicious edits through coordinated image-text optimization. Specifically, at the visual defense level, we introduce FlatGrad Defense Mechanism (FDM), which incorporates gradient regularization into the adversarial objective. By explicitly steering the perturbations toward flat minima, FDM amplifies immune robustness against unseen editing models. For textual enhancement protection, we propose an adversarial optimization paradigm named Dynamic Prompt Defense (DPD), which periodically refines text embeddings to align the editing outcomes of immunized images with those of the original images, then updates the images under optimized embeddings. Through iterative adversarial updates to diverse embeddings, DPD enforces the generation of immunized images that seek a broader set of immunity-enhancing features, thereby achieving cross-model transferability. Extensive experimental results demonstrate that our TDAE achieves state-of-the-art performance in mitigating malicious edits under both intra- and cross-model evaluations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14341v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jie Zhang, Shuai Dong, Shiguang Shan, Xilin Chen</dc:creator>
    </item>
    <item>
      <title>"Talking past each other": Issue ownership and microtargeting in Swiss online political ads</title>
      <link>https://arxiv.org/abs/2512.14564</link>
      <description>arXiv:2512.14564v1 Announce Type: cross 
Abstract: Switzerland's unique system of direct democracy, characterized by frequent popular referenda, provides a critical context for studying the impact of online political advertising beyond standard electoral cycles. This paper presents a large-scale, data-driven analysis of 40k political ads published on Facebook and Instagram in Switzerland between 2021 and 2025. Despite a voting population of only 5.6 million, the ad campaigns were significant in scale, costing CHF 4.5 million and achieving 560 million impressions. This study shows that political ads are used not only for federal elections, but also to influence referenda, where greater exposure to ``pro-Yes'' advertising correlates significantly with approval outcomes. The analysis of microtargeting reveals distinct partisan strategies: centrist and right-wing parties predominantly target older men, whereas left-wing parties focus on young women. Furthermore, significant region-specific demographic variations are observed even within the same party, reflecting Switzerland's strong territorial divisions. Regarding content, a clear pattern of ``talking past each other'' is identified: in line with issue ownership theory, parties avoid direct debate on shared issues, preferring to promote exclusively owned topics. Finally, it is demonstrated that these strategies are so distinct that an ad's author can be predicted using a machine learning model trained exclusively on its audience and topic features. This study sheds light on how microtargeting and issue divergence on social platforms may fragment the public sphere and bypass traditional democratic deliberation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14564v1</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arthur Capozzi</dc:creator>
    </item>
    <item>
      <title>CiRL: Open-Source Environments for Reinforcement Learning in Circular Economy and Net Zero</title>
      <link>https://arxiv.org/abs/2505.21536</link>
      <description>arXiv:2505.21536v2 Announce Type: replace 
Abstract: The demand of finite raw materials will keep increasing as they fuel modern society. Simultaneously, solutions for stopping carbon emissions in the short term are not available, thus making the net zero target extremely challenging to achieve at scale. The circular economy (CE) paradigm is gaining attention as a solution to address climate change and the uncertainties of supplies of critical materials. Hence, in this paper, we introduce CiRL, a deep reinforcement learning (DRL) library of environments focused on the circularity control of both solid and fluid materials. The integration of DRL into the design of material circularity is possible thanks to the formalism of thermodynamical material networks, which is underpinned by compartmental dynamical thermodynamics. Along with the focus on circularity, this library has three more features: the new CE-oriented environments are in the state-space form, which is typically used in dynamical systems analysis and control design; it is based on a state-of-the-art Python library of DRL algorithms, namely, Stable-Baselines3; and it is developed in Google Colaboratory to be accessible to researchers from different disciplines and backgrounds as is often the case for circular economy researchers and engineers. CiRL is intended to be a tool to generate AI-driven actions for optimizing the circularity of supply-recovery chains and to be combined with human-driven decisions derived from material flow analysis (MFA) studies. CiRL is publicly available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21536v2</guid>
      <category>cs.CY</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Federico Zocco, Andrea Corti, Monica Malvezzi</dc:creator>
    </item>
    <item>
      <title>Resistance Technologies: Moving Beyond Alternative Designs</title>
      <link>https://arxiv.org/abs/2508.05223</link>
      <description>arXiv:2508.05223v2 Announce Type: replace 
Abstract: The discourse about sustainable technology has emerged from the acknowledgment of the environmental collapse we are facing. In this paper, we argue that addressing this crisis requires more than the development of sustainable alternatives to current online services or the optimization of resources using various dashboards and AI. Rather, the focus must shift toward designing technologies that protect us from the consequences of the environmental damages. Among these consequences, wars, genocide and new forms of colonialism are perhaps the most significant. We identify "protection" not in terms of military defense as Western States like to argue, but as part of sovereignty. We seek to define the term of "Resistance Technologies" for such technologies, arguing further that anti-surveillance technologies are a foundational component of sovereignty and must be part of future conversations around sustainability. Finally, our paper seeks to open a discourse with the Computing-within-Limits community and beyond, towards defining other essential aspects or concepts of technologies that we see as core values of "Resistance Technology".</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05223v2</guid>
      <category>cs.CY</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Iness Ben Guirat, Jan Tobias Muehlberg</dc:creator>
    </item>
    <item>
      <title>FLARE v2: A Recursive Framework for Program Comprehension Across Common Teaching Languages and Levels of Abstraction</title>
      <link>https://arxiv.org/abs/2512.09261</link>
      <description>arXiv:2512.09261v2 Announce Type: replace 
Abstract: Building on the classroom framework in Heath et al. (2025), this paper proposes FLARE v2 as a recursive, semiotically informed account of how program meaning can be described across abstraction scales in common teaching languages. It reframes FLARE v1's tiers as one cycle: identify bounded elements (Receives, Sends, Effects, Shares), analyse bindings along two dimensions (Causal-Temporal and Communicative), and treat the bound set as a new element at the next scale. Causal-Temporal binding has three subtypes - Sequential, Branch, and Event - to distinguish user-authored control flow from event-driven control whose dispatch is hidden in the runtime. A Compositional Ladder visualises the same compositional move from blocks and statements through segments and systems.
  FLARE v2 is scoped to imperative and event-driven environments typical of primary and lower-secondary curricula. Above the system layer, behaviour is increasingly shaped by interaction between code and operating context (scheduling, infrastructure, permissions, contracts, failures, platform policy). Here, the element-and-binding vocabulary remains a structural baseline, but continuity of explanation typically requires overlays that make environmental constraints explicit. Event binding and overlays serve a common pedagogical role - preserving coherent structural reasoning where key causal mechanisms are not fully visible in the authored artefact. OOP design reasoning, explicit concurrency models, distributed systems, and functional paradigms are treated as future extensions; implementation and evaluation are left for future work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09261v2</guid>
      <category>cs.CY</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Justin Heath</dc:creator>
    </item>
    <item>
      <title>Assessing Greenspace Attractiveness with ChatGPT, Claude, and Gemini: Do AI Models Reflect Human Perceptions?</title>
      <link>https://arxiv.org/abs/2512.11827</link>
      <description>arXiv:2512.11827v2 Announce Type: replace 
Abstract: Understanding greenspace attractiveness is essential for designing livable and inclusive urban environments, yet existing assessment approaches often overlook informal or transient spaces and remain too resource intensive to capture subjective perceptions at scale. This study examines the ability of multimodal large language models (MLLMs), ChatGPT GPT-4o, Claude 3.5 Haiku, and Gemini 2.0 Flash, to assess greenspace attractiveness similarly to humans using Google Street View imagery. We compared model outputs with responses from a geo-questionnaire of residents in Lodz, Poland, across both formal (for example, parks and managed greenspaces) and informal (for example, meadows and wastelands) greenspaces. Survey respondents and models indicated whether each greenspace was attractive or unattractive and provided up to three free text explanations. Analyses examined how often their attractiveness judgments aligned and compared their explanations after classifying them into shared reasoning categories. Results show high AI human agreement for attractive formal greenspaces and unattractive informal spaces, but low alignment for attractive informal and unattractive formal greenspaces. Models consistently emphasized aesthetic and design oriented features, underrepresenting safety, functional infrastructure, and locally embedded qualities valued by survey respondents. While these findings highlight the potential for scalable pre-assessment, they also underscore the need for human oversight and complementary participatory approaches. We conclude that MLLMs can support, but not replace, context sensitive greenspace evaluation in planning practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11827v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Milad Malekzadeh, Magdalena Biernacka, Elias Willberg, Jussi Torkko, Edyta {\L}aszkiewicz, Tuuli Toivonen</dc:creator>
    </item>
    <item>
      <title>The Memecoin Phenomenon: An In-Depth Study of Solana's Blockchain Trends</title>
      <link>https://arxiv.org/abs/2512.11850</link>
      <description>arXiv:2512.11850v2 Announce Type: replace 
Abstract: This paper analyzes the emerging memecoin phenomenon on the Solana blockchain, focusing on the Pump$.$fun platform during Q4 2024. Using on-chain data, it is explored how retail-focused token creation platforms are reshaping blockchain ecosystems and influencing market participation. This study finds that Pump$.$fun accounted for up to 71.1% of all tokens minted on Solana and contributed 40-67.4% of total DEX transactions. Despite this activity, fewer than 2% of tokens successfully transitioned to major decentralized exchanges, highlighting a highly speculative market structure. The platform experienced rapid growth, with daily active users rising from 60,000 to peaks of 260,000, underscoring strong retail adoption. This reflects a broader shift towards accessible, socially-driven market participation enabled by memecoins. However, while memecoins lower entry barriers and encourage retail engagement, they introduce significant risks. The volatile and speculative nature of these platforms raises concerns about long-term sustainability and the resilience of the blockchain ecosystem. These findings reveal the dual impact of memecoins: they democratize token creation and alter market dynamics but may jeopardize market efficiency and stability. This paper highlights the need to critically assess the implications of retail-driven speculative trading and its potential to disrupt emerging blockchain economies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11850v2</guid>
      <category>cs.CY</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Davide Mancino</dc:creator>
    </item>
    <item>
      <title>Using Socio-economic Indicators, Smart Transit Systems, and Urban Simulator to Accelerate ZEV Adoption and Reduce VMT</title>
      <link>https://arxiv.org/abs/2512.11870</link>
      <description>arXiv:2512.11870v2 Announce Type: replace 
Abstract: Globally, on-road transportation accounts for 15% of greenhouse gas (GHG) emissions and an estimated 385,000 premature deaths from PM2.5. Cities play a critical role in meeting IPCC targets, generating 75% of global energy-related GHG emissions. In Houston, Texas, on-road transportation represents 48% of baseline emissions in the Climate Action Plan (CAP). To reach net-zero by 2050, the CAP targets a 70% emissions reduction from a 2014 baseline, offset by 30% renewable energy. This goal is challenging because Houston is low-density and auto-dependent, with 89% of on-road emissions from cars and small trucks and limited public transit usage. Socio-economic disparities further constrain Zero Emissions Vehicle (ZEV) adoption. Strategies focus on expanding ZEV access and reducing Vehicle Miles Traveled (VMT) by 20% through transit improvements and city design. This paper presents methods for establishing an on-road emissions baseline and evaluating policies that leverage socio-economic indicators and Intelligent Transportation Systems (ITS) to accelerate ZEV adoption and reduce VMT. Smart parking, transit incentives, secure data systems, and ZEV fleet management support improvements in modal split and system reliability. Policy options are analyzed and potential actions identified. To support evaluation, a simulation environment was developed in Unity 3D, enabling dynamic modeling of urban mobility and visualization of policy scenarios. Auto-dependent cities aiming for 2050 emission targets can benefit from the indicators, metrics, and technologies discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11870v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mulham Fawakherji, Bruce Race, Driss Benhaddou</dc:creator>
    </item>
    <item>
      <title>Decoding Emotional Trajectories: A Temporal-Semantic Network Approach for Latent Depression Assessment in Social Media</title>
      <link>https://arxiv.org/abs/2305.13127</link>
      <description>arXiv:2305.13127v3 Announce Type: replace-cross 
Abstract: The early identification and intervention of latent depression are of significant societal importance for mental health governance. While current automated detection methods based on social media have shown progress, their decision-making processes often lack a clinically interpretable framework, particularly in capturing the duration and dynamic evolution of depressive symptoms. To address this, this study introduces a semantic parsing network integrated with multi-scale temporal prototype learning. The model detects depressive states by capturing temporal patterns and semantic prototypes in users' emotional expression, providing a duration-aware interpretation of underlying symptoms. Validated on a large-scale social media dataset, the model outperforms existing state-of-the-art methods. Analytical results indicate that the model can identify emotional expression patterns not systematically documented in traditional survey-based approaches, such as sustained narratives expressing admiration for an "alternative life." Further user evaluation demonstrates the model's superior interpretability compared to baseline methods. This research contributes a structurally transparent, clinically aligned framework for depression detection in social media to the information systems literature. In practice, the model can generate dynamic emotional profiles for social platform users, assisting in the targeted allocation of mental health support resources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.13127v3</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Junwei Kuang, Jiaheng Xie, Zhijun Yan</dc:creator>
    </item>
    <item>
      <title>Transparent Networks for Multivariate Time Series</title>
      <link>https://arxiv.org/abs/2410.10535</link>
      <description>arXiv:2410.10535v3 Announce Type: replace-cross 
Abstract: Transparent models, which provide inherently interpretable predictions, are receiving significant attention in high-stakes domains. However, despite much real-world data being collected as time series, there is a lack of studies on transparent time series models. To address this gap, we propose a novel transparent neural network model for time series called Generalized Additive Time Series Model (GATSM). GATSM consists of two parts: 1) independent feature networks to learn feature representations, and 2) a transparent temporal module to learn temporal patterns across different time steps using the feature representations. This structure allows GATSM to effectively capture temporal patterns and handle varying-length time series while preserving transparency. Empirical experiments show that GATSM significantly outperforms existing generalized additive models and achieves comparable performance to black-box time series models, such as recurrent neural networks and Transformer. In addition, we demonstrate that GATSM finds interesting patterns in time series.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10535v3</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Minkyu Kim, Suan Lee, Jinho Kim</dc:creator>
    </item>
    <item>
      <title>Optimizing Large Language Models for ESG Activity Detection in Financial Texts</title>
      <link>https://arxiv.org/abs/2502.21112</link>
      <description>arXiv:2502.21112v2 Announce Type: replace-cross 
Abstract: The integration of Environmental, Social, and Governance (ESG) factors into corporate decision-making is a fundamental aspect of sustainable finance. However, ensuring that business practices align with evolving regulatory frameworks remains a persistent challenge. AI-driven solutions for automatically assessing the alignment of sustainability reports and non-financial disclosures with specific ESG activities could greatly support this process. Yet, this task remains complex due to the limitations of general-purpose Large Language Models (LLMs) in domain-specific contexts and the scarcity of structured, high-quality datasets. In this paper, we investigate the ability of current-generation LLMs to identify text related to environmental activities. Furthermore, we demonstrate that their performance can be significantly enhanced through fine-tuning on a combination of original and synthetically generated data. To this end, we introduce ESG-Activities, a benchmark dataset containing 1,325 labelled text segments classified according to the EU ESG taxonomy. Our experimental results show that fine-tuning on ESG-Activities significantly enhances classification accuracy, with open models such as Llama 7B and Gemma 7B outperforming large proprietary solutions in specific configurations. These findings have important implications for financial analysts, policymakers, and AI researchers seeking to enhance ESG transparency and compliance through advanced natural language processing techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.21112v2</guid>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.IR</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3768292.3770371</arxiv:DOI>
      <arxiv:journal_reference>Proceedings of the ACM International Conference on AI in Finance (ICAIF), 2024, ACM</arxiv:journal_reference>
      <dc:creator>Mattia Birti, Andrea Maurino, Francesco Osborne</dc:creator>
    </item>
    <item>
      <title>One Size Fits None: A Personalized Framework for Urban Accessibility Using Exponential Decay</title>
      <link>https://arxiv.org/abs/2512.08941</link>
      <description>arXiv:2512.08941v2 Announce Type: replace-cross 
Abstract: This study develops a personalized accessibility framework that integrates exponential decay functions with user-customizable weighting systems. The framework enables real-time, personalized urban evaluation based on individual priorities and lifestyle requirements. The methodology employs grid-based discretization and a two-stage computational architecture that separates intensive preprocessing from lightweight real-time calculations. The computational architecture demonstrates that accessibility modelling can be made accessible to non-technical users through interactive interfaces, enabling fine-grained spatial analysis and identification of accessibility variations within neighbourhoods. The research contributes to Sustainable Development Goal 11's vision of inclusive, sustainable cities by providing tools for understanding how different populations experience identical urban spaces, supporting evidence-based policy development that addresses accessibility gaps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.08941v2</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Prabhanjana Ghuriki, S. Chanti</dc:creator>
    </item>
    <item>
      <title>Enhancing Geo-localization for Crowdsourced Flood Imagery via LLM-Guided Attention</title>
      <link>https://arxiv.org/abs/2512.11811</link>
      <description>arXiv:2512.11811v2 Announce Type: replace-cross 
Abstract: Crowdsourced street-view imagery from social media provides real-time visual evidence of urban flooding and other crisis events, yet it often lacks reliable geographic metadata for emergency response. Existing image geo-localization approaches, also known as Visual Place Recognition (VPR) models, exhibit substantial performance degradation when applied to such imagery due to visual distortions and domain shifts in cross-source scenarios. This paper presents VPR-AttLLM, a model-agnostic framework that integrates the semantic reasoning and geo-knowledge of Large Language Models (LLMs) into established VPR pipelines through attention-guided descriptor enhancement. By leveraging LLMs to identify location-informative regions within the city context and suppress visual noise, VPR-AttLLM improves retrieval performance without requiring model retraining or additional data. Comprehensive evaluations are conducted on extended benchmarks including SF-XL enriched with real social-media flood images, synthetic flooding scenarios over established query sets and Mapillary photos, and a new HK-URBAN dataset capturing morphologically distinct cityscapes. Integrating VPR-AttLLM with three state-of-the-art VPR models-CosPlace, EigenPlaces, and SALAD-consistently improves recall performance, yielding relative gains typically between 1-3% and reaching up to 8% on the most challenging real flood imagery. Beyond measurable gains in retrieval accuracy, this study establishes a generalizable paradigm for LLM-guided multimodal fusion in visual retrieval systems. By embedding principles from urban perception theory into attention mechanisms, VPR-AttLLM bridges human-like spatial reasoning with modern VPR architectures. Its plug-and-play design, strong cross-source robustness, and interpretability highlight its potential for scalable urban monitoring and rapid geo-localization of crowdsourced crisis imagery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11811v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.CY</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fengyi Xu, Jun Ma, Waishan Qiu, Cui Guo, Jack C. P. Cheng</dc:creator>
    </item>
  </channel>
</rss>
