<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DC</link>
    <description>cs.DC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 25 Jul 2024 04:00:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 25 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Inference Load-Aware Orchestration for Hierarchical Federated Learning</title>
      <link>https://arxiv.org/abs/2407.16836</link>
      <description>arXiv:2407.16836v1 Announce Type: new 
Abstract: Hierarchical federated learning (HFL) designs introduce intermediate aggregator nodes between clients and the global federated learning server in order to reduce communication costs and distribute server load. One side effect is that machine learning model replication at scale comes "for free" as part of the HFL process: model replicas are hosted at the client end, intermediate nodes, and the global server level and are readily available for serving inference requests. This creates opportunities for efficient model serving but simultaneously couples the training and serving processes and calls for their joint orchestration. This is particularly important for continual learning, where serving a model while (re)training it periodically, upon specific triggers, or continuously, takes place over shared infrastructure spanning the computing continuum. Consequently, training and inference workloads can interfere with detrimental effects on performance. To address this issue, we propose an inference load-aware HFL orchestration scheme, which makes informed decisions on HFL configuration, considering knowledge about inference workloads and the respective processing capacity. Applying our scheme to a continual learning use case in the transportation domain, we demonstrate that by optimizing aggregator node placement and device-aggregator association, significant inference latency savings can be achieved while communication costs are drastically reduced compared to flat centralized federated learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16836v1</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anna Lackinger, Pantelis A. Frangoudis, Ivan \v{C}ili\'c, Alireza Furutanpey, Ilir Murturi, Ivana Podnar \v{Z}arko, Schahram Dustdar</dc:creator>
    </item>
    <item>
      <title>Software Defined Vehicles for Development of Deterministic Services</title>
      <link>https://arxiv.org/abs/2407.17287</link>
      <description>arXiv:2407.17287v1 Announce Type: new 
Abstract: With modern vehicles evolving with more features, services, complex systems, with more sensors, actuators, and processing units, it is essential to think about vehicles not only as means of transportation that may tend towards full autonomy, but also as adaptive objects, that suit themselves to the needs of occupants. Vehicular services can be developed to support these adaptations. However, the increasing complexity of vehicular service development, even with current standardizations and best practices and guidelines, are insufficient to tackle the high complexity of development, with expectations of up to 1 (U.S.) billion lines of code for a fully (level 5) autonomous vehicle. Within this survey, the paradigm of Deterministic Software Defined Vehicles is explored towards increasing the quality and easiness of the development of services for automotive. Towards this, a proposed vision with four pillars is also provided: the deterministic network configurator, the data layer configurator, and the hypervisor configurator and the vehicle abstraction layer, all coordinated by a software orchestrator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17287v1</guid>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pedro Veloso Teixeira, Duarte Raposo, Rui Lopes, Susana Sargento</dc:creator>
    </item>
    <item>
      <title>Edge-Cloud Continuum Orchestration of Critical Services: A Smart-City Approach</title>
      <link>https://arxiv.org/abs/2407.17314</link>
      <description>arXiv:2407.17314v1 Announce Type: new 
Abstract: Smart-city services are typically developed as closed systems within each city's vertical, communicating and interacting with cloud services while remaining isolated within each provider's domain. With the emergence of 5G private domains and the introduction of new M2M services focusing on autonomous systems, there is a shift from the cloud-based approach to a distributed edge computing paradigm, in a \textit{continuum} orchestration. However, an essential component is missing. Current orchestration tools, designed for cloud-based deployments, lack robust workload isolation, fail to meet timing constraints, and are not tailored to the resource-constrained nature of edge devices. Therefore, new orchestration methods are needed to support MEC environments. The work presented in this paper addresses this gap. Based on the real needs of a smart-city testbed - the Aveiro Living Lab-, we developed a set of orchestration components to facilitate the seamless orchestration of both cloud and edge-based services, encompassing both critical and non-critical services. This work extends the current Kubernetes orchestration platform to include a novel location-specific resource definition, a custom scheduler to accommodate real-time and legacy services, continuous service monitoring to detect sub-optimal states, and a refined load balancing mechanism that prioritizes the fastest response times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17314v1</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rodrigo Rosmaninho, Duarte Raposo, Pedro Rito, Susana Sargento</dc:creator>
    </item>
    <item>
      <title>Lossy Data Compression By Adaptive Mesh Coarsening</title>
      <link>https://arxiv.org/abs/2407.17316</link>
      <description>arXiv:2407.17316v1 Announce Type: new 
Abstract: Today's scientific simulations, for example in the high-performance exascale sector, produce huge amounts of data. Due to limited I/O bandwidth and available storage space, there is the necessity to reduce scientific data of high performance computing applications. Error-bounded lossy compression has been proven to be an effective approach tackling the trade-off between accuracy and storage space. Within this work, we are exploring and discussing error-bounded lossy compression solely based on adaptive mesh refinement techniques. This compression technique is not only easily integrated into existing adaptive mesh refinement applications but also suits as a general lossy compression approach for arbitrary data in form of multi-dimensional arrays, irrespective of the data type. Moreover, these techniques permit the exclusion of regions of interest and even allows for nested error domains during the compression. The described data compression technique is presented exemplary on ERA5 data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17316v1</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>N. B\"oing, J. Holke, C. Hergl, L. Spataro, G. Gassner, A. Basermann</dc:creator>
    </item>
    <item>
      <title>Tutorial: Object as a Service (OaaS) Serverless Cloud Computing Paradigm</title>
      <link>https://arxiv.org/abs/2407.17391</link>
      <description>arXiv:2407.17391v1 Announce Type: new 
Abstract: While the first generation of cloud computing systems mitigated the job of system administrators, the next generation of cloud computing systems is emerging to mitigate the burden for cloud developers -- facilitating the development of cloud-native applications. This paradigm shift is primarily happening by offering higher-level serverless abstractions, such as Function as a Service (FaaS). Although FaaS has successfully abstracted developers from the cloud resource management details, it falls short in abstracting the management of both data (i.e., state) and the non-functional aspects, such as Quality of Service (QoS) requirements. The lack of such abstractions implies developer intervention and is counterproductive to the objective of mitigating the burden of cloud-native application development. To further streamline cloud-native application development, we present Object-as-a-Service (OaaS) -- a serverless paradigm that borrows the object-oriented programming concepts to encapsulate application logic and data in addition to non-functional requirements into a single deployment package, thereby streamlining provider-agnostic cloud-native application development. We realized the OaaS paradigm through the development of an open-source platform called Oparaca. In this tutorial, we will present the concept and design of the OaaS paradigm and its implementation -- the Oparaca platform. Then, we give a tutorial on developing and deploying the application on the Oparaca platform and discuss its benefits and its optimal configurations to avoid potential overheads.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17391v1</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Proceedings of the 44th International Conference on Distributed Computing Systems Workshops (ICDCSW), Jersey City, New Jersey, July 2024</arxiv:journal_reference>
      <dc:creator>Pawissanutt Lertpongrujikorn, Mohsen Amini Salehi</dc:creator>
    </item>
    <item>
      <title>Distributed Difference of Convex Optimization</title>
      <link>https://arxiv.org/abs/2407.16728</link>
      <description>arXiv:2407.16728v1 Announce Type: cross 
Abstract: In this article, we focus on solving a class of distributed optimization problems involving $n$ agents with the local objective function at every agent $i$ given by the difference of two convex functions $f_i$ and $g_i$ (difference-of-convex (DC) form), where $f_i$ and $g_i$ are potentially nonsmooth. The agents communicate via a directed graph containing $n$ nodes. We create smooth approximations of the functions $f_i$ and $g_i$ and develop a distributed algorithm utilizing the gradients of the smooth surrogates and a finite-time approximate consensus protocol. We term this algorithm as DDC-Consensus. The developed DDC-Consensus algorithm allows for non-symmetric directed graph topologies and can be synthesized distributively. We establish that the DDC-Consensus algorithm converges to a stationary point of the nonconvex distributed optimization problem. The performance of the DDC-Consensus algorithm is evaluated via a simulation study to solve a nonconvex DC-regularized distributed least squares problem. The numerical results corroborate the efficacy of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16728v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Vivek Khatana, Murti V. Salapaka</dc:creator>
    </item>
    <item>
      <title>Bridging Trust into the Blockchain: A Systematic Review on On-Chain Identity</title>
      <link>https://arxiv.org/abs/2407.17276</link>
      <description>arXiv:2407.17276v1 Announce Type: cross 
Abstract: The ongoing regulation of blockchain-based services and applications requires the identification of users who are issuing transactions on the blockchain. This systematic review explores the current status, identifies research gaps, and outlines future research directions for establishing trusted and privacy-compliant identities on the blockchain (on-chain identity). A systematic search term was applied across various scientific databases, collecting 2232 potentially relevant research papers. These papers were narrowed down in two methodologically executed steps to 98 and finally to 13 relevant sources. The relevant articles were then systematically analyzed based on a set of screening questions. The results of the selected studies have provided insightful findings on the mechanisms of on-chain identities. On-chain identities are established using zero-knowledge proofs, public key infrastructure/certificates, and web of trust approaches. The technologies and architectures used by the authors are also highlighted. Trust has emerged as a key research gap, manifesting in two ways: firstly, a gap in how to trust the digital identity representation of a physical human; secondly, a gap in how to trust identity providers that issue identity confirmations on-chain. Potential future research avenues are suggested to help fill the current gaps in establishing trust and on-chain identities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17276v1</guid>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <category>cs.DC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Awid Vaziry, Kaustabh Barman, Patrick Herbke</dc:creator>
    </item>
    <item>
      <title>Noise-Aware Distributed Quantum Approximate Optimization Algorithm on Near-term Quantum Hardware</title>
      <link>https://arxiv.org/abs/2407.17325</link>
      <description>arXiv:2407.17325v1 Announce Type: cross 
Abstract: This paper introduces a noise-aware distributed Quantum Approximate Optimization Algorithm (QAOA) tailored for execution on near-term quantum hardware. Leveraging a distributed framework, we address the limitations of current Noisy Intermediate-Scale Quantum (NISQ) devices, which are hindered by limited qubit counts and high error rates. Our approach decomposes large QAOA problems into smaller subproblems, distributing them across multiple Quantum Processing Units (QPUs) to enhance scalability and performance. The noise-aware strategy incorporates error mitigation techniques to optimize qubit fidelity and gate operations, ensuring reliable quantum computations. We evaluate the efficacy of our framework using the HamilToniQ Benchmarking Toolkit, which quantifies the performance across various quantum hardware configurations. The results demonstrate that our distributed QAOA framework achieves significant improvements in computational speed and accuracy, showcasing its potential to solve complex optimization problems efficiently in the NISQ era. This work sets the stage for advanced algorithmic strategies and practical quantum system enhancements, contributing to the broader goal of achieving quantum advantage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17325v1</guid>
      <category>quant-ph</category>
      <category>cs.DC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kuan-Cheng Chen, Xiatian Xu, Felix Burt, Chen-Yu Liu</dc:creator>
    </item>
    <item>
      <title>Scalable mRMR feature selection to handle high dimensional datasets: Vertical partitioning based Iterative MapReduce framework</title>
      <link>https://arxiv.org/abs/2208.09901</link>
      <description>arXiv:2208.09901v2 Announce Type: replace 
Abstract: While building machine learning models, Feature selection (FS) stands out as an essential preprocessing step used to handle the uncertainty and vagueness in the data. Recently, the minimum Redundancy and Maximum Relevance (mRMR) approach has proven to be effective in obtaining the irredundant feature subset. Owing to the generation of voluminous datasets, it is essential to design scalable solutions using distributed/parallel paradigms. MapReduce solutions are proven to be one of the best approaches to designing fault-tolerant and scalable solutions. This work analyses the existing MapReduce approaches for mRMR feature selection and identifies the limitations thereof. In the current study, we proposed VMR_mRMR, an efficient vertical partitioning-based approach using a memorization approach, thereby overcoming the extant approaches limitations. The experiment analysis says that VMR_mRMR significantly outperformed extant approaches and achieved a better computational gain (C.G). In addition, we also conducted a comparative analysis with the horizontal partitioning approach HMR_mRMR [1] to assess the strengths and limitations of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.09901v2</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yelleti Vivek, P. S. V. S. Sai Prasad</dc:creator>
    </item>
    <item>
      <title>Portable, heterogeneous ensemble workflows at scale using libEnsemble</title>
      <link>https://arxiv.org/abs/2403.03709</link>
      <description>arXiv:2403.03709v3 Announce Type: replace 
Abstract: libEnsemble is a Python-based toolkit for running dynamic ensembles, developed as part of the DOE Exascale Computing Project. The toolkit utilizes a unique generator--simulator--allocator paradigm, where generators produce input for simulators, simulators evaluate those inputs, and allocators decide whether and when a simulator or generator should be called. The generator steers the ensemble based on simulation results. Generators may, for example, apply methods for numerical optimization, machine learning, or statistical calibration. libEnsemble communicates between a manager and workers. We overview the unique characteristics of libEnsemble as well as current and potential interoperability with other packages in the workflow ecosystem. We highlight libEnsemble's dynamic resource features: libEnsemble can detect system resources, such as available nodes, cores, and GPUs, and assign these in a portable way. These features allow users to specify the number of processors and GPUs required for each simulation; and resources will be automatically assigned on a wide range of systems, including Frontier, Aurora, and Perlmutter. Such ensembles can include multiple simulation types, some using GPUs and others using only CPUs, sharing nodes for maximum efficiency. We also describe the benefits of libEnsemble's generator--simulator coupling, which easily exposes to the user the ability to cancel, and portably kill, running simulations based on models that are updated with intermediate simulation output. We demonstrate libEnsemble's capabilities, scalability, and scientific impact via a Gaussian process surrogate training problem for the longitudinal density profile at the exit of a plasma accelerator stage. The study uses gpCAM for the surrogate model and employs either Wake-T or WarpX simulations, highlighting efficient use of resources that can easily extend to exascale.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03709v3</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stephen Hudson, Jeffrey Larson, John-Luke Navarro, Stefan M. Wild</dc:creator>
    </item>
    <item>
      <title>Computational Power of Mobile Robots in Synchronous Environment: Discrete Version</title>
      <link>https://arxiv.org/abs/2407.05678</link>
      <description>arXiv:2407.05678v4 Announce Type: replace 
Abstract: In distributed computing by mobile robots, robots are deployed over a region, continuous or discrete, operating through a sequence of \textit{look-compute-move} cycles. An extensive study has been carried out to understand the computational powers of different robot models. The models vary on the ability to 1)~remember constant size information and 2)~communicate constant size message. Depending on the abilities the different models are 1)~$\mathcal{OBLOT}$ (robots are oblivious and silent), 2)~$\mathcal{FSTA}$ (robots have finite states but silent), 3)~$\mathcal{FCOM}$ (robots are oblivious but can communicate constant size information) and, 4)~$\mathcal{LUMI}$ (robots have finite states and can communicate constant size information). Another factor that affects computational ability is the scheduler that decides the activation time of the robots. The main three schedulers are \textit{fully-synchronous}, \textit{semi-synchronous} and \textit{asynchronous}. Combining the models ($M$) with schedulers ($K$), we have twelve combinations $M^K$.
  In the euclidean domain, the comparisons between these twelve variants have been done in different works for transparent robots, opaque robots, and robots with limited visibility. There is a vacant space for similar works when robots are operating on discrete regions like networks. It demands separate research attention because there have been a series of works where robots operate on different networks, and there is a fundamental difference when robots are operating on a continuous domain versus a discrete domain in terms of robots' movement. This work contributes to filling the space by giving a full comparison table for all models with two synchronous schedulers: fully-synchronous and semi-synchronous.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05678v4</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Avisek Sharma, Pritam Goswami, Buddhadeb Sau</dc:creator>
    </item>
    <item>
      <title>Proof-of-Collaborative-Learning: A Multi-winner Federated Learning Consensus Algorithm</title>
      <link>https://arxiv.org/abs/2407.13018</link>
      <description>arXiv:2407.13018v2 Announce Type: replace 
Abstract: Regardless of their variations, blockchains require a consensus mechanism to validate transactions, supervise added blocks, maintain network security, synchronize the network state, and distribute incentives. Proof-of-Work (PoW), one of the most influential implementations of consensus mechanisms, consumes an extraordinary amount of energy for a task that lacks direct productive output. In this paper, we propose Proof-of-Collaborative-Learning (PoCL), a multi-winner federated learning validated consensus mechanism that redirects the computation power of blockchains to train federated learning models. In addition, we present a novel evaluation mechanism to ensure the efficiency of the locally trained models of miners. We evaluated the security of our evaluation mechanism by introducing and conducting probable attacks. Moreover, we present a novel reward distribution mechanism to incentivize winning miners fairly, and demonstrate that our reward system is fair both within and across all rounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13018v2</guid>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amirreza Sokhankhosh, Sara Rouhani</dc:creator>
    </item>
    <item>
      <title>Refined Bitcoin Security-Latency Under Network Delay</title>
      <link>https://arxiv.org/abs/2212.01372</link>
      <description>arXiv:2212.01372v4 Announce Type: replace-cross 
Abstract: We study security-latency bounds for Nakamoto consensus, i.e., how secure a block is after it becomes $k$-deep in the chain. We improve the state-of-the-art bounds by analyzing the race between adversarial and honest chains in three different phases. We find the probability distribution of the growth of the adversarial chains under models similar to those in [Guo, Ren; AFT 2022] when a target block becomes $k$-deep in the chain. We analyze certain properties of this race to model each phase with random walks that provide tighter bounds than the existing results. Combining all three phases provides novel upper and lower bounds for blockchains with small $\lambda\Delta$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.01372v4</guid>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <category>cs.DM</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mustafa Doger, Sennur Ulukus</dc:creator>
    </item>
    <item>
      <title>Worst-Case Input Generation for Concurrent Programs under Non-Monotone Resource Metrics</title>
      <link>https://arxiv.org/abs/2309.01261</link>
      <description>arXiv:2309.01261v2 Announce Type: replace-cross 
Abstract: Worst-case input generation aims to automatically generate inputs that exhibit the worst-case performance of programs. It has several applications, and can, for example, detect vulnerabilities to denial-of-service attacks. However, it is non-trivial to generate worst-case inputs for concurrent programs, particularly for resources like memory where the peak cost depends on how processes are scheduled.
  This article presents the first sound worst-case input generation algorithm for concurrent programs under non-monotone resource metrics like memory. The key insight is to leverage resource-annotated session types and symbolic execution. Session types describe communication protocols on channels in process calculi. Equipped with resource annotations, resource-annotated session types not only encode cost bounds but also indicate how many resources can be reused and transferred between processes. This information is critical for identifying a worst-case execution path during symbolic execution. The algorithm is sound: if it returns any input, it is guaranteed to be a valid worst-case input. The algorithm is also relatively complete: as long as resource-annotated session types are sufficiently expressive and the background theory for SMT solving is decidable, a worst-case input is guaranteed to be returned. A simple case study of a web server's memory usage demonstrates the utility of the worst-case input generation algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.01261v2</guid>
      <category>cs.PL</category>
      <category>cs.DC</category>
      <category>cs.LO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Long Pham, Jan Hoffmann</dc:creator>
    </item>
    <item>
      <title>Causal Discovery over High-Dimensional Structured Hypothesis Spaces with Causal Graph Partitioning</title>
      <link>https://arxiv.org/abs/2406.06348</link>
      <description>arXiv:2406.06348v2 Announce Type: replace-cross 
Abstract: The aim in many sciences is to understand the mechanisms that underlie the observed distribution of variables, starting from a set of initial hypotheses. Causal discovery allows us to infer mechanisms as sets of cause and effect relationships in a generalized way -- without necessarily tailoring to a specific domain. Causal discovery algorithms search over a structured hypothesis space, defined by the set of directed acyclic graphs, to find the graph that best explains the data. For high-dimensional problems, however, this search becomes intractable and scalable algorithms for causal discovery are needed to bridge the gap. In this paper, we define a novel causal graph partition that allows for divide-and-conquer causal discovery with theoretical guarantees. We leverage the idea of a superstructure -- a set of learned or existing candidate hypotheses -- to partition the search space. We prove under certain assumptions that learning with a causal graph partition always yields the Markov Equivalence Class of the true causal graph. We show our algorithm achieves comparable accuracy and a faster time to solution for biologically-tuned synthetic networks and networks up to ${10^4}$ variables. This makes our method applicable to gene regulatory network inference and other domains with high-dimensional structured hypothesis spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06348v2</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ashka Shah, Adela DePavia, Nathaniel Hudson, Ian Foster, Rick Stevens</dc:creator>
    </item>
  </channel>
</rss>
