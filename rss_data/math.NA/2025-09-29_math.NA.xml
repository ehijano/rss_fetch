<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 30 Sep 2025 03:29:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Towards provable energy-stable overset grid methods using sub-cell summation-by-parts operators</title>
      <link>https://arxiv.org/abs/2509.21442</link>
      <description>arXiv:2509.21442v1 Announce Type: new 
Abstract: Overset grid methods handle complex geometries by overlapping simpler, geometry-fitted grids to cover the original, more complex domain. However, ensuring their stability -- particularly at high orders -- remains a practical and theoretical challenge. In this work, we address this gap by developing a discrete counterpart to the recent well-posedness analysis of Kopriva, Gassner, and Nordstr\"om for continuous overset domain initial-boundary-value problems. To this end, we introduce the novel concept of sub-cell summation-by-parts (SBP) operators. These discrete derivative operators mimic integration by parts at a sub-cell level. By exploiting this sub-cell SBP property, we develop provably conservative and energy-stable overset grid methods, thereby resolving longstanding stability issues in the field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21442v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jan Glaubitz, Joshua Lampert, Andrew R. Winters, Jan Nordstr\"om</dc:creator>
    </item>
    <item>
      <title>Conforming lifting and adjoint consistency for the Discrete de Rham complex of differential forms</title>
      <link>https://arxiv.org/abs/2509.21449</link>
      <description>arXiv:2509.21449v1 Announce Type: new 
Abstract: Discrete de Rham (DDR) methods provide non-conforming but compatible approximations of the continuous de Rham complex on general polytopal meshes. Owing to the non-conformity, several challenges arise in the analysis of these methods. In this work, we design conforming liftings on the DDR spaces, that are right-inverse of the interpolators and can be used to solve some of these challenges. We illustrate this by tackling the question of the global integration-by-part formula. By non-conformity of the discrete complex, this formula involves a residual -- which can be interpreted as a consistency error on the adjoint of the discrete exterior derivative -- on which we obtain, using the conforming lifting, an optimal bound in terms of the mesh size. Our analysis is carried out in the polytopal exterior calculus framework, which allows for unified proofs for all the spaces and operators in the DDR complex. Moreover, the liftings are explicitly constructed in finite element spaces on a simplicial submesh of the underlying polytopal mesh, which gives more control on the resulting functions (e.g., discrete trace and inverse inequalities).</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21449v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniele A. Di Pietro, J\'er\^ome Droniou, Silvano Pitassi</dc:creator>
    </item>
    <item>
      <title>Fast summation of Stokes potentials using a new kernel-splitting in the DMK framework</title>
      <link>https://arxiv.org/abs/2509.21471</link>
      <description>arXiv:2509.21471v1 Announce Type: new 
Abstract: Classical Ewald methods for Coulomb and Stokes interactions rely on ``kernel-splitting," using decompositions based on Gaussians to divide the resulting potential into a near field and a far field component. Here, we show that a more efficient splitting for the scalar biharmonic Green's function can be derived using zeroth-order prolate spheroidal wave functions (PSWFs), which in turn yields new efficient splittings for the Stokeslet, stresslet, and elastic kernels, since these Green's tensors can all be derived from the biharmonic kernel. This benefits all fast summation methods based on kernel splitting, including FFT-based Ewald summation methods, that are suitable for uniform point distributions, and DMK-based methods that allow for nonuniform point distributions. The DMK (dual-space multilevel kernel-splitting) algorithm we develop here is fast, adaptive, and linear-scaling, both in free space and in a periodic cube. We demonstrate its performance with numerical examples in two and three dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21471v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.flu-dyn</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ludvig af Klinteberg, Leslie Greengard, Shidong Jiang, Anna-Karin Tornberg</dc:creator>
    </item>
    <item>
      <title>An Adaptive CUR Algorithm and its Application to Reduced-Order Modeling of Random PDEs</title>
      <link>https://arxiv.org/abs/2509.21480</link>
      <description>arXiv:2509.21480v1 Announce Type: new 
Abstract: Certain classes of CUR algorithms, also referred to as cross or pseudoskeleton algorithms, are widely used for low-rank matrix approximation when direct access to all matrix entries is costly. Their key advantage lies in constructing a rank-r approximation by sampling only r columns and r rows of the target matrix. This property makes them particularly attractive for reduced-order modeling of nonlinear matrix differential equations, where nonlinear operations on low-rank matrices can otherwise produce high-rank or even full-rank intermediates that must subsequently be truncated to rank $r$. CUR cross algorithms bypass the intermediate step and directly form the rank-$r$ matrix. However, standard cross algorithms may suffer from loss of accuracy in some settings, limiting their robustness and broad applicability. In this work, we propose a cross oversampling algorithm that augments the intersection with additional sampled columns and rows. We provide an error analysis demonstrating that the proposed oversampling improves robustness. We also present an algorithm that adaptively selects the number of oversampling entries based on efficiently computable indicators. We demonstrate the performance of the proposed CUR algorithm for time integration of several nonlinear stochastic PDEs on low-rank matrix manifolds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21480v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Grishma Palkar, Hessam Babaee</dc:creator>
    </item>
    <item>
      <title>Micro-macro kinetic flux-vector splitting schemes for the multidimensional Boltzmann-ES-BGK equation</title>
      <link>https://arxiv.org/abs/2509.21832</link>
      <description>arXiv:2509.21832v1 Announce Type: new 
Abstract: The kinetic Boltzmann equation models gas dynamics over a wide range of spatial and temporal scales. Simplified versions of the full Boltzmann collision operator, such as the classical Bhatnagar-Gross-Krook and the closely related Ellipsoidal-Statistical-BGK operators, can dramatically decrease the computational costs of numerical solving kinetic equations. Classical BGK yields incorrect transport coefficients (relative to the full Boltzmann collision operator) at low Knudsen numbers, whereas ES-BGK captures them correctly. In this work, we develop a finite volume method using a micro-macro decomposition of the distribution function, which requires a smaller velocity mesh relative to direct kinetic methods for low and intermediate Knudsen numbers. The macro portion of the model is a fluid model with a moment closure provided from the heat flux tensor calculated from the micro portion. The micro portion is obtained by applying to the original kinetic equation a projector into the orthogonal complement of the null space of the collision operator - this projector depends on the macro portion. In particular, we extend the technique of Bennoune, Lemou, and Mieussens [Uniformly stable schemes for the Boltzmann equation preserving the compressible Navier-Stokes asymptotics, J. Comput. Phys. (2008)] to two-space dimensions, the ES-BGK collision operator, and problems with reflecting wall boundary conditions. As it appears in both the micro and macro equations, the collision operator is handled via L-stable implicit time discretizations. At the same time, the remaining transport terms are computed via kinetic flux vector splitting (for macro) and upwind differencing (for micro). The resulting scheme is applied to various test cases in 1D and 2D. The 2D version of the code is parallelized via MPI, and we present weak and strong scaling studies with varying numbers of processors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21832v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.flu-dyn</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James A. Rossmanith, Preeti Sar</dc:creator>
    </item>
    <item>
      <title>Fast Rank Adaptive CUR via a Recycled Small Sketch</title>
      <link>https://arxiv.org/abs/2509.21963</link>
      <description>arXiv:2509.21963v1 Announce Type: new 
Abstract: The computation of accurate low-rank matrix approximations is central to improving the scalability of various techniques in machine learning, uncertainty quantification, and control. Traditionally, low-rank approximations are constructed using SVD-based approaches such as truncated SVD or RandomizedSVD. Although these SVD approaches -- especially RandomizedSVD -- have proven to be very computationally efficient, other low-rank approximation methods can offer even greater performance. One such approach is the CUR decomposition, which forms a low-rank approximation using direct row and column subsets of a matrix. Because CUR uses direct matrix subsets, it is also often better able to preserve native matrix structures like sparsity or non-negativity than SVD-based approaches and can facilitate data interpretation in many contexts. This paper introduces IterativeCUR, which draws on previous work in randomized numerical linear algebra to build a new algorithm that is highly competitive compared to prior work: (1) It is adaptive in the sense that it takes as an input parameter the desired tolerance, rather than an a priori guess of the numerical rank. (2) It typically runs significantly faster than both existing CUR algorithms and techniques such as RandomizedSVD, in particular when these methods are run in an adaptive rank mode. Its asymptotic complexity is $\mathcal{O}(mn + (m+n)r^2 + r^3)$ for an $m\times n$ matrix of numerical rank $r$. (3) It relies on a single small sketch from the matrix that is successively downdated as the algorithm proceeds.
  We demonstrate through extensive experiments that IterativeCUR achieves up to $4\times$ speed-up over state-of-the-art pivoting-on-sketch approaches with no loss of accuracy, and up to $40\times$ speed-up over rank-adaptive randomized SVD approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21963v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>stat.CO</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nathaniel Pritchard, Taejun Park, Yuji Nakatsukasa, Per-Gunnar Martinsson</dc:creator>
    </item>
    <item>
      <title>A Parallel-in-Time Combination Method for Parabolic Problems</title>
      <link>https://arxiv.org/abs/2509.22156</link>
      <description>arXiv:2509.22156v1 Announce Type: new 
Abstract: In this article, we present a parallel discretization and solution method for parabolic problems with a higher number of space dimensions. It consists of a parallel-in-time approach using the multigrid reduction-in-time algorithm MGRIT with its implementation in the library XBraid, the sparse grid combination method for discretizing the resulting elliptic problems in space, and a domain decomposition method for each of the subproblems in the combination method based on the space-filling curve approach. As a result, we obtain an extremely fast and embarrassingly parallel solver with excellent speedup and scale-up qualities, which is perfectly suited for parabolic problems with up to six space dimensions. We describe our new parallel approach and show its superior parallelization properties for the heat equation, the chemical master equation and some exemplary stochastic differential equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22156v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Griebel, Marc Alexander Schweitzer, Lukas Troska</dc:creator>
    </item>
    <item>
      <title>Well-balanced high-order method for non-conservative hyperbolic PDEs with source terms: application to one-dimensional blood flow equations with gravity</title>
      <link>https://arxiv.org/abs/2509.22190</link>
      <description>arXiv:2509.22190v1 Announce Type: new 
Abstract: The present work proposes a well-balanced finite volume-type numerical method for the solution of non-conservative hyperbolic partial differential equations (PDEs) with source terms. The method is characterized, first, by the use of a recently introduced high-order spatial reconstruction, based on generalized Riemann problem information from the previous time level. Such reconstruction is well-balanced up to order three, compact, efficient and easy to implement. Second, the method incorporates a well-balanced space-time evolution operator, which allows for well-balanced fully explicit time evolution. The accuracy and efficiency of the method are assessed on both a scalar problem (Burgers' equation) and a nonlinear PDE system (hyperbolized one-dimensional blood flow equations with gravity and friction, and with variable mechanical and geometrical properties). The well-balanced property is verified by showing that numerically-determined stationary solutions are preserved up to machine precision. The order of accuracy in space and time is validated through empirical convergence rate studies. Additionally, the performance of the method is assessed on a network of 86 arteries, under both stationary and transient conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22190v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Chiara Colombo, Caterina Dalmaso, Lucas O. M\"uller, Annunziato Siviglia</dc:creator>
    </item>
    <item>
      <title>Square-Domain Area-Preserving Parameterization for Genus-Zero and Genus-One Closed Surfaces</title>
      <link>https://arxiv.org/abs/2509.22269</link>
      <description>arXiv:2509.22269v1 Announce Type: new 
Abstract: The parameterization of closed surfaces typically requires either multiple charts or a non-planar domain to achieve a seamless global mapping. In this paper, we propose a numerical framework for the seamless parameterization of genus-zero and genus-one closed simplicial surfaces onto a unit square domain. The process begins by slicing the surface with either the shortest-path or the Reeb graph method. The sliced surface is then mapped onto the unit square using a globally convergent algorithm that minimizes the weighted variance of per-triangle area ratios to achieve area preservation. Numerical experiments on benchmark models demonstrate that our method achieves high accuracy and efficiency. Furthermore, the proposed method enables applications such as geometry images, producing accurate and high-quality surface reconstructions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22269v1</guid>
      <category>math.NA</category>
      <category>cs.CG</category>
      <category>cs.NA</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shu-Yung Liu, Mei-Heng Yueh</dc:creator>
    </item>
    <item>
      <title>Universal Solution to Kronecker Product Decomposition</title>
      <link>https://arxiv.org/abs/2509.22373</link>
      <description>arXiv:2509.22373v1 Announce Type: new 
Abstract: This paper provides a general solution for the Kronecker product decomposition (KPD) of vectors, matrices, and hypermatrices. First, an algorithm, namely, monic decomposition algorithm (MDA), is reviewed. It consists of a set of projections from a higher dimension Euclidian space to its factor-dimension subspaces. It is then proved that the KPD of vectors is solvable, if and only if, the project mappings provide the required decomposed vectors. Hence it provides an easily verifiable necessary and sufficient condition for the KPD of vectors. Then an algorithm is proposed to calculate the least square error approximated decomposition. Using it finite times a finite sum (precise) KPD of any vectors can be obtained. Then the swap matrix is used to make the elements of a matrix re-arranging, and then provides a method to convert the KPD of matrices to its corresponding KPD of vectors. It is proved that the KPD of a matrix is solvable, if and only if, the KPD of its corresponding vector is solvable. In this way, the necessary and sufficient condition, and the followed algorithms for approximate and finite sum KPDs for matrices are also obtained. Finally, the permutation matrix is introduced and used to convert the KPD of any hypermatrix to KPD of its corresponding vector. Similarly to matrix case, the necessary and sufficient conditions for solvability and the techniques for vectors and matrices are also applicable for hypermatrices, though some additional algorithms are necessary. Several numerical examples are included to demonstrate this universal KPD solving method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22373v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daizhan Cheng</dc:creator>
    </item>
    <item>
      <title>The discretizations of the derivative by the continuous Galerkin and the discontinuous Galerkin methods are exactly the same</title>
      <link>https://arxiv.org/abs/2509.22587</link>
      <description>arXiv:2509.22587v1 Announce Type: new 
Abstract: In the framework of ODEs, we uncover a new link between the continuous Galerkin method (see Math. Comp. (1972), 26 (118 and 120), 415-426 and 881-891) and the discontinuous Galerkin method (see Mathematical Aspects of Finite elements in PDEs, (1974), 89-123), namely, that the discretizations of the derivative by these two methods are the same. A direct consequence of this result is the construction of a new elementwise post-processing of the approximate solution provided by the Discontinuous Galerkin method. When the DG method uses polynomials of degree $k\ge0$, the post-processing consists in adding, to the DG approximate solution, the (scaled) left-Radau polynomial of degree $k+1$ multiplied by the jump of the approximate solution at the left boundary of the interval. No extra computation is required. The resulting new approximation is continuous and, for $k&gt;0$, converges with order $k+2$, that is, with one order more than the original discontinuous Galerkin approximation. For $k=0$, the order remains the same.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22587v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Beijing Journal of Pure and Applied Mathematics, Volume 2, Issue 1, Publication date 2025/4/14,, Pages 115-122, Publisher International Press of Boston</arxiv:journal_reference>
      <dc:creator>Bernardo Cockburn</dc:creator>
    </item>
    <item>
      <title>GenUQ: Predictive Uncertainty Estimates via Generative Hyper-Networks</title>
      <link>https://arxiv.org/abs/2509.21605</link>
      <description>arXiv:2509.21605v1 Announce Type: cross 
Abstract: Operator learning is a recently developed generalization of regression to mappings between functions. It promises to drastically reduce expensive numerical integration of PDEs to fast evaluations of mappings between functional states of a system, i.e., surrogate and reduced-order modeling. Operator learning has already found applications in several areas such as modeling sea ice, combustion, and atmospheric physics. Recent approaches towards integrating uncertainty quantification into the operator models have relied on likelihood based methods to infer parameter distributions from noisy data. However, stochastic operators may yield actions from which a likelihood is difficult or impossible to construct. In this paper, we introduce, GenUQ, a measure-theoretic approach to UQ that avoids constructing a likelihood by introducing a generative hyper-network model that produces parameter distributions consistent with observed data. We demonstrate that GenUQ outperforms other UQ methods in three example problems, recovering a manufactured operator, learning the solution operator to a stochastic elliptic PDE, and modeling the failure location of porous steel under tension.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21605v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tian Yu Yen, Reese E. Jones, Ravi G. Patel</dc:creator>
    </item>
    <item>
      <title>A regret minimization approach to fixed-point iterations</title>
      <link>https://arxiv.org/abs/2509.21653</link>
      <description>arXiv:2509.21653v1 Announce Type: cross 
Abstract: We propose a conversion scheme that turns regret minimizing algorithms into fixed point iterations, with convergence guarantees following from regret bounds. The resulting iterations can be seen as a grand extension of the classical Krasnoselskii--Mann iterations, as the latter are recovered by converting the Online Gradient Descent algorithm. This approach yields new simple iterations for finding fixed points of non-self operators. We also focus on converting algorithms from the AdaGrad family of regret minimizers, and thus obtain fixed point iterations with adaptive guarantees of a new kind. Numerical experiments on various problems demonstrate faster convergence of AdaGrad-based fixed point iterations over Krasnoselskii--Mann iterations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21653v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joon Kwon</dc:creator>
    </item>
    <item>
      <title>Spiking Neural Networks: a theoretical framework for Universal Approximation and training</title>
      <link>https://arxiv.org/abs/2509.21920</link>
      <description>arXiv:2509.21920v1 Announce Type: cross 
Abstract: Spiking Neural Networks (SNNs) are widely regarded as a biologically-inspired and energy-efficient alternative to classical artificial neural networks. Yet, their theoretical foundations remain only partially understood. In this work, we develop a rigorous mathematical analysis of a representative SNN architecture based on Leaky Integrate-and-Fire (LIF) neurons with threshold-reset dynamics. Our contributions are twofold. First, we establish a universal approximation theorem showing that SNNs can approximate continuous functions on compact domains to arbitrary accuracy. The proof relies on a constructive encoding of target values via spike timing and a careful interplay between idealized $\delta$-driven dynamics and smooth Gaussian-regularized models. Second, we analyze the quantitative behavior of spike times across layers, proving well-posedness of the hybrid dynamics and deriving conditions under which spike counts remain stable, decrease, or in exceptional cases increase due to resonance phenomena or overlapping inputs. Together, these results provide a principled foundation for understanding both the expressive power and the dynamical constraints of SNNs, offering theoretical guarantees for their use in classification and signal processing tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21920v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Umberto Biccari</dc:creator>
    </item>
    <item>
      <title>Discretization Error of Fourier Neural Operators</title>
      <link>https://arxiv.org/abs/2405.02221</link>
      <description>arXiv:2405.02221v2 Announce Type: replace 
Abstract: Operator learning is a variant of machine learning that is designed to approximate maps between function spaces from data. The Fourier Neural Operator (FNO) is one of the main model architectures used for operator learning. The FNO combines linear and nonlinear operations in physical space with linear operations in Fourier space, leading to a parameterized map acting between function spaces. Although in definition, FNOs are objects in continuous space and perform convolutions on a continuum, their implementation is a discretized object performing computations on a grid, allowing efficient implementation via the FFT. Thus, there is a discretization error between the continuum FNO definition and the discretized object used in practice that is separate from other previously analyzed sources of model error. We examine this discretization error here and obtain algebraic rates of convergence in terms of the grid resolution as a function of the input regularity. Numerical experiments that validate the theory and describe model stability are performed. In addition, an algorithm is presented that leverages the discretization error and model error decomposition to optimize computational training time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02221v2</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Samuel Lanthaler, Andrew M. Stuart, Margaret Trautner</dc:creator>
    </item>
    <item>
      <title>Analysis of the SQP Method for Hyperbolic PDE-Constrained Optimization in Acoustic Full Waveform Inversion</title>
      <link>https://arxiv.org/abs/2405.05158</link>
      <description>arXiv:2405.05158v4 Announce Type: replace 
Abstract: In this paper, the SQP method applied to a hyperbolic PDE-constrained optimization problem is considered. The model arises from the acoustic full waveform inversion in the time domain. The analysis is mainly challenging due to the involved hyperbolicity and second-order bilinear structure. This notorious character leads to an undesired effect of loss of regularity in the SQP method, calling for a substantial extension of developed parabolic techniques. We propose and analyze a novel strategy for the well-posedness and convergence analysis based on the use of a smooth-in-time initial condition, a tailored self-mapping operator, and a two-step estimation process along with Stampacchia's method for second-order wave equations. Our final theoretical result is the R-superlinear convergence of the SQP method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05158v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luis Ammann, Irwin Yousept</dc:creator>
    </item>
    <item>
      <title>Numerical analysis of high-order methods for variable-exponent fractional diffusion-wave equation</title>
      <link>https://arxiv.org/abs/2406.02941</link>
      <description>arXiv:2406.02941v4 Announce Type: replace 
Abstract: This work considers the variable-exponent fractional diffusion-wave equation, which describes, e.g. the propagation of mechanical diffusive waves in viscoelastic media with varying material properties. Rigorous numerical analysis for this model is not available in the literature, partly because the variable-exponent Abel kernel in the leading term may not be positive definite or monotonic. We adopt the idea of model reformulation to obtain a more tractable form, which, however, still involves an ``indefinite-sign, nonpositive-definite, nonmonotonic'' convolution kernel that introduces difficulties in numerical analysis. We address this issue to design two high-order schemes and derive their stability and error estimate based on the proved solution regularity, with $\alpha(0)$-order and second-order accuracy in time, respectively. Numerical experiments are presented to substantiate the theoretical findings and to show the transition behavior of the mechanical (diffusive) wave modeled by variable exponent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02941v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenlin Qiu, Xiangcheng Zheng</dc:creator>
    </item>
    <item>
      <title>Computation of harmonic functions on higher genus surfaces</title>
      <link>https://arxiv.org/abs/2410.06763</link>
      <description>arXiv:2410.06763v2 Announce Type: replace 
Abstract: We extend a classical approximation result of harmonic functions in planar domains due to Bernstein and Walsch to the setting of harmonic functions in Riemann surfaces. This result gives an exact characterization of the rate at which a harmonic function in a subdomain of a compact Riemann surface may be approached by globally defined harmonic functions with prescribed poles. We illustrate the effectiveness and the impact of the method solving general boundary value Laplace problems in subdomains of the surface; we lay the groundwork for this numerical method in Riemann surfaces represented by a gluing of hyperbolic polygons. In particular, we give a general approximation procedure that computes this basis efficiently with arbitrary precision.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06763v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Micka\"el Nahon, \'Edouard Oudet</dc:creator>
    </item>
    <item>
      <title>Inf-sup stable space-time Local Discontinuous Galerkin method for the heat equation</title>
      <link>https://arxiv.org/abs/2411.14819</link>
      <description>arXiv:2411.14819v2 Announce Type: replace 
Abstract: We propose and analyze a space-time Local Discontinuous Galerkin method for the approximation of the solution to parabolic problems. The method allows for very general discrete spaces and prismatic space-time meshes. Existence and uniqueness of a discrete solution are shown by means of an inf-sup condition, whose proof does not rely on polynomial inverse estimates. Moreover, for piecewise polynomial spaces satisfying an additional mild condition, we show a second inf-sup condition that provides additional control over the time derivative of the discrete solution. We derive $hp$-a priori error bounds based on these inf-sup conditions, which we use to prove convergence rates for standard, tensor-product, and quasi-Trefftz polynomial spaces. Numerical experiments validate our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14819v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sergio G\'omez, Chiara Perinati, Paul Stocker</dc:creator>
    </item>
    <item>
      <title>Convergence theory for two-level hybrid Schwarz preconditioners for high-frequency Helmholtz problems</title>
      <link>https://arxiv.org/abs/2501.11060</link>
      <description>arXiv:2501.11060v3 Announce Type: replace 
Abstract: We give a novel convergence theory for two-level hybrid Schwarz domain-decomposition (DD) methods for finite-element discretisations of the high-frequency Helmholtz equation. This theory gives sufficient conditions for the preconditioned matrix to be close to the identity, and covers DD subdomains of arbitrary size, arbitrary absorbing layers/boundary conditions on both the global and local Helmholtz problems, and coarse spaces not necessarily related to the subdomains.
  The assumptions on the coarse space are satisfied by the approximation spaces using problem-adapted basis functions that have been recently analysed as coarse spaces for the Helmholtz equation, as well as all spaces that are known to be quasi-optimal via a Schatz-type argument.
  As an example, we apply this theory when the coarse space consists of piecewise polynomials; these are then the first rigorous convergence results about a two-level Schwarz preconditioner applied to the high-frequency Helmholtz equation with a coarse space that does not consist of problem-adapted basis functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11060v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeffrey Galkowski, Euan A. Spence</dc:creator>
    </item>
    <item>
      <title>Theory of two-level Schwarz preconditioners with piecewise-polynomial coarse spaces for the high-frequency Helmholtz equation</title>
      <link>https://arxiv.org/abs/2501.15976</link>
      <description>arXiv:2501.15976v3 Announce Type: replace 
Abstract: We analyse two-level Schwarz domain-decomposition GMRES preconditioners -- both the classic additive Schwarz preconditioner and a hybrid variant -- for finite-element discretisations of the Helmholtz equation with wavenumber $k$, where the coarse space consists of piecewise polynomials.
  We prove results for fixed polynomial degree (in both the fine and coarse spaces), as well as for polynomial degree increasing like $\log k$. In the latter case, we exhibit choices of fine and coarse spaces such that -- up to factors of $\log k$ -- the fine and coarse spaces are both pollution free (with the ratio of the coarse-space dimension to the fine-space dimension arbitrarily small), the number of degrees of freedom per subdomain is constant, and the number of GMRES iterations is bounded independently of $k$.
  These are the first convergence results about a two-level Schwarz preconditioner for high-frequency Helmholtz with a coarse space that is pollution free (up to factors of $\log k$) and does not consist of problem-adapted basis functions. Additionally, these are the first $k$-explicit convergence results about any two-level completely-additive Schwarz preconditioner for high-frequency Helmholtz.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15976v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ivan G. Graham, Euan A. Spence</dc:creator>
    </item>
    <item>
      <title>Fourier Analysis of Finite Difference Schemes for the Helmholtz Equation in 1D with Dirichlet Conditions: Sharp Estimates and Relative Errors</title>
      <link>https://arxiv.org/abs/2501.16696</link>
      <description>arXiv:2501.16696v2 Announce Type: replace 
Abstract: We propose an approach based on Fourier analysis to wavenumber explicit sharp estimation of absolute and relative errors of finite difference methods for the Helmholtz equation in 1D with Dirichlet boundary conditions and general source terms. We use the approach to analyze the classical centred scheme for the Helmholtz equation with a general smooth source term and Dirichlet boundary conditions in 1D. For the Fourier interpolants of the discrete solution with homogeneous (or inhomogeneous) Dirichlet conditions, we show rigorously that the worst case attainable convergence order of the absolute error is k2h2 (or k3h2) in the L2-norm and k3h2 (or k4h2) in the H1-semi-norm, and that of the relative error is k3h2 in both L2- and H1-semi-norms. Even though the classical centred scheme is well-known, it is the first time that such sharp estimates of absolute and relative errors are obtained. We show also that the Fourier analysis approach can be used as a convenient visual tool for evaluating finite difference schemes in presence of source terms, which is beyond the scope of dispersion analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16696v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin J. Gander, Hui Zhang</dc:creator>
    </item>
    <item>
      <title>Modeling and simulation of inductionless magnetohydrodynamic free surface problems with unmatched densities</title>
      <link>https://arxiv.org/abs/2507.14518</link>
      <description>arXiv:2507.14518v2 Announce Type: replace 
Abstract: We propose a new diffuse interface model for simulating an inductionless magnetohydrodynamic (MHD) free surface problem. By using the Onsager's variational principle and the laws of thermodynamics, we derive a thermodynamically consistent system that couples the Cahn--Hilliard equation modeling phase separation, the Navier--Stokes equations governing fluid motion, and a generalized Darcy's law accounting for electromagnetic effects. In contrast to existing diffuse interface MHD models, the proposed model can handle general material properties in practical engineering applications. Furthermore, through asymptotic arguments, we investigate the sharp interface limit, and then demonstrate that the classical sharp interface model can be recovered as the interface thickness approaches zero, theoretically validating the proposed diffuse interface model as an approximate approach. An efficient decoupled, linear, and charge-conservative finite element scheme is designed, and it significantly facilitates the large-scale and accurate numerical simulations involving large parameter ratios. Finally, we present several three-dimensional numerical experiments of magnetic damping effects on bubble dynamics for the demonstration of the capability of the proposed model and method in capturing complex MHD phenomena.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.14518v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.flu-dyn</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiancheng Wang, Maojun Li, Zeyu Xia, Liwei Xu</dc:creator>
    </item>
    <item>
      <title>A convergence proof for a finite element discretization of Chorin's projection method of the incompressible Navier-Stokes equations</title>
      <link>https://arxiv.org/abs/2508.13416</link>
      <description>arXiv:2508.13416v2 Announce Type: replace 
Abstract: We study Chorin's projection method combined with a finite element spatial discretization for the time-dependent incompressible Navier-Stokes equations. The scheme advances the solution in two steps: a prediction step, which computes an intermediate velocity field that is generally not divergence-free, and a projection step, which enforces (approximate) incompressibility by projecting this velocity onto the (approximately) divergence-free subspace. We establish convergence, up to a subsequence, of the numerical approximations generated by this scheme to a Leray-Hopf weak solution of the Navier-Stokes equations, without any additional regularity assumptions beyond square-integrable initial data. A discrete energy inequality yields a priori estimates, which we combine with a new compactness result to prove precompactness of the approximations in $L^2([0,T]\times\Omega)$, where $[0,T]$ is the time interval and $\Omega$ is the spatial domain. Passing to the limit as the discretization parameters vanish, we obtain a weak solution of the Navier-Stokes equations. A central difficulty is that different a priori bounds are available for the intermediate and projected velocity fields; our compactness argument carefully integrates these estimates to complete the convergence proof.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13416v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Franziska Weber</dc:creator>
    </item>
    <item>
      <title>The Polar Express: Optimal Matrix Sign Methods and Their Application to the Muon Algorithm</title>
      <link>https://arxiv.org/abs/2505.16932</link>
      <description>arXiv:2505.16932v3 Announce Type: replace-cross 
Abstract: Computing the polar decomposition and the related matrix sign function has been a well-studied problem in numerical analysis for decades. Recently, it has emerged as an important subroutine within the Muon algorithm for training deep neural networks. However, the requirements of this application differ sharply from classical settings: deep learning demands GPU-friendly algorithms that prioritize high throughput over high precision. We introduce Polar Express, a new method for computing the polar decomposition. Like Newton-Schulz and other classical polynomial methods, our approach uses only matrix-matrix multiplications, making it very efficient on GPUs. Inspired by earlier work of Chen &amp; Chow and Nakatsukasa &amp; Freund, Polar Express adapts the update rule at each iteration by solving a minimax optimization problem. We prove that this strategy minimizes error in a worst-case sense, allowing Polar Express to converge as rapidly as possible both in the early iterations and asymptotically. We also address finite-precision issues, making it practical to use in bfloat16. When integrated into the Muon training framework, our method leads to consistent improvements in validation loss when training a GPT-2 model on one billion tokens from the FineWeb dataset, outperforming recent alternatives across a range of learning rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.16932v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Noah Amsel, David Persson, Christopher Musco, Robert M. Gower</dc:creator>
    </item>
    <item>
      <title>Next Generation Equation-Free Multiscale Modelling of Crowd Dynamics via Machine Learning</title>
      <link>https://arxiv.org/abs/2508.03926</link>
      <description>arXiv:2508.03926v2 Announce Type: replace-cross 
Abstract: Bridging the microscopic and the macroscopic modelling scales in crowd dynamics constitutes an important open challenge for systematic numerical analysis, optimization and control. We propose a combined manifold and machine learning approach to learn the discrete evolution operator for the emergent crowd dynamics in latent spaces from high-fidelity agent-based simulations. The proposed framework builds upon our previous works on next-generation Equation-free algorithms for learning surrogate models of high-dim. multiscale systems. Our approach is a four-stage one, explicitly conserving the mass of the reconstructed dynamics in the high-dim. space. In the first step, we derive continuous macroscopic fields (densities) from discrete microscopic data (pedestrians' positions) using KDE. In the second step, based on manifold learning, we construct a map from the macroscopic ambient space into the latent space parametrized by a few coordinates based on POD of the corresponding density distribution. The third step involves learning reduced-order surrogate ROMs in the latent space using machine learning techniques, particularly LSTMs networks and MVARs. Finally, we reconstruct the crowd dynamics in the high-dim. space in terms of macroscopic density profiles. With this "embed-&gt;learn in latent space-&gt;lift back to ambient space" pipeline, we create an effective solution operator of the unavailable macroscopic PDE for the density evolution. For our illustrations, we use SFM to generate data in a corridor with an obstacle, imposing periodic boundary conditions. The numerical results demonstrate high accuracy, robustness, and generalizability, thus allowing for fast and accurate modelling of crowd dynamics from agent-based simulations. Notably, linear MVAR models surpass nonlinear LSTMs in predictive accuracy, while also offering significantly lower complexity and greater interpretability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03926v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.NA</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hector Vargas Alvarez, Dimitrios G. Patsatzis, Lucia Russo, Ioannis Kevrekidis, Constantinos Siettos</dc:creator>
    </item>
    <item>
      <title>A Variational Framework for Residual-Based Adaptivity in Neural PDE Solvers and Operator Learning</title>
      <link>https://arxiv.org/abs/2509.14198</link>
      <description>arXiv:2509.14198v2 Announce Type: replace-cross 
Abstract: Residual-based adaptive strategies are widely used in scientific machine learning but remain largely heuristic. We introduce a unifying variational framework that formalizes these methods by integrating convex transformations of the residual. Different transformations correspond to distinct objective functionals: exponential weights target the minimization of uniform error, while linear weights recover the minimization of quadratic error. Within this perspective, adaptive weighting is equivalent to selecting sampling distributions that optimize the primal objective, thereby linking discretization choices directly to error metrics. This principled approach yields three benefits: (1) it enables systematic design of adaptive schemes across norms, (2) reduces discretization error through variance reduction of the loss estimator, and (3) enhances learning dynamics by improving the gradient signal-to-noise ratio. Extending the framework to operator learning, we demonstrate substantial performance gains across optimizers and architectures. Our results provide a theoretical justification of residual-based adaptivity and establish a foundation for principled discretization and training strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14198v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Juan Diego Toscano, Daniel T. Chen, Vivek Oommen, J\'er\^ome Darbon, George Em Karniadakis</dc:creator>
    </item>
    <item>
      <title>Monte Carlo on a single sample</title>
      <link>https://arxiv.org/abs/2509.17025</link>
      <description>arXiv:2509.17025v2 Announce Type: replace-cross 
Abstract: In this paper, we consider a Monte Carlo simulation method (MinMC) that approximates prices and risk measures for a range $\Gamma$ of model parameters at once. The simulation method that we study has recently gained popularity [HS20, FPP22, BDG24], and we provide a theoretical framework and convergence rates for it. In particular, we show that sample-based approximations to $\mathbb{E}_{\theta}[X]$, where $\theta$ denotes the model and $\mathbb{E}_{\theta}$ the expectation with respect to the distribution $P_\theta$ of the model $\theta$, can be obtained across all $\theta \in \Gamma$ by minimizing a map $V:H\rightarrow \mathbb{R}$ with $H$ a suitable function space. The minimization can be achieved easily by fitting a standard feedforward neural network with stochastic gradient descent. We show that MinMC, which uses only one sample for each model, significantly outperforms a traditional Monte Carlo method performed for multiple values of $\theta$, which are subsequently interpolated. Our case study suggests that MinMC might serve as a new benchmark for parameter-dependent Monte Carlo simulations, which appear not only in quantitative finance but also in many other areas of scientific computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.17025v2</guid>
      <category>math.ST</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nils Detering, Paul Eisenberg, Nicole Hufnagel</dc:creator>
    </item>
    <item>
      <title>Data-driven Neural Networks for Windkessel Parameter Calibration</title>
      <link>https://arxiv.org/abs/2509.21206</link>
      <description>arXiv:2509.21206v2 Announce Type: replace-cross 
Abstract: In this work, we propose a novel method for calibrating Windkessel (WK) parameters in a dimensionally reduced 1D-0D coupled blood flow model. To this end, we design a data-driven neural network (NN)trained on simulated blood pressures in the left brachial artery. Once trained, the NN emulates the pressure pulse waves across the entire simulated domain, i.e., over time, space and varying WK parameters, with negligible error and computational effort. To calibrate the WK parameters on a measured pulse wave, the NN is extended by dummy neurons and retrained only on these. The main objective of this work is to assess the effectiveness of the method in various scenarios -- particularly, when the exact measurement location is unknown or the data are affected by noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21206v2</guid>
      <category>q-bio.TO</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Benedikt Hoock, Tobias K\"oppl</dc:creator>
    </item>
  </channel>
</rss>
