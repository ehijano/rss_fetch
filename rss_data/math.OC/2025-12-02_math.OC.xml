<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 02 Dec 2025 05:00:06 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Exact Decentralized Optimization via Explicit $\ell_1$ Consensus Penalties</title>
      <link>https://arxiv.org/abs/2512.00268</link>
      <description>arXiv:2512.00268v1 Announce Type: new 
Abstract: Consensus optimization enables autonomous agents to solve joint tasks through peer-to-peer exchanges alone. Classical decentralized gradient descent is appealing for its minimal state but fails to achieve exact consensus with fixed stepsizes unless additional trackers or dual variables are introduced. We revisit penalty methods and introduce a decentralized two-layer framework that couples an outer penalty-continuation loop with an inner plug-and-play saddle-point solver. Any primal-dual routine that satisfies simple stationarity and communication conditions can be used; when instantiated with a proximal-gradient solver, the framework yields the DP$^2$G algorithm, which reaches exact consensus with constant stepsizes, stores only one dual residual per agent, and requires exactly two short message exchanges per inner iteration. An explicit $\ell_1$ penalty enforces agreement and, once above a computable threshold, makes the penalized and constrained problems equivalent. Leveraging the Kurdyka-\L{}ojasiewicz property, we prove global convergence, vanishing disagreement, and linear rates for strongly convex objectives under any admissible inner solver. Experiments on distributed least squares, logistic regression, and elastic-net tasks across various networks demonstrate that DP$^2$G outperforms DGD-type methods in both convergence speed and communication efficiency, is competitive with gradient-tracking approaches while using less memory, and naturally accommodates composite objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00268v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Hong Wang</dc:creator>
    </item>
    <item>
      <title>A multilevel proximal trust-region method for nonsmooth optimization with applications</title>
      <link>https://arxiv.org/abs/2512.00538</link>
      <description>arXiv:2512.00538v1 Announce Type: new 
Abstract: Many large-scale optimization problems arising in science and engineering are naturally defined at multiple levels of discretization or model fidelity. Multilevel methods exploit this hierarchy to accelerate convergence by combining coarse- and fine-level information, a strategy that has proven highly effective in the numerical solution of partial differential equations and related optimization problems. It turns out that many applications in PDE-constrained optimization and data science require minimizing the sum of smooth and nonsmooth functions. For example, training neural networks may require minimizing a mean squared error plus an $L^1$-regularization to induce sparsity in the weights. Correspondingly, we introduce a multilevel proximal trust-region method to minimize the sum of a nonconvex, smooth and a convex, nonsmooth function. Exploiting ideas from the multilevel literature allows us to reduce the cost of the step computation, which is a major bottleneck in single level procedures. Our work unifies theory behind the proximal trust-region methods and multilevel recursive strategies. We prove global convergence of our method in finite dimensional space and provide an efficient nonsmooth subproblem solver. We show the efficiency and robustness of our algorithm by means of numerical examples in PDE constrained optimization and machine-learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00538v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert Baraldi, Michael Hinterm\"uller, Qi Wang</dc:creator>
    </item>
    <item>
      <title>Optimal Control of McKean--Vlasov Branching Diffusion Processes</title>
      <link>https://arxiv.org/abs/2512.00633</link>
      <description>arXiv:2512.00633v1 Announce Type: new 
Abstract: We study an optimal control problem of McKean--Vlasov branching diffusion processes, in which the interaction term is determined by the marginal measure induced by all alive particles in the system. Accordingly, the value function is defined on the space of finite nonnegative measures over the Euclidean space. Within the framework of Lipschitz continuous closed-loop controls, and by using the uniqueness of solution to the associated nonlinear Fokker--Planck equation, we establish the dynamic programming principle. Further, under the regularity assumptions, we show that the value function satisfies a Hamilton--Jacobi--Bellman (HJB) master equation defined on the space of finite nonnegative measures. We next provide a corresponding verification theorem. Finally, we study a linear--quadratic controlled branching processes problem, for which explicit solutions are derived in terms of Riccati-type equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00633v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julien Claisse, Jiazhi Kang, Tianxu Lan, Xiaolu Tan</dc:creator>
    </item>
    <item>
      <title>Cosine-Similarity Methods for Efficient Training and Sampling in High-Dimensional Latent Spaces</title>
      <link>https://arxiv.org/abs/2512.00684</link>
      <description>arXiv:2512.00684v1 Announce Type: new 
Abstract: Latent generative models are increasingly shifting from traditional VAEs toward representation autoencoders and semantically aligned latent spaces, which lift images into higher-dimensional feature domains where semantic factors become more separable. Yet these spaces also contain geometric regularities that existing methods do not fully exploit--particularly in the directional relationships between features.
  We introduce a cosine-similarity-based mechanism that improves both training and sampling by selecting couplings that produce cleaner, less entangled velocity fields. This simple alignment reduces gradient noise, accelerates convergence, and improves sample fidelity. Building on this idea, we develop cosine-similarity-based fine-tuning and time-scheduling strategies that reduce the FID of an 800-epoch RAE from 11.99 to 8.60. Furthermore, by formulating an optimal-transport coupling using a cosine cost, a single-epoch fine-tuning step at the 20-epoch checkpoint reaches 3.30 FID-matching the performance of the 80-epoch baseline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00684v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xu Duan, Dongmei Chen</dc:creator>
    </item>
    <item>
      <title>A warmstarting technique for general conic optimization in interior point methods</title>
      <link>https://arxiv.org/abs/2512.00693</link>
      <description>arXiv:2512.00693v1 Announce Type: new 
Abstract: We propose a novel warmstarting method for primal-dual interior point methods based on a smoothing operator that generates a starting point on the central path from the previous optimum. Compared to traditional approaches that prioritize minimizing infeasibility residuals, our method focuses on maintaining proximity to the central path. Computation of a smoothing operator is efficient and can be parallelized for conic constraints. We also prove that the residual of the smoothed starting point remains comparable to the one before the smoothing step. The numerical tests show that the proposed warmstarting strategy can reduce iteration numbers and computational time effectively across test problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00693v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuwen Chen, Paul Goulart, Colin Jones</dc:creator>
    </item>
    <item>
      <title>Constructing control landscape for non-convex optimal control of elliptic equation by PDE-constrained high-index saddle dynamics</title>
      <link>https://arxiv.org/abs/2512.00732</link>
      <description>arXiv:2512.00732v1 Announce Type: new 
Abstract: Non-convex optimal control arises from various applications but may contain multiple stationary points. Classical solvers usually perform a ``local'' search near a saddle point or a local minimum, thus rely on good initial guess to reach the (quasi-)optimal control. We introduce a novel solution strategy for the non-convex optimal control of an elliptic equation. We develop a PDE-constrained high-index saddle dynamics (PCHiSD) to construct the control landscape. This method depicts the macroscopic configuration of control and state spaces such that the local and global minima could be systematically computed along the transition pathways in control landscape without requiring good initial conditions. We establish the well-posedness of the state equation and the existence of an optimal control, and then implement the PCHiSD and control landscape algorithms for numerical experiments and comparisons. Numerical results not only indicate the effectiveness of the proposed method, but reveal unintuitive phenomena that supports the necessity of computing multiple solutions of high indices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00732v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ning Du, Yanlin Liu, Lei Zhang, Xiangcheng Zheng</dc:creator>
    </item>
    <item>
      <title>On Approximation Algorithms for Commutative Quaternion Polynomial Optimization</title>
      <link>https://arxiv.org/abs/2512.00779</link>
      <description>arXiv:2512.00779v1 Announce Type: new 
Abstract: Quaternion optimization has attracted significant interest due to its broad applications, including color face recognition, video compression, and signal processing. Despite the growing literature on quadratic and matrix quaternion optimization, to the best of our knowledge, the study on quaternion polynomial optimization still remains blank. In this paper, we introduce the first investigation into this fundamental problem, and focus on the sphere-constrained homogeneous polynomial optimization over the commutative quaternion domain, which includes the best rank-one tensor approximation as a special case. Our study proposes a polynomial-time randomized approximation algorithm that employs tensor relaxation and random sampling techniques to tackle this problem. Theoretically, we prove an approximation ratio for the algorithm providing a worst-case performance guarantee</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00779v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chang He, Bo Jiang, Hongye Wang, Xihua Zhu</dc:creator>
    </item>
    <item>
      <title>Accurately modeling long-term storage with minimum representative hours in large-scale renewable energy systems</title>
      <link>https://arxiv.org/abs/2512.00892</link>
      <description>arXiv:2512.00892v1 Announce Type: new 
Abstract: Energy system optimization often relies on time series aggregation to ensure computational tractability. Aggregation generally loses the chronology of time steps, which renders the storage level representation challenging. Typically, this challenge is addressed by using representative days (RD) to utilize intra-day chronology, even though representative hours (RH) can describe the input time series more accurately at fewer representative time steps than RD. However, until now, the use of RH storage representation methods has been limited by either high computational complexity, poor accuracy in clustering and storage representation, or restricted applicability. Here, we present a novel storage representation method based on RH that combines the high accuracy of RH time series aggregation with the high computational efficiency of methods based on RD. Through benchmarking the four most established storage representation methods on a model of a net-zero European energy system, we find that the proposed method can reduce the solving time by over 95% for the same objective value compared to the most established RD and RH methods. The proposed method exhibits particular strengths at strong aggregations of around 100 to 500 representative hours per year, making the method especially applicable to large-scale and sector-coupled transition pathway models. The developed method for accurately modeling both short-term and long-term storage, along with the presented findings, is of practical relevance to energy system modelers who seek computational tractability in large-scale applications while avoiding the misallocation of storage and conversion capacities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00892v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jacob Mannhardt, Lukas Kunz, Giovanni Sansavini</dc:creator>
    </item>
    <item>
      <title>A Dual-Mode Framework for Mean-Field Systems: Model-Based $H_2/H_\infty$ Control with Jump Diffusions and Model-Free Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2512.01000</link>
      <description>arXiv:2512.01000v1 Announce Type: new 
Abstract: The stochastic $H_2/H_\infty$ control problem for continuous-time mean-field stochastic differential equations with Poisson jumps over finite horizon is investigated in this paper. Continuous and jump diffusion terms in the system depend not only on the state but also on the control input, external disturbance, and mean-field components. By employing the quasi-linear technique and the method of completing the square, a mean-field stochastic jump bounded real lemma of the system is derived. This study demonstrates that the feasibility of the stochastic $H_2/H_\infty$ control problem is equivalent to the solvability of four sets of cross-coupled generalized differential Riccati equations, which generalizes the previous results to mean-field jump-diffusion systems. To validate the proposed methodology, a numerical simulation example is provided to illustrate the effectiveness of the control strategy. This paper also presents a data-driven, model-free, off-policy reinforcement learning approach, which can be utilized to solve the $H_\infty$ control problem for the mean-field systems discussed herein. The findings establish a systematic framework for designing robust controllers for interacting particle systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01000v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huimin Han, Shaolin Ji, Weihai Zhang</dc:creator>
    </item>
    <item>
      <title>Games with infinite past</title>
      <link>https://arxiv.org/abs/2512.01001</link>
      <description>arXiv:2512.01001v1 Announce Type: new 
Abstract: We study multi-player games with perfect information and general payoff function, where the set of stages is the set of non-positive integers $\{\ldots,-2,-1,0\}$. We define two related equilibrium concepts: one considering only deviations at finitely many stages and another considering all deviations. We show that (i) The sets of equilibrium plays coincide for the two equilibrium concepts, provided that at least two players are active along each infinite play. (ii) In win-lose games, the game has an equilibrium if the winning sets have Borel-rank at most 2, and we provide a counter-example showing that this is no longer true for Borel-rank 3. (iii) In general non-zero-sum games, the game has an equilibrium if the payoff functions are continuous, for example, with reversed-time discounted payoffs. The challenge for all these results is that not all strategy profiles admit a consistent infinite play, hampering the use of backward induction arguments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01001v1</guid>
      <category>math.OC</category>
      <category>math.LO</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Galit Ashkenazi-Golan, J\'anos Flesch, Eilon Solan</dc:creator>
    </item>
    <item>
      <title>MP and DPP for Mean-Variance Portfolio Selection Problem with Poisson Jumps, Recursive Utility and Their Relationship</title>
      <link>https://arxiv.org/abs/2512.01378</link>
      <description>arXiv:2512.01378v1 Announce Type: new 
Abstract: In this paper, the mean-variance portfolio selection problem with Poisson jumps are studied, where the recursive utility is given by the solution to a backward stochastic differential equation with Poisson jumps. Both the maximum principle and dynamic programming principle are applied to solve this problem, and their relationship is also investigated. The optimal portfolio and efficient frontier of Markowitz's type are derived using both methods. A comparison of efficient frontiers obtained in this paper and in the framework without jumps is conducted.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01378v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Qiyue Zhang, Jingtao Shi</dc:creator>
    </item>
    <item>
      <title>Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections</title>
      <link>https://arxiv.org/abs/2512.01408</link>
      <description>arXiv:2512.01408v1 Announce Type: new 
Abstract: We revisit Merton's continuous-time portfolio selection through a data-driven, distributionally robust lens. Our aim is to tap the benefits of frequent trading over short horizons while acknowledging that drift is hard to pin down, whereas volatility can be screened using realized or implied measures for appropriately selected assets. Rather than time-rectangular distributional robust control -- which replenishes adversarial power at every instant and induces over-pessimism -- we place a single ambiguity set on the drift prior within a Bayesian Merton model. This prior-level ambiguity preserves learning and tractability: a minimax swap reduces the robust control to optimizing a nonlinear functional of the prior, enabling Karatzas and Zhao \cite{KZ98}-type's closed-form evaluation for each candidate prior. We then characterize small-radius worst-case priors under Wasserstein uncertainty via an explicit asymptotically optimal pushforward of the nominal prior, and we calibrate the ambiguity radius through a nonlinear Wasserstein projection tailored to the Merton functional. Synthetic and real-data studies demonstrate reduced pessimism relative to DRC and improved performance over myopic DRO-Markowitz under frequent rebalancing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01408v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>q-fin.MF</category>
      <category>stat.TH</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jose Blanchet, Jiayi Cheng, Hao Liu, Yang Liu</dc:creator>
    </item>
    <item>
      <title>Competition among seaports through Mean Field Games and real-world data</title>
      <link>https://arxiv.org/abs/2512.01438</link>
      <description>arXiv:2512.01438v1 Announce Type: new 
Abstract: This paper presents a Mean Field Game (MFG) model for maritime traffic flow, treating the navigation of ships between seaports as a large-scale stochastic control problem. The MFG framework enables the modeling of agents at a microscopic level as rational decision-makers who seek to optimize their utility, thereby translating complex microscopic behaviors into macroscopic models. We build upon this MFG framework to develop a mesoscopic-scale MFG model that defines the payoff and cost functions for a coordinator at each seaport considered in our study. The coordinator determines the routes taken by ships transporting goods between ports by evaluating several key factors: transportation costs, expected profit margins from loading specific goods at the seaports and unloading them at various destinations, and a congestion term that reflects the costs associated with accessing the destination port. We derive an explicit solution for the stationary version of the model under certain approximations and establish conditions necessary to ensure the uniqueness of the corresponding Mean Field Equilibrium (MFE). Furthermore, we introduce a statistical methodology to infer the parameters of the game from real-world data, specifically focusing on costs and the components of expected commercial margins. To validate our model in a real-world context, we analyze the ShipFix dataset of daily ''Dry Coal'' shipments worldwide from 2015 to 2025. Our discussion highlights the influence of empirical traffic flow on various components of costs. We believe that this research represents a significant advancement in the application of MFGs for effective maritime traffic management and offers valuable insights for practitioners in the field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01438v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Charles-Albert Lehalle (X), Giulia Livieri (LSE)</dc:creator>
    </item>
    <item>
      <title>Approximate Stability of Subadditive Games and Traveling Salesman Games</title>
      <link>https://arxiv.org/abs/2512.01470</link>
      <description>arXiv:2512.01470v1 Announce Type: new 
Abstract: The core of Transferable Utility (T.U.) games is a well-known solution concept from cooperative game theory yielding a cost allocation among n agents (called players) forming a coalition that is stable (i.e. no subset of players has an interest to deviate). In this paper, inspired by a practical application in the context of a decision support system for collaborative transportation in a Short Food Supply Chain (SFSC), we mainly focus on Traveling Salesman Games (TSGs), where the objective is to allocate the cost of a Traveling Salesman Problem (TSP) with n locations and 1 depot to n players, each linked to exactly one of the locations. Given the computational complexity of computing an element of the core and the cost of a TSP, we study semicore allocations: a relaxation of the core that only requires that the subsets of size n -1 and of size 1 do not wish to deviate from the coalition. In the literature, instances of TSGs with empty cores and semicores are found. Hence, this paper first surveys the methods to approximate stability whenever the core is empty, such as the cost of stability (computing the minimum amount of money to subsidize the coalition with to attain stability) and the $\epsilon$-core (which is a set of allocations that allow subsets of players to exceed their actual cost, but at most of a value of $\epsilon$). We prove that these two solution</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01470v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas Besson-Niebles (G-SCOP\_GROG), Sylvain Bouveret (LIG), Nadia Brauner (G-SCOP\_ROSP), Nicolas Brulard (G-SCOP\_GROG)</dc:creator>
    </item>
    <item>
      <title>On robotic manipulators with time-dependent inertial parameters: From physical consistency to boundedness of the mass matrix</title>
      <link>https://arxiv.org/abs/2512.01482</link>
      <description>arXiv:2512.01482v1 Announce Type: new 
Abstract: We generalize the robotics equation describing the dynamics of an open kinematic chain to include the effect of time-dependent change of inertial parameters as well as the effects of its cause, i.e. time dependency of the distributions of mass originating from parasitic movements of mass-carrying particles. The results generate insight that allows linking the novel concepts of uniform physical consistency and upper boundedness of inertial parameters -- ruling out approaching the edge to physical inconsistency or to diverge -- with the existence of finite, positive uniform bounds of the mass matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01482v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tom Kaufmann, Johann Reger</dc:creator>
    </item>
    <item>
      <title>Exact Objective Space Contraction for the Preprocessing of Multi-objective Integer Programs</title>
      <link>https://arxiv.org/abs/2512.01535</link>
      <description>arXiv:2512.01535v1 Announce Type: new 
Abstract: Solving integer optimization problems with large or widely ranged objective coefficients can lead to numerical instability and increased runtimes. When the problem also involves multiple objectives, the impact of the objective coefficients on runtimes and numerical issues multiplies. We address this issue by transforming the coefficients of linear objective functions into smaller integer coefficients. To the best of our knowledge, this problem has not been defined before. Next to a straightforward scaling heuristic, we introduce a novel exact transformation approach for the preprocessing of multi-objective binary problems. In this exact approach, the large or widely ranged integer objective coefficients are transformed into the minimal integer objective coefficients that preserve the dominance relation of the points in the objective space. The transformation problem is solved with an integer programming formulation with an exponential number of constraints. We present a cutting-plane algorithm that can efficiently handle the problem size. In a first computational study, we analyze how often and in which settings the transformation actually leads to smaller coefficients. In a second study, we evaluate how the exact transformation and a typical scaling heuristic, when used as preprocessing, affect the runtime and numerical stability of the Defining Point Algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01535v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Stephanie Riedm\"uller, Thorsten Koch</dc:creator>
    </item>
    <item>
      <title>Deep FlexQP: Accelerated Nonlinear Programming via Deep Unfolding</title>
      <link>https://arxiv.org/abs/2512.01565</link>
      <description>arXiv:2512.01565v1 Announce Type: new 
Abstract: We propose an always-feasible quadratic programming (QP) optimizer, FlexQP, which is based on an exact relaxation of the QP constraints. If the original constraints are feasible, then the optimizer finds the optimal solution to the original QP. On the other hand, if the constraints are infeasible, the optimizer identifies a solution that minimizes the constraint violation in a sparse manner. FlexQP scales favorably with respect to the problem dimension, is robust to both feasible and infeasible QPs with minimal assumptions on the problem data, and can be effectively warm-started. We subsequently apply deep unfolding to improve our optimizer through data-driven techniques, leading to an accelerated Deep FlexQP. By learning dimension-agnostic feedback policies for the parameters from a small number of training examples, Deep FlexQP generalizes to problems with larger dimensions and can optimize for many more iterations than it was initially trained for. Our approach outperforms two recently proposed state-of-the-art accelerated QP approaches on a suite of benchmark systems including portfolio optimization, classification, and regression problems. We provide guarantees on the expected performance of our deep QP optimizer through probably approximately correct (PAC) Bayes generalization bounds. These certificates are used to design an accelerated sequential quadratic programming solver that solves nonlinear optimal control and predictive safety filter problems faster than traditional approaches. Overall, our approach is very robust and greatly outperforms existing non-learning and learning-based optimizers in terms of both runtime and convergence to the optimal solution across multiple classes of NLPs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01565v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alex Oshin, Rahul Vodeb Ghosh, Augustinos D. Saravanos, Evangelos A. Theodorou</dc:creator>
    </item>
    <item>
      <title>The Maxmin Value of Repeated Games with Incomplete Information on One Side and Tail-Measurable Payoffs</title>
      <link>https://arxiv.org/abs/2512.01581</link>
      <description>arXiv:2512.01581v1 Announce Type: new 
Abstract: We study two-player zero-sum repeated games with incomplete information on one side, where the payoff function is tail measurable (and not necessarily the long-run average payoff). We show that the maxmin value equals the concavification of the value function of the non-revealing game. In addition, we provide an example demonstrating that, under tail-measurable payoffs, the value of the game may fail to exist.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01581v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gil Bar Castellon Koltun, Ehud Lehrer, Eilon Solan</dc:creator>
    </item>
    <item>
      <title>Bayesian Ambiguity Contraction-based Adaptive Robust Markov Decision Processes for Adversarial Surveillance Missions</title>
      <link>https://arxiv.org/abs/2512.01660</link>
      <description>arXiv:2512.01660v1 Announce Type: new 
Abstract: Collaborative Combat Aircraft (CCAs) are envisioned to enable autonomous Intelligence, Surveillance, and Reconnaissance (ISR) missions in contested environments, where adversaries may act strategically to deceive or evade detection. These missions pose challenges due to model uncertainty and the need for safe, real-time decision-making. Robust Markov Decision Processes (RMDPs) provide worst-case guarantees but are limited by static ambiguity sets that capture initial uncertainty without adapting to new observations. This paper presents an adaptive RMDP framework tailored to ISR missions with CCAs. We introduce a mission-specific formulation in which aircraft alternate between movement and sensing states. Adversarial tactics are modeled as a finite set of transition kernels, each capturing assumptions about how adversarial sensing or environmental conditions affect rewards. Our approach incrementally refines policies by eliminating inconsistent threat models, allowing agents to shift from conservative to aggressive behaviors while maintaining robustness. We provide theoretical guarantees showing that the adaptive planner converges as credible sets contract to the true threat and maintains safety under uncertainty. Experiments under Gaussian and non-Gaussian threat models across diverse network topologies show higher mission rewards and fewer exposure events compared to nominal and static robust planners.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01660v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jimin Choi, Max Z. Li</dc:creator>
    </item>
    <item>
      <title>Experiment design using prior knowledge on controllability and stabilizability</title>
      <link>https://arxiv.org/abs/2512.01876</link>
      <description>arXiv:2512.01876v1 Announce Type: new 
Abstract: In this paper, we consider the problem of designing input signals for an unknown linear time-invariant system in such a way that the resulting input-state data is suitable for identification or stabilization. We will take into account prior knowledge on system-theoretic properties of the system, in particular, controllability and stabilizability. For this, we extend the notion of universal inputs to incorporate prior knowledge on the system. An input is called universal for identification (resp., stabilization) if, when applied to any system complying with the prior knowledge, it results in data suitable for identification (resp., stabilization) regardless of the initial condition. We provide a full characterization of such universal inputs. In addition, we discuss online experiment design using prior knowledge, and we study cases where this approach results in the shortest possible experiment for identification and stabilization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01876v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amir Shakouri, Henk J. van Waarde, M. Kanat Camlibel</dc:creator>
    </item>
    <item>
      <title>Analytical Inverse Kinematic Solution for "Moz1" NonSRS 7-DOF Robot arm with novel arm angle</title>
      <link>https://arxiv.org/abs/2511.22996</link>
      <description>arXiv:2511.22996v1 Announce Type: cross 
Abstract: This paper presents an analytical solution to the inverse kinematic problem(IKP) for the seven degree-of-freedom (7-DOF) Moz1 Robot Arm with offsets on wrist. We provide closed-form solutions with the novel arm angle . it allow fully self-motion and solve the problem of algorithmic singularities within the workspace. It also provides information on how the redundancy is resolved in a new arm angle representation where traditional SEW angle faied to be defined and how singularities are handled. The solution is simple, fast and exact, providing full solution space (i.e. all 16 solutions) per pose.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22996v1</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ke Chen</dc:creator>
    </item>
    <item>
      <title>Dependent Reachable Sets for the Constant Bearing Pursuit Strategy</title>
      <link>https://arxiv.org/abs/2512.00273</link>
      <description>arXiv:2512.00273v1 Announce Type: cross 
Abstract: This paper introduces a novel reachability problem for the scenario where one agent follows another agent using the constant bearing pursuit strategy, and analyzes the geometry of the reachable set of the follower. Key theoretical results are derived, providing bounds for the associated dependent reachable set. Simulation results are presented to empirically establish the shape of the dependent reachable set. In the process, an original optimization problem for the constant bearing strategy is formulated and analyzed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00273v1</guid>
      <category>eess.SY</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Venkata Ramana Makkapati, Tulasi Ram Vechalapu, Vinodhini Comandur, Seth Hutchinson</dc:creator>
    </item>
    <item>
      <title>Finite Difference Method for Global Stabilization of the Viscous Burgers' Equation with Nonlinear Neumann Boundary Feedback Control</title>
      <link>https://arxiv.org/abs/2512.00317</link>
      <description>arXiv:2512.00317v1 Announce Type: cross 
Abstract: This article focuses on a nonlinear Neumann boundary feedback control formulation for the viscous Burgers' equation and develops a class of finite difference schemes to achieve global stabilization. The proposed procedure, known as the $\theta$-scheme with $\theta \in [0,1]$, unifies explicit and implicit time discretizations and is suitable for handling the nonlinear boundary feedback control problem. Using the discrete energy method, we prove that the proposed difference scheme is conditionally stable for $0 \leq \theta &lt; \frac{1}{2}$ and unconditionally stable for $\theta \geq \frac{1}{2}$. In addition, we establish the exponential stability of the fully discrete solution. The error analysis shows a first-order convergence rate of the state variable in the discrete $L^{2}$-, $H^{1}$-, and $L^{\infty}$-norms for $\theta \geq \frac{1}{2}$, while preserving the exponential stability property. A first-order convergence rate for the boundary control inputs is also obtained. Numerical experiments are conducted to validate the theoretical findings and to demonstrate the effectiveness of the method for the inhomogeneous nonlinear Neumann boundary feedback control of the viscous Burgers' equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00317v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shishu Pal Singh, Sudeep Kundu</dc:creator>
    </item>
    <item>
      <title>Finite Element Analysis for the Chafee-Infante Equation Using Distributed Feedback Control</title>
      <link>https://arxiv.org/abs/2512.00320</link>
      <description>arXiv:2512.00320v1 Announce Type: cross 
Abstract: In this paper, we propose a \( C^0 \)-conforming finite element method for the Chafee-Infante equation with a finite-parameter feedback control. We establish error analysis for both the state variable and the control variable for the spatially discretized solution. Furthermore, we employ the backward Euler method for time discretization and discuss the stability analysis of the fully discrete scheme. Additionally, we develop error estimates for both the state variable and the control input in the fully discrete setting. Finally, we verify our theoretical conclusions using some numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00320v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shishu Pal Singh, Sudeep Kundu</dc:creator>
    </item>
    <item>
      <title>Exposed extreme rays of the SONC cone</title>
      <link>https://arxiv.org/abs/2512.00348</link>
      <description>arXiv:2512.00348v1 Announce Type: cross 
Abstract: We provide a complete and explicit characterization of the exposed extreme rays of the cone of sums of nonnegative circuit (SONC) polynomials. The criterion we derive is purely combinatorial and depends only on the existence of certain circuits within the ground set and on the nature of the corresponding extreme ray. Our constructive proofs also yield explicit exposing functionals, offering a basis for algorithmic detection of exposed rays in SONC-based optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00348v1</guid>
      <category>math.AG</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mareike Dressler, Hongzhi Liao, Vera Roshchina</dc:creator>
    </item>
    <item>
      <title>No-Regret Gaussian Process Optimization of Time-Varying Functions</title>
      <link>https://arxiv.org/abs/2512.00517</link>
      <description>arXiv:2512.00517v1 Announce Type: cross 
Abstract: Sequential optimization of black-box functions from noisy evaluations has been widely studied, with Gaussian Process bandit algorithms such as GP-UCB guaranteeing no-regret in stationary settings. However, for time-varying objectives, it is known that no-regret is unattainable under pure bandit feedback unless strong and often unrealistic assumptions are imposed.
  In this article, we propose a novel method to optimize time-varying rewards in the frequentist setting, where the objective has bounded RKHS norm. Time variations are captured through uncertainty injection (UI), which enables heteroscedastic GP regression that adapts past observations to the current time step. As no-regret is unattainable in general in the strict bandit setting, we relax the latter allowing additional queries on previously observed points. Building on sparse inference and the effect of UI on regret, we propose \textbf{W-SparQ-GP-UCB}, an online algorithm that achieves no-regret with only a vanishing number of additional queries per iteration. To assess the theoretical limits of this approach, we establish a lower bound on the number of additional queries required for no-regret, proving the efficiency of our method. Finally, we provide a comprehensive analysis linking the degree of time-variation of the function to achievable regret rates, together with upper and lower bounds on the number of additional queries needed in each regime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00517v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Eliabelle Mauduit, Elo\"ise Berthier, Andrea Simonetto</dc:creator>
    </item>
    <item>
      <title>Peng's Maximum Principle for Stochastic Delay Differential Equations of Mean-Field Type</title>
      <link>https://arxiv.org/abs/2512.00934</link>
      <description>arXiv:2512.00934v1 Announce Type: cross 
Abstract: We extend Peng's maximum principle to the case of stochastic delay differential equations of mean-field type. More precisely, the coefficients of our control problem depend on the state, on the past trajectory and on its expected value. Moreover, the control enters the noise coefficient and the control domain may be non-convex. Our approach is based on a lifting of the state equation to an infinite dimensional Hilbert space that removes the explicit delay in the state equation. The main ingredient in the proof of the maximum principle is a precise asymptotic for the expectation of the first order variational process, which allows us to neglect the corresponding second order terms in the expansion of the cost functional.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00934v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giuseppina Guatteri, Federica Masiero, Lukas Wessels</dc:creator>
    </item>
    <item>
      <title>Mechanism Design with Spiteful Agents</title>
      <link>https://arxiv.org/abs/2512.01021</link>
      <description>arXiv:2512.01021v1 Announce Type: cross 
Abstract: We study a mechanism-design problem in which spiteful agents strive to not only maximize their rewards but also, contingent upon their own payoff levels, seek to lower the opponents' rewards. We characterize all individually rational (IR) and incentive-compatible (IC) mechanisms that are immune to such spiteful behavior, showing that they take the form of threshold mechanisms with an ordering of the agents. Building on this characterization, we prove two impossibility results: under either anonymity or efficiency, any such IR and IC mechanism collapses to the null mechanism, which never allocates the item to any agent. Leveraging these findings, we partially extend our analysis to a multi-item setup. These results illuminate the challenges of auctioning items in the natural presence of other-regarding preferences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01021v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aditya Aradhye, David Lagziel, Eilon Solan</dc:creator>
    </item>
    <item>
      <title>The Silence that Speaks: Neural Estimation via Communication Gaps</title>
      <link>https://arxiv.org/abs/2512.01056</link>
      <description>arXiv:2512.01056v1 Announce Type: cross 
Abstract: Accurate remote state estimation is a fundamental component of many autonomous and networked dynamical systems, where multiple decision-making agents interact and communicate over shared, bandwidth-constrained channels. These communication constraints introduce an additional layer of complexity, namely, the decision of when to communicate. This results in a fundamental trade-off between estimation accuracy and communication resource usage. Traditional extensions of classical estimation algorithms (e.g., the Kalman filter) treat the absence of communication as 'missing' information. However, silence itself can carry implicit information about the system's state, which, if properly interpreted, can enhance the estimation quality even in the absence of explicit communication. Leveraging this implicit structure, however, poses significant analytical challenges, even in relatively simple systems. In this paper, we propose CALM (Communication-Aware Learning and Monitoring), a novel learning-based framework that jointly addresses the dual challenges of communication scheduling and estimator design. Our approach entails learning not only when to communicate but also how to infer useful information from periods of communication silence. We perform comparative case studies on multiple benchmarks to demonstrate that CALM is able to decode the implicit coordination between the estimator and the scheduler to extract information from the instances of 'silence' and enhance the estimation accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01056v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shubham Aggarwal, Dipankar Maity, Tamer Ba\c{s}ar</dc:creator>
    </item>
    <item>
      <title>Bayesian dynamic scheduling of multipurpose batch processes under incomplete look-ahead information</title>
      <link>https://arxiv.org/abs/2512.01093</link>
      <description>arXiv:2512.01093v1 Announce Type: cross 
Abstract: Multipurpose batch processes become increasingly popular in manufacturing industries since they adapt to low-volume, high-value products and shifting demands. These processes often operate in a dynamic environment, which faces disturbances such as processing delays and demand changes. To minimise long-term cost and system nervousness (i.e., disruptive changes to schedules), schedulers must design rescheduling strategies to address such disturbances effectively. Existing methods often assume complete look-ahead information over the scheduling horizon. This assumption contrasts with realistic situations where schedulers can only access incomplete look-ahead information. Sticking with existing methods may lead to suboptimal long-term costs and high-level system nervousness. In this work we propose a Bayesian dynamic scheduling method. Our method relies on learning a Bayesian Network from the probability distribution of disturbances. Specifically, the Bayesian Network represents how likely each operation will be impacted by disturbances. During the online execution, when new disturbances become observed, this method updates the posterior distribution and therefore guides the rescheduling strategy. We compare our method with the existing periodic rescheduling strategy (which generates new schedules from scratch at fixed intervals) on four benchmark problems. Computational results show that our method achieves statistically better long-term costs and system nervousness. In the theoretical aspect, we prove that if disturbances are mutually independent, the impact-quantifying variables inherently satisfy the independence assumptions required by Bayesian Networks. As an implication, practitioners can extend the method to other scheduling problems (such as job shop scheduling and continuous processes), given that they define the problem-specific dependencies between operations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01093v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taicheng Zheng, Dan Li, Jie Li</dc:creator>
    </item>
    <item>
      <title>High-dimensional Mean-Field Games by Particle-based Flow Matching</title>
      <link>https://arxiv.org/abs/2512.01172</link>
      <description>arXiv:2512.01172v1 Announce Type: cross 
Abstract: Mean-field games (MFGs) study the Nash equilibrium of systems with a continuum of interacting agents, which can be formulated as the fixed-point of optimal control problems. They provide a unified framework for a variety of applications, including optimal transport (OT) and generative models. Despite their broad applicability, solving high-dimensional MFGs remains a significant challenge due to fundamental computational and analytical obstacles. In this work, we propose a particle-based deep Flow Matching (FM) method to tackle high-dimensional MFG computation. In each iteration of our proximal fixed-point scheme, particles are updated using first-order information, and a flow neural network is trained to match the velocity of the sample trajectories in a simulation-free manner. Theoretically, in the optimal control setting, we prove that our scheme converges to a stationary point sublinearly, and upgrade to linear (exponential) convergence under additional convexity assumptions. Our proof uses FM to induce an Eulerian coordinate (density-based) from a Lagrangian one (particle-based), and this also leads to certain equivalence results between the two formulations for MFGs when the Eulerian solution is sufficiently regular. Our method demonstrates promising performance on non-potential MFGs and high-dimensional OT problems cast as MFGs through a relaxed terminal-cost formulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01172v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiajia Yu, Junghwan Lee, Yao Xie, Xiuyuan Cheng</dc:creator>
    </item>
    <item>
      <title>Enhanced Single-Photon Detector: Achieving Superconducting-Level Performance with Conventional Quantum Technology</title>
      <link>https://arxiv.org/abs/2512.01328</link>
      <description>arXiv:2512.01328v1 Announce Type: cross 
Abstract: High-performance single-photon detectors (SPDs) are indispensable components for quantum optical tasks. However, the reliance of state-of-the-art devices on superconducting materials imposes severe technological demands and challenging operational conditions (e.g., cryogenics), which hinder scalable commercial deployment. To address this, we propose the Enhanced Single-Photon Detector (ESPD) framework, a novel paradigm for achieving high-performance SPDs through the iterative enhancement of low-technology SPDs. Utilizing only standard quantum optical components, the ESPD scheme transforms a legacy non-superconducting SPD, with detection efficiency (DE) about $59\%$ and dark count rate (DCR) $10^{-2}$, into a device with superior performance metrics, achieving DE higher than $95\%$ and DCR below $10^{-9}$. This level of performance is comparable to or surpasses recently designed superconducting SPDs, allowing the minimal tolerable channel transmission rate for Quantum Key Distribution (QKD) protocols to be reduced by several orders of magnitude. Furthermore, the scheme's device requirements are moderate, relying on readily available current technology, which ensures near-term experimental feasibility. The ESPD framework thus provides a clear, scalable path toward the large-scale deployment of high-performance SPDs and the commercialization of quantum communication technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01328v1</guid>
      <category>quant-ph</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Shu</dc:creator>
    </item>
    <item>
      <title>In-context Inverse Optimality for Fair Digital Twins: A Preference-based approach</title>
      <link>https://arxiv.org/abs/2512.01650</link>
      <description>arXiv:2512.01650v1 Announce Type: cross 
Abstract: Digital Twins (DTs) are increasingly used as autonomous decision-makers in complex socio-technical systems. Their mathematically optimal decisions often diverge from human expectations, exposing a persistent gap between algorithmic and bounded human rationality. This work addresses this gap by proposing a framework that operationalizes fairness as a learnable objective within optimization-based Digital Twins. We introduce a preference-driven learning pipeline that infers latent fairness objectives directly from human pairwise preferences over feasible decisions. A novel Siamese neural network is developed to generate convex quadratic cost functions conditioned on contextual information. The resulting surrogate objectives align optimization outcomes with human-perceived fairness while maintaining computational efficiency. The approach is demonstrated on a COVID-19 hospital resource allocation scenario. This study provides an actionable path toward embedding human-centered fairness in the design of autonomous decision-making systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01650v1</guid>
      <category>cs.LG</category>
      <category>cs.SE</category>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniele Masti, Francesco Basciani, Arianna Fedeli, Girgio Gnecco, Francesco Smarra</dc:creator>
    </item>
    <item>
      <title>Integrating Artificial Intelligence and Mixed Integer Linear Programming: Explainable Graph-Based Instance Space Analysis in Air Transportation</title>
      <link>https://arxiv.org/abs/2512.01698</link>
      <description>arXiv:2512.01698v1 Announce Type: cross 
Abstract: This paper analyzes the integration of artificial intelligence (AI) with mixed integer linear programming (MILP) to address complex optimization challenges in air transportation with explainability. The study aims to validate the use of Graph Neural Networks (GNNs) for extracting structural feature embeddings from MILP instances, using the air05 crew scheduling problem. The MILP instance was transformed into a heterogeneous bipartite graph to model relationships between variables and constraints. Two neural architectures, Graph Convolutional Networks (GCN) and Graph Attention Networks (GAT) were trained to generate node embeddings. These representations were evaluated using Instance Space Analysis (ISA) through linear (PCA) and non-linear (UMAP, t-SNE) dimensionality reduction techniques. Analysis revealed that PCA failed to distinguish cluster structures, necessitating non-linear reductions to visualize the embedding topology. The GCN architecture demonstrated superior performance, capturing global topology with well-defined clusters for both variables and constraints. In contrast, the GAT model failed to organize the constraint space. The findings confirm that simpler graph architectures can effectively map the sparse topology of aviation logistics problems without manual feature engineering, contributing to explainability of instance complexity. This structural awareness provides a validated foundation for developing future Learning to Optimize (L2O) agents capable of improving solver performance in safety-critical environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01698v1</guid>
      <category>cs.CE</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Artur Guerra Rosa, Felipe Tavares Loureiro, Marcus Vinicius Santos da Silva, Andr\'eia Elizabeth Silva Barros, Silvia Ara\'ujo dos Reis, Victor Rafael Rezende Celestino</dc:creator>
    </item>
    <item>
      <title>Beyond Scaffold: A Unified Spatio-Temporal Gradient Tracking Method</title>
      <link>https://arxiv.org/abs/2512.01732</link>
      <description>arXiv:2512.01732v1 Announce Type: cross 
Abstract: In distributed and federated learning algorithms, communication overhead is often reduced by performing multiple local updates between communication rounds. However, due to data heterogeneity across nodes and the local gradient noise within each node, this strategy can lead to the drift of local models away from the global optimum. To address this issue, we revisit the well-known federated learning method Scaffold (Karimireddy et al., 2020) under a gradient tracking perspective, and propose a unified spatio-temporal gradient tracking algorithm, termed ST-GT, for distributed stochastic optimization over time-varying graphs. ST-GT tracks the global gradient across neighboring nodes to mitigate data heterogeneity, while maintaining a running average of local gradients to substantially suppress noise, with slightly more storage overhead. Without assuming bounded data heterogeneity, we prove that ST-GT attains a linear convergence rate for strongly convex problems and a sublinear rate for nonconvex cases. Notably, ST-GT achieves the first linear speed-up in communication complexity with respect to the number of local updates per round $\tau$ for the strongly-convex setting. Compared to traditional gradient tracking methods, ST-GT reduces the topology-dependent noise term from $\sigma^2$ to $\sigma^2/\tau$, where $\sigma^2$ denotes the noise level, thereby improving communication efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01732v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yan Huang, Jinming Xu, Jiming Chen, Karl Henrik Johansson</dc:creator>
    </item>
    <item>
      <title>A novel sequential method for building upper and lower bounds of moments of distributions</title>
      <link>https://arxiv.org/abs/2512.01761</link>
      <description>arXiv:2512.01761v1 Announce Type: cross 
Abstract: Approximating integrals is a fundamental task in probability theory and statistical inference, and their applied fields of signal processing, and Bayesian learning, as soon as expectations over probability distributions must be computed efficiently and accurately. When these integrals lack closed-form expressions, numerical methods must be used, from the Newton-Cotes formulas and Gaussian quadrature, to Monte Carlo and variational approximation techniques. Despite these numerous tools, few are guaranteed to preserve majoration/minoration inequalities, while this feature is fundamental in certain applications in statistics. In this paper, we focus on the integration problem arising in the estimation of moments of scalar, unnormalized, distributions. We introduce a sequential method for constructing upper and lower bounds on the sought integral. Our approach leverages the majorization-minimization framework to iteratively refine these bounds, in an enveloped principle. The method has proven convergence, and controlled accuracy, under mild conditions. We demonstrate its effectiveness through a detailed numerical example of the estimation of a Monte-Carlo sampler variance in a Bayesian inference problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01761v1</guid>
      <category>math.ST</category>
      <category>math.OC</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Solal Martin, Emilie Chouzenoux, Victor Elvira</dc:creator>
    </item>
    <item>
      <title>Event-triggered control of nonlinear systems from data</title>
      <link>https://arxiv.org/abs/2512.01938</link>
      <description>arXiv:2512.01938v1 Announce Type: cross 
Abstract: In a recent paper [8], we introduced a data-based approach to design event-triggered controllers for linear systems directly from data. Here, we extend the results in [8] to a class of nonlinear systems. We provide two data-based designs certified by a (classical) Lyapunov function. For these two designs, we devise event-triggered policies that rely on the previously found Lyapunov function, have parameters tuned from data, ensure a positive minimum inter-event time, and act based either on the state error or on the library error. These two different policies, and their respective advantages, are illustrated numerically.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01938v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hailong Chen, Claudio De Persis, Andrea Bisoffi, Pietro Tesi</dc:creator>
    </item>
    <item>
      <title>A Dual Approach for Hierarchical Information-Theoretic Tree Abstractions</title>
      <link>https://arxiv.org/abs/2512.01985</link>
      <description>arXiv:2512.01985v1 Announce Type: cross 
Abstract: In this paper, we consider establishing a formal connection between two distinct tree-abstraction problems inspired by the information-bottleneck (IB) method. Specifically, we consider the hard- and soft-constrained formulations that have recently appeared in the literature to determine the conditions for which the two approaches are equivalent. Our analysis leverages concepts from Lagrangian relaxation and duality theory to relate the dual function of the hard-constrained problem to the Q-function employed in Q-tree search and shows the connection between tree phase transitions and solutions to the dual problem obtained by exploiting the problem structure. An algorithm is proposed that employs knowledge of the tree phase transitions to find a setting of the dual variable that solves the dual problem. Furthermore, we present an alternative approach to select the dual variable that leverages the integer programming formulation of the hard-constrained problem and the strong duality of linear programming. To obtain a linear program, we establish that a relaxation of the integer programming formulation of the hard-constrained tree-search problem has the integrality property by showing that the program constraint matrix is totally unimodular. Empirical results that corroborate the theoretical developments are presented and discussed throughout.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01985v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel T. Larsson, Dipankar Maity, Panagiotis Tsiotras</dc:creator>
    </item>
    <item>
      <title>Adaptive Matrix Sparsification and Applications to Empirical Risk Minimization</title>
      <link>https://arxiv.org/abs/2512.02003</link>
      <description>arXiv:2512.02003v1 Announce Type: cross 
Abstract: Consider the empirical risk minimization (ERM) problem, which is stated as follows. Let $K_1, \dots, K_m$ be compact convex sets with $K_i \subseteq \mathbb{R}^{n_i}$ for $i \in [m]$, $n = \sum_{i=1}^m n_i$, and $n_i\le C_K$ for some absolute constant $C_K$. Also, consider a matrix $A \in \mathbb{R}^{n \times d}$ and vectors $b \in \mathbb{R}^d$ and $c \in \mathbb{R}^n$. Then the ERM problem asks to find \[ \min_{\substack{x \in K_1 \times \dots \times K_m\\ A^\top x = b}}
  c^\top x. \] We give an algorithm to solve this to high accuracy in time $\widetilde{O}(nd + d^6\sqrt{n}) \le \widetilde{O} (nd + d^{11})$, which is nearly-linear time in the input size when $A$ is dense and $n \ge d^{10}$.
  Our result is achieved by implementing an $\widetilde{O}(\sqrt{n})$-iteration interior point method (IPM) efficiently using dynamic data structures. In this direction, our key technical advance is a new algorithm for maintaining leverage score overestimates of matrices undergoing row updates. Formally, given a matrix $A \in \mathbb{R}^{n \times d}$ undergoing $T$ batches of row updates of total size $n$ we give an algorithm which can maintain leverage score overestimates of the rows of $A$ summing to $\widetilde{O}(d)$ in total time $\widetilde{O}(nd + Td^6)$. This data structure is used to sample a spectral sparsifier within a robust IPM framework to establish the main result.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02003v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang P. Liu, Richard Peng, Colin Tang, Albert Weng, Junzhao Yang</dc:creator>
    </item>
    <item>
      <title>Sparse PCA With Multiple Components</title>
      <link>https://arxiv.org/abs/2209.14790</link>
      <description>arXiv:2209.14790v4 Announce Type: replace 
Abstract: Sparse Principal Component Analysis (sPCA) is a cardinal technique for obtaining combinations of features, or principal components (PCs), that explain the variance of high-dimensional datasets in an interpretable manner. This involves solving a sparsity and orthogonality constrained convex maximization problem, which is extremely computationally challenging. Most existing works address sparse PCA via methods-such as iteratively computing one sparse PC and deflating the covariance matrix-that do not guarantee the orthogonality, let alone the optimality, of the resulting solution when we seek multiple mutually orthogonal PCs. We challenge this status by reformulating the orthogonality conditions as rank constraints and optimizing over the sparsity and rank constraints simultaneously. We design tight semidefinite relaxations to supply high-quality upper bounds, which we strengthen via additional second-order cone inequalities when each PC's individual sparsity is specified. Further, we derive a combinatorial upper bound on the maximum amount of variance explained as a function of the support. We exploit these relaxations and bounds to propose exact methods and rounding mechanisms that, together, obtain solutions with a bound gap on the order of 0%-15% for real-world datasets with p = 100s or 1000s of features and r \in {2, 3} components. Numerically, our algorithms match (and sometimes surpass) the best performing methods in terms of fraction of variance explained and systematically return PCs that are sparse and orthogonal. In contrast, we find that existing methods like deflation return solutions that violate the orthogonality constraints, even when the data is generated according to sparse orthogonal PCs. Altogether, our approach solves sparse PCA problems with multiple components to certifiable (near) optimality in a practically tractable fashion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.14790v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryan Cory-Wright, Jean Pauphilet</dc:creator>
    </item>
    <item>
      <title>Solving Convex Smooth Function Constrained Optimization Is Almost As Easy As Unconstrained Optimization</title>
      <link>https://arxiv.org/abs/2210.05807</link>
      <description>arXiv:2210.05807v4 Announce Type: replace 
Abstract: While Nesterov's Accelerated Gradient Descent (AGD) efficiently solves constrained problems when the constraint set $X \subseteq \mathbb{R}^n$ is simple and easy to project onto, it remains an open question whether function-constrained problems $\min_{x \in X} \{F(x) : g(x) \leq 0\}$ can be solved as efficiently as unconstrained problems in terms of oracle complexity. We provide an affirmative answer by proposing the Accelerated Constrained Gradient Descent (ACGD) method, a single-loop algorithm that modifies AGD by replacing the descent step with a constrained descent step, adding only a few linear constraints to the prox mapping. ACGD achieves nearly the same oracle complexity as minimizing the optimal Lagrangian function (with the multiplier fixed at its optimal value). We establish matching lower bounds, demonstrating these complexity results are unimprovable. For large-scale problems with many constraints, we introduce ACGD-S, which replaces the computationally demanding constrained descent step with basic matrix-vector multiplications, maintaining optimal oracle and computation complexities. Together, these methods provide a nearly complete characterization of the hardness of smooth function-constrained optimization. We also propose parameter-free adaptive versions that achieve optimal oracle complexity (requiring only the strong convexity modulus) and present encouraging numerical results demonstrating their efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.05807v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhe Zhang, Guanghui Lan</dc:creator>
    </item>
    <item>
      <title>Variational Properties of Decomposable Functions. Part II: Strong Second-Order Theory</title>
      <link>https://arxiv.org/abs/2311.07276</link>
      <description>arXiv:2311.07276v3 Announce Type: replace 
Abstract: Local superlinear convergence of the semismooth Newton method usually necessitates assumptions on the uniform invertibility of the utilized, generalized Jacobian matrices, such as, e.g., BD- or CD-regularity. For certain composite-type problems and nonlinear programs (for which explicit representations of the generalized Jacobians of the associated stationarity equations are available), such regularity assumptions are closely connected to strong second-order sufficient conditions. However, general characterizations are not well understood. In this paper, we investigate a strong second-order sufficient condition ($\mathrm{SSOSC}$) for composite problems whose nonsmooth part has a generalized conic-quadratic second subderivative. We discuss the relationship between the $\mathrm{SSOSC}$ and other second order-type conditions that involve the generalized Jacobians of the normal map. In particular, these two conditions are equivalent under certain structural assumptions on the generalized Jacobian matrix of the proximity operator. Leveraging second-order variational techniques and properties, we then verify that the introduced structural conditions hold for a broad class of $C^2$-strictly decomposable functions. Finally, it is shown that the $\mathrm{SSOSC}$ is further equivalent to the strong metric regularity of the subdifferential, the normal map, and the natural residual.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.07276v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenqing Ouyang, Andre Milzarek</dc:creator>
    </item>
    <item>
      <title>Dynamical State Feedback Control for Linear Input Delay Systems, Part I: Dissipative Stabilization via Semidefinite Programming</title>
      <link>https://arxiv.org/abs/2311.14944</link>
      <description>arXiv:2311.14944v3 Announce Type: replace 
Abstract: We propose an SDP-based framework to address the stabilization of input delay systems while taking into account dissipative constraints. A key to our approach is the introduction of the concept of parameterized linear dynamical state feedbacks (LDSFs), which draws inspiration from recent advancements in the analyses of distributed delays. The parameterized LDSFs generalize conventional predictor controllers, where the interpretation of state prediction is concealed and their degree of parameterization can be increased by adjusting the integral kernels. A sufficient condition for the existence of dissipative LDSFs is formulated as matrix inequalities by constructing a complete type Krasovski\u{\i} functional. To solve the bilinear matrix inequality in the synthesis condition, we employ an off-line inner convex approximation algorithm that can be initialized using the gains of predictor controllers obtained via explicit construction. So the unknowns of our LTDS can be computed by solving convex semidefinite programs. Numerical examples and simulations were experimented to demonstrate the validity and effectiveness of our methodology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.14944v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qian Feng, Cong Zhang, Bo Wei</dc:creator>
    </item>
    <item>
      <title>A parallel framework for graphical optimal transport</title>
      <link>https://arxiv.org/abs/2406.10849</link>
      <description>arXiv:2406.10849v2 Announce Type: replace 
Abstract: We study multi-marginal optimal transport (MOT) problems where the underlying cost has a graphical structure. These graphical multi-marginal optimal transport problems have found applications in several domains including traffic flow control, barycenter and regression problems in the Wasserstein space, and Hidden Markov model inference problems. The MOT problem can be approached through two formulations: a single big MOT problem, or coupled minor OT problems. In this paper, we focus on the latter approach and demonstrate its efficiency gain from parallelization. For tree-structured MOT problems, we introduce a novel parallelizable algorithm that significantly reduces computational complexity. Additionally, we adapt this algorithm for general graphs, employing the modified junction trees to enable parallel updates. Our contributions, validated through numerical experiments, offer new avenues for MOT applications and establish benchmarks in computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10849v2</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiaojiao Fan, Isabel Haasler, Qinsheng Zhang, Johan Karlsson, Yongxin Chen</dc:creator>
    </item>
    <item>
      <title>Fortifying Critical Infrastructure Networks with Multicriteria Portfolio Decision Analysis: An Application to Railway Stations in Finland</title>
      <link>https://arxiv.org/abs/2501.06279</link>
      <description>arXiv:2501.06279v3 Announce Type: replace 
Abstract: Advanced societies are crucially dependent on critical infrastructure networks for the reliable delivery of essential goods and services. Hence, well-founded analyses concerning disruptions are necessary to inform decisions that aim to ensure the performance of these networks in the face of failures caused by vulnerabilities to external hazards or technical malfunctions. In this setting, we develop an approach based on multicriteria decision analysis to support the identification of cost-efficient portfolios of preventive fortification actions. Our approach (i) accounts for multiple performance objectives, such as those that maximize the uninterrupted volume of traffic between different origin-destination pairs in a transportation network, (ii) uses methods of probabilistic risk assessment to quantify the expected performance of the network with regard to these objectives, and (iii) uses a search algorithm combined with an optimization model to identify those combinations of fortification actions that are cost-efficient in improving the performance of the network, given the available, possibly partial information about the relative importance of objectives and minimum performance requirements on them. Our methodological contributions are illustrated by a case study on the analysis of railway switches at a representative Finnish railway station.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.06279v3</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ress.2025.112006</arxiv:DOI>
      <arxiv:journal_reference>Reliability Engineering and System Safety, 268, 2025, 112006</arxiv:journal_reference>
      <dc:creator>Joaqu\'in de la Barra, Ahti Salo, Leevi Olander, Kash Barker, Jussi Kangaspunta</dc:creator>
    </item>
    <item>
      <title>Social Optimization in Noncooperative Games under Central Regulation</title>
      <link>https://arxiv.org/abs/2503.17100</link>
      <description>arXiv:2503.17100v2 Announce Type: replace 
Abstract: Motivated by the increasing attention to overall social benefits in networked multi-agent systems, this paper investigates an optimization problem building on noncooperative games under high-level regulation, which can be formulated in a bilevel structure. Specifically, the low level consists of a noncooperative game, where each player competes to minimize its own cost function that depends not only on the strategies of all players, but also on an intervention decision of a regulator located at the high level. Under the intervention of the high-level regulator, the low-level players aim to seek a Nash equilibrium (NE), which indeed is related to the regulator's decision. Meanwhile, the regulator in the high level attempts to achieve the social optimum, that is, to minimize the sum of all players' costs obtained at the NE. This bilevel social optimization problem is proven to be nonconvex and nonsmooth, leading to challenges for solving it effectively, as the exact gradient of cost sum functions may not be available. To address this intricate problem, an inexact zeroth-order algorithm is developed by virtue of the smoothing techniques, allowing for approximating the NE of the low-level game and thus estimating the required gradients. It is rigorously shown that the devised algorithm achieves a sublinear convergence rate for computing an approximate stationary point of the studied problem. Moreover, the sublinear convergence rate in the scenario where the exact equilibrium of the low-level game is available is established. Finally, numerical simulations are conducted to demonstrate the efficiency of theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17100v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaixin Du, Min Meng, Xiaoming Hu</dc:creator>
    </item>
    <item>
      <title>Differentiable Optimization for Deep Learning-Enhanced DC Approximation of AC Optimal Power Flow</title>
      <link>https://arxiv.org/abs/2504.01970</link>
      <description>arXiv:2504.01970v2 Announce Type: replace 
Abstract: The growing scale of power systems and the increasing uncertainty introduced by renewable energy sources necessitates novel optimization techniques that are significantly faster and more accurate than existing methods. The AC Optimal Power Flow (AC-OPF) problem, a core component of power grid optimization, is often approximated using linearized DC Optimal Power Flow (DC-OPF) models for computational tractability, albeit at the cost of suboptimal and inefficient decisions. To address these limitations, we propose a novel deep learning-based framework for network equivalency that enhances DC-OPF to more closely mimic the behavior of AC-OPF. The approach utilizes recent advances in differentiable optimization, incorporating a neural network trained to predict adjusted nodal shunt conductances and branch susceptances in order to account for nonlinear power flow behavior. The model can be trained end-to-end using modern deep learning frameworks by leveraging the implicit function theorem. Results demonstrate the framework's ability to significantly improve prediction accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01970v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew Rosemberg, Michael Klamkin, Pascal Van Hentenryck</dc:creator>
    </item>
    <item>
      <title>Mean Field Control with Poissonian Common Noise: A Pathwise Compactification Approach</title>
      <link>https://arxiv.org/abs/2505.23441</link>
      <description>arXiv:2505.23441v3 Announce Type: replace 
Abstract: This paper contributes to the compactification approach to study mean-field control problems with Poissonian common noise. To overcome the lack of compactness and continuity issues caused by common noise, we exploit the point process representation of the Poisson random measure with finite intensity and propose a pathwise formulation in a two-step procedure by freezing a sample path of the common noise. In the first step, we establish the existence of the optimal relaxed control in the pathwise formulation as if common noise is absent, but with finite deterministic jumping times. The second step plays the key role in our approach, which is to aggregate the optimal solutions in the pathwise formulation over all sample paths of common noise and show that it yields an optimal solution in the original model. To this end, with the help of concatenation techniques, we first develop a pathwise superposition principle in the model with deterministic jumping times, drawing a relationship between the pathwise relaxed control problem and the pathwise measure-valued control problem. As a result, we can further bridge the equivalence among different problem formulations and verify that the constructed solution under aggregation is indeed optimal in the original problem. We also extend the methodology to solve mean-field games with Poissonian common noise, confirming the existence of a strong mean field equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23441v3</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lijun Bo, Jingfei Wang, Xiaoli Wei, Xiang Yu</dc:creator>
    </item>
    <item>
      <title>Fully Coupled Nonlinear FBS$\Delta$Es: Maximum principle and LQ Control Insights</title>
      <link>https://arxiv.org/abs/2507.20075</link>
      <description>arXiv:2507.20075v2 Announce Type: replace 
Abstract: This paper investigates the optimal control problem for a class of nonlinear fully coupled forward-backward stochastic difference equations (FBS$\Delta$Es). Under the convexity assumption of the control domain, we establish a variational formula for the cost functional involving the Hamiltonian and adjoint system. Both necessary and sufficient conditions for optimal control are derived using the Pontryagin maximum principle. As an application, we present a linear quadratic optimal control problem to illustrate our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20075v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Zhipeng Niu, Jun Moon, Qingxin Meng</dc:creator>
    </item>
    <item>
      <title>Regularization of Port-Hamiltonian Descriptor Systems</title>
      <link>https://arxiv.org/abs/2509.02715</link>
      <description>arXiv:2509.02715v2 Announce Type: replace 
Abstract: We study the regularization problem for port-Hamiltonian descriptor systems by proportional and/or derivative output feedback. Necessary and sufficient conditions are given, which guarantee that there exist output feedbacks such that the closed-loop system is regular, has index at most one, and is still port-Hamiltonian with desired rank properties. All results are derived based on condensed forms, computations of these condensed form can be implemented using only orthogonal transformations and hence are numerically reliable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02715v2</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Delin Chu, Volker Mehrmann</dc:creator>
    </item>
    <item>
      <title>Distance Between Stochastic Linear Systems</title>
      <link>https://arxiv.org/abs/2509.04014</link>
      <description>arXiv:2509.04014v3 Announce Type: replace 
Abstract: While the existing stochastic control theory is well equipped to handle dynamical systems with stochastic uncertainties, a paradigm shift using distance measure based decision making is required for the effective further exploration of the field. As a first step, a distance measure between two stochastic linear time invariant systems is proposed here, extending the existing distance metrics between deterministic linear dynamical systems. In the frequency domain, the proposed distance measure corresponds to the worst-case point-wise in frequency Wasserstein distance between distributions characterising the uncertainties using inverse stereographic projection on the Riemann sphere. For the time domain setting, the proposed distance corresponds to the gap metric induced type-q Wasserstein distance between the distributions characterising the uncertainty of plant models. Apart from providing lower and upper bounds for the proposed distance measures in both frequency and time domain settings, it is proved that the former never exceeds the latter. The proposed distance measures will facilitate the provision of probabilistic guarantees on system robustness and controller performances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04014v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Venkatraman Renganathan, Sei Zhen Khong</dc:creator>
    </item>
    <item>
      <title>Convergence Filters for Efficient Economic MPC of Non-dissipative Systems</title>
      <link>https://arxiv.org/abs/2509.11869</link>
      <description>arXiv:2509.11869v2 Announce Type: replace 
Abstract: This note presents a novel, efficient economic model predictive control (EMPC) scheme for non-dissipative systems subject to state and input constraints. A new conception of convergence filters is defined to address the stability issue of EMPC for constrained non-dissipative systems. Three convergence filters are designed accordingly to be imposed into the receding horizon optimization problem of EMPC. To improve online computational efficiency, the variable horizon idea without explicit terminal state constraints is adopted to compromise the convergence speed, economic performance, and computational burden of EMPC. Moreover, sufficient conditions are derived to guarantee the recursive feasibility and stability of the EMPC. The advantages of the proposed EMPC are validated by a classical non-dissipative continuous stirred-tank reactor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11869v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Defeng He, Weiliang Xiong, Shiqiang He, Haiping Du</dc:creator>
    </item>
    <item>
      <title>Differentiable-by-design Nonlinear Optimization for Model Predictive Control</title>
      <link>https://arxiv.org/abs/2509.12692</link>
      <description>arXiv:2509.12692v3 Announce Type: replace 
Abstract: Nonlinear optimization-based control policies, such as those those arising in nonlinear Model Predictive Control, have seen remarkable success in recent years. These policies require solving computationally demanding nonlinear optimization programs online at each time-step. The resulting solution map, viewed as a function of the measured state of the system and design parameters, may not be differentiable, which poses significant challenges if the control policy is embedded in a gradient-based policy optimization scheme. We propose a principled way to regularize the nonlinear optimization problem, obtaining a surrogate derivative even if when the original problem is not differentiable. The surrogate problem is differentiable by design and its solution map coincides with the solution of the unregularized problem. We demonstrate the effectiveness of our approach in a free-final-time optimal control problem and a receding-horizon nonlinear MPC example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.12692v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Riccardo Zuliani, Efe C. Balta, John Lygeros</dc:creator>
    </item>
    <item>
      <title>The fastest way through a traffic light</title>
      <link>https://arxiv.org/abs/2511.09530</link>
      <description>arXiv:2511.09530v2 Announce Type: replace 
Abstract: We give a rigorous solution of an optimisation problem of minimizing the expected delay caused by encountering a red traffic light on a road journey. The problem incorporates simple constraints on maximum speed, acceleration and braking rates, and depends on the assumed distribution of the remaining time until the traffic light will turn green, after it is first noticed. We assume that this distribution has a bounded and non-increasing density, which is natural since this holds for the law of the excess time in any stationary renewal process. In two special cases, where this distribution is either Uniform or Exponential, we give a complete characterisation of all possible combinations of phases of maximum acceleration, maximum speed, maximum braking, following an Euler--Lagrange curve, and standing stationary at the traffic light, which can make up an optimal solution. The key technique is to write the problem in terms of a two-dimensional pressure integral, so that the problem becomes analogous to filling a tank with a given quantity of liquid.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09530v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M\'arton Bal\'azs, Edward Crane, Alexander Tallis</dc:creator>
    </item>
    <item>
      <title>Adaptive SGD with Line-Search and Polyak Stepsizes: Nonconvex Convergence and Accelerated Rates</title>
      <link>https://arxiv.org/abs/2511.20207</link>
      <description>arXiv:2511.20207v4 Announce Type: replace 
Abstract: We extend the convergence analysis of AdaSLS and AdaSPS in [Jiang and Stich, 2024] to the nonconvex setting, presenting a unified convergence analysis of stochastic gradient descent with adaptive Armijo line-search (AdaSLS) and Polyak stepsize (AdaSPS) for nonconvex optimization. Our contributions include: (1) an $\mathcal{O}(1/\sqrt{T})$ convergence rate for general nonconvex smooth functions, (2) an $\mathcal{O}(1/T)$ rate under quasar-convexity and interpolation, and (3) an $\mathcal{O}(1/T)$ rate under the strong growth condition for general nonconvex functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.20207v4</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haotian Wu</dc:creator>
    </item>
    <item>
      <title>Singular extremals of optimal control problems with $L^1$ cost</title>
      <link>https://arxiv.org/abs/2511.21527</link>
      <description>arXiv:2511.21527v2 Announce Type: replace 
Abstract: We study the optimal control problem for a control-affine system, where we want to minimize the $L^1$ norm of the control. First, we show how Pontryagin Maximum Principle (PMP) applies to this problem and we divide the extremal trajectories into two categories: regular and singular extremals. Then, we obtain a strong generalized Legendre-Clebsch condition for singular extremals and we show that this condition together with the absence of conjugate points is sufficient to ensure local strong optimality. We provide also some geometric examples where we apply our results. Finally, we prove that generalized Legendre-Clebsch condition is necessary for optimality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21527v2</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrei Agrachev, Ivan Beschastnyi, Michele Motta</dc:creator>
    </item>
    <item>
      <title>Topography optimization for enhancing microalgal growth in raceway ponds</title>
      <link>https://arxiv.org/abs/2011.04913</link>
      <description>arXiv:2011.04913v2 Announce Type: replace-cross 
Abstract: Modelling the evolution process for the growth of microalgae in an artificial pond is a huge challenge, given the complex interaction between hydrodynamics and biological processes occurring across various timescales. In this paper, we consider a raceway, i.e., an oval pond where the water is set in motion by a paddle wheel. Our aim is to investigate theoretically and numerically the impact of bottom topography in such raceway ponds on microalgae growth. To achieve this goal, we consider a biological model based on the Han model, coupled with the Saint--Venant systems that model the fluid. We then formulate an optimization problem, for which we apply the weak maximum principle to characterize optimal topographies that maximize biomass production over one lap of the raceway pond or multiple laps with a paddle wheel. In contrast to a widespread belief in the field of microalgae, we show that a flat topography in a periodic regime satisfies the necessary optimality condition, and observe in the numerical experiments that the flat topography is actually optimal in this case. However, non-trivial topographies may be more advantageous in alternative scenarios, such as when considering the effects of mixing devices within the model. This study sheds light on the intricate relationship between bottom topography, fluid dynamics, and microalgae growth in raceway ponds, offering valuable insights into optimizing biomass production.</description>
      <guid isPermaLink="false">oai:arXiv.org:2011.04913v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Olivier Bernard (BIOCORE), Liu-Di Lu (BIOCORE, ANGE, LJLL), Jacques Sainte-Marie (ANGE, LJLL), Julien Salomon (ANGE, LJLL)</dc:creator>
    </item>
    <item>
      <title>Achieving Linear Speedup with ProxSkip in Distributed Stochastic Optimization</title>
      <link>https://arxiv.org/abs/2310.07983</link>
      <description>arXiv:2310.07983v4 Announce Type: replace-cross 
Abstract: The ProxSkip algorithm for distributed optimization is gaining increasing attention due to its effectiveness in reducing communication. However, existing analyses of ProxSkip are limited to the strongly convex setting and fail to achieve linear speedup with respect to the number of nodes. Key questions regarding its behavior in the non-convex setting and the achievability of linear speedup remain open. In this paper, we revisit ProxSkip and address both questions. We provide a comprehensive analysis for stochastic non-convex, convex, and strongly convex problems, revealing the effects of gradient noise, local updates, network connectivity, and data heterogeneity on its convergence. We prove that ProxSkip achieves linear speedup across all three settings, and can further achieve linear speedup with network-independent stepsizes in the strongly convex setting. Moreover, we show that properly increasing local updates effectively reduces communication complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.07983v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luyao Guo, Sulaiman A. Alghunaim, Kun Yuan, Laurent Condat, Jinde Cao</dc:creator>
    </item>
    <item>
      <title>Generalized Short Path Algorithms: Towards Super-Quadratic Speedup over Markov Chain Search for Combinatorial Optimization</title>
      <link>https://arxiv.org/abs/2410.23270</link>
      <description>arXiv:2410.23270v2 Announce Type: replace-cross 
Abstract: We analyze generalizations of quantum algorithms based on the short path framework first proposed by Hastings~[\textit{Quantum} 2, 78 (2018)], which has been extended and shown by Dalzell~et~al.~[STOC~'23] to achieve super-Grover speedups for certain binary optimization problems. We demonstrate that, under some commonly satisfied technical conditions, an appropriate generalization can achieve super-quadratic speedups not only over unstructured search but also over a classical optimization algorithm that searches for the optimum by drawing samples from the stationary distribution of a Markov chain. We employ this framework to obtain algorithms for problems including variants of Max Bisection, Max Independent Set, and finding the ground states of the Antiferromagnetic Ising Model and the Sherrington-Kirkpatrick Model, whose runtimes are asymptotically faster than those obtainable with previous short path techniques. In certain cases, our algorithms achieve super-quadratic speedups compared to the best known classical algorithms with rigorously established runtimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23270v2</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shouvanik Chakrabarti, Dylan Herman, Guneykan Ozgul, Shuchen Zhu, Brandon Augustino, Tianyi Hao, Zichang He, Ruslan Shaydulin, Marco Pistoia</dc:creator>
    </item>
    <item>
      <title>The Performance Of The Unadjusted Langevin Algorithm Without Smoothness Assumptions</title>
      <link>https://arxiv.org/abs/2502.03458</link>
      <description>arXiv:2502.03458v4 Announce Type: replace-cross 
Abstract: In this article, we study the problem of sampling from distributions whose densities are not necessarily smooth nor logconcave. We propose a simple Langevin-based algorithm that does not rely on popular but computationally challenging techniques, such as the Moreau-Yosida envelope or Gaussian smoothing, and show consequently that the performance of samplers like ULA does not necessarily degenerate arbitrarily with low regularity. In particular, we show that the Lipschitz or H\"older continuity assumption can be replaced by a geometric one-sided Lipschitz condition that allows even for discontinuous log-gradients. We derive non-asymptotic guarantees for the convergence of the algorithm to the target distribution in Wasserstein distances. Non-asymptotic bounds are also provided for the performance of the algorithm as an optimizer, specifically for the solution of associated excess risk optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03458v4</guid>
      <category>stat.ML</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.CO</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tim Johnston, Iosif Lytras, Nikolaos Makras, Sotirios Sabanis</dc:creator>
    </item>
    <item>
      <title>LORE: Lagrangian-Optimized Robust Embeddings for Visual Encoders</title>
      <link>https://arxiv.org/abs/2505.18884</link>
      <description>arXiv:2505.18884v2 Announce Type: replace-cross 
Abstract: Visual encoders have become fundamental components in modern computer vision pipelines. However, ensuring robustness against adversarial perturbations remains a critical challenge. Recent efforts have explored both supervised and unsupervised adversarial fine-tuning strategies. We identify two key limitations in these approaches: (i) they often suffer from instability, especially during the early stages of fine-tuning, resulting in suboptimal convergence and degraded performance on clean data, and (ii) they exhibit a suboptimal trade-off between robustness and clean data accuracy, hindering the simultaneous optimization of both objectives. To overcome these challenges, we propose Lagrangian-Optimized Robust Embeddings (LORE), a novel unsupervised adversarial fine-tuning framework. LORE utilizes constrained optimization, which offers a principled approach to balancing competing goals, such as improving robustness while preserving nominal performance. By enforcing embedding-space proximity constraints, LORE effectively maintains clean data performance throughout adversarial fine-tuning. Extensive experiments show that LORE significantly improves zero-shot adversarial robustness with minimal degradation in clean data accuracy. Furthermore, we demonstrate the effectiveness of the adversarially fine-tuned CLIP image encoder in out-of-distribution generalization and enhancing the interpretability of image embeddings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18884v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Borna Khodabandeh, Amirabbas Afzali, Amirhossein Afsharrad, Seyed Shahabeddin Mousavi, Sanjay Lall, Sajjad Amini, Seyed-Mohsen Moosavi-Dezfooli</dc:creator>
    </item>
    <item>
      <title>Sharpness of Minima in Deep Matrix Factorization: Exact Expressions</title>
      <link>https://arxiv.org/abs/2509.25783</link>
      <description>arXiv:2509.25783v3 Announce Type: replace-cross 
Abstract: Understanding the geometry of the loss landscape near a minimum is key to explaining the implicit bias of gradient-based methods in non-convex optimization problems such as deep neural network training and deep matrix factorization. A central quantity to characterize this geometry is the maximum eigenvalue of the Hessian of the loss, which measures the sharpness of the landscape. Currently, its precise role has been obfuscated because no exact expressions for this sharpness measure were known in general settings. In this paper, we present the first exact expression for the maximum eigenvalue of the Hessian of the squared-error loss at any minimizer in general overparameterized deep matrix factorization (i.e., deep linear neural network training) problems, resolving an open question posed by Mulayoff &amp; Michaeli (2020). This expression uncovers a fundamental property of the loss landscape of depth-2 matrix factorization problems: a minimum is flat if and only if it is spectral-norm balanced, which implies that flat minima are not necessarily Frobenius-norm balanced. Furthermore, to complement our theory, we empirically investigate an escape phenomenon observed during gradient-based training near a minimum that crucially relies on our exact expression of the sharpness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.25783v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anil Kamber, Rahul Parhi</dc:creator>
    </item>
    <item>
      <title>Equilibrium Portfolio Selection under Utility-Variance Analysis of Log Returns in Incomplete Markets</title>
      <link>https://arxiv.org/abs/2511.05861</link>
      <description>arXiv:2511.05861v2 Announce Type: replace-cross 
Abstract: This paper investigates a time-inconsistent portfolio selection problem in the incomplete mar ket model, integrating expected utility maximization with risk control. The objective functional
  balances the expected utility and variance on log returns, giving rise to time inconsistency and
  motivating the search of a time-consistent equilibrium strategy. We characterize the equilibrium
  via a coupled quadratic backward stochastic differential equation (BSDE) system and establish
  the existence theory in two special cases: (i)the two Brownian motions driven the price dynamics
  and the factor process are independent with $\rho = 0$; (ii) the trading strategy is constrained to
  be bounded. For the general case with correlation coefficient $\rho \neq 0$, we introduce the notion
  of an approximate time-consistent equilibrium. Employing the solution structure from the
  equilibrium in the case $\rho = 0$, we can construct an approximate time-consistent equilibrium in
  the general case with an error of order $O(\rho^2)$. Numerical examples and financial insights are
  also presented based on deep learning algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.05861v2</guid>
      <category>q-fin.PM</category>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yue Cao, Zongxia Liang, Sheng Wang, Xiang Yu</dc:creator>
    </item>
    <item>
      <title>PolyOCP.jl -- A Julia Package for Stochastic OCPs and MPC</title>
      <link>https://arxiv.org/abs/2511.19084</link>
      <description>arXiv:2511.19084v2 Announce Type: replace-cross 
Abstract: The consideration of stochastic uncertainty in optimal and predictive control is a well-explored topic. Recently Polynomial Chaos Expansions (PCE) have seen a lot of considerations for problems involving stochastically uncertain system parameters and also for problems with additive stochastic i.i.d. disturbances. While there exist a number of open-source PCE toolboxes, tailored open-source codes for the solution of OCPs involving additive stochastic i.i.d. disturbances in julia are not available. Hence, this paper introduces the toolbox \texttt{PolyOCP.jl} which enables to efficiently solve stochastic OCPs for a large class of disturbance distributions. We explain the main mathematical concepts between the PCE transcription of stochastic OCPs and how they are provided in the toolbox. We draw upon two examples to illustrate the functionalities of \texttt{PolyOCP.jl}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19084v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruchuan Ou, Learta Januzi, Jonas Schie{\ss}l, Michael Heinrich Baumann, Lars Gr\"une, Timm Faulwasser</dc:creator>
    </item>
  </channel>
</rss>
