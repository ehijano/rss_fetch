<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 28 May 2025 01:55:29 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Mesoscale Turbulence in Type Ia Supernova Deflagrations: Buoyancy-Driven Fuel Heating and Prospects for Delayed-Detonations</title>
      <link>https://arxiv.org/abs/2505.18482</link>
      <description>arXiv:2505.18482v1 Announce Type: cross 
Abstract: The aim of this work is to characterize the thermodynamic state of fuel mixed into the turbulent flame brush in the context of the Zel'dovich deflagration-to-detonation transition (ZDDT) mechanism of Type Ia supernovae (SNe Ia). We perform a series of three-dimensional computer simulations of thermonuclear deflagrations subject to the Rayleigh-Taylor instability (RTI) for conditions found in model explosions of centrally ignited realistic, Chandrasekhar mass white dwarf progenitors. These conditions correspond to explosion times when the flame reaches low density progenitor regions where DDT is expected to occur. The flame database is constructed using a thickened flame model. High numerical resolution is achieved with the help of the adaptive mesh refinement (AMR) approach allowing, for the first time, to resolve mesoscale buoyancy-driven flame turbulence. The system is evolved to a quasi-steady state, and flow properties in the turbulent region, where turbulence is most isotropic, is analyzed in a co-moving frame of reference. We find evidence for strong buoyancy-driven adiabatic heating of fuel layers adjacent to the flame front. The heating results in a dramatic reduction of fuel ignition times by between $\approx$2 and more than about 5 orders of magnitude. The heating increases with the RTI forcing. The observed shortening of fuel burning timescales suggests a new source of energy is important inside fuel penetrating the flame brush. These regions are up to several hundred meters wide. On the basis of the previous results of turbulent combustion in SNe Ia, preconditioning required by the ZDDT mechanism can occur there.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18482v1</guid>
      <category>astro-ph.SR</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ezra Brooker, Andrey Zhiglo, Tomasz Plewa</dc:creator>
    </item>
    <item>
      <title>Dynamical Dark Energy at Late Time $\Lambda$CDM</title>
      <link>https://arxiv.org/abs/2505.18900</link>
      <description>arXiv:2505.18900v1 Announce Type: cross 
Abstract: We investigate the dynamical properties of dark energy through a detailed analysis of its equation of state parameter $w(z)$ as a function of redshift. We derive a general expression for $w(z)$ from the Friedmann-Lema\^itre-Robertson-Walker (FLRW) equations, establishing a direct relationship between the dark energy equation of state and the observable Hubble parameter $H(z)$ and its derivative. Using the relation $w(z) = -1 + \frac{2(1+z)}{3H(z)} \frac{dH}{dz}$, we develop an approximation method valid for $z \lesssim 1$ that accounts for the changing balance between matter and dark energy contributions to cosmic expansion. We compare our theoretical framework with recent observational data from the Dark Energy Spectroscopic Instrument (DESI) DR2, analysing how well the commonly used Chevallier-Polarski-Linder (CPL) parametrization $w(z) = -1 + w_a \frac{z}{1+z}$ captures the evolution of dark energy. Our results indicate that the dark energy equation of state exhibits a monotonic evolution with redshift, transitioning from deceleration to acceleration around $z \approx 0.7$. Notably, our predicted $w_{\mathrm{DE}}$ remains greater than $-1$ across all redshifts, avoiding phantom energy scenarios that would violate the null energy condition. This work demonstrates how precise measurements of the cosmic expansion history can constrain the nature of dark energy and provides a framework for testing dynamical dark energy models against current and future cosmological observations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18900v1</guid>
      <category>astro-ph.CO</category>
      <category>gr-qc</category>
      <category>hep-th</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>J. W. Moffat, E. J. Thompson</dc:creator>
    </item>
    <item>
      <title>The influence of data gaps and outliers on resilience indicators</title>
      <link>https://arxiv.org/abs/2505.19034</link>
      <description>arXiv:2505.19034v2 Announce Type: cross 
Abstract: The resilience, or stability, of major Earth system components is increasingly threatened by anthropogenic pressures, demanding reliable early warning signals for abrupt and irreversible regime shifts. Widely used data-driven resilience indicators based on variance and autocorrelation detect `critical slowing down', a signature of decreasing stability. However, the interpretation of these indicators is hampered by poorly understood interdependencies and their susceptibility to common data issues such as missing values and outliers. Here, we establish a rigorous mathematical analysis of the statistical dependency between variance- and autocorrelation-based resilience indicators, revealing that their agreement is fundamentally driven by the time series' initial data point. Using synthetic and empirical data, we demonstrate that missing values substantially weaken indicator agreement, while outliers introduce systematic biases that lead to overestimation of resilience based on temporal autocorrelation. Our results provide a necessary and rigorous foundation for preprocessing strategies and accuracy assessments across the growing number of disciplines that use real-world data to infer changes in system resilience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19034v2</guid>
      <category>nlin.AO</category>
      <category>nlin.CD</category>
      <category>physics.data-an</category>
      <category>physics.geo-ph</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Teng Liu, Andreas Morr, Sebastian Bathiany, Lana L. Blaschke, Zhen Qian, Chan Diao, Taylor Smith, Niklas Boers</dc:creator>
    </item>
    <item>
      <title>Validating The Effectiveness of Electrospun Self Healing Diels Alder Interleaves to Mode I fracture resistance by Comparing Simulation Outputs with Experimental Results</title>
      <link>https://arxiv.org/abs/2505.19230</link>
      <description>arXiv:2505.19230v1 Announce Type: cross 
Abstract: The predictive capabilities of the finite element approach were assessed by comparing simulation outputs with experimental results, including load-displacement trends, damage initiation points, and delamination evolution. This comparison validated the effectiveness of the self-healing interleaves and highlighted the strengths and limitations of the adopted numerical framework. The simulations not only reproduced key damage characteristics but also provided a deeper understanding of failure mechanisms in the modified laminates. This modeling strategy contributes to the broader goal of developing high-fidelity virtual testing tools for complex, multifunctional composite structures used in aerospace and related industries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19230v1</guid>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Constantinos Rouvalis, Vassilis Kostopoulos, Spyridon Psarras</dc:creator>
    </item>
    <item>
      <title>Numerical Analysis of Damage Evolution in Open Hole CFRP Laminates Modified with Electrospun Self Healing Diels Alder Interleaves</title>
      <link>https://arxiv.org/abs/2505.19232</link>
      <description>arXiv:2505.19232v1 Announce Type: cross 
Abstract: The study analyzes open hole carbon fiber reinforced polymer CFRP laminates modified with electrospun interleaves containing Diels Alder-based self-healing agents. It develops a high-fidelity simulation framework to investigate the quasistatic tensile behavior of these composites. The study uses Hashin's failure criteria to capture intralaminar damage and surface-based cohesive contact interactions to model interlaminar delamination. Two interleave configurations are examined: solution electrospinning (SEP) for full thickness coverage and melt electrospinning (MEP) for localized reinforcement. Results show good agreement with experimental data, capturing key failure mechanisms like matrix cracking, fiber breakage, and delamination. The study emphasizes the importance of spatially resolved cohesive properties and meshing strategies in accurately simulating damage progression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19232v1</guid>
      <category>physics.comp-ph</category>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marianna Chantzi, Vassilis Kostopoulos, Spyridon Psarras</dc:creator>
    </item>
    <item>
      <title>Diffusion with stochastic resetting on a lattice</title>
      <link>https://arxiv.org/abs/2505.19903</link>
      <description>arXiv:2505.19903v1 Announce Type: cross 
Abstract: We provide an exact formula for the mean first-passage time (MFPT) to a target at the origin for a single particle diffusing on a $d$-dimensional hypercubic {\em lattice} starting from a fixed initial position $\vec R_0$ and resetting to $\vec R_0$ with a rate $r$. Previously known results in the continuous space are recovered in the scaling limit $r\to 0$, $R_0=|\vec R_0|\to \infty$ with the product $\sqrt{r}\, R_0$ fixed. However, our formula is valid for any $r$ and any $\vec R_0$ that enables us to explore a much wider region of the parameter space that are inaccessible in the continuum limit. For example, we have shown that the MFPT, as a function of $r$ for fixed $\vec R_0$, diverges in the two opposite limits $r\to 0$ and $r\to \infty$ with a unique minimum in between, provided the starting point is not a nearest neighbour of the target. In this case, the MFPT diverges as a power law $\sim r^{\phi}$ as $r\to \infty$, but very interestingly with an exponent $\phi= (|m_1|+|m_2|+\ldots +|m_d|)-1$ that depends on the starting point $\vec R_0= a\, (m_1,m_2,\ldots, m_d)$ where $a$ is the lattice spacing and $m_i$'s are integers. If, on the other hand, the starting point happens to be a nearest neighbour of the target, then the MFPT decreases monotonically with increasing $r$, approaching a universal limiting value $1$ as $r\to \infty$, indicating that the optimal resetting rate in this case is infinity. We provide a simple physical reason and a simple Markov-chain explanation behind this somewhat unexpected universal result. Our analytical predictions are verified in numerical simulations on lattices up to $50$ dimensions. Finally, in the absence of a target, we also compute exactly the position distribution of the walker in the nonequlibrium stationary state that also displays interesting lattice effects not captured by the continuum theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19903v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander K. Hartmann, Satya N. Majumdar</dc:creator>
    </item>
    <item>
      <title>Universal scaling of intra-urban climate fluctuations</title>
      <link>https://arxiv.org/abs/2505.19998</link>
      <description>arXiv:2505.19998v1 Announce Type: cross 
Abstract: Urban-induced changes in local microclimate, such as the urban heat island effect and air pollution, are known to vary with city size, leading to distinctive relations between average climate variables and city-scale quantities (e.g., total population or area). However, these approaches suffer from biases related to the choice of city boundaries and they neglect intra-urban variations of urban characteristics. Here we use high-resolution data of urban temperatures, air quality, population counts, and street intersections from 142 cities worldwide and show that their marginal and joint probability distributions follow universal scaling functions. By using a logarithmic relation between urban spatial features and climate variables, we show that average street network properties are sufficient to characterize the entire variability of the temperature and air pollution fields observed within and across cities. We further demonstrate that traditional models linking climate variables to the distance from the city center fail to reproduce the observed distributions unless the stochasticity of urban structure is fully considered. These findings provide a unified statistical framework for characterizing intra-urban climate variability, with important implications for climate modelling and urban planning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19998v1</guid>
      <category>physics.soc-ph</category>
      <category>cond-mat.stat-mech</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marc Duran-Sala, Martin Hendrick, Gabriele Manoli</dc:creator>
    </item>
    <item>
      <title>Noise-Robust One-Bit Diffraction Tomography and Optimal Dose Fractionation</title>
      <link>https://arxiv.org/abs/2310.05571</link>
      <description>arXiv:2310.05571v3 Announce Type: replace-cross 
Abstract: This study presents a noise-robust framework for 1-bit diffraction tomography, a novel imaging approach that relies on intensity-only binary measurements obtained through coded apertures. The proposed reconstruction scheme leverages random matrix theory and iterative algorithms to effectively recover 3D object structures under high-noise conditions.
  A key contribution is the numerical investigation of dose fractionation, revealing optimal performance at a signal-to-noise ratio near 1, {\em independent of the total dose}. This finding addresses the question: How to distribute a given level of total radiation energy among different tomographic views in order to optimize the quality of reconstruction?</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.05571v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pengwen Chen, Albert Fannjiang</dc:creator>
    </item>
    <item>
      <title>KAN we improve on HEP classification tasks? Kolmogorov-Arnold Networks applied to an LHC physics example</title>
      <link>https://arxiv.org/abs/2408.02743</link>
      <description>arXiv:2408.02743v2 Announce Type: replace-cross 
Abstract: Recently, Kolmogorov-Arnold Networks (KANs) have been proposed as an alternative to multilayer perceptrons, suggesting advantages in performance and interpretability. We study a typical binary event classification task in high-energy physics including high-level features and comment on the performance and interpretability of KANs in this context. Consistent with expectations, we find that the learned activation functions of a one-layer KAN resemble the univariate log-likelihood ratios of the respective input features. In deeper KANs, the activations in the first layer differ from those in the one-layer KAN, which indicates that the deeper KANs learn more complex representations of the data, a pattern commonly observed in other deep-learning architectures. We study KANs with different depths and widths and we compare them to multilayer perceptrons in terms of performance and number of trainable parameters. For the chosen classification task, we do not find that KANs are more parameter efficient. However, small KANs may offer advantages in terms of interpretability that come at the cost of only a moderate loss in performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02743v2</guid>
      <category>hep-ph</category>
      <category>cs.LG</category>
      <category>hep-ex</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s41781-025-00138-3</arxiv:DOI>
      <arxiv:journal_reference>Comput. Softw. Big Sci. 9, 9 (2025)</arxiv:journal_reference>
      <dc:creator>Johannes Erdmann, Florian Mausolf, Jan Lukas Sp\"ah</dc:creator>
    </item>
    <item>
      <title>Flow Annealed Importance Sampling Bootstrap meets Differentiable Particle Physics</title>
      <link>https://arxiv.org/abs/2411.16234</link>
      <description>arXiv:2411.16234v2 Announce Type: replace-cross 
Abstract: High-energy physics requires the generation of large numbers of simulated data samples from complex but analytically tractable distributions called matrix elements. Surrogate models, such as normalizing flows, are gaining popularity for this task due to their computational efficiency. We adopt an approach based on Flow Annealed importance sampling Bootstrap (FAB) that evaluates the differentiable target density during training and helps avoid the costly generation of training data in advance. We show that FAB reaches higher sampling efficiency with fewer target evaluations in high dimensions in comparison to other methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16234v2</guid>
      <category>hep-ph</category>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1088/2632-2153/addbc1</arxiv:DOI>
      <dc:creator>Annalena Kofler, Vincent Stimper, Mikhail Mikhasenko, Michael Kagan, Lukas Heinrich</dc:creator>
    </item>
    <item>
      <title>Position: Solve Layerwise Linear Models First to Understand Neural Dynamical Phenomena (Neural Collapse, Emergence, Lazy/Rich Regime, and Grokking)</title>
      <link>https://arxiv.org/abs/2502.21009</link>
      <description>arXiv:2502.21009v2 Announce Type: replace-cross 
Abstract: In physics, complex systems are often simplified into minimal, solvable models that retain only the core principles. In machine learning, layerwise linear models (e.g., linear neural networks) act as simplified representations of neural network dynamics. These models follow the dynamical feedback principle, which describes how layers mutually govern and amplify each other's evolution. This principle extends beyond the simplified models, successfully explaining a wide range of dynamical phenomena in deep neural networks, including neural collapse, emergence, lazy and rich regimes, and grokking. In this position paper, we call for the use of layerwise linear models retaining the core principles of neural dynamical phenomena to accelerate the science of deep learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.21009v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yoonsoo Nam, Seok Hyeong Lee, Clementine C J Domine, Yeachan Park, Charles London, Wonyl Choi, Niclas Goring, Seungjai Lee</dc:creator>
    </item>
  </channel>
</rss>
