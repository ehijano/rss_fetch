<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 29 Jan 2026 05:00:35 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>New Adaptive Numerical Methods Based on Dual Formulation of Hyperbolic Conservation Laws</title>
      <link>https://arxiv.org/abs/2601.20000</link>
      <description>arXiv:2601.20000v1 Announce Type: new 
Abstract: In this paper, we propose an adaptive high-order method for hyperbolic systems of conservation laws. The proposed method is based on a dual formulation approach: Two numerical solutions, corresponding to conservative and nonconservative formulations of the same system, are evolved simultaneously. Since nonconservative schemes are known to produce nonphysical weak solutions near discontinuities, we exploit the difference between these two solutions to construct a smoothness indicator (SI). In smooth regions, the difference between the conservative and nonconservative solutions is of the same order as the truncation error of the underlying discretization, whereas in nonsmooth regions, it is ${\cal O}(1)$. We apply this idea to the Euler equations of gas dynamics and define the SI using differences in the momentum and pressure variables. This choice allows us to further distinguish neighborhoods of contact discontinuities from other nonsmooth parts of the computed solution. The resulting classification is used to adaptively select numerical discretizations. In the vicinities of contact discontinuities, we employ the low-dissipation central-upwind numerical flux and a second-order piecewise linear reconstruction with the slopes computed using an overcompressive SBM limiter. Elsewhere, we use an alternative weighted essentially non-oscillatory (A-WENO) framework with the central-upwind finite-volume numerical fluxes and either unlimited (in smooth regions) or Ai-WENO-Z (in the nonsmooth regions away from contact discontinuities) fifth-order interpolation. Numerical results for the one- and two-dimensional compressible Euler equations show that the proposed adaptive method improves both the computational efficiency and resolution of complex flow features compared with the non-adaptive fifth-order A-WENO scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20000v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alina Chertock, Qingcheng Fu, Alexander Kurganov, Lorenzo Micalizzi</dc:creator>
    </item>
    <item>
      <title>Least-Squares Neural Network (LSNN) Method for Scalar Hyperbolic Partial Differential Equations</title>
      <link>https://arxiv.org/abs/2601.20013</link>
      <description>arXiv:2601.20013v1 Announce Type: new 
Abstract: This chapter offers a comprehensive introduction to the least-squares neural network (LSNN) method introduced in [14,16], for solving scalar first-order hyperbolic partial differential equations, specifically linear advection-reaction equations and nonlinear hyperbolic conservation laws. The LSNN method is built on an equivalent least-squares formulation of the underlying problem on an admissible solution set that accommodates discontinuous solutions. It employs ReLU neural networks (in place of finite elements) as the approximating functions, uses a carefully designed physics-preserved numerical differentiation, and avoids penalization techniques such as artificial viscosity, entropy condition, and/or total variation. This approach captures shock features in the solution without oscillations or overshooting. Efficiently and reliably solving the resulting non-convex optimization problem posed by the LSNN method remains an open challenge. This chapter concludes with a brief discussion on application of the structure-guided Gauss-Newton (SgGN) method developed recently in [21] for solving shallow NN approximation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20013v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Min Liu, Zhiqiang Cai</dc:creator>
    </item>
    <item>
      <title>A mixed virtual element discretization for the generalized Oseen problem</title>
      <link>https://arxiv.org/abs/2601.20050</link>
      <description>arXiv:2601.20050v1 Announce Type: new 
Abstract: In this paper we introduce a mixed virtual element method to approximate the solution for the two dimensional generalized Oseen problem. We introduce the pseudostress as an additional unknown, which allows to eliminate the pressure from the system; the pressure can be recovered via a post-process of the pseudostress tensor. We prove existence and uniqueness of the continuous solution via a fixed point argument. Under standard mesh assumptions, we develop a virtual element method to approximate both the tensor and the velocity field, and we show that it is stable. Furthermore, we provide a priori error estimates for the method and validate them through a series of numerical tests using different polygonal meshes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20050v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Felipe Lepe, Gonzalo Rivera</dc:creator>
    </item>
    <item>
      <title>Improving Smoothed Aggregation AMG Robustness on Stretched Mesh Applications</title>
      <link>https://arxiv.org/abs/2601.20119</link>
      <description>arXiv:2601.20119v1 Announce Type: new 
Abstract: Strength-of-connection algorithms play a key role in algebraic multigrid (AMG). Specifically, they determine which matrix nonzeros are classified as weak and so ignored when coarsening matrix graphs and defining interpolation sparsity patterns. The general goal is to encourage coarsening only in directions where error can be smoothed and to avoid coarsening across sharp problem variations. Unfortunately, developing robust and inexpensive strength-of-connection schemes is challenging.
  The classification of matrix nonzeros involves four aspects: (a) choosing a strength-of-connection matrix, (b) scaling its values, (c) choosing a criterion to classify scaled values as strong or weak, and (d) dropping weak entries which includes adjusting matrix values to account for dropped terms. Typically, smoothed aggregation AMG uses the linear system being solved as a strength-of-connection matrix. It scales values symmetrically using square-roots of the matrix diagonal. It classifies based on whether scaled values are above or below a threshold. Finally, it adjusts matrix values by modifying the diagonal so that the sum of entries within each row of the dropped matrix matches that of the original. While these procedures can work well, we illustrate failure cases that motivate alternatives. The first alternative uses a distance Laplacian strength-of-connection matrix. The second centers on non-symmetric scaling. We then investigate alternative classification criteria based on identifying gaps in the values of the scaled entries. Finally, an alternative lumping procedure is proposed where row sums are preserved by modifying all retained matrix entries (as opposed to just diagonal entries). A series of numerical results illustrates trade-offs demonstrating in some cases notably more robust convergence on matrices coming from linear finite elements on stretched meshes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20119v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Chris Siefert, Raymond Tuminaro, Daniel Sunderland</dc:creator>
    </item>
    <item>
      <title>Error estimates of $hp$-finite element method for elliptic optimal control problems with robin boundary</title>
      <link>https://arxiv.org/abs/2601.20145</link>
      <description>arXiv:2601.20145v1 Announce Type: new 
Abstract: A priori and a posteriori error analysis of $hp$ finite element method for elliptic control problem with Robin boundary condition and boundary observation are presented. are presented. Through the Cl\'ement-type approach and the construction of an auxiliary system, we derived a priori error estimates for the elliptic optimal control problem. Residual-based a posteriori error estimates are derived based on the well-known Scott-Zhang-type quasi-interpolation and coupled state-control approximations, thus establishing an a posteriori error estimator for the $hp$ finite element method. The numerical example demonstrates the accuracy of error estimation for the elliptic optimal control problems with Robin boundary.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20145v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xingyuan Lin, Xiuxiu Lin, Xuesong Chen</dc:creator>
    </item>
    <item>
      <title>A direct sampling method for magnetic induction tomography</title>
      <link>https://arxiv.org/abs/2601.20191</link>
      <description>arXiv:2601.20191v1 Announce Type: new 
Abstract: This paper proposes a direct sampling method for the inverse problem of magnetic induction tomography (MIT). Our approach defines a class of point spread functions with explicit expressions, which are computed via inner products, leading to a simple and fast imaging process. We then prove that these point spread functions decay with distance, establishing the theoretical basis of the algorithm. Specific expressions for special cases are also derived to visually demonstrate their attenuation pattern. Numerical experimental results further confirm the efficiency and accuracy of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20191v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junqing Chen, Chengzhe Jiang</dc:creator>
    </item>
    <item>
      <title>Local Regularity Estimation through Sobolev-Scale Norm Profile</title>
      <link>https://arxiv.org/abs/2601.20207</link>
      <description>arXiv:2601.20207v1 Announce Type: new 
Abstract: We develop a kernel-based approach for estimating the spatially varying Sobolev regularity~$s$ of an unknown $d$-variate function~$f$ from scattered sampling data, which quantifies the degree of local differentiability supported by the data. Relying only on neighborhood data near the point of interest $z\in \Omega_z$, our method constructs a sequence of Sobolev-space reproducing kernel interpolants whose kernel smoothness order is specified by an index~$m &gt; d/2$. The native-space norms of these interpolants are evaluated over a bounded range of~$m$, producing a \emph{Sobolev-scale norm profile}. The elbow of this profile serves as a quantitative probe of the underlying local regularity~$s(\Omega_z)$. In particular, when $m &gt; s(\Omega_z)$, the profile exhibits rapid, near-worst-case growth governed by the classical upper bound associated with the conditioning of the kernel matrix. A band-limited surrogate analysis explains this transition and establishes a lower-bound relation linking native-norm growth to the Sobolev regularity of~$f$. Two complementary strategies are incorporated for further enhancement: (i)~a \emph{stencil-shift} subroutine, which repositions local neighborhoods to avoid crossing discontinuities whenever possible, thereby suppressing artifacts in the norm estimates; and (ii)~a local--global \emph{norm-sweep comparison} strategy that combines short two-point local tails with an optional one-point global screen to detect outlier $\Omega_z$ of low Sobolev regularity and accelerate evaluation on large datasets. Numerical experiments on synthetic test functions and turbulent-flow data demonstrate accurate recovery of spatially varying regularity and confirm the robustness of the proposed characterization for kernel-based approximation and differentiation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20207v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xiaobin Li, Leevan Ling, Yizhong Sun</dc:creator>
    </item>
    <item>
      <title>A low regularity exponential-type integrator for the derivative nonlinear Schr\"odinger equation</title>
      <link>https://arxiv.org/abs/2601.20212</link>
      <description>arXiv:2601.20212v1 Announce Type: new 
Abstract: In this work, we present a first-order unfiltered exponential integrator for the one-dimensional derivative nonlinear Schr\"odinger equation with low regularity. Our analysis shows that for any $s&gt;\frac12$, the method converges with first-order in $H^s(\mathbb{T})$ for initial data $u_0\in H^{s+1}(\mathbb{T})$. Moreover, we constructed a symmetrized version of this method that performs better in terms of both global error and conservation behavior. To the best of our knowledge, these are the first low regularity integrators for the derivative nonlinear Schr\"odinger equation. Numerical experiments illustrate our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20212v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Lun Ji, Hang Li, Alexander Ostermann</dc:creator>
    </item>
    <item>
      <title>A Unified Variational Functional for Equidistribution and Alignment in Moving Mesh Adaptation</title>
      <link>https://arxiv.org/abs/2601.20235</link>
      <description>arXiv:2601.20235v1 Announce Type: new 
Abstract: Existing variational mesh functionals often suffer from strong nonlinearity or dependence on empirical parameters.We propose a new variational functional for adaptive moving mesh generation that enforces equidistribution and alignment through an $\boldsymbol A$-pullback formulation, where $\boldsymbol A=\boldsymbol J^{-1}\boldsymbol M^{-1}\boldsymbol J^{-T}$. The functional combines a trace-based term with a logarithmic determinant term, achieving balanced control of mesh size and anisotropy without empirical parameters. We establish coercivity, polyconvexity, existence of minimizers, and geodesic convexity with respect to the inverse Jacobian, and derive a simplified geometric discretization leading to an efficient moving mesh algorithm. Numerical experiments confirm the theoretical properties and demonstrate robust adaptive behavior for function-induced meshes and Rayleigh-Taylor instability simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20235v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenbin Wang, Yunqing Huang, Huayi Wei</dc:creator>
    </item>
    <item>
      <title>Element-based B-spline basis function spaces: construction and application in isogeometric analysis</title>
      <link>https://arxiv.org/abs/2601.20243</link>
      <description>arXiv:2601.20243v1 Announce Type: new 
Abstract: This paper develops a unified theoretical framework for constructing B-spline basis function spaces with structural equivalence to finite element spaces. The theory rigorously establishes that these bases emerge as explicit linear combinations of B-spline element bases. For any prescribed smoothness requirements, this element-wise formulation enables the Hermite interpolation at nodes, which directly utilizes function values and derivatives without solving global linear systems. By focusing on explicit interpolation properties, element-wise analysis establishes optimal approximation errors, even when the space smoothness attains its theoretical maximum for the space degree. In isogeometric analysis (IgA), the construction naturally decomposes geometric mappings into element-level representations, allowing efficient computations across elements regardless of node distribution. Notably, the same Hermite interpolation framework simultaneously handles domain parameterization and IgA solutions, allowing direct imposition of boundary conditions through function and derivative matching. Numerical tests demonstrate optimal convergence rates and superconvergence properties in 2D IgA under uniform knot configurations, and improved computational efficiency in 3D IgA with non-uniform knot distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20243v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peng Yang, Maodong Pan, Falai Chen, Zhimin Zhang</dc:creator>
    </item>
    <item>
      <title>A note on approximation in weighted Korobov spaces via multiple rank-1 lattices</title>
      <link>https://arxiv.org/abs/2601.20290</link>
      <description>arXiv:2601.20290v1 Announce Type: new 
Abstract: This paper studies the multivariate approximation of functions in weighted Korobov spaces using multiple rank-1 lattice rules. It has been shown by K\"{a}mmerer and Volkmer (2019) that algorithms based on multiple rank-1 lattices achieve the optimal convergence rate for the $L_{\infty}$ error in Wiener-type spaces, up to logarithmic factors. While this result was translated to weighted Korobov spaces in the recent monograph by Dick, Kritzer, and Pillichshammer (2022), the analysis requires the smoothness parameter $\alpha$ to be greater than $1$ and is restricted to product weights. In this paper, we extend this result for multiple rank-1 lattice-based algorithms to the case where $1/2&lt;\alpha\le 1$ and for general weights, covering a broader range of periodic functions with low smoothness and general relative importance of variables. We also provide a summability condition on the weights to ensure strong polynomial tractability for any $\alpha&gt;1/2$. Furthermore, by incorporating random shifts into multiple rank-1 lattice-based algorithms, we prove that the resulting randomized algorithm achieves a nearly optimal convergence rate in terms of the worst-case root mean squared $L_2$ error, while retaining the same tractability property.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20290v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mou Cai, Takashi Goda</dc:creator>
    </item>
    <item>
      <title>Refined rates of convergence for target-data dependent greedy generalized interpolation with Sobolev kernels</title>
      <link>https://arxiv.org/abs/2601.20407</link>
      <description>arXiv:2601.20407v1 Announce Type: new 
Abstract: Greedy methods have recently been successfully applied to generalized kernel interpolation, or the recovery of a function from data stemming from the evaluation of linear functionals, including the approximation of solutions of linear PDEs by symmetric collocation. When applied to kernels generating Sobolev spaces as their native Hilbert spaces, some of these greedy methods can provide the same error guarantee of generalized interpolation on quasi-uniform points. More importantly, certain target-data-adaptive methods even give a dimension- and smoothness-independent improvement in the speed of convergence over quasi-uniform points, thus offering advantages for high-dimensional problems. These convergence rates however contain a spurious logarithmic term that limits this beneficial effect. The goal of this note is to remove this factor, and this is possible by using estimates on metric entropy numbers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20407v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bernard Haasdonk, Gabriele Santin, Tizian Wenzel, Daniel Winkle</dc:creator>
    </item>
    <item>
      <title>Fokker--Planck Dynamics on Star Graphs with Variable Drift: Well-Posedness, Adjoint Analysis, and Numerical Approximation</title>
      <link>https://arxiv.org/abs/2601.20456</link>
      <description>arXiv:2601.20456v1 Announce Type: new 
Abstract: Stochastic transport processes on networked domains (modelled on metric graphs) arise in a variety of applications where diffusion and drift mechanisms interact with an underlying graph structure. The Fokker--Planck equation provides a natural framework for describing the evolution of probability densities associated with such dynamics. While Fokker--Planck equations on metric graphs have been studied from an analytical viewpoint, their optimal control remains largely unexplored, particularly in settings where the control acts through the drift term. In this paper, we investigate an optimal control problem governed by the Fokker--Planck equation on a star graph, with a bilinear control appearing in the drift. We establish the well-posedness of the state equation and prove the existence of at least one optimal control. The associated adjoint system is derived, and first-order necessary optimality conditions are formulated. A wavelet-based numerical scheme is proposed to approximate the optimal solution, and its performance is illustrated through representative numerical experiments. These results contribute to the analytical and computational understanding of controlled stochastic dynamics on network-like domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20456v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ritu Kumari, Cyrille Kenne, Landry Djomegne, Mani Mehra</dc:creator>
    </item>
    <item>
      <title>Monotone-based Numerical Schemes for Two-Dimensional Systems of Nonlocal Conservation Laws</title>
      <link>https://arxiv.org/abs/2601.20494</link>
      <description>arXiv:2601.20494v1 Announce Type: new 
Abstract: We present a class of numerical schemes for two-dimensional systems of nonlocal conservation laws, which are based on utilizing well-known monotone numerical flux functions after suitably approximating the nonlocal terms. The considered systems are weakly coupled by the nonlocal terms and the underlying flux function is rather general to guarantee that our results are applicable to a wide range of common nonlocal models. We state sufficient conditions to ensure the convergence of the monotone-based numerical schemes to the unique weak entropy solution. Moreover, we provide an error estimate that yields the convergence rate of $\mathcal{O}(\sqrt{\Delta t})$ for the numerical approximations of the solution. Our results include an existence and uniqueness proof of the nonlocal system, too. Numerical results illustrate our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20494v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anika Beckers, Jan Friedrich</dc:creator>
    </item>
    <item>
      <title>Local convergence analysis of a linearized Alikhanov scheme for the time fractional sine-Gordon equation</title>
      <link>https://arxiv.org/abs/2601.20566</link>
      <description>arXiv:2601.20566v1 Announce Type: new 
Abstract: This paper investigates the time fractional sine-Gordon equation whose solution exhibits a weak singularity of type t^{\alpha}. By means of the Alikhanov formula we derive a fully discrete, linearized scheme. Using the more general regularity assumption, we derive a sharp truncation-error bound for the fractional derivative. Furthermore, we prove a key inequality and a less restrictive stability result that is valid on general graded temporal meshes. Consequently, the temporal local convergence order is shown to be min{2, r} in H^1-seminorm, where r is the degree of grading; numerical experiments confirm that the optimal rate is already attained as soon as r = 2.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20566v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chang Hou, Hu Chen</dc:creator>
    </item>
    <item>
      <title>Quantitative synthetic aperture radar inversion</title>
      <link>https://arxiv.org/abs/2601.20583</link>
      <description>arXiv:2601.20583v1 Announce Type: new 
Abstract: We study an inverse scattering problem for monostatic synthetic aperture radar (SAR): Estimate the wave speed in a heterogeneous, isotropic and nonmagnetic medium probed by waves emitted and measured by a moving antenna. The forward map, from the wave speed to the measurements, is derived from Maxwell's equations. It is a nonlinear map that accounts for multiple scattering and it is very oscillatory at high frequencies. This makes the standard, nonlinear least squares data fitting formulation of the inverse problem difficult to solve. We introduce an alternative, two-step approach: The first step computes the nonlinear map from the measurements to an approximation of the electric field inside the unknown medium aka, the internal wave. This is done for each antenna location in a non-iterative manner.
  The internal wave fits the data by construction, but it does not solve Maxwell's equations. The second step uses optimization to minimize the discrepancy between the internal wave and the solution of Maxwell's equations, for all antenna locations. The optimization is iterative. The first step defines an imaging function whose computational cost is comparable to that of standard SAR imaging, but it gives a better estimate of the support of targets. Further iterations improve the quantitative estimation of the wave speed. We assess the performance of the method with numerical simulations and compare the results with those of standard inversion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20583v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>eess.SP</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liliana Borcea, Josselin Garnier, Alexander V. Mamonov, J\"orn Zimmerling</dc:creator>
    </item>
    <item>
      <title>Unconditional full linear convergence and quasi-optimal complexity of smoothed adaptive finite element methods</title>
      <link>https://arxiv.org/abs/2601.20677</link>
      <description>arXiv:2601.20677v1 Announce Type: new 
Abstract: We present the first rigorous convergence analysis of the smoothed adaptive finite element method (S-AFEM) proposed in [Mulita, Giani, Heltai: SIAM J. Sci. Comput. 43, 2021]. S-AFEM modifies the classical adaptive finite element method (AFEM) by performing accurate discrete solves only on periodically determined mesh levels, while the intermediate levels employ a fixed number of cheap smoothing iterations. Numerical experiments in that work showed that this strategy generates adapted meshes comparable to those of AFEM at substantially lower computational cost. In this paper, we prove unconditional full R-linear convergence of a suitable quasi-error quantity and, for sufficiently small adaptivity parameters, optimal convergence rates with respect to the overall computational cost. The analysis requires only a mild uniform stability assumption on the employed smoother, satisfied by standard methods such as Richardson, Gauss-Seidel, conjugate gradient, and multigrid schemes. Our results apply to general second-order linear elliptic PDEs and show that S-AFEM retains all desired abstract convergence guarantees of AFEM while reducing the cumulative computational time. Numerical experiments validate the theory, analyze runtime performance, and underline the potential of S-AFEM for speed-up in AFEM computations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20677v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philipp Bringmann, Christoph Lietz, Dirk Praetorius</dc:creator>
    </item>
    <item>
      <title>Adaptive domain decomposition method for time-dependent problems with applications in fluid dynamics</title>
      <link>https://arxiv.org/abs/2601.20750</link>
      <description>arXiv:2601.20750v1 Announce Type: new 
Abstract: We deal with the numerical solution of the time-dependent partial differential equations using the adaptive space-time discontinuous Galerkin (DG) method. The discretization leads to a nonlinear algebraic system at each time level, the size of the system is varying due to mesh adaptation. A Newton-like iterative solver leads to a sequence of linear algebraic systems which are solved by GMRES solver with a domain decomposition preconditioner. Particularly, we consider additive and hybrid two-level Schwarz preconditioners which are efficient and easy to implement for DG discretization. We study the convergence of the linear solver in dependence on the number of subdomains and the number of element of the coarse grid. We propose a simplified cost model measuring the computational costs in terms of floating-point operations, the speed of computation, and the wall-clock time for communications among computer cores. Moreover, the cost model serves as a base of the presented adaptive domain decomposition method which chooses the number of subdomains and the number of element of the coarse grid in order to minimize the computational costs. The efficiency of the proposed technique is demonstrated by two benchmark problems of compressible flow simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20750v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vit Dolejsi, Jakub Sistek</dc:creator>
    </item>
    <item>
      <title>Optimal Sensor Placement in Gaussian Processes via Column Subset Selection</title>
      <link>https://arxiv.org/abs/2601.20781</link>
      <description>arXiv:2601.20781v1 Announce Type: new 
Abstract: Gaussian process regression uses data measured at sensor locations to reconstruct a spatially dependent function with quantified uncertainty. However, if only a limited number of sensors can be deployed, it is important to determine how to optimally place the sensors to minimize a measure of the uncertainty in the reconstruction. We consider the Bayesian D-optimal criterion to determine the optimal sensor locations by choosing sensors from a candidate set of sensors. Since this is an NP-hard problem, our approach models sensor placement as a column subset selection problem (CSSP) on the covariance matrix, computed using the kernel function on the candidate sensor points. We propose an algorithm that uses the Golub-Klema-Stewart framework (GKS) to select sensors and provide an analysis of lower bounds on the D-optimality of these sensor placements. To reduce the computational cost in the GKS step, we propose and analyze algorithms for the D-optimal sensor placements using Nystr\"om approximations on the covariance matrix. Moreover, we propose several algorithms that select sensors via Nystr\"om approximation of the covariance matrix, utilizing the randomized Nystr\"om approximation, random pivoted Cholesky and greedy pivoted Cholesky. We demonstrate the performance of our method on two applications: thin liquid film dynamics and sea surface temperature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20781v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jessie Chen, Hangjie Ji, Arvind K. Saibaba</dc:creator>
    </item>
    <item>
      <title>Jacobi Hamiltonian Integrators: construction and applications</title>
      <link>https://arxiv.org/abs/2601.20799</link>
      <description>arXiv:2601.20799v1 Announce Type: new 
Abstract: We propose a systematic framework for constructing geometric integrators for Hamiltonian systems on Jacobi manifolds. By combining Poissonization of Jacobi structures with homogeneous symplectic bi-realizations, Jacobi dynamics are lifted to homogeneous Poisson Hamiltonian systems, enabling the construction of structure-preserving Jacobi Hamiltonian integrators. The resulting schemes are constructed explicitly and applied to a range of examples, including contact Hamiltonian systems and classical models. Numerical experiments highlight their qualitative advantages over standard integrators, including better preservation of geometric structure and improved long-time behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20799v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.DG</category>
      <category>math.MP</category>
      <category>math.SG</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ad\'erito Ara\'ujo, Gon\c{c}alo Inoc\^encio Oliveira, Jo\~ao Nuno Mestre</dc:creator>
    </item>
    <item>
      <title>A locking-free mixed virtual element discretization for the elasticity eigenvalue problem</title>
      <link>https://arxiv.org/abs/2601.20807</link>
      <description>arXiv:2601.20807v1 Announce Type: new 
Abstract: In this paper, we introduce a mixed virtual element method to approximate the eigenvalues and eigenfunctions of the two-dimensional elasticity eigenvalue problem. Under standard assumptions on the meshes, we prove the convergence of the discrete solution operator to the continuous one as the mesh size tends to zero. Using the theory of compact operators, we analyze the convergence of the method and derive error estimates for both the eigenvalues and eigenfunctions. We validate our theoretical results with a series of numerical tests, in which we compute convergence orders and show that the method is locking-free and capable of accurately approximating the spectrum independently of the shape of the polygons on the meshes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20807v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Felipe Leppe, Gonzalo Rivera</dc:creator>
    </item>
    <item>
      <title>Fast Solvers for the Reynolds Equation on Piecewise Linear Geometries</title>
      <link>https://arxiv.org/abs/2601.20841</link>
      <description>arXiv:2601.20841v1 Announce Type: new 
Abstract: The Reynolds equation is derived from the incompressible Navier Stokes equations under the lubrication assumptions of a long and thin domain geometry and a small scaled Reynolds number. The Reynolds equation is an elliptic differential equation and a dramatic simplification from the governing equations. When the fluid domain is piecewise linear, the Reynolds equation has an exact solution that we formulate by coupling the exact solutions of each piecewise component. We consider a formulation specifically for piecewise constant heights, and a more general formulation for piecewise linear heights; in both cases the linear system is inverted using the Schur complement. These methods can also be applied in the case of non-linear heights by approximating the height as piecewise constant or piecewise linear, in which case the methods achieve second order accuracy. We assess the time complexity of the two methods, and determine that the method for piecewise linear heights is linear time for the number of piecewise components. As an application of these methods, we explore the limits of validity for lubrication theory by comparing the solutions of the Reynolds and the Stokes equations for a variety of linear and non-linear textured slider geometries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20841v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>physics.flu-dyn</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sarah Dennis, Thomas G. Fai</dc:creator>
    </item>
    <item>
      <title>Rate-induced tipping in a solvable model with the Allee effect</title>
      <link>https://arxiv.org/abs/2601.20128</link>
      <description>arXiv:2601.20128v1 Announce Type: cross 
Abstract: We present a novel exactly solvable ordinary differential equation model for rate-induced tipping: a dynamic phenomenon of dynamical systems where a time-dependent parameter triggers the transition of stability of a system. Our model contains an Allee effect that induces a saddle point and admits an explicit solution along with the extinction threshold of a time-dependent Allee parameter. More specifically, we derive an integral inequality that serves as a necessary condition for the occurrence of rate-induced tipping. A remarkable point in the proposed model is that it can handle population extinction such that the solution completely vanishes in a finite amount of time. An unconditionally stable cubature method suitable for our model is proposed, and its superiority over the classical forward Euler method is discussed. We also discuss a fisheries application where inland fisheries rose and fell from modern times to the present in Japan. The proposed model serves as a tractable mathematical tool for studying rate-induced tipping phenomena.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20128v1</guid>
      <category>math.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hidekazu Yoshioka</dc:creator>
    </item>
    <item>
      <title>ProFlow: Zero-Shot Physics-Consistent Sampling via Proximal Flow Guidance</title>
      <link>https://arxiv.org/abs/2601.20227</link>
      <description>arXiv:2601.20227v1 Announce Type: cross 
Abstract: Inferring physical fields from sparse observations while strictly satisfying partial differential equations (PDEs) is a fundamental challenge in computational physics. Recently, deep generative models offer powerful data-driven priors for such inverse problems, yet existing methods struggle to enforce hard physical constraints without costly retraining or disrupting the learned generative prior. Consequently, there is a critical need for a sampling mechanism that can reconcile strict physical consistency and observational fidelity with the statistical structure of the pre-trained prior. To this end, we present ProFlow, a proximal guidance framework for zero-shot physics-consistent sampling, defined as inferring solutions from sparse observations using a fixed generative prior without task-specific retraining. The algorithm employs a rigorous two-step scheme that alternates between: (\romannumeral1) a terminal optimization step, which projects the flow prediction onto the intersection of the physically and observationally consistent sets via proximal minimization; and (\romannumeral2) an interpolation step, which maps the refined state back to the generative trajectory to maintain consistency with the learned flow probability path. This procedure admits a Bayesian interpretation as a sequence of local maximum a posteriori (MAP) updates. Comprehensive benchmarks on Poisson, Helmholtz, Darcy, and viscous Burgers' equations demonstrate that ProFlow achieves superior physical and observational consistency, as well as more accurate distributional statistics, compared to state-of-the-art diffusion- and flow-based baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20227v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zichao Yu, Ming Li, Wenyi Zhang, Difan Zou, Weiguo Gao</dc:creator>
    </item>
    <item>
      <title>TINNs: Time-Induced Neural Networks for Solving Time-Dependent PDEs</title>
      <link>https://arxiv.org/abs/2601.20361</link>
      <description>arXiv:2601.20361v1 Announce Type: cross 
Abstract: Physics-informed neural networks (PINNs) solve time-dependent partial differential equations (PDEs) by learning a mesh-free, differentiable solution that can be evaluated anywhere in space and time. However, standard space--time PINNs take time as an input but reuse a single network with shared weights across all times, forcing the same features to represent markedly different dynamics. This coupling degrades accuracy and can destabilize training when enforcing PDE, boundary, and initial constraints jointly. We propose Time-Induced Neural Networks (TINNs), a novel architecture that parameterizes the network weights as a learned function of time, allowing the effective spatial representation to evolve over time while maintaining shared structure. The resulting formulation naturally yields a nonlinear least-squares problem, which we optimize efficiently using a Levenberg--Marquardt method. Experiments on various time-dependent PDEs show up to $4\times$ improved accuracy and $10\times$ faster convergence compared to PINNs and strong baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20361v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chen-Yang Dai, Che-Chia Chang, Te-Sheng Lin, Ming-Chih Lai, Chieh-Hsin Lai</dc:creator>
    </item>
    <item>
      <title>A multiscale approach to the stationary Ginzburg-Landau equations of superconductivity</title>
      <link>https://arxiv.org/abs/2409.12023</link>
      <description>arXiv:2409.12023v3 Announce Type: replace 
Abstract: In this work, we study the numerical approximation of minimizers of the Ginzburg-Landau free energy, a common model to describe the behavior of superconductors under magnetic fields. The unknowns are the order parameter, which characterizes the density of superconducting charge carriers, and the magnetic vector potential, which allows to deduce the magnetic field that penetrates the superconductor. Physically important and numerically challenging are especially settings which involve lattices of quantized vortices which can be formed in materials with a large Ginzburg-Landau parameter $\kappa$. In particular, $\kappa$ introduces a severe mesh resolution condition for numerical approximations. In order to reduce these computational restrictions, we investigate a particular discretization which is based on mixed meshes where we apply a Lagrange finite element approach for the vector potential and a localized orthogonal decomposition (LOD) approach for the order parameter. We justify the proposed method by a rigorous a-priori error analysis (in $L^2$ and $H^1$) in which we keep track of the influence of $\kappa$ in all error contributions. This allows us to conclude $\kappa$-dependent resolution conditions for the various meshes and which only impose moderate practical constraints compared to a conventional finite element discretization. Finally, our theoretical findings are illustrated by numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12023v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian D\"oding, Benjamin D\"orich, Patrick Henning</dc:creator>
    </item>
    <item>
      <title>Speeding up an unsteady flow simulation by adaptive BDDC and Krylov subspace recycling</title>
      <link>https://arxiv.org/abs/2412.17543</link>
      <description>arXiv:2412.17543v3 Announce Type: replace 
Abstract: We deal with accelerating the solution of a sequence of large linear systems solved by preconditioned conjugate gradient method (PCG). The sequence originates from time-stepping within a simulation of an unsteady incompressible flow. We apply a pressure correction scheme and focus on the solution of the Poisson problem for the pressure corrector. Its scalable solution presents the main computational challenge in many applications. The right-hand side of the problem changes in each time step, while the system matrix is constant and symmetric positive definite. The acceleration techniques are studied on a representative problem of flow around a unit sphere. Our baseline approach is based on a parallel solution of each problem in the sequence by nonoverlapping domain decomposition method. The interface problem is solved by PCG with the three-level BDDC preconditioner. As a preliminary step, an appropriate stopping criterion for the PCG iterations is chosen. Next, two techniques for accelerating the solution are gradually added to the baseline approach. Deflation is used within PCG with several approaches to Krylov subspace recycling. Finally, we add the adaptive selection of the coarse space within the three-level BDDC method. The paper is rich in experiments with careful measurements of computational times on a parallel supercomputer. The combination of the acceleration techniques eventually leads to saving more than 40 % of the computational time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17543v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Martin Hanek, Jan Pape\v{z}, Jakub \v{S}\'istek</dc:creator>
    </item>
    <item>
      <title>Convergence analysis of SPH method on irregular particle distributions for the Poisson equation</title>
      <link>https://arxiv.org/abs/2503.15188</link>
      <description>arXiv:2503.15188v2 Announce Type: replace 
Abstract: The numerical accuracy of particle-based approximations in Smoothed Particle Hydrodynamics (SPH) is significantly affected by the spatial uniformity of particle distributions, especially for second-order derivatives. This study aims to enhance the accuracy of SPH method and analyze its convergence with irregular particle distributions. By establishing regularity conditions for particle distributions, we ensure that the local truncation error of traditional SPH formulations, including first and second derivatives, achieves second-order accuracy. Our proposed method, the volume reconstruction SPH method, guarantees these regularity conditions while preserving the discrete maximum principle. Benefiting from the discrete maximum principle, we conduct a rigorous global error analysis in the $L^\infty$-norm for the Poisson equation with variable coefficients, achieving second-order convergence. Numerical examples are presented to validate the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15188v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhonghua Qiao, Yifan Wei</dc:creator>
    </item>
    <item>
      <title>Numerical analysis of an H(div)-conforming divergence-free DG method with a second-order explicit Runge-Kutta scheme for incompressible flows</title>
      <link>https://arxiv.org/abs/2504.18903</link>
      <description>arXiv:2504.18903v3 Announce Type: replace 
Abstract: Recently, H(div)-conforming DG type methods coupled with Runge-Kutta (RK) time stepping have been widely employed for simulating high Reynolds number flows, with the convective terms treated explicitly. Although the analysis techniques of RKDG methods were well developed, the extension to incompressible flows is highly nontrivial due to the exactly divergence-free constraint, where the key lies in analyzing the convective terms. We neglect viscosity effects, and conduct an error analysis for an H(div)-conforming divergence-free DG method combined with a second-order explicit RK scheme, for the incompressible Euler equations. We derive an a priori error estimate of $O(h^{k+1 / 2}+\tau^2)$ under a restrictive CFL condition $\tau \lesssim h^{4 / 3}$ for polynomials of degree $k \geq 1$, where $h$ and $\tau$ are the mesh size and time step size, respectively, assuming that the exact solution is smooth. For the case of linear polynomials, we investigate whether existing analytical techniques can relax the restrictive CFL condition to a standard CFL condition $\tau \lesssim h$. It is demonstrated that the exactly divergence-free constraint prevents the application of these techniques. We conjecture that the error estimates for linear polynomials cannot be derived under a standard CFL condition. Finally, we mention that based on our analytical framework, our analytical results will be readily extended to the Navier-Stokes equations at high mesh Reynolds number, with the viscous and convective terms treated explicitly. Numerical experiments are conducted, supporting our analytical results and the conjecture for linear polynomials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18903v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yongbin Han, Yanren Hou, Xuehua Zhao</dc:creator>
    </item>
    <item>
      <title>Bayesian dictionary learning estimation of cell membrane permeability from surface pH data</title>
      <link>https://arxiv.org/abs/2507.09651</link>
      <description>arXiv:2507.09651v2 Announce Type: replace 
Abstract: Gas transport across cell membrane is a very important process in biochemistry which is essential for many crucial tasks, including cell respiration pH regulation in the cell. In the late 1990's, the suggestion that gasses are transported via preferred gas channels embedded into the cell membrane challenged the century old Overton's theory that gases pass through the lipid cell membrane by diffusing across the concentration gradient. Since experimental evidence alone does not provide enough evidence to favor one of the proposed mechanisms, mathematical models have been introduced to provide a context for the interpretation of laboratory measurement. Following up on previous work where the membrane permeability was estimated using particle filter, in this article we propose an algorithm based on dictionary learning for estimating cell membrane permeability. Computed examples illustrate that the novel approach, which can be applied when the properties of the membrane do not change in the course of the data collection process, is computationally much more efficient than particle filter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09651v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alberto Bocchinfuso, Daniela Calvetti, Erkki Somersalo</dc:creator>
    </item>
    <item>
      <title>Preconditioned pseudo-time continuation for parameterized inverse problems</title>
      <link>https://arxiv.org/abs/2508.21155</link>
      <description>arXiv:2508.21155v2 Announce Type: replace 
Abstract: We consider parameterized variational inverse problems that are constrained by partial differential equations (PDEs). We seek to efficiently compute the solution of the inverse problem when auxiliary model parameters, which appear in the governing PDE, are varied. Computing the solution of the inverse problem for different auxiliary parameter values is crucial for uncertainty quantification. This, however, is computationally challenging since it requires solving many optimization problems for different realizations of the auxiliary parameters. We leverage pseudo-time continuation and solve an initial value problem to evolve the optimal solution along an auxiliary parameter path. This article introduces the use of an adaptive quasi-Newton Hessian preconditioner to accelerate the computation. Our proposed preconditioner exploits properties of the pseudo-time continuation process to achieve reliable and efficient computation. We elaborate our proposed framework and elucidate its properties for two nonlinear inverse problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21155v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joseph Hart, Alen Alexanderian, Bart van Bloemen Waanders</dc:creator>
    </item>
    <item>
      <title>Invariant subspace perturbations related to defective eigenvalues of $\Delta$-Hermitian and Hamiltonian matrices</title>
      <link>https://arxiv.org/abs/2509.10643</link>
      <description>arXiv:2509.10643v2 Announce Type: replace 
Abstract: Structured perturbation results for invariant subspaces of $\Delta$-Hermitian and Hamiltonian matrices are provided. The invariant subspaces under consideration are associated with the eigenvalues perturbed from a single defective eigenvalue. The results show how the original eigenvectors and generalized eigenvectors are involved in composing such perturbed invariant subspaces and eigenvectors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10643v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hongguo Xu</dc:creator>
    </item>
    <item>
      <title>Recursive algorithms for computing Birkhoff interpolation polynomials</title>
      <link>https://arxiv.org/abs/2511.09014</link>
      <description>arXiv:2511.09014v2 Announce Type: replace 
Abstract: As a generalization of Hermite interpolation problem, Birkhoff interpolation is an important subject in numerical approximation. This paper generalizes the existing Generalized Recursive Polynomial Interpolation Algorithm (GRPIA) that is used to compute the Hermite interpolation polynomial. Based on the theory of the Schur complement and the Sylvester identity, the proposed recursive algorithms are applicable to a broader class of Birkhoff interpolation problems, where each interpolation condition is given by the composition of an evaluation functional and a differential polynomial. The approach incorporates a judgment condition to ensure the problem's well-posedness and computes a lower-degree Newton-type interpolation basis (which is also a strongly proper interpolation basis) along with the corresponding interpolation polynomial. Following the numerical examples, we analyze and compare the computational process and complexity of the proposed algorithm against traditional interpolation methods based on Gaussian elimination, and thus demonstrate that the proposed recursive approach reduces both computational cost and storage space requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09014v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xue Jiang, Yuanhe Li, Zhe Li</dc:creator>
    </item>
    <item>
      <title>Qualitative and Numerical Simulation of a Time-Fractional SEIR Mpox Model Arising in Population Epidemiology</title>
      <link>https://arxiv.org/abs/2601.09479</link>
      <description>arXiv:2601.09479v2 Announce Type: replace 
Abstract: Epidemiological modeling is vital in understanding disease dynamics and guiding public health interventions. This study presents a time-fractional SEIR model to describe the transmission dynamics of Mpox, incorporating memory effects via the fractional derivative. We perform an extensive qualitative investigation, proving that there is a unique solution and that the solutions are Hyers-Ulam stable. To approximate the model numerically, we implement the L1 finite difference scheme for the Caputo derivative and solve the resulting nonlinear system using the Newton-Raphson technique. A detailed error analysis is provided, demonstrating that the scheme achieves algebraic convergence. Comparative results with the Fractional Modified Euler method (FMEM) confirm the superior accuracy and stability of the proposed approach. Numerical simulations under biologically relevant parameters illustrate the impact of the non-integer order and vaccination rate on disease progression. The study underscores the effectiveness of fractional order models in capturing epidemic memory effects and positions the L1 scheme as a robust numerical tool for simulating such dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09479v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gaurav Saini, Bappa Ghosh, Sunita Chand, Jugal Mohapatra</dc:creator>
    </item>
    <item>
      <title>Moving Least Squares without Quasi-Uniformity: A Stochastic Approach</title>
      <link>https://arxiv.org/abs/2601.13782</link>
      <description>arXiv:2601.13782v2 Announce Type: replace-cross 
Abstract: Local Polynomial Regression (LPR) and Moving Least Squares (MLS) are closely related nonparametric estimation methods, developed independently in statistics and approximation theory. While statistical LPR analysis focuses on overcoming sampling noise under probabilistic assumptions, the deterministic MLS theory studies smoothness properties and convergence rates with respect to the \textit{fill-distance} (a resolution parameter). Despite this similarity, the deterministic assumptions underlying MLS fail to hold under random sampling. We begin by quantifying the probabilistic behavior of the fill-distance $h_n$ and \textit{separation} $\delta_n$ of an i.i.d. random sample. That is, for a distribution satisfying a mild regularity condition, $h_n\propto n^{-1/d}\log^{1/d} (n)$ and $\delta_n \propto n^{-1/d}$. We then prove that, for MLS of degree $k\!-\!1$, the approximation error associated with a differential operator $Q$ of order $|m|\le k-1$ decays as $h_n^{\,k-|m|}$ up to logarithmic factors, establishing stochastic analogues of the classical MLS estimates. Additionally, We show that the MLS approximant is smooth with high probability. Finally, we apply the stochastic MLS theory to manifold estimation. Assuming that the sampled Manifold is $k$-times smooth, we show that the Hausdorff distance between the true manifold and its MLS reconstruction decays as $h_n^k$, extending the deterministic Manifold-MLS guarantees to random samples. This work provides the first unified stochastic analysis of MLS, demonstrating that -- despite the failure of deterministic sampling assumptions -- the classical convergence and smoothness properties persist under natural probabilistic models</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13782v2</guid>
      <category>math.ST</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.TH</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shir Tapiro-Moshe, Yariv Aizenbud, Barak Sober</dc:creator>
    </item>
  </channel>
</rss>
