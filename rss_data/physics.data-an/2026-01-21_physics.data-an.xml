<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 21 Jan 2026 05:02:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Logarithmic scaling and stochastic criticality in collective attention</title>
      <link>https://arxiv.org/abs/2601.12306</link>
      <description>arXiv:2601.12306v1 Announce Type: cross 
Abstract: We uncover a universal scaling law governing the dispersion of collective attention and identify its underlying stochastic criticality. By analysing large-scale ensembles of Wikipedia page views, we find that the variance of logarithmic attention grows ultraslowly, $\operatorname{Var}[\ln{X(t)}]\propto\ln{t}$, in sharp contrast to the power-law scaling typically expected for diffusive processes. We show that this behaviour is captured by a minimal stochastic differential equation driven by fractional Brownian motion, in which long-range memory ($H$) and temporal decay of volatility ($\eta$) enter through the single exponent $\xi\equiv H-\eta$. At marginality, $\xi=0$, the variance grows logarithmically, marking the critical boundary between power-law growth ($\xi&gt;0$) and saturation ($\xi&lt;0$). By incorporating article-level heterogeneity through a Gaussian mixture model, we further reconstruct the empirical distribution of cumulative attention within the same framework. Our results place collective attention in a distinct class of non-Markovian stochastic processes, with close affinity to ageing-like and ultraslow dynamics in glassy systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.12306v1</guid>
      <category>physics.soc-ph</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.DL</category>
      <category>cs.SI</category>
      <category>physics.data-an</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keisuke Okamura</dc:creator>
    </item>
    <item>
      <title>PYVALE: A Fast, Scalable, Open-Source 2D Digital Image Correlation (DIC) Engine Capable of Handling Gigapixel Images</title>
      <link>https://arxiv.org/abs/2601.12941</link>
      <description>arXiv:2601.12941v1 Announce Type: cross 
Abstract: Pyvale is an open-source software package that aims to become an all-in-one tool for sensor simulation, sensor uncertainty quantification, sensor placement optimization, and calibration/validation. Central to this is support for image-based sensors, with a dedicated Digital Image Correlation (DIC) module designed for both standalone use and integration within broader experimental design workflows. The design philosophy behind the DIC engine in Pyvale prioritizes a user-friendly Python interface with performant compiled code under the hood. This paper covers Pyvale's 2D DIC engine design, implementation, metrological performance compared to other DIC codes, and the unique ability to handle gigapixel size scanning electron microscope (SEM) images. Finally, we compare runtimes between Pyvale and other open-source DIC codes and show strong computational performance across a range of image resolutions and thread counts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.12941v1</guid>
      <category>eess.IV</category>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.data-an</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Joel Hirst, Lorna Sibson, Adel Tayeb, Ben Poole, Megan Sampson, Wiera Bielajewa, Michael Atkinson, Alex Marsh, Rory Spencer, Rob Hamill, Cory Hamelin, Allan Harte, Lloyd Fletcher</dc:creator>
    </item>
    <item>
      <title>CausationEntropy: Pythonic Optimal Causation Entropy</title>
      <link>https://arxiv.org/abs/2601.13365</link>
      <description>arXiv:2601.13365v1 Announce Type: cross 
Abstract: Optimal Causation Entropy (oCSE) is a robust causal network modeling technique that reveals causal networks from dynamical systems and coupled oscillators, distinguishing direct from indirect paths. CausationEntropy is a Python package that implements oCSE and several of its significant optimizations and methodological extensions. In this paper, we introduce the version 1.1 release of CausationEntropy, which includes new synthetic data generators, plotting tools, and several advanced information-theoretical causal network discovery algorithms with criteria for estimating Gaussian, k-nearest neighbors (kNN), geometric k-nearest neighbors (geometric-kNN), kernel density (KDE) and Poisson entropic estimators. The package is easy to install from the PyPi software repository, is thoroughly documented, supplemented with extensive code examples, and is modularly structured to support future additions. The entire codebase is released under the MIT license and is available on GitHub and through PyPi Repository. We expect this package to serve as a benchmark tool for causal discovery in complex dynamical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13365v1</guid>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kevin Slote, Jeremie Fish, Erik Bollt</dc:creator>
    </item>
    <item>
      <title>It's Not The Plane -- It's The Pilot: A Framework for Cognitive-Activated AI-Augmentation to Avoid the Boiling Frog Problem</title>
      <link>https://arxiv.org/abs/2601.13812</link>
      <description>arXiv:2601.13812v1 Announce Type: cross 
Abstract: Generative artificial intelligence (AI) systems can now reliably solve many standard tasks used in introductory physics courses, producing correct equations, graphs, and explanations. While this capability is often framed as an opportunity for efficiency or personalization, it also poses a subtle ethical and educational risk: students may increasingly submit correct results without engaging in the epistemic practices that define learning physics.This challenge has recently been described as the "boiling frog problem" because we may not fully recognize how rapidly AI capabilities are advancing and fail to respond with commensurate urgency. In this article, we argue that the central challenge of AI in physics education is not cheating or tool selection, but instructional design. Drawing on research on self-regulated learning, cognitive load, multiple representations, and hybrid intelligence, we propose a practical framework for cognitively activated learning activities that structures student activities before, during, and after AI use. Using an example from an introductory kinematics laboratory, we show how AI can be integrated in ways that preserve prediction, interpretation, and evaluation as core learning activities. Rather than treating AI as an answer-generating tool, the framework positions AI as an epistemic partner whose contributions are deliberately bounded and reflected upon.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13812v1</guid>
      <category>physics.ed-ph</category>
      <category>physics.data-an</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jochen Kuhn, Stefan K\"uchemann, Dave Rakestraw, Patrik Vogt</dc:creator>
    </item>
    <item>
      <title>Evaluating state-of-the-art cloud quantum computers for quantum neural networks in gravitational waves data analysis</title>
      <link>https://arxiv.org/abs/2601.14036</link>
      <description>arXiv:2601.14036v1 Announce Type: cross 
Abstract: In this work, we explore the possibility of using quantum computers provided for usage in cloud by big companies (such as IBM, IonQ, IQM Quantum Computers, etc.) to run our quantum neural network (QNN) developed for data analysis in the context of LISA Space Mission, developed with the Qiskit library in Python. Our previous work demonstrated that our QNN learns patterns in gravitational wave (GW) data much faster than a classical neural network, making it suitable for fast GW signal detection in future LISA data streams. Analyzing the fees from hardware providers like IBM Quantum, Amazon Braket and Microsoft Azure, we found that the fees for running the first segment of our QNN sum up to \$2000, \$60000, and \$1000000 respectively. Using free plans, we succeed to run the 3-qubit feature map of the QNN for one random data sample on {\fontfamily{qcr} \selectfont ibm\_kyoto} and {\fontfamily{qcr}\selectfont IQM Quantum Computers\_Garnet} quantum computers, obtaining a fidelity of 99\%; we could also run the first prediction segment of our QNN on {\fontfamily{qcr} \selectfont ibm\_kyoto}, implemented for 4 qubits, and obtained a prediction accuracy of 20\%. We queried providers such as IBM Quantum, Amazon Braket, Pasqal, and Munich Quantum Valley to obtain access to their plans, but, with the exception of Amazon Braket, our applications remain unanswered to this day. Other major setbacks in using the quantum computers we had access to included Qiskit library version issues (as in the cases of IBM Quantum and IQM Quantum Computers) and the frequent unavailability of the devices, as was the case with the Microsoft Azure provider. All the results presented in this paper were accumulated in 2024.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.14036v1</guid>
      <category>astro-ph.CO</category>
      <category>astro-ph.IM</category>
      <category>physics.data-an</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maria-Catalina Isfan, Laurentiu-Ioan Caramete, Ana Caramete</dc:creator>
    </item>
    <item>
      <title>Under-coverage in high-statistics counting experiments with finite MC samples</title>
      <link>https://arxiv.org/abs/2401.10542</link>
      <description>arXiv:2401.10542v3 Announce Type: replace 
Abstract: We consider the problem of setting confidence intervals on a parameter of interest from the maximum-likelihood fit of a physics model to a binned data set with a large number of bins, large event-counts per bin, and in the presence of systematic uncertainties modeled as nuisance parameters. We use the profile-likelihood ratio for statistical inference and focus on the case in which the model is determined from Monte Carlo simulated samples of finite size. We start by presenting a toy model in which the properties of widely used approximations of the profile-likelihood ratio in the asymptotic limit, which are commonly expected to hold in the high-statistics regime, are manifestly broken even if the numbers of events per bin in both the data and simulated samples are seemingly large enough to warrant their validity. We then move to the general setting to show how statistical uncertainties in the Monte Carlo predictions can affect the coverage of confidence intervals constructed in the asymptotic approximation always in the same direction, namely they lead to systematic under-coverage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.10542v3</guid>
      <category>physics.data-an</category>
      <category>hep-ex</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cristina-Andreea Alexe, Joshua Bendavid, Lorenzo Bianchini, Davide Bruschini</dc:creator>
    </item>
    <item>
      <title>An Adaptive Online Smoother with Closed-Form Solutions and Information-Theoretic Lag Selection for Conditional Gaussian Nonlinear Systems</title>
      <link>https://arxiv.org/abs/2411.05870</link>
      <description>arXiv:2411.05870v2 Announce Type: replace-cross 
Abstract: Data assimilation (DA) combines partial observations with dynamical models to improve state estimation. Filter-based DA uses only past and present data and is the prerequisite for real-time forecasts. Smoother-based DA exploits both past and future observations. It aims to fill in missing data, provide more accurate estimations, and develop high-quality datasets. However, the standard smoothing procedure requires using all historical state estimations, which is storage-demanding, especially for high-dimensional systems. This paper develops an adaptive-lag online smoother for a large class of complex dynamical systems with strong nonlinear and non-Gaussian features, which has important applications to many real-world problems. The adaptive lag allows the utilization of observations only within a nearby window, thus reducing computational complexity and storage needs. Online lag adjustment is essential for tackling turbulent systems, where temporal autocorrelation varies significantly over time due to intermittency, extreme events, and nonlinearity. Based on the uncertainty reduction in the estimated state, an information criterion is developed to systematically determine the adaptive lag. Notably, the mathematical structure of these systems facilitates the use of closed analytic formulae to calculate the online smoother and adaptive lag, avoiding empirical tunings as in ensemble-based DA methods. The adaptive online smoother is applied to studying three important scientific problems. First, it helps detect online causal relationships between state variables. Second, the advantage of reduced computational storage expenditure is illustrated via Lagrangian DA, a high-dimensional nonlinear problem. Finally, the adaptive smoother advances online parameter estimation with partial observations, emphasizing the role of the observed extreme events in accelerating convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05870v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.DS</category>
      <category>math.PR</category>
      <category>physics.data-an</category>
      <category>stat.ME</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marios Andreou, Nan Chen, Yingda Li</dc:creator>
    </item>
    <item>
      <title>Machine Learning Symmetry Discovery for Integrable Hamiltonian Dynamics</title>
      <link>https://arxiv.org/abs/2412.14632</link>
      <description>arXiv:2412.14632v2 Announce Type: replace-cross 
Abstract: We propose a data-driven Machine-Learning Symmetry Discovery (MLSD) framework for identifying continuous symmetry generators and their Lie-algebraic structure directly from phase-space trajectory data expressed in canonical coordinates. MLSD parameterizes candidate conserved quantities with neural networks and learns antisymmetric structure coefficients by enforcing Poisson-bracket closure, supplemented by a weak independence regularizer. We validate MLSD on two integrable benchmark systems -- the three-dimensional Kepler problem and the three-dimensional isotropic harmonic oscillator -- recovering the expected non-Abelian algebras (respectively $\mathfrak{so}(4)$ and $\mathfrak{su}(3)$) up to basis transformations. This work focuses on integrable benchmark dynamics, where global conserved quantities are well-defined and admit compact representations learnable from canonical-coordinate trajectories. Extending symmetry discovery to mixed or chaotic phase-space regimes is an important direction for future work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14632v2</guid>
      <category>cond-mat.dis-nn</category>
      <category>physics.class-ph</category>
      <category>physics.data-an</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wanda Hou, Molan Li, Yi-Zhuang You</dc:creator>
    </item>
  </channel>
</rss>
