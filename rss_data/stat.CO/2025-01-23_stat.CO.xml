<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 23 Jan 2025 05:00:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>TimeDepFrail: Time-Dependent Shared Frailty Cox Models in R</title>
      <link>https://arxiv.org/abs/2501.12718</link>
      <description>arXiv:2501.12718v1 Announce Type: new 
Abstract: This paper introduces TimeDepFrail, an R package designed to implement time-varying shared frailty models by extending the traditional shared frailty Cox model to allow the frailty term to evolve across time intervals. These models are particularly suited for survival analysis in clustered data where unobserved heterogeneity changes over time, providing greater flexibility in modeling time-to-event data.
  The package builds on the piecewise gamma frailty model originally proposed by Paik (1994) and refined by Wintrebert et al. (2004). Our key contributions include the integration of posterior frailty estimation, a reduction in computational complexity, the definition of a prediction framework and the efficient implementation of these models within an R package.
  As a practical application, we use TimeDepFrail to analyze dropout rates within a university, where high dropout rates are a known issue. By allowing frailty to vary over time, the package uncovers new insights into the unobserved factors influencing dropout.
  TimeDepFrail simplifies access to advanced time-varying frailty models, providing a practical and scalable alternative to more computationally demanding methods, making it highly applicable for large-scale datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12718v1</guid>
      <category>stat.CO</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alessandra Ragni, Giulia Romani, Chiara Masci</dc:creator>
    </item>
    <item>
      <title>Outcome-Assisted Multiple Imputation of Missing Treatments</title>
      <link>https://arxiv.org/abs/2501.12471</link>
      <description>arXiv:2501.12471v1 Announce Type: cross 
Abstract: We provide guidance on multiple imputation of missing at random treatments in observational studies. Specifically, analysts should account for both covariates and outcomes, i.e., not just use propensity scores, when imputing the missing treatments. To do so, we develop outcome-assisted multiple imputation of missing treatments: the analyst fits a regression for the outcome on the treatment indicator and covariates, which is used to sharpen the predictive probabilities for missing treatments under an estimated propensity score model. We derive an expression for the bias of the inverse probability weighted estimator for the average treatment effect under multiple imputation of missing treatments, and we show theoretically that this bias can be made small by using outcome-assisted multiple imputation. Simulations demonstrate empirically that outcome-assisted multiple imputation can offer better inferential properties than using the treatment assignment model alone. We illustrate the procedure in an analysis of data from the National Longitudinal Survey of Youth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12471v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joseph Feldman, Jerome P. Reiter</dc:creator>
    </item>
    <item>
      <title>BRBVS: An R Package for Bivariate Variable selection in Copula Survival Model(s) domain</title>
      <link>https://arxiv.org/abs/2501.12837</link>
      <description>arXiv:2501.12837v1 Announce Type: cross 
Abstract: BRBVS is a publicly available \texttt{R} package on CRAN that implements the algorithm proposed in Petti et al.(2024a). The algorithm was developed as the first proposal of variable selection for the class of Bivariate Survival Copula Models originally proposed in Marra &amp; Radice (2020) and implemented in the \texttt{GJRM} package. The core of the \texttt{BRBVS} package is to implement and make available to practitioners variable selection algorithms for bivariate survival data affected by censoring, providing easy-to-use functions and graphical outputs. The idea behind the algorithm is almost general and may also be extended to different class of models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12837v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Danilo Petti, Marcella Niglio, Marialuisa Restaino</dc:creator>
    </item>
    <item>
      <title>Supervised and Unsupervised Mapping of Binary Variables: A proximity perspective</title>
      <link>https://arxiv.org/abs/2402.07624</link>
      <description>arXiv:2402.07624v2 Announce Type: replace 
Abstract: We propose a new mapping tool for supervised and unsupervised analysis of multivariate binary data with multiple items, questions, or response variables. The mapping assumes an underlying proximity response function, where participants can have multiple reasons to disagree or say ``no'' to a question. The probability to endorse, or to agree with an item depends on an item specific parameter and the distance in a joint space between a point representing the item and a point representing the participant. The item specific parameter defines a circle in the joint space around the location of the item such that for participants positioned within the circle the endorsement probability is larger than 0.5. For map estimation, we develop and test an MM-algorithm in which the negative log-likelihood function is majorized with a weighted least squares function. The weighted least squares function can be minimized with standard algorithms for multidimensional unfolding. To illustrate the new mapping, two empirical data sets are analyzed. The mappings are interpreted in detail and the unsupervised map is compared to a visualization based on correspondence analysis. In a Monte Carlo study, we test the performance of the algorithm in terms of recovery of population parameters and conclude that this recovery is adequate. A second Monte Carlo study investigates the predictive performance of the new mapping compared to a similar mapping with a monotone response function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07624v2</guid>
      <category>stat.CO</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s41237-024-00248-z</arxiv:DOI>
      <dc:creator>Mark de Rooij, Dion Woestenburg, Frank Busing</dc:creator>
    </item>
    <item>
      <title>Reducing Total Trip Time and Vehicle Emission through Park-and-Ride -- methods and case-study</title>
      <link>https://arxiv.org/abs/2407.05572</link>
      <description>arXiv:2407.05572v2 Announce Type: replace 
Abstract: This study addresses important issues of traffic congestion and vehicle emissions in urban areas by developing a comprehensive mathematical framework to evaluate Park-and-Ride (PnR) systems. The proposed approach integrates queueing theory and emissions modeling to simultaneously assess waiting times, travel times, and vehicle emissions under various PnR usage scenarios. The methodology employs a novel combination of Monte Carlo simulation and matrix geometric analytic methods to analyze a queueing network representing PnR facilities and road traffic. A case study of Tsukuba, Japan demonstrates the model's applicability, revealing potential reductions in social costs related to total trip time and emissions through optimized PnR policies. Specifically, the study found that implementing optimal bus frequency and capacity policies could reduce total social costs by up to 30\% compared to current conditions. This research contributes to the literature by providing a unified framework for evaluating PnR systems that considers both time and environmental costs, offering valuable insights for urban planners and policymakers seeking to improve transportation sustainability. The proposed model utilizes a single server queue with a deterministic service time and multiple arrival streams to represent traffic flow, incorporating both private cars and public buses. Emissions are calculated using the Methodologies for Estimating Air Pollutant Emissions from Transport (MEET) framework. The social cost of emissions and total trip time (SCETT) is introduced as a comprehensive metric for evaluating PnR system performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05572v2</guid>
      <category>stat.CO</category>
      <category>stat.OT</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ayane Nakamura, Fabiana Ferracina, Naoki Sakata, Takahiro Noguchi, Hiroyasu Ando</dc:creator>
    </item>
    <item>
      <title>Logistic Multidimensional Data Analysis for Ordinal Response Variables using a Cumulative Link function</title>
      <link>https://arxiv.org/abs/2402.07629</link>
      <description>arXiv:2402.07629v2 Announce Type: replace-cross 
Abstract: We present a multidimensional data analysis framework for the analysis of ordinal response variables. Underlying the ordinal variables, we assume a continuous latent variable, leading to cumulative logit models. The framework includes unsupervised methods, when no predictor variables are available, and supervised methods, when predictor variables are available. We distinguish between dominance variables and proximity variables, where dominance variables are analyzed using inner product models, whereas the proximity variables are analyzed using distance models. An expectation-majorization-minimization algorithm is derived for estimation of the parameters of the models. We illustrate our methodology with three empirical data sets highlighting the advantages of the proposed framework. A simulation study is conducted to evaluate the performance of the algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07629v2</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mark de Rooij, Ligaya Breemer, Dion Woestenburg, Frank Busing</dc:creator>
    </item>
    <item>
      <title>A Multinomial Canonical Decomposition Model, with emphasis on the analysis of Multivariate Binary data</title>
      <link>https://arxiv.org/abs/2402.07634</link>
      <description>arXiv:2402.07634v3 Announce Type: replace-cross 
Abstract: In this paper, we propose to decompose the canonical parameter of a multinomial model into a set of participant scores and category scores. External information about the participants or the categories can be used to restrict these scores. Therefore, we impose the constraint that the scores are linear combinations of the external variables. For the estimation of the parameters of the decomposition, we derive a majorization-minimization algorithm. We place special emphasis on the case where the categories represent profiles of binary response variables. In that case, the multinomial model becomes a regression model for multiple binary response variables and researchers might be interested in the effect of an external variable for the participant (i.e., a predictor) on a binary response variable or in the effect of this predictor on the association among binary response variables. We derive interpretational rules for these relationships in terms of changes in log odds or log odds ratios. Connections between our multinomial canonical decomposition and loglinear models, multinomial logistic regression, multinomial reduced rank logistic regression, and double constrained correspondence analysis are discussed. We use two empirical data sets, the first to show the relationships between a loglinear analysis approach and our modelling approach. The second data set is used as an illustration of our modelling approach and describes the model selection and interpretation in detail.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07634v3</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mark de Rooij</dc:creator>
    </item>
    <item>
      <title>Statistical algorithms for low-frequency diffusion data: A PDE approach</title>
      <link>https://arxiv.org/abs/2405.01372</link>
      <description>arXiv:2405.01372v3 Announce Type: replace-cross 
Abstract: We consider the problem of making nonparametric inference in a class of multi-dimensional diffusions in divergence form, from low-frequency data. Statistical analysis in this setting is notoriously challenging due to the intractability of the likelihood and its gradient, and computational methods have thus far largely resorted to expensive simulation-based techniques. In this article, we propose a new computational approach which is motivated by PDE theory and is built around the characterisation of the transition densities as solutions of the associated heat (Fokker-Planck) equation. Employing optimal regularity results from the theory of parabolic PDEs, we prove a novel characterisation for the gradient of the likelihood. Using these developments, for the nonlinear inverse problem of recovering the diffusivity, we then show that the numerical evaluation of the likelihood and its gradient can be reduced to standard elliptic eigenvalue problems, solvable by powerful finite element methods. This enables the efficient implementation of a large class of popular statistical algorithms, including (i) preconditioned Crank-Nicolson and Langevin-type methods for posterior sampling, and (ii) gradient-based descent optimisation schemes to compute maximum likelihood and maximum-a-posteriori estimates. We showcase the effectiveness of these methods via extensive simulation studies in a nonparametric Bayesian model with Gaussian process priors, in which both the proposed optimisation and sampling schemes provide good numerical recovery. The reproducible code is available online at https://github.com/MattGiord/LF-Diffusion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01372v3</guid>
      <category>stat.ME</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Giordano, Sven Wang</dc:creator>
    </item>
    <item>
      <title>Reduced Rank Regression for Mixed Predictor and Response Variables</title>
      <link>https://arxiv.org/abs/2405.19865</link>
      <description>arXiv:2405.19865v2 Announce Type: replace-cross 
Abstract: In this paper, we propose the generalized mixed reduced rank regression method, GMR$^3$ for short. GMR$^3$ is a regression method for a mix of numeric, binary, and ordinal response variables. The predictor variables can be a mix of binary, nominal, ordinal, and numeric variables. For dealing with the categorical predictors we use optimal scaling. A majorization-minimization algorithm is derived for maximum likelihood estimation under a local independence assumption. A series of simulation studies is shown (Section 4) to evaluate the performance of the algorithm with different types of predictor and response variables. In Section 5.2, we briefly discuss the choices to make when applying the model the empirical data and give suggestions for supporting such choices. In Section 6.1, we show an application of GMR$^3$ using the Eurobarometer Surveys data set of 2023.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19865v2</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mark de Rooij, Lorenza Cotugno, Roberta Siciliano</dc:creator>
    </item>
  </channel>
</rss>
