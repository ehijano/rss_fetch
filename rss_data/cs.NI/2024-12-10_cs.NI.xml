<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 10 Dec 2024 05:00:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Enhanced 5G/B5G Network Planning/Optimization deploying RIS in Urban/Outdoor Scenarios</title>
      <link>https://arxiv.org/abs/2412.05385</link>
      <description>arXiv:2412.05385v1 Announce Type: new 
Abstract: In recent years, the fifth-generation (5G) mobile network has been developed worldwide to remarkably improve network performance and spectral efficiency. Very recently, reconfigurable intelligent surfaces (RISs) technology has emerged as an innovative solution for controlling the propagation medium of the forthcoming sixth-generation (6G) networks. Specifically, RIS takes advantage of the reflected rays on the propagation environment to redirect them to a desired target, improving wireless coverage. To further improve RIS performance, an interesting technique called synchronized transmission with advanced reconfigurable surfaces (STARS) has appeared to allow simultaneous transmission and reflection of intelligent omni-surfaces. With that in mind, this paper introduces an enhanced strategy for the network planning of 5G and beyond (B5G) mobile networks in dense urban scenarios focused on the city of Quito-Ecuador. The efficacy of RIS and its cutting-edge STARS concept is emphasized, providing useful insights into coverage, quality, and throughput results. In particular, this work considers the 3.5/28 GHz frequency bands, optimizing the radio network and anticipating their applicability in B5G networks. Finally, simulation results are also shown, which allow the identification of the benefits of STAR RIS in terms of coverage, signal quality, and data performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05385v1</guid>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Valdemar Farr\'e, Juan C. Estrada-Jim\'enez, Jos\'e D. Vega S\'anchez, Juan A. Vasquez-Peralvo, Symeon Chatzinotas</dc:creator>
    </item>
    <item>
      <title>Partially Synchronous BFT Consensus Made Practical in Wireless Networks</title>
      <link>https://arxiv.org/abs/2412.05512</link>
      <description>arXiv:2412.05512v1 Announce Type: new 
Abstract: Consensus is becoming increasingly important in wireless networks. Partially synchronous BFT consensus, a significant branch of consensus, has made considerable progress in wired networks. However, its implementation in wireless networks, especially in dynamic ad hoc wireless networks, remains challenging. Existing wireless synchronous consensus protocols, despite being well-developed, are not readily adaptable to partially synchronous settings. Additionally, reliable communication, a cornerstone of BFT consensus, can lead to high message and time complexity in wireless networks. To address these challenges, we propose a wireless communication protocol called ReduceCatch (Reduce and Catch) that supports reliable 1-to-N, N-to-1, and N-to-N communications. We employ ReduceCatch to tailor three partially synchronous BFT consensus protocols (PBFT, Tendermint, and HotStuff) for seamless adaptation from wired to ad hoc wireless networks. To evaluate the performance of the ReduceCatch-enabled consensus protocols, we develop a three-layer wireless consensus testbed, based on which we implement 20 distinct consensus protocols and measure their latency and throughput. The experimental results demonstrate the superiority of the ReduceCatch-based consensus protocol in terms of latency and throughput.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05512v1</guid>
      <category>cs.NI</category>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuo Liu, Minghui Xu, Yuezhou Zheng, Yifei Zou, Wangjie Qiu, Gang Qu, Xiuzhen Cheng</dc:creator>
    </item>
    <item>
      <title>RouteNet-Fermi: Network Modeling With GNN (Analysis And Re-implementation)</title>
      <link>https://arxiv.org/abs/2412.05649</link>
      <description>arXiv:2412.05649v1 Announce Type: new 
Abstract: Network performance modeling presents important challenges in modern computer networks due to increasing complexity, scale, and diverse traffic patterns. While traditional approaches like queuing theory and packet-level simulation have served as foundational tools, they face limitations in modeling complex traffic behaviors and scaling to large networks. This project presents an extended implementation of RouteNet-Fermi, a Graph Neural Network (GNN) architecture designed for network performance prediction, with additional recurrent neural network variants. We improve the the original architecture by implementing Long Short-Term Memory (LSTM) cells and Recurrent Neural Network (RNN) cells alongside the existing Gated Recurrent Unit (GRU) cells implementation. This work contributes to the understanding of recurrent neural architectures in GNN-based network modeling and provides a flexible framework for future experimentation with different cell types.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05649v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shourya Verma, Simran Kadadi, Swathi Jayaprakash, Arpan Kumar Mahapatra, Ishaan Jain</dc:creator>
    </item>
    <item>
      <title>Network Slicing with Flexible VNF Order: A Branch-and-Bound Approach</title>
      <link>https://arxiv.org/abs/2412.05993</link>
      <description>arXiv:2412.05993v1 Announce Type: new 
Abstract: Network slicing is a critical feature in 5G and beyond communication systems, enabling the creation of multiple virtual networks (i.e., slices) on a shared physical network infrastructure. This involves efficiently mapping each slice component, including virtual network functions (VNFs) and their interconnections (virtual links), onto the physical network.
  This paper considers slice embedding problem in which the order of VNFs can be adjusted, providing increased flexibility for service deployment on the infrastructure. This also complicates embedding, as the best order has to be selected. We propose an innovative optimization framework to tackle the challenges of jointly optimizing slice admission control and embedding with flexible VNF ordering. Additionally, we introduce a near-optimal branch-and-bound (BnB) algorithm, combined with the A* search algorithm, to generate embedding solutions efficiently. Extensive simulations on both small and large-scale scenarios demonstrate that flexible VNF ordering significantly increases the number of deployable slices within the network infrastructure, thereby improving resource utilization and meeting diverse demands across varied network topologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05993v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Quang-Trung Luu, Minh-Thanh Nguyen, Tuan-Anh Do, Michel Kieffer, Van-Dinh Nguyen, Tai-Hung Nguyen, Huu-Thanh Nguyen</dc:creator>
    </item>
    <item>
      <title>Hallucination-aware Optimization for Large Language Model-empowered Communications</title>
      <link>https://arxiv.org/abs/2412.06007</link>
      <description>arXiv:2412.06007v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have significantly advanced communications fields, such as Telecom Q\&amp;A, mathematical modeling, and coding. However, LLMs encounter an inherent issue known as hallucination, i.e., generating fact-conflicting or irrelevant content. This problem critically undermines the applicability of LLMs in communication systems yet has not been systematically explored. Hence, this paper provides a comprehensive review of LLM applications in communications, with a particular emphasis on hallucination mitigation. Specifically, we analyze hallucination causes and summarize hallucination mitigation strategies from both model- and system-based perspectives. Afterward, we review representative LLM-empowered communication schemes, detailing potential hallucination scenarios and comparing the mitigation strategies they adopted. Finally, we present a case study of a Telecom-oriented LLM that utilizes a novel hybrid approach to enhance the hallucination-aware service experience. On the model side, we publish a Telecom hallucination dataset and apply direct preference optimization to fine-tune LLMs, resulting in a 20.6\% correct rate improvement. Moreover, we construct a mobile-edge mixture-of-experts architecture for optimal LLM expert activation. Our research aims to propel the field of LLM-empowered communications forward by detecting and minimizing hallucination impacts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06007v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yinqiu Liu, Guangyuan Liu, Ruichen Zhang, Dusit Niyato, Zehui Xiong, Dong In Kim, Kaibin Huang, Hongyang Du</dc:creator>
    </item>
    <item>
      <title>BECS: A Privacy-Preserving Computing Sharing Mechanism in 6G Computing Power Network</title>
      <link>https://arxiv.org/abs/2412.06196</link>
      <description>arXiv:2412.06196v1 Announce Type: new 
Abstract: 5G networks provide secure and reliable information transmission services for the Internet of Everything, thus paving the way for 6G networks, which is anticipated to be an AI-based network, supporting unprecedented intelligence across applications. Abundant computing resources will establish the 6G Computing Power Network (CPN) to facilitate ubiquitous intelligent services. In this article, we propose BECS, a computing sharing mechanism based on evolutionary algorithm and blockchain, designed to balance task offloading among user devices, edge devices, and cloud resources within 6G CPN, thereby enhancing the computing resource utilization. We model computing sharing as a multi-objective optimization problem, aiming to improve resource utilization while balancing other issues. To tackle this NP-hard problem, we devise a kernel distance-based dominance relation and incorporated it into the Non-dominated Sorting Genetic Algorithm III, significantly enhancing the diversity of the evolutionary population. In addition, we propose a pseudonym scheme based on zero-knowledge proof to protect the privacy of users participating in computing sharing. Finally, the security analysis and simulation results demonstrate that BECS can fully and effectively utilize all computing resources in 6G CPN, significantly improving the computing resource utilization while protecting user privacy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06196v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kun Yan, Wenping Ma, Shaohui Sun</dc:creator>
    </item>
    <item>
      <title>FogROS2-FT: Fault Tolerant Cloud Robotics</title>
      <link>https://arxiv.org/abs/2412.05408</link>
      <description>arXiv:2412.05408v1 Announce Type: cross 
Abstract: Cloud robotics enables robots to offload complex computational tasks to cloud servers for performance and ease of management. However, cloud compute can be costly, cloud services can suffer occasional downtime, and connectivity between the robot and cloud can be prone to variations in network Quality-of-Service (QoS). We present FogROS2-FT (Fault Tolerant) to mitigate these issues by introducing a multi-cloud extension that automatically replicates independent stateless robotic services, routes requests to these replicas, and directs the first response back. With replication, robots can still benefit from cloud computations even when a cloud service provider is down or there is low QoS. Additionally, many cloud computing providers offer low-cost spot computing instances that may shutdown unpredictably. Normally, these low-cost instances would be inappropriate for cloud robotics, but the fault tolerance nature of FogROS2-FT allows them to be used reliably. We demonstrate FogROS2-FT fault tolerance capabilities in 3 cloud-robotics scenarios in simulation (visual object detection, semantic segmentation, motion planning) and 1 physical robot experiment (scan-pick-and-place). Running on the same hardware specification, FogROS2-FT achieves motion planning with up to 2.2x cost reduction and up to a 5.53x reduction on 99 Percentile (P99) long-tail latency. FogROS2-FT reduces the P99 long-tail latency of object detection and semantic segmentation by 2.0x and 2.1x, respectively, under network slowdown and resource contention.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05408v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kaiyuan Chen, Kush Hari, Trinity Chung, Michael Wang, Nan Tian, Christian Juette, Jeffrey Ichnowski, Liu Ren, John Kubiatowicz, Ion Stoica, Ken Goldberg</dc:creator>
    </item>
    <item>
      <title>Federated Split Learning with Model Pruning and Gradient Quantization in Wireless Networks</title>
      <link>https://arxiv.org/abs/2412.06414</link>
      <description>arXiv:2412.06414v1 Announce Type: cross 
Abstract: As a paradigm of distributed machine learning, federated learning typically requires all edge devices to train a complete model locally. However, with the increasing scale of artificial intelligence models, the limited resources on edge devices often become a bottleneck for efficient fine-tuning. To address this challenge, federated split learning (FedSL) implements collaborative training across the edge devices and the server through model splitting. In this paper, we propose a lightweight FedSL scheme, that further alleviates the training burden on resource-constrained edge devices by pruning the client-side model dynamicly and using quantized gradient updates to reduce computation overhead. Additionally, we apply random dropout to the activation values at the split layer to reduce communication overhead. We conduct theoretical analysis to quantify the convergence performance of the proposed scheme. Finally, simulation results verify the effectiveness and advantages of the proposed lightweight FedSL in wireless network environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06414v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TVT.2024.3515083</arxiv:DOI>
      <dc:creator>Junhe Zhang, Wanli Ni, Dongyu Wang</dc:creator>
    </item>
    <item>
      <title>UAV Virtual Antenna Array Deployment for Uplink Interference Mitigation in Data Collection Networks</title>
      <link>https://arxiv.org/abs/2412.06456</link>
      <description>arXiv:2412.06456v1 Announce Type: cross 
Abstract: Unmanned aerial vehicles (UAVs) have gained considerable attention as a platform for establishing aerial wireless networks and communications. However, the line-of-sight dominance in air-to-ground communications often leads to significant interference with terrestrial networks, reducing communication efficiency among terrestrial terminals. This paper explores a novel uplink interference mitigation approach based on the collaborative beamforming (CB) method in multi-UAV network systems. Specifically, the UAV swarm forms a UAV-enabled virtual antenna array (VAA) to achieve the transmissions of gathered data to multiple base stations (BSs) for data backup and distributed processing. However, there is a trade-off between the effectiveness of CB-based interference mitigation and the energy conservation of UAVs. Thus, by jointly optimizing the excitation current weights and hover position of UAVs as well as the sequence of data transmission to various BSs, we formulate an uplink interference mitigation multi-objective optimization problem (MOOP) to decrease interference affection, enhance transmission efficiency, and improve energy efficiency, simultaneously. In response to the computational demands of the formulated problem, we introduce an evolutionary computation method, namely chaotic non-dominated sorting genetic algorithm II (CNSGA-II) with multiple improved operators. The proposed CNSGA-II efficiently addresses the formulated MOOP, outperforming several other comparative algorithms, as evidenced by the outcomes of the simulations. Moreover, the proposed CB-based uplink interference mitigation approach can significantly reduce the interference caused by UAVs to non-receiving BSs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06456v1</guid>
      <category>cs.NE</category>
      <category>cs.NI</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongjuan Li, Hui Kang, Geng Sun, Jiahui Li, Jiacheng Wang, Xue Wang, Dusit Niyato, Victor C. M. Leung</dc:creator>
    </item>
    <item>
      <title>Byzantine-Eavesdropper Alliance: How to Achieve Symmetric Privacy in Quantum $X$-Secure $B$-Byzantine $E$-Eavesdropped $U$-Unresponsive $T$-Colluding PIR?</title>
      <link>https://arxiv.org/abs/2412.06728</link>
      <description>arXiv:2412.06728v1 Announce Type: cross 
Abstract: We consider the quantum \emph{symmetric} private information retrieval (QSPIR) problem in a system with $N$ databases and $K$ messages, with $U$ unresponsive servers, $T$-colluding servers, and $X$-security parameter, under several fundamental threat models. In the first model, there are $\mathcal{E}_1$ eavesdropped links in the uplink direction (the direction from the user to the $N$ servers), $\mathcal{E}_2$ eavesdropped links in the downlink direction (the direction from the servers to the user), where $|\mathcal{E}_1|, |\mathcal{E}_2| \leq E$; we coin this eavesdropper setting as \emph{dynamic} eavesdroppers. We show that super-dense coding gain can be achieved for some regimes. In the second model, we consider the case with Byzantine servers, i.e., servers that can coordinate to devise a plan to harm the privacy and security of the system together with static eavesdroppers, by listening to the same links in both uplink and downlink directions. It is important to note the considerable difference between the two threat models, since the eavesdroppers can take huge advantage of the presence of the Byzantine servers. Unlike the previous works in SPIR with Byzantine servers, that assume that the Byzantine servers can send only random symbols independent of the stored messages, we follow the definition of Byzantine servers in \cite{byzantine_tpir}, where the Byzantine servers can send symbols that can be functions of the storage, queries, as well as the random symbols in a way that can produce worse harm to the system. In the third and the most novel threat model, we consider the presence of Byzantine servers and dynamic eavesdroppers together. We show that having dynamic eavesdroppers along with Byzantine servers in the same system model creates more threats to the system than having static eavesdroppers with Byzantine servers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06728v1</guid>
      <category>cs.IT</category>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>quant-ph</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohamed Nomeir, Alptug Aytekin, Sennur Ulukus</dc:creator>
    </item>
    <item>
      <title>Learning State-Augmented Policies for Information Routing in Communication Networks</title>
      <link>https://arxiv.org/abs/2310.00248</link>
      <description>arXiv:2310.00248v3 Announce Type: replace 
Abstract: This paper examines the problem of information routing in a large-scale communication network, which can be formulated as a constrained statistical learning problem having access to only local information. We delineate a novel State Augmentation (SA) strategy to maximize the aggregate information at source nodes using graph neural network (GNN) architectures, by deploying graph convolutions over the topological links of the communication network. The proposed technique leverages only the local information available at each node and efficiently routes desired information to the destination nodes. We leverage an unsupervised learning procedure to convert the output of the GNN architecture to optimal information routing strategies. In the experiments, we perform the evaluation on real-time network topologies to validate our algorithms. Numerical simulations depict the improved performance of the proposed method in training a GNN parameterization as compared to baseline algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.00248v3</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sourajit Das, Navid NaderiAlizadeh, Alejandro Ribeiro</dc:creator>
    </item>
    <item>
      <title>A Quick Primer on Machine Learning in Wireless Communications</title>
      <link>https://arxiv.org/abs/2312.17713</link>
      <description>arXiv:2312.17713v4 Announce Type: replace 
Abstract: This is our third (and final) issue of the quick primer on the use of Python to build a wireless communications prototype. This prototype simulates multiple-input and multiple-output (MIMO) systems for a single orthogonal frequency division multiplexing (OFDM) symbol. In addition, it shows several artificial intelligence (AI) and machine learning (ML) use cases with code implementation. The intent of this primer is to empower the reader with the means to efficiently create reproducible simulations related to AI and ML in wireless communications. This primer has sprung from a draft aligned with the syllabus of a graduate course (EESC 7v86), which we created to be first taught in Fall 2022.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.17713v4</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Faris B. Mismar</dc:creator>
    </item>
    <item>
      <title>A Survey on Privacy-Preserving Caching at Network Edge: Classification, Solutions, and Challenges</title>
      <link>https://arxiv.org/abs/2405.01844</link>
      <description>arXiv:2405.01844v3 Announce Type: replace 
Abstract: Caching content at the edge network is a popular and effective technique widely deployed to alleviate the burden of network backhaul, shorten service delay and improve service quality. However, there has been some controversy over privacy violations in caching content at the edge network. On the one hand, the multi-access open edge network provides an ideal entrance or interface for external attackers to obtain private data from edge caches by extracting sensitive information. On the other hand, privacy can be infringed on by curious edge caching providers through caching trace analysis targeting the achievement of better caching performance or higher profits. Therefore, an in-depth understanding of privacy issues in edge caching networks is vital and indispensable for creating a privacy-preserving caching service at the edge network. In this article, we are among the first to fill this gap by examining privacy-preserving techniques for caching content at the edge network. Firstly, we provide an introduction to the background of privacy-preserving edge caching (PPEC). Next, we summarize the key privacy issues and present a taxonomy for caching at the edge network from the perspective of private information. Additionally, we conduct a retrospective review of the state-of-the-art countermeasures against privacy leakage from content caching at the edge network. Finally, we conclude the survey and envision challenges for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01844v3</guid>
      <category>cs.NI</category>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3706630</arxiv:DOI>
      <dc:creator>Xianzhi Zhang, Yipeng Zhou, Di Wu, Quan Z. Sheng, Shazia Riaz, Miao Hu, Linchang Xiao</dc:creator>
    </item>
    <item>
      <title>Hamiltonian Monte Carlo-Based Near-Optimal MIMO Signal Detection</title>
      <link>https://arxiv.org/abs/2412.02391</link>
      <description>arXiv:2412.02391v2 Announce Type: replace 
Abstract: Multiple-input multiple-output (MIMO) technology is essential for the optimal functioning of next-generation wireless networks; however, enhancing its signal-detection performance for improved spectral efficiency is challenging. Here, we propose an approach that transforms the discrete MIMO detection problem into a continuous problem while leveraging the efficient Hamiltonian Monte Carlo algorithm. For this continuous framework, we employ a mixture of t-distributions as the prior distribution. To improve the performance in the coded case further, we treat the likelihood's temperature parameter as a random variable and address its optimization. This treatment leads to the adoption of a horseshoe density for the likelihood. Theoretical analysis and extensive simulations demonstrate that our method achieves near-optimal detection performance while maintaining polynomial computational complexity. This MIMO detection technique can accelerate the development of 6G mobile communication systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02391v2</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junichiro Hagiwara, Toshihiko Nishimura, Takanori Sato, Yasutaka Ogawa, Takeo Ohgane</dc:creator>
    </item>
    <item>
      <title>Stability of Sequential Lateration and of Stress Minimization in the Presence of Noise</title>
      <link>https://arxiv.org/abs/2310.10900</link>
      <description>arXiv:2310.10900v3 Announce Type: replace-cross 
Abstract: Sequential lateration is a class of methods for multidimensional scaling where a suitable subset of nodes is first embedded by some method, e.g., a clique embedded by classical scaling, and then the remaining nodes are recursively embedded by lateration. A graph is a lateration graph when it can be embedded by such a procedure. We provide a stability result for a particular variant of sequential lateration. We do so in a setting where the dissimilarities represent noisy Euclidean distances between nodes in a geometric lateration graph. We then deduce, as a corollary, a perturbation bound for stress minimization. To argue that our setting applies broadly, we show that a (large) random geometric graph is a lateration graph with high probability under mild conditions, extending a previous result of Aspnes et al (2006).</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.10900v3</guid>
      <category>math.ST</category>
      <category>cs.NI</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ery Arias-Castro, Siddharth Vishwanath</dc:creator>
    </item>
    <item>
      <title>The Internet of Things in the Era of Generative AI: Vision and Challenges</title>
      <link>https://arxiv.org/abs/2401.01923</link>
      <description>arXiv:2401.01923v4 Announce Type: replace-cross 
Abstract: Advancements in Generative AI hold immense promise to push Internet of Things (IoT) to the next level. In this article, we share our vision on IoT in the era of Generative AI. We discuss some of the most important applications of Generative AI in IoT-related domains. We also identify some of the most critical challenges and discuss current gaps as well as promising opportunities on enabling Generative AI for IoT. We hope this article can inspire new research on IoT in the era of Generative AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.01923v4</guid>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Wang, Zhongwei Wan, Arvin Hekmati, Mingyu Zong, Samiul Alam, Mi Zhang, Bhaskar Krishnamachari</dc:creator>
    </item>
    <item>
      <title>Asynchronous Federated Reinforcement Learning with Policy Gradient Updates: Algorithm Design and Convergence Analysis</title>
      <link>https://arxiv.org/abs/2404.08003</link>
      <description>arXiv:2404.08003v4 Announce Type: replace-cross 
Abstract: To improve the efficiency of reinforcement learning (RL), we propose a novel asynchronous federated reinforcement learning (FedRL) framework termed AFedPG, which constructs a global model through collaboration among $N$ agents using policy gradient (PG) updates. To address the challenge of lagged policies in asynchronous settings, we design a delay-adaptive lookahead technique \textit{specifically for FedRL} that can effectively handle heterogeneous arrival times of policy gradients. We analyze the theoretical global convergence bound of AFedPG, and characterize the advantage of the proposed algorithm in terms of both the sample complexity and time complexity. Specifically, our AFedPG method achieves $O(\frac{{\epsilon}^{-2.5}}{N})$ sample complexity for global convergence at each agent on average. Compared to the single agent setting with $O(\epsilon^{-2.5})$ sample complexity, it enjoys a linear speedup with respect to the number of agents. Moreover, compared to synchronous FedPG, AFedPG improves the time complexity from $O(\frac{t_{\max}}{N})$ to $O({\sum_{i=1}^{N} \frac{1}{t_{i}}})^{-1}$, where $t_{i}$ denotes the time consumption in each iteration at agent $i$, and $t_{\max}$ is the largest one. The latter complexity $O({\sum_{i=1}^{N} \frac{1}{t_{i}}})^{-1}$ is always smaller than the former one, and this improvement becomes significant in large-scale federated settings with heterogeneous computing powers ($t_{\max}\gg t_{\min}$). Finally, we empirically verify the improved performance of AFedPG in four widely-used MuJoCo environments with varying numbers of agents. We also demonstrate the advantages of AFedPG in various computing heterogeneity scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08003v4</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guangchen Lan, Dong-Jun Han, Abolfazl Hashemi, Vaneet Aggarwal, Christopher G. Brinton</dc:creator>
    </item>
    <item>
      <title>Secure Integration of 5G in Industrial Networks: State of the Art, Challenges and Opportunities</title>
      <link>https://arxiv.org/abs/2408.16833</link>
      <description>arXiv:2408.16833v2 Announce Type: replace-cross 
Abstract: The industrial landscape is undergoing a significant transformation, moving away from traditional wired fieldbus networks to cutting-edge 5G mobile networks. This transition, extending from local applications to company-wide use and spanning multiple factories, is driven by the promise of low-latency communication and seamless connectivity for various devices in industrial settings. However, besides these tremendous benefits, the integration of 5G as the communication infrastructure in industrial networks introduces a new set of risks and threats to the security of industrial systems. The inherent complexity of 5G systems poses unique challenges for ensuring a secure integration, surpassing those encountered with any technology previously utilized in industrial networks. Most importantly, the distinct characteristics of industrial networks, such as real-time operation, required safety guarantees, and high availability requirements, further complicate this task. As the industrial transition from wired to wireless networks is a relatively new concept, a lack of guidance and recommendations on securely integrating 5G renders many industrial systems vulnerable and exposed to threats associated with 5G. To address this situation, in this paper, we summarize the state-of-the-art and derive a set of recommendations for the secure integration of 5G into industrial networks based on a thorough analysis of the research landscape. Furthermore, we identify opportunities to utilize 5G to enhance security and indicate remaining challenges, identifying future academic directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16833v2</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.future.2024.107645</arxiv:DOI>
      <arxiv:journal_reference>Future Generation Computer Systems, Volume 166, 2025</arxiv:journal_reference>
      <dc:creator>Sotiris Michaelides, Stefan Lenz, Thomas Vogt, Martin Henze</dc:creator>
    </item>
    <item>
      <title>What If We Had Used a Different App? Reliable Counterfactual KPI Analysis in Wireless Systems</title>
      <link>https://arxiv.org/abs/2410.00150</link>
      <description>arXiv:2410.00150v2 Announce Type: replace-cross 
Abstract: In modern wireless network architectures, such as Open Radio Access Network (O-RAN), the operation of the radio access network (RAN) is managed by applications, or apps for short, deployed at intelligent controllers. These apps are selected from a given catalog based on current contextual information. For instance, a scheduling app may be selected on the basis of current traffic and network conditions. Once an app is chosen and run, it is no longer possible to directly test the key performance indicators (KPIs) that would have been obtained with another app. In other words, we can never simultaneously observe both the actual KPI, obtained by the selected app, and the counterfactual KPI, which would have been attained with another app, for the same network condition, making individual-level counterfactual KPIs analysis particularly challenging. This what-if analysis, however, would be valuable to monitor and optimize the network operation, e.g., to identify suboptimal app selection strategies. This paper addresses the problem of estimating the values of KPIs that would have been obtained if a different app had been implemented by the RAN. To this end, we propose a conformal-prediction-based counterfactual analysis method for wireless systems that provides reliable error bars for the estimated KPIs, despite the inherent covariate shift between logged and test data. Experimental results for medium access control-layer apps and for physical-layer apps demonstrate the merits of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00150v2</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiushuo Hou, Sangwoo Park, Matteo Zecchin, Yunlong Cai, Guanding Yu, Osvaldo Simeone</dc:creator>
    </item>
  </channel>
</rss>
