<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.TH</link>
    <description>econ.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 03 Jan 2025 05:00:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Robust Intervention in Networks</title>
      <link>https://arxiv.org/abs/2501.00235</link>
      <description>arXiv:2501.00235v1 Announce Type: new 
Abstract: In various contexts, such as learning, social distancing behavior, and financial contagion, economic agents' decisions are interdependent and can be represented as a network. This paper investigates how a decision maker (DM) can design an optimal intervention while addressing uncertainty in the network structure. The DM's problem is modeled as a zero-sum game against an adversarial player, referred to as "Nature," whose objective is to disrupt the DM's goals by reconfiguring the network into its most disadvantageous state. Using the principle of duality, we derive the DM's unique robust intervention strategy and identify the corresponding unique worst-case network structure determined by Nature. This framework provides insights into robust decision-making under network uncertainty, balancing the DM's objectives with Nature's adversarial actions. Moreover, we explore the costs of robustness and highlight the significance of higher-order uncertainties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00235v1</guid>
      <category>econ.TH</category>
      <pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daeyoung Jeong, Tongseok Lim, Euncheol Shin</dc:creator>
    </item>
    <item>
      <title>The Limits of Tolerance</title>
      <link>https://arxiv.org/abs/2501.00578</link>
      <description>arXiv:2501.00578v1 Announce Type: new 
Abstract: I propose a model of aggregation of intervals relevant to the study of legal standards of tolerance. Seven axioms: responsiveness, anonymity, continuity, strategyproofness, and three variants of neutrality are then used to prove several important results about a new class of aggregation methods called endpoint rules. The class of endpoint rules includes extreme tolerance (allowing anything permitted by anyone) and a form of majoritarianism (the median rule).</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00578v1</guid>
      <category>econ.TH</category>
      <category>cs.LO</category>
      <pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alan D. Miller</dc:creator>
    </item>
    <item>
      <title>Dynamics of Adversarial Attacks on Large Language Model-Based Search Engines</title>
      <link>https://arxiv.org/abs/2501.00745</link>
      <description>arXiv:2501.00745v1 Announce Type: cross 
Abstract: The increasing integration of Large Language Model (LLM) based search engines has transformed the landscape of information retrieval. However, these systems are vulnerable to adversarial attacks, especially ranking manipulation attacks, where attackers craft webpage content to manipulate the LLM's ranking and promote specific content, gaining an unfair advantage over competitors. In this paper, we study the dynamics of ranking manipulation attacks. We frame this problem as an Infinitely Repeated Prisoners' Dilemma, where multiple players strategically decide whether to cooperate or attack. We analyze the conditions under which cooperation can be sustained, identifying key factors such as attack costs, discount rates, attack success rates, and trigger strategies that influence player behavior. We identify tipping points in the system dynamics, demonstrating that cooperation is more likely to be sustained when players are forward-looking. However, from a defense perspective, we find that simply reducing attack success probabilities can, paradoxically, incentivize attacks under certain conditions. Furthermore, defensive measures to cap the upper bound of attack success rates may prove futile in some scenarios. These insights highlight the complexity of securing LLM-based systems. Our work provides a theoretical foundation and practical insights for understanding and mitigating their vulnerabilities, while emphasizing the importance of adaptive security strategies and thoughtful ecosystem design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00745v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.IR</category>
      <category>econ.TH</category>
      <pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiyang Hu</dc:creator>
    </item>
    <item>
      <title>Recursive Preferences, Correlation Aversion, and the Temporal Resolution of Uncertainty</title>
      <link>https://arxiv.org/abs/2304.04599</link>
      <description>arXiv:2304.04599v4 Announce Type: replace 
Abstract: This paper investigates a novel behavioral feature of recursive preferences: aversion to risks that persist over time, or simply correlation aversion. Greater persistence provides information about future consumption but reduces opportunities to hedge consumption risk. I show that, for recursive preferences, correlation aversion is equivalent to increasing relative risk aversion. To quantify correlation aversion, I develop the concept of the persistence premium, which measures how much an individual is willing to pay to eliminate persistence in consumption. I provide an approximation of the persistence premium in the spirit of Arrow-Pratt, which provides a quantitative representation of the trade-off between information and hedging. I present several applications. The persistence premium helps create more realistic calibrations for macro-finance models. In an optimal taxation model, I show that recursive preferences unlike standard preferences-lead to more progressive taxation when human capital persistence is greater. Finally, I show that correlation-averse preferences have a variational representation, linking correlation aversion to concerns about model misspecification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.04599v4</guid>
      <category>econ.TH</category>
      <pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lorenzo Maria Stanca</dc:creator>
    </item>
    <item>
      <title>Robust Auction Design with Support Information</title>
      <link>https://arxiv.org/abs/2305.09065</link>
      <description>arXiv:2305.09065v3 Announce Type: replace 
Abstract: A seller wants to sell an item to $n$ buyers. Buyer valuations are drawn i.i.d. from a distribution unknown to the seller; the seller only knows that the support is included in $[a, b]$. To be robust, the seller chooses a DSIC mechanism that optimizes the worst-case performance relative to the ideal expected revenue the seller could have collected with knowledge of buyers' valuations. Our analysis unifies the regret and the ratio objectives.
  For these objectives, we derive an optimal mechanism and the corresponding performance in quasi-closed form, as a function of the support information $[a, b]$ and the number of buyers $n$. Our analysis reveals three regimes of support information and a new class of robust mechanisms. i.) When $a/b$ is below a threshold, the optimal mechanism is a second-price auction (SPA) with random reserve, a focal class in earlier literature. ii.) When $a/b$ is above another threshold, SPAs are strictly suboptimal, and an optimal mechanism belongs to a class of mechanisms we introduce, which we call pooling auctions (POOL); whenever the highest value is above a threshold, the mechanism still allocates to the highest bidder, but otherwise the mechanism allocates to a uniformly random buyer, i.e., pools low types. iii.) When $a/b$ is between two thresholds, a randomization between SPA and POOL is optimal.
  We also characterize optimal mechanisms within nested central subclasses of mechanisms: standard mechanisms that only allocate to the highest bidder, SPA with random reserve, and SPA with no reserve. We show strict separations in terms of performance across classes, implying that deviating from standard mechanisms is necessary for robustness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.09065v3</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jerry Anunrojwong, Santiago R. Balseiro, Omar Besbes</dc:creator>
    </item>
    <item>
      <title>Equal Pay for Similar Work</title>
      <link>https://arxiv.org/abs/2306.17111</link>
      <description>arXiv:2306.17111v2 Announce Type: replace 
Abstract: Equal pay laws increasingly require that workers doing "similar" work are paid equal wages within firm. We study such "equal pay for similar work" (EPSW) policies theoretically and test our model's predictions empirically using evidence from a 2009 Chilean EPSW. When EPSW only binds across protected class (e.g., no woman can be paid less than any similar man, and vice versa), firms segregate their workforce by gender. When there are more men than women in a labor market, EPSW increases the gender wage gap. By contrast, EPSW that is not based on protected class can decrease the gender wage gap.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.17111v2</guid>
      <category>econ.TH</category>
      <pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Diego Gentile Passaro, Fuhito Kojima, Bobak Pakzad-Hurson</dc:creator>
    </item>
    <item>
      <title>Random Attention and Unobserved Reference Alternatives</title>
      <link>https://arxiv.org/abs/2407.01528</link>
      <description>arXiv:2407.01528v3 Announce Type: replace 
Abstract: In this paper, I develop and characterize a random attention model with unobserved reference alternatives. The decision-maker pays attention to different subsets of the available set of alternatives randomly. The reference alternatives are exactly those alternatives that are always paid attention to, i.e. they are attention-privileged. These alternatives are unknown to the outside observer. The characterization allows for a complete identification of the reference alternatives and a coarse identification of the underlying preferences. I then restrict the model by considering the independent random attention function and provide a complete identification of the underlying preferences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01528v3</guid>
      <category>econ.TH</category>
      <pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Varun Bansal</dc:creator>
    </item>
    <item>
      <title>Fine-Tuning Games: Bargaining and Adaptation for General-Purpose Models</title>
      <link>https://arxiv.org/abs/2308.04399</link>
      <description>arXiv:2308.04399v3 Announce Type: replace-cross 
Abstract: Recent advances in Machine Learning (ML) and Artificial Intelligence (AI) follow a familiar structure: A firm releases a large, pretrained model. It is designed to be adapted and tweaked by other entities to perform particular, domain-specific functions. The model is described as `general-purpose,' meaning it can be transferred to a wide range of downstream tasks, in a process known as adaptation or fine-tuning. Understanding this process - the strategies, incentives, and interactions involved in the development of AI tools - is crucial for making conclusions about societal implications and regulatory responses, and may provide insights beyond AI about general-purpose technologies. We propose a model of this adaptation process. A Generalist brings the technology to a certain level of performance, and one or more Domain specialist(s) adapt it for use in particular domain(s). Players incur costs when they invest in the technology, so they need to reach a bargaining agreement on how to share the resulting revenue before making their investment decisions. We find that for a broad class of cost and revenue functions, there exists a set of Pareto-optimal profit-sharing arrangements where the players jointly contribute to the technology. Our analysis, which utilizes methods based on bargaining solutions and sub-game perfect equilibria, provides insights into the strategic behaviors of firms in these types of interactions. For example, profit-sharing can arise even when one firm faces significantly higher costs than another. After demonstrating findings in the case of one domain-specialist, we provide closed-form and numerical bargaining solutions in the generalized setting with $n$ domain specialists. We find that any potential domain specialization will either contribute, free-ride, or abstain in their uptake of the technology, and provide conditions yielding these different responses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.04399v3</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>econ.TH</category>
      <pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin Laufer, Jon Kleinberg, Hoda Heidari</dc:creator>
    </item>
    <item>
      <title>Paid with Models: Optimal Contract Design for Collaborative Machine Learning</title>
      <link>https://arxiv.org/abs/2412.11122</link>
      <description>arXiv:2412.11122v2 Announce Type: replace-cross 
Abstract: Collaborative machine learning (CML) provides a promising paradigm for democratizing advanced technologies by enabling cost-sharing among participants. However, the potential for rent-seeking behaviors among parties can undermine such collaborations. Contract theory presents a viable solution by rewarding participants with models of varying accuracy based on their contributions. However, unlike monetary compensation, using models as rewards introduces unique challenges, particularly due to the stochastic nature of these rewards when contribution costs are privately held information. This paper formalizes the optimal contracting problem within CML and proposes a transformation that simplifies the non-convex optimization problem into one that can be solved through convex optimization algorithms. We conduct a detailed analysis of the properties that an optimal contract must satisfy when models serve as the rewards, and we explore the potential benefits and welfare implications of these contract-driven CML schemes through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11122v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bingchen Wang, Zhaoxuan Wu, Fusheng Liu, Bryan Kian Hsiang Low</dc:creator>
    </item>
  </channel>
</rss>
