<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 26 Jun 2024 01:52:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 25 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Stochastic approximation method for kernel sliced average variance estimation</title>
      <link>https://arxiv.org/abs/2406.15950</link>
      <description>arXiv:2406.15950v1 Announce Type: new 
Abstract: In this paper, we use the stochastic approximation method to estimate Sliced Average Variance Estimation (SAVE). This method is known for its efficiency in recursive estimation. Stochastic approximation is particularly effective for constructing recursive estimators and has been widely used in density estimation, regression, and semi-parametric models. We demonstrate that the resulting estimator is asymptotically normal and root n consistent. Through simulations conducted in the laboratory and applied to real data, we show that it is faster than the kernel method previously proposed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15950v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emmanuel De Dieu Nkou</dc:creator>
    </item>
    <item>
      <title>Filtering Problem for Functionals of Stationary Sequences</title>
      <link>https://arxiv.org/abs/2406.15975</link>
      <description>arXiv:2406.15975v1 Announce Type: new 
Abstract: The problem of the mean-square optimal linear estimation of functionals which depend on the unknown values of a stationary stochastic sequence from observations of the sequence with noise is considered. In the case of spectral certainty, where the spectral densities of the sequences are exactly known, we propose formulas for calculating the spectral characteristic and value of the mean-square error of the estimate, which are determined using the Fourier coefficients of some functions from the spectral densities. The minimax-robust method of estimation is applied in the case of spectral uncertainty, where the spectral densities are not exactly known, but a class of admissible spectral densities is given. Formulas for determining the least favorable spectral densities and the minimax-robust spectral characteristics of the optimal estimates of the functionals are proposed for some specific classes of admissible spectral densities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15975v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.19139/soic.v4i1.172</arxiv:DOI>
      <arxiv:journal_reference>Statistics, Optimization &amp; Information Computing, 4(1), 68-83, 2016</arxiv:journal_reference>
      <dc:creator>Maksym Luz, Mikhail Moklyachuk</dc:creator>
    </item>
    <item>
      <title>Constrained recursive kernel density/regression estimation by stochastic quasi-gradient methods</title>
      <link>https://arxiv.org/abs/2406.16550</link>
      <description>arXiv:2406.16550v1 Announce Type: new 
Abstract: The paper considers nonparametric kernel density/regression estimation from a stochastic optimization point of view. The estimation problem is represented through a family of stochastic optimization problems. Recursive constrained estimators are obtained by application of stochastic (quasi)gradient methods to these problems, classical kernel estimates are derived as particular cases. Accuracy and rate of convergence of the obtained estimates are established, and asymptotically optimal estimation procedure parameters are found. The case of moving density/regression is particularly studied.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16550v1</guid>
      <category>math.ST</category>
      <category>math.OC</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vladimir Norkin, Vladimir Kirilyuk</dc:creator>
    </item>
    <item>
      <title>Anomaly Detection based on Markov Data: A Statistical Depth Approach</title>
      <link>https://arxiv.org/abs/2406.16759</link>
      <description>arXiv:2406.16759v1 Announce Type: new 
Abstract: It is the main purpose of this article to extend the notion of statistical depth to the
  case of sample paths of a Markov chain, a very popular probabilistic model to describe
  parsimoniously random phenomena with a temporal causality. Initially introduced to
  define a center-outward ordering of points in the support of a multivariate
  distribution, depth functions permit to generalize the notions of quantiles and
  (signed) ranks for observations in $\mathbb{R}^d$ with $d&gt;1$, as well as statistical
  procedures based on such quantities, for (unsupervised) anomaly detection tasks in
  particular. In this paper, overcoming the lack of natural order on the torus composed
  of all possible trajectories of finite length, we develop a general theoretical
  framework for evaluating the depth of a Markov sample path and recovering it
  statistically from an estimate of its transition probability with (non-) asymptotic
  guarantees. We also detail its numerous applications, focusing particularly on anomaly
  detection, a key task in various fields involving the analysis of (supposedly) Markov
  time-series (\textit{e.g.} health monitoring of complex infrastructures, security).
  Beyond the description of the methodology promoted and the statistical analysis carried
  out to guarantee its validity, numerical experiments are displayed, providing strong
  empirical evidence of the relevance of the novel concept we introduce here to quantify
  the degree of abnormality of Markov path sequences of variable length.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16759v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Carlos Fern\'andez, Stephan Cl\'emen\c{c}on</dc:creator>
    </item>
    <item>
      <title>Nonparametric bootstrap of high-dimensional sample covariance matrices</title>
      <link>https://arxiv.org/abs/2406.16849</link>
      <description>arXiv:2406.16849v1 Announce Type: new 
Abstract: We introduce a new "$(m,mp/n)$ out of $(n,p)$" sampling-with-replace\-ment bootstrap for eigenvalue statistics of high-dimensional sample covariance matrices based on $n$ independent $p$-dimensional random vectors. In the high-dimensional scenario $p/n\rightarrow c\in (0,\infty)$, this fully nonparametric and computationally tractable bootstrap is shown to consistently reproduce the empirical spectral measure if $m/n\rightarrow 0$. If $m^2/n\rightarrow 0$, it approximates correctly the distribution of linear spectral statistics. The crucial component is a suitably defined Representative Subpopulation Condition which is shown to be verified in a large variety of situations. Our proofs are conducted under minimal moment requirements and incorporate delicate results on non-centered quadratic forms, combinatorial trace moments estimates as well as a conditional bootstrap martingale CLT which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16849v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Holger Dette, Angelika Rohde</dc:creator>
    </item>
    <item>
      <title>Statistical Inference and A/B Testing in Fisher Markets and Paced Auctions</title>
      <link>https://arxiv.org/abs/2406.15522</link>
      <description>arXiv:2406.15522v1 Announce Type: cross 
Abstract: We initiate the study of statistical inference and A/B testing for two market equilibrium models: linear Fisher market (LFM) equilibrium and first-price pacing equilibrium (FPPE). LFM arises from fair resource allocation systems such as allocation of food to food banks and notification opportunities to different types of notifications. For LFM, we assume that the data observed is captured by the classical finite-dimensional Fisher market equilibrium, and its steady-state behavior is modeled by a continuous limit Fisher market. The second type of equilibrium we study, FPPE, arises from internet advertising where advertisers are constrained by budgets and advertising opportunities are sold via first-price auctions. For platforms that use pacing-based methods to smooth out the spending of advertisers, FPPE provides a hindsight-optimal configuration of the pacing method. We propose a statistical framework for the FPPE model, in which a continuous limit FPPE models the steady-state behavior of the auction platform, and a finite FPPE provides the data to estimate primitives of the limit FPPE. Both LFM and FPPE have an Eisenberg-Gale convex program characterization, the pillar upon which we derive our statistical theory. We start by deriving basic convergence results for the finite market to the limit market. We then derive asymptotic distributions, and construct confidence intervals. Furthermore, we establish the asymptotic local minimax optimality of estimation based on finite markets. We then show that the theory can be used for conducting statistically valid A/B testing on auction platforms. Synthetic and semi-synthetic experiments verify the validity and practicality of our theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15522v1</guid>
      <category>cs.GT</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luofeng Liao, Christian Kroer</dc:creator>
    </item>
    <item>
      <title>Testing the Feasibility of Linear Programs with Bandit Feedback</title>
      <link>https://arxiv.org/abs/2406.15648</link>
      <description>arXiv:2406.15648v1 Announce Type: cross 
Abstract: While the recent literature has seen a surge in the study of constrained bandit problems, all existing methods for these begin by assuming the feasibility of the underlying problem. We initiate the study of testing such feasibility assumptions, and in particular address the problem in the linear bandit setting, thus characterising the costs of feasibility testing for an unknown linear program using bandit feedback. Concretely, we test if $\exists x: Ax \ge 0$ for an unknown $A \in \mathbb{R}^{m \times d}$, by playing a sequence of actions $x_t\in \mathbb{R}^d$, and observing $Ax_t + \mathrm{noise}$ in response. By identifying the hypothesis as determining the sign of the value of a minimax game, we construct a novel test based on low-regret algorithms and a nonasymptotic law of iterated logarithms. We prove that this test is reliable, and adapts to the `signal level,' $\Gamma,$ of any instance, with mean sample costs scaling as $\widetilde{O}(d^2/\Gamma^2)$. We complement this by a minimax lower bound of $\Omega(d/\Gamma^2)$ for sample costs of reliable tests, dominating prior asymptotic lower bounds by capturing the dependence on $d$, and thus elucidating a basic insight missing in the extant literature on such problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15648v1</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aditya Gangrade, Aditya Gopalan, Venkatesh Saligrama, Clayton Scott</dc:creator>
    </item>
    <item>
      <title>Rates of Convergence of the Magnetization in the Tensor Curie-Weiss Potts Model</title>
      <link>https://arxiv.org/abs/2406.15907</link>
      <description>arXiv:2406.15907v1 Announce Type: cross 
Abstract: In this paper, we derive distributional convergence rates for the magnetization vector in the tensor Curie-Weiss Potts model. Limit theorems for the magnetization vector have been derived recently in Bhowal &amp; Mukherjee (2023), where several phase transition phenomena in terms of the scaling of the (centered) magnetization and its asymptotic distribution were established, depending upon the position of the true parameters in the parameter space. In the current work, we establish Berry-Esseen type results for the magnetization vector, specifying its rate of convergence at these different phases. At "most" points in the parameter space, this rate is $N^{-1/2}$ ($N$ being the size of the Curie-Weiss network), while at some "special" points, the rate is either $N^{-1/4}$ or $N^{-1/6}$, depending upon the behavior of the fourth derivative of a certain negative free energy function at these special points.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15907v1</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sanchayan Bhowal, Somabha Mukherjee</dc:creator>
    </item>
    <item>
      <title>Weak recovery, hypothesis testing, and mutual information in stochastic block models and planted factor graphs</title>
      <link>https://arxiv.org/abs/2406.15957</link>
      <description>arXiv:2406.15957v1 Announce Type: cross 
Abstract: The stochastic block model is a canonical model of communities in random graphs. It was introduced in the social sciences and statistics as a model of communities, and in theoretical computer science as an average case model for graph partitioning problems under the name of the ``planted partition model.'' Given a sparse stochastic block model, the two standard inference tasks are: (i) Weak recovery: can we estimate the communities with non trivial overlap with the true communities? (ii) Detection/Hypothesis testing: can we distinguish if the sample was drawn from the block model or from a random graph with no community structure with probability tending to $1$ as the graph size tends to infinity?
  In this work, we show that for sparse stochastic block models, the two inference tasks are equivalent except at a critical point. That is, weak recovery is information theoretically possible if and only if detection is possible. We thus find a strong connection between these two notions of inference for the model. We further prove that when detection is impossible, an explicit hypothesis test based on low degree polynomials in the adjacency matrix of the observed graph achieves the optimal statistical power. This low degree test is efficient as opposed to the likelihood ratio test, which is not known to be efficient. Moreover, we prove that the asymptotic mutual information between the observed network and the community structure exhibits a phase transition at the weak recovery threshold.
  Our results are proven in much broader settings including the hypergraph stochastic block models and general planted factor graphs. In these settings we prove that the impossibility of weak recovery implies contiguity and provide a condition which guarantees the equivalence of weak recovery and detection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15957v1</guid>
      <category>math.PR</category>
      <category>cs.IT</category>
      <category>cs.SI</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elchanan Mossel, Allan Sly, Youngtak Sohn</dc:creator>
    </item>
    <item>
      <title>Enumeration of Row-Column Designs</title>
      <link>https://arxiv.org/abs/2406.16444</link>
      <description>arXiv:2406.16444v1 Announce Type: cross 
Abstract: We computationally completely enumerate a number of types of row-column designs up to isotopism, including double, sesqui and triple arrays as known from the literature, and two newly introduced types that we call mono arrays and AO-arrays. We calculate autotopism group sizes for the designs we generate. For larger parameter values, where complete enumeration is not feasible, we generate examples of some of the designs, and generate exhaustive lists of admissible parameters. For some admissible parameter sets, we prove non-existence results. We also give some explicit constructions of sesqui arrays, mono arrays and AO-arrays, and investigate connections to Youden rectangles and binary pseud Youden designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16444v1</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gerold J\"ager, Klas Markstr\"om, Lars-Daniel \"Ohman, Denys Shcherbak</dc:creator>
    </item>
    <item>
      <title>Sampling Strategies in Bayesian Inversion: A Study of RTO and Langevin Methods</title>
      <link>https://arxiv.org/abs/2406.16658</link>
      <description>arXiv:2406.16658v2 Announce Type: cross 
Abstract: This paper studies two classes of sampling methods for the solution of inverse problems, namely Randomize-Then-Optimize (RTO), which is rooted in sensitivity analysis, and Langevin methods, which are rooted in the Bayesian framework. The two classes of methods correspond to different assumptions and yield samples from different target distributions. We highlight the main conceptual and theoretical differences between the two approaches and compare them from a practical point of view by tackling two classical inverse problems in imaging: deblurring and inpainting. We show that the choice of the sampling method has a significant impact on the quality of the reconstruction and that the RTO method is more robust to the choice of the parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16658v2</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Remi Laumont, Yiqiu Dong, Martin Skovgaard Andersen</dc:creator>
    </item>
    <item>
      <title>Survival Analysis with Graph-Based Regularization for Predictors</title>
      <link>https://arxiv.org/abs/2108.12827</link>
      <description>arXiv:2108.12827v2 Announce Type: replace 
Abstract: We study the variable selection problem in survival analysis to identify the most important factors affecting survival time. Our method incorporates prior knowledge of mutual correlations among variables, represented through a graph. We utilize the Cox proportional hazard model with a graph-based regularizer for variable selection. We present a computationally efficient algorithm developed to solve the graph regularized maximum likelihood problem by establishing connections with the group lasso, and provide theoretical guarantees about the recovery error and asymptotic distribution of the proposed estimators. The improved performance of the proposed approach compared with existing methods are demonstrated in both synthetic and real organ transplantation datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2108.12827v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liyan Xie, Xi He, Pinar Keskinocak, Yao Xie</dc:creator>
    </item>
    <item>
      <title>Extreme Limit Theory of Competing Risks under Power Normalization</title>
      <link>https://arxiv.org/abs/2305.02742</link>
      <description>arXiv:2305.02742v4 Announce Type: replace 
Abstract: Advanced science and technology provide a wealth of big data from different sources for extreme value analysis. Classical extreme value theory was extended to obtain an accelerated max-stable distribution family for modelling competing risk-based extreme data in Cao and Zhang (2021). In this paper, we establish probability models for power normalized maxima and minima from competing risks. The limit distributions consist of an extensional new accelerated max-stable and min-stable distribution family (termed as the accelerated p-max/p-min stable distribution), and its left-truncated version. The consistency and asymptotic normality are obtained for the maximum likelihood estimation of the parameters involved in the accelerated p-max and p-min stable distributions when it exists. The limit types of distributions are determined principally by the sample generating process and the interplay among the competing risks, which are illustrated by common examples. Further, the statistical inference concerning the maximum likelihood estimation and model diagnosis of this model was investigated. Numerical studies show first the efficient approximation of all limit scenarios as well as its comparable convergence rate in contrast with those under linear normalization, and then present the maximum likelihood estimation and diagnosis of accelerated p-max/p-min stable models for simulated data sets. Finally, two real datasets concerning annual maximum of ground level ozone and survival times of Stanford heart plant demonstrate the performance of our accelerated p-max and accelerated p-min stable models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.02742v4</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kaihao Hu, Kai Wang, Corina Constantinescu, Zhengjun Zhang, Chengxiu Ling</dc:creator>
    </item>
    <item>
      <title>Causal Inference on Process Graphs, Part I: The Structural Equation Process Representation</title>
      <link>https://arxiv.org/abs/2305.11561</link>
      <description>arXiv:2305.11561v2 Announce Type: replace 
Abstract: When dealing with time series data, causal inference methods often employ structural vector autoregressive (SVAR) processes to model time-evolving random systems. In this work, we rephrase recursive SVAR processes with possible latent component processes as a linear Structural Causal Model (SCM) of stochastic processes on a simple causal graph, the \emph{process graph}, that models every process as a single node. Using this reformulation, we generalise Wright's well-known path-rule for linear Gaussian SCMs to the newly introduced process SCMs and we express the auto-covariance sequence of an SVAR process by means of a generalised trek-rule. Employing the Fourier-Transformation, we derive compact expressions for causal effects in the frequency domain that allow us to efficiently visualise the causal interactions in a multivariate SVAR process. Finally, we observe that the process graph can be used to formulate graphical criteria for identifying causal effects and to derive algebraic relations with which these frequency domain causal effects can be recovered from the observed spectral density.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.11561v2</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas-Domenic Reiter, Andreas Gerhardus, Jonas Wahl, Jakob Runge</dc:creator>
    </item>
    <item>
      <title>A Note on Improved Multivariate Normal Mean Estimation With Unknown Covariance When p Is Greater Than n</title>
      <link>https://arxiv.org/abs/2311.13140</link>
      <description>arXiv:2311.13140v2 Announce Type: replace 
Abstract: In this paper, we highlight a major error in the proofs of the important results of [D.Ch\'etelat and M. T. Wells(2012). Improved Multivariate Normal Mean Estimation with Unknown Covariance when p is Greater than n. The Annals of Statistics, Vol. 40, No.6, 3137--3160]. In particular, the proofs of some of their main results are based on Theorem 2 whose proof needs to be revisited. More precisely, there are some major mistakes in the derivation of this important result. Further, under a very realistic assumption about the rank of the estimator of the variance-covariance matrix, we correct the proof of the quoted result.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.13140v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arash A. Foroushani, Severien Nkurunziza</dc:creator>
    </item>
    <item>
      <title>Improved Gaussian Mean Matrix Estimators In High-Dimensional Data</title>
      <link>https://arxiv.org/abs/2311.14263</link>
      <description>arXiv:2311.14263v2 Announce Type: replace 
Abstract: In this paper, we introduce a class of improved estimators for the mean parameter matrix of a multivariate normal distribution with an unknown variance-covariance matrix. In particular, the main results of [D.Ch\'etelat and M. T. Wells(2012). Improved Multivariate Normal Mean Estimation with Unknown Covariance when $p$ is Greater than $n$. The Annals of Statistics, Vol. 40, No.6, 3137--3160] are established in their full generalities and we provide the corrected version of their Theorem 2. Specifically, we generalize the existing results in three ways. First, we consider a parameter matrix estimation problem which enclosed as a special case the one about the vector parameter. Second, we propose a class of James-Stein matrix estimators and, we establish a necessary and a sufficient condition for any member of the proposed class to have a finite risk function. Third, we present the conditions for the proposed class of estimators to dominate the maximum likelihood estimator. On the top of these interesting contributions, the additional novelty consists in the fact that, we extend the methods suitable for the vector parameter case and the derived results hold in the classical case as well as in the context of high and ultra-high dimensional data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.14263v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arash A. Foroushani, Severien Nkurunziza</dc:creator>
    </item>
    <item>
      <title>Convergence rates of non-stationary and deep Gaussian process regression</title>
      <link>https://arxiv.org/abs/2312.07320</link>
      <description>arXiv:2312.07320v3 Announce Type: replace 
Abstract: The focus of this work is the convergence of non-stationary and deep Gaussian process regression. More precisely, we follow a Bayesian approach to regression or interpolation, where the prior placed on the unknown function $f$ is a non-stationary or deep Gaussian process, and we derive convergence rates of the posterior mean to the true function $f$ in terms of the number of observed training points. In some cases, we also show convergence of the posterior variance to zero. The only assumption imposed on the function $f$ is that it is an element of a certain reproducing kernel Hilbert space, which we in particular cases show to be norm-equivalent to a Sobolev space. Our analysis includes the case of estimated hyper-parameters in the covariance kernels employed, both in an empirical Bayes' setting and the particular hierarchical setting constructed through deep Gaussian processes. We consider the settings of noise-free or noisy observations on deterministic or random training points. We establish general assumptions sufficient for the convergence of deep Gaussian process regression, along with explicit examples demonstrating the fulfilment of these assumptions. Specifically, our examples require that the H\"older or Sobolev norms of the penultimate layer are bounded almost surely.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.07320v3</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Conor Moriarty-Osborne, Aretha L. Teckentrup</dc:creator>
    </item>
    <item>
      <title>Clustered Switchback Experiments: Near-Optimal Rates Under Spatiotemporal Interference</title>
      <link>https://arxiv.org/abs/2312.15574</link>
      <description>arXiv:2312.15574v4 Announce Type: replace 
Abstract: We consider experimentation in the presence of non-stationarity, inter-unit (spatial) interference, and carry-over effects (temporal interference), where we wish to estimate the global average treatment effect (GATE), the difference between average outcomes having exposed all units at all times to treatment or to control. We suppose spatial interference is described by a graph, where a unit's outcome depends on its neighborhood's treatment assignments, and that temporal interference is described by a hidden Markov decision process, where the transition kernel under either treatment (action) satisfies a rapid mixing condition. We propose a clustered switchback design, where units are grouped into clusters and time steps are grouped into blocks and each whole cluster-block combination is assigned a single random treatment. Under this design, we show that for graphs that admit good clustering, a truncated exposure-mapping Horvitz-Thompson estimator achieves $\tilde O(1/NT)$ mean-squared error (MSE), matching an $\Omega(1/NT)$ lower bound up to logarithmic terms. Our results simultaneously generalize the $N=1$ setting of Hu, Wager 2022 (and improves on the MSE bound shown therein for difference-in-means estimators) as well as the $T=1$ settings of Ugander et al 2013 and Leung 2022. Simulation studies validate the favorable performance of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.15574v4</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Su Jia, Nathan Kallus, Christina Lee Yu</dc:creator>
    </item>
    <item>
      <title>Semiparametric Estimation of Treatment Effects in Observational Studies with Heterogeneous Partial Interference</title>
      <link>https://arxiv.org/abs/2107.12420</link>
      <description>arXiv:2107.12420v3 Announce Type: replace-cross 
Abstract: In many observational studies in social science and medicine, subjects or units are connected, and one unit's treatment and attributes may affect another's treatment and outcome, violating the stable unit treatment value assumption (SUTVA) and resulting in interference. To enable feasible estimation and inference, many previous works assume exchangeability of interfering units (neighbors). However, in many applications with distinctive units, interference is heterogeneous and needs to be modeled explicitly. In this paper, we focus on the partial interference setting, and only restrict units to be exchangeable conditional on observable characteristics. Under this framework, we propose generalized augmented inverse propensity weighted (AIPW) estimators for general causal estimands that include heterogeneous direct and spillover effects. We show that they are semiparametric efficient and robust to heterogeneous interference as well as model misspecifications. We apply our methods to the Add Health dataset to study the direct effects of alcohol consumption on academic performance and the spillover effects of parental incarceration on adolescent well-being.</description>
      <guid isPermaLink="false">oai:arXiv.org:2107.12420v3</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaonan Qu, Ruoxuan Xiong, Jizhou Liu, Guido Imbens</dc:creator>
    </item>
    <item>
      <title>Exact and Approximate Conformal Inference for Multi-Output Regression</title>
      <link>https://arxiv.org/abs/2210.17405</link>
      <description>arXiv:2210.17405v2 Announce Type: replace-cross 
Abstract: It is common in machine learning to estimate a response $y$ given covariate information $x$. However, these predictions alone do not quantify any uncertainty associated with said predictions. One way to overcome this deficiency is with conformal inference methods, which construct a set containing the unobserved response $y$ with a prescribed probability. Unfortunately, even with a one-dimensional response, conformal inference is computationally expensive despite recent encouraging advances. In this paper, we explore multi-output regression, delivering exact derivations of conformal inference $p$-values when the predictive model can be described as a linear function of $y$. Additionally, we propose \texttt{unionCP} and a multivariate extension of \texttt{rootCP} as efficient ways of approximating the conformal prediction region for a wide array of multi-output predictors, both linear and nonlinear, while preserving computational advantages. We also provide both theoretical and empirical evidence of the effectiveness of these methods using both real-world and simulated data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.17405v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.OT</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chancellor Johnstone, Eugene Ndiaye</dc:creator>
    </item>
    <item>
      <title>Communication-Efficient Distributed Estimation and Inference for Cox's Model</title>
      <link>https://arxiv.org/abs/2302.12111</link>
      <description>arXiv:2302.12111v3 Announce Type: replace-cross 
Abstract: Motivated by multi-center biomedical studies that cannot share individual data due to privacy and ownership concerns, we develop communication-efficient iterative distributed algorithms for estimation and inference in the high-dimensional sparse Cox proportional hazards model. We demonstrate that our estimator, even with a relatively small number of iterations, achieves the same convergence rate as the ideal full-sample estimator under very mild conditions. To construct confidence intervals for linear combinations of high-dimensional hazard regression coefficients, we introduce a novel debiased method, establish central limit theorems, and provide consistent variance estimators that yield asymptotically valid distributed confidence intervals. In addition, we provide valid and powerful distributed hypothesis tests for any coordinate element based on a decorrelated score test. We allow time-dependent covariates as well as censored survival times. Extensive numerical experiments on both simulated and real data lend further support to our theory and demonstrate that our communication-efficient distributed estimators, confidence intervals, and hypothesis tests improve upon alternative methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.12111v3</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pierre Bayle, Jianqing Fan, Zhipeng Lou</dc:creator>
    </item>
    <item>
      <title>Large Sample Theory for Bures-Wasserstein Barycentres</title>
      <link>https://arxiv.org/abs/2305.15592</link>
      <description>arXiv:2305.15592v2 Announce Type: replace-cross 
Abstract: We establish a strong law of large numbers and a central limit theorem in the Bures-Wasserstein space of covariance operators -- or equivalently centred Gaussian measures -- over a general separable Hilbert space. Specifically, we show that under a minimal first-moment condition, empirical barycentre sequences indexed by sample size are almost certainly relatively compact, with accumulation points comprising population barycentres. We give a sufficient regularity condition for the limit to be unique. When the limit is unique, we also establish a central limit theorem under a refined pair of moment and regularity conditions. Finally, we prove strong operator convergence of the empirical optimal transport maps to their population counterparts. Though our results naturally extend finite-dimensional counterparts, including associated regularity conditions, our techniques are distinctly different owing to the functional nature of the problem in the general setting. A key element is the elicitation of a class of compact sets that reflect an \emph{ordered} Heine-Borel property of the Bures-Wasserstein space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.15592v2</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leonardo V. Santoro, Victor M. Panaretos</dc:creator>
    </item>
    <item>
      <title>Statistical Inference for Bures-Wasserstein Flows</title>
      <link>https://arxiv.org/abs/2310.13764</link>
      <description>arXiv:2310.13764v2 Announce Type: replace-cross 
Abstract: We develop a statistical framework for conducting inference on collections of time-varying covariance operators (covariance flows) over a general, possibly infinite dimensional, Hilbert space. We model the intrinsically non-linear structure of covariances by means of the Bures-Wasserstein metric geometry. We make use of the Riemmanian-like structure induced by this metric to define a notion of mean and covariance of a random flow, and develop an associated Karhunen-Lo\`eve expansion. We then treat the problem of estimation and construction of functional principal components from a finite collection of covariance flows, observed fully or irregularly.
  Our theoretical results are motivated by modern problems in functional data analysis, where one observes operator-valued random processes -- for instance when analysing dynamic functional connectivity and fMRI data, or when analysing multiple functional time series in the frequency domain. Nevertheless, our framework is also novel in the finite-dimensions (matrix case), and we demonstrate what simplifications can be afforded then. We illustrate our methodology by means of simulations and data analyses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.13764v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leonardo V. Santoro, Victor M. Panaretos</dc:creator>
    </item>
    <item>
      <title>Theory of Compression Channels for Postselected Quantum Metrology</title>
      <link>https://arxiv.org/abs/2311.06679</link>
      <description>arXiv:2311.06679v3 Announce Type: replace-cross 
Abstract: Postselected quantum metrological scheme is especially advantageous when the final measurements are either very noisy or expensive in practical experiments. In this work, we put forward a general theory on the compression channels in postselected quantum metrology. We define the basic notions characterizing the compression quality and illuminate the underlying structure of lossless compression channels. Previous experiments on Postselected optical phase estimation and weak-value amplification are shown to be particular cases of this general theory. Furthermore, for two categories of bipartite systems, we show that the compression loss can be made arbitrarily small even when the compression channel acts only on one subsystem. These findings can be employed to distribute quantum measurements so that the measurement noise and cost are dramatically reduced.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.06679v3</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1103/PhysRevLett.132.250802</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. Lett. 132, 250802(2024)</arxiv:journal_reference>
      <dc:creator>Jing Yang</dc:creator>
    </item>
    <item>
      <title>Probabilistic cellular automata with local transition matrices: synchronization, ergodicity, and inference</title>
      <link>https://arxiv.org/abs/2405.02928</link>
      <description>arXiv:2405.02928v3 Announce Type: replace-cross 
Abstract: We introduce a new class of probabilistic cellular automata that are capable of exhibiting rich dynamics such as synchronization and ergodicity and can be easily inferred from data. The system is a finite-state locally interacting Markov chain on a circular graph. Each site's subsequent state is random, with a distribution determined by its neighborhood's empirical distribution multiplied by a local transition matrix. We establish sufficient and necessary conditions on the local transition matrix for synchronization and ergodicity. Also, we introduce novel least squares estimators for inferring the local transition matrix from various types of data, which may consist of either multiple trajectories, a long trajectory, or ensemble sequences without trajectory information. Under suitable identifiability conditions, we show the asymptotic normality of these estimators and provide non-asymptotic bounds for their accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02928v3</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Erhan Bayraktar, Fei Lu, Mauro Maggioni, Ruoyu Wu, Sichen Yang</dc:creator>
    </item>
    <item>
      <title>Towards Bayesian Data Selection</title>
      <link>https://arxiv.org/abs/2406.12560</link>
      <description>arXiv:2406.12560v2 Announce Type: replace-cross 
Abstract: A wide range of machine learning algorithms iteratively add data to the training sample. Examples include semi-supervised learning, active learning, multi-armed bandits, and Bayesian optimization. We embed this kind of data addition into decision theory by framing data selection as a decision problem. This paves the way for finding Bayes-optimal selections of data. For the illustrative case of self-training in semi-supervised learning, we derive the respective Bayes criterion. We further show that deploying this criterion mitigates the issue of confirmation bias by empirically assessing our method for generalized linear models, semi-parametric generalized additive models, and Bayesian neural networks on simulated and real-world data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12560v2</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julian Rodemann</dc:creator>
    </item>
  </channel>
</rss>
