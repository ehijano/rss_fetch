<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 26 Jun 2024 01:48:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 25 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>What is Best for Students, Numerical Scores or Letter Grades?</title>
      <link>https://arxiv.org/abs/2406.15405</link>
      <description>arXiv:2406.15405v1 Announce Type: new 
Abstract: We study letter grading schemes, which are routinely employed for evaluating student performance. Typically, a numerical score obtained via one or more evaluations is converted into a letter grade (e.g., A+, B-, etc.) by associating a disjoint interval of numerical scores to each letter grade.
  We propose the first model for studying the (de)motivational effects of such grading on the students and, consequently, on their performance in future evaluations. We use the model to compare uniform letter grading schemes, in which the range of scores is divided into equal-length parts that are mapped to the letter grades, to numerical scoring, in which the score is not converted to any letter grade (equivalently, every score is its own letter grade).
  Theoretically, we identify realistic conditions under which numerical scoring is better than any uniform letter grading scheme. Our experiments confirm that this holds under even weaker conditions, but also find cases where the converse occurs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15405v1</guid>
      <category>cs.GT</category>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Evi Micha, Shreyas Sekar, Nisarg Shah</dc:creator>
    </item>
    <item>
      <title>Large-Scale Contextual Market Equilibrium Computation through Deep Learning</title>
      <link>https://arxiv.org/abs/2406.15459</link>
      <description>arXiv:2406.15459v1 Announce Type: new 
Abstract: Market equilibrium is one of the most fundamental solution concepts in economics and social optimization analysis. Existing works on market equilibrium computation primarily focus on settings with a relatively small number of buyers. Motivated by this, our paper investigates the computation of market equilibrium in scenarios with a large-scale buyer population, where buyers and goods are represented by their contexts. Building on this realistic and generalized contextual market model, we introduce MarketFCNet, a deep learning-based method for approximating market equilibrium. We start by parameterizing the allocation of each good to each buyer using a neural network, which depends solely on the context of the buyer and the good. Next, we propose an efficient method to estimate the loss function of the training algorithm unbiasedly, enabling us to optimize the network parameters through gradient descent. To evaluate the approximated solution, we introduce a metric called Nash Gap, which quantifies the deviation of the given allocation and price pair from the market equilibrium. Experimental results indicate that MarketFCNet delivers competitive performance and significantly lower running times compared to existing methods as the market scale expands, demonstrating the potential of deep learning-based methods to accelerate the approximation of large-scale contextual market equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15459v1</guid>
      <category>cs.GT</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunxuan Ma, Yide Bian, Hao Xu, Weitao Yang, Jingshu Zhao, Zhijian Duan, Feng Wang, Xiaotie Deng</dc:creator>
    </item>
    <item>
      <title>Statistical Inference and A/B Testing in Fisher Markets and Paced Auctions</title>
      <link>https://arxiv.org/abs/2406.15522</link>
      <description>arXiv:2406.15522v1 Announce Type: new 
Abstract: We initiate the study of statistical inference and A/B testing for two market equilibrium models: linear Fisher market (LFM) equilibrium and first-price pacing equilibrium (FPPE). LFM arises from fair resource allocation systems such as allocation of food to food banks and notification opportunities to different types of notifications. For LFM, we assume that the data observed is captured by the classical finite-dimensional Fisher market equilibrium, and its steady-state behavior is modeled by a continuous limit Fisher market. The second type of equilibrium we study, FPPE, arises from internet advertising where advertisers are constrained by budgets and advertising opportunities are sold via first-price auctions. For platforms that use pacing-based methods to smooth out the spending of advertisers, FPPE provides a hindsight-optimal configuration of the pacing method. We propose a statistical framework for the FPPE model, in which a continuous limit FPPE models the steady-state behavior of the auction platform, and a finite FPPE provides the data to estimate primitives of the limit FPPE. Both LFM and FPPE have an Eisenberg-Gale convex program characterization, the pillar upon which we derive our statistical theory. We start by deriving basic convergence results for the finite market to the limit market. We then derive asymptotic distributions, and construct confidence intervals. Furthermore, we establish the asymptotic local minimax optimality of estimation based on finite markets. We then show that the theory can be used for conducting statistically valid A/B testing on auction platforms. Synthetic and semi-synthetic experiments verify the validity and practicality of our theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15522v1</guid>
      <category>cs.GT</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luofeng Liao, Christian Kroer</dc:creator>
    </item>
    <item>
      <title>Calibrated Forecasting and Persuasion</title>
      <link>https://arxiv.org/abs/2406.15680</link>
      <description>arXiv:2406.15680v1 Announce Type: new 
Abstract: How should an expert send forecasts to maximize her utility subject to passing a calibration test? We consider a dynamic game where an expert sends probabilistic forecasts to a decision maker. The decision maker uses a calibration test based on past outcomes to verify the expert's forecasts. We characterize the optimal forecasting strategy by reducing the dynamic game to a static persuasion problem. A distribution of forecasts is implementable by a calibrated strategy if and only if it is a mean-preserving contraction of the distribution of conditionals (honest forecasts). We characterize the value of information by comparing what an informed and uninformed expert can attain. Moreover, we consider a decision maker who uses regret minimization, instead of the calibration test, to take actions. We show that the expert can achieve the same payoff against a regret minimizer as under the calibration test, and in some instances, she can achieve strictly more.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15680v1</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Atulya Jain, Vianney Perchet</dc:creator>
    </item>
    <item>
      <title>Fast, optimal, and dynamic electoral campaign budgeting by a generalized Colonel Blotto game</title>
      <link>https://arxiv.org/abs/2406.15714</link>
      <description>arXiv:2406.15714v2 Announce Type: new 
Abstract: The Colonel Blotto game is a deeply studied theoretical model for competitive allocation environments including elections, advertising, and ecology. However, the original formulation of Colonel Blotto has had few practical implications due to the lack of fast algorithms to compute its optimal strategies and the limited applicability of its winner-take-all reward distribution. We demonstrate that the Colonel Blotto game can be a practical model for competitive allocation environments by implementing the multiplicative weights update algorithm from Beaglehole et al. (2023). In particular, using that this algorithm allows for arbitrary winning-rules, we study strategies for a more realistic model of political campaigning we term Electoral Colonel Blotto. Contrary to existing theory and the implemented allocation strategies from U.S. presidential elections, we find that the optimal response to Democratic and Republican strategies in the 2008 and 2020 presidential elections was to focus allocations on a subset of states and sacrifice winning probability on others. We also found that campaigners should compete for undecided voters even in states where the opponent has significantly many more decided voters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15714v2</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Thomas Valles, Daniel Beaglehole</dc:creator>
    </item>
    <item>
      <title>Defection-Free Collaboration between Competitors in a Learning System</title>
      <link>https://arxiv.org/abs/2406.15898</link>
      <description>arXiv:2406.15898v1 Announce Type: new 
Abstract: We study collaborative learning systems in which the participants are competitors who will defect from the system if they lose revenue by collaborating. As such, we frame the system as a duopoly of competitive firms who are each engaged in training machine-learning models and selling their predictions to a market of consumers. We first examine a fully collaborative scheme in which both firms share their models with each other and show that this leads to a market collapse with the revenues of both firms going to zero. We next show that one-sided collaboration in which only the firm with the lower-quality model shares improves the revenue of both firms. Finally, we propose a more equitable, *defection-free* scheme in which both firms share with each other while losing no revenue, and we show that our algorithm converges to the Nash bargaining solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15898v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mariel Werner, Sai Praneeth Karimireddy, Michael I. Jordan</dc:creator>
    </item>
    <item>
      <title>Imperfect-Recall Games: Equilibrium Concepts and Their Complexity</title>
      <link>https://arxiv.org/abs/2406.15970</link>
      <description>arXiv:2406.15970v1 Announce Type: new 
Abstract: We investigate optimal decision making under imperfect recall, that is, when an agent forgets information it once held before. An example is the absentminded driver game, as well as team games in which the members have limited communication capabilities. In the framework of extensive-form games with imperfect recall, we analyze the computational complexities of finding equilibria in multiplayer settings across three different solution concepts: Nash, multiselves based on evidential decision theory (EDT), and multiselves based on causal decision theory (CDT). We are interested in both exact and approximate solution computation. As special cases, we consider (1) single-player games, (2) two-player zero-sum games and relationships to maximin values, and (3) games without exogenous stochasticity (chance nodes). We relate these problems to the complexity classes P, PPAD, PLS, $\Sigma_2^P$ , $\exists$R, and $\exists \forall$R.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15970v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emanuel Tewolde, Brian Hu Zhang, Caspar Oesterheld, Manolis Zampetakis, Tuomas Sandholm, Paul W. Goldberg, Vincent Conitzer</dc:creator>
    </item>
    <item>
      <title>Simple Delegated Choice</title>
      <link>https://arxiv.org/abs/2406.16343</link>
      <description>arXiv:2406.16343v1 Announce Type: new 
Abstract: This paper studies delegation in a model of discrete choice. In the delegation problem, an uninformed principal must consult an informed agent to make a decision. Both the agent and principal have preferences over the decided-upon action which vary based on the state of the world, and which may not be aligned. The principal may commit to a mechanism, which maps reports of the agent to actions. When this mechanism is deterministic, it can take the form of a menu of actions, from which the agent simply chooses upon observing the state. In this case, the principal is said to have delegated the choice of action to the agent.
  We consider a setting where the decision being delegated is a choice of a utility-maximizing action from a set of several options. We assume the shared portion of the agent's and principal's utilities is drawn from a distribution known to the principal, and that utility misalignment takes the form of a known bias for or against each action. We provide tight approximation analyses for simple threshold policies under three increasingly general sets of assumptions. With independently-distributed utilities, we prove a $3$-approximation. When the agent has an outside option the principal cannot rule out, the constant approximation fails, but we prove a $\log \rho/\log\log \rho$-approximation, where $\rho$ is the ratio of the maximum value to the optimal utility. We also give a weaker but tight bound that holds for correlated values, and complement our upper bounds with hardness results. One special case of our model is utility-based assortment optimization, for which our results are new.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16343v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Proceedings of the 2024 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA 2024)</arxiv:journal_reference>
      <dc:creator>Ali Khodabakhsh, Emmanouil Pountourakis, Samuel Taggart</dc:creator>
    </item>
    <item>
      <title>Combinatorics on Social Configurations</title>
      <link>https://arxiv.org/abs/2406.16409</link>
      <description>arXiv:2406.16409v1 Announce Type: new 
Abstract: In cooperative game theory, the social configurations of players are modeled by balanced collections. The Bondareva-Shapley theorem, perhaps the most fundamental theorem in cooperative game theory, characterizes the existence of solutions to the game that benefit everyone using balanced collections. Roughly speaking, if the trivial set system of all players is one of the most efficient balanced collections for the game, then the set of solutions from which each coalition benefits, the so-called core, is non-empty.
  In this paper, we discuss some interactions between combinatorics and cooperative game theory that are still relatively unexplored. Indeed, the similarity between balanced collections and uniform hypergraphs seems to be a relevant point of view to obtain new properties on those collections through the theory of combinatorial species.  </description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16409v1</guid>
      <category>cs.GT</category>
      <category>cs.DM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.403.27</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 403, 2024, pp. 128-133</arxiv:journal_reference>
      <dc:creator>Dylan Laplace Mermoud (UMA, ENSTA Paris, Institut Polytechnique de Paris), Pierre Popoli (Department of Mathematics, UliÃ¨ge)</dc:creator>
    </item>
    <item>
      <title>FlipDyn in Graphs: Resource Takeover Games in Graphs</title>
      <link>https://arxiv.org/abs/2406.16812</link>
      <description>arXiv:2406.16812v1 Announce Type: new 
Abstract: We present \texttt{FlipDyn-G}, a dynamic game model extending the \texttt{FlipDyn} framework to a graph-based setting, where each node represents a dynamical system. This model captures the interactions between a defender and an adversary who strategically take over nodes in a graph to minimize (resp. maximize) a finite horizon additive cost. At any time, the \texttt{FlipDyn} state is represented as the current node, and each player can transition the \texttt{FlipDyn} state to a depending based on the connectivity from the current node. Such transitions are driven by the node dynamics, state, and node-dependent costs. This model results in a hybrid dynamical system where the discrete state (\texttt{FlipDyn} state) governs the continuous state evolution and the corresponding state cost. Our objective is to compute the Nash equilibrium of this finite horizon zero-sum game on a graph. Our contributions are two-fold. First, we model and characterize the \texttt{FlipDyn-G} game for general dynamical systems, along with the corresponding Nash equilibrium (NE) takeover strategies. Second, for scalar linear discrete-time dynamical systems with quadratic costs, we derive the NE takeover strategies and saddle-point values independent of the continuous state of the system. Additionally, for a finite state birth-death Markov chain (represented as a graph) under scalar linear dynamical systems, we derive analytical expressions for the NE takeover strategies and saddle-point values. We illustrate our findings through numerical studies involving epidemic models and linear dynamical systems with adversarial interactions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16812v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sandeep Banik, Shaunak D. Bopardikar, Naira Hovakimyan</dc:creator>
    </item>
    <item>
      <title>Stochastic Scheduling with Abandonments via Greedy Strategies</title>
      <link>https://arxiv.org/abs/2406.15691</link>
      <description>arXiv:2406.15691v1 Announce Type: cross 
Abstract: Motivated by applications where impatience is pervasive and service times are uncertain, we study a scheduling model where jobs may depart at an unknown point in time and service times are stochastic. Initially, we have access to a single server and $n$ jobs with known non-negative values: these jobs have unknown stochastic service and departure times with known distributional information, which we assume to be independent. When the server is free, we can run an available job which occupies the server for an unknown amount of time, and collect its value. The objective is to maximize the expected total value obtained from jobs run on the server. Natural formulations of this problem suffer from the curse of dimensionality. In fact, this problem is NP-hard even in the deterministic case. Hence, we focus on efficiently computable approximation algorithms that can provide high expected reward compared to the optimal expected value. Towards this end, we first provide a compact linear programming (LP) relaxation that gives an upper bound on the expected value obtained by the optimal policy. Then we design a polynomial-time algorithm that is nearly a $(1/2)\cdot (1-1/e)$-approximation to the optimal LP value (so also to the optimal expected value). We next shift our focus to the case of independent and identically distributed (i.i.d.) service times. In this case, we show that the greedy policy that always runs the highest-valued job whenever the server is free obtains a $1/2$-approximation to the optimal expected value. Our approaches extend effortlessly and we demonstrate their flexibility by providing approximations to natural extensions of our problem. Finally, we evaluate our LP-based policies and the greedy policy empirically on synthetic and real datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15691v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yihua Xu, Rohan Ghuge, Sebastian Perez-Salazar</dc:creator>
    </item>
    <item>
      <title>Language Alignment via Nash-learning and Adaptive feedback</title>
      <link>https://arxiv.org/abs/2406.15890</link>
      <description>arXiv:2406.15890v1 Announce Type: cross 
Abstract: Recent research has shown the potential of Nash Learning via Human Feedback for large language model alignment by incorporating the notion of a preference model in a minimax game setup. We take this idea further by casting the alignment as a mirror descent algorithm against the adaptive feedback of an improved opponent, thereby removing the need for learning a preference model or the existence of an annotated dataset altogether. The resulting algorithm, which we refer to as Language Alignment via Nash-learning and Adaptive feedback (LANA), is capable of self-alignment without the need for a human-annotated preference dataset. We support this statement with various experiments and mathematical discussion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15890v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.GT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ari Azarafrooz, Farshid Faal</dc:creator>
    </item>
    <item>
      <title>A Mechanism for Optimizing Media Recommender Systems</title>
      <link>https://arxiv.org/abs/2406.16212</link>
      <description>arXiv:2406.16212v1 Announce Type: cross 
Abstract: A mechanism is described that addresses the fundamental trade off between media producers who want to increase reach and consumers who provide attention based on the rate of utility received, and where overreach negatively impacts that rate. An optimal solution can be achieved when the media source considers the impact of overreach in a cost function used in determining the optimal distribution of content to maximize individual consumer utility and participation. The result is a Nash equilibrium between producer and consumer that is also Pareto efficient. Comparison with the literature on Recommender systems highlights the advantages of the mechanism.The review suggests advancements over that literature including identifying an optimal content volume for the consumer and improvements for handling multiple objectives A practical algorithm to generate the optimal distribution for each consumer is provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16212v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <category>cs.IR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brian McFadden</dc:creator>
    </item>
    <item>
      <title>Cherry on the Cake: Fairness is NOT an Optimization Problem</title>
      <link>https://arxiv.org/abs/2406.16606</link>
      <description>arXiv:2406.16606v1 Announce Type: cross 
Abstract: Fair cake-cutting is a mathematical subfield that studies the problem of fairly dividing a resource among a number of participants. The so-called ``cake,'' as an object, represents any resource that can be distributed among players. This concept is connected to supervised multi-label classification: any dataset can be thought of as a cake that needs to be distributed, where each label is a player that receives its share of the dataset. In particular, any efficient cake-cutting solution for the dataset is equivalent to an optimal decision function. Although we are not the first to demonstrate this connection, the important ramifications of this parallel seem to have been partially forgotten. We revisit these classical results and demonstrate how this connection can be prolifically used for fairness in machine learning problems. Understanding the set of achievable fair decisions is a fundamental step in finding optimal fair solutions and satisfying fairness requirements. By employing the tools of cake-cutting theory, we have been able to describe the behavior of optimal fair decisions, which, counterintuitively, often exhibit quite unfair properties. Specifically, in order to satisfy fairness constraints, it is sometimes preferable, in the name of optimality, to purposefully make mistakes and deny giving the positive label to deserving individuals in a community in favor of less worthy individuals within the same community. This practice is known in the literature as cherry-picking and has been described as ``blatantly unfair.''</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16606v1</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <category>cs.GT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marco Favier, Toon Calders</dc:creator>
    </item>
    <item>
      <title>Bandits with Preference Feedback: A Stackelberg Game Perspective</title>
      <link>https://arxiv.org/abs/2406.16745</link>
      <description>arXiv:2406.16745v1 Announce Type: cross 
Abstract: Bandits with preference feedback present a powerful tool for optimizing unknown target functions when only pairwise comparisons are allowed instead of direct value queries. This model allows for incorporating human feedback into online inference and optimization and has been employed in systems for fine-tuning large language models. The problem is well understood in simplified settings with linear target functions or over finite small domains that limit practical interest. Taking the next step, we consider infinite domains and nonlinear (kernelized) rewards. In this setting, selecting a pair of actions is quite challenging and requires balancing exploration and exploitation at two levels: within the pair, and along the iterations of the algorithm. We propose MAXMINLCB, which emulates this trade-off as a zero-sum Stackelberg game, and chooses action pairs that are informative and yield favorable rewards. MAXMINLCB consistently outperforms existing algorithms and satisfies an anytime-valid rate-optimal regret guarantee. This is due to our novel preference-based confidence sequences for kernelized logistic estimators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16745v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Barna P\'asztor, Parnian Kassraie, Andreas Krause</dc:creator>
    </item>
    <item>
      <title>Game Transformations That Preserve Nash Equilibria or Best-Response Sets</title>
      <link>https://arxiv.org/abs/2111.00076</link>
      <description>arXiv:2111.00076v4 Announce Type: replace 
Abstract: In this paper, we investigate under which conditions normal-form games are (guaranteed to be) strategically equivalent. First, we show for N-player games (N &gt;= 3) that
  (A) it is NP-hard to decide whether a given strategy is a best response to some strategy profile of the opponents, and that
  (B) it is co-NP-hard to decide whether two games have the same best-response sets.
  Combining that with known results from the literature, we move our attention to equivalence-preserving game transformations.
  It is a widely used fact that a positive affine (linear) transformation of the utility payoffs neither changes the best-response sets nor the Nash equilibrium set. We investigate which other game transformations also possess either of the following two properties when being applied to an arbitrary N-player game (N &gt;= 2):
  (i) The Nash equilibrium set stays the same;
  (ii) The best-response sets stay the same.
  For game transformations that operate player-wise and strategy-wise, we prove that (i) implies (ii) and that transformations with property (ii) must be positive affine. The resulting equivalence chain highlights the special status of positive affine transformations among all the transformation procedures that preserve key game-theoretic characteristics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2111.00076v4</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emanuel Tewolde, Vincent Conitzer</dc:creator>
    </item>
    <item>
      <title>Adaptively Perturbed Mirror Descent for Learning in Games</title>
      <link>https://arxiv.org/abs/2305.16610</link>
      <description>arXiv:2305.16610v5 Announce Type: replace 
Abstract: This paper proposes a payoff perturbation technique for the Mirror Descent (MD) algorithm in games where the gradient of the payoff functions is monotone in the strategy profile space, potentially containing additive noise. The optimistic family of learning algorithms, exemplified by optimistic MD, successfully achieves {\it last-iterate} convergence in scenarios devoid of noise, leading the dynamics to a Nash equilibrium. A recent re-emerging trend underscores the promise of the perturbation approach, where payoff functions are perturbed based on the distance from an anchoring, or {\it slingshot}, strategy. In response, we propose {\it Adaptively Perturbed MD} (APMD), which adjusts the magnitude of the perturbation by repeatedly updating the slingshot strategy at a predefined interval. This innovation empowers us to find a Nash equilibrium of the underlying game with guaranteed rates. Empirical demonstrations affirm that our algorithm exhibits significantly accelerated convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.16610v5</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kenshi Abe, Kaito Ariu, Mitsuki Sakamoto, Atsushi Iwasaki</dc:creator>
    </item>
    <item>
      <title>Mixed Fair Division: A Survey</title>
      <link>https://arxiv.org/abs/2306.09564</link>
      <description>arXiv:2306.09564v3 Announce Type: replace 
Abstract: Fair division considers the allocation of scarce resources among agents in such a way that every agent gets a fair share. It is a fundamental problem in society and has received significant attention and rapid developments from the game theory and artificial intelligence communities in recent years. The majority of the fair division literature can be divided along at least two orthogonal directions: goods versus chores, and divisible versus indivisible resources. In this survey, besides describing the state of the art, we outline a number of interesting open questions and future directions in three mixed fair division settings: (i) indivisible goods and chores, (ii) divisible and indivisible goods (mixed goods), and (iii) indivisible goods with subsidy which can be viewed like a divisible good.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.09564v3</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shengxin Liu, Xinhang Lu, Mashbat Suzuki, Toby Walsh</dc:creator>
    </item>
    <item>
      <title>Evolutionary dynamics of any multiplayer game on regular graphs</title>
      <link>https://arxiv.org/abs/2401.11686</link>
      <description>arXiv:2401.11686v2 Announce Type: replace 
Abstract: Multiplayer games on graphs are at the heart of theoretical descriptions of key evolutionary processes that govern vital social and natural systems. However, a comprehensive theoretical framework for solving multiplayer games with an arbitrary number of strategies on graphs is still missing. Here, we solve this by drawing an analogy with the Balls-and-Boxes problem, based on which we show that the local configuration of multiplayer games on graphs is equivalent to distributing $k$ identical co-players among $n$ distinct strategies. We use this to derive the replicator equation for any $n$-strategy multiplayer game under weak selection, which can be solved in polynomial time. As an example, we revisit the second-order free-riding problem, where costly punishment cannot truly resolve social dilemmas in a well-mixed population. Yet, in structured populations, we derive an accurate threshold for the punishment strength, beyond which punishment can either lead to the extinction of defection or transform the system into a rock-paper-scissors-like cycle. The analytical solution also qualitatively agrees with the phase diagrams that were previously obtained for non-marginal selection strengths. Our framework thus allows an exploration of any multi-strategy multiplayer game on regular graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.11686v2</guid>
      <category>cs.GT</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.CC</category>
      <category>nlin.CG</category>
      <category>q-bio.PE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1038/s41467-024-49505-5</arxiv:DOI>
      <arxiv:journal_reference>Nature Communications, volume 15, Article number: 5349 (2024)</arxiv:journal_reference>
      <dc:creator>Chaoqian Wang, Matja\v{z} Perc, Attila Szolnoki</dc:creator>
    </item>
    <item>
      <title>Proof of a conjecture about Parrondo's paradox for two-armed slot machines</title>
      <link>https://arxiv.org/abs/2310.08935</link>
      <description>arXiv:2310.08935v3 Announce Type: replace-cross 
Abstract: The 1936 Mills Futurity slot machine had the feature that, if a player loses 10 times in a row, the 10 lost coins are returned. Ethier and Lee (2010) studied a generalized version of this machine, with 10 replaced by deterministic parameter J. They established the Parrondo effect for a hypothetical two-armed machine with the Futurity award. Specifically, arm A and arm B, played individually, are asymptotically fair, but when alternated ran-domly (the so-called random mixture strategy), the casino makes money in the long run. They also considered the nonrandom periodic pattern strategy for patterns with r As and s Bs (e.g., ABABB if r = 2 and s = 3). They established the Parrondo effect if r + s divides J, and conjectured it in four other situations, including the case J = 2 with r &gt;= 1 and s &gt;= 1. We prove the conjecture in the latter case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.08935v3</guid>
      <category>math.PR</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huaijin Liang, Zengjing Chen</dc:creator>
    </item>
  </channel>
</rss>
