<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 13 Jun 2024 04:00:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 13 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Content Provider Contributions to Capacity Expansion of a Neutral ISP: Effect of Private Option</title>
      <link>https://arxiv.org/abs/2406.07898</link>
      <description>arXiv:2406.07898v1 Announce Type: new 
Abstract: Increasing content consumption by users and the expectation of a better Internet experience requires Internet service providers (ISPs) to expand the capacity of the access network continually. The ISPs have been demanding the participation of the content providers (CPs) in sharing the cost of upgrading the infrastructure. From CPs' perspective, investing in the ISP infrastructure, termed as \emph{public investment}, seems rational as it will boost their profit. However, the CPs can alternatively invest in making content delivery more efficient, termed as \emph{private investment}, as it also boosts their profit. Thus, in this work, we investigate this trade-off between public and private investment of the CPs for a net-neutral ISP. Specifically, we consider centralized decision and non-cooperative forms of interaction between CPs and an ISP and determine the optimum public and private investments of the CPs for each model. In the non-cooperative interaction, we find that at most one CP contributes to the public infrastructure, whereas all invest in their private infrastructure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07898v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pranay Agarwal, D. Manjunath</dc:creator>
    </item>
    <item>
      <title>Semantic-Aware Resource Allocation Based on Deep Reinforcement Learning for 5G-V2X HetNets</title>
      <link>https://arxiv.org/abs/2406.07996</link>
      <description>arXiv:2406.07996v1 Announce Type: new 
Abstract: This letter proposes a semantic-aware resource allocation (SARA) framework with flexible duty cycle (DC) coexistence mechanism (SARADC) for 5G-V2X Heterogeneous Network (HetNets) based on deep reinforcement learning (DRL) proximal policy optimization (PPO). Specifically, we investigate V2X networks within a two-tiered HetNets structure. In response to the needs of high-speed vehicular networking in urban environments, we design a semantic communication system and introduce two resource allocation metrics: high-speed semantic transmission rate (HSR) and semantic spectrum efficiency (HSSE). Our main goal is to maximize HSSE. Additionally, we address the coexistence of vehicular users and WiFi users in 5G New Radio Unlicensed (NR-U) networks. To tackle this complex challenge, we propose a novel approach that jointly optimizes flexible DC coexistence mechanism and the allocation of resources and base stations (BSs). Unlike traditional bit transmission methods, our approach integrates the semantic communication paradigm into the communication system. Experimental results demonstrate that our proposed solution outperforms traditional bit transmission methods with traditional DC coexistence mechanism in terms of HSSE and semantic throughput (ST) for both vehicular and WiFi users.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07996v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiyu Shao, Qiong Wu, Pingyi Fan, Nan Cheng, Qiang Fan, Jiangzhou Wang</dc:creator>
    </item>
    <item>
      <title>Large Language Model(LLM) assisted End-to-End Network Health Management based on Multi-Scale Semanticization</title>
      <link>https://arxiv.org/abs/2406.08305</link>
      <description>arXiv:2406.08305v1 Announce Type: new 
Abstract: Network device and system health management is the foundation of modern network operations and maintenance. Traditional health management methods, relying on expert identification or simple rule-based algorithms, struggle to cope with the dynamic heterogeneous networks (DHNs) environment. Moreover, current state-of-the-art distributed anomaly detection methods, which utilize specific machine learning techniques, lack multi-scale adaptivity for heterogeneous device information, resulting in unsatisfactory diagnostic accuracy for DHNs. In this paper, we develop an LLM-assisted end-to-end intelligent network health management framework. The framework first proposes a Multi-Scale Semanticized Anomaly Detection Model (MSADM), incorporating semantic rule trees with an attention mechanism to address the multi-scale anomaly detection problem in DHNs. Secondly, a chain-of-thought-based large language model is embedded in downstream to adaptively analyze the fault detection results and produce an analysis report with detailed fault information and optimization strategies. Experimental results show that the accuracy of our proposed MSADM for heterogeneous network entity anomaly detection is as high as 91.31\%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08305v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fengxiao Tang, Xiaonan Wang, Xun Yuan, Linfeng Luo, Ming Zhao, Nei Kato</dc:creator>
    </item>
    <item>
      <title>Cyber Threat Landscape Analysis for Starlink Assessing Risks and Mitigation Strategies in the Global Satellite Internet Infrastructure</title>
      <link>https://arxiv.org/abs/2406.07562</link>
      <description>arXiv:2406.07562v1 Announce Type: cross 
Abstract: Satellite internet networks have emerged as indispensable components of the modern digital landscape, promising to extend connectivity to even the most remote corners of the globe. Among these networks, Starlink, pioneered by SpaceX, has garnered significant attention for its ambitious mission to provide high-speed internet access on a global scale. However, the proliferation of satellite infrastructure also brings to the forefront a myriad of cybersecurity challenges, as these networks become increasingly vital for critical communication and data exchange. This research endeavours to conduct a comprehensive analysis of the cybersecurity landscape surrounding Starlink, with a focus on identifying potential threats, assessing associated risks, and proposing mitigation strategies to bolster the resilience of the network. Through an exploration of existing literature, an examination of the system architecture of Starlink, and an analysis of the current cyber threat landscape facing satellite internet networks, this study aims to provide valuable insights into the cybersecurity challenges inherent in the operation of global satellite internet infrastructure. By prioritizing risks and proposing effective mitigation strategies, this research seeks to contribute to the ongoing efforts to safeguard the integrity and accessibility of satellite-based internet connectivity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07562v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Karwan Mustafa Kareem</dc:creator>
    </item>
    <item>
      <title>Guardians of Anonymity: Exploring Tactics to Combat Cyber Threats in Onion Routing Environments</title>
      <link>https://arxiv.org/abs/2406.07563</link>
      <description>arXiv:2406.07563v1 Announce Type: cross 
Abstract: Onion routing networks, also known as darknets, are private networks that enable anonymous communication over the Internet. They are used by individuals and organizations to protect their privacy, but they also attract cybercriminals who exploit the anonymity provided by these networks for illegal activities. This paper comprehensively analyzes cybercrime threats and countermeasures in onion routing networks. We review the various types of cybercrime that occur in these networks, including drug trafficking, fraud, hacking, and other illicit activities. We then discuss the challenges associated with detecting and mitigating cybercrime in onion routing networks, such as the difficulty of tracing illegal activities back to their source due to the strong anonymity guarantees provided by these networks. We also explore the countermeasures that have been proposed and implemented to combat cybercrime in onion routing networks, including law enforcement efforts, technological solutions, and policy interventions. Finally, we highlight the limitations of existing countermeasures and identify potential directions for future research in this area, including the need for interdisciplinary approaches that combine technical, legal, and social perspectives to effectively combat cybercrime in onion routing networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07563v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karwan Mustafa Kareem</dc:creator>
    </item>
    <item>
      <title>Individual Packet Features are a Risk to Model Generalisation in ML-Based Intrusion Detection</title>
      <link>https://arxiv.org/abs/2406.07578</link>
      <description>arXiv:2406.07578v1 Announce Type: cross 
Abstract: Machine learning is increasingly used for intrusion detection in IoT networks. This paper explores the effectiveness of using individual packet features (IPF), which are attributes extracted from a single network packet, such as timing, size, and source-destination information. Through literature review and experiments, we identify the limitations of IPF, showing they can produce misleadingly high detection rates. Our findings emphasize the need for approaches that consider packet interactions for robust intrusion detection. Additionally, we demonstrate that models based on IPF often fail to generalize across datasets, compromising their reliability in diverse IoT environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07578v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kahraman Kostas, Mike Just, Michael A. Lones</dc:creator>
    </item>
    <item>
      <title>Toward Enhanced Reinforcement Learning-Based Resource Management via Digital Twin: Opportunities, Applications, and Challenges</title>
      <link>https://arxiv.org/abs/2406.07857</link>
      <description>arXiv:2406.07857v1 Announce Type: cross 
Abstract: This article presents a digital twin (DT)-enhanced reinforcement learning (RL) framework aimed at optimizing performance and reliability in network resource management, since the traditional RL methods face several unified challenges when applied to physical networks, including limited exploration efficiency, slow convergence, poor long-term performance, and safety concerns during the exploration phase. To deal with the above challenges, a comprehensive DT-based framework is proposed to enhance the convergence speed and performance for unified RL-based resource management. The proposed framework provides safe action exploration, more accurate estimates of long-term returns, faster training convergence, higher convergence performance, and real-time adaptation to varying network conditions. Then, two case studies on ultra-reliable and low-latency communication (URLLC) services and multiple unmanned aerial vehicles (UAV) network are presented, demonstrating improvements of the proposed framework in performance, convergence speed, and training cost reduction both on traditional RL and neural network based Deep RL (DRL). Finally, the article identifies and explores some of the research challenges and open issues in this rapidly evolving field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07857v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nan Cheng, Xiucheng Wang, Zan Li Zhisheng Yin, Tom Luan, Xuemin Shen</dc:creator>
    </item>
    <item>
      <title>Demonstration of Safe Electromagnetic Radiation Emitted by 5G Active Antenna Systems</title>
      <link>https://arxiv.org/abs/2406.07910</link>
      <description>arXiv:2406.07910v1 Announce Type: cross 
Abstract: The careful planning and safe deployment of 5G technologies will bring enormous benefits to society and the economy. Higher frequency, beamforming, and small-cells are key technologies that will provide unmatched throughput and seamless connectivity to 5G users. Superficial knowledge of these technologies has raised concerns among the general public about the harmful effects of radiation. Several standardization bodies are active to put limits on the emissions which are based on a defined set of radiation measurement methodologies. However, due to the peculiarity of 5G such as dynamicity of the beams, network densification, Time Division Duplexing mode of operation, etc, using existing EMF measurement methods may provide inaccurate results. In this context, we discuss our experimental studies aimed towards the measurement of radiation caused by beam-based transmissions from a 5G base station equipped with an Active Antenna System(AAS). We elaborate on the shortcomings of current measurement methodologies and address several open questions. Next, we demonstrate that using user-specific downlink beamforming, not only better performance is achieved compared to non-beamformed downlink, but also the radiation in the vicinity of the intended user is significantly decreased. Further, we show that under weak reception conditions, an uplink transmission can cause significantly high radiation in the vicinity of the user equipment. We believe that our work will help in clearing several misleading concepts about the 5G EMF radiation effects. We conclude the work by providing guidelines to improve the methodology of EMF measurement by considering the spatiotemporal dynamicity of the 5G transmission.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07910v1</guid>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sumit Kumar, Chandan Kumar Sheemar, Abdelrahman Astro, Jorge Querol, Symeon Chatzinotas</dc:creator>
    </item>
    <item>
      <title>Efficient Network Traffic Feature Sets for IoT Intrusion Detection</title>
      <link>https://arxiv.org/abs/2406.08042</link>
      <description>arXiv:2406.08042v1 Announce Type: cross 
Abstract: The use of Machine Learning (ML) models in cybersecurity solutions requires high-quality data that is stripped of redundant, missing, and noisy information. By selecting the most relevant features, data integrity and model efficiency can be significantly improved. This work evaluates the feature sets provided by a combination of different feature selection methods, namely Information Gain, Chi-Squared Test, Recursive Feature Elimination, Mean Absolute Deviation, and Dispersion Ratio, in multiple IoT network datasets. The influence of the smaller feature sets on both the classification performance and the training time of ML models is compared, with the aim of increasing the computational efficiency of IoT intrusion detection. Overall, the most impactful features of each dataset were identified, and the ML models obtained higher computational efficiency while preserving a good generalization, showing little to no difference between the sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08042v1</guid>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Miguel Silva, Jo\~ao Vitorino, Eva Maia, Isabel Pra\c{c}a</dc:creator>
    </item>
    <item>
      <title>GreenBytes: Intelligent Energy Estimation for Edge-Cloud</title>
      <link>https://arxiv.org/abs/2403.04665</link>
      <description>arXiv:2403.04665v2 Announce Type: replace-cross 
Abstract: This study investigates the application of advanced machine learning models, specifically Long Short-Term Memory (LSTM) networks and Gradient Booster models, for accurate energy consumption estimation within a Kubernetes cluster environment. It aims to enhance sustainable computing practices by providing precise predictions of energy usage across various computing nodes. Through meticulous analysis of model performance on both master and worker nodes, the research reveals the strengths and potential applications of these models in promoting energy efficiency. The LSTM model demonstrates remarkable predictive accuracy, particularly in capturing dynamic computing workloads over time, evidenced by low mean squared error (MSE) rates and the ability to closely track actual energy consumption trends. Conversely, the Gradient Booster model showcases robustness and adaptability across different computational environments, despite slightly higher MSE values. The study underscores the complementary nature of these models in advancing sustainable computing practices, suggesting their integration into energy management systems could significantly enhance environmental sustainability in technology operations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04665v2</guid>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kasra Kassai, Tasos Dagiuklas, Satwat Bashir, Muddesar Iqbal</dc:creator>
    </item>
  </channel>
</rss>
