<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 14 Feb 2025 05:00:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Compositional Taylor expansion in cartesian differential categories</title>
      <link>https://arxiv.org/abs/2502.09066</link>
      <description>arXiv:2502.09066v1 Announce Type: new 
Abstract: This paper provides a compositional approach to Taylor expansion, in the setting of cartesian differential categories. Taylor expansion is captured here by a functor that generalizes the tangent bundle functor to higher order derivatives. The fundamental properties of Taylor expansion then boils down to naturality equations that turns this functor into a monad. This monad provides a categorical approach to higher order dual numbers and the jet bundle construction used in automated differentiation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09066v1</guid>
      <category>cs.LO</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Walch Aymeric (IRIF)</dc:creator>
    </item>
    <item>
      <title>Data Structures for Finite Downsets of Natural Vectors: Theory and Practice</title>
      <link>https://arxiv.org/abs/2502.09189</link>
      <description>arXiv:2502.09189v1 Announce Type: new 
Abstract: Manipulating downward-closed sets of vectors forms the basis of so-called antichain-based algorithms in verification. In that context, the dimension of the vectors is intimately tied to the size of the input structure to be verified. In this work, we formally analyze the complexity of classical list-based algorithms to manipulate antichains as well as that of Zampuni\'eris's sharing trees and traditional and novel kdtree-based antichain algorithms. In contrast to the existing literature, and to better address the needs of formal verification, our analysis of \kdtree algorithms does not assume that the dimension of the vectors is fixed. Our theoretical results show that kdtrees are asymptotically better than both list- and sharing-tree-based algorithms, as an antichain data structure, when the antichains become exponentially larger than the dimension of the vectors. We evaluate this on applications in the synthesis of reactive systems from linear-temporal logic and parity-objective specifications, and establish empirically that current benchmarks for these computational tasks do not lead to a favorable situation for current implementations of kdtrees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09189v1</guid>
      <category>cs.LO</category>
      <category>cs.DS</category>
      <category>cs.FL</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Micha\"el Cadilhac, Vanessa Fl\"ugel, Guillermo A. P\'erez, Shrisha Rao</dc:creator>
    </item>
    <item>
      <title>Efficient OWL2QL Meta-reasoning Using ASP-based Hybrid Knowledge Bases</title>
      <link>https://arxiv.org/abs/2502.09206</link>
      <description>arXiv:2502.09206v1 Announce Type: new 
Abstract: Metamodeling refers to scenarios in ontologies in which classes and roles can be members of classes or occur in roles. This is a desirable modelling feature in several applications, but allowing it without restrictions is problematic for several reasons, mainly because it causes undecidability. Therefore, practical languages either forbid metamodeling explicitly or treat occurrences of classes as instances to be semantically different from other occurrences, thereby not allowing metamodeling semantically. Several extensions have been proposed to provide metamodeling to some extent. Building on earlier work that reduces metamodeling query answering to Datalog query answering, recently reductions to query answering over hybrid knowledge bases were proposed with the aim of using the Datalog transformation only where necessary. Preliminary work showed that the approach works, but the hoped-for performance improvements were not observed yet. In this work we expand on this body of work by improving the theoretical basis of the reductions and by using alternative tools that show competitive performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09206v1</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <category>cs.SC</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.416.17</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 416, 2025, pp. 188-200</arxiv:journal_reference>
      <dc:creator>Haya Majid Qureshi (University of Klagenfurt), Wolfgang Faber (University of Klagenfurt)</dc:creator>
    </item>
    <item>
      <title>Autonomous Task Completion Based on Goal-directed Answer Set Programming</title>
      <link>https://arxiv.org/abs/2502.09208</link>
      <description>arXiv:2502.09208v1 Announce Type: new 
Abstract: Task planning for autonomous agents has typically been done using deep learning models and simulation-based reinforcement learning. This research proposes combining inductive learning techniques with goal-directed answer set programming to increase the explainability and reliability of systems for task breakdown and completion. Preliminary research has led to the creation of a Python harness that utilizes s(CASP) to solve task problems in a computationally efficient way. Although this research is in the early stages, we are exploring solutions to complex problems in simulated task completion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09208v1</guid>
      <category>cs.LO</category>
      <category>cs.SE</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.416.39</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 416, 2025, pp. 381-389</arxiv:journal_reference>
      <dc:creator>Alexis R. Tudor</dc:creator>
    </item>
    <item>
      <title>Architecture for Simulating Behavior Mode Changes in Norm-Aware Autonomous Agents</title>
      <link>https://arxiv.org/abs/2502.09215</link>
      <description>arXiv:2502.09215v1 Announce Type: new 
Abstract: This paper presents an architecture for simulating the actions of a norm-aware intelligent agent whose behavior with respect to norm compliance is set, and can later be changed, by a human controller. Updating an agent's behavior mode from a norm-abiding to a riskier one may be relevant when the agent is involved in time-sensitive rescue operations, for example. We base our work on the Authorization and Obligation Policy Language AOPL designed by Gelfond and Lobo for the specification of norms. We introduce an architecture and a prototype software system that can be used to simulate an agent's plans under different behavior modes that can later be changed by the controller. We envision such software to be useful to policy makers, as they can more readily understand how agents may act in certain situations based on the agents' attitudes towards norm-compliance. Policy makers may then refine their policies if simulations show unwanted consequences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09215v1</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.416.7</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 416, 2025, pp. 95-107</arxiv:journal_reference>
      <dc:creator>Sean Glaze (Miami University), Daniela Inclezan (Miami University)</dc:creator>
    </item>
    <item>
      <title>Data2Concept2Text: An Explainable Multilingual Framework for Data Analysis Narration</title>
      <link>https://arxiv.org/abs/2502.09218</link>
      <description>arXiv:2502.09218v1 Announce Type: new 
Abstract: This paper presents a complete explainable system that interprets a set of data, abstracts the underlying features and describes them in a natural language of choice. The system relies on two crucial stages: (i) identifying emerging properties from data and transforming them into abstract concepts, and (ii) converting these concepts into natural language. Despite the impressive natural language generation capabilities demonstrated by Large Language Models, their statistical nature and the intricacy of their internal mechanism still force us to employ these techniques as black boxes, forgoing trustworthiness. Developing an explainable pipeline for data interpretation would allow facilitating its use in safety-critical environments like processing medical information and allowing non-experts and visually impaired people to access narrated information. To this end, we believe that the fields of knowledge representation and automated reasoning research could present a valid alternative. Expanding on prior research that tackled the first stage (i), we focus on the second stage, named Concept2Text. Being explainable, data translation is easily modeled through logic-based rules, once again emphasizing the role of declarative programming in achieving AI explainability. This paper explores a Prolog/CLP-based rewriting system to interpret concepts-articulated in terms of classes and relations, plus common knowledge-derived from a generic ontology, generating natural language text. Its main features include hierarchical tree rewritings, modular multilingual generation, support for equivalent variants across semantic, grammar, and lexical levels, and a transparent rule-based system. We outline the architecture and demonstrate its flexibility through some examples capable of generating numerous diverse and equivalent rewritings based on the input concept.
</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09218v1</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.416.13</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 416, 2025, pp. 139-152</arxiv:journal_reference>
      <dc:creator>Flavio Bertini (UNIPR), Alessandro Dal Pal\`u (UNIPR), Federica Zaglio (UNIPR), Francesco Fabiano (NMSU), Andrea Formisano (UNIUD)</dc:creator>
    </item>
    <item>
      <title>Abduction of Domain Relationships from Data for VQA</title>
      <link>https://arxiv.org/abs/2502.09219</link>
      <description>arXiv:2502.09219v1 Announce Type: new 
Abstract: In this paper, we study the problem of visual question answering (VQA) where the image and query are represented by ASP programs that lack domain data.  We provide an approach that is orthogonal and complementary to existing knowledge augmentation techniques where we abduce domain relationships of image constructs from past examples. After framing the abduction problem, we provide a baseline approach, and an implementation that significantly improves the accuracy of query answering yet requires few examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09219v1</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.416.15</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 416, 2025, pp. 168-174</arxiv:journal_reference>
      <dc:creator>Al Mehdi Saadat Chowdhury, Paulo Shakarian, Gerardo I. Simari</dc:creator>
    </item>
    <item>
      <title>Graphical Conditions for the Existence, Unicity and Number of Regular Models</title>
      <link>https://arxiv.org/abs/2502.09220</link>
      <description>arXiv:2502.09220v1 Announce Type: new 
Abstract: The regular models of a normal logic program are a particular type of partial (i.e. 3-valued) models which correspond to stable partial models with minimal undefinedness. In this paper, we explore graphical conditions on the dependency graph of a finite ground normal logic program to analyze the existence, unicity and number of regular models for the program. We show three main results: 1) a necessary condition for the existence of non-trivial (i.e. non-2-valued) regular models, 2) a sufficient condition for the unicity of regular models, and 3) two upper bounds for the number of regular models based on positive feedback vertex sets. The first two conditions generalize the finite cases of the two existing results obtained by You and Yuan (1994) for normal logic programs with well-founded stratification. The third result is also new to the best of our knowledge. Key to our proofs is a connection that we establish between finite ground normal logic programs and Boolean network theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09220v1</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <category>cs.DM</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.416.16</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 416, 2025, pp. 175-187</arxiv:journal_reference>
      <dc:creator>Van-Giang Trinh (LIRICA team, LIS, Aix-Marseille University, Marseille, France), Belaid Benhamou (LIRICA team, LIS, Aix-Marseille University, Marseille, France), Sylvain Soliman (Inria Saclay, EP Lifeware, Palaiseau, France), Fran\c{c}ois Fages (Inria Saclay, EP Lifeware, Palaiseau, France)</dc:creator>
    </item>
    <item>
      <title>A Coq Formalization of Unification Modulo Exclusive-Or</title>
      <link>https://arxiv.org/abs/2502.09225</link>
      <description>arXiv:2502.09225v1 Announce Type: new 
Abstract: Equational Unification is a critical problem in many areas such as automated theorem proving and security protocol analysis. In this paper, we focus on XOR-Unification, that is, unification modulo the theory of exclusive-or. This theory contains an operator with the properties Associativity, Commutativity, Nilpotency, and the presence of an identity. In the proof assistant Coq, we implement an algorithm that solves XOR unification problems, whose design was inspired by Liu and Lynch, and prove it sound, complete, and terminating. Using Coq's code extraction capability we obtain an implementation in the programming language OCaml.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09225v1</guid>
      <category>cs.LO</category>
      <category>cs.CR</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.416.23</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 416, 2025, pp. 267-273</arxiv:journal_reference>
      <dc:creator>Yichi Xu (Worcester Polytechnic Institute), Daniel J. Dougherty (Worcester Polytechnic Institute), Rose Bohrer (Worcester Polytechnic Institute)</dc:creator>
    </item>
    <item>
      <title>Bridging Logic Programming and Deep Learning for Explainability through ILASP</title>
      <link>https://arxiv.org/abs/2502.09227</link>
      <description>arXiv:2502.09227v1 Announce Type: new 
Abstract: My research explores integrating deep learning and logic programming to set the basis for a new generation of AI systems. By combining neural networks with Inductive Logic Programming (ILP), the goal is to construct systems that make accurate predictions and generate comprehensible rules to validate these predictions. Deep learning models process and analyze complex data, while ILP techniques derive logical rules to prove the network's conclusions. Explainable AI methods, like eXplainable Answer Set Programming (XASP), elucidate the reasoning behind these rules and decisions. The focus is on applying ILP frameworks, specifically ILASP and FastLAS, to enhance explainability in various domains. My test cases span weather prediction, the legal field, and image recognition. In weather forecasting, the system will predict events and provides explanations using FastLAS, with plans to integrate recurrent neural networks in the future. In the legal domain, the research focuses on interpreting vague decisions and assisting legal professionals by encoding Italian legal articles and learning reasoning patterns from Court of Cassation decisions using ILASP. For biological laboratories, we will collaborate with a research group to automate spermatozoa morphology classification for Bull Breeding Soundness Evaluation using YOLO networks and ILP to explain classification outcomes. This hybrid approach aims to bridge the gap between the high performance of deep learning models and the transparency of symbolic reasoning, advancing AI by providing interpretable and trustworthy applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09227v1</guid>
      <category>cs.LO</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.416.31</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 416, 2025, pp. 314-323</arxiv:journal_reference>
      <dc:creator>Talissa Dreossi (University of Udine)</dc:creator>
    </item>
    <item>
      <title>Relating Answer Set Programming and Many-sorted Logics for Formal Verification</title>
      <link>https://arxiv.org/abs/2502.09230</link>
      <description>arXiv:2502.09230v1 Announce Type: new 
Abstract: Answer Set Programming (ASP) is an important logic programming paradigm within the field of Knowledge Representation and Reasoning. As a concise, human-readable, declarative language, ASP is an excellent tool for developing trustworthy (especially, artificially intelligent) software systems. However, formally verifying ASP programs offers some unique challenges, such as
  1. a lack of modularity (the meanings of rules are difficult to define in isolation from the enclosing program),
  2. the ground-and-solve semantics (the meanings of rules are dependent on the input data with which the program is grounded), and
  3. limitations of existing tools.
  My research agenda has been focused on addressing these three issues with the intention of making ASP verification an accessible, routine task that is regularly performed alongside program development. In this vein, I have investigated alternative semantics for ASP based on translations into the logic of here-and-there and many-sorted first-order logic. These semantics promote a modular understanding of logic programs, bypass grounding, and enable us to use automated theorem provers to automatically verify properties of programs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09230v1</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <category>cs.PL</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.416.33</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 416, 2025, pp. 332-344</arxiv:journal_reference>
      <dc:creator>Zachary Hansen (University of Nebraska Omaha)</dc:creator>
    </item>
    <item>
      <title>Logical foundations of Smart Contracts</title>
      <link>https://arxiv.org/abs/2502.09232</link>
      <description>arXiv:2502.09232v1 Announce Type: new 
Abstract: Nowadays, sophisticated domains are emerging which require appropriate formalisms to be specified accurately in order to reason about them. One such domain is constituted of smart contracts that have emerged in cyber physical systems as a way of enforcing formal agreements between components of these systems.  Smart contracts self-execute to run and share business processes through blockchain, in decentralized systems, with many different participants. Legal contracts are in many cases complex documents, with a number of exceptions, and many subcontracts. The implementation of smart contracts based on legal contracts is a long and laborious task, that needs to include all actions, procedures, and the effects of actions related to the execution of the contract. An ongoing open problem in this area is to formally account for smart contracts using a uniform and somewhat universal formalism. This thesis proposes logical foundations to smart contracts using the Situation Calculus, a logic for reasoning about actions. Situation Calculus is one of the prominent logic-based artificial intelligence approaches that provides enough logical mechanism to specify and implement dynamic and complex systems such as contracts. Situation Calculus is suitable to show how worlds dynamically change.  Smart contracts are going to be implement with Golog (written en Prolog), a Situation Calculus-based programming language for modeling complex and dynamic behaviors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09232v1</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.416.35</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 416, 2025, pp. 351-357</arxiv:journal_reference>
      <dc:creator>Kalonji Kalala (University of Ottawa)</dc:creator>
    </item>
    <item>
      <title>A Category-Theoretic Perspective on Approximation Fixpoint Theory</title>
      <link>https://arxiv.org/abs/2502.09234</link>
      <description>arXiv:2502.09234v1 Announce Type: new 
Abstract: Approximation Fixpoint Theory (AFT) was founded in the early 2000s by Denecker, Marek, and Truszczy\'nski as an abstract algebraic framework to study the semantics of non-monotonic logics. Since its early successes, the potential of AFT as a unifying semantic framework has become widely recognised, and the interest in AFT has gradually increased, with applications now ranging from foundations of database theory to abstract argumentation. The non-monotonic constructive processes that occur in many more areas of computer science, together with their associated semantic structures, can be successfully studied using AFT, which greatly simplifies their characterizations. The goal of my research is to take a step towards the lifting of AFT into a more general framework for constructive knowledge. </description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09234v1</guid>
      <category>cs.LO</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.416.37</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 416, 2025, pp. 365-373</arxiv:journal_reference>
      <dc:creator>Samuele Pollaci (VUB)</dc:creator>
    </item>
    <item>
      <title>Early Validation of High-level Requirements on Cyber-Physical Systems</title>
      <link>https://arxiv.org/abs/2502.09236</link>
      <description>arXiv:2502.09236v1 Announce Type: new 
Abstract: The overarching, broad topic of my research are advancements in the area of safety-critical, cyber-physical systems (CPS) development with emphasis on validation and verification. The particular focus of my research is the early validation of high-level requirements on CPS. My current approach for tackling this problem is transforming the requirements into Event Calculus and subsequently reasoning about them using ASP solvers such as the grounding-free s(CASP). Below, I discuss my research, its current state, and the open issues that are still left to tackle. The first results of my work will be presented in a paper that was accepted for ICLP'24, which is my first paper in this area.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09236v1</guid>
      <category>cs.LO</category>
      <category>cs.SE</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.416.40</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 416, 2025, pp. 390-397</arxiv:journal_reference>
      <dc:creator>Ond\v{r}ej Va\v{s}\'i\v{c}ek (Brno University of Technology, Czechia)</dc:creator>
    </item>
    <item>
      <title>Reliable Conversational Agents under ASP Control that Understand Natural Language</title>
      <link>https://arxiv.org/abs/2502.09237</link>
      <description>arXiv:2502.09237v1 Announce Type: new 
Abstract: Efforts have been made to make machines converse like humans in the past few decades. The recent techniques of Large Language Models (LLMs) make it possible to have human-like conversations with machines, but LLM's flaws of lacking understanding and reliability are well documented. We believe that the best way to eliminate this problem is to use LLMs only as parsers to translate text to knowledge and vice versa and carry out the conversation by reasoning over this knowledge using the answer set programming. I have been developing a framework based on LLMs and ASP to realize reliable chatbots that "understand" human conversation. This framework has been used to develop task-specific chatbots as well as socialbots. My future research is focused on making these chatbots scalable and trainable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09237v1</guid>
      <category>cs.LO</category>
      <category>cs.CL</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.416.41</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 416, 2025, pp. 398-406</arxiv:journal_reference>
      <dc:creator>Yankai Zeng (The University of Texas at Dallas)</dc:creator>
    </item>
    <item>
      <title>Logical Lease Litigation: Prolog and LLMs for Rental Law Compliance in New York</title>
      <link>https://arxiv.org/abs/2502.09204</link>
      <description>arXiv:2502.09204v1 Announce Type: cross 
Abstract: Legal cases require careful logical reasoning following the laws, whereas interactions with non- technical users must be in natural language. As an application combining logical reasoning using Prolog and natural language processing using large language models (LLMs), this paper presents a novel approach and system, LogicLease, to automate the analysis of landlord-tenant legal cases in the state of New York. LogicLease determines compliance with relevant legal requirements by analyzing case descriptions and citing all relevant laws. It leverages LLMs for information extraction and Prolog for legal reasoning. By separating information extraction from legal reasoning, LogicLease achieves greater transparency and control over the legal logic applied to each case. We evaluate the accuracy, efficiency, and robustness of LogicLease through a series of tests, achieving 100% accuracy and an average processing time of 2.57 seconds. LogicLease presents advantages over state-of-the-art LLM- based legal analysis systems by providing clear, step-by-step reasoning, citing specific laws, and distinguishing itself by its ability to avoid hallucinations - a common issue in LLMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09204v1</guid>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.416.4</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 416, 2025, pp. 59-68</arxiv:journal_reference>
      <dc:creator>Sanskar Sehgal, Yanhong A. Liu</dc:creator>
    </item>
    <item>
      <title>Counterfactual Explanations as Plans</title>
      <link>https://arxiv.org/abs/2502.09205</link>
      <description>arXiv:2502.09205v1 Announce Type: cross 
Abstract: There has been considerable recent interest in explainability in AI, especially with black-box machine learning models.  As correctly observed by the planning community, when the application at hand is not a single-shot decision or prediction, but a sequence of actions that depend on observations, a richer notion of explanations are desirable. 
  In this paper, we look to provide a formal account of ``counterfactual explanations," based in terms of action sequences. We then show that this naturally leads to an account of model reconciliation, which might take the form of the user correcting the agent's model, or suggesting actions to the agent's plan. For this, we will need to articulate what is true versus what is known, and we appeal to a modal fragment of the situation calculus to formalise these intuitions. We consider various settings: the agent knowing partial truths, weakened truths and having false beliefs, and show that our definitions easily generalize to these different settings. </description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09205v1</guid>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.416.14</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 416, 2025, pp. 153-167</arxiv:journal_reference>
      <dc:creator>Vaishak Belle (University of Edinburgh)</dc:creator>
    </item>
    <item>
      <title>Visual Graph Question Answering with ASP and LLMs for Language Parsing</title>
      <link>https://arxiv.org/abs/2502.09211</link>
      <description>arXiv:2502.09211v1 Announce Type: cross 
Abstract: Visual Question Answering (VQA) is a challenging problem that requires to process multimodal input. Answer-Set Programming (ASP) has shown great potential in this regard to add interpretability and explainability to modular VQA architectures. In this work, we address the problem of how to integrate ASP with modules for vision and natural language processing to solve a new and demanding VQA variant that is concerned with images of graphs (not graphs in symbolic form). Images containing graph-based structures are an ubiquitous and popular form of visualisation. Here, we deal with the particular problem of graphs inspired by transit networks, and we introduce a novel dataset that amends an existing one by adding images of graphs that resemble metro lines. Our modular neuro-symbolic approach combines optical graph recognition for graph parsing, a pretrained optical character recognition neural network for parsing labels, Large Language Models (LLMs) for language processing, and ASP for reasoning. This method serves as a first baseline and achieves an overall average accuracy of 73% on the dataset. Our evaluation provides further evidence of the potential of modular neuro-symbolic systems, in particular with pretrained models that do not involve any further training and logic programming for reasoning, to solve complex VQA tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09211v1</guid>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.LO</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.416.2</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 416, 2025, pp. 15-28</arxiv:journal_reference>
      <dc:creator>Jakob Johannes Bauer (ETH Zuerich, Switzerland), Thomas Eiter (TU Wien, Austria), Nelson Higuera Ruiz (TU Wien, Austria), Johannes Oetsch (Jonkoping University, Sweden)</dc:creator>
    </item>
    <item>
      <title>Mind the Gaps: Logical English, Prolog, and Multi-agent Systems for Autonomous Vehicles</title>
      <link>https://arxiv.org/abs/2502.09216</link>
      <description>arXiv:2502.09216v1 Announce Type: cross 
Abstract: In this paper, we present a modular system for representing and reasoning with legal aspects of traffic rules for autonomous vehicles. We focus on a subset of the United Kingdom's Highway Code (HC) related to junctions. As human drivers and automated vehicles (AVs) will interact on the roads, especially in urban environments, we claim that an accessible, unitary, high-level computational model should exist and be applicable to both users. Autonomous vehicles introduce a shift in liability that should not bring disadvantages or increased burden on human drivers. We develop a system "in silico" of the model.  The proposed system is built of three main components: a natural language interface, using Logical English, which encodes the rules; an internal representation of the rules in Prolog; and an multi-agent-based simulation environment, built in NetLogo. The three components interact: Logical English is translated into and out of Prolog (along with some support code); Prolog and NetLogo interface via predicates. Such a modular approach enables the different components to carry different "burdens" in the overall system; it also allows swapping of modules. Given NetLogo, we can visualize the effect of the modeled rules as well as validate the system with a simple dynamic running scenario. Designated agents monitor the behaviour of the vehicles for compliance and record potential violations where they occur. The information on potential violations is then utilized by Validators, to determine whether the violation is punishable, differentiating between exceptions and cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09216v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LO</category>
      <category>cs.MA</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.416.9</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 416, 2025, pp. 111-124</arxiv:journal_reference>
      <dc:creator>Galileo Sartor (Swansea University), Adam Wyner (Swansea University), Giuseppe Contissa (University of Bologna)</dc:creator>
    </item>
    <item>
      <title>Pearce's Characterisation in an Epistemic Domain</title>
      <link>https://arxiv.org/abs/2502.09221</link>
      <description>arXiv:2502.09221v1 Announce Type: cross 
Abstract: Answer-set programming (ASP) is a successful problem-solving approach in logic-based AI. In ASP, problems are represented as declarative logic programs, and solutions are identified through their answer sets. Equilibrium logic (EL) is a general-purpose nonmonotonic reasoning formalism, based on a monotonic logic called here-and-there logic. EL was basically proposed by Pearce as a foundational framework of ASP. Epistemic specifications (ES) are extensions of ASP-programs with subjective literals. These new modal constructs in the ASP-language make it possible to check whether a regular literal of ASP is true in every (or some) answer-set of a program. ES-programs are interpreted by world-views, which are essentially collections of answer-sets. (Reflexive) autoepistemic logic is a nonmonotonic formalism, modeling self-belief (knowledge) of ideally rational agents. A relatively new semantics for ES is based on a combination of EL and (reflexive) autoepistemic logic. In this paper, we first propose an overarching framework in the epistemic ASP domain. We then establish a correspondence between existing (reflexive) (auto)epistemic equilibrium logics and our easily-adaptable comprehensive framework, building on Pearce's characterisation of answer-sets as equilibrium models. We achieve this by extending Ferraris' work on answer sets for propositional theories to the epistemic case and reveal the relationship between some ES-semantic proposals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09221v1</guid>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.416.18</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 416, 2025, pp. 201-214</arxiv:journal_reference>
      <dc:creator>Ezgi Iraz Su (Sinop University)</dc:creator>
    </item>
    <item>
      <title>ASP-driven User-interaction with Clinguin</title>
      <link>https://arxiv.org/abs/2502.09222</link>
      <description>arXiv:2502.09222v1 Announce Type: cross 
Abstract: We present clinguin, a system for ASP-driven user interface design. Clinguin streamlines the development of user interfaces for ASP developers by letting them build interactive prototypes directly in ASP, eliminating the need for separate frontend languages. To this end, clinguin uses a few dedicated predicates to define user interfaces and the treatment of user-triggered events. This simple design greatly facilitates the specification of user interactions with an ASP system, in our case clingo.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09222v1</guid>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.LO</category>
      <category>cs.SE</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.416.19</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 416, 2025, pp. 215-228</arxiv:journal_reference>
      <dc:creator>Alexander Beiser, Susana Hahn, Torsten Schaub</dc:creator>
    </item>
    <item>
      <title>A Prolog Program for Bottom-up Evaluation</title>
      <link>https://arxiv.org/abs/2502.09223</link>
      <description>arXiv:2502.09223v1 Announce Type: cross 
Abstract: This short paper describes a simple and intuitive Prolog program, a metainterpreter, that computes the bottom up meaning of a simple positive Horn clause definition.  It involves a simple transformation of the object program rules into metarules, which are then used by a metainterpreter to compute bottom up the model of the original program.  The resulting algorithm is a form of semi-naive bottom-up evaluation.  We discuss various reasons why this Prolog program is particularly interesting.  
  In particular, this is perhaps the only Prolog program for which I find the use of Prolog's assert/1 to be intrinsic, easily understood, and the best, most perspicuous, way to program an algorithm.  This short paper might be best characterized as a Prolog programming pearl.
</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09223v1</guid>
      <category>cs.PL</category>
      <category>cs.DB</category>
      <category>cs.LO</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.416.20</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 416, 2025, pp. 229-235</arxiv:journal_reference>
      <dc:creator>David S. Warren (Stony Brook University)</dc:creator>
    </item>
    <item>
      <title>Order-Sorted Intensional Logic: Expressing Subtyping Polymorphism with Typing Assertions and Quantification over Concepts</title>
      <link>https://arxiv.org/abs/2502.09224</link>
      <description>arXiv:2502.09224v1 Announce Type: cross 
Abstract: Subtyping, also known as subtype polymorphism, is a concept extensively studied in programming language theory, delineating the substitutability relation among datatypes. This property ensures that programs designed for supertype objects remain compatible with their subtypes.
  In this paper, we explore the capability of order-sorted logic for utilizing these ideas in the context of Knowledge Representation. We recognize two fundamental limitations: First, the inability of this logic to address the concept  rather than the value  of non-logical symbols, and second, the lack of language constructs for constraining the type of terms. Consequently, we propose guarded order-sorted intensional logic, where guards are language constructs for annotating typing information and intensional logic provides support for quantification over concepts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09224v1</guid>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.416.22</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 416, 2025, pp. 253-266</arxiv:journal_reference>
      <dc:creator>{\DJ}or{\dj}e Markovi\'c, Marc Denecker</dc:creator>
    </item>
    <item>
      <title>Computational methods for Dynamic Answer Set Programming</title>
      <link>https://arxiv.org/abs/2502.09228</link>
      <description>arXiv:2502.09228v1 Announce Type: cross 
Abstract: In our daily lives and industrial settings, we often encounter dynamic problems that require reasoning over time and metric constraints. These include tasks such as scheduling, routing, and production sequencing. Dynamic logics have traditionally addressed these needs but often lack the flexibility and integration required for comprehensive problem modeling. This research aims to extend Answer Set Programming (ASP), a powerful declarative problem-solving approach, to handle dynamic domains effectively. By integrating concepts from dynamic, temporal, and metric logics into ASP, we seek to develop robust systems capable of modeling complex dynamic problems and performing efficient reasoning tasks, thereby enhancing ASPs applicability in industrial contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09228v1</guid>
      <category>cs.AI</category>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.416.32</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 416, 2025, pp. 324-331</arxiv:journal_reference>
      <dc:creator>Susana Hahn (University of Potsdam, Germany)</dc:creator>
    </item>
    <item>
      <title>Answer Set Counting and its Applications</title>
      <link>https://arxiv.org/abs/2502.09231</link>
      <description>arXiv:2502.09231v1 Announce Type: cross 
Abstract: We have focused on Answer Set Programming (ASP), more specifically, answer set counting, exploring both exact and approximate methodologies. We developed an exact ASP counter, sharpASP, which utilizes a compact encoding for propositional formulas, significantly enhancing efficiency compared to existing methods that often struggle with inefficient encodings. Our evaluations indicate that sharpASP outperforms current ASP counters on several benchmarks. In addition, we proposed an approximate ASP counter, named ApproxASP, a hashing-based counter integrating Gauss-Jordan elimination within the ASP solver, clingo. As a practical application, we employed ApproxASP for network reliability estimation, demonstrating superior performance over both traditional reliability estimators and #SAT-based methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09231v1</guid>
      <category>cs.CL</category>
      <category>cs.LO</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.416.34</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 416, 2025, pp. 345-350</arxiv:journal_reference>
      <dc:creator>Mohimenul Kabir (National University of Singapore)</dc:creator>
    </item>
    <item>
      <title>Hybrid Answer Set Programming: Foundations and Applications</title>
      <link>https://arxiv.org/abs/2502.09235</link>
      <description>arXiv:2502.09235v1 Announce Type: cross 
Abstract: Answer Set Programming (ASP) is a powerful tool for solving real-world problems. However, many problems involve numeric values and complex constraints beyond the capabilities of standard ASP solvers. Hybrid solvers like CLINGCON and CLINGO[DL] address this by using specialized methods for specific constraints. However, these solvers lack a strong theoretical foundation.
  This issue has first been addressed by introducing the Logic of Here-and-There with constraints (HT_c) as an extension of the Logic of Here-and-There (HT) and its non-monotone extension Equilibrium Logic. Nowadays, HT serves as a logical foundation for ASP and has facilitated a broader understanding of this paradigm. The idea is that HTC (and other extensions) play an analogous role for hybrid ASP.
  There remain many open questions about these logics regarding their fundamental characteristics as well as their practical use in solvers, ie. how they can guide the implementation.
  Having a formal understanding of these hybrid logics is also needed to better understand the inherent structure of the (real-world) problems they are applied to and to improve their representations in ASP. As an example of an application of ASP we use product configuration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09235v1</guid>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.416.38</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 416, 2025, pp. 374-380</arxiv:journal_reference>
      <dc:creator>Nicolas R\"uhling</dc:creator>
    </item>
    <item>
      <title>A Cut-free Sequent Calculus for Basic Intuitionistic Dynamic Topological Logic</title>
      <link>https://arxiv.org/abs/2502.09456</link>
      <description>arXiv:2502.09456v1 Announce Type: cross 
Abstract: As part of a broader family of logics, [1, 3] introduced two key logical systems: $\mathsf{iK_{d}}$, which encapsulates the basic logical structure of dynamic topological systems, and $\mathsf{iK_{d*}}$, which provides a well-behaved yet sufficiently general framework for an abstract notion of implication. These logics have been thoroughly examined through their algebraic, Kripke-style, and topological semantics. To complement these investigations with their missing proof-theoretic analysis, this paper introduces a cut-free G3-style sequent calculus for $\mathsf{iK_{d}}$ and $\mathsf{iK_{d*}}$. Using these systems, we demonstrate that they satisfy the disjunction property and, more broadly, admit a generalization of Visser's rules. Additionally, we establish that $\mathsf{iK_{d}}$ enjoys the Craig interpolation property and that its sequent system possesses the deductive interpolation property.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09456v1</guid>
      <category>math.LO</category>
      <category>cs.LO</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amirhossein Akbar Tabatabai, Majid Alizadeh, Alireza Mahmoudian</dc:creator>
    </item>
    <item>
      <title>Logical forms complement probability in understanding language model (and human) performance</title>
      <link>https://arxiv.org/abs/2502.09589</link>
      <description>arXiv:2502.09589v1 Announce Type: cross 
Abstract: With the increasing interest in using large language models (LLMs) for planning in natural language, understanding their behaviors becomes an important research question. This work conducts a systematic investigation of LLMs' ability to perform logical reasoning in natural language. We introduce a controlled dataset of hypothetical and disjunctive syllogisms in propositional and modal logic and use it as the testbed for understanding LLM performance. Our results lead to novel insights in predicting LLM behaviors: in addition to the probability of input (Gonen et al., 2023; McCoy et al., 2024), logical forms should be considered as orthogonal factors. In addition, we show similarities and differences between the logical reasoning performances of humans and LLMs by comparing LLM and human behavioral results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09589v1</guid>
      <category>cs.CL</category>
      <category>cs.LO</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yixuan Wang, Freda Shi</dc:creator>
    </item>
    <item>
      <title>Checking Trustworthiness of Probabilistic Computations in a Typed Natural Deduction System</title>
      <link>https://arxiv.org/abs/2206.12934</link>
      <description>arXiv:2206.12934v4 Announce Type: replace 
Abstract: In this paper we present the probabilistic typed natural deduction calculus TPTND, designed to reason about and derive trustworthiness properties of probabilistic computational processes, like those underlying current AI applications. Derivability in TPTND is interpreted as the process of extracting $n$ samples of possibly complex outputs with a certain frequency from a given categorical distribution. We formalize trust for such outputs as a form of hypothesis testing on the distance between such frequency and the intended probability. The main advantage of the calculus is to render such notion of trustworthiness checkable. We present a computational semantics for the terms over which we reason and then the semantics of TPTND, where logical operators as well as a Trust operator are defined through introduction and elimination rules. We illustrate structural and metatheoretical properties, with particular focus on the ability to establish under which term evolutions and logical rules applications the notion of trustworhtiness can be preserved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.12934v4</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1093/logcom/exaf003</arxiv:DOI>
      <arxiv:journal_reference>F. A. D'Asaro, F. A. Genco, G. Primiero, Checking trustworthiness of probabilistic computations in a typed natural deduction system, Journal of Logic and Computation, 2025, exaf00</arxiv:journal_reference>
      <dc:creator>Fabio Aurelio D'Asaro, Francesco Genco, Giuseppe Primiero</dc:creator>
    </item>
    <item>
      <title>A Typed Lambda-Calculus for Establishing Trust in Probabilistic Programs</title>
      <link>https://arxiv.org/abs/2302.00958</link>
      <description>arXiv:2302.00958v2 Announce Type: replace 
Abstract: The extensive deployment of probabilistic algorithms has radically changed our perspective on several well-established computational notions. Correctness is probably the most basic one. While a typical probabilistic program cannot be said to compute the correct result, we often have quite strong expectations about the frequency with which it should return certain outputs. In these cases, trust as a generalisation of correctness fares better. One way to understand it is to say that a probabilistic computational process is trustworthy if the frequency of its outputs is compliant with a probability distribution which models its expected behaviour. We present a formal computational framework that formalises this idea. In order to do so, we define a typed lambda-calculus that features operators for conducting experiments at runtime on probabilistic programs and for evaluating whether they compute outputs as determined by a target probability distribution. After proving some fundamental computational properties of the calculus, such as progress and termination, we define a static notion of confidence that allows to prove that our notion of trust behaves correctly with respect to the basic tenets of probability theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.00958v2</guid>
      <category>cs.LO</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francesco A. Genco, Giuseppe Primiero</dc:creator>
    </item>
    <item>
      <title>Fully Evaluated Left-Sequential Logics</title>
      <link>https://arxiv.org/abs/2403.14576</link>
      <description>arXiv:2403.14576v2 Announce Type: replace 
Abstract: We consider a family of two-valued "fully evaluated left-sequential logics" (FELs), of which Free FEL (defined by Staudt in 2012) is most distinguishing (weakest) and immune to atomic side effects. Next is Memorising FEL, in which evaluations of subexpressions are memorised. The following stronger logic is Conditional FEL (inspired by Guzm\'an and Squier's Conditional logic, 1990). The strongest FEL is static FEL, a sequential version of propositional logic. We use evaluation trees as a simple, intuitive semantics and provide complete axiomatisations for closed terms (left-sequential propositional expressions).
  For each FEL except Static FEL, we also define its three-valued version, with a constant U for "undefinedness" and again provide complete, independent axiomatisations, each one containing two additional axioms for U on top of the axiomatisations of the two-valued case. In this setting, the strongest FEL is equivalent to Bochvar's strict logic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14576v2</guid>
      <category>cs.LO</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alban Ponse, Daan J. C. Staudt</dc:creator>
    </item>
    <item>
      <title>Regular Typed Unification</title>
      <link>https://arxiv.org/abs/2404.16406</link>
      <description>arXiv:2404.16406v2 Announce Type: replace 
Abstract: Here we define a new unification algorithm for terms interpreted in semantic domains denoted by a subclass of regular types here called deterministic regular types. This reflects our intention not to handle the semantic universe as a homogeneous collection of values, but instead, to partition it in a way that is similar to data types in programming languages. We first define the new unification algorithm which is based on constraint generation and constraint solving, and then prove its main properties: termination, soundness, and completeness with respect to the semantics. Finally, we discuss how to apply this algorithm to a dynamically typed version of Prolog.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16406v2</guid>
      <category>cs.LO</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.416.21</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 416, 2025, pp. 236-252</arxiv:journal_reference>
      <dc:creator>Jo\~ao Barbosa, M\'ario Florido, V\'itor Santos Costa</dc:creator>
    </item>
    <item>
      <title>Geospatial Trajectory Generation via Efficient Abduction: Deployment for Independent Testing</title>
      <link>https://arxiv.org/abs/2407.06447</link>
      <description>arXiv:2407.06447v2 Announce Type: replace 
Abstract: The ability to generate artificial human movement patterns while meeting location and time constraints is an important problem in the security community, particularly as it enables the study of the analog problem of detecting such patterns while maintaining privacy.  We frame this problem as an instance of abduction guided by a novel parsimony function represented as an aggregate truth value over an annotated logic program.  This approach has the added benefit of affording explainability to an analyst user.  By showing that any subset of such a program can provide a lower bound on this parsimony requirement, we are able to abduce movement trajectories efficiently through an informed (i.e., A*) search.  We describe how our implementation was enhanced with the application of multiple techniques in order to be scaled and integrated with a cloud-based software stack that included bottom-up rule learning, geolocated knowledge graph retrieval/management, and interfaces with government systems for independently conducted government-run tests for which we provide results.  We also report on our own experiments showing that we not only provide exact results but also scale to very large scenarios and provide realistic agent trajectories that can go undetected by machine learning anomaly detectors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06447v2</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.416.24</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 416, 2025, pp. 274-287</arxiv:journal_reference>
      <dc:creator>Divyagna Bavikadi, Dyuman Aditya, Devendra Parkar, Paulo Shakarian, Graham Mueller, Chad Parvis, Gerardo I. Simari</dc:creator>
    </item>
    <item>
      <title>Algorithms for Markov Binomial Chains</title>
      <link>https://arxiv.org/abs/2408.04902</link>
      <description>arXiv:2408.04902v2 Announce Type: replace 
Abstract: We study algorithms to analyze a particular class of Markov population processes that is often used in epidemiology. More specifically, Markov binomial chains are the model that arises from stochastic time-discretizations of classical compartmental models. In this work we formalize this class of Markov population processes and focus on the problem of computing the expected time to termination in a given such model. Our theoretical contributions include proving that Markov binomial chains whose flow of individuals through compartments is acyclic almost surely terminate. We give a PSPACE algorithm for the problem of approximating the time to termination and a direct algorithm for the exact problem in the Blum-Shub-Smale model of computation. Finally, we provide a natural encoding of Markov binomial chains into a common input language for probabilistic model checkers. We implemented the latter encoding and present some initial empirical results showcasing what formal methods can do for practicing epidemiologists.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04902v2</guid>
      <category>cs.LO</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alejandro Alarc\'on Gonzalez, Niel Hens, Tim Leys, Guillermo A. P\'erez</dc:creator>
    </item>
    <item>
      <title>Each of those eight coalition logics is also determined by six other kinds of models</title>
      <link>https://arxiv.org/abs/2501.05466</link>
      <description>arXiv:2501.05466v2 Announce Type: replace 
Abstract: Coalition Logic is a central logic in logical research on strategic reasoning. In two recent papers, Li and Ju argued that generally, concurrent game models, models of Coalition Logic, have three too strong assumptions: seriality, independence of agents, and determinism. They presented eight coalition logics based on eight classes of general concurrent game models, determined by which of the three assumptions are met. In this paper, we show that each of the eight logics is also determined by six other kinds of models, with respective properties, that is, single-coalition-first action models, single-coalition-first neighborhood models, clear grand-coalition-first action models, clear single-coalition-first neighborhood models, tree-like grand-coalition-first action models, and tree-like single-coalition-first neighborhood models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05466v2</guid>
      <category>cs.LO</category>
      <category>cs.GT</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zixuan Chen, Fengkui Ju</dc:creator>
    </item>
    <item>
      <title>Stronger Validity Criteria for Encoding Synchrony</title>
      <link>https://arxiv.org/abs/2502.08307</link>
      <description>arXiv:2502.08307v2 Announce Type: replace 
Abstract: We analyse two translations from the synchronous into the asynchronous $\pi$-calculus, both without choice, that are often quoted as standard examples of valid encodings, showing that the asynchronous $\pi$-calculus is just as expressive as the synchronous one. We examine which of the quality criteria for encodings from the literature support the validity of these translations. Moreover, we prove their validity according to much stronger criteria than considered previously in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08307v2</guid>
      <category>cs.LO</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-030-31175-9_11</arxiv:DOI>
      <arxiv:journal_reference>In The Art of Modelling Computational Systems: A Journey from Logic and Concurrency to Security and Privacy - Essays Dedicated to Catuscia Palamidessi on the Occasion of Her 60th Birthday, LNCS 11760, Springer, 2019, pp. 182-205</arxiv:journal_reference>
      <dc:creator>Rob van Glabbeek, Ursula Goltz, Christopher Lippert, Stephan Mennicke</dc:creator>
    </item>
    <item>
      <title>Decomposition Strategies and Multi-shot ASP Solving for Job-shop Scheduling</title>
      <link>https://arxiv.org/abs/2205.07537</link>
      <description>arXiv:2205.07537v4 Announce Type: replace-cross 
Abstract: The Job-shop Scheduling Problem (JSP) is a well-known and challenging combinatorial optimization problem in which tasks sharing a machine are to be arranged in a sequence such that encompassing jobs can be completed as early as possible. In this paper, we investigate problem decomposition into time windows whose operations can be successively scheduled and optimized by means of multi-shot Answer Set Programming (ASP) solving. From a computational perspective, decomposition aims to split highly complex scheduling tasks into better manageable subproblems with a balanced number of operations such that good-quality or even optimal partial solutions can be reliably found in a small fraction of runtime. We devise and investigate a variety of decomposition strategies in terms of the number and size of time windows as well as heuristics for choosing their operations. Moreover, we incorporate time window overlapping and compression techniques into the iterative scheduling process to counteract optimization limitations due to the restriction to window-wise partial schedules. Our experiments on different JSP benchmark sets show that successive optimization by multi-shot ASP solving leads to substantially better schedules within tight runtime limits than single-shot optimization on the full problem. In particular, we find that decomposing initial solutions obtained with proficient heuristic methods into time windows leads to improved solution quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.07537v4</guid>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammed M. S. El-Kholany, Martin Gebser, Konstantin Schekotihin</dc:creator>
    </item>
    <item>
      <title>Smooth and Proper Maps</title>
      <link>https://arxiv.org/abs/2402.00331</link>
      <description>arXiv:2402.00331v5 Announce Type: replace-cross 
Abstract: This is an expository note explaining how the geometric notions of local connectedness and properness are related to the $\Sigma$-type and $\Pi$-type constructors of dependent type theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.00331v5</guid>
      <category>math.CT</category>
      <category>cs.LO</category>
      <category>math.AG</category>
      <category>math.LO</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1017/S096012952400032X</arxiv:DOI>
      <arxiv:journal_reference>Anel M, Weinberger J. Smooth and proper maps with respect to a fibration. Mathematical Structures in Computer Science. 2024;34(9):971-984</arxiv:journal_reference>
      <dc:creator>Mathieu Anel, Jonathan Weinberger</dc:creator>
    </item>
  </channel>
</rss>
