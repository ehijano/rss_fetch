<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 21 Aug 2024 01:48:06 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 20 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Online SLA Decomposition: Enabling Real-Time Adaptation to Evolving Systems</title>
      <link>https://arxiv.org/abs/2408.08968</link>
      <description>arXiv:2408.08968v2 Announce Type: new 
Abstract: When a network slice spans multiple domains, each domain must uphold the End-to-End (E2E) Service Level Agreement (SLA) associated with the slice. This requires decomposing the E2E SLA into partial SLAs for each domain. In a two-level network slicing management system with an E2E orchestrator and local controllers, we propose an online learning-decomposition framework that dynamically updates risk models using recent feedback. This approach utilizes online gradient descent and FIFO memory buffers to enhance stability and robustness. Our empirical study shows the proposed framework outperforms state-of-the-art static methods, offering more accurate and resilient SLA decomposition under varying conditions and sparse data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08968v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cyril Shih-Huan Hsu, Danny De Vleeschauwer, Chrysa Papagianni</dc:creator>
    </item>
    <item>
      <title>A Primer on Generative AI for Telecom: From Theory to Practice</title>
      <link>https://arxiv.org/abs/2408.09031</link>
      <description>arXiv:2408.09031v1 Announce Type: new 
Abstract: The rise of generative artificial intelligence (GenAI) is transforming the telecom industry. GenAI models, particularly large language models (LLMs), have emerged as powerful tools capable of driving innovation, improving efficiency, and delivering superior customer services in telecom. This paper provides an overview of GenAI for telecom from theory to practice. We review GenAI models and discuss their practical applications in telecom. Furthermore, we describe the key technology enablers and best practices for applying GenAI to telecom effectively. We highlight the importance of retrieval augmented generation (RAG) in connecting LLMs to telecom domain specific data sources to enhance the accuracy of the LLMs' responses. We present a real-world use case on RAG-based chatbot that can answer open radio access network (O-RAN) specific questions. The demonstration of the chatbot to the O-RAN Alliance has triggered immense interest in the industry. We have made the O-RAN RAG chatbot publicly accessible on GitHub.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09031v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xingqin Lin, Lopamudra Kundu, Chris Dick, Maria Amparo Canaveras Galdon, Janaki Vamaraju, Swastika Dutta, Vinay Raman</dc:creator>
    </item>
    <item>
      <title>GLANCE: Graph-based Learnable Digital Twin for Communication Networks</title>
      <link>https://arxiv.org/abs/2408.09040</link>
      <description>arXiv:2408.09040v1 Announce Type: new 
Abstract: As digital twins (DTs) to physical communication systems, network simulators can aid the design and deployment of communication networks. However, time-consuming simulations must be run for every new set of network configurations. Learnable digital twins (LDTs), in contrast, can be trained offline to emulate simulation outcomes and serve as a more efficient alternative to simulation-based DTs at runtime. In this work, we propose GLANCE, a communication LDT that learns from the simulator ns-3. It can evaluate network key performance indicators (KPIs) and assist in network management with exceptional efficiency. Leveraging graph learning, we exploit network data characteristics and devise a specialized architecture to embed sequential and topological features of traffic flows within the network. In addition, multi-task learning (MTL) and transfer learning (TL) are leveraged to enhance GLANCE's generalizability to unseen inputs and efficacy across different tasks. Beyond end-to-end KPI prediction, GLANCE can be deployed within an optimization framework for network management. It serves as an efficient or differentiable evaluator in optimizing network configurations such as traffic loads and flow destinations. Through numerical experiments and benchmarking, we verify the effectiveness of the proposed LDT architecture, demonstrate its robust generalization to various inputs, and showcase its efficacy in network management applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09040v1</guid>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Boning Li, Gunjan Verma, Timofey Efimov, Abhishek Kumar, Santiago Segarra</dc:creator>
    </item>
    <item>
      <title>Improved Q-learning based Multi-hop Routing for UAV-Assisted Communication</title>
      <link>https://arxiv.org/abs/2408.09109</link>
      <description>arXiv:2408.09109v1 Announce Type: new 
Abstract: Designing effective Unmanned Aerial Vehicle(UAV)-assisted routing protocols is challenging due to changing topology, limited battery capacity, and the dynamic nature of communication environments. Current protocols prioritize optimizing individual network parameters, overlooking the necessity for a nuanced approach in scenarios with intermittent connectivity, fluctuating signal strength, and varying network densities, ultimately failing to address aerial network requirements comprehensively. This paper proposes a novel, Improved Q-learning-based Multi-hop Routing (IQMR) algorithm for optimal UAV-assisted communication systems. Using Q(\lambda) learning for routing decisions, IQMR substantially enhances energy efficiency and network data throughput. IQMR improves system resilience by prioritizing reliable connectivity and inter-UAV collision avoidance while integrating real-time network status information, all in the absence of predefined UAV path planning, thus ensuring dynamic adaptability to evolving network conditions. The results validate IQMR's adaptability to changing system conditions and superiority over the current techniques. IQMR showcases 36.35\% and 32.05\% improvements in energy efficiency and data throughput over the existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09109v1</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>N P Sharvari, Dibakar Das, Jyotsna Bapat, Debabrata Das</dc:creator>
    </item>
    <item>
      <title>Utility Optimal Scheduling with a Slow Time-Scale Index-Bias for Achieving Rate Guarantees in Cellular Networks</title>
      <link>https://arxiv.org/abs/2408.09182</link>
      <description>arXiv:2408.09182v1 Announce Type: new 
Abstract: One of the requirements of network slicing in 5G networks is RAN (radio access network) scheduling with rate guarantees. We study a three-time-scale algorithm for maximum sum utility scheduling, with minimum rate constraints. As usual, the scheduler computes an index for each UE in each slot, and schedules the UE with the maximum index. This is at the fastest, natural time-scale of channel fading. The next time-scale is of the exponentially weighted moving average (EWMA) rate update. The slowest time scale in our algorithm is an "index-bias" update by a stochastic approximation algorithm, with a step-size smaller than the EWMA. The index-biases are related to Lagrange multipliers, and bias the slot indices of the UEs with rate guarantees, promoting their more frequent scheduling. We obtain a pair of coupled ordinary differential equations (o.d.e.) such that the unique stable points of the two o.d.e.s are the primal and dual solutions of the constrained utility optimization problem. The UE rate and index-bias iterations track the asymptotic behaviour of the o.d.e. system for small step-sizes of the two slower time-scale iterations. Simulations show that, by running the index-bias iteration at a slower time-scale than the EWMA iteration and using the EWMA throughput itself in the index-bias update, the UE rates stabilize close to the optimum operating point on the rate region boundary, and the index-biases have small fluctuations around the optimum Lagrange multipliers. We compare our results with a prior two-time-scale algorithm and show improved performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09182v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Anurag Kumar, Rajesh Sundaresan</dc:creator>
    </item>
    <item>
      <title>Next-Generation Satellite IoT Networks: A HAPS-Enabled Solution to Enhance Optical Data Transfer</title>
      <link>https://arxiv.org/abs/2408.09281</link>
      <description>arXiv:2408.09281v1 Announce Type: new 
Abstract: For decades, satellites have facilitated remote internet of things (IoT) services. However, the recent proliferation of increasingly capable sensors and a surge in the number deployed, has led to a substantial growth in the volume of data that needs to be transmitted via satellites. In response to this growing demand, free space optical communication systems have been proposed, as they allow for the use of large bandwidths of unlicensed spectrum, enabling high data rates. However, optical communications are highly vulnerable to weather-induced disruptions, thereby limiting their high potential. This paper proposes the use of high altitude platform station (HAPS) systems in conjunction with delay-tolerant networking techniques to increase the amount of data that can be transmitted to the ground from satellites when compared to the use of traditional ground station network architectures. The architectural proposal is evaluated in terms of delivery ratio and buffer occupancy, and the subsequent discussion analyzes the advantages, challenges and potential areas for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09281v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ethan Fettes, Pablo G. Madoery, Halim Yanikomeroglu, Gunes Karabulut Kurt, Colin Bellinger, St\'ephane Martel, Khaled Ahmed, Sameera Siddiqui</dc:creator>
    </item>
    <item>
      <title>A Spatio-temporal Prediction Methodology Based on Deep Learning and Real Wi-Fi Measurements</title>
      <link>https://arxiv.org/abs/2408.09423</link>
      <description>arXiv:2408.09423v1 Announce Type: new 
Abstract: The rapid development of Wi-Fi technologies in recent years has caused a significant increase in the traffic usage. Hence, knowledge obtained from Wi-Fi network measurements can be helpful for a more efficient network management. In this paper, we propose a methodology to predict future values of some specific network metrics (e.g. traffic load, transmission failures, etc.). These predictions may be useful for improving the network performance. After data collection and preprocessing, the correlation between each target access point (AP) and its neighbouring APs is estimated. According to these correlations, either an only-temporal or a spatio-temporal based prediction is done. To evaluate the proposed methodology, real measurements are collected from 100 APs deployed in different university buildings for 3 months. Deep Learning (DL) methods (i.e. Convolutional Neural Network (CNN), Simple Recurrent Neural Network (SRNN), Gated Recurrent Unit (GRU), Long Short-Term Memory (LSTM), Transformer) are evaluated and compared for both temporal and spatio-temporal based predictions. Moreover, a hybrid prediction methodology is proposed using a spatial processing based on CNN and a temporal prediction based on RNN. The proposed hybrid methodology provides an improvement in the prediction accuracy at expenses of a slight increase in the Training Computational Time (TCT) and negligible in Prediction Computational Time (PCT).</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09423v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.comnet.2024.110569</arxiv:DOI>
      <arxiv:journal_reference>Computer Networks, Volume 250, August 2024, 110569</arxiv:journal_reference>
      <dc:creator>Seyedeh Soheila Shaabanzadeh (Universitat Polit\`ecnica de Catalunya), Juan S\'anchez-Gonz\'alez (Universitat Polit\`ecnica de Catalunya)</dc:creator>
    </item>
    <item>
      <title>Measurement-based Resource Allocation and Control in Data Centers: A Survey</title>
      <link>https://arxiv.org/abs/2408.09497</link>
      <description>arXiv:2408.09497v1 Announce Type: new 
Abstract: Data centers have become ubiquitous for today's businesses. From banks to startups, they rely on cloud infrastructure to deploy user applications. In this context, it is vital to provide users with application performance guarantees. Network interference is one of the causes of unpredictable application performance, and many solutions have been proposed over the years. The main objective of this survey is to familiarize the reader with research into network measurement-based resource allocation and control in \dcs, focusing on network resources in order to provide cloud performance guarantees. We start with a primer on general network measurement techniques and \dc network and applications to give the reader context. We then summarize the characteristics of network traffic and cluster workloads in \dcs, which are pivotal for measurement-based allocation and control. We study and compare network monitoring in data centers, giving an overview on their evolution from Software-Defined Networking (SDN) to programmable dataplanes-based. The network monitoring information can serve as input to cluster allocation and scheduling decisions. We next categorize cluster scheduling frameworks, and perform an analysis of those that provide network guarantees in data centers, and we also look at emergent Machine Learning-driven resource allocation and control. We conclude with a discussion about future research directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09497v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Diana Andreea Popescu</dc:creator>
    </item>
    <item>
      <title>ISAC-Fi: Enabling Full-fledged Monostatic Sensing over Wi-Fi Communication</title>
      <link>https://arxiv.org/abs/2408.09851</link>
      <description>arXiv:2408.09851v1 Announce Type: new 
Abstract: Whereas Wi-Fi communications have been exploited for sensing purpose for over a decade, the bistatic or multistatic nature of Wi-Fi still poses multiple challenges, hampering real-life deployment of integrated sensing and communication (ISAC) within Wi-Fi framework. In this paper, we aim to re-design WiFi so that monostatic sensing (mimicking radar) can be achieved over the multistatic communication infrastructure. Specifically, we propose, design, and implement ISAC-Fi as an ISAC-ready Wi-Fi prototype. We first present a novel self-interference cancellation scheme, in order to extract reflected (radio frequency) signals for sensing purpose in the face of transmissions. We then subtly revise existing Wi-Fi framework so as to seamlessly operate monostatic sensing under Wi-Fi communication standard. Finally, we offer two ISAC-Fi designs: while a USRP-based one emulates a totally re-designed ISAC-Fi device, another plug-andplay design allows for backward compatibility by attaching an extra module to an arbitrary Wi-Fi device. We perform extensive experiments to validate the efficacy of ISAC-Fi and also to demonstrate its superiority over existing Wi-Fi sensing proposals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09851v1</guid>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhe Chen, Chao Hu, Tianyue Zheng, Hangcheng Cao, Yanbing Yang, Yen Chu, Hongbo Jiang, Jun Luo</dc:creator>
    </item>
    <item>
      <title>Selecting Relay Nodes Based on Evaluation Results to Enhance P2P Broadcasting Efficiency</title>
      <link>https://arxiv.org/abs/2408.10092</link>
      <description>arXiv:2408.10092v1 Announce Type: new 
Abstract: The existence of node failures is inevitable in distributed systems, thus many P2P broadcasting networks adopt highly robust Flooding-based broadcast algorithms. High redundancy inevitably leads to high network resource consumption, and it may constrain the data transmission rate of the network. To address excessive network resource consumption, many studies have explored broadcasting mechanisms in structured P2P overlay networks. However, existing DHT-based algorithms cannot assess the quality of neighbors, which is crucial for broadcast efficiency. In this paper, we introduce the Neighbor Evaluation mechanism to select relay nodes based on their evaluated contributions. According to experimental results, the Neighbor Evaluation mechanism has a significant effect on both broadcast latency and coverage rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10092v1</guid>
      <category>cs.NI</category>
      <category>cs.DC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chunlin Huang</dc:creator>
    </item>
    <item>
      <title>LCDN: Providing Network Determinism with Low-Cost Switches</title>
      <link>https://arxiv.org/abs/2408.10171</link>
      <description>arXiv:2408.10171v1 Announce Type: new 
Abstract: The demands on networks are increasing on a fast pace. In particular, real-time applications have very strict network requirements. However, building a network capable of hosting real-time applications is a cost-intensive endeavor, especially for experimental systems such as testbeds. Systems that provide guaranteed real-time networking capabilities usually work with expensive software-defined switches. In contrast, real-time networking systems based on cheaper hardware face the limitation of lower link speeds. Therefore, this paper fills this gap and presents Low-Cost Deterministic Networking (LCDN), a system that is designed to work with cheap common off-the-shelf switches and devices. LCDN works at Gigabit speed and enables powerful testbeds that can host real-time applications with hard delay guarantees. This paper also provides the evaluation of the determinism of the used switch as well as a Raspberry Pi used as an end device.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10171v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philip Diederich, Yash Deshpande, Laura Becker, Wolfgang Kellerer</dc:creator>
    </item>
    <item>
      <title>Twin Sorting Dynamic Programming Assisted User Association and Wireless Bandwidth Allocation for Hierarchical Federated Learning</title>
      <link>https://arxiv.org/abs/2408.09076</link>
      <description>arXiv:2408.09076v1 Announce Type: cross 
Abstract: In this paper, we study user association and wireless bandwidth allocation for a hierarchical federated learning system that consists of mobile users, edge servers, and a cloud server. To minimize the length of a global round in hierarchical federated learning with equal bandwidth allocation, we formulate a combinatorial optimization problem. We design the twin sorting dynamic programming (TSDP) algorithm that obtains a globally optimal solution in polynomial time when there are two edge servers. In addition, we put forward the TSDP-assisted algorithm for user association when there are three or more edge servers. Furthermore, given a user association matrix, we formulate and solve a convex optimization problem for optimal wireless bandwidth allocation. Simulation results show that the proposed approach outperforms a number of alternative schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09076v1</guid>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rung-Hung Gau, Ting-Yu Wang, Chun-Hung Liu</dc:creator>
    </item>
    <item>
      <title>DRL-Based Resource Allocation for Motion Blur Resistant Federated Self-Supervised Learning in IoV</title>
      <link>https://arxiv.org/abs/2408.09194</link>
      <description>arXiv:2408.09194v1 Announce Type: cross 
Abstract: In the Internet of Vehicles (IoV), Federated Learning (FL) provides a privacy-preserving solution by aggregating local models without sharing data. Traditional supervised learning requires image data with labels, but data labeling involves significant manual effort. Federated Self-Supervised Learning (FSSL) utilizes Self-Supervised Learning (SSL) for local training in FL, eliminating the need for labels while protecting privacy. Compared to other SSL methods, Momentum Contrast (MoCo) reduces the demand for computing resources and storage space by creating a dictionary. However, using MoCo in FSSL requires uploading the local dictionary from vehicles to Base Station (BS), which poses a risk of privacy leakage. Simplified Contrast (SimCo) addresses the privacy leakage issue in MoCo-based FSSL by using dual temperature instead of a dictionary to control sample distribution. Additionally, considering the negative impact of motion blur on model aggregation, and based on SimCo, we propose a motion blur-resistant FSSL method, referred to as BFSSL. Furthermore, we address energy consumption and delay in the BFSSL process by proposing a Deep Reinforcement Learning (DRL)-based resource allocation scheme, called DRL-BFSSL. In this scheme, BS allocates the Central Processing Unit (CPU) frequency and transmission power of vehicles to minimize energy consumption and latency, while aggregating received models based on the motion blur level. Simulation results validate the effectiveness of our proposed aggregation and resource allocation methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09194v1</guid>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xueying Gu, Qiong Wu, Pingyi Fan, Qiang Fan, Nan Cheng, Wen Chen, Khaled B. Letaief</dc:creator>
    </item>
    <item>
      <title>ByCAN: Reverse Engineering Controller Area Network (CAN) Messages from Bit to Byte Level</title>
      <link>https://arxiv.org/abs/2408.09265</link>
      <description>arXiv:2408.09265v1 Announce Type: cross 
Abstract: As the primary standard protocol for modern cars, the Controller Area Network (CAN) is a critical research target for automotive cybersecurity threats and autonomous applications. As the decoding specification of CAN is a proprietary black-box maintained by Original Equipment Manufacturers (OEMs), conducting related research and industry developments can be challenging without a comprehensive understanding of the meaning of CAN messages. In this paper, we propose a fully automated reverse-engineering system, named ByCAN, to reverse engineer CAN messages. ByCAN outperforms existing research by introducing byte-level clusters and integrating multiple features at both byte and bit levels. ByCAN employs the clustering and template matching algorithms to automatically decode the specifications of CAN frames without the need for prior knowledge. Experimental results demonstrate that ByCAN achieves high accuracy in slicing and labeling performance, i.e., the identification of CAN signal boundaries and labels. In the experiments, ByCAN achieves slicing accuracy of 80.21%, slicing coverage of 95.21%, and labeling accuracy of 68.72% for general labels when analyzing the real-world CAN frames.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09265v1</guid>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaojie Lin, Baihe Ma, Xu Wang, Guangsheng Yu, Ying He, Ren Ping Liu, Wei Ni</dc:creator>
    </item>
    <item>
      <title>Global BGP Attacks that Evade Route Monitoring</title>
      <link>https://arxiv.org/abs/2408.09622</link>
      <description>arXiv:2408.09622v1 Announce Type: cross 
Abstract: As the deployment of comprehensive Border Gateway Protocol (BGP) security measures is still in progress, BGP monitoring continues to play a critical role in protecting the Internet from routing attacks. Fundamentally, monitoring involves observing BGP feeds to detect suspicious announcements and taking defensive action. However, BGP monitoring relies on seeing the malicious BGP announcement in the first place! In this paper, we develop a novel attack that can hide itself from all state-of-the-art BGP monitoring systems we tested while affecting the entire Internet. The attack involves launching a sub-prefix hijack with the RFC-specified NO_EXPORT community attached to prevent networks with the malicious route installed from sending the route to BGP monitoring systems. We study the viability of this attack at four tier-1 networks and find all networks we studied were vulnerable to the attack. Finally, we propose a mitigation that significantly improves the robustness of the BGP monitoring ecosystem. Our paper aims to raise awareness of this issue and offer guidance to providers to protect against such attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09622v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Henry Birge-Lee, Maria Apostolaki, Jennifer Rexford</dc:creator>
    </item>
    <item>
      <title>Validation of the Results of Cross-chain Smart Contract Based on Confirmation Method</title>
      <link>https://arxiv.org/abs/2408.09962</link>
      <description>arXiv:2408.09962v1 Announce Type: cross 
Abstract: Smart contracts are widely utilized in cross-chain interactions, where their results are transmitted from one blockchain (the producer blockchain) to another (the consumer blockchain). Unfortunately, the consumer blockchain often accepts these results without executing the smart contracts for validation, posing potential security risks. To address this, we propose a method for validating cross-chain smart contract results. Our approach emphasizes consumer blockchain execution of cross-chain smart contracts of producer blockchain, allowing comparison of results with the transmitted ones to detect potential discrepancies and ensure data integrity during cross-chain data dissemination. Additionally, we introduce the confirmation with proof method, which involves incorporating the chain of blocks and relevant cross-chain smart contract data from the producer blockchain into the consumer blockchain as evidence (or proof), establishing a unified and secure perspective of cross-chain smart contract results. Our verification results highlight the feasibility of cross-chain validation at the smart contract level.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09962v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hong Su</dc:creator>
    </item>
    <item>
      <title>Revisiting Multi-User Downlink in IEEE 802.11ax: A Designers Guide to MU-MIMO</title>
      <link>https://arxiv.org/abs/2406.05913</link>
      <description>arXiv:2406.05913v2 Announce Type: replace 
Abstract: Downlink (DL) Multi-User (MU) Multiple Input Multiple Output (MU-MIMO) is a key technology that allows multiple concurrent data transmissions from an Access Point (AP) to a selected sub-set of clients for higher network efficiency in IEEE 802.11ax. However, DL MU-MIMO feature is typically turned off as the default setting in AP vendors' products, that is, turning on the DL MU-MIMO may not help increase the network efficiency, which is counter-intuitive. In this article, we provide a sufficiently deep understanding of the interplay between the various underlying factors, i.e., CSI overhead and spatial correlation, which result in negative results when turning on the DL MU-MIMO. Furthermore, we provide a fundamental guideline as a function of operational scenarios to address the fundamental question "when the DL MU-MIMO should be turned on/off".</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05913v2</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liu Cao, Lyutianyang Zhang, Sumit Roy, Sian Jin</dc:creator>
    </item>
    <item>
      <title>Hybrid Semantic/Bit Communication Based Networking Problem Optimization</title>
      <link>https://arxiv.org/abs/2408.07820</link>
      <description>arXiv:2408.07820v2 Announce Type: replace 
Abstract: This paper jointly investigates user association (UA), mode selection (MS), and bandwidth allocation (BA) problems in a novel and practical next-generation cellular network where two modes of semantic communication (SemCom) and conventional bit communication (BitCom) coexist, namely hybrid semantic/bit communication network (HSB-Net). Concretely, we first identify a unified performance metric of message throughput for both SemCom and BitCom links. Next, we comprehensively develop a knowledge matching-aware two-stage tandem packet queuing model and theoretically derive the average packet loss ratio and queuing latency. Combined with several practical constraints, we then formulate a joint optimization problem for UA, MS, and BA to maximize the overall message throughput of HSB-Net. Afterward, we propose an optimal resource management strategy by employing a Lagrange primal-dual method and devising a preference list-based heuristic algorithm. Finally, numerical results validate the performance superiority of our proposed strategy compared with different benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07820v2</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Le Xia, Yao Sun, Dusit Niyato, Lan Zhang, Lei Zhang, Muhammad Ali Imran</dc:creator>
    </item>
    <item>
      <title>Learning Automata-Based Enhancements to RPL: Pioneering Load-Balancing and Traffic Management in IoT</title>
      <link>https://arxiv.org/abs/2408.08373</link>
      <description>arXiv:2408.08373v2 Announce Type: replace 
Abstract: The Internet of Things (IoT) signifies a revolutionary technological advancement, enhancing various applications through device interconnectivity while introducing significant challenges due to these devices' limited hardware and communication capabilities. To navigate these complexities, the Internet Engineering Task Force (IETF) has tailored the Routing Protocol for Low-Power and Lossy Networks (RPL) to meet the unique demands of IoT environments. However, RPL struggles with traffic congestion and load distribution issues, negatively impacting network performance and reliability. This paper presents a novel enhancement to RPL by integrating learning automata designed to optimize network traffic distribution. This enhanced protocol, the Learning Automata-based Load-Aware RPL (LALARPL), dynamically adjusts routing decisions based on real-time network conditions, achieving more effective load balancing and significantly reducing network congestion. Extensive simulations reveal that this approach outperforms existing methodologies, leading to notable improvements in packet delivery rates, end-to-end delay, and energy efficiency. The findings highlight the potential of our approach to enhance IoT network operations and extend the lifespan of network components. The effectiveness of learning automata in refining routing processes within RPL offers valuable insights that may drive future advancements in IoT networking, aiming for more robust, efficient, and sustainable network architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08373v2</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Mohammadhossein Homaei</dc:creator>
    </item>
    <item>
      <title>Distributed No-Regret Learning for Multi-Stage Systems with End-to-End Bandit Feedback</title>
      <link>https://arxiv.org/abs/2404.04509</link>
      <description>arXiv:2404.04509v2 Announce Type: replace-cross 
Abstract: This paper studies multi-stage systems with end-to-end bandit feedback. In such systems, each job needs to go through multiple stages, each managed by a different agent, before generating an outcome. Each agent can only control its own action and learn the final outcome of the job. It has neither knowledge nor control on actions taken by agents in the next stage. The goal of this paper is to develop distributed online learning algorithms that achieve sublinear regret in adversarial environments.
  The setting of this paper significantly expands the traditional multi-armed bandit problem, which considers only one agent and one stage. In addition to the exploration-exploitation dilemma in the traditional multi-armed bandit problem, we show that the consideration of multiple stages introduces a third component, education, where an agent needs to choose its actions to facilitate the learning of agents in the next stage. To solve this newly introduced exploration-exploitation-education trilemma, we propose a simple distributed online learning algorithm, $\epsilon-$EXP3. We theoretically prove that the $\epsilon-$EXP3 algorithm is a no-regret policy that achieves sublinear regret. Simulation results show that the $\epsilon-$EXP3 algorithm significantly outperforms existing no-regret online learning algorithms for the traditional multi-armed bandit problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04509v2</guid>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>I-Hong Hou</dc:creator>
    </item>
    <item>
      <title>HookChain: A new perspective for Bypassing EDR Solutions</title>
      <link>https://arxiv.org/abs/2404.16856</link>
      <description>arXiv:2404.16856v3 Announce Type: replace-cross 
Abstract: In the current digital security ecosystem, where threats evolve rapidly and with complexity, companies developing Endpoint Detection and Response (EDR) solutions are in constant search for innovations that not only keep up but also anticipate emerging attack vectors. In this context, this article introduces the HookChain, a look from another perspective at widely known techniques, which when combined, provide an additional layer of sophisticated evasion against traditional EDR systems. Through a precise combination of IAT Hooking techniques, dynamic SSN resolution, and indirect system calls, HookChain redirects the execution flow of Windows subsystems in a way that remains invisible to the vigilant eyes of EDRs that only act on Ntdll.dll, without requiring changes to the source code of the applications and malwares involved. This work not only challenges current conventions in cybersecurity but also sheds light on a promising path for future protection strategies, leveraging the understanding that continuous evolution is key to the effectiveness of digital security. By developing and exploring the HookChain technique, this study significantly contributes to the body of knowledge in endpoint security, stimulating the development of more robust and adaptive solutions that can effectively address the ever-changing dynamics of digital threats. This work aspires to inspire deep reflection and advancement in the research and development of security technologies that are always several steps ahead of adversaries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16856v3</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <category>cs.OS</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Helvio Carvalho Junior</dc:creator>
    </item>
  </channel>
</rss>
