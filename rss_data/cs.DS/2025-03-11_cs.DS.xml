<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 12 Mar 2025 02:14:43 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Improving Merge Sort and Quick Sort Performance by Utilizing Alphadev's Sorting Networks as Base Cases</title>
      <link>https://arxiv.org/abs/2503.05934</link>
      <description>arXiv:2503.05934v1 Announce Type: new 
Abstract: Recent work by Google DeepMind introduced assembly-optimized sorting networks that achieve faster performance for small fixed-size arrays (3-8). In this research, we investigate the integration of these networks as base cases in classical divide-and-conquer sorting algorithms, specifically Merge Sort and Quick Sort, to leverage these efficient sorting networks for small subarrays generated during the recursive process. We conducted benchmarks with 11 different optimization configurations and compared them to classical Merge Sort and Quick Sort. We tested the configurations with random, sorted and nearly sorted arrays.
  Our optimized Merge Sort, using a configuration of three sorting networks (sizes 6, 7, and 8), achieves at least 1.5x speedup for random and nearly sorted arrays, and at least 2x speedup for sorted arrays, in comparison to classical Merge Sort. This optimized Merge Sort surpasses both classical Quick Sort and similarly optimized Quick Sort variants when sorting random arrays of size 10,000 and larger.
  When comparing our optimized Quick Sort to classical Quick Sort, we observe a 1.5x speedup using the 3-to-5 configuration on sorted arrays of size 10,000. The 6-to-8 configuration maintains a consistent 1.5x improvement across sorted arrays from 25,000 to 1 million elements. Our findings demonstrate the potential of integrating AI-optimized sorting networks to enhance the performance of classical sorting algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05934v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anas Gamal Aly, Anders E. Jensen, Hala ElAarag</dc:creator>
    </item>
    <item>
      <title>The connectivity carcass of a vertex subset in a graph: both odd and even case</title>
      <link>https://arxiv.org/abs/2503.06266</link>
      <description>arXiv:2503.06266v1 Announce Type: new 
Abstract: Let $G=(V,E)$ be an undirected unweighted multi-graph and $S\subseteq V$ be a subset of vertices called the Steiner set. A set of edges with the least cardinality whose removal disconnects $S$, that is, there is no path between at least one pair of vertices from $S$, is called a Steiner mincut for $S$ or simply an $S$-mincut. Connectivity Carcass is a compact data structure storing all $S$-mincuts in $G$ announced by Dinitz and Vainshtein in an extended abstract by Dinitz and Vainshtein in 1994. The complete proof of various results of this data structure for the simpler case when the capacity of $S$-mincut is odd appeared in the year 2000 in SICOMP. Over the last couple of decades, there have been attempts towards the proof for the case when the capacity of $S$-mincut is even, but none of them met a logical end. We present the following results.
  - We present the first complete, self-contained exposition of the connectivity carcass which covers both even and odd cases of the capacity of $S$-mincut.
  - We derive the results using an alternate and much simpler approach. In particular, we derive the results using submodularity of cuts -- a well-known property of graphs expressed using a simple inequality.
  - We also show how the connectivity carcass can be helpful in efficiently answering some basic queries related to $S$-mincuts using some additional insights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06266v1</guid>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Surender Baswana, Abhyuday Pandey</dc:creator>
    </item>
    <item>
      <title>Detecting correlation efficiently in stochastic block models: breaking Otter's threshold by counting decorated trees</title>
      <link>https://arxiv.org/abs/2503.06464</link>
      <description>arXiv:2503.06464v1 Announce Type: new 
Abstract: Consider a pair of sparse correlated stochastic block models $\mathcal S(n,\tfrac{\lambda}{n},\epsilon;s)$ subsampled from a common parent stochastic block model with two symmetric communities, average degree $\lambda=O(1)$ and divergence parameter $\epsilon \in (0,1)$. For all $\epsilon\in(0,1)$, we construct a statistic based on the combination of two low-degree polynomials and show that there exists a sufficiently small constant $\delta=\delta(\epsilon)&gt;0$ and a sufficiently large constant $\Delta=\Delta(\epsilon,\delta)$ such that when $\lambda&gt;\Delta$ and $s&gt;\sqrt{\alpha}-\delta$ where $\alpha\approx 0.338$ is Otter's constant, this statistic can distinguish this model and a pair of independent stochastic block models $\mathcal S(n,\tfrac{\lambda s}{n},\epsilon)$ with probability $1-o(1)$. We also provide an efficient algorithm that approximates this statistic in polynomial time. The crux of our statistic's construction lies in a carefully curated family of multigraphs called \emph{decorated trees}, which enables effective aggregation of the community signal and graph correlation from the counts of the same decorated tree while suppressing the undesirable correlations among counts of different decorated trees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06464v1</guid>
      <category>cs.DS</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guanyi Chen, Jian Ding, Shuyang Gong, Zhangsong Li</dc:creator>
    </item>
    <item>
      <title>Faster and Space Efficient Indexing for Locality Sensitive Hashing</title>
      <link>https://arxiv.org/abs/2503.06737</link>
      <description>arXiv:2503.06737v1 Announce Type: new 
Abstract: This work suggests faster and space-efficient index construction algorithms for LSH for Euclidean distance (\textit{a.k.a.}~\ELSH) and cosine similarity (\textit{a.k.a.}~\SRP). The index construction step of these LSHs relies on grouping data points into several bins of hash tables based on their hashcode. To generate an $m$-dimensional hashcode of the $d$-dimensional data point, these LSHs first project the data point onto a $d$-dimensional random Gaussian vector and then discretise the resulting inner product. The time and space complexity of both \ELSH~and \SRP~for computing an $m$-sized hashcode of a $d$-dimensional vector is $O(md)$, which becomes impractical for large values of $m$ and $d$. To overcome this problem, we propose two alternative LSH hashcode generation algorithms both for Euclidean distance and cosine similarity, namely, \CSELSH, \HCSELSH~and \CSSRP, \HCSSRP, respectively. \CSELSH~and \CSSRP~are based on count sketch \cite{count_sketch} and \HCSELSH~and \HCSSRP~utilize higher-order count sketch \cite{shi2019higher}. These proposals significantly reduce the hashcode computation time from $O(md)$ to $O(d)$. Additionally, both \CSELSH~and \CSSRP~reduce the space complexity from $O(md)$ to $O(d)$; ~and \HCSELSH, \HCSSRP~ reduce the space complexity from $O(md)$ to $O(N \sqrt[N]{d})$ respectively, where $N\geq 1$ denotes the size of the input/reshaped tensor. Our proposals are backed by strong mathematical guarantees, and we validate their performance through simulations on various real-world datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06737v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bhisham Dev Verma, Rameshwar Pratap</dc:creator>
    </item>
    <item>
      <title>Inverting Parameterized Burrows-Wheeler Transform</title>
      <link>https://arxiv.org/abs/2503.06970</link>
      <description>arXiv:2503.06970v1 Announce Type: new 
Abstract: The Burrows-Wheeler Transform (BWT) of a string is an invertible permutation of the string, which can be used for data compression and a compact index for string pattern matching. Ganguly et al. [SODA, 2017] introduced parameterized BWT (pBWT) to design a compact index for parameterized matching (p-matching), a variant of string pattern matching with parameter symbols introduced by Baker [STOC, 1993]. Although pBWT was inspired by BWT, it is not obvious whether the pBWT itself is invertible or not. In this paper we show that we can retrieve the original string (up to renaming of parameter symbols) from the pBWT of length $n$ in $O(n^2)$ time and $O(n)$ space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06970v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shogen Kawanami, Kento Iseri, Tomohiro I</dc:creator>
    </item>
    <item>
      <title>Encoding Schemes for Parallel In-Place Algorithms</title>
      <link>https://arxiv.org/abs/2503.06999</link>
      <description>arXiv:2503.06999v1 Announce Type: new 
Abstract: Many parallel algorithms which solve basic problems in computer science use auxiliary space linear in the input to facilitate conflict-free computation. There has been significant work on improving these parallel algorithms to be in-place, that is to use as little auxiliary memory as possible. In this paper, we provide novel in-place algorithms to solve the fundamental problems of merging two sorted sequences, and randomly shuffling a sequence. Both algorithms are work-efficient and have polylogarithmic span. Our algorithms employ encoding techniques which exploit the underlying structure of the input to gain access to more bits, which enables the use of auxiliary data as well as non-in-place methods. The encoding techniques we develop are general. We expect them to be useful in developing in-place algorithms for other problems beyond those already mentioned. To demonstrate this, we outline an additional application to integer sorting. In addition to our theoretical contributions, we implement our merging algorithm, and measure its memory usage and runtime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06999v1</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chase Hutton, Adam Melrod</dc:creator>
    </item>
    <item>
      <title>Encoding Co-Lex Orders of Finite-State Automata in Linear Space</title>
      <link>https://arxiv.org/abs/2503.07061</link>
      <description>arXiv:2503.07061v1 Announce Type: new 
Abstract: The Burrows-Wheeler transform (BWT) is a string transformation that enhances string indexing and compressibility. Cotumaccio and Prezza [SODA '21] extended this transformation to nondeterministic finite automata (NFAs) through co-lexicographic partial orders, i.e., by sorting the states of an NFA according to the co-lexicographic order of the strings reaching them. As the BWT of an NFA shares many properties with its original string variant, the transformation can be used to implement indices for locating specific patterns on the NFA itself. The efficiency of the resulting index is influenced by the width of the partial order on the states: the smaller the width, the faster the index. The most efficient index for arbitrary NFAs currently known in the literature is based on the coarsest forward-stable co-lex (CFS) order of Becker et al. [SPIRE '24]. In this paper, we prove that this CFS order can be encoded within linear space in the number of states in the automaton. The importance of this result stems from the fact that encoding such an order in linear space represents a big first step in the direction of building the index based on this order in near-linear time -- the biggest open research question in this context. The currently most efficient known algorithm for this task run in quadratic time in the number of transitions in the NFA and are thus infeasible to be run on very large graphs (e.g., pangenome graphs). At this point, a near-linear time algorithm is solely known for the simpler case of deterministic automata [Becker et al., ESA '23] and, in fact, this algorithmic result was enabled by a linear space encoding for deterministic automata [Kim et al., CPM '23].</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07061v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruben Becker, Nicola Cotumaccio, Sung-Hwan Kim, Nicola Prezza, Carlo Tosoni</dc:creator>
    </item>
    <item>
      <title>Welfare Approximation in Additively Separable Hedonic Games</title>
      <link>https://arxiv.org/abs/2503.06017</link>
      <description>arXiv:2503.06017v1 Announce Type: cross 
Abstract: Partitioning a set of $n$ items or agents while maximizing the value of the partition is a fundamental algorithmic task. We study this problem in the specific setting of maximizing social welfare in additively separable hedonic games. Unfortunately, this task faces strong computational boundaries: Extending previous results, we show that approximating welfare by a factor of $n^{1-\epsilon}$ is NP-hard, even for severely restricted weights. However, we can obtain a randomized $\log n$-approximation on instances for which the sum of input valuations is nonnegative. Finally, we study two stochastic models of aversion-to-enemies games, where the weights are derived from Erd\H{o}s-R\'{e}nyi or multipartite graphs. We obtain constant-factor and logarithmic-factor approximations with high probability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06017v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Bullinger, Vaggos Chatziafratis, Parnian Shahkar</dc:creator>
    </item>
    <item>
      <title>Digital Zero-Noise Extrapolation with Quantum Circuit Unoptimization</title>
      <link>https://arxiv.org/abs/2503.06341</link>
      <description>arXiv:2503.06341v1 Announce Type: cross 
Abstract: Quantum circuit unoptimization is an algorithm that transforms a quantum circuit into a different circuit that uses more gate operations while maintaining the same unitary transformation. We demonstrate that this method can implement digital zero-noise extrapolation (ZNE), a quantum error mitigation technique. By employing quantum circuit unoptimization as a form of circuit folding, noise can be systematically amplified. The key advantages of this approach are twofold. First, its ability to generate an exponentially increasing number of distinct circuit variants as the noise level is amplified, which allows noise averaging over many circuit instances with slightly different circuit structure which mitigates the effect of biased error propagation because of the significantly altered circuit structure from quantum circuit unoptimization, or highly biased local noise on a quantum processor. Second, quantum circuit unoptimization by design resists circuit simplification back to the original unmodified circuit, making it plausible to use ZNE in contexts where circuit compiler optimization is applied server-side. We evaluate the effectiveness of quantum circuit unoptimization as a noise-scaling method for ZNE in two test cases using depolarizing noise numerical simulations: random quantum volume circuits, where the observable is the heavy output probability, and QAOA circuits for the (unweighted) maximum cut problem on random 3-regular graphs, where the observable is the cut value. We show that using quantum circuit unoptimization to perform ZNE can approximately recover signal from noisy quantum simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06341v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elijah Pelofske, Vincent Russo</dc:creator>
    </item>
    <item>
      <title>Deterministically approximating the volume of a Kostka polytope</title>
      <link>https://arxiv.org/abs/2503.06459</link>
      <description>arXiv:2503.06459v1 Announce Type: cross 
Abstract: The volumes of Kostka polytopes appear naturally in questions of random matrix theory in the context of the randomized Schur-Horn problem, i.e., evaluating the probability density that a random Hermitian matrix with fixed spectrum has a given diagonal. We give a polynomial-time deterministic algorithm for approximating the volume of a ($\Omega(n^2)$ dimensional) Kostka polytope $\mathrm{GT}(\lambda, \mu)$ to within a multiplicative factor of $\exp(O(n\log n))$, when $\lambda$ is an integral partition with $n$ parts, with entries bounded above by a polynomial in $n$, and $\mu$ is an integer vector lying in the interior of the Schur-Horn polytope associated to $\lambda$. The algorithm thus gives asymptotically correct estimates of the log-volume of Kostka polytopes corresponding to such $(\lambda, \mu)$. Our approach is based on a partition function interpretation of the continuous analogue of Schur polynomials, and an associated maximum entropy principle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06459v1</guid>
      <category>math.CO</category>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hariharan Narayanan, Piyush Srivastava</dc:creator>
    </item>
    <item>
      <title>Combinatorial Optimization via LLM-driven Iterated Fine-tuning</title>
      <link>https://arxiv.org/abs/2503.06917</link>
      <description>arXiv:2503.06917v1 Announce Type: cross 
Abstract: We present a novel way to integrate flexible, context-dependent constraints into combinatorial optimization by leveraging Large Language Models (LLMs) alongside traditional algorithms. Although LLMs excel at interpreting nuanced, locally specified requirements, they struggle with enforcing global combinatorial feasibility. To bridge this gap, we propose an iterated fine-tuning framework where algorithmic feedback progressively refines the LLM's output distribution. Interpreting this as simulated annealing, we introduce a formal model based on a "coarse learnability" assumption, providing sample complexity bounds for convergence. Empirical evaluations on scheduling, graph connectivity, and clustering tasks demonstrate that our framework balances the flexibility of locally expressed constraints with rigorous global optimization more effectively compared to baseline sampling methods. Our results highlight a promising direction for hybrid AI-driven combinatorial reasoning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06917v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>stat.ML</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pranjal Awasthi, Sreenivas Gollapudi, Ravi Kumar, Kamesh Munagala</dc:creator>
    </item>
    <item>
      <title>A Quadratic Vertex Kernel and a Subexponential Algorithm for Subset-FAST</title>
      <link>https://arxiv.org/abs/2503.07208</link>
      <description>arXiv:2503.07208v1 Announce Type: cross 
Abstract: In the Subset Feedback Arc Set in Tournaments, Subset-FAST problem we are given as input a tournament $T$ with a vertex set $V(T)$ and an arc set $A(T)$, along with a terminal set $S \subseteq V(T)$, and an integer $ k$. The objective is to determine whether there exists a set $ F \subseteq A(T) $ with $|F| \leq k$ such that the resulting graph $T-F $ contains no cycle that includes any vertex of $S$. When $S=V(T)$ this is the classic Feedback Arc Set in Tournaments (FAST) problem. We obtain the first polynomial kernel for this problem parameterized by the solution size. More precisely, we obtain an algorithm that, given an input instance $(T, S, k)$, produces an equivalent instance $(T',S',k')$ with $k'\leq k$ and $V(T')=O(k^2)$.
  It was known that FAST admits a simple quadratic vertex kernel and a non-trivial linear vertex kernel. However, no such kernel was previously known for Subset-FAST. Our kernel employs variants of the most well-known reduction rules for FAST and introduces two new reduction rules to identify irrelevant vertices. As a result of our kernelization, we also obtain the first sub-exponential time FPT algorithm for Subset-FAST.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07208v1</guid>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Satyabrata Jana, Lawqueen Kanesh, Madhumita Kundu, Daniel Lokshtanov, Saket Saurabh</dc:creator>
    </item>
    <item>
      <title>Coreset Spectral Clustering</title>
      <link>https://arxiv.org/abs/2503.07227</link>
      <description>arXiv:2503.07227v1 Announce Type: cross 
Abstract: Coresets have become an invaluable tool for solving $k$-means and kernel $k$-means clustering problems on large datasets with small numbers of clusters. On the other hand, spectral clustering works well on sparse graphs and has recently been extended to scale efficiently to large numbers of clusters. We exploit the connection between kernel $k$-means and the normalised cut problem to combine the benefits of both. Our main result is a coreset spectral clustering algorithm for graphs that clusters a coreset graph to infer a good labelling of the original graph. We prove that an $\alpha$-approximation for the normalised cut problem on the coreset graph is an $O(\alpha)$-approximation on the original. We also improve the running time of the state-of-the-art coreset algorithm for kernel $k$-means on sparse kernels, from $\tilde{O}(nk)$ to $\tilde{O}(n\cdot \min \{k, d_{avg}\})$, where $d_{avg}$ is the average number of non-zero entries in each row of the $n\times n$ kernel matrix. Our experiments confirm our coreset algorithm is asymptotically faster on large real-world graphs with many clusters, and show that our clustering algorithm overcomes the main challenge faced by coreset kernel $k$-means on sparse kernels which is getting stuck in local optima.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07227v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ben Jourdan, Gregory Schwartzman, Peter Macgregor, He Sun</dc:creator>
    </item>
    <item>
      <title>Geometric realizations of dichotomous ordinal graphs</title>
      <link>https://arxiv.org/abs/2503.07361</link>
      <description>arXiv:2503.07361v1 Announce Type: cross 
Abstract: A dichotomous ordinal graph consists of an undirected graph with a partition of the edges into short and long edges. A geometric realization of a dichotomous ordinal graph $G$ in a metric space $X$ is a drawing of $G$ in $X$ in which every long edge is strictly longer than every short edge. We call a graph $G$ pandichotomous in $X$ if $G$ admits a geometric realization in $X$ for every partition of its edge set into short and long edges. We exhibit a very close relationship between the degeneracy of a graph $G$ and its pandichotomic Euclidean or spherical dimension, that is, the smallest dimension $k$ such that $G$ is pandichotomous in $\mathbb{R}^k$ or the sphere $\mathbb{S}^k$, respectively. First, every $d$-degenerate graph is pandichotomous in $\mathbb{R}^{d}$ and $\mathbb{S}^{d-1}$ and these bounds are tight for the sphere and for $\mathbb{R}^2$ and almost tight for $\mathbb{R}^d$, for $d\ge 3$. Second, every $n$-vertex graph that is pandichotomous in $\mathbb{R}^k$ has at most $\mu kn$ edges, for some absolute constant $\mu&lt;7.23$. This shows that the pandichotomic Euclidean dimension of any graph is linearly tied to its degeneracy and in the special cases $k\in \{1,2\}$ resolves open problems posed by Alam, Kobourov, Pupyrev, and Toeniskoetter. Further, we characterize which complete bipartite graphs are pandichotomous in $\mathbb{R}^2$: These are exactly the $K_{m,n}$ with $m\le 3$ or $m=4$ and $n\le 6$. For general bipartite graphs, we can guarantee realizations in $\mathbb{R}^2$ if the short or the long subgraph is constrained: namely if the short subgraph is outerplanar or a subgraph of a rectangular grid, or if the long subgraph forms a caterpillar.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07361v1</guid>
      <category>cs.CG</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Patrizio Angelini, Sabine Cornelsen, Carolina Haase, Michael Hoffmann, Eleni Katsanou, Fabrizio Montecchiani, Raphael Steiner, Antonios Symvonis</dc:creator>
    </item>
    <item>
      <title>Queueing, Predictions, and LLMs: Challenges and Open Problems</title>
      <link>https://arxiv.org/abs/2503.07545</link>
      <description>arXiv:2503.07545v1 Announce Type: cross 
Abstract: Queueing systems present many opportunities for applying machine-learning predictions, such as estimated service times, to improve system performance. This integration raises numerous open questions about how predictions can be effectively leveraged to improve scheduling decisions. Recent studies explore queues with predicted service times, typically aiming to minimize job time in the system. We review these works, highlight the effectiveness of predictions, and present open questions on queue performance. We then move to consider an important practical example of using predictions in scheduling, namely Large Language Model (LLM) systems, which presents novel scheduling challenges and highlights the potential for predictions to improve performance. In particular, we consider LLMs performing inference. Inference requests (jobs) in LLM systems are inherently complex; they have variable inference times, dynamic memory footprints that are constrained by key-value (KV) store memory limitations, and multiple possible preemption approaches that affect performance differently. We provide background on the important aspects of scheduling in LLM systems, and introduce new models and open problems that arise from them. We argue that there are significant opportunities for applying insights and analysis from queueing theory to scheduling in LLM systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07545v1</guid>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Mitzenmacher, Rana Shahout</dc:creator>
    </item>
    <item>
      <title>Differentially Private Continual Release of Histograms and Related Queries</title>
      <link>https://arxiv.org/abs/2302.11341</link>
      <description>arXiv:2302.11341v2 Announce Type: replace 
Abstract: We study privately releasing column sums of a $d$-dimensional table with entries from a universe $\chi$ undergoing $T$ row updates, called histogram under continual release. Our mechanisms give better additive $\ell_\infty$-error than existing mechanisms for a large class of queries and input streams. Our first contribution is an output-sensitive mechanism in the insertions-only model ($\chi = \{0,1\}$) for maintaining (i) the histogram or (ii) queries that do not require maintaining the entire histogram, such as the maximum or minimum column sum, the median, or any quantiles. The mechanism has an additive error of $O(d\log^2 (dq^*)+\log T)$ whp, where $q^*$ is the maximum output value over all time steps on this dataset. The mechanism does not require $q^*$ as input. This breaks the $\Omega(d \log T)$ bound of prior work when $q^* \ll T$. Our second contribution is a mechanism for the turnstile model that admits negative entry updates ($\chi = \{-1, 0,1\}$). This mechanism has an additive error of $O(d \log^2 (dK) + \log T)$ whp, where $K$ is the number of times two consecutive data rows differ, and the mechanism does not require $K$ as input. This is useful when monitoring inputs that only vary under unusual circumstances. For $d=1$ this gives the first private mechanism with error $O(\log^2 K + \log T)$ for continual counting in the turnstile model, improving on the $O(\log^2 n + \log T)$ error bound by Dwork et al. [ASIACRYPT 2015], where $n$ is the number of ones in the stream, as well as allowing negative entries, while Dwork et al. [ASIACRYPT 2015] can only handle nonnegative entries ($\chi=\{0,1\}$).</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.11341v2</guid>
      <category>cs.DS</category>
      <category>cs.CR</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Monika Henzinger, A. R. Sricharan, Teresa Anna Steiner</dc:creator>
    </item>
    <item>
      <title>Maintaining $k$-MinHash Signatures over Fully-Dynamic Data Streams with Recovery</title>
      <link>https://arxiv.org/abs/2407.21614</link>
      <description>arXiv:2407.21614v2 Announce Type: replace 
Abstract: We consider the task of performing Jaccard similarity queries over a large collection of items that are dynamically updated according to a streaming input model. An item here is a subset of a large universe $U$ of elements. A well-studied approach to address this important problem in data mining is to design fast-similarity data sketches. In this paper, we focus on global solutions for this problem, i.e., a single data structure which is able to answer both Similarity Estimation and All-Candidate Pairs queries, while also dynamically managing an arbitrary, online sequence of element insertions and deletions received in input.
  We introduce and provide an in-depth analysis of a dynamic, buffered version of the well-known $k$-MinHash sketch. This buffered version better manages critical update operations thus significantly reducing the number of times the sketch needs to be rebuilt from scratch using expensive recovery queries. We prove that the buffered $k$-MinHash uses $O(k \log |U|)$ memory words per subset and that its amortized update time per insertion/deletion is $O(k \log |U|)$ with high probability. Moreover, our data structure can return the $k$-MinHash signature of any subset in $O(k)$ time, and this signature is exactly the same signature that would be computed from scratch (and thus the quality of the signature is the same as the one guaranteed by the static $k$-MinHash).
  Analytical and experimental comparisons with the other, state-of-the-art global solutions for this problem given in [Bury et al.,WSDM'18] show that the buffered $k$-MinHash turns out to be competitive in a wide and relevant range of the online input parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21614v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Andrea Clementi, Luciano Gual\`a, Luca Pep\`e Sciarria, Alessandro Straziota</dc:creator>
    </item>
    <item>
      <title>Distributed Distance Sensitivity Oracles</title>
      <link>https://arxiv.org/abs/2411.13728</link>
      <description>arXiv:2411.13728v2 Announce Type: replace 
Abstract: We present results for the distance sensitivity oracle (DSO) problem, where one needs to preprocess a given directed weighted graph $G=(V,E)$ in order to answer queries about the shortest path distance from $s$ to $t$ in $G$ that avoids edge $e$, for any $s,t \in V, e \in E$. No non-trivial results are known for DSO in the distributed CONGEST model even though it is of importance to maintain efficient communication under an edge failure. We present DSO algorithms with different tradeoffs between preprocessing and query cost -- one that optimizes query response rounds, and another that prioritizes preprocessing rounds. We complement these algorithms with unconditional CONGEST lower bounds. Additionally, we present almost-optimal upper and lower bounds for the related all pairs second simple shortest path (2-APSiSP) problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13728v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vignesh Manoharan, Vijaya Ramachandran</dc:creator>
    </item>
    <item>
      <title>Differentially Private Release of Hierarchical Origin/Destination Data with a TopDown Approach</title>
      <link>https://arxiv.org/abs/2412.09256</link>
      <description>arXiv:2412.09256v2 Announce Type: replace 
Abstract: This paper presents a novel method for generating differentially private tabular datasets for hierarchical data, specifically focusing on origin-destination (O/D) trips. The approach builds upon the TopDown algorithm, a constraint-based mechanism developed by the U.S. Census to incorporate invariant queries into tabular data. O/D hierarchical data refers to datasets representing trips between geographical areas organized in a hierarchical structure (e.g., region $\rightarrow$ province $\rightarrow$ city). The proposed method is designed to improve the accuracy of queries covering broader geographical areas, which are derived through aggregation. This feature provides a "zoom-in" effect on the dataset, ensuring that when zoomed back out, the overall picture is preserved. Furthermore, the approach aims to reduce false positive detection. These characteristics can strengthen practitioners' and decision-makers' confidence in adopting differential privacy datasets. The main technical contribution of this paper includes a novel TopDown algorithm that employs constrained optimization with Chebyshev distance minimization, with theoretical guarantees on the maximum absolute error. Additionally, we propose a new integer optimization algorithm that significantly reduces the incidence of false positives. The effectiveness of the proposed approach is validated using real-world and synthetic O/D datasets, demonstrating its ability to generate private data with high utility and a reduced number of false positives. Our experiments focus on O/D datasets with a single trip as a unit of privacy: nevertheless, the proposed approach supports other units of privacy and also applies to any tabular data with a hierarchical structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09256v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabrizio Boninsegna, Francesco Silvestri</dc:creator>
    </item>
    <item>
      <title>Linear Space Streaming Lower Bounds for Approximating CSPs</title>
      <link>https://arxiv.org/abs/2106.13078</link>
      <description>arXiv:2106.13078v3 Announce Type: replace-cross 
Abstract: We consider the approximability of constraint satisfaction problems in the streaming setting. For every constraint satisfaction problem (CSP) on $n$ variables taking values in $\{0,\ldots,q-1\}$, we prove that improving over the trivial approximability by a factor of $q$ requires $\Omega(n)$ space even on instances with $O(n)$ constraints. We also identify a broad subclass of problems for which any improvement over the trivial approximability requires $\Omega(n)$ space. The key technical core is an optimal, $q^{-(k-1)}$-inapproximability for the Max $k$-LIN-mod $q$ problem, which is the Max CSP problem where every constraint is given by a system of $k-1$ linear equations $\bmod q$ over $k$ variables.
  Our work builds on and extends the breakthrough work of Kapralov and Krachun (Proc. STOC 2019) who showed a linear lower bound on any non-trivial approximation of the MaxCut problem in graphs. MaxCut corresponds roughly to the case of Max $k$-LIN-mod $q$ with ${k=q=2}$. For general CSPs in the streaming setting, prior results only yielded $\Omega(\sqrt{n})$ space bounds. In particular no linear space lower bound was known for an approximation factor less than $1/2$ for any CSP. Extending the work of Kapralov and Krachun to Max $k$-LIN-mod $q$ to $k&gt;2$ and $q&gt;2$ (while getting optimal hardness results) is the main technical contribution of this work. Each one of these extensions provides non-trivial technical challenges that we overcome in this work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2106.13078v3</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chi-Ning Chou, Alexander Golovnev, Madhu Sudan, Ameya Velingker, Santhoshini Velusamy</dc:creator>
    </item>
    <item>
      <title>Online Coalition Formation under Random Arrival or Coalition Dissolution</title>
      <link>https://arxiv.org/abs/2306.16965</link>
      <description>arXiv:2306.16965v2 Announce Type: replace-cross 
Abstract: Coalition formation explores how to partition a set of $n$ agents into disjoint coalitions according to their preferences. We consider a cardinal utility model with an additively separable aggregation of preferences and study the online variant of coalition formation, where the agents arrive in sequence. The goal is to achieve competitive social welfare. In the basic model, agents arrive in an arbitrary order and have to be assigned to coalitions immediately and irrevocably. There, the natural greedy algorithm is known to achieve an optimal competitive ratio, which heavily relies on the range of utilities.
  We complement this result by considering two related models. First, we study a model where agents arrive in a random order. We find that the competitive ratio of the greedy algorithm is $\Theta\left(\frac{1}{n^2}\right)$. In contrast, an alternative algorithm, which is based on alternating between waiting and greedy phases, can achieve a competitive ratio of $\Theta\left(\frac{1}{n}\right)$. Second, we relax the irrevocability of decisions by allowing the dissolution of coalitions into singleton coalitions. We achieve an asymptotically optimal competitive ratio of $\Theta\left(\frac 1n\right)$ by drawing a close connection to a general model of online matching. Hence, in both models, we obtain a competitive ratio that removes the unavoidable utility dependencies in the basic model and essentially matches the best possible approximation ratio by polynomial-time algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.16965v2</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Bullinger, Ren\'e Romen</dc:creator>
    </item>
    <item>
      <title>Quantum Langevin Dynamics for Optimization</title>
      <link>https://arxiv.org/abs/2311.15587</link>
      <description>arXiv:2311.15587v3 Announce Type: replace-cross 
Abstract: We initiate the study of utilizing Quantum Langevin Dynamics (QLD) to solve optimization problems, particularly those non-convex objective functions that present substantial obstacles for traditional gradient descent algorithms. Specifically, we examine the dynamics of a system coupled with an infinite heat bath. This interaction induces both random quantum noise and a deterministic damping effect to the system, which nudge the system towards a steady state that hovers near the global minimum of objective functions. We theoretically prove the convergence of QLD in convex landscapes, demonstrating that the average energy of the system can approach zero in the low temperature limit with an exponential decay rate correlated with the evolution time. Numerically, we first show the energy dissipation capability of QLD by retracing its origins to spontaneous emission. Furthermore, we conduct detailed discussion of the impact of each parameter. Finally, based on the observations when comparing QLD with classical Fokker-Plank-Smoluchowski equation, we propose a time-dependent QLD by making temperature and $\hbar$ time-dependent parameters, which can be theoretically proven to converge better than the time-independent case and also outperforms a series of state-of-the-art quantum and classical optimization algorithms in many non-convex landscapes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.15587v3</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s00220-025-05234-4</arxiv:DOI>
      <arxiv:journal_reference>Communications in Mathematical Physics 406 (2025), 52</arxiv:journal_reference>
      <dc:creator>Zherui Chen, Yuchen Lu, Hao Wang, Yizhou Liu, Tongyang Li</dc:creator>
    </item>
    <item>
      <title>Stability in Online Coalition Formation</title>
      <link>https://arxiv.org/abs/2312.09119</link>
      <description>arXiv:2312.09119v2 Announce Type: replace-cross 
Abstract: Coalition formation is concerned with the question of how to partition a set of agents into disjoint coalitions according to their preferences. Deviating from most of the previous work, we consider an online variant of the problem, where agents arrive in sequence. Whenever an agent arrives, they must be assigned to a coalition immediately and irrevocably. The scarce existing literature on online coalition formation has focused on maximizing social welfare, a demanding requirement, even in the offline setting. Instead, we seek to achieve \emph{stable} coalition structures online and treat the most common stability concepts based on deviations by single agents and groups of agents. We present a comprehensive picture in additively separable hedonic games, leading to dichotomies, where positive results are obtained by deterministic algorithms and negative results even hold for randomized algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.09119v2</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Bullinger, Ren\'e Romen</dc:creator>
    </item>
  </channel>
</rss>
