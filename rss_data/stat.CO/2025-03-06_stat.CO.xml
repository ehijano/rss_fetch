<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 07 Mar 2025 02:55:22 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Diagnosis of Patients with Viral, Bacterial, and Non-Pneumonia Based on Chest X-Ray Images Using Convolutional Neural Networks</title>
      <link>https://arxiv.org/abs/2503.02906</link>
      <description>arXiv:2503.02906v1 Announce Type: cross 
Abstract: According to the World Health Organization (WHO), pneumonia is a disease that causes a significant number of deaths each year. In response to this issue, the development of a decision support system for the classification of patients into those without pneumonia and those with viral or bacterial pneumonia is proposed. This is achieved by implementing transfer learning (TL) using pre-trained convolutional neural network (CNN) models on chest x-ray (CXR) images. The system is further enhanced by integrating Relief and Chi-square methods as dimensionality reduction techniques, along with support vector machines (SVM) for classification. The performance of a series of experiments was evaluated to build a model capable of distinguishing between patients without pneumonia and those with viral or bacterial pneumonia. The obtained results include an accuracy of 91.02%, precision of 97.73%, recall of 98.03%, and an F1 Score of 97.88% for discriminating between patients without pneumonia and those with pneumonia. In addition, accuracy of 93.66%, precision of 94.26%, recall of 92.66%, and an F1 Score of 93.45% were achieved for discriminating between patients with viral pneumonia and those with bacterial pneumonia.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02906v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Carlos Arizmendi, Jorge Pinto, Alejandro Arboleda, Hernando Gonz\'alez</dc:creator>
    </item>
    <item>
      <title>A Novel First-order Method with Event-driven Objective Evaluations</title>
      <link>https://arxiv.org/abs/2503.03526</link>
      <description>arXiv:2503.03526v1 Announce Type: cross 
Abstract: Arising in semi-parametric statistics, control applications, and as sub-problems in global optimization methods, certain optimization problems can have objective functions requiring numerical integration to evaluate, yet gradient function evaluations that are relatively cheap. For such problems, typical optimization methods that require multiple evaluations of the objective for each new iterate become computationally expensive. In light of this, optimization methods that avoid objective function evaluations are attractive, yet we show anti-convergence behavior for these methods on the problem class of interest. To address this gap, we develop a novel gradient algorithm that only evaluates the objective function when specific events are triggered and propose a step size scheme that greedily takes advantage of the properties induced by these triggering events. We prove that our methodology has global convergence guarantees under the most general smoothness conditions, and show through extensive numerical results that our method performs favorably on optimization problems arising in semi-parametric statistics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03526v1</guid>
      <category>math.OC</category>
      <category>stat.CO</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christian Varner, Vivak Patel</dc:creator>
    </item>
    <item>
      <title>Semiparametric Growth-Curve Modeling in Hierarchical, Longitudinal Studies</title>
      <link>https://arxiv.org/abs/2503.03550</link>
      <description>arXiv:2503.03550v2 Announce Type: cross 
Abstract: Modeling of growth (or decay) curves arises in many fields such as microbiology, epidemiology, marketing, and econometrics. Parametric forms like Logistic and Gompertz are often used for modeling such monotonic patterns. While useful for compact description, the real-life growth curves rarely follow these parametric forms perfectly. Therefore, the curve estimation methods that strike a balance between prior information in the parametric form and fidelity with the observed data are preferred. In hierarchical, longitudinal studies the interest lies in comparing the growth curves of different groups while accounting for the differences between the within-group subjects. This article describes a flexible state space modeling framework that enables semiparametric growth curve modeling for the data generated from hierarchical, longitudinal studies. The methodology, a type of functional mixed effects modeling, is illustrated with a real-life example of bacterial growth in different settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03550v2</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rajesh Selukar</dc:creator>
    </item>
    <item>
      <title>Chopin: An Open Source R-language Tool to Support Spatial Analysis on Parallelizable Infrastructure</title>
      <link>https://arxiv.org/abs/2412.11355</link>
      <description>arXiv:2412.11355v2 Announce Type: replace-cross 
Abstract: An increasing volume of studies utilize geocomputation methods in large spatial data. There is a bottleneck in scalable computation for general scientific use as the existing solutions require high-performance computing domain knowledge and are tailored for specific use cases. This study presents an R package `chopin` to reduce the technical burden for parallelization in geocomputation. Supporting popular spatial analysis packages in R, `chopin` leverages parallel computing by partitioning data that are involved in a computation task. The partitioning is implemented at regular grids, data hierarchies, and multiple file inputs with flexible input types for interoperability between different packages and efficiency. This approach makes the geospatial covariate calculation to the scale of the available processing power in a wide range of computing assets from laptop computers to high-performance computing infrastructure. Testing use cases in environmental exposure assessment demonstrated that the package reduced the execution time by order of processing units used. The work is expected to provide broader research communities using geospatial data with an efficient tool to process large scale data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11355v2</guid>
      <category>cs.DC</category>
      <category>cs.PF</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Insang Song, Kyle P. Messier</dc:creator>
    </item>
    <item>
      <title>Cohering Disaggregation and Uncertainty Quantification for Spatially Misaligned Data</title>
      <link>https://arxiv.org/abs/2502.10584</link>
      <description>arXiv:2502.10584v2 Announce Type: replace-cross 
Abstract: Spatial misalignment problems arise from both data aggregation and attempts to align misaligned data, leading to information loss. We propose a Bayesian disaggregation framework that links misaligned data to a continuous domain model using an iteratively linearised integration method via integrated nested Laplace approximation (INLA). The framework supports point pattern and aggregated count models under four covariate field scenarios: \textit{Raster at Full Resolution (RastFull), Raster Aggregation (RastAgg), Polygon Aggregation (PolyAgg), and Point Values (PointVal)}. The first three involve aggregation, while the latter two have incomplete fields. For PolyAgg and PointVal, we estimate the full covariate field using \textit{Value Plugin, Joint Uncertainty, and Uncertainty Plugin} methods, with the latter two accounting for uncertainty propagation. These methods demonstrate superior performance, and remain more robust even under model misspecification (i.e.\ modelling a nonlinear field as linear).
  In landslide studies, landslide occurrences are often aggregated into counts based on slope units, reducing spatial detail. The results indicate that point pattern observations and full-resolution covariate fields should be prioritized. For incomplete fields, methods incorporating uncertainty propagation are preferred. This framework supports landslide susceptibility and other spatial mapping, integrating seamlessly with INLA-extension packages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10584v2</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Man Ho Suen, Mark Naylor, Finn Lindgren</dc:creator>
    </item>
    <item>
      <title>Generative Adversarial Networks for High-Dimensional Item Factor Analysis: A Deep Adversarial Learning Algorithm</title>
      <link>https://arxiv.org/abs/2502.10650</link>
      <description>arXiv:2502.10650v2 Announce Type: replace-cross 
Abstract: Advances in deep learning and representation learning have transformed item factor analysis (IFA) in the item response theory (IRT) literature by enabling more efficient and accurate parameter estimation. Variational Autoencoders (VAEs) have been one of the most impactful techniques in modeling high-dimensional latent variables in this context. However, the limited expressiveness of the inference model based on traditional VAEs can still hinder the estimation performance. We introduce Adversarial Variational Bayes (AVB) algorithms as an improvement to VAEs for IFA with improved flexibility and accuracy. By bridging the strengths of VAEs and Generative Adversarial Networks (GANs), AVB incorporates an auxiliary discriminator network to reframe the estimation process as a two-player adversarial game and removes the restrictive assumption of standard normal distributions in the inference model. Theoretically, AVB can achieve similar or higher likelihood compared to VAEs. A further enhanced algorithm, Importance-weighted Adversarial Variational Bayes (IWAVB) is proposed and compared with Importance-weighted Autoencoders (IWAE). In an exploratory analysis of empirical data, IWAVB demonstrated superior expressiveness by achieving a higher likelihood compared to IWAE. In confirmatory analysis with simulated data, IWAVB achieved similar mean-square error results to IWAE while consistently achieving higher likelihoods. When latent variables followed a multimodal distribution, IWAVB outperformed IWAE. With its innovative use of GANs, IWAVB is shown to have the potential to extend IFA to handle large-scale data, facilitating the potential integration of psychometrics and multimodal data analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10650v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nanyu Luo, Feng Ji</dc:creator>
    </item>
    <item>
      <title>A Framework to Analyze Multiscale Sampling MCMC Methods</title>
      <link>https://arxiv.org/abs/2503.00251</link>
      <description>arXiv:2503.00251v2 Announce Type: replace-cross 
Abstract: We consider the theoretical analysis of Multiscale Sampling Methods, which are a new class of gradient-free Markov chain Monte Carlo (MCMC) methods for high dimensional inverse differential equation problems. A detailed presentation of those methods is given, including a review of each MCMC technique that they employ. Then, we propose a two-part framework to study and compare those methods. The first part identifies the new corresponding state space for the chain of random fields, and the second assesses convergence conditions on the instrumental and target distributions. Three Multiscale Sampling Methods are then analyzed using this new framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00251v2</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Lucas Seiffert, Felipe Pereira</dc:creator>
    </item>
  </channel>
</rss>
