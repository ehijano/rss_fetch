<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 20 Feb 2026 02:33:46 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Theoretical Approach to Stablecoin Design via Price Windows</title>
      <link>https://arxiv.org/abs/2602.15981</link>
      <description>arXiv:2602.15981v1 Announce Type: new 
Abstract: In this paper, we explore the short- and long-term stability of backed stablecoins offering constant mint and redeem prices to all agents. We refer to such designs as price window-based, since the mint and redeem prices constrain the stablecoin's market equilibrium. We show that, without secondary stabilization mechanisms, price window designs cannot achieve both short- and long-term stability unless they are backed by already-stable reserves. In particular, the mechanism faces a tradeoff: either risk eventual reserve depletion through persistent arbitrage by a speculator, or widen the distance between mint and redeem prices enough to disincentivize arbitrage. In the latter case, however, the market price of the stablecoin inherits the volatility of its backing asset, with fluctuations that can be proportional to the backing asset's own volatility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15981v1</guid>
      <category>cs.GT</category>
      <category>cs.CR</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Katherine Molinet, Aris Filos-Ratsikas</dc:creator>
    </item>
    <item>
      <title>Convergence rates of random-order best-response dynamics in public good games on networks</title>
      <link>https://arxiv.org/abs/2602.15986</link>
      <description>arXiv:2602.15986v1 Announce Type: new 
Abstract: We study convergence rates of random-order best-response dynamics in games on networks with linear best responses and strategic substitutes. Combining formal analysis with numerical simulations we identify phenomena that lead to slow convergence. One of the key such phenomena is convergence to stable strategy profiles in parts of the network neighboring sets of nodes which remain inactive until the dynamics is close to converging and then switch to activity, initiating convergence to profiles with a new set of active agents and possibly leading to another iteration of such behavior. We identify structural properties of graphs which make such phenomena more likely. These properties go beyond the spectrum of a graph, which we demonstrate analyzing convergence rates on co-spectral mates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15986v1</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wojciech Misiak, Marcin Dziubi\'nski</dc:creator>
    </item>
    <item>
      <title>Nash-convergence of Game Dynamics and Complexity</title>
      <link>https://arxiv.org/abs/2602.16016</link>
      <description>arXiv:2602.16016v1 Announce Type: new 
Abstract: Does the failure of learning dynamics to converge globally to Nash equilibria stem from the geometry of the game or the complexity of computation? Previous impossibility results relied on game degeneracy, leaving open the case for generic, nondegenerate games. We resolve this by proving that while Nash-convergent dynamics theoretically exist for all nondegenerate games, computing them is likely intractable. We formulate the Impossibility Conjecture: if a locally efficient Nash-convergent dynamic exists for nondegenerate games, then $P=PPAD$. We validate this for three specific families of dynamics, showing their tractability would imply collapses such as $NP=RP$ or $CLS=PPAD$. En route, we settle the complexity of finding Nash equilibria of a given game that lie on a given affine subspace. Finally, we explain why the general conjecture remains open: we introduce a Proving Game to demonstrate that black-box reductions cannot distinguish between convergent and non-convergent dynamics in polynomial time. Our results suggest the barrier to Nash learning is not the non-existence of a vector field, but the intractability of computing it.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16016v1</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Oliver Biggar, Christos Papadimitriou, Georgios Piliouras</dc:creator>
    </item>
    <item>
      <title>Multi-Agent Combinatorial-Multi-Armed-Bandit framework for the Submodular Welfare Problem under Bandit Feedback</title>
      <link>https://arxiv.org/abs/2602.16183</link>
      <description>arXiv:2602.16183v1 Announce Type: new 
Abstract: We study the \emph{Submodular Welfare Problem} (SWP), where items are partitioned among agents with monotone submodular utilities to maximize the total welfare under \emph{bandit feedback}. Classical SWP assumes full value-oracle access, achieving $(1-1/e)$ approximations via continuous-greedy algorithms. We extend this to a \emph{multi-agent combinatorial bandit} framework (\textsc{MA-CMAB}), where actions are partitions under full-bandit feedback with non-communicating agents. Unlike prior single-agent or separable multi-agent CMAB models, our setting couples agents through shared allocation constraints. We propose an explore-then-commit strategy with randomized assignments, achieving $\tilde{\mathcal{O}}(T^{2/3})$ regret against a $(1-1/e)$ benchmark, the first such guarantee for partition-based submodular welfare problem under bandit feedback.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16183v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Subham Pokhriyal, Shweta Jain, Vaneet Aggarwal</dc:creator>
    </item>
    <item>
      <title>Modeling Trust and Liquidity Under Payment System Stress: A Multi-Agent Approach</title>
      <link>https://arxiv.org/abs/2602.16186</link>
      <description>arXiv:2602.16186v1 Announce Type: new 
Abstract: Operational disruptions in retail payments can induce behavioral responses that outlast technical recovery and may amplify liquidity stress. We propose a multi-agent model linking card payment outages to trust dynamics, channel avoidance, and threshold-gated withdrawals. Customers and merchants interact through repeated payment attempts, while customers additionally influence one another on a Watts-Strogatz small-world network. Customers update bounded memory variables capturing accumulated negative experience (scar) and perceived systemic risk (rumor), with merchants contributing persistent broadcast signals that may lag operational recovery. We prove that, under mild conditions on memory persistence and threshold gating, aggregate withdrawal pressure can peak strictly after the outage nadir, including during the recovery phase. Simulations reproduce behavioral hysteresis and confirm delayed peaks of outflows. We further study payment substitution via instant transfer: substitution consistently reduces peak avoidance, yet its effect on cumulative outflows is non-monotonic under realistic merchant broadcast persistence. Robustness experiments across random seeds show stable qualitative behavior. The model highlights why "status green" is not equivalent to risk resolution and motivates incident response strategies that address perception, merchant messaging, and post-recovery communication in addition to technical remediation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16186v1</guid>
      <category>cs.GT</category>
      <category>cs.CE</category>
      <category>cs.MA</category>
      <category>cs.SI</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Masoud Amouzgar</dc:creator>
    </item>
    <item>
      <title>Temporal Panel Selection in Ongoing Citizens' Assemblies</title>
      <link>https://arxiv.org/abs/2602.16194</link>
      <description>arXiv:2602.16194v1 Announce Type: new 
Abstract: Permanent citizens' assemblies are ongoing deliberative bodies composed of randomly selected citizens, organized into panels that rotate over time. Unlike one-off panels, which represent the population in a single snapshot, permanent assemblies enable shifting participation across multiple rounds. This structure offers a powerful framework for ensuring that different groups of individuals are represented over time across successive panels. In particular, it allows smaller groups of individuals that may not warrant representation in every individual panel to be represented across a sequence of them. We formalize this temporal sortition framework by requiring proportional representation both within each individual panel and across the sequence of panels.
  Building on the work of Ebadian and Micha (2025), we consider a setting in which the population lies in a metric space, and the goal is to achieve both proportional representation, ensuring that every group of citizens receives adequate representation, and individual fairness, ensuring that each individual has an equal probability of being selected. We extend the notion of representation to a temporal setting by requiring that every initial segment of the panel sequence, viewed as a cumulative whole, proportionally reflects the structure of the population. We present algorithms that provide varying guarantees of proportional representation, both within individual panels and across any sequence of panels, while also maintaining individual fairness over time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16194v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yusuf Hakan Kalayci, Evi Micha</dc:creator>
    </item>
    <item>
      <title>Computing Equilibria in Games with Stochastic Action Sets</title>
      <link>https://arxiv.org/abs/2602.16234</link>
      <description>arXiv:2602.16234v1 Announce Type: new 
Abstract: The study of learning in games typically assumes that each player always has access to all of their actions. However, in many practical scenarios, arbitrary restrictions induced by exogenous stochasticity might be placed on a player's action set. To model this setting, for a game $\mathcal{G}_{\mathrm{orig}}$ with action set $A_i$ for each player $i$, we introduce the corresponding Game with Stochastic Action Sets (GSAS) which is parametrized by a probability distribution over the players' set of possible action subsets $\mathcal{S}_i \subseteq 2^{\vert A_i\vert}\backslash\{\varnothing\}$. In a GSAS, players' strategies and Nash equilibria (NE) admit prohibitively large representations, thus existing algorithms for NE computation scale poorly. Under the assumption that action availabilities are independent between players, we show that NE in two-player zero-sum (2p0s) GSAS can be compactly represented by a vector of size $\vert A_i\vert$, overcoming naive exponential sized representation of equilibria. Computationally, we introduce an efficient approach based on sleeping internal regret minimization and show that it converges to approximate NE in 2p0s-GSAS at a rate $O(\sqrt{\log\vert A_i\vert/T})$ with appropriate choice of stepsizes, avoiding the exponential blow-up of game-dependent constants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16234v1</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas Schwarz, Ryann Sim, Chun Kai Ling</dc:creator>
    </item>
    <item>
      <title>Condorcet Dimension and Pareto Optimality for Matchings and Beyond</title>
      <link>https://arxiv.org/abs/2602.16289</link>
      <description>arXiv:2602.16289v1 Announce Type: new 
Abstract: We study matching problems in which agents form one side of a bipartite graph and have preferences over objects on the other side. A central solution concept in this setting is popularity: a matching is popular if it is a (weak) Condorcet winner, meaning that no other matching is preferred by a strict majority of agents. It is well known, however, that Condorcet winners need not exist. We therefore turn to a natural and prominent relaxation. A set of matchings is a Condorcet-winning set if, for every competing matching, a majority of agents prefers their favorite matching in the set over the competitor. The Condorcet dimension is the smallest cardinality of a Condorcet-winning set.
  Our main results reveal a connection between Condorcet-winning sets and Pareto optimality. We show that any Pareto-optimal set of two matchings is, in particular, a Condorcet-winning set. This implication continues to hold when we impose matroid constraints on the set of matched objects, and even when agents' valuations are given as partial orders. The existence picture, however, changes sharply with partial orders. While for weak orders a Pareto-optimal set of two matchings always exists, this is -- surprisingly -- not the case under partial orders. Consequently, although the Condorcet dimension for matchings is 2 under weak orders (even under matroid constraints), this guarantee fails for partial orders: we prove that the Condorcet dimension is $\Theta(\sqrt{n})$, and rises further to $\Theta(n)$ when matroid constraints are added. On the computational side, we show that, under partial orders, deciding whether there exists a Condorcet -- winning set of a given fixed size is NP-hard. The same holds for deciding the existence of a Pareto-optimal matching, which we believe to be of independent interest. Finally, we also show that the Condorcet dimension for a related problem on arborescences is also 2.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16289v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Telikepalli Kavitha, Jannik Matuschke, Ulrike Schmidt-Kraepelin</dc:creator>
    </item>
    <item>
      <title>A Theory of Network Games Part 1: Utility Representations</title>
      <link>https://arxiv.org/abs/2602.16071</link>
      <description>arXiv:2602.16071v2 Announce Type: cross 
Abstract: We demonstrate that a ubiquitous feature of network games, bilateral strategic interactions, is equivalent to having player utilities that are additively separable across opponents. We distinguish two formal notions of bilateral strategic interactions. Opponent independence means that player i's preferences over opponent j's action do not depend on what other opponents do. Strategic independence means that how opponent j's choice influences i's preference between any two actions does not depend on what other opponents do. If i's preferences jointly satisfy both conditions, then we can represent her preferences over strategy profiles using an additively separable utility. If i's preferences satisfy only strategic independence, then we can still represent her preferences over just her own actions using an additively separable utility. Common utilities based on a linear aggregate of opponent actions satisfy strategic independence and are therefore strategically equivalent to additively separable utilities--in fact, we can assume a utility that is linear in opponent actions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16071v2</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joseph Root, Evan Sadler</dc:creator>
    </item>
    <item>
      <title>Computing Tarski Fixed Points in Financial Networks</title>
      <link>https://arxiv.org/abs/2602.16387</link>
      <description>arXiv:2602.16387v1 Announce Type: cross 
Abstract: Modern financial networks are highly connected and result in complex interdependencies of the involved institutions. In the prominent Eisenberg-Noe model, a fundamental aspect is clearing -- to determine the amount of assets available to each financial institution in the presence of potential defaults and bankruptcy. A clearing state represents a fixed point that satisfies a set of natural axioms. Existence can be established (even in broad generalizations of the model) using Tarski's theorem.
  While a maximal fixed point can be computed in polynomial time, the complexity of computing other fixed points is open. In this paper, we provide an efficient algorithm to compute a minimal fixed point that runs in strongly polynomial time. It applies in a broad generalization of the Eisenberg-Noe model with any monotone, piecewise-linear payment functions and default costs. Moreover, in this scenario we provide a polynomial-time algorithm to compute a maximal fixed point. For networks without default costs, we can efficiently decide the existence of fixed points in a given range.
  We also study claims trading, a local network adjustment to improve clearing, when networks are evaluated with minimal clearing. We provide an efficient algorithm to decide existence of Pareto-improving trades and compute optimal ones if they exist.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16387v1</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <category>q-fin.RM</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leander Besting, Martin Hoefer, Lars Huth</dc:creator>
    </item>
    <item>
      <title>Strategic Hiring under Algorithmic Monoculture</title>
      <link>https://arxiv.org/abs/2502.20063</link>
      <description>arXiv:2502.20063v2 Announce Type: replace 
Abstract: We study the impact of strategic behavior in labor markets characterized by algorithmic monoculture, where firms compete for a shared pool of applicants using a common algorithmic evaluation. In this setting, "naive" hiring strategies lead to severe congestion, as firms collectively target the same high-scoring candidates. We model this competition as a game with capacity-constrained firms and fully characterize the set of Nash equilibria. We demonstrate that equilibrium strategies, which naturally diversify firms' interview targets, significantly outperform naive selection, increasing social welfare for both firms and applicants. Specifically, the Price of Naive Selection (welfare gain from strategy) grows linearly with the number of firms, while the Price of Anarchy (efficiency loss from decentralization) approaches 1, implying that the decentralized equilibrium is nearly socially optimal. Finally, we analyze convergence, and we show that a simple sequential best-response process converges to the desired equilibrium. However, we show that firms generally cannot infer the key input needed to compute best responses, namely congestion for specific candidates, from their own historical data alone. Consequently, to realize the welfare gains of strategic differentiation, algorithmic platforms must explicitly reveal congestion information to participating firms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20063v2</guid>
      <category>cs.GT</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jackie Baek, Hamsa Bastani, Shihan Chen</dc:creator>
    </item>
    <item>
      <title>Stability in Distance Preservation Games on Graphs</title>
      <link>https://arxiv.org/abs/2602.15784</link>
      <description>arXiv:2602.15784v2 Announce Type: replace 
Abstract: We introduce a new class of network allocation games called graphical distance preservation games. Here, we are given a graph, called a topology, and a set of agents that need to be allocated to its vertices. Moreover, every agent has an ideal (and possibly different) distance in which to be from some of the other agents. Given an allocation of agents, each one of them suffers a cost that is the sum of the differences from the ideal distance for each agent in their subset. The goal is to decide whether there is a stable allocation of the agents, i.e., no agent would like to deviate from their location. Specifically, we consider three different stability notions: envy-freeness, swap stability, and jump stability. We perform a comprehensive study of the (parameterized) complexity of the problem in three different dimensions: the topology of the graph, the number of agents, and the structure of preferences of the agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15784v2</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Argyrios Deligkas, Eduard Eiben, Tiger-Lily Goldsmith, Du\v{s}an Knop, \v{S}imon Schierreich</dc:creator>
    </item>
    <item>
      <title>EconEvals: Benchmarks and Litmus Tests for Economic Decision-Making by LLM Agents</title>
      <link>https://arxiv.org/abs/2503.18825</link>
      <description>arXiv:2503.18825v4 Announce Type: replace-cross 
Abstract: We develop evaluation methods for measuring the economic decision-making capabilities and tendencies of LLMs. First, we develop benchmarks derived from key problems in economics -- procurement, scheduling, and pricing -- that test an LLM's ability to learn from the environment in context. Second, we develop the framework of litmus tests, evaluations that quantify an LLM's choice behavior on a stylized decision-making task with multiple conflicting objectives. Each litmus test outputs a litmus score, which quantifies an LLM's tradeoff response, a reliability score, which measures the coherence of an LLM's choice behavior, and a competency score, which measures an LLM's capability at the same task when the conflicting objectives are replaced by a single, well-specified objective. Evaluating a broad array of frontier LLMs, we (1) investigate changes in LLM capabilities and tendencies over time, (2) derive economically meaningful insights from the LLMs' choice behavior and chain-of-thought, (3) validate our litmus test framework by testing self-consistency, robustness, and generalizability. Overall, this work provides a foundation for evaluating LLM agents as they are further integrated into economic decision-making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18825v4</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.GT</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sara Fish, Julia Shephard, Minkai Li, Ran I. Shorrer, Yannai A. Gonczarowski</dc:creator>
    </item>
  </channel>
</rss>
