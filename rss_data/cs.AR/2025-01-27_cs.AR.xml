<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.AR updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.AR</link>
    <description>cs.AR updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.AR" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 28 Jan 2025 03:45:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Dual Dielectric Metasurface for Simultaneous Sensing and Reconfigurable Reflections</title>
      <link>https://arxiv.org/abs/2501.14042</link>
      <description>arXiv:2501.14042v1 Announce Type: new 
Abstract: This paper presents a novel dual-functional hybrid Reconfigurable Intelligent Surface (RIS) for simultaneous sensing and reconfigurable reflections. We design a novel hybrid unit cell featuring dual elements, which share the same phase center, to support both intended functionalities, with the antenna being miniaturized via a high dielectric material approach. The hybrid unit cell has a size of one eighth of the wavelength forming the foundation of an innovative metasurface that incorporates a sub-wavelength reflecting array of split-ring unit cells integrated with a load-tuning matrix. In particular, two interleaved sensing arrays of half-wavelength spacing, orthogonal polarization, and quarter-wavelength offset are embedded within the proposed dual-functional RIS, each tasked to sense the channel parameters towards one of the end communication nodes wishing to profit from the surface's reconfigurable reflections. Our full-wave simulations, indicatively centered around the frequency of $5.5$ GHz, showcase the promising performance of both designed hybrid unit cells and reflective split-ring ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14042v1</guid>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mahesh Birari, Deepak Singh Nagarkoti, Anestis Katsounaros, Hruday Kumar Reddy Mudireddy, Jagannath Malik, George C. Alexandropoulos</dc:creator>
    </item>
    <item>
      <title>TCDM Burst Access: Breaking the Bandwidth Barrier in Shared-L1 RVV Clusters Beyond 1000 FPUs</title>
      <link>https://arxiv.org/abs/2501.14370</link>
      <description>arXiv:2501.14370v1 Announce Type: new 
Abstract: As computing demand and memory footprint of deep learning applications accelerate, clusters of cores sharing local (L1) multi-banked memory are widely used as key building blocks in large-scale architectures. When the cluster's core count increases, a flat all-to-all interconnect between cores and L1 memory banks becomes a physical implementation bottleneck, and hierarchical network topologies are required. However, hierarchical, multi-level intra-cluster networks are subject to internal contention which may lead to significant performance degradation, especially for SIMD or vector cores, as their memory access is bursty. We present the TCDM Burst Access architecture, a software-transparent burst transaction support to improve bandwidth utilization in clusters with many vector cores tightly coupled to a multi-banked L1 data memory. In our solution, a Burst Manager dispatches burst requests to L1 memory banks, multiple 32b words from burst responses are retired in parallel on channels with parametric data-width. We validate our design on a RISC-V Vector (RVV) many-core cluster, evaluating the benefits on different core counts. With minimal logic area overhead (less than 8%), we improve the bandwidth of a 16-, a 256-, and a 1024--Floating Point Unit (FPU) baseline clusters, without Tightly Coupled Data Memory (TCDM) Burst Access, by 118%, 226%, and 77% respectively. Reaching up to 80% of the cores-memory peak bandwidth, our design demonstrates ultra-high bandwidth utilization and enables efficient performance scaling. Implemented in 12-nm FinFET technology node, compared to the serialized access baseline, our solution achieves up to 1.9x energy efficiency and 2.76x performance in real-world kernel benchmarkings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14370v1</guid>
      <category>cs.AR</category>
      <category>cs.DC</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Diyou Shen, Yichao Zhang, Marco Bertuletti, Luca Benini</dc:creator>
    </item>
    <item>
      <title>Dynamic Loop Fusion in High-Level Synthesis</title>
      <link>https://arxiv.org/abs/2501.14631</link>
      <description>arXiv:2501.14631v1 Announce Type: new 
Abstract: Dynamic High-Level Synthesis (HLS) uses additional hardware to perform memory disambiguation at runtime, increasing loop throughput in irregular codes compared to static HLS. However, most irregular codes consist of multiple sibling loops, which currently have to be executed sequentially by all HLS tools. Static HLS performs loop fusion only on regular codes, while dynamic HLS relies on loops with dependencies to run to completion before the next loop starts.
  We present dynamic loop fusion for HLS, a compiler/hardware co-design approach that enables multiple loops to run in parallel, even if they contain unpredictable memory dependencies. Our only requirement is that memory addresses are monotonically non-decreasing in inner loops. We present a novel program-order schedule for HLS, inspired by polyhedral compilers, that together with our address monotonicity analysis enables dynamic memory disambiguation that does not require searching of address histories and sequential loop execution. Our evaluation shows an average speedup of 14$\times$ over static and 4$\times$ over dynamic HLS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14631v1</guid>
      <category>cs.AR</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3706628.3708871</arxiv:DOI>
      <dc:creator>Robert Szafarczyk, Syed Waqar Nabi, Wim Vanderbauwhede</dc:creator>
    </item>
    <item>
      <title>Adaptive Genetic Algorithms for Pulse-Level Quantum Error Mitigation</title>
      <link>https://arxiv.org/abs/2501.14007</link>
      <description>arXiv:2501.14007v1 Announce Type: cross 
Abstract: Noise remains a fundamental challenge in quantum computing, significantly affecting pulse fidelity and overall circuit performance. This paper introduces an adaptive algorithm for pulse-level quantum error mitigation, designed to enhance fidelity by dynamically responding to noise conditions without modifying circuit gates. By targeting pulse parameters directly, this method reduces the impact of various noise sources, improving algorithm resilience in quantum circuits. We show the latter by applying our protocol to Grover's and Deutsch-Jozsa algorithms. Experimental results show that this pulse-level strategy provides a flexible and efficient solution for increasing fidelity during the noisy execution of quantum circuits. Our work contributes to advancements in error mitigation techniques, essential for robust quantum computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14007v1</guid>
      <category>quant-ph</category>
      <category>cs.AI</category>
      <category>cs.AR</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>William Aguilar-Calvo, Santiago N\'u\~nez-Corrales</dc:creator>
    </item>
    <item>
      <title>Analysis of heralded higher-fidelity two-qubit entangling gates with self-correction</title>
      <link>https://arxiv.org/abs/2501.14220</link>
      <description>arXiv:2501.14220v1 Announce Type: cross 
Abstract: For the quantum error correction (QEC) and noisy intermediate-scale quantum (NISQ) algorithms to function with high efficiency, the raw fidelity of quantum logic gates on physical qubits needs to satisfy strict requirement. The neutral atom quantum computing equipped with Rydberg blockade gates has made impressive progress recently, which makes it worthwhile to explore its potential in the two-qubit entangling gates, including Controlled-PHASE gate and in particular the CZ gate. Provided the quantum coherence is well preserved, improving the fidelity of Rydberg blockade gates calls for special mechanisms to deal with adverse effects caused by realistic experimental conditions. Here the heralded very-high-fidelity Rydberg blockade Controlled-PHASE gate is designed to address these issues, which contains self-correction and projection as the key steps. This trailblazing method can be built on the basis of the previously established buffer-atom-mediated gate, and a special form of symmetry under PT transformation plays a crucial role in the process. We further analyze the performance with respect to a few typical sources of imperfections. This procedure can also be regarded as quantum hardware error correction or mitigation. While this paper by itself does not cover every single subtle issue and still contains many over-simplifications, we find it reasonable to anticipate very-high-fidelity two-qubit quantum logic gate operated in the sense of heralded but probabilistic, whose gate error can reduce to the level of $10^{-4}$--$10^{-6}$ or even lower with reasonably high possibilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14220v1</guid>
      <category>quant-ph</category>
      <category>cs.AR</category>
      <category>physics.atom-ph</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuan Sun</dc:creator>
    </item>
    <item>
      <title>Securing DRAM at Scale: ARFM-Driven Row Hammer Defense with Unveiling the Threat of Short tRC Patterns</title>
      <link>https://arxiv.org/abs/2501.14328</link>
      <description>arXiv:2501.14328v1 Announce Type: cross 
Abstract: To address the issue of powerful row hammer (RH) attacks, our study involved an extensive analysis of the prevalent attack patterns in the field. We discovered a strong correlation between the timing and density of the active-to-active command period, ${tRC}$, and the likelihood of RH attacks. In this paper, we introduce MARC, an innovative ARFM-driven RH mitigation IP that significantly reinforces existing RH mitigation IPs. MARC dynamically adjusts the frequency of RFM in response to the severity of the RH attack environment, offering a tailored security solution that not only detects the threats but also adapts to varying threat levels. MARC's detection mechanism has demonstrated remarkable efficiency, identifying over 99\% of attack patterns. Moreover, MARC is designed as a compact hardware module, facilitating tight integration either on the memory controller-side or DRAM-side within the memory system. It only occupies a negligible hardware area of 3363~\textit{$\mu m^2$}. By activating ARFM based on MARC's detection, the additional energy overhead is also negligible in normal workloads. We conduct experiments to compare the highest row count throughout the patterns, defined as max exposure, between the vanilla RH mitigation IPs and the MARC-enhanced versions of the same IPs, focusing on both DRAM-side and memory controller-side. On the DRAM-side, MARC + probabilistic scheme and MARC + counter-based tracking scheme achieve 8.1$\times$ and 1.5$\times$ improvement in max exposure ratio compared to the vanilla IPs, respectively. On the memory controller-side, the MARC + PARA and MARC + Graphene achieve 50$\times$ and 5.7$\times$ improvement in max exposure ratio compared to the vanilla IPs, respectively. MARC ensures optimal security without sacrificing system performance, making MARC a pioneering solution in the realm of RH attack mitigation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14328v1</guid>
      <category>cs.CR</category>
      <category>cs.AR</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nogeun Joo, Donghyuk Kim, Hyunjun Cho, Junseok Noh, Dongha Jung, Joo-Young Kim</dc:creator>
    </item>
    <item>
      <title>BILLNET: A Binarized Conv3D-LSTM Network with Logic-gated residual architecture for hardware-efficient video inference</title>
      <link>https://arxiv.org/abs/2501.14495</link>
      <description>arXiv:2501.14495v1 Announce Type: cross 
Abstract: Long Short-Term Memory (LSTM) and 3D convolution (Conv3D) show impressive results for many video-based applications but require large memory and intensive computing. Motivated by recent works on hardware-algorithmic co-design towards efficient inference, we propose a compact binarized Conv3D-LSTM model architecture called BILLNET, compatible with a highly resource-constrained hardware. Firstly, BILLNET proposes to factorize the costly standard Conv3D by two pointwise convolutions with a grouped convolution in-between. Secondly, BILLNET enables binarized weights and activations via a MUX-OR-gated residual architecture. Finally, to efficiently train BILLNET, we propose a multi-stage training strategy enabling to fully quantize LSTM layers. Results on Jester dataset show that our method can obtain high accuracy with extremely low memory and computational budgets compared to existing Conv3D resource-efficient models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14495v1</guid>
      <category>cs.CV</category>
      <category>cs.AR</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/SiPS55645.2022.9919206</arxiv:DOI>
      <arxiv:journal_reference>2022 IEEE Workshop on Signal Processing Systems (SiPS), Rennes, France, 2022, pp. 1-6</arxiv:journal_reference>
      <dc:creator>Van Thien Nguyen, William Guicquero, Gilles Sicard</dc:creator>
    </item>
    <item>
      <title>Towards a Cryogenic CMOS-Memristor Neural Decoder for Quantum Error Correction</title>
      <link>https://arxiv.org/abs/2501.14525</link>
      <description>arXiv:2501.14525v1 Announce Type: cross 
Abstract: This paper presents a novel approach utilizing a scalable neural decoder application-specific integrated circuit (ASIC) based on metal oxide memristors in a 180nm CMOS technology. The ASIC architecture employs in-memory computing with memristor crossbars for efficient vector-matrix multiplications (VMM). The ASIC decoder architecture includes an input layer implemented with a VMM and an analog sigmoid activation function, a recurrent layer with analog memory, and an output layer with a VMM and a threshold activation function. Cryogenic characterization of the ASIC is conducted, demonstrating its performance at both room temperature and cryogenic temperatures down to 1.2K. Results indicate stable activation function shapes and pulse responses at cryogenic temperatures. Moreover, power consumption measurements reveal consistent behavior at room and cryogenic temperatures. Overall, this study lays the foundation for developing efficient and scalable neural decoders for quantum error correction in cryogenic environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14525v1</guid>
      <category>quant-ph</category>
      <category>cs.AR</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/QCE60285.2024.00149</arxiv:DOI>
      <arxiv:journal_reference>2024 IEEE International Conference on Quantum Computing and Engineering (QCE)</arxiv:journal_reference>
      <dc:creator>Pierre-Antoine Mouny, Maher Benhouria, Victor Yon, Patrick Dufour, Linxiang Huang, Yann Beilliard, Sophie Rochette, Dominique Drouin, Pooya Ronagh</dc:creator>
    </item>
    <item>
      <title>Shavette: Low Power Neural Network Acceleration via Algorithm-level Error Detection and Undervolting</title>
      <link>https://arxiv.org/abs/2410.13415</link>
      <description>arXiv:2410.13415v2 Announce Type: replace 
Abstract: Reduced voltage operation is an effective technique for substantial energy efficiency improvement in digital circuits. This brief introduces a simple approach for enabling reduced voltage operation of Deep Neural Network (DNN) accelerators by mere software modifications. Conventional approaches for enabling reduced voltage operation e.g., Timing Error Detection (TED) systems, incur significant development costs and overheads, while not being applicable to the off-the-shelf components. Contrary to those, the solution proposed in this paper relies on algorithm-based error detection, and hence, is implemented with low development costs, does not require any circuit modifications, and is even applicable to commodity devices. By showcasing the solution through experimenting on popular DNNs, i.e., LeNet and VGG16, on a GPU platform, we demonstrate 18% to 25% energy saving with no accuracy loss of the models and negligible throughput compromise (&lt; 3.9%), considering the overheads from integration of the error detection schemes into the DNN. The integration of presented algorithmic solution into the design is simpler when compared conventional TED based techniques that require extensive circuit-level modifications, cell library characterizations or special support from the design tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13415v2</guid>
      <category>cs.AR</category>
      <category>cs.AI</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mikael Rinkinen, Lauri Koskinen, Olli Silven, Mehdi Safarpour</dc:creator>
    </item>
    <item>
      <title>Multi-Tenant SmartNICs for In-Network Preprocessing of Recommender Systems</title>
      <link>https://arxiv.org/abs/2501.12032</link>
      <description>arXiv:2501.12032v2 Announce Type: replace 
Abstract: Keeping ML-based recommender models up-to-date as data drifts and evolves is essential to maintain accuracy. As a result, online data preprocessing plays an increasingly important role in serving recommender systems. Existing solutions employ multiple CPU workers to saturate the input bandwidth of a single training node. Such an approach results in high deployment costs and energy consumption. For instance, a recent report from industrial deployments shows that data storage and ingestion pipelines can account for over 60\% of the power consumption in a recommender system. In this paper, we tackle the issue from a hardware perspective by introducing Piper, a flexible and network-attached accelerator that executes data loading and preprocessing pipelines in a streaming fashion. As part of the design, we define MiniPipe, the smallest pipeline unit enabling multi-pipeline implementation by executing various data preprocessing tasks across the single board, giving Piper the ability to be reconfigured at runtime. Our results, using publicly released commercial pipelines, show that Piper, prototyped on a power-efficient FPGA, achieves a 39$\sim$105$\times$ speedup over a server-grade, 128-core CPU and 3$\sim$17$\times$ speedup over GPUs like RTX 3090 and A100 in multiple pipelines. The experimental analysis demonstrates that Piper provides advantages in both latency and energy efficiency for preprocessing tasks in recommender systems, providing an alternative design point for systems that today are in very high demand.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12032v2</guid>
      <category>cs.AR</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yu Zhu, Wenqi Jiang, Gustavo Alonso</dc:creator>
    </item>
    <item>
      <title>Design and Implementation of an Efficient Onboard Computer System for CanSat Atmosphere Monitoring</title>
      <link>https://arxiv.org/abs/2308.03496</link>
      <description>arXiv:2308.03496v2 Announce Type: replace-cross 
Abstract: With advancements in technology, the smaller versions of satellites have gained momentum in the space industry for earth monitoring and communication-based applications. The rise of CanSat technology has significantly impacted the space industry by providing a cost-effective solution for space exploration. CanSat is a simulation model of a real satellite and plays a crucial role in collecting and transmitting atmospheric data. This paper discusses the design of an Onboard Computer System forCanSat, used to study various environmental parameters by monitoring the concentrations of gases in the atmosphere. The Onboard Computer System uses GPS, accelerometer, altitude, temperature, pressure, gyroscope, magnetometer, UV radiation, and air quality sensors for atmospheric sensing. A highly efficient and low-power ESP32 microcontroller and a transceiver module are used to acquire data, facilitate seamless communication and transmit the collected data to the ground station.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.03496v2</guid>
      <category>eess.SY</category>
      <category>cs.AR</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abhijit Gadekar</dc:creator>
    </item>
  </channel>
</rss>
