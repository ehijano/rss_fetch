<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.ME updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.ME</link>
    <description>stat.ME updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.ME" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 11 Nov 2024 05:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Misclassification of Vaccination Status in Electronic Health Records: A Bayesian Approach in Cluster Randomized Trials</title>
      <link>https://arxiv.org/abs/2411.05215</link>
      <description>arXiv:2411.05215v1 Announce Type: new 
Abstract: Misclassification in binary outcomes is not uncommon and statistical methods to investigate its impact on policy-driving study results are lacking. While misclassifying binary outcomes is a statistically ubiquitous phenomena, we focus on misclassification in a public health application: vaccinations. One such study design in public health that addresses policy is the cluster controlled randomized trial (CCRT). A CCRT that measures the impact of a novel behavioral intervention on increasing vaccine uptake can be severely biased when the supporting data are incomplete vaccination records. In particular, these vaccine records more often may be prone to negative misclassification, that is, a clinic's record of an individual patient's vaccination status may be unvaccinated when, in reality, this patient was vaccinated outside of the clinic. With large nation-wide endeavors to encourage vaccinations without a gold-standard vaccine record system, sensitivity analyses that incorporate misclassification rates are promising for robust inference. In this work we introduce a novel extension of Bayesian logistic regression where we perturb the clinic size and vaccination count with random draws from expert-elicited prior distributions. These prior distributions represent the misclassification rates for each clinic that stochastically add unvaccinated counts to the observed vaccinated counts. These prior distributions are assigned for each clinic (the first level in a group-level randomized trial). We demonstrate this method with a data application from a CCRT evaluating the influence of a behavioral intervention on vaccination uptake among U.S. veterans. A simulation study is carried out demonstrating its estimation properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05215v1</guid>
      <category>stat.ME</category>
      <pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Adam Kaplan, Collin Calvert, Bridget C. Griffith, Daniel Bertenthal, Natalie Purcell, Karen Seal, Jeffrey M. Pyne, Karen Anderson Oliver, Denise Esserman, David Nelson</dc:creator>
    </item>
    <item>
      <title>Caliper Synthetic Matching: Generalized Radius Matching with Local Synthetic Controls</title>
      <link>https://arxiv.org/abs/2411.05246</link>
      <description>arXiv:2411.05246v1 Announce Type: new 
Abstract: Matching promises transparent causal inferences for observational data, making it an intuitive approach for many applications. In practice, however, standard matching methods often perform poorly compared to modern approaches such as response-surface modeling and optimizing balancing weights. We propose Caliper Synthetic Matching (CSM) to address these challenges while preserving simple and transparent matches and match diagnostics. CSM extends Coarsened Exact Matching by incorporating general distance metrics, adaptive calipers, and locally constructed synthetic controls. We show that CSM can be viewed as a monotonic imbalance bounding matching method, so that it inherits the usual bounds on imbalance and bias enjoyed by MIB methods. We further provide a bound on a measure of joint covariate imbalance. Using a simulation study, we illustrate how CSM can even outperform modern matching methods in certain settings, and finally illustrate its use in an empirical example. Overall, we find CSM allows for many of the benefits of matching while avoiding some of the costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05246v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonathan Che, Xiang Meng, Luke Miratrix</dc:creator>
    </item>
    <item>
      <title>Differentiable Calibration of Inexact Stochastic Simulation Models via Kernel Score Minimization</title>
      <link>https://arxiv.org/abs/2411.05315</link>
      <description>arXiv:2411.05315v1 Announce Type: new 
Abstract: Stochastic simulation models are generative models that mimic complex systems to help with decision-making. The reliability of these models heavily depends on well-calibrated input model parameters. However, in many practical scenarios, only output-level data are available to learn the input model parameters, which is challenging due to the often intractable likelihood of the stochastic simulation model. Moreover, stochastic simulation models are frequently inexact, with discrepancies between the model and the target system. No existing methods can effectively learn and quantify the uncertainties of input parameters using only output-level data. In this paper, we propose to learn differentiable input parameters of stochastic simulation models using output-level data via kernel score minimization with stochastic gradient descent. We quantify the uncertainties of the learned input parameters using a frequentist confidence set procedure based on a new asymptotic normality result that accounts for model inexactness. The proposed method is evaluated on exact and inexact G/G/1 queueing models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05315v1</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziwei Su, Diego Klabjan</dc:creator>
    </item>
    <item>
      <title>SASWISE-UE: Segmentation and Synthesis with Interpretable Scalable Ensembles for Uncertainty Estimation</title>
      <link>https://arxiv.org/abs/2411.05324</link>
      <description>arXiv:2411.05324v1 Announce Type: cross 
Abstract: This paper introduces an efficient sub-model ensemble framework aimed at enhancing the interpretability of medical deep learning models, thus increasing their clinical applicability. By generating uncertainty maps, this framework enables end-users to evaluate the reliability of model outputs. We developed a strategy to develop diverse models from a single well-trained checkpoint, facilitating the training of a model family. This involves producing multiple outputs from a single input, fusing them into a final output, and estimating uncertainty based on output disagreements. Implemented using U-Net and UNETR models for segmentation and synthesis tasks, this approach was tested on CT body segmentation and MR-CT synthesis datasets. It achieved a mean Dice coefficient of 0.814 in segmentation and a Mean Absolute Error of 88.17 HU in synthesis, improved from 89.43 HU by pruning. Additionally, the framework was evaluated under corruption and undersampling, maintaining correlation between uncertainty and error, which highlights its robustness. These results suggest that the proposed approach not only maintains the performance of well-trained models but also enhances interpretability through effective uncertainty estimation, applicable to both convolutional and transformer models in a range of imaging tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05324v1</guid>
      <category>cs.LG</category>
      <category>cs.CV</category>
      <category>stat.ME</category>
      <pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Weijie Chen, Alan McMillan</dc:creator>
    </item>
    <item>
      <title>Increasing power and robustness in screening trials by testing stored specimens in the control arm</title>
      <link>https://arxiv.org/abs/2411.05580</link>
      <description>arXiv:2411.05580v1 Announce Type: cross 
Abstract: Background: Screening trials require large sample sizes and long time-horizons to demonstrate mortality reductions. We recently proposed increasing statistical power by testing stored control-arm specimens, called the Intended Effect (IE) design. To evaluate feasibility of the IE design, the US National Cancer Institute (NCI) is collecting blood specimens in the control-arm of the NCI Vanguard Multicancer Detection pilot feasibility trial. However, key assumptions of the IE design require more investigation and relaxation. Methods: We relax the IE design to (1) reduce costs by testing only a stratified sample of control-arm specimens by incorporating inverse-probability sampling weights, (2) correct for potential loss-of-signal in stored control-arm specimens, and (3) correct for non-compliance with control-arm specimen collections. We also examine sensitivity to unintended effects of screening. Results: In simulations, testing all primary-outcome control-arm specimens and a 50% sample of the rest maintains nearly all the power of the IE while only testing half the control-arm specimens. Power remains increased from the IE analysis (versus the standard analysis) even if unintended effects exist. The IE design is robust to some loss-of-signal scenarios, but otherwise requires retest-positive fractions that correct bias at a small loss of power. The IE can be biased and lose power under control-arm non-compliance scenarios, but corrections correct bias and can increase power. Conclusions: The IE design can be made more cost-efficient and robust to loss-of-signal. Unintended effects will not typically reduce the power gain over the standard trial design. Non-compliance with control-arm specimen collections can cause bias and loss of power that can be mitigated by corrections. Although promising, practical experience with the IE design in screening trials is necessary.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05580v1</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hormuzd A. Katki, Li C. Cheung</dc:creator>
    </item>
    <item>
      <title>Detecting Cointegrating Relations in Non-stationary Matrix-Valued Time Series</title>
      <link>https://arxiv.org/abs/2411.05601</link>
      <description>arXiv:2411.05601v1 Announce Type: cross 
Abstract: This paper proposes a Matrix Error Correction Model to identify cointegration relations in matrix-valued time series. We hereby allow separate cointegrating relations along the rows and columns of the matrix-valued time series and use information criteria to select the cointegration ranks. Through Monte Carlo simulations and a macroeconomic application, we demonstrate that our approach provides a reliable estimation of the number of cointegrating relationships.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05601v1</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alain Hecq, Ivan Ricardo, Ines Wilms</dc:creator>
    </item>
    <item>
      <title>Cross-validating causal discovery via Leave-One-Variable-Out</title>
      <link>https://arxiv.org/abs/2411.05625</link>
      <description>arXiv:2411.05625v1 Announce Type: cross 
Abstract: We propose a new approach to falsify causal discovery algorithms without ground truth, which is based on testing the causal model on a pair of variables that has been dropped when learning the causal model. To this end, we use the "Leave-One-Variable-Out (LOVO)" prediction where $Y$ is inferred from $X$ without any joint observations of $X$ and $Y$, given only training data from $X,Z_1,\dots,Z_k$ and from $Z_1,\dots,Z_k,Y$. We demonstrate that causal models on the two subsets, in the form of Acyclic Directed Mixed Graphs (ADMGs), often entail conclusions on the dependencies between $X$ and $Y$, enabling this type of prediction. The prediction error can then be estimated since the joint distribution $P(X, Y)$ is assumed to be available, and $X$ and $Y$ have only been omitted for the purpose of falsification. After presenting this graphical method, which is applicable to general causal discovery algorithms, we illustrate how to construct a LOVO predictor tailored towards algorithms relying on specific a priori assumptions, such as linear additive noise models. Simulations indicate that the LOVO prediction error is indeed correlated with the accuracy of the causal outputs, affirming the method's effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05625v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniela Schkoda, Philipp Faller, Patrick Bl\"obaum, Dominik Janzing</dc:creator>
    </item>
    <item>
      <title>Pseudo-Labeling for Kernel Ridge Regression under Covariate Shift</title>
      <link>https://arxiv.org/abs/2302.10160</link>
      <description>arXiv:2302.10160v3 Announce Type: replace 
Abstract: We develop and analyze a principled approach to kernel ridge regression under covariate shift. The goal is to learn a regression function with small mean squared error over a target distribution, based on unlabeled data from there and labeled data that may have a different feature distribution. We propose to split the labeled data into two subsets, and conduct kernel ridge regression on them separately to obtain a collection of candidate models and an imputation model. We use the latter to fill the missing labels and then select the best candidate accordingly. Our non-asymptotic excess risk bounds demonstrate that our estimator adapts effectively to both the structure of the target distribution and the covariate shift. This adaptation is quantified through a notion of effective sample size that reflects the value of labeled source data for the target regression task. Our estimator achieves the minimax optimal error rate up to a polylogarithmic factor, and we find that using pseudo-labels for model selection does not significantly hinder performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.10160v3</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaizheng Wang</dc:creator>
    </item>
    <item>
      <title>Hierarchical Regression Discontinuity Design: Pursuing Subgroup Treatment Effects</title>
      <link>https://arxiv.org/abs/2309.01404</link>
      <description>arXiv:2309.01404v3 Announce Type: replace 
Abstract: Regression discontinuity design (RDD) is widely adopted for causal inference under intervention determined by a continuous variable. While one is interested in treatment effect heterogeneity by subgroups in many applications, RDD typically suffers from small subgroup-wise sample sizes, which makes the estimation results highly instable. To solve this issue, we introduce hierarchical RDD (HRDD), a hierarchical Bayes approach for pursuing treatment effect heterogeneity in RDD. A key feature of HRDD is to employ a pseudo-model based on a loss function to estimate subgroup-level parameters of treatment effects under RDD, and assign a hierarchical prior distribution to ''borrow strength'' from other subgroups. The posterior computation can be easily done by a simple Gibbs sampling, and the optimal bandwidth can be automatically selected by the Hyv\"{a}rinen scores for unnormalized models. We demonstrate the proposed HRDD through simulation and real data analysis, and show that HRDD provides much more stable point and interval estimation than separately applying the standard RDD method to each subgroup.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.01404v3</guid>
      <category>stat.ME</category>
      <pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shonosuke Sugasawa, Takuya Ishihara, Daisuke Kurisu</dc:creator>
    </item>
    <item>
      <title>Demystifying Spatial Confounding</title>
      <link>https://arxiv.org/abs/2309.16861</link>
      <description>arXiv:2309.16861v2 Announce Type: replace 
Abstract: Spatial confounding is a fundamental issue in spatial regression models which arises because spatial random effects, included to approximate unmeasured spatial variation, are typically not independent of covariates in the model. This can lead to significant bias in covariate effect estimates. The problem is complex and has been the topic of extensive research with sometimes puzzling and seemingly contradictory results. Here, we develop a broad theoretical framework that brings mathematical clarity to the mechanisms of spatial confounding, providing explicit analytical expressions for the resulting bias. We see that the problem is directly linked to spatial smoothing and identify exactly how the size and occurrence of bias relate to the features of the spatial model as well as the underlying confounding scenario. Using our results, we can explain subtle and counter-intuitive behaviours. Finally, we propose a general approach for dealing with spatial confounding bias in practice, applicable for any spatial model specification. When a covariate has non-spatial information, we show that a general form of the so-called spatial+ method can be used to eliminate bias. When no such information is present, the situation is more challenging but, under the assumption of unconfounded high frequencies, we develop a procedure in which multiple capped versions of spatial+ are applied to assess the bias in this case. We illustrate our approach with an application to air temperature in Germany.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.16861v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emiko Dupont, Isa Marques, Thomas Kneib</dc:creator>
    </item>
    <item>
      <title>A constructive approach to selective risk control</title>
      <link>https://arxiv.org/abs/2401.16651</link>
      <description>arXiv:2401.16651v2 Announce Type: replace 
Abstract: Many modern applications require using data to select the statistical tasks and make valid inference after selection. In this article, we provide a unifying approach to control for a class of selective risks. Our method is motivated by a reformulation of the celebrated Benjamini-Hochberg (BH) procedure for multiple hypothesis testing as the fixed point iteration of the Benjamini-Yekutieli (BY) procedure for constructing post-selection confidence intervals. Building on this observation, we propose a constructive approach to control extra-selection risk (where selection is made after decision) by iterating decision strategies that control the post-selection risk (where decision is made after selection). We show that many previous methods and results are special cases of this general framework, and we further extend this approach to problems with multiple selective risks. Our development leads to two surprising results about the BH procedure: (1) in the context of one-sided location testing, the BH procedure not only controls the false discovery rate at the null but also at other locations for free; (2) in the context of permutation tests, the BH procedure with exact permutation p-values can be well approximated by a procedure which only requires a total number of permutations that is almost linear in the total number of hypotheses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.16651v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zijun Gao, Wenjie Hu, Qingyuan Zhao</dc:creator>
    </item>
    <item>
      <title>Fast Bayesian Basis Selection for Functional Data Representation with Correlated Errors</title>
      <link>https://arxiv.org/abs/2405.20758</link>
      <description>arXiv:2405.20758v3 Announce Type: replace 
Abstract: Functional data analysis finds widespread application across various fields. While functional data are intrinsically infinite-dimensional, in practice, they are observed only at a finite set of points, typically over a dense grid. As a result, smoothing techniques are often used to approximate the observed data as functions. In this work, we propose a novel Bayesian approach for selecting basis functions for smoothing one or multiple curves simultaneously. Our method differentiates from other Bayesian approaches in two key ways: (i) by accounting for correlated errors and (ii) by developing a variational EM algorithm, which is faster than MCMC methods such as Gibbs sampling. Simulation studies demonstrate that our method effectively identifies the true underlying structure of the data across various scenarios, and it is applicable to different types of functional data. Our variational EM algorithm not only recovers the basis coefficients and the correct set of basis functions but also estimates the existing within-curve correlation. When applied to the motorcycle and Canadian weather datasets, our method demonstrates comparable, and in some cases superior, performance in terms of adjusted $R^2$ compared to regression splines, smoothing splines, Bayesian LASSO and LASSO. Our proposed method is implemented in R and codes are available at https://github.com/acarolcruz/VB-Bases-Selection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20758v3</guid>
      <category>stat.ME</category>
      <pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ana Carolina da Cruz, Camila P. E. de Souza, Pedro H. T. O. Sousa</dc:creator>
    </item>
    <item>
      <title>BARD: A seamless two-stage dose optimization design integrating backfill and adaptive randomization</title>
      <link>https://arxiv.org/abs/2409.15663</link>
      <description>arXiv:2409.15663v2 Announce Type: replace 
Abstract: One common approach for dose optimization is a two-stage design, which initially conducts dose escalation to identify the maximum tolerated dose (MTD), followed by a randomization stage where patients are assigned to two or more doses to further assess and compare their risk-benefit profiles to identify the optimal dose. A limitation of this approach is its requirement for a relatively large sample size. To address this challenge, we propose a seamless two-stage design, BARD (Backfill and Adaptive Randomization for Dose Optimization), which incorporates two key features to reduce sample size and shorten trial duration. The first feature is the integration of backfilling into the stage 1 dose escalation, enhancing patient enrollment and data generation without prolonging the trial. The second feature involves seamlessly combining patients treated in stage 1 with those in stage 2, enabled by covariate-adaptive randomization, to inform the optimal dose and thereby reduce the sample size. Our simulation study demonstrates that BARD reduces the sample size, improves the accuracy of identifying the optimal dose, and maintains covariate balance in randomization, allowing for unbiased comparisons between doses. BARD designs offer an efficient solution to meet the dose optimization requirements set by Project Optimus, with software freely available at www.trialdesign.org.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.15663v2</guid>
      <category>stat.ME</category>
      <pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yixuan Zhao, Rachael Liu, Jianchang Lin, Ying Yuan</dc:creator>
    </item>
    <item>
      <title>Control of probability flow in Markov chain Monte Carlo -- Nonreversibility and lifting</title>
      <link>https://arxiv.org/abs/1207.0258</link>
      <description>arXiv:1207.0258v3 Announce Type: replace-cross 
Abstract: The Markov chain Monte Carlo (MCMC) method is widely used in various fields as a powerful numerical integration technique for systems with many degrees of freedom. In MCMC methods, probabilistic state transitions can be considered as a random walk in state space, and random walks allow for sampling from complex distributions. However, paradoxically, it is necessary to carefully suppress the randomness of the random walk to improve computational efficiency. By breaking detailed balance, we can create a probability flow in the state space and perform more efficient sampling along this flow. Motivated by this idea, practical and efficient nonreversible MCMC methods have been developed over the past ten years. In particular, the lifting technique, which introduces probability flows in an extended state space, has been applied to various systems and has proven more efficient than conventional reversible updates. We review and discuss several practical approaches to implementing nonreversible MCMC methods, including the shift method in the cumulative distribution and the directed-worm algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:1207.0258v3</guid>
      <category>cond-mat.stat-mech</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.NA</category>
      <category>physics.data-an</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1063/5.0233858</arxiv:DOI>
      <arxiv:journal_reference>J. Chem. Phys. 161, 174107 (2024)</arxiv:journal_reference>
      <dc:creator>Hidemaro Suwa, Synge Todo</dc:creator>
    </item>
    <item>
      <title>Semi-Supervised Health Index Monitoring with Feature Generation and Fusion</title>
      <link>https://arxiv.org/abs/2312.02867</link>
      <description>arXiv:2312.02867v3 Announce Type: replace-cross 
Abstract: The Health Index (HI) is crucial for evaluating system health and is important for tasks like anomaly detection and Remaining Useful Life (RUL) prediction of safety-critical systems. Real-time, meticulous monitoring of system conditions is essential, especially in manufacturing high-quality and safety-critical components such as spray coatings. However, acquiring accurate health status information (HI labels) in real scenarios can be difficult or costly because it requires continuous, precise measurements that fully capture the system's health. As a result, using datasets from systems run-to-failure, which provide limited HI labels only at the healthy and end-of-life phases, becomes a practical approach. We employ Deep Semi-supervised Anomaly Detection (DeepSAD) embeddings to tackle the challenge of extracting features associated with the system's health state. Additionally, we introduce a diversity loss to further enrich the DeepSAD embeddings. We also propose applying an alternating projection algorithm with isotonic constraints to transform the embedding into a normalized HI with an increasing trend. Validation on the PHME2010 milling dataset, a recognized benchmark with ground truth HIs, confirms the efficacy of our proposed HI estimations. Our methodology is further applied to monitor the wear states of thermal spray coatings using high-frequency voltage. These contributions facilitate more accessible and reliable HI estimation, particularly in scenarios where obtaining ground truth HI labels is impossible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.02867v3</guid>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ga\"etan Frusque, Ismail Nejjar, Majid Nabavi, Olga Fink</dc:creator>
    </item>
  </channel>
</rss>
