<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 30 Jul 2025 04:00:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Half-life of Youtube News Videos: Diffusion Dynamics and Predictive Factors</title>
      <link>https://arxiv.org/abs/2507.21187</link>
      <description>arXiv:2507.21187v1 Announce Type: new 
Abstract: Consumption of YouTube news videos significantly shapes public opinion and political narratives. While prior works have studied the longitudinal dissemination dynamics of YouTube News videos across extended periods, limited attention has been paid to the short-term trends. In this paper, we investigate the early-stage diffusion patterns and dispersion rate of news videos on YouTube, focusing on the first 24 hours. To this end, we introduce and analyze a rich dataset of over 50,000 videos across 75 countries and six continents. We provide the first quantitative evaluation of the 24-hour half-life of YouTube news videos as well as identify their distinct diffusion patterns. According to the findings, the average 24-hour half-life is approximately 7 hours, with substantial variance both within and across countries, ranging from as short as 2 hours to as long as 15 hours. Additionally, we explore the problem of predicting the latency of news videos' 24-hour half-lives. Leveraging the presented datasets, we train and contrast the performance of 6 different models based on statistical as well as Deep Learning techniques. The difference in prediction results across the models is traced and analyzed. Lastly, we investigate the importance of video- and channel-related predictors through Explainable AI (XAI) techniques. The dataset, analysis codebase and the trained models are released at http://bit.ly/3ILvTLU to facilitate further research in this area.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.21187v1</guid>
      <category>cs.SI</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anahit Sargsyan, Hridoy Sankar Dutta, Juergen Pfeffer</dc:creator>
    </item>
    <item>
      <title>How Growing Toxicity Manifests: A Topic Trajectory Analysis of U.S. Immigration Discourse on Social Media</title>
      <link>https://arxiv.org/abs/2507.21418</link>
      <description>arXiv:2507.21418v1 Announce Type: new 
Abstract: In the online public sphere, discussions about immigration often become increasingly fractious, marked by toxic language and polarization. Drawing on 4 million X posts over six months, we combine a user- and topic-centric approach to study how shifts in toxicity manifest as topical shifts. Our topic discovery method, which leverages instruction-based embeddings and recursive HDBSCAN, uncovers 157 fine-grained subtopics within the U.S. immigration discourse. We focus on users in four groups: (1) those with increasing toxicity, (2) those with decreasing toxicity, and two reference groups with no significant toxicity trend but matched toxicity levels. Treating each posting history as a trajectory through a five-dimensional topic space, we compare average group trajectories using permutational MANOVA. Our findings show that users with increasing toxicity drift toward alarmist, fear-based frames, whereas those with decreasing toxicity pivot toward legal and policy-focused themes. Both patterns diverge statistically significantly from their reference groups. This pipeline, which combines hierarchical topic discovery with trajectory analysis, offers a replicable method for studying dynamic conversations around social issues at scale.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.21418v1</guid>
      <category>cs.SI</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Una Joh, Yiqi Li, Jeff Hemsley</dc:creator>
    </item>
    <item>
      <title>Who's important? -- SUnSET: Synergistic Understanding of Stakeholder, Events and Time for Timeline Generation</title>
      <link>https://arxiv.org/abs/2507.21903</link>
      <description>arXiv:2507.21903v1 Announce Type: new 
Abstract: As news reporting becomes increasingly global and decentralized online, tracking related events across multiple sources presents significant challenges. Existing news summarization methods typically utilizes Large Language Models and Graphical methods on article-based summaries. However, this is not effective since it only considers the textual content of similarly dated articles to understand the gist of the event. To counteract the lack of analysis on the parties involved, it is essential to come up with a novel framework to gauge the importance of stakeholders and the connection of related events through the relevant entities involved. Therefore, we present SUnSET: Synergistic Understanding of Stakeholder, Events and Time for the task of Timeline Summarization (TLS). We leverage powerful Large Language Models (LLMs) to build SET triplets and introduced the use of stakeholder-based ranking to construct a $Relevancy$ metric, which can be extended into general situations. Our experimental results outperform all prior baselines and emerged as the new State-of-the-Art, highlighting the impact of stakeholder information within news article.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.21903v1</guid>
      <category>cs.SI</category>
      <category>cs.CL</category>
      <category>cs.IR</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Tiviatis Sim, Kaiwen Yang, Shen Xin, Kenji Kawaguchi</dc:creator>
    </item>
    <item>
      <title>Bridging the Gap: Enhancing News Interpretation Across Diverse Audiences with Large Language Models</title>
      <link>https://arxiv.org/abs/2507.21055</link>
      <description>arXiv:2507.21055v1 Announce Type: cross 
Abstract: In the interconnected world, news media are critical in conveying information to public across diverse domains including technology, finance, and agriculture. Journalists make efforts to present accurate information, however, the interpretation of news often varies significantly among different audiences due to their specific expertise and age. In this work, we investigate how to identify these comprehension gaps and provide solutions to improve audiences understanding of news content, particular to the aspects of articles outside their primary domains of knowledge. We propose a agent-based framework using large language models (LLMs) to simulate society communication behaviors, where several agents can discuss news. These agents can be designed to be experts from various occupation, or from different age group. Our results indicate that this framework can identify confusions or even misunderstanding of news for the agent through the iterative discussion process. Based on these accurate identification, the framework can design a supplement material specific to these agents on the news. Our results show that agents exhibit significantly improved news understanding after receiving this material. These findings highlight our framework's utility and efficiency in enhancing news comprehension for diverse audiences by directly addressing their understanding gap.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.21055v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leyi Ouyang</dc:creator>
    </item>
    <item>
      <title>Efficient Data Retrieval and Comparative Bias Analysis of Recommendation Algorithms for YouTube Shorts and Long-Form Videos</title>
      <link>https://arxiv.org/abs/2507.21467</link>
      <description>arXiv:2507.21467v1 Announce Type: cross 
Abstract: The growing popularity of short-form video content, such as YouTube Shorts, has transformed user engagement on digital platforms, raising critical questions about the role of recommendation algorithms in shaping user experiences. These algorithms significantly influence content consumption, yet concerns about biases, echo chambers, and content diversity persist. This study develops an efficient data collection framework to analyze YouTube's recommendation algorithms for both short-form and long-form videos, employing parallel computing and advanced scraping techniques to overcome limitations of YouTube's API. The analysis uncovers distinct behavioral patterns in recommendation algorithms across the two formats, with short-form videos showing a more immediate shift toward engaging yet less diverse content compared to long-form videos. Furthermore, a novel investigation into biases in politically sensitive topics, such as the South China Sea dispute, highlights the role of these algorithms in shaping narratives and amplifying specific viewpoints. By providing actionable insights for designing equitable and transparent recommendation systems, this research underscores the importance of responsible AI practices in the evolving digital media landscape.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.21467v1</guid>
      <category>cs.IR</category>
      <category>cs.SI</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Selimhan Dagtas, Mert Can Cakmak, Nitin Agarwal</dc:creator>
    </item>
    <item>
      <title>Towards Tight Bounds for Estimating Degree Distribution in Streaming and Query Models</title>
      <link>https://arxiv.org/abs/2507.21784</link>
      <description>arXiv:2507.21784v1 Announce Type: cross 
Abstract: The degree distribution of a graph $G=(V,E)$, $|V|=n$, $|E|=m$ is one of the most fundamental objects of study in the analysis of graphs as it embodies relationship among entities. In particular, an important derived distribution from degree distribution is the complementary cumulative degree histogram (ccdh). The ccdh is a fundamental summary of graph structure, capturing, for each threshold $d$, the number of vertices with degree at least $d$. For approximating ccdh, we consider the $(\varepsilon_D,\varepsilon_R)$-BiCriteria Multiplicative Approximation, which allows for controlled multiplicative slack in both the domain and the range. The exact complexity of the problem was not known and had been posed as an open problem in WOLA 2019 [Sublinear.info, Problem 98].
  In this work, we first design an algorithm that can approximate ccdh if a suitable vertex sample and an edge sample can be obtained and thus, the algorithm is independent of any sublinear model. Next, we show that in the streaming and query models, these samples can be obtained efficiently. On the other end, we establish the first lower bounds for this problem in both query and streaming models, and (almost) settle the complexity of the problem across both the sublinear models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.21784v1</guid>
      <category>cs.DS</category>
      <category>cs.SI</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Arijit Bishnu, Debarshi Chanda, Gopinath Mishra</dc:creator>
    </item>
    <item>
      <title>Demystifying Misconceptions in Social Bots Research</title>
      <link>https://arxiv.org/abs/2303.17251</link>
      <description>arXiv:2303.17251v4 Announce Type: replace 
Abstract: Research on social bots aims at advancing knowledge and providing solutions to one of the most debated forms of online manipulation. Yet, social bot research is plagued by widespread biases, hyped results, and misconceptions that set the stage for ambiguities, unrealistic expectations, and seemingly irreconcilable findings. Overcoming such issues is instrumental towards ensuring reliable solutions and reaffirming the validity of the scientific method. Here, we discuss a broad set of consequential methodological and conceptual issues that affect current social bots research, illustrating each with examples drawn from recent studies. More importantly, we demystify common misconceptions, addressing fundamental points on how social bots research is discussed. Our analysis surfaces the need to discuss research about online disinformation and manipulation in a rigorous, unbiased, and responsible way. This article bolsters such effort by identifying and refuting common fallacious arguments used by both proponents and opponents of social bots research, as well as providing directions toward sound methodologies for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.17251v4</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Stefano Cresci, Kai-Cheng Yang, Angelo Spognardi, Roberto Di Pietro, Filippo Menczer, Marinella Petrocchi</dc:creator>
    </item>
    <item>
      <title>Scalable Signed Exponential Random Graph Models under Local Dependence</title>
      <link>https://arxiv.org/abs/2507.07660</link>
      <description>arXiv:2507.07660v3 Announce Type: replace 
Abstract: Traditional network analysis focuses on binary edges, while real-world relationships are more nuanced, encompassing cooperation, neutrality, and conflict. The rise of negative edges in social media discussions spurred interest in analyzing signed interactions, especially in polarized debates. However, the vast data generated by digital networks presents challenges for traditional methods like Stochastic Block Models (SBM) and Exponential Family Random Graph Models (ERGM), particularly due to the homogeneity assumption and global dependence, which become increasingly unrealistic as network size grows. To address this, we propose a novel method that combines the strengths of SBM and ERGM while mitigating their weaknesses by incorporating local dependence based on non-overlapping blocks. Our approach involves a two-step process: first, decomposing the network into sub-networks using SBM approximation, and then estimating parameters using ERGM methods. We validate our method on large synthetic networks and apply it to a signed Wikipedia network of thousands of editors. Through the use of local dependence, we find patterns consistent with structural balance theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07660v3</guid>
      <category>cs.SI</category>
      <category>stat.CO</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Marc Schalberger, Cornelius Fritz</dc:creator>
    </item>
    <item>
      <title>Quotegraph: A Social Network Extracted from Millions of News Quotations</title>
      <link>https://arxiv.org/abs/2507.17626</link>
      <description>arXiv:2507.17626v2 Announce Type: replace 
Abstract: We introduce Quotegraph, a novel large-scale social network derived from speaker-attributed quotations in English news articles published between 2008 and 2020. Quotegraph consists of 528 thousand unique nodes and 8.63 million directed edges, pointing from speakers to persons they mention. The nodes are linked to their corresponding items in Wikidata, thereby endowing the dataset with detailed biographic entity information, including nationality, gender, and political affiliation. Being derived from Quotebank, a massive corpus of quotations, relations in Quotegraph are additionally enriched with the information about the context in which they are featured. Each part of the network construction pipeline is language agnostic, enabling the construction of similar datasets based on non-English news corpora. We believe Quotegraph is a compelling resource for computational social scientists, complementary to online social networks, with the potential to yield novel insights into the behavior of public figures and how it is captured in the news.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17626v2</guid>
      <category>cs.SI</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Marko \v{C}uljak, Robert West, Andreas Spitz, Akhil Arora</dc:creator>
    </item>
    <item>
      <title>"Whose Side Are You On?" Estimating Ideology of Political and News Content Using Large Language Models and Few-shot Demonstration Selection</title>
      <link>https://arxiv.org/abs/2503.20797</link>
      <description>arXiv:2503.20797v2 Announce Type: replace-cross 
Abstract: The rapid growth of social media platforms has led to concerns about radicalization, filter bubbles, and content bias. Existing approaches to classifying ideology are limited in that they require extensive human effort, the labeling of large datasets, and are not able to adapt to evolving ideological contexts. This paper explores the potential of Large Language Models (LLMs) for classifying the political ideology of online content in the context of the two-party US political spectrum through in-context learning (ICL). Our extensive experiments involving demonstration selection in label-balanced fashion, conducted on three datasets comprising news articles and YouTube videos, reveal that our approach significantly outperforms zero-shot and traditional supervised methods. Additionally, we evaluate the influence of metadata (e.g., content source and descriptions) on ideological classification and discuss its implications. Finally, we show how providing the source for political and non-political content influences the LLM's classification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20797v2</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muhammad Haroon, Magdalena Wojcieszak, Anshuman Chhabra</dc:creator>
    </item>
    <item>
      <title>Green building blocks reveal the complex anatomy of climate change mitigation technologies</title>
      <link>https://arxiv.org/abs/2504.06834</link>
      <description>arXiv:2504.06834v2 Announce Type: replace-cross 
Abstract: Achieving net-zero emissions requires rapid innovation, yet the necessary technological knowhow is scattered across industries and countries. Comparing functionally similar green and nongreen patents, we identify "Green Building Blocks" (GBBs): modular components that can be added to reduce existing technologies' carbon footprints. These GBBs depict the anatomy of the green transition as a network that connects problems -- nongreen technologies -- to GBBs that mitigate their climate-change impact. Node degrees in this network are highly unequal, showing that the scope for climate-change mitigating innovation varies substantially across domains. The network also helps predict which green technologies firms develop themselves, and which alliances they form to do so. This reveals a critical dependence on international collaboration: optimal innovation partners for 84% of US, 87% of German, and 92% of Chinese firms are foreign, providing quantitative evidence that rising economic nationalism threatens the pace of innovation required to meet global climate goals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06834v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yang Li, Frank Neffke</dc:creator>
    </item>
    <item>
      <title>The Dual Personas of Social Media Bots</title>
      <link>https://arxiv.org/abs/2504.12498</link>
      <description>arXiv:2504.12498v2 Announce Type: replace-cross 
Abstract: Social media bots are AI agents that participate in online conversations. Most studies focus on the general bot and the malicious nature of these agents. However, bots have many different personas, each specialized towards a specific behavioral or content trait. Neither are bots singularly bad, because they are used for both good and bad information dissemination. In this article, we introduce fifteen agent personas of social media bots. These personas have two main categories: Content-Based Bot Persona and Behavior-Based Bot Persona. We also form yardsticks of the good-bad duality of the bots, elaborating on metrics of good and bad bot agents. Our work puts forth a guideline to inform bot detection regulation, emphasizing that policies should focus on how these agents are employed, rather than collectively terming bot agents as bad.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.12498v2</guid>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Lynnette Hui Xian Ng, Kathleen M. Carley</dc:creator>
    </item>
  </channel>
</rss>
