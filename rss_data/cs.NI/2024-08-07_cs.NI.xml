<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 07 Aug 2024 04:00:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 07 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Towards Smart Microfarming in an Urban Computing Continuum</title>
      <link>https://arxiv.org/abs/2408.02992</link>
      <description>arXiv:2408.02992v1 Announce Type: new 
Abstract: Microfarming and urban computing have evolved as two distinct sustainability pillars of urban living today. In this paper, we combine these two concepts, while majorly extending them jointly towards novel concepts of smart microfarming and urban computing continuum. Smart microfarming is proposed with applications of artificial intelligence in microfarming, while an urban computing continuum is proposed as a major extension of the concept towards an efficient IoT-edge-cloud continuum. We propose and build a system architecture for a plant recommendation system that uses machine learning at the edge to find, from a pool of given plants, the most suitable ones for a given microfarm using monitored soil values obtained from IoT sensor devices. Moreover, we propose to integrate long-distance LoRa communication solution for sending the data from IoT to the edge system, due to its unlicensed nature and potential for open source implementations. Finally, we propose to integrate open source and less constrained application protocol solutions, such as AMQP and HTTP protocols, for storing the data in the cloud. An experimental setup is used to evaluate and analyze the performance and reliability of the data collection procedure and the quality of the recommendation solution. Furthermore, collaborative filtering is used for the completion of an incomplete information about soils and plants. Finally, various ML algorithms are applied to identify and recommend the optimal plan for a specific microfarm in an urban area.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02992v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marla Grunewald, Mounir Bensalem, Jasenka Dizdarevi\'c, Admela Jukan</dc:creator>
    </item>
    <item>
      <title>Congestion or No Congestion: Packet Loss Identification and Prediction Using Machine Learning</title>
      <link>https://arxiv.org/abs/2408.03007</link>
      <description>arXiv:2408.03007v1 Announce Type: new 
Abstract: Packet losses in the network significantly impact network performance. Most TCP variants reduce the transmission rate when detecting packet losses, assuming network congestion, resulting in lower throughput and affecting bandwidth-intensive applications like immersive applications. However, not all packet losses are due to congestion; some occur due to wireless link issues, which we refer to as non-congestive packet losses. In today's hybrid Internet, packets of a single flow may traverse wired and wireless segments of a network to reach their destination. TCP should not react to non-congestive packet losses the same way as it does to congestive losses. However, TCP currently can not differentiate between these types of packet losses and lowers its transmission rate irrespective of packet loss type, resulting in lower throughput for wireless clients. To address this challenge, we use machine learning techniques to distinguish between these types of packet losses at end hosts, utilizing easily available features at the host. Our results demonstrate that Random Forest and K-Nearest Neighbor classifiers perform better in predicting the type of packet loss, offering a promising solution to enhance network performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03007v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Inayat Ali, Sonia Sabir, Seungwoo Hong, Taesik Cheung</dc:creator>
    </item>
    <item>
      <title>DRL-Assisted Dynamic QoT-Aware Service Provisioning in Multi-Band Elastic Optical Networks</title>
      <link>https://arxiv.org/abs/2408.03221</link>
      <description>arXiv:2408.03221v1 Announce Type: new 
Abstract: We propose a DRL-assisted approach for service provisioning in multi-band elastic optical networks. Our simulation environment uses an accurate QoT estimator based on the GN/EGN model. Results show that the proposed approach reduces request blocking by 50% compared with heuristics from the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03221v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiran Teng, Carlos Natalino, Farhad Arpanaei, Alfonso S\'anchez-Maci\'an, Paolo Monti, Shuangyi Yan, Dimitra Simeonidou</dc:creator>
    </item>
    <item>
      <title>Active Learning for WBAN-based Health Monitoring</title>
      <link>https://arxiv.org/abs/2408.02849</link>
      <description>arXiv:2408.02849v1 Announce Type: cross 
Abstract: We consider a novel active learning problem motivated by the need of learning machine learning models for health monitoring in wireless body area network (WBAN). Due to the limited resources at body sensors, collecting each unlabeled sample in WBAN incurs a nontrivial cost. Moreover, training health monitoring models typically requires labels indicating the patient's health state that need to be generated by healthcare professionals, which cannot be obtained at the same pace as data collection. These challenges make our problem fundamentally different from classical active learning, where unlabeled samples are free and labels can be queried in real time. To handle these challenges, we propose a two-phased active learning method, consisting of an online phase where a coreset construction algorithm is proposed to select a subset of unlabeled samples based on their noisy predictions, and an offline phase where the selected samples are labeled to train the target model. The samples selected by our algorithm are proved to yield a guaranteed error in approximating the full dataset in evaluating the loss function. Our evaluation based on real health monitoring data and our own experimentation demonstrates that our solution can drastically save the data curation cost without sacrificing the quality of the target model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02849v1</guid>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cho-Chun Chiu, Tuan Nguyen, Ting He, Shiqiang Wang, Beom-Su Kim, Ki-Il Kim</dc:creator>
    </item>
    <item>
      <title>Rate-Splitting for Joint Unicast and Multicast Transmission in LEO Satellite Networks with Non-Uniform Traffic Demand</title>
      <link>https://arxiv.org/abs/2408.02872</link>
      <description>arXiv:2408.02872v1 Announce Type: cross 
Abstract: Low Earth orbit (LEO) satellite communications (SATCOM) with ubiquitous global connectivity is deemed a pivotal catalyst in advancing wireless communication systems for 5G and beyond. LEO SATCOM excels in delivering versatile information services across expansive areas, facilitating both unicast and multicast transmissions via high-speed broadband capability. Nonetheless, given the broadband coverage of LEO SATCOM, traffic demand distribution within the service area is non-uniform, and the time/frequency/power resources available at LEO satellites remain significantly limited. Motivated by these challenges, we propose a rate-matching framework for non-orthogonal unicast and multicast (NOUM) transmission. Our approach aims to minimize the difference between offered rates and traffic demands for both unicast and multicast messages. By multiplexing unicast and multicast transmissions over the same radio resource, rate-splitting multiple access (RSMA) is employed to manage interference between unicast and multicast streams, as well as inter-user interference under imperfect channel state information at the LEO satellite. To address the formulated problems non-smoothness and non-convexity, the common rate is approximated using the LogSumExp technique. Thereafter, we represent the common rate portion as the ratio of the approximated function, converting the problem into an unconstrained form. A generalized power iteration (GPI)-based algorithm, coined GPI-RS-NOUM, is proposed upon this reformulation. Through comprehensive numerical analysis across diverse simulation setups, we demonstrate that the proposed framework outperforms various benchmarks for LEO SATCOM with uneven traffic demands.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02872v1</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jaehyup Seong, Juha Park, Dong-Hyun Jung, Jeonghun Park, Wonjae Shin</dc:creator>
    </item>
    <item>
      <title>PolarStar: Expanding the Scalability Horizon of Diameter-3 Networks</title>
      <link>https://arxiv.org/abs/2302.07217</link>
      <description>arXiv:2302.07217v2 Announce Type: replace 
Abstract: We present PolarStar, a novel family of diameter-3 network topologies derived from the star product of low-diameter factor graphs. PolarStar gives the largest known diameter-3 network topologies for almost all radixes, thus providing the best known scalable diameter-$3$ network. Compared to current state-of-the-art diameter-$3$ networks, PolarStar achieves $1.3\times$ geometric mean increase in scale over Bundlefly, $1.9\times$ over Dragonfly, and $6.7\times$ over {3-D} HyperX. PolarStar has many other desirable properties, including a modular layout, large bisection, high resilience to link failures and a large number of feasible configurations for every radix. We give a detailed evaluation with simulations of synthetic and real-world traffic patterns and show that PolarStar exhibits comparable or better performance than current diameter-3 networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.07217v2</guid>
      <category>cs.NI</category>
      <category>cs.DC</category>
      <category>math.CO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3626183.3659975</arxiv:DOI>
      <arxiv:journal_reference>In Proceedings of the 36th ACM Symposium on Parallelism in Algorithms and Architectures 2024 (SPAA '24). ACM, New York, NY, USA, pages 345 - 357</arxiv:journal_reference>
      <dc:creator>Kartik Lakhotia, Laura Monroe, Kelly Isham, Maciej Besta, Nils Blach, Torsten Hoefler, Fabrizio Petrini</dc:creator>
    </item>
    <item>
      <title>Performance Evaluation of Transport Protocols and Roadmap to a High-Performance Transport Design for Immersive Applications</title>
      <link>https://arxiv.org/abs/2306.16692</link>
      <description>arXiv:2306.16692v3 Announce Type: replace 
Abstract: Immersive technologies such as virtual reality (VR), augmented reality (AR), and holograms will change users' digital experience. These immersive technologies have a multitude of applications, including telesurgeries, teleconferencing, Internet shopping, computer games, etc. Holographic-type communication (HTC) is a type of augmented reality media that provides an immersive experience to Internet users. However, HTC has different characteristics and network requirements, and the existing network architecture and transport protocols may not be able to cope with the stringent network requirements of HTC. Therefore, in this paper, we provide an in-depth and critical study of the transport protocols for HTC. We also discuss the characteristics and the network requirements for HTC. Based on the performance evaluation of the existing transport protocols, we propose a roadmap to design new high-performance transport protocols for immersive applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.16692v3</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/ICUFN57995.2023.10199443</arxiv:DOI>
      <dc:creator>Inayat Ali, Seungwoo Hong, Pyung-koo Park, Tae Yeon Kim</dc:creator>
    </item>
    <item>
      <title>Adaptive Prediction Approach for 3D Geometry-based communication</title>
      <link>https://arxiv.org/abs/2311.03975</link>
      <description>arXiv:2311.03975v4 Announce Type: replace 
Abstract: This paper addresses the challenges of mobile user requirements in shadowing and multi-fading environments, focusing on the Downlink (DL) radio node selection based on Uplink (UL) channel estimation. One of the key issues tackled in this research is the prediction performance in scenarios where estimated channels are integrated. An adaptive deep learning approach is proposed to improve performance, offering a compelling alternative to traditional interpolation techniques for air-to-ground link selection on demand. Moreover, our study considers a 3D channel model, which provides a more realistic and accurate representation than 2D models, particularly in the context of 3D network node distributions. This consideration becomes crucial in addressing the complex multipath fading effects within geometric stochastic 3D 3GPP channel models in urban environments. Furthermore, our research emphasises the need for adaptive prediction mechanisms that carefully balance the trade-off between DL link forecasted frequency response accuracy and the complexity requirements associated with estimation and prediction. This paper contributes to advancing 3D radio resource management by addressing these challenges, enabling more efficient and reliable communication for energy-constrained flying network nodes in dynamic environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.03975v4</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mervat Zarour, Qiuheng Zhou, Sergiy Melnyk, Hans D. Schotten</dc:creator>
    </item>
    <item>
      <title>Experimental Evaluation of Interactive Edge/Cloud Virtual Reality Gaming over Wi-Fi using Unity Render Streaming</title>
      <link>https://arxiv.org/abs/2402.00540</link>
      <description>arXiv:2402.00540v2 Announce Type: replace 
Abstract: Virtual Reality (VR) streaming enables end-users to seamlessly immerse themselves in interactive virtual environments using even low-end devices. However, the quality of the VR experience heavily relies on Wireless Fidelity (Wi-Fi) performance, since it serves as the last hop in the network chain. Our study delves into the intricate interplay between Wi-Fi and VR traffic, drawing upon empirical data and leveraging a Wi-Fi simulator. In this work, we further evaluate Wi-Fi's suitability for VR streaming in terms of the Quality of Service (QoS) it provides. In particular, we employ Unity Render Streaming to remotely stream real-time VR gaming content over Wi-Fi 6 using Web Real-Time Communication (WebRTC), considering a server physically located at the network's edge, near the end user. Our findings demonstrate the system's sustained network performance, showcasing minimal round-trip time (RTT) and jitter at 60 and 90 frames per second (fps). In addition, we uncover the characteristics and patterns of the generated traffic streams, unveiling a distinctive video transmission approach inherent to WebRTC-based services: the systematic packetization of video frames (VFs) and their transmission in discrete batches at regular intervals, regardless of the targeted frame rate. This interval-based transmission strategy maintains consistent video packet delays across video frame rates but leads to increased Wi-Fi airtime consumption. Our results demonstrate that shortening the interval between batches is advantageous, as it enhances Wi-Fi efficiency and reduces delays in delivering complete frames.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.00540v2</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.comcom.2024.08.001</arxiv:DOI>
      <dc:creator>Miguel Casasnovas, Costas Michaelides, Marc Carrascosa-Zamacois, Boris Bellalta</dc:creator>
    </item>
    <item>
      <title>NetLLM: Adapting Large Language Models for Networking</title>
      <link>https://arxiv.org/abs/2402.02338</link>
      <description>arXiv:2402.02338v3 Announce Type: replace 
Abstract: Many networking tasks now employ deep learning (DL) to solve complex prediction and optimization problems. However, current design philosophy of DL-based algorithms entails intensive engineering overhead due to the manual design of deep neural networks (DNNs) for different networking tasks. Besides, DNNs tend to achieve poor generalization performance on unseen data distributions/environments.
  Motivated by the recent success of large language models (LLMs), this work studies the LLM adaptation for networking to explore a more sustainable design philosophy. With the powerful pre-trained knowledge, the LLM is promising to serve as the foundation model to achieve "one model for all tasks" with even better performance and stronger generalization. In pursuit of this vision, we present NetLLM, the first framework that provides a coherent design to harness the powerful capabilities of LLMs with low efforts to solve networking problems. Specifically, NetLLM empowers the LLM to effectively process multimodal data in networking and efficiently generate task-specific answers. Besides, NetLLM drastically reduces the costs of fine-tuning the LLM to acquire domain knowledge for networking. Across three networking-related use cases - viewport prediction, adaptive bitrate streaming and cluster job scheduling, we showcase that the NetLLM-adapted LLM significantly outperforms state-of-the-art algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.02338v3</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3651890.3672268</arxiv:DOI>
      <dc:creator>Duo Wu, Xianda Wang, Yaqi Qiao, Zhi Wang, Junchen Jiang, Shuguang Cui, Fangxin Wang</dc:creator>
    </item>
    <item>
      <title>RIS Assisted Wireless Networks: Collaborative Regulation, Deployment Mode and Field Testing</title>
      <link>https://arxiv.org/abs/2404.08644</link>
      <description>arXiv:2404.08644v2 Announce Type: replace 
Abstract: In recent years, RIS has made significant progress in engineering application research and industrialization and academic research. However, the engineering application research field of RIS still faces several challenges. This article analyzes and discusses the two deployment modes of RIs-assisted wireless networks: Network Controlled Mode and Standalone mode. It also presents three typical collaboration scenarios of RIS networks, including multi-RIS collaboration, multi-user access, and multi-cell coordination, which reflect the differences between the two deployment modes of RIS. The article proposes collaborative regulation mechanisms for RIS and analyzes their applications in the two network deployment modes in-depth. Furthermore, the article establishes simulation models of three scenarios and provides rich numerical simulation results. An actual field test environment was also built, where a specially designed and processed RIS prototype was used for preliminary field test and verification. Finally, this article puts forward future trends and challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08644v2</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1049/cmu2.12808</arxiv:DOI>
      <dc:creator>Yajun Zhao</dc:creator>
    </item>
    <item>
      <title>Future-Proofing Mobile Networks: A Digital Twin Approach to Multi-Signal Management</title>
      <link>https://arxiv.org/abs/2407.15520</link>
      <description>arXiv:2407.15520v2 Announce Type: replace 
Abstract: Digital Twins (DTs) are set to become a key enabling technology in future wireless networks, with their use in network management increasing significantly. We developed a DT framework that leverages the heterogeneity of network access technologies as a resource for enhanced network performance and management, enabling smart data handling in the physical network. Tested in a Campus Area Network environment, our framework integrates diverse data sources to provide real-time, holistic insights into network performance and environmental sensing. We also envision that traditional analytics will evolve to rely on emerging AI models, such as Generative AI (GenAI), while leveraging current analytics capabilities. This capacity can simplify analytics processes through advanced ML models, enabling descriptive, diagnostic, predictive, and prescriptive analytics in a unified fashion. Finally, we present specific research opportunities concerning interoperability aspects and envision aligning advancements in DT technology with evolved AI integration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15520v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roberto Morabito, Bivek Pandey, Paulius Daubaris, Yasith R Wanigarathna, Sasu Tarkoma</dc:creator>
    </item>
    <item>
      <title>Optimal Sampling under Cost for Remote Estimation of the Wiener Process over a Channel with Delay</title>
      <link>https://arxiv.org/abs/2407.21181</link>
      <description>arXiv:2407.21181v2 Announce Type: replace 
Abstract: In this paper, we address the optimal sampling of a Wiener process under sampling and transmission costs, with the samples being forwarded to a remote estimator over a channel with random IID delay. The goal of the estimator is to reconstruct an estimate of the real-time signal value from causally received samples. Our study focuses on the optimal online strategy for both sampling and transmission, aiming to minimize the mean square estimation error. We establish that the optimal strategy involves threshold policies for both sampling and transmission, and we derive the optimal thresholds. We utilize Lagrange relaxation and backward induction as our methodology, revealing the problem of minimizing estimation error, under the assumption that sampling and transmission times are independent of the observed Wiener process. Our comparative analysis demonstrates that the estimation error achieved by the optimal joint sampling and transmission policy is significantly lower than that of age-optimal sampling, zero-wait sampling, periodic sampling, and policies that optimize only the sampling times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21181v2</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Orhan T. Yava\c{s}can, S\"uleyman \c{C}{\i}t{\i}r, Elif Uysal</dc:creator>
    </item>
  </channel>
</rss>
