<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 22 Apr 2025 04:00:35 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Incremental Attractor Neural Network Modelling of the Lifespan Retrieval Curve</title>
      <link>https://arxiv.org/abs/2504.14528</link>
      <description>arXiv:2504.14528v1 Announce Type: new 
Abstract: The human lifespan retrieval curve describes the proportion of recalled memories from each year of life. It exhibits a reminiscence bump - a tendency for aged people to better recall memories formed during their young adulthood than from other periods of life. We have modelled this using an attractor Bayesian Confidence Propagation Neural Network (BCPNN) with incremental learning. We systematically studied the synaptic mechanisms underlying the reminiscence bump in this network model after introduction of an exponential decay of the synaptic learning rate and examined its sensitivity to network size and other relevant modelling mechanisms. The most influential parameters turned out to be the synaptic learning rate at birth and the time constant of its exponential decay with age, which set the bump position in the lifespan retrieval curve. The other parameters mainly influenced the general magnitude of this curve. Furthermore, we introduced the parametrization of the recency phenomenon - the tendency to better remember the most recent memories - reflected in the curve's upwards tail in the later years of the lifespan. Such recency was achieved by adding a constant baseline component to the exponentially decaying synaptic learning rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14528v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patr\'icia Pereira, Anders Lansner, Pawel Herman</dc:creator>
    </item>
    <item>
      <title>Mapping Emotional Feeling in the Body: A Tripartite Framework for Understanding the Embodied Mind</title>
      <link>https://arxiv.org/abs/2504.14865</link>
      <description>arXiv:2504.14865v1 Announce Type: new 
Abstract: People often speak of being "moved beyond words" when witnessing awe-inspiring natural beauty, experiencing profound moral elevation, or encountering powerful works of art and music. Such moments evoke intensely embodied sensations - a swelling in the chest, a quickened heartbeat, or a sudden stillness that floods the entire body. These experiences are difficult to articulate, yet they are vividly real and spatially anchored in bodily experience. This review examines the emerging method of body mapping, which captures how individuals subjectively localize emotional sensations across the body. Drawing on over two dozen empirical studies, we propose a tripartite framework for understanding the origins of emotional bodily maps: (1) bottom-up physiological signals, (2) top-down behavioral engagement (including motor actions), and (3) conceptual and metaphorical constructions. Crucially, we argue that bodily maps are not mere reflections of physiological monitoring, but expressive interfaces between brain, body, and conceptualization. Because they rely on introspective sensation rather than verbal articulation, bodily maps offer a promising language-independent tool for assessing emotional experience - particularly in cross-cultural research, developmental studies, and clinical contexts where verbal reporting may be limited or unreliable. Ultimately, bodily maps reveal the hidden geography of emotion-those feelings that elude precise definition or verbalization, like being moved beyond words, yet are undeniably real and embodied - offering a compelling window into how emotions are formed, shared, and lived through the body.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14865v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tatsuya Daikoku, Maiko Minatoya, Masaki Tanaka</dc:creator>
    </item>
    <item>
      <title>Dynamic Difficulty Adjustment With Brain Waves as a Tool for Optimizing Engagement</title>
      <link>https://arxiv.org/abs/2504.13965</link>
      <description>arXiv:2504.13965v1 Announce Type: cross 
Abstract: This study explores the use of electroencephalography (EEG)-based brain wave monitoring to enable dynamic difficulty adjustment (DDA) in a virtual reality (VR) gaming environment. Using the Task Engagement Index (TEI) derived from frontal EEG electrodes, we adapt game challenge levels in real time to maintain optimal player engagement. In a within-subject design with six participants, we found that the DDA condition significantly increased engagement duration by 19.79% compared to a non-DDA control condition. These results suggest that combining EEG, DDA, and VR technologies can enhance user experience and has potential applications in adaptive learning, rehabilitation, and personalized interfaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.13965v1</guid>
      <category>cs.HC</category>
      <category>cs.NE</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Nir Cafri</dc:creator>
    </item>
    <item>
      <title>Causal pieces: analysing and improving spiking neural networks piece by piece</title>
      <link>https://arxiv.org/abs/2504.14015</link>
      <description>arXiv:2504.14015v1 Announce Type: cross 
Abstract: We introduce a novel concept for spiking neural networks (SNNs) derived from the idea of "linear pieces" used to analyse the expressiveness and trainability of artificial neural networks (ANNs). We prove that the input domain of SNNs decomposes into distinct causal regions where its output spike times are locally Lipschitz continuous with respect to the input spike times and network parameters. The number of such regions - which we call "causal pieces" - is a measure of the approximation capabilities of SNNs. In particular, we demonstrate in simulation that parameter initialisations which yield a high number of causal pieces on the training set strongly correlate with SNN training success. Moreover, we find that feedforward SNNs with purely positive weights exhibit a surprisingly high number of causal pieces, allowing them to achieve competitive performance levels on benchmark tasks. We believe that causal pieces are not only a powerful and principled tool for improving SNNs, but might also open up new ways of comparing SNNs and ANNs in the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14015v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dominik Dold, Philipp Christian Petersen</dc:creator>
    </item>
    <item>
      <title>sEEG-based Encoding for Sentence Retrieval: A Contrastive Learning Approach to Brain-Language Alignment</title>
      <link>https://arxiv.org/abs/2504.14468</link>
      <description>arXiv:2504.14468v1 Announce Type: cross 
Abstract: Interpreting neural activity through meaningful latent representations remains a complex and evolving challenge at the intersection of neuroscience and artificial intelligence. We investigate the potential of multimodal foundation models to align invasive brain recordings with natural language. We present SSENSE, a contrastive learning framework that projects single-subject stereo-electroencephalography (sEEG) signals into the sentence embedding space of a frozen CLIP model, enabling sentence-level retrieval directly from brain activity. SSENSE trains a neural encoder on spectral representations of sEEG using InfoNCE loss, without fine-tuning the text encoder. We evaluate our method on time-aligned sEEG and spoken transcripts from a naturalistic movie-watching dataset. Despite limited data, SSENSE achieves promising results, demonstrating that general-purpose language representations can serve as effective priors for neural decoding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14468v1</guid>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yijun Liu</dc:creator>
    </item>
    <item>
      <title>Extended mean-field theories for networks of real neurons</title>
      <link>https://arxiv.org/abs/2504.15197</link>
      <description>arXiv:2504.15197v1 Announce Type: cross 
Abstract: If the behavior of a system with many degrees of freedom can be captured by a small number of collective variables, then plausibly there is an underlying mean-field theory. We show that simple versions of this idea fail to describe the patterns of activity in networks of real neurons. An extended mean-field theory that matches the distribution of collective variables is at least consistent, though shows signs that these networks are poised near a critical point, in agreement with other observations. These results suggest a path to analysis of emerging data on ever larger numbers of neurons.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15197v1</guid>
      <category>physics.bio-ph</category>
      <category>cond-mat.stat-mech</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luca Di Carlo, Francesca Mignacco, Christopher W. Lynn, William Bialek</dc:creator>
    </item>
    <item>
      <title>Shifting Attention to You: Personalized Brain-Inspired AI Models</title>
      <link>https://arxiv.org/abs/2502.04658</link>
      <description>arXiv:2502.04658v2 Announce Type: replace 
Abstract: The integration of human and artificial intelligence offers a powerful avenue for advancing our understanding of information processing, as each system provides unique computational insights. However, despite the promise of human-AI integration, current AI models are largely trained on massive datasets, optimized for population-level performance, lacking mechanisms to align their computations with individual users' perceptual semantics and neural dynamics. Here we show that integrating human behavioral insights and millisecond scale neural data within a fine tuned CLIP based model not only captures generalized and individualized aspects of perception but also over doubles behavioral performance compared to the unmodified CLIP baseline. By embedding human inductive biases and mirroring dynamic neural processes during training, personalized neural fine tuning improves predictions of human similarity judgments and tracks the temporal evolution of individual neural responses. Our work establishes a novel, interpretable framework for designing adaptive AI systems, with broad implications for neuroscience, personalized medicine, and human-computer interaction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04658v2</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Stephen Chong Zhao, Yang Hu, Jason Lee, Andrew Bender, Trisha Mazumdar, Mark Wallace, David A. Tovar</dc:creator>
    </item>
    <item>
      <title>EEG relative phase-based analysis unveils the complexity and universality of human brain dynamics: integrative insights from general anesthesia and ADHD</title>
      <link>https://arxiv.org/abs/2503.19924</link>
      <description>arXiv:2503.19924v3 Announce Type: replace 
Abstract: Understanding brain wave patterns is fundamental to uncovering neural information processing mechanisms, making quantifying complexity across brain states an important line of investigation. We present a comprehensive analysis of the complexity of electroencephalography (EEG) signals, integrating data from seven distinct states experienced by participants undergoing general anesthesia, and resting-state recordings from individuals with inattentive-type ADHD alongside healthy control groups. Departing from prior studies that primarily focus on EEG amplitude dynamics, we adopt a novel relative phase approach to extract patterns of information flow directionality based on EEG phase dynamics. We quantify the complexity of these relative phase directionality patterns across various states using permutation entropy (PE) and statistical complexity measure within ordinal pattern framework. Our analysis: (i) PE is inversely correlated with the level of consciousness during general anesthesia, reflecting a dynamic interplay between anesthetic depth and shifts in directional information flow; (ii) healthy subjects consistently show higher PE than inADHD participants; (iii) when mapped onto the complexity-entropy causality plane, all brain states, regardless of condition or individual differences, align along a single curve, suggesting an underlying universal pattern in brain dynamics; and (iv) brain data consistently exhibit higher complexity than standard stochastic processes, likely due to greater multifractal scaling. These findings highlight that neural information propagation, as captured by EEG relative phase dynamics, is governed by self-organizing principles that are fundamentally more complex than the stochastic processes. Our EEG relative phase-based characterization provides new insight into the complexity of neural information flow directionality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.19924v3</guid>
      <category>q-bio.NC</category>
      <category>nlin.AO</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Athokpam Langlen Chanu, Youngjai Park, Younghwa Cha, UnCheol Lee, Joon-Young Moon, Jong-Min Park</dc:creator>
    </item>
    <item>
      <title>Neural Encoding and Decoding at Scale</title>
      <link>https://arxiv.org/abs/2504.08201</link>
      <description>arXiv:2504.08201v3 Announce Type: replace 
Abstract: Recent work has demonstrated that large-scale, multi-animal models are powerful tools for characterizing the relationship between neural activity and behavior. Current large-scale approaches, however, focus exclusively on either predicting neural activity from behavior (encoding) or predicting behavior from neural activity (decoding), limiting their ability to capture the bidirectional relationship between neural activity and behavior. To bridge this gap, we introduce a multimodal, multi-task model that enables simultaneous Neural Encoding and Decoding at Scale (NEDS). Central to our approach is a novel multi-task-masking strategy, which alternates between neural, behavioral, within-modality, and cross-modality masking. We pretrain our method on the International Brain Laboratory (IBL) repeated site dataset, which includes recordings from 83 animals performing the same visual decision-making task. In comparison to other large-scale models, we demonstrate that NEDS achieves state-of-the-art performance for both encoding and decoding when pretrained on multi-animal data and then fine-tuned on new animals. Surprisingly, NEDS's learned embeddings exhibit emergent properties: even without explicit training, they are highly predictive of the brain regions in each recording. Altogether, our approach is a step towards a foundation model of the brain that enables seamless translation between neural activity and behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08201v3</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yizi Zhang, Yanchen Wang, Mehdi Azabou, Alexandre Andre, Zixuan Wang, Hanrui Lyu, The International Brain Laboratory, Eva Dyer, Liam Paninski, Cole Hurwitz</dc:creator>
    </item>
  </channel>
</rss>
