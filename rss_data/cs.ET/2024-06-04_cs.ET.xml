<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 05 Jun 2024 01:54:55 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 04 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Kinematic Model of Magnetic Domain Wall Motion for Fast, High-Accuracy Simulations</title>
      <link>https://arxiv.org/abs/2406.00225</link>
      <description>arXiv:2406.00225v1 Announce Type: new 
Abstract: Domain wall (DW) devices have garnered recent interest for diverse applications including memory, logic, and neuromorphic primitives; fast, accurate device models are therefore imperative for large-scale system design and verification. Extant DW motion models are sub-optimal for large-scale system design either over-consuming compute resources with physics-heavy equations or oversimplifying the physics, drastically reducing model accuracy. We propose a DW model inspired by the phenomenological similarities between motions of a DW and a classical object being acted on by forces like air resistance or static friction. Our proposed phenomenological model predicts DW motion within 1.2% on average compared with micromagnetic simulations that are 400 times slower. Additionally our model is seven times faster than extant collective coordinate models and 14 times more accurate than extant hyper-reduced models making it an essential tool for large-scale DW circuit design and simulation. The model is publicly posted along with scripts that automatically extract model parameters from user-provided simulation or experimental data to extend the model to alternative micromagnetic parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00225v1</guid>
      <category>cs.ET</category>
      <category>cond-mat.mes-hall</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kristi Doleh, Leonard Humphrey, Chandler M. Linseisen, Michael D. Kitcher, Joanna M. Martin, Can Cui, Jean Anne C. Incorvia, Felipe Garcia-Sanchez, Naimul Hassan, Alexander J. Edwards, Joseph S. Friedman</dc:creator>
    </item>
    <item>
      <title>Computer Simulation of DNA Computing-Based Boolean Matrix Multiplication</title>
      <link>https://arxiv.org/abs/2406.00407</link>
      <description>arXiv:2406.00407v1 Announce Type: new 
Abstract: DNA computing is an unconventional approach to computing that harnesses the parallelism and information storage capabilities of DNA molecules. It has emerged as a promising field with potential applications in solving a variety of computationally complex problems. This paper explores a DNA computing algorithm for Boolean matrix multiplication proposed by Nobuyuki et al. (2006) using a computer simulation, inspired by similar work done in the past by Obront (2021) for the DNA computing algorithm developed by Adleman (1994) for solving the Hamiltonian path problem. We develop a Python program to simulate the logical operations involved in the DNA-based Boolean matrix multiplication algorithm. The simulation replicates the key steps of the algorithm, including DNA sequence generation and hybridization, without imitating the physical behaviour of the DNA molecules. It is intended to serve as a basic prototype for larger, more comprehensive DNA computing simulators that can be used as educational or research tools in the future. Through this work, we aim to contribute to the understanding of DNA-based computing paradigms and their potential advantages and trade-offs compared to conventional computing systems, paving the way for future research and advancements in this emerging field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00407v1</guid>
      <category>cs.ET</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muhammad Asad Tariq, Rafay Junaid, Muhammad Mehdy Hasnain, Danyal Farhat</dc:creator>
    </item>
    <item>
      <title>Embedding-Aligned Language Models</title>
      <link>https://arxiv.org/abs/2406.00024</link>
      <description>arXiv:2406.00024v1 Announce Type: cross 
Abstract: We propose a novel approach for training large language models (LLMs) to adhere to objectives defined within a latent embedding space. Our method leverages reinforcement learning (RL), treating a pre-trained LLM as an environment. Our embedding-aligned guided language (EAGLE) agent is trained to iteratively steer the LLM's generation towards optimal regions of the latent embedding space, w.r.t. some predefined criterion. We demonstrate the effectiveness of the EAGLE agent using the MovieLens 25M dataset to surface content gaps that satisfy latent user demand. We also demonstrate the benefit of using an optimal design of a state-dependent action set to improve EAGLE's efficiency. Our work paves the way for controlled and grounded text generation using LLMs, ensuring consistency with domain-specific knowledge and data representations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00024v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guy Tennenholtz, Yinlam Chow, Chih-Wei Hsu, Lior Shani, Ethan Liang, Craig Boutilier</dc:creator>
    </item>
    <item>
      <title>On complexity of colloid cellular automata</title>
      <link>https://arxiv.org/abs/2406.00166</link>
      <description>arXiv:2406.00166v1 Announce Type: cross 
Abstract: The colloid cellular automata do not imitate the physical structure of colloids but are governed by logical functions derived from the colloids. We analyse the space-time complexity of Boolean circuits derived from the electrical responses of colloids: ZnO (zinc oxide, an inorganic compound also known as calamine or zinc white, which naturally occurs as the mineral zincite), proteinoids (microspheres and crystals of thermal abiotic proteins), and combinations thereof to electrical stimulation. To extract Boolean circuits from colloids, we send all possible configurations of two-, four-, and eight-bit binary strings, encoded as electrical potential values, to the colloids, record their responses, and thereby infer the Boolean functions they implement. We map the discovered functions onto the cell-state transition rules of cellular automata (arrays of binary state machines that update their states synchronously according to the same rule) -- the colloid cellular automata. We then analyse the phenomenology of the space-time configurations of the automata and evaluate their complexity using measures such as compressibility, Shannon entropy, Simpson diversity, and expressivity. A hierarchy of phenomenological and measurable space-time complexity is constructed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00166v1</guid>
      <category>nlin.CG</category>
      <category>cs.ET</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew Adamatzky, Nic Roberts, Raphael Fortulan, Noushin Raeisi Kheirabadi, Panagiotis Mougkogiannis, Michail-Antisthenis Tsompanas, Genaro J. Martinez, Georgios Ch. Sirakoulis, Alessandro Chiolerio</dc:creator>
    </item>
    <item>
      <title>Exfiltration of personal information from ChatGPT via prompt injection</title>
      <link>https://arxiv.org/abs/2406.00199</link>
      <description>arXiv:2406.00199v1 Announce Type: cross 
Abstract: We report that ChatGPT 4 and 4o are susceptible to a prompt injection attack that allows an attacker to query users' personal data. It is applicable without the use of any 3rd party tools and all users are currently affected. This vulnerability is exacerbated by the recent introduction of ChatGPT's memory feature, which allows an attacker to command ChatGPT to monitor the user for the desired personal data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00199v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gregory Schwartzman</dc:creator>
    </item>
    <item>
      <title>Bringing active learning, experimentation, and student-created videos in engineering: A study about teaching electronics and physical computing integrating online and mobile learning</title>
      <link>https://arxiv.org/abs/2406.00895</link>
      <description>arXiv:2406.00895v1 Announce Type: cross 
Abstract: Active Learning (AL) is a well-known teaching method in engineering because it allows to foster learning and critical thinking of the students by employing debate, hands-on activities, and experimentation. However, most educational results of this instructional method have been achieved in face-to-face educational settings and less has been said about how to promote AL and experimentation for online engineering education. Then, the main aim of this study was to create an AL methodology to learn electronics, physical computing (PhyC), programming, and basic robotics in engineering through hands-on activities and active experimentation in online environments. N=56 students of two engineering programs (Technology in Electronics and Industrial Engineering) participated in the methodology that was conceived using the guidelines of the Integrated Course Design Model (ICDM) and in some courses combining mobile and online learning with an Android app. The methodology gathered three main components: (1) In-home laboratories performed through low-cost hardware devices, (2) Student-created videos and blogs to evidence the development of skills, and (3) Teacher support and feedback. Data in the courses were collected through surveys, evaluation rubrics, semi-structured interviews, and students grades and were analyzed through a mixed approach. The outcomes indicate a good perception of the PhyC and programming activities by the students and suggest that these influence motivation, self-efficacy, reduction of anxiety, and improvement of academic performance in the courses. The methodology and previous results can be useful for researchers and practitioners interested in developing AL methodologies or strategies in engineering with online, mobile, or blended learning modalities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00895v1</guid>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1002/cae.22673</arxiv:DOI>
      <arxiv:journal_reference>Computer Applications in Engineering Education, 2023, 31, 1723-1749</arxiv:journal_reference>
      <dc:creator>Jonathan \'Alvarez Ariza</dc:creator>
    </item>
    <item>
      <title>How Ethical Should AI Be? How AI Alignment Shapes the Risk Preferences of LLMs</title>
      <link>https://arxiv.org/abs/2406.01168</link>
      <description>arXiv:2406.01168v1 Announce Type: cross 
Abstract: This study explores the risk preferences of Large Language Models (LLMs) and how the process of aligning them with human ethical standards influences their economic decision-making. By analyzing 30 LLMs, we uncover a broad range of inherent risk profiles ranging from risk-averse to risk-seeking. We then explore how different types of AI alignment, a process that ensures models act according to human values and that focuses on harmlessness, helpfulness, and honesty, alter these base risk preferences. Alignment significantly shifts LLMs towards risk aversion, with models that incorporate all three ethical dimensions exhibiting the most conservative investment behavior. Replicating a prior study that used LLMs to predict corporate investments from company earnings call transcripts, we demonstrate that although some alignment can improve the accuracy of investment forecasts, excessive alignment results in overly cautious predictions. These findings suggest that deploying excessively aligned LLMs in financial decision-making could lead to severe underinvestment. We underline the need for a nuanced approach that carefully balances the degree of ethical alignment with the specific requirements of economic domains when leveraging LLMs within finance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01168v1</guid>
      <category>econ.GN</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shumiao Ouyang, Hayong Yun, Xingjian Zheng</dc:creator>
    </item>
    <item>
      <title>Efficient Computation Using Spatial-Photonic Ising Machines: Utilizing Low-Rank and Circulant Matrix Constraints</title>
      <link>https://arxiv.org/abs/2406.01400</link>
      <description>arXiv:2406.01400v1 Announce Type: cross 
Abstract: We explore the potential of spatial-photonic Ising machines (SPIMs) to address computationally intensive Ising problems that employ low-rank and circulant coupling matrices. Our results indicate that the performance of SPIMs is critically affected by the rank and precision of the coupling matrices. By developing and assessing advanced decomposition techniques, we expand the range of problems SPIMs can solve, overcoming the limitations of traditional Mattis-type matrices. Our approach accommodates a diverse array of coupling matrices, including those with inherently low ranks, applicable to complex NP-complete problems. We explore the practical benefits of low-rank approximation in optimization tasks, particularly in financial optimization, to demonstrate the real-world applications of SPIMs. Finally, we evaluate the computational limitations imposed by SPIM hardware precision and suggest strategies to optimize the performance of these systems within these constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01400v1</guid>
      <category>physics.comp-ph</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>physics.optics</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Richard Zhipeng Wang, James S. Cummins, Marvin Syed, Nikita Stroev, George Pastras, Jason Sakellariou, Symeon Tsintzos, Alexis Askitopoulos, Daniele Veraldi, Marcello Calvanese Strinati, Silvia Gentilini, Davide Pierangeli, Claudio Conti, Natalia G. Berloff</dc:creator>
    </item>
    <item>
      <title>Near-Field Beam Tracking with Extremely Large Dynamic Metasurface Antennas</title>
      <link>https://arxiv.org/abs/2406.01488</link>
      <description>arXiv:2406.01488v1 Announce Type: cross 
Abstract: The interplay between large antenna apertures and high frequencies in future generations of wireless networks will give rise to near-field communications. In this paper, we focus on the hybrid analog and digital beamforming architecture of dynamic metasurface antennas, which constitutes a recent prominent enabler of extremely massive antenna architectures, and devise a near-field beam tracking framework that initiates near-field beam sweeping only when the base station estimates that its provided beamforming gain drops below a threshold from its theoretically optimum value. Novel analytical expressions for the correlation function between any two beam focusing vectors, the beamforming gain with respect to user coordinate mismatch, the direction of the user movement yielding the fastest beamforming gain deterioration, and the minimum user displacement for a certain performance loss are presented. We also design a non-uniform coordinate grid for effectively sampling the user area of interest at each position estimation slot. Our extensive simulation results validate our theoretical analysis and showcase the superiority of the proposed near-field beam tracking over benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01488v1</guid>
      <category>cs.IT</category>
      <category>cs.ET</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Panagiotis Gavriilidis, George C. Alexandropoulos</dc:creator>
    </item>
    <item>
      <title>Symmetric silicon microring resonator optical crossbar array for accelerated inference and training in deep learning</title>
      <link>https://arxiv.org/abs/2401.16072</link>
      <description>arXiv:2401.16072v3 Announce Type: replace 
Abstract: Photonic integrated circuits are emerging as a promising platform for accelerating matrix multiplications in deep learning, leveraging the inherent parallel nature of light. Although various schemes have been proposed and demonstrated to realize such photonic matrix accelerators, the in-situ training of artificial neural networks using photonic accelerators remains challenging due to the difficulty of direct on-chip backpropagation on a photonic chip. In this work, we propose a silicon microring resonator (MRR) optical crossbar array with a symmetric structure that allows for simple on-chip backpropagation, potentially enabling the acceleration of both the inference and training phases of deep learning. We demonstrate a $4 \times 4$ circuit on a Si-on-insulator (SOI) platform and use it to perform inference tasks of a simple neural network for classifying Iris flowers, achieving a classification accuracy of 93.3%. Subsequently, we train the neural network using simulated on-chip backpropagation and achieve an accuracy of 91.1% in the same inference task after training. Furthermore, we simulate a convolutional neural network (CNN) for handwritten digit recognition, using a $9 \times 9$ MRR crossbar array to perform the convolution operations. This work contributes to the realization of compact and energy-efficient photonic accelerators for deep learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.16072v3</guid>
      <category>cs.ET</category>
      <category>physics.optics</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1364/PRJ.520518</arxiv:DOI>
      <arxiv:journal_reference>Photonics Research, 2024</arxiv:journal_reference>
      <dc:creator>Rui Tang, Shuhei Ohno, Ken Tanizawa, Kazuhiro Ikeda, Makoto Okano, Kasidit Toprasertpong, Shinichi Takagi, Mitsuru Takenaka</dc:creator>
    </item>
    <item>
      <title>DOCTOR: Dynamic On-Chip Temporal Variation Remediation Toward Self-Corrected Photonic Tensor Accelerators</title>
      <link>https://arxiv.org/abs/2403.02688</link>
      <description>arXiv:2403.02688v2 Announce Type: replace 
Abstract: Photonic computing has emerged as a promising solution for accelerating computation-intensive artificial intelligence (AI) workloads, offering unparalleled speed and energy efficiency, especially in resource-limited, latency-sensitive edge computing environments. However, the deployment of analog photonic tensor accelerators encounters reliability challenges due to hardware noise and environmental variations. While off-chip noise-aware training and on-chip training have been proposed to enhance the variation tolerance of optical neural accelerators with moderate, static noise, we observe a notable performance degradation over time due to temporally drifting variations, which requires a real-time, in-situ calibration mechanism. To tackle this challenging reliability issues, for the first time, we propose a lightweight dynamic on-chip remediation framework, dubbed DOCTOR, providing adaptive, in-situ accuracy recovery against temporally drifting noise. The DOCTOR framework intelligently monitors the chip status using adaptive probing and performs fast in-situ training-free calibration to restore accuracy when necessary. Recognizing nonuniform spatial variation distributions across devices and tensor cores, we also propose a variation-aware architectural remapping strategy to avoid executing critical tasks on noisy devices. Extensive experiments show that our proposed framework can guarantee sustained performance under drifting variations with 34% higher accuracy and 2-3 orders-of-magnitude lower overhead compared to state-of-the-art on-chip training methods. Our code is open-sourced at https://github.com/ScopeX-ASU/DOCTOR.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02688v2</guid>
      <category>cs.ET</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haotian Lu, Sanmitra Banerjee, Jiaqi Gu</dc:creator>
    </item>
    <item>
      <title>Generalized "Square roots of Not" matrices, their application to the unveiling of hidden logical operators and to the definition of fully matrix circular Euler functions</title>
      <link>https://arxiv.org/abs/2107.06067</link>
      <description>arXiv:2107.06067v3 Announce Type: replace-cross 
Abstract: The square root of Not is a logical operator of importance in quantum computing theory and of interest as a mathematical object in its own right. In physics, it is a square complex matrix of dimension 2. In the present work it is a complex square matrix of arbitrary dimension. The introduction of linear algebra into logical theory has been enhanced in recent decades by the researches in the field of neural networks and quantum computing. Here we will make a brief description of the representation of logical operations through matrices and we show how general expressions for the two square roots of the Not operator are obtained. Then, we explore two topics. First, we study an extension to a non-quantum domain of a short form of Deutsch's algorithm. Then, we assume that a root of Not is a matrix extension of the imaginary unit i, and under this idea we obtain fully matrix versions for the Euler expansions and for the representations of circular functions by complex exponentials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2107.06067v3</guid>
      <category>cs.OH</category>
      <category>cs.ET</category>
      <category>quant-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eduardo Mizraji</dc:creator>
    </item>
    <item>
      <title>Evidence of Scaling Advantage for the Quantum Approximate Optimization Algorithm on a Classically Intractable Problem</title>
      <link>https://arxiv.org/abs/2308.02342</link>
      <description>arXiv:2308.02342v2 Announce Type: replace-cross 
Abstract: The quantum approximate optimization algorithm (QAOA) is a leading candidate algorithm for solving optimization problems on quantum computers. However, the potential of QAOA to tackle classically intractable problems remains unclear. Here, we perform an extensive numerical investigation of QAOA on the low autocorrelation binary sequences (LABS) problem, which is classically intractable even for moderately sized instances. We perform noiseless simulations with up to 40 qubits and observe that the runtime of QAOA with fixed parameters scales better than branch-and-bound solvers, which are the state-of-the-art exact solvers for LABS. The combination of QAOA with quantum minimum finding gives the best empirical scaling of any algorithm for the LABS problem. We demonstrate experimental progress in executing QAOA for the LABS problem using an algorithm-specific error detection scheme on Quantinuum trapped-ion processors. Our results provide evidence for the utility of QAOA as an algorithmic component that enables quantum speedups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.02342v2</guid>
      <category>quant-ph</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.ET</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1126/sciadv.adm6761</arxiv:DOI>
      <arxiv:journal_reference>Sci. Adv. 10 (22), eadm6761 (2024)</arxiv:journal_reference>
      <dc:creator>Ruslan Shaydulin, Changhao Li, Shouvanik Chakrabarti, Matthew DeCross, Dylan Herman, Niraj Kumar, Jeffrey Larson, Danylo Lykov, Pierre Minssen, Yue Sun, Yuri Alexeev, Joan M. Dreiling, John P. Gaebler, Thomas M. Gatterman, Justin A. Gerber, Kevin Gilmore, Dan Gresh, Nathan Hewitt, Chandler V. Horst, Shaohan Hu, Jacob Johansen, Mitchell Matheny, Tanner Mengle, Michael Mills, Steven A. Moses, Brian Neyenhuis, Peter Siegfried, Romina Yalovetzky, Marco Pistoia</dc:creator>
    </item>
    <item>
      <title>Quantum Theory and Application of Contextual Optimal Transport</title>
      <link>https://arxiv.org/abs/2402.14991</link>
      <description>arXiv:2402.14991v3 Announce Type: replace-cross 
Abstract: Optimal Transport (OT) has fueled machine learning (ML) across many domains. When paired data measurements $(\boldsymbol{\mu}, \boldsymbol{\nu})$ are coupled to covariates, a challenging conditional distribution learning setting arises. Existing approaches for learning a $\textit{global}$ transport map parameterized through a potentially unseen context utilize Neural OT and largely rely on Brenier's theorem. Here, we propose a first-of-its-kind quantum computing formulation for amortized optimization of contextualized transportation plans. We exploit a direct link between doubly stochastic matrices and unitary operators thus unravelling a natural connection between OT and quantum computation. We verify our method (QontOT) on synthetic and real data by predicting variations in cell type distributions conditioned on drug dosage. Importantly we conduct a 24-qubit hardware experiment on a task challenging for classical computers and report a performance that cannot be matched with our classical neural OT approach. In sum, this is a first step toward learning to predict contextualized transportation plans through quantum computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.14991v3</guid>
      <category>cs.LG</category>
      <category>cs.ET</category>
      <category>math.QA</category>
      <category>q-bio.QM</category>
      <category>quant-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Nicola Mariella, Albert Akhriev, Francesco Tacchino, Christa Zoufal, Juan Carlos Gonzalez-Espitia, Benedek Harsanyi, Eugene Koskin, Ivano Tavernelli, Stefan Woerner, Marianna Rapsomaniki, Sergiy Zhuk, Jannis Born</dc:creator>
    </item>
    <item>
      <title>Generating Reservoir State Descriptions with Random Matrices</title>
      <link>https://arxiv.org/abs/2404.07278</link>
      <description>arXiv:2404.07278v2 Announce Type: replace-cross 
Abstract: We demonstrate a novel approach to reservoir computer measurements using random matrices. We do so to motivate how atomic-scale devices might be used for real-world computing applications. Our approach uses random matrices to construct reservoir measurements, introducing a simple, scalable means for producing state descriptions. In our studies, two reservoirs, a five-atom Heisenberg spin chain, and a five-qubit quantum circuit, perform time series prediction and data interpolation. The performance of the measurement technique and current limitations are discussed in detail alongside an exploration of the diversity of measurements yielded by the random matrices. Additionally, we explore the role of the parameters of the reservoirs, adjusting coupling strength and the measurement dimension, yielding insights into how these learning machines might be automatically tuned for different problems. This research highlights using random matrices to measure simple quantum reservoirs for natural learning devices and outlines a path forward for improving their performance and experimental realization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07278v2</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samuel Tovey, Tobias Fellner, Christian Holm, Michael Spannowsky</dc:creator>
    </item>
    <item>
      <title>Proof-of-Learning with Incentive Security</title>
      <link>https://arxiv.org/abs/2404.09005</link>
      <description>arXiv:2404.09005v4 Announce Type: replace-cross 
Abstract: Most concurrent blockchain systems rely heavily on the Proof-of-Work (PoW) or Proof-of-Stake (PoS) mechanisms for decentralized consensus and security assurance. However, the substantial energy expenditure stemming from computationally intensive yet meaningless tasks has raised considerable concerns surrounding traditional PoW approaches, The PoS mechanism, while free of energy consumption, is subject to security and economic issues. Addressing these issues, the paradigm of Proof-of-Useful-Work (PoUW) seeks to employ challenges of practical significance as PoW, thereby imbuing energy consumption with tangible value. While previous efforts in Proof of Learning (PoL) explored the utilization of deep learning model training SGD tasks as PoUW challenges, recent research has revealed its vulnerabilities to adversarial attacks and the theoretical hardness in crafting a byzantine-secure PoL mechanism. In this paper, we introduce the concept of incentive-security that incentivizes rational provers to behave honestly for their best interest, bypassing the existing hardness to design a PoL mechanism with computational efficiency, a provable incentive-security guarantee and controllable difficulty. Particularly, our work is secure against two attacks to the recent work of Jia et al. [2021], and also improves the computational overhead from $\Theta(1)$ to $O(\frac{\log E}{E})$. Furthermore, while most recent research assumes trusted problem providers and verifiers, our design also guarantees frontend incentive-security even when problem providers are untrusted, and verifier incentive-security that bypasses the Verifier's Dilemma. By incorporating ML training into blockchain consensus mechanisms with provable guarantees, our research not only proposes an eco-friendly solution to blockchain systems, but also provides a proposal for a completely decentralized computing power market in the new AI age.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09005v4</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zishuo Zhao, Zhixuan Fang, Xuechao Wang, Xi Chen, Yuan Zhou</dc:creator>
    </item>
    <item>
      <title>Embedding Privacy in Computational Social Science and Artificial Intelligence Research</title>
      <link>https://arxiv.org/abs/2404.11515</link>
      <description>arXiv:2404.11515v2 Announce Type: replace-cross 
Abstract: Privacy is a human right. It ensures that individuals are free to engage in discussions, participate in groups, and form relationships online or offline without fear of their data being inappropriately harvested, analyzed, or otherwise used to harm them. Preserving privacy has emerged as a critical factor in research, particularly in the computational social science (CSS), artificial intelligence (AI) and data science domains, given their reliance on individuals' data for novel insights. The increasing use of advanced computational models stands to exacerbate privacy concerns because, if inappropriately used, they can quickly infringe privacy rights and lead to adverse effects for individuals -- especially vulnerable groups -- and society. We have already witnessed a host of privacy issues emerge with the advent of large language models (LLMs), such as ChatGPT, which further demonstrate the importance of embedding privacy from the start. This article contributes to the field by discussing the role of privacy and the issues that researchers working in CSS, AI, data science and related domains are likely to face. It then presents several key considerations for researchers to ensure participant privacy is best preserved in their research design, data collection and use, analysis, and dissemination of research results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11515v2</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.36190/2024.18</arxiv:DOI>
      <dc:creator>Keenan Jones, Fatima Zahrah, Jason R. C. Nurse</dc:creator>
    </item>
    <item>
      <title>Impact of Traffic-Following on Order of Autonomous Airspace Operations</title>
      <link>https://arxiv.org/abs/2404.17627</link>
      <description>arXiv:2404.17627v2 Announce Type: replace-cross 
Abstract: In this paper, we investigate the dynamic emergence of traffic order in a distributed multi-agent system, aiming to minimize inefficiencies that stem from unnecessary structural impositions. We introduce a methodology for developing a dynamically-updating traffic pattern map of the airspace by leveraging information about the consistency and frequency of flow directions used by current as well as preceding traffic. Informed by this map, an agent can discern the degree to which it is advantageous to follow traffic by trading off utilities such as time and order. We show that for the traffic levels studied, for low degrees of traffic-following behavior, there is minimal penalty in terms of aircraft travel times while improving the overall orderliness of the airspace. On the other hand, heightened traffic-following behavior may result in increased aircraft travel times, while marginally reducing the overall entropy of the airspace. Ultimately, the methods and metrics presented in this paper can be used to optimally and dynamically adjust an agent's traffic-following behavior based on these trade-offs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17627v2</guid>
      <category>cs.MA</category>
      <category>cs.CE</category>
      <category>cs.ET</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Anahita Jain, Husni R. Idris, John-Paul Clarke</dc:creator>
    </item>
  </channel>
</rss>
