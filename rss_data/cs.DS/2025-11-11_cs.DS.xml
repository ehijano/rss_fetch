<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 12 Nov 2025 02:50:34 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Efficient Dynamic MaxFlow Computation on GPUs</title>
      <link>https://arxiv.org/abs/2511.05895</link>
      <description>arXiv:2511.05895v1 Announce Type: new 
Abstract: Maxflow is a fundamental problem in graph theory and combinatorial optimisation, used to determine the maximum flow from a source node to a sink node in a flow network. It finds applications in diverse domains, including computer networks, transportation, and image segmentation. The core idea is to maximise the total flow across the network without violating capacity constraints on edges and ensuring flow conservation at intermediate nodes. The rapid growth of unstructured and semi-structured data has motivated the development of parallel solutions to compute MaxFlow. However, due to the higher computational complexity, computing Maxflow for real-world graphs is time-consuming in practice. In addition, these graphs are dynamic and constantly evolve over time. In this work, we propose two Push-Relabel based algorithms for processing dynamic graphs on GPUs. The key novelty of our algorithms is their ability to efficiently handle both increments and decrements in edge capacities together when they appear in a batch. We illustrate the efficacy of our algorithms with a suite of real-world graphs. Overall, we find that for small updates, dynamic recomputation is significantly faster than a static GPU-based Maxflow.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.05895v1</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shruthi Kannappan, Ashwina Kumar, Rupesh Nasre</dc:creator>
    </item>
    <item>
      <title>A Better-Than-2 Approximation for the Directed Tree Augmentation Problem</title>
      <link>https://arxiv.org/abs/2511.06162</link>
      <description>arXiv:2511.06162v1 Announce Type: new 
Abstract: We introduce and study a directed analogue of the weighted Tree Augmentation Problem (WTAP). In the weighted Directed Tree Augmentation Problem (WDTAP), we are given an oriented tree $T = (V,A)$ and a set of directed links $L \subseteq V \times V$ with positive costs. The goal is to select a minimum cost set of links which enters each fundamental dicut of $T$ (cuts with one leaving and no entering tree arc). WDTAP captures the problem of covering a cross-free set family with directed links. It can also be used to solve weighted multi $2$-TAP, in which we must cover the edges of an undirected tree at least twice. WDTAP can be approximated to within a factor of $2$ using standard techniques. We provide an improved $(1.75+ \varepsilon)$-approximation algorithm for WDTAP in the case where the links have bounded costs, a setting that has received significant attention for WTAP. To obtain this result, we discover a class of instances, called "willows'', for which the natural set covering LP is an integral formulation. We further introduce the notion of "visibly $k$-wide'' instances which can be solved exactly using dynamic programming. Finally, we show how to leverage these tractable cases to obtain an improved approximation ratio via an elaborate structural analysis of the tree.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06162v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Meike Neuwohner, Olha Silina, Michael Zlatin</dc:creator>
    </item>
    <item>
      <title>No Price Tags? No Problem: Query Strategies for Unpriced Information</title>
      <link>https://arxiv.org/abs/2511.06170</link>
      <description>arXiv:2511.06170v1 Announce Type: new 
Abstract: The classic *priced query model*, introduced by Charikar et al. (STOC 2000), captures the task of computing a known function on an unknown input when each input variable can only be revealed by paying an associated cost. The goal is to design a query strategy that determines the function's value while minimizing the total cost incurred. However, all prior work in this model assumes complete advance knowledge of the query costs -- an assumption that fails in many realistic settings.
  We introduce a variant of the priced query model that explicitly handles *unknown* variable costs. We prove a separation from the traditional priced query model, showing that uncertainty in variable costs imposes an unavoidable overhead for every query strategy. Despite this, we design strategies that essentially match our lower bound and are competitive with the best cost-aware strategies for arbitrary Boolean functions. Our results build on a recent connection between priced query strategies and the analysis of Boolean functions, and draw techniques from online algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06170v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shivam Nadimpalli, Mingda Qiao, Ronitt Rubinfeld</dc:creator>
    </item>
    <item>
      <title>Spanning and Metric Tree Covers Parameterized by Treewidth</title>
      <link>https://arxiv.org/abs/2511.06263</link>
      <description>arXiv:2511.06263v1 Announce Type: new 
Abstract: Given a graph $G=(V,E)$, a tree cover is a collection of trees $\mathcal{T}=\{T_1,T_2,...,T_q\}$, such that for every pair of vertices $u,v\in V$ there is a tree $T\in\mathcal{T}$ that contains a $u-v$ path with a small stretch. If the trees $T_i$ are sub-graphs of $G$, the tree cover is called a spanning tree cover. If these trees are HSTs, it is called an HST cover.
  In a seminal work, Mendel and Naor [2006] showed that for any parameter $k=1,2,...$, there exists an HST cover, and a non-spanning tree cover, with stretch $O(k)$ and with $O(kn^{\frac{1}{k}})$ trees. Abraham et al. [2020] devised a spanning version of this result, albeit with stretch $O(k\log\log n)$. For graphs of small treewidth $t$, Gupta et al. [2004] devised an exact spanning tree cover with $O(t\log n)$ trees, and Chang et al. [2-23] devised a $(1+\epsilon)$-approximate non-spanning tree cover with $2^{(t/\epsilon)^{O(t)}}$ trees.
  We prove a smooth tradeoff between the stretch and the number of trees for graphs with balanced recursive separators of size at most $s(n)$ or treewidth at most $t(n)$. Specifically, for any $k=1,2,...$, we provide tree covers and HST covers with stretch $O(k)$ and $O\left(\frac{k^2\log n}{\log s(n)}\cdot s(n)^{\frac{1}{k}}\right)$ trees or $O(k\log n\cdot t(n)^{\frac{1}{k}})$ trees, respectively. We also devise spanning tree covers with these parameters and stretch $O(k\log\log n)$. In addition devise a spanning tree cover for general graphs with stretch $O(k\log\log n)$ and average overlap $O(n^{\frac{1}{k}})$.
  We use our tree covers to provide improved path-reporting spanners, emulators (including low-hop emulators, known also as low-hop metric spanners), distance labeling schemes and routing schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06263v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Elkin, Idan Shabat</dc:creator>
    </item>
    <item>
      <title>Coloring Reconfiguration under Color Swapping</title>
      <link>https://arxiv.org/abs/2511.06473</link>
      <description>arXiv:2511.06473v1 Announce Type: new 
Abstract: In the \textsc{Coloring Reconfiguration} problem, we are given two proper $k$-colorings of a graph and asked to decide whether one can be transformed into the other by repeatedly applying a specified recoloring rule, while maintaining a proper coloring throughout. For this problem, two recoloring rules have been widely studied: \emph{single-vertex recoloring} and \emph{Kempe chain recoloring}. In this paper, we introduce a new rule, called \emph{color swapping}, where two adjacent vertices may exchange their colors, so that the resulting coloring remains proper, and study the computational complexity of the problem under this rule. We first establish a complexity dichotomy with respect to $k$: the problem is solvable in polynomial time for $k \leq 2$, and is PSPACE-complete for $k \geq 3$. We further show that the problem remains PSPACE-complete even on restricted graph classes, including bipartite graphs, split graphs, and planar graphs of bounded degree. In contrast, we present polynomial-time algorithms for several graph classes: for paths when $k = 3$, for split graphs when $k$ is fixed, and for cographs when $k$ is arbitrary.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06473v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Janosch Fuchs, Rin Saito, Tatsuhiro Suga, Takahiro Suzuki, Yuma Tamura</dc:creator>
    </item>
    <item>
      <title>UAIC_Twin_Width: An Exact yet Efficient Twin-Width Algorithm</title>
      <link>https://arxiv.org/abs/2511.06486</link>
      <description>arXiv:2511.06486v1 Announce Type: new 
Abstract: Twin-width is a recently formulated graph and matrix invariant that intuitively quantifies how far a graph is from having the structural simplicity of a co-graph. Since its introduction in 2020, twin-width has received increasing attention and has driven research leading to notable advances in algorithmic fields, including graph theory and combinatorics. The 2023 edition of the Parameterized Algorithms and Computational Experiments (PACE) Challenge aimed to fulfill the need for a diverse and consistent public benchmark encompassing various graph structures, while also collecting state-of-the-art heuristic and exact approaches to the problem. In this paper, we propose two algorithms for efficiently computing the twin-width of graphs with arbitrary structures, comprising one exact and one heuristic approach. The proposed solutions performed strongly in the competition, with the exact algorithm achieving the best student result and ranking fourth overall. We release our source code publicly to enable practical applications of our work and support further research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06486v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Andrei Arhire, Matei Chiriac, Radu Timofte</dc:creator>
    </item>
    <item>
      <title>Improved Approximation for Ranking on General Graphs</title>
      <link>https://arxiv.org/abs/2511.06504</link>
      <description>arXiv:2511.06504v1 Announce Type: new 
Abstract: In this paper, we study Ranking, a well-known randomized greedy matching algorithm, for general graphs. The algorithm was originally introduced by Karp, Vazirani, and Vazirani [STOC 1990] for the online bipartite matching problem with one-sided vertex arrivals, where it achieves a tight approximation ratio of 1 - 1/e. It was later extended to general graphs by Goel and Tripathi [FOCS 2012]. The Ranking algorithm for general graphs is as follows: a permutation $\sigma$ over the vertices is chosen uniformly at random. The vertices are then processed sequentially according to this order, with each vertex being matched to the first available neighbor (if any) according to the same permutation $\sigma$.
  While the algorithm is quite well-understood for bipartite graphs-with the approximation ratio lying between 0.696 and 0.727, its approximation ratio for general graphs remains less well characterized despite extensive efforts. Prior to this work, the best known lower bound for general graphs was 0.526 by Chan et al. [TALG 2018], improving on the approximation ratio of 0.523 by Chan et al. [SICOMP 2018]. The upper bound, however, remains the same as that for bipartite graphs.
  In this work, we improve the approximation ratio of \textsc{Ranking} for general graphs to 0.5469, up from 0.526. This also surpasses the best-known approximation ratio of $0.531$ by Tang et al. [JACM 2023] for the oblivious matching problem. Our approach builds on the standard primal-dual analysis. The novelty of our work lies in proving new structural properties of Ranking by introducing the notion of the backup for vertices matched by the algorithm. For a fixed permutation, a vertex's backup is its potential match if its current match is removed. This concept helps characterize the rank distribution of the match of each vertex, enabling us to eliminate certain bad events that constrained previous work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06504v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mahsa Derakhshan, Mohammad Roghani, Mohammad Saneian, Tao Yu</dc:creator>
    </item>
    <item>
      <title>The Harmonic Policy for Online Buffer Sharing is (2 + ln n)-Competitive: A Simple Proof</title>
      <link>https://arxiv.org/abs/2511.06514</link>
      <description>arXiv:2511.06514v1 Announce Type: new 
Abstract: The problem of online buffer sharing is expressed as follows. A switch with $n$ output ports receives a stream of incoming packets. When an incoming packet is accepted by the switch, it is stored in a shared buffer of capacity $B$ common to all packets and awaits its transmission through its corresponding output port determined by its destination. Each output port transmits one packet per time unit. The problem is to find an algorithm for the switch to accept or reject a packet upon its arrival in order to maximize the total number of transmitted packets.
  Building on the work of Kesselman et al. (STOC 2001) on split buffer sharing, Kesselman and Mansour (TCS 2004) considered the problem of online buffer sharing which models most deployed internet switches. In their work, they presented the Harmonic policy and proved that it is $(2 + \ln n)$-competitive, which is the best known competitive ratio for this problem. The Harmonic policy unfortunately saw less practical relevance as it performs $n$ threshold checks per packets which is deemed costly in practice, especially on network switches processing multiple terabits of packets per second. While the Harmonic policy is elegant, the original proof is also rather complex and involves a lengthy matching routine along with multiple intermediary results.
  This note presents a simplified Harmonic policy, both in terms of implementation and proof. First, we show that the Harmonic policy can be implemented with a constant number of threshold checks per packet, matching the widely deployed \emph{Dynamic Threshold} policy. Second, we present a simple proof that shows the Harmonic policy is $(2 + \ln n)$-competitive. In contrast to the original proof, the current proof is direct and relies on a 3-partitioning of the packets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06514v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vamsi Addanki, Julien Dallot, Leon Kellerhals, Maciej Pacut, Stefan Schmid</dc:creator>
    </item>
    <item>
      <title>Approximating the Average-Case Graph Search Problem with Non-Uniform Costs</title>
      <link>https://arxiv.org/abs/2511.06564</link>
      <description>arXiv:2511.06564v1 Announce Type: new 
Abstract: Consider the following generalization of the classic binary search problem: A searcher is required to find a hidden target vertex $x$ in a graph $G$. To do so, they iteratively perform queries to an oracle, each about a chosen vertex $v$. After each such call, the oracle responds whether the target was found and if not, the searcher receives as a reply the connected component in $G-v$ which contains $x$. Additionally, each vertex $v$ may have a different query cost $c(v)$ and a different weight $w(v)$. The goal is to find the optimal querying strategy which minimizes the weighted average-case cost required to find $x$. The problem is NP-hard even for uniform weights and query costs. Inspired by the progress on the edge query variant of the problem [SODA '17], we establish a connection between searching and vertex separation. By doing so, we provide an $O(\sqrt{\log n})$-approximation algorithm for general graphs and a $(4+\epsilon)$-approximation algorithm for the case when the input is a tree.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06564v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Micha{\l} Szyfelbein</dc:creator>
    </item>
    <item>
      <title>Improved Tree Sparsifiers in Near-Linear Time</title>
      <link>https://arxiv.org/abs/2511.06574</link>
      <description>arXiv:2511.06574v1 Announce Type: new 
Abstract: A \emph{tree cut-sparsifier} $T$ of quality $\alpha$ of a graph $G$ is a single tree that preserves the capacities of all cuts in the graph up to a factor of $\alpha$. A \emph{tree flow-sparsifier} $T$ of quality $\alpha$ guarantees that every demand that can be routed in $T$ can also be routed in $G$ with congestion at most $\alpha$.
  We present a near-linear time algorithm that, for any undirected capacitated graph $G=(V,E,c)$, constructs a tree cut-sparsifier $T$ of quality $O(\log^{2} n \log\log n)$, where $n=|V|$. This nearly matches the quality of the best known polynomial construction of a tree cut-sparsifier, of quality $O(\log^{1.5} n \log\log n)$ [R\"acke and Shah, ESA~2014]. By the flow-cut gap, our result yields a tree flow-sparsifier (and congestion-approximator) of quality $O(\log^{3} n \log\log n)$. This improves on the celebrated result of [R\"acke, Shah, and T\"aubig, SODA~2014] (RST) that gave a near-linear time construction of a tree flow-sparsifier of quality $O(\log^{4} n)$.
  Our algorithm builds on a recent \emph{expander decomposition} algorithm by [Agassy, Dorfman, and Kaplan, ICALP~2023], which we use as a black box to obtain a clean and modular foundation for tree cut-sparsifiers. This yields an improved and simplified version of the RST construction for cut-sparsifiers with quality $O(\log^{3} n)$. We then introduce a near-linear time \emph{refinement phase} that controls the load accumulated on boundary edges of the sub-clusters across the levels of the tree. Combining the improved framework with this refinement phase leads to our final $O(\log^{2} n \log\log n)$ tree cut-sparsifier.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06574v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Agassy, Dani Dorfman, Haim Kaplan</dc:creator>
    </item>
    <item>
      <title>Acceleration for Distributed Transshipment and Parallel Maximum Flow</title>
      <link>https://arxiv.org/abs/2511.06581</link>
      <description>arXiv:2511.06581v1 Announce Type: new 
Abstract: We combine several recent advancements to solve $(1+\varepsilon)$-transshipment and $(1+\varepsilon)$-maximum flow with a parallel algorithm with $\tilde{O}(1/\varepsilon)$ depth and $\tilde{O}(m/\varepsilon)$ work. We achieve this by developing and deploying suitable parallel linear cost approximators in conjunction with an accelerated continuous optimization framework known as the box-simplex game by Jambulapati et al. (ICALP 2022). A linear cost approximator is a linear operator that allows us to efficiently estimate the cost of the optimal solution to a given routing problem. Obtaining accelerated $\varepsilon$ dependencies for both problems requires developing a stronger multicommodity cost approximator, one where cancellations between different commodities are disallowed. For maximum flow, we observe that a recent linear cost approximator due to Agarwal et al. (SODA 2024) can be augmented with additional parallel operations and achieve $\varepsilon^{-1}$ dependency via the box-simplex game.
  For transshipment, we also obtain construct a deterministic and distributed approximator. This yields a deterministic CONGEST algorithm that requires $\tilde{O}(\varepsilon^{-1}(D + \sqrt{n}))$ rounds on general networks of hop diameter $D$ and $\tilde{O}(\varepsilon^{-1}D)$ rounds on minor-free networks to compute a $(1+\varepsilon)$-approximation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06581v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christoph Grunau, Rasmus Kyng, Goran Zuzic</dc:creator>
    </item>
    <item>
      <title>Revisiting Chazelle's Implementation of the Bottom-Left Heuristic: A Corrected and Rigorous Analysis</title>
      <link>https://arxiv.org/abs/2511.07008</link>
      <description>arXiv:2511.07008v1 Announce Type: new 
Abstract: The Strip Packing Problem is a classical optimization problem in which a given set of rectangles must be packed, without overlap, into a strip of fixed width and infinite height, while minimizing the total height of the packing. A straightforward and widely studied approach to this problem is the Bottom-Left Heuristic. It consists of iteratively placing each rectangle in the given order at the lowest feasible position in the strip and, in case of ties, at the leftmost of those. Due to its simplicity and good empirical performance, this heuristic is widely used in practical applications. The most efficient implementation of this heuristic was proposed by Chazelle in 1983, requiring $O(n^2)$ time and $O(n)$ space to place $n$ rectangles. However, although Chazelle's original description was largely correct, it omitted several formal details. Furthermore, our analysis revealed a critical flaw in the original runtime analysis, which, in certain cases, results in $\Omega(n^3)$ running time. Motivated by this finding, this paper provides a rigorous and corrected presentation of the implementation, addressing the imprecise arguments and resolving the identified flaw. The resulting analysis establishes a formally verified version of Chazelle's implementation and confirms its quadratic time complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07008v1</guid>
      <category>cs.DS</category>
      <category>cs.CG</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Stefan Michel</dc:creator>
    </item>
    <item>
      <title>Polynomial-time algorithms for PATH COVER and PATH PARTITION on trees and graphs of bounded treewidth</title>
      <link>https://arxiv.org/abs/2511.07160</link>
      <description>arXiv:2511.07160v1 Announce Type: new 
Abstract: In the PATH COVER problem, one asks to cover the vertices of a graph using the smallest possible number of (not necessarily disjoint) paths. While the variant where the paths need to be pairwise vertex-disjoint, which we call PATH PARTITION, is extensively studied, surprisingly little is known about PATH COVER. We start filling this gap by designing a linear-time algorithm for PATH COVER on trees.
  We show that PATH COVER can be solved in polynomial time on graphs of bounded treewidth using a dynamic programming scheme. It runs in XP time $n^{t^{O(t)}}$ (where $n$ is the number of vertices and $t$ the treewidth of the input graph) or $\kappa^{t^{O(t)}}n$ if there is an upper-bound $\kappa$ on the solution size. A similar algorithm gives an FPT $2^{O(t\log t)}n$ algorithm for PATH PARTITION, which can be improved to (randomized) $2^{O(t)}n$ using the Cut\&amp;Count technique. These results also apply to the variants where the paths are required to be induced (i.e. chordless) and/or edge-disjoint.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07160v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Florent Foucaud, Atrayee Majumder, Tobias M\"omke, Aida Roshany-Tabrizi</dc:creator>
    </item>
    <item>
      <title>A Fully Polynomial-Time Algorithm for Robustly Learning Halfspaces over the Hypercube</title>
      <link>https://arxiv.org/abs/2511.07244</link>
      <description>arXiv:2511.07244v1 Announce Type: new 
Abstract: We give the first fully polynomial-time algorithm for learning halfspaces with respect to the uniform distribution on the hypercube in the presence of contamination, where an adversary may corrupt some fraction of examples and labels arbitrarily. We achieve an error guarantee of $\eta^{O(1)}+\epsilon$ where $\eta$ is the noise rate. Such a result was not known even in the agnostic setting, where only labels can be adversarially corrupted. All prior work over the last two decades has a superpolynomial dependence in $1/\epsilon$ or succeeds only with respect to continuous marginals (such as log-concave densities).
  Previous analyses rely heavily on various structural properties of continuous distributions such as anti-concentration. Our approach avoids these requirements and makes use of a new algorithm for learning Generalized Linear Models (GLMs) with only a polylogarithmic dependence on the activation function's Lipschitz constant. More generally, our framework shows that supervised learning with respect to discrete distributions is not as difficult as previously thought.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07244v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gautam Chandrasekaran, Adam R. Klivans, Konstantinos Stavropoulos, Arsen Vasilyan</dc:creator>
    </item>
    <item>
      <title>A Learning Perspective on Random-Order Covering Problems</title>
      <link>https://arxiv.org/abs/2511.07283</link>
      <description>arXiv:2511.07283v1 Announce Type: new 
Abstract: In the random-order online set cover problem, the instance with $m$ sets and $n$ elements is chosen in a worst-case fashion, but then the elements arrive in a uniformly random order. Can this random-order model allow us to circumvent the bound of $O(\log m \log n)$-competitiveness for the adversarial arrival order model? This long-standing question was recently resolved by Gupta et al. (2021), who gave an algorithm that achieved an $O(\log mn)$-competitive ratio. While their LearnOrCover was inspired by ideas in online learning (and specifically the multiplicative weights update method), the analysis proceeded by showing progress from first principles.
  In this work, we show a concrete connection between random-order set cover and stochastic mirror-descent/online convex optimization. In particular, we show how additive/multiplicative regret bounds for the latter translate into competitiveness for the former. Indeed, we give a clean recipe for this translation, allowing us to extend our results to covering integer programs, set multicover, and non-metric facility location in the random order model, matching (and giving simpler proofs of) the previous applications of the LearnOrCover framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07283v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anupam Gupta, Marco Molinaro, Matteo Russo</dc:creator>
    </item>
    <item>
      <title>Dynamic Set Cover with Worst-Case Recourse</title>
      <link>https://arxiv.org/abs/2511.07354</link>
      <description>arXiv:2511.07354v1 Announce Type: new 
Abstract: In the dynamic set cover (SC) problem, the input is a dynamic universe of at most $n$ elements and a fixed collection of $m$ sets, where each element belongs to at most $f$ sets and each set has cost in $[1/C, 1]$. The objective is to efficiently maintain an approximate minimum SC under element updates; efficiency is primarily measured by the update time, but another important parameter is the recourse (number of changes to the solution per update). Ideally, one would like to achieve low worst-case bounds on both update time and recourse.
  One can achieve approximation $(1+\epsilon)\ln n$ (greedy-based) or $(1+\epsilon)f$ (primal-dual-based) with worst-case update time $O(f\log n)$ (ignoring $\epsilon$ dependencies). However, despite a large body of work, no algorithm with low update time (even amortized) and nontrivial worst-case recourse is known, even for unweighted instances ($C = 1$)!
  We remedy this by providing a transformation that, given as a black-box a SC algorithm with approximation $\alpha$ and update time $T$, returns a set cover algorithm with approximation $(2 + \epsilon)\alpha$, update time $O(T + \alpha C)$, and worst-case recourse $O(\alpha C)$. Our main results are obtained by leveraging this transformation for constant $C$:...</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07354v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shay Solomon, Amitai Uzrad</dc:creator>
    </item>
    <item>
      <title>Halfspaces are hard to test with relative error</title>
      <link>https://arxiv.org/abs/2511.06171</link>
      <description>arXiv:2511.06171v1 Announce Type: cross 
Abstract: Several recent works [DHLNSY25, CPPS25a, CPPS25b] have studied a model of property testing of Boolean functions under a \emph{relative-error} criterion. In this model, the distance from a target function $f: \{0,1\}^n \to \{0,1\}$ that is being tested to a function $g$ is defined relative to the number of inputs $x$ for which $f(x)=1$; moreover, testing algorithms in this model have access both to a black-box oracle for $f$ and to independent uniform satisfying assignments of $f$. The motivation for this model is that it provides a natural framework for testing \emph{sparse} Boolean functions that have few satisfying assignments, analogous to well-studied models for property testing of sparse graphs.
  The main result of this paper is a lower bound for testing \emph{halfspaces} (i.e., linear threshold functions) in the relative error model: we show that $\tilde{\Omega}(\log n)$ oracle calls are required for any relative-error halfspace testing algorithm over the Boolean hypercube $\{0,1\}^n$. This stands in sharp contrast both with the constant-query testability (independent of $n$) of halfspaces in the standard model [MORS10], and with the positive results for relative-error testing of many other classes given in [DHLNSY25, CPPS25a, CPPS25b]. Our lower bound for halfspaces gives the first example of a well-studied class of functions for which relative-error testing is provably more difficult than standard-model testing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06171v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xi Chen, Anindya De, Yizhi Huang, Shivam Nadimpalli, Rocco A. Servedio, Tianqi Yang</dc:creator>
    </item>
    <item>
      <title>Sparse Linear Regression is Easy on Random Supports</title>
      <link>https://arxiv.org/abs/2511.06211</link>
      <description>arXiv:2511.06211v1 Announce Type: cross 
Abstract: Sparse linear regression is one of the most basic questions in machine learning and statistics. Here, we are given as input a design matrix $X \in \mathbb{R}^{N \times d}$ and measurements or labels ${y} \in \mathbb{R}^N$ where ${y} = {X} {w}^* + {\xi}$, and ${\xi}$ is the noise in the measurements. Importantly, we have the additional constraint that the unknown signal vector ${w}^*$ is sparse: it has $k$ non-zero entries where $k$ is much smaller than the ambient dimension. Our goal is to output a prediction vector $\widehat{{w}}$ that has small prediction error: $\frac{1}{N}\cdot \|{X} {w}^* - {X} \widehat{{w}}\|^2_2$.
  Information-theoretically, we know what is best possible in terms of measurements: under most natural noise distributions, we can get prediction error at most $\epsilon$ with roughly $N = O(k \log d/\epsilon)$ samples. Computationally, this currently needs $d^{\Omega(k)}$ run-time. Alternately, with $N = O(d)$, we can get polynomial-time. Thus, there is an exponential gap (in the dependence on $d$) between the two and we do not know if it is possible to get $d^{o(k)}$ run-time and $o(d)$ samples.
  We give the first generic positive result for worst-case design matrices ${X}$: For any ${X}$, we show that if the support of ${w}^*$ is chosen at random, we can get prediction error $\epsilon$ with $N = \text{poly}(k, \log d, 1/\epsilon)$ samples and run-time $\text{poly}(d,N)$. This run-time holds for any design matrix ${X}$ with condition number up to $2^{\text{poly}(d)}$.
  Previously, such results were known for worst-case ${w}^*$, but only for random design matrices from well-behaved families, matrices that have a very low condition number ($\text{poly}(\log d)$; e.g., as studied in compressed sensing), or those with special structural properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06211v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gautam Chandrasekaran, Raghu Meka, Konstantinos Stavropoulos</dc:creator>
    </item>
    <item>
      <title>Nearly-Optimal Private Selection via Gaussian Mechanism</title>
      <link>https://arxiv.org/abs/2511.06871</link>
      <description>arXiv:2511.06871v1 Announce Type: cross 
Abstract: Steinke (2025) recently asked the following intriguing open question: Can we solve the differentially private selection problem with nearly-optimal error by only (adaptively) invoking Gaussian mechanism on low-sensitivity queries? We resolve this question positively. In particular, for a candidate set $\mathcal{Y}$, we achieve error guarantee of $\tilde{O}(\log |\mathcal{Y}|)$, which is within a factor of $(\log \log |\mathcal{Y}|)^{O(1)}$ of the exponential mechanism (McSherry and Talwar, 2007). This improves on Steinke's mechanism which achieves an error of $O(\log^{3/2} |\mathcal{Y}|)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06871v1</guid>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ethan Leeman, Pasin Manurangsi</dc:creator>
    </item>
    <item>
      <title>On Subexponential Parameterized Algorithms for Steiner Tree on Intersection Graphs of Geometric Objects</title>
      <link>https://arxiv.org/abs/2511.07346</link>
      <description>arXiv:2511.07346v1 Announce Type: cross 
Abstract: We study the Steiner Tree problem on the intersection graph of most natural families of geometric objects, e.g., disks, squares, polygons, etc. Given a set of $n$ objects in the plane and a subset $T$ of $t$ terminal objects, the task is to find a subset $S$ of $k$ objects such that the intersection graph of $S\cup T$ is connected. Given how typical parameterized problems behave on planar graphs and geometric intersection graphs, we would expect that exact algorithms with some form of subexponential dependence on the solution size or the number of terminals exist. Contrary to this expectation, we show that, assuming the Exponential-Time Hypothesis (ETH), there is no $2^{o(k+t)}\cdot n^{O(1)}$ time algorithm even for unit disks or unit squares, that is, there is no FPT algorithm subexponential in the size of the Steiner tree. However, subexponential dependence can appear in a different form: we show that Steiner Tree can be solved in time $n^{O(\sqrt{t})}$ for many natural classes of objects, including: Disks of arbitrary size. Axis-parallel squares of arbitrary size. Similarly-sized fat polygons.
  This in particular significantly improves and generalizes two recent results: (1) Steiner Tree on unit disks can be solved in time $n^{\Oh(\sqrt{k + t})}$ (Bhore, Carmi, Kolay, and Zehavi, Algorithmica 2023) and (2) Steiner Tree on planar graphs can be solved in time $n^{O(\sqrt{t})}$ (Marx, Pilipczuk, and Pilipczuk, FOCS 2018). We complement our algorithms with lower bounds that demonstrate that the class of objects cannot be significantly extended, even if we allow the running time to be $n^{o(k+t)/\log(k+t)}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07346v1</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sujoy Bhore, Baris Can Esmer, Daniel Marx, Karol Wegrzycki</dc:creator>
    </item>
    <item>
      <title>The Landscape of Almost Equitable Allocations</title>
      <link>https://arxiv.org/abs/2511.07395</link>
      <description>arXiv:2511.07395v1 Announce Type: cross 
Abstract: Equitability is a fundamental notion in fair division which requires that all agents derive equal value from their allocated bundles. We study, for general (possibly non-monotone) valuations, a popular relaxation of equitability known as equitability up to one item (EQ1). An EQ1 allocation may fail to exist even with additive non-monotone valuations; for instance, when there are two agents, one valuing every item positively and the other negatively. This motivates a mild and natural assumption: all agents agree on the sign of their value for the grand bundle. Under this assumption, we prove the existence and provide an efficient algorithm for computing EQ1 allocations for two agents with general valuations. When there are more than two agents, we show the existence and polynomial-time computability of EQ1 allocations for valuation classes beyond additivity and monotonicity, in particular for (1) doubly monotone valuations and (2) submodular (resp. supermodular) valuations where the value for the grand bundle is nonnegative (resp. nonpositive) for all agents. Furthermore, we settle an open question of Bil`o et al. by showing that an EQ1 allocation always exists for nonnegative(resp. nonpositive) valuations, i.e., when every agent values each subset of items nonnegatively (resp. nonpositively). Finally, we complete the picture by showing that for general valuations with more than two agents, EQ1 allocations may not exist even when agents agree on the sign of the grand bundle, and that deciding the existence of an EQ1 allocation is computationally intractable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07395v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hadi Hosseini, Vishwa Prakash HV, Aditi Sethia, Jatin Yadav</dc:creator>
    </item>
    <item>
      <title>Language Generation with Infinite Contamination</title>
      <link>https://arxiv.org/abs/2511.07417</link>
      <description>arXiv:2511.07417v1 Announce Type: cross 
Abstract: We study language generation in the limit, where an algorithm observes an adversarial enumeration of strings from an unknown target language $K$ and must eventually generate new, unseen strings from $K$. Kleinberg and Mullainathan [KM24] proved that generation is achievable in surprisingly general settings. But their generator suffers from ``mode collapse,'' producing from an ever-smaller subset of the target. To address this, Kleinberg and Wei [KW25] require the generator's output to be ``dense'' in the target language. They showed that generation with density, surprisingly, remains achievable at the same generality.
  Both results assume perfect data: no noisy insertions and no omissions. This raises a central question: how much contamination can generation tolerate? Recent works made partial progress on this question by studying (non-dense) generation with either finite amounts of noise (but no omissions) or omissions (but no noise).
  We characterize robustness under contaminated enumerations: 1. Generation under Contamination: Language generation in the limit is achievable for all countable collections iff the fraction of contaminated examples converges to zero. When this fails, we characterize which collections are generable. 2. Dense Generation under Contamination: Dense generation is strictly less robust to contamination than generation. As a byproduct, we resolve an open question of Raman and Raman [ICML25] by showing that generation is possible with only membership oracle access under finitely many contaminated examples.
  Finally, we introduce a beyond-worst-case model inspired by curriculum learning and prove that dense generation is achievable even with infinite contamination provided the fraction of contaminated examples converges to zero. This suggests curriculum learning may be crucial for learning from noisy web data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07417v1</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anay Mehrotra, Grigoris Velegkas, Xifan Yu, Felix Zhou</dc:creator>
    </item>
    <item>
      <title>JumpBackHash: Say Goodbye to the Modulo Operation to Distribute Keys Uniformly to Buckets</title>
      <link>https://arxiv.org/abs/2403.18682</link>
      <description>arXiv:2403.18682v3 Announce Type: replace 
Abstract: Introduction. Distributed data processing and storage systems require efficient methods to distribute keys across buckets. While simple and fast, the traditional modulo-based mapping is unstable when the number of buckets changes, leading to spikes in system resource utilization, such as network or database requests. Consistent hash algorithms minimize remappings but are either significantly slower, require floating-point arithmetic, or are based on a family of hash functions rarely available in standard libraries. This work introduces JumpBackHash, a consistent hash algorithm that overcomes those shortcomings.
  Methodology. JumpBackHash applies the concept of active indices borrowed from consistent weighted sampling, which inherently leads to consistency. It generates the active indices in reverse order, which avoids floating-point operations, enables the minimization of consumed random values and the use of a standard pseudorandom generator, and finally leads to a very efficient algorithm.
  Results. Theoretical analysis shows that JumpBackHash has an expected constant runtime. The expected value and the variance of the number of consumed random values perfectly agree with the experiments. Empirical tests also confirm the consistency.
  Conclusion. JumpBackHash offers a fast and efficient solution for uniformly distributing keys across buckets in distributed systems. Its simplicity, performance, and the availability of a production-ready Java implementation as part of the Hash4j open source library make it a viable replacement for the modulo-based approach for improving assignment and system stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18682v3</guid>
      <category>cs.DS</category>
      <category>cs.DB</category>
      <category>cs.DC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1002/spe.3385</arxiv:DOI>
      <dc:creator>Otmar Ertl</dc:creator>
    </item>
    <item>
      <title>PCF Learned Sort: a Learning Augmented Sort Algorithm with $O(n \log\log n)$ Expected Complexity</title>
      <link>https://arxiv.org/abs/2405.07122</link>
      <description>arXiv:2405.07122v3 Announce Type: replace 
Abstract: Sorting is one of the most fundamental algorithms in computer science. Recently, Learned Sorts, which use machine learning to improve sorting speed, have attracted attention. While existing studies show that Learned Sort is empirically faster than classical sorting algorithms, they do not provide theoretical guarantees about its computational complexity. We propose Piecewise Constant Function (PCF) Learned Sort, a theoretically guaranteed Learned Sort algorithm. We prove that the expected complexity of PCF Learned Sort is $\mathcal{O}(n \log \log n)$ under mild assumptions on the data distribution. We also confirm empirically that PCF Learned Sort has a computational complexity of $\mathcal{O}(n \log \log n)$ on both synthetic and real datasets. This is the first study to theoretically support the empirical success of Learned Sort, and provides evidence for why Learned Sort is fast. The code is available at https://github.com/atsukisato/PCF_Learned_Sort .</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07122v3</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Atsuki Sato, Yusuke Matsui</dc:creator>
    </item>
    <item>
      <title>Pointwise Lipschitz Continuous Graph Algorithms</title>
      <link>https://arxiv.org/abs/2405.08938</link>
      <description>arXiv:2405.08938v4 Announce Type: replace 
Abstract: In many real-world applications, it is undesirable to drastically change the problem solution after a small perturbation in the input, as unstable outputs can lead to costly transaction fees, privacy and security concerns, reduced user trust, and lack of replicability. Despite the widespread application of graph algorithms, many classical algorithms are not robust to small input disturbances. Towards addressing this issue, we study the pointwise Lipschitz continuity of graph algorithms, a notion of stability introduced by Kumabe and Yoshida [KY23, FOCS'23] and further studied in related settings [KY24, ICALP'24], [KY25, SODA'25], [GKY25, ESA'25].
  Our main result is a linear programming (LP) based minimum $S$-$T$ cut algorithm with a provably optimal Lipschitz constant, as witnessed by an accompanying lower bound. As a direct corollary, we give the first dynamic minimum $S$-$T$ cut algorithm with non-trivial recourse bound. At the core of our techniques is a novel framework for analyzing the Lipschitz constant of regularized LP relaxations. Our framework crucially unlocks the use of weighted regularizers, which could not be analyzed through previous methods, and leads to polynomial improvements in the Lipschitz constant compared to what is achievable through previous techniques. To demonstrate the flexibility of our methods, we also design an LP-based $b$-matching algorithm that improves on the state-of-the-art [KY23] Lipschitz constant in certain input regimes when $b\equiv 1$. Moreover, our algorithm cleanly extends to the general case when $b\geq 1$, whereas [KY23] is specialized to the case of $b\equiv 1$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.08938v4</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Quanquan C. Liu, Grigoris Velegkas, Yuichi Yoshida, Felix Zhou</dc:creator>
    </item>
    <item>
      <title>Estimating Random-Walk Probabilities in Directed Graphs</title>
      <link>https://arxiv.org/abs/2504.16481</link>
      <description>arXiv:2504.16481v3 Announce Type: replace 
Abstract: We study discounted random walks in directed graphs. In each step, the walk either terminates with a constant probability $\alpha$, or proceeds to a random out-neighbor. Our goal is to estimate the probability $\pi(s, t)$ that a discounted random walk starting from $s$ terminates at $t$. This probability is also known as the Personalized PageRank (PPR) score, which measures the relevance of $t$ to $s$, for instance, when $s$ and $t$ are web pages on the Internet. We aim to estimate $\pi(s, t)$ within a constant relative error with constant probability.
  A variety of algorithms have been developed for several problem variants, such as single-pair, single-source, single-target, and single-node estimation, under both worst-case and average-case settings, and for different combinations of allowed graph queries. However, in many important cases, there remain polynomial gaps between known upper and lower bounds.
  In this paper, we establish tight bounds for all problem variants and query combinations, closing all existing gaps in both the worst-case and average-case settings. We provide tight (up to logarithmic factors) lower bounds, showing that for all but one query combination, existing algorithms are already optimal.
  For the remaining case, we design a novel algorithm that matches our new lower bound, thereby achieving optimality. This is the first algorithm to exploit this specific query combination. It uses a new randomized bidirectional framework that combines randomized backward propagation with selective Monte Carlo estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16481v3</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian Bertram, Mads Vestergaard Jensen, Mikkel Thorup, Hanzhi Wang, Shuyi Yan</dc:creator>
    </item>
    <item>
      <title>Towards universally optimal sorting algorithms</title>
      <link>https://arxiv.org/abs/2506.08261</link>
      <description>arXiv:2506.08261v2 Announce Type: replace 
Abstract: We formalize a new paradigm for optimality of algorithms, that generalizes worst-case optimality based only on input-size to problem-dependent parameters including implicit ones. We re-visit some existing sorting algorithms from this perspective, and also present a novel measure of sortedness that leads to an optimal algorithm based on partition sort. This paradigm of measuring efficiency of algorithms looks promising for further interesting applications beyond the existing ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08261v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sandeep Sen</dc:creator>
    </item>
    <item>
      <title>Improved Directed Expander Decompositions</title>
      <link>https://arxiv.org/abs/2507.09729</link>
      <description>arXiv:2507.09729v2 Announce Type: replace 
Abstract: We obtain faster expander decomposition algorithms for directed graphs, matching the guarantees of Saranurak and Wang (SODA 2019) for expander decomposition on undirected graphs. Our algorithms are faster than prior work and also generalize almost losslessly to capacitated graphs. In particular, we obtain the first directed expander decomposition algorithm for capacitated graphs in near-linear time with optimal dependence on $\phi$.
  To obtain our result, we provide the first implementation and analysis of the non-stop cut-matching game for directed, capacitated graphs. All existing directed expander decomposition algorithms instead temporarily add ''fake edges'' before pruning them away in a final cleanup step. Our result shows that the natural undirected approach applies even to directed graphs. The difficulty is in its analysis, which is technical and requires significant modifications from the original setting of undirected graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09729v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Henry Fleischmann, George Z. Li, Jason Li</dc:creator>
    </item>
    <item>
      <title>Fully Dynamic Euclidean k-Means</title>
      <link>https://arxiv.org/abs/2507.11256</link>
      <description>arXiv:2507.11256v3 Announce Type: replace 
Abstract: We consider the fundamental Euclidean $k$-means clustering problem in a dynamic setting, where the input $X \subseteq \mathbb{R}^d$ evolves over time via a sequence of point insertions/deletions. We have to explicitly maintain a solution (a set of $k$ centers) $S \subseteq \mathbb{R}^d$ throughout these updates, while minimizing the approximation ratio, the update time (time taken to handle a point insertion/deletion) and the recourse (number of changes made to the solution $S$) of the algorithm.
  We present a dynamic algorithm for this problem with $\text{poly}(1/\epsilon)$-approximation ratio, $\tilde{O}(k^{\epsilon})$ update time and $\tilde{O}(1)$ recourse. In the general regime, where the dimension $d$ cannot be assumed to be a fixed constant, our algorithm has almost optimal guarantees across all these three parameters. Indeed, improving our update time or approximation ratio would imply beating the state-of-the-art static algorithm for this problem (which is widely believed to be the best possible), and the recourse of any dynamic algorithm must be $\Omega(1)$.
  We obtain our result by building on top of the recent work of [Bhattacharya, Costa, Farokhnejad; STOC'25], which gave a near-optimal dynamic algorithm for $k$-means in general metric spaces (as opposed to in the Euclidean setting). Along the way, we design several novel geometric data structures that are of independent interest. Specifically, one of our main contributions is designing the first consistent hashing scheme [Czumaj, Jiang, Krauthgamer, Vesel\'y, Yang; FOCS'22] that achieves $\tilde O(n^\epsilon)$ running time per point evaluation with competitive parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11256v3</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sayan Bhattacharya, Mart\'in Costa, Ermiya Farokhnejad, Shaofeng H. -C. Jiang, Yaonan Jin, Jianing Lou</dc:creator>
    </item>
    <item>
      <title>Online Combinatorial Optimization with Graphical Dependencies</title>
      <link>https://arxiv.org/abs/2507.16031</link>
      <description>arXiv:2507.16031v2 Announce Type: replace 
Abstract: Most existing work in online stochastic combinatorial optimization assumes that inputs are drawn from independent distributions -- a strong assumption that often fails in practice. At the other extreme, arbitrary correlations are equivalent to worst-case inputs via Yao's minimax principle, making good algorithms often impossible. This motivates the study of intermediate models that capture mild correlations while still permitting non-trivial algorithms.
  In this paper, we study online combinatorial optimization under Markov Random Fields (MRFs), a well-established graphical model for structured dependencies. MRFs parameterize correlation strength via the maximum weighted degree $\Delta$, smoothly interpolating between independence ($\Delta = 0$) and full correlation ($\Delta \to \infty$). While na\"ively this yields $e^{O(\Delta)}$-competitive algorithms and $\Omega(\Delta)$ hardness, we ask: when can we design tight $\Theta(\Delta)$-competitive algorithms?
  We present general techniques achieving $O(\Delta)$-competitive algorithms for both minimization and maximization problems under MRF-distributed inputs. For minimization problems with coverage constraints (e.g., Facility Location and Steiner Tree), we reduce to the well-studied $p$-sample model. For maximization problems (e.g., matchings and combinatorial auctions with XOS buyers), we extend the "balanced prices" framework for online allocation problems to MRFs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.16031v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhimeng Gao, Evangelia Gergatsouli, Kalen Patton, Sahil Singla</dc:creator>
    </item>
    <item>
      <title>Explicit Min-wise Hash Families with Optimal Size</title>
      <link>https://arxiv.org/abs/2510.10431</link>
      <description>arXiv:2510.10431v3 Announce Type: replace 
Abstract: We study explicit constructions of min-wise hash families and their extension to $k$-min-wise hash families. Informally, a min-wise hash family guarantees that for any fixed subset $X\subseteq[N]$, every element in $X$ has an equal chance to have the smallest value among all elements in $X$; a $k$-min-wise hash family guarantees this for every subset of size $k$ in $X$. Min-wise hash is widely used in many areas of computer science such as sketching, web page detection, and $\ell_0$ sampling.
  The classical works by Indyk and P\u{a}tra\c{s}cu and Thorup have shown $\Theta(\log(1/\delta))$-wise independent families give min-wise hash of multiplicative (relative) error $\delta$, resulting in a construction with $\Theta(\log(1/\delta)\log N)$ random bits. Based on a reduction from pseudorandom generators for combinatorial rectangles by Saks, Srinivasan, Zhou and Zuckerman, Gopalan and Yehudayoff improved the number of bits to $O(\log N\log\log N)$ for polynomially small errors $\delta$. However, no construction with $O(\log N)$ bits (polynomial size family) and sub-constant error was known before.
  In this work, we continue and extend the study of constructing ($k$-)min-wise hash families from pseudorandomness for combinatorial rectangles and read-once branching programs. Our main result gives the first explicit min-wise hash families that use an optimal (up to constant) number of random bits and achieve a sub-constant (in fact, almost polynomially small) error, specifically, an explicit family of $k$-min-wise hash with $O(k\log N)$ bits and $2^{-O(\log N/\log\log N)}$ error. This improves all previous results for any $k=\log^{O(1)}N$ under $O(k \log N)$ bits. Our main techniques involve several new ideas to adapt the classical Nisan-Zuckerman pseudorandom generator to fool min-wise hashing with a multiplicative error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.10431v3</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xue Chen, Shengtang Huang, Xin Li</dc:creator>
    </item>
    <item>
      <title>Multipartite Entanglement Distribution in Quantum Networks using Subgraph Complementations</title>
      <link>https://arxiv.org/abs/2308.13700</link>
      <description>arXiv:2308.13700v5 Announce Type: replace-cross 
Abstract: Quantum networks are important for quantum communication, enabling tasks such as quantum teleportation, quantum key distribution, quantum sensing, and quantum error correction, often utilizing graph states, a specific class of multipartite entangled states that can be represented by graphs. We propose a novel approach for distributing graph states across a quantum network. We show that the distribution of graph states can be characterized by a system of subgraph complementations, which we also relate to the minimum rank of the underlying graph and the degree of entanglement quantified by the Schmidt-rank of the quantum state. We analyze resource usage for our algorithm and show that it improves on the number of qubits, bits for classical communication, and EPR pairs utilized, as compared to prior work. In fact, the number of local operations and resource consumption for our approach scales linearly in the number of vertices. This produces a quadratic improvement in completion time for several classes of graph states represented by dense graphs, which translates into an exponential improvement by allowing parallelization of gate operations. This leads to improved fidelities in the presence of noisy operations, as we show through simulation in the presence of noisy operations. We classify common classes of graph states, along with their optimal distribution time using subgraph complementations. We find a sequence of subgraph complementation operations to distribute an arbitrary graph state which we conjecture is close to the optimal sequence, and establish upper bounds on distribution time along with providing approximate greedy algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.13700v5</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.NI</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aniruddha Sen, Kenneth Goodenough, Don Towsley</dc:creator>
    </item>
    <item>
      <title>Sparsifying Suprema of Gaussian Processes</title>
      <link>https://arxiv.org/abs/2411.14664</link>
      <description>arXiv:2411.14664v2 Announce Type: replace-cross 
Abstract: We give a dimension-independent sparsification result for suprema of centered Gaussian processes: Let $T$ be any (possibly infinite) bounded set of vectors in $\mathbb{R}^n$, and let $\{\boldsymbol{X}_t := t \cdot \boldsymbol{g} \}_{t\in T}$ be the canonical Gaussian process on $T$, where $\boldsymbol{g}\sim N(0, I_n)$. We show that there is an $O_\varepsilon(1)$-size subset $S \subseteq T$ and a set of real values $\{c_s\}_{s \in S}$ such that the random variable $\sup_{s \in S} \{{\boldsymbol{X}}_s + c_s\}$ is an $\varepsilon$-approximator\,(in $L^1$) of the random variable $\sup_{t \in T} {\boldsymbol{X}}_t$. Notably, the size of the sparsifier $S$ is completely independent of both $|T|$ and the ambient dimension $n$.
  We give two applications of this sparsification theorem:
  - A "Junta Theorem" for Norms: We show that given any norm $\nu(x)$ on $\mathbb{R}^n$, there is another norm $\psi(x)$ depending only on the projection of $x$ onto $O_\varepsilon(1)$ directions, for which $\psi({\boldsymbol{g}})$ is a multiplicative $(1 \pm \varepsilon)$-approximation of $\nu({\boldsymbol{g}})$ with probability $1-\varepsilon$ for ${\boldsymbol{g}} \sim N(0,I_n)$.
  - Sparsification of Convex Sets: We show that any intersection of (possibly infinitely many) halfspaces in $\mathbb{R}^n$ that are at distance $r$ from the origin is $\varepsilon$-close (under $N(0,I_n)$) to an intersection of only $O_{r,\varepsilon}(1)$ halfspaces. This yields new polynomial-time \emph{agnostic learning} and \emph{tolerant property testing} algorithms for intersections of halfspaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14664v2</guid>
      <category>stat.ML</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anindya De, Shivam Nadimpalli, Ryan O'Donnell, Rocco A. Servedio</dc:creator>
    </item>
    <item>
      <title>Private Statistical Estimation via Truncation</title>
      <link>https://arxiv.org/abs/2505.12541</link>
      <description>arXiv:2505.12541v2 Announce Type: replace-cross 
Abstract: We introduce a novel framework for differentially private (DP) statistical estimation via data truncation, addressing a key challenge in DP estimation when the data support is unbounded. Traditional approaches rely on problem-specific sensitivity analysis, limiting their applicability. By leveraging techniques from truncated statistics, we develop computationally efficient DP estimators for exponential family distributions, including Gaussian mean and covariance estimation, achieving near-optimal sample complexity. Previous works on exponential families only consider bounded or one-dimensional families. Our approach mitigates sensitivity through truncation while carefully correcting for the introduced bias using maximum likelihood estimation and DP stochastic gradient descent. Along the way, we establish improved uniform convergence guarantees for the log-likelihood function of exponential families, which may be of independent interest. Our results provide a general blueprint for DP algorithm design via truncated statistics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12541v2</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>stat.ML</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Manolis Zampetakis, Felix Zhou</dc:creator>
    </item>
    <item>
      <title>Matchings Under Biased and Correlated Evaluations</title>
      <link>https://arxiv.org/abs/2510.23628</link>
      <description>arXiv:2510.23628v2 Announce Type: replace-cross 
Abstract: We study a two-institution stable matching model in which candidates from two distinct groups are evaluated using partially correlated signals that are group-biased. This extends prior work (which assumes institutions evaluate candidates in an identical manner) to a more realistic setting in which institutions rely on overlapping, but independently processed, criteria. These evaluations could consist of a variety of informative tools such as standardized tests, shared recommendation systems, or AI-based assessments with local noise. Two key parameters govern evaluations: the bias parameter $\beta \in (0,1]$, which models systematic disadvantage faced by one group, and the correlation parameter $\gamma \in [0,1]$, which captures the alignment between institutional rankings. We study the representation ratio, i.e., the ratio of disadvantaged to advantaged candidates selected by the matching process in this setting. Focusing on a regime in which all candidates prefer the same institution, we characterize the large-market equilibrium and derive a closed-form expression for the resulting representation ratio. Prior work shows that when $\gamma = 1$, this ratio scales linearly with $\beta$. In contrast, we show that the representation ratio increases nonlinearly with $\gamma$ and even modest losses in correlation can cause sharp drops in the representation ratio. Our analysis identifies critical $\gamma$-thresholds where institutional selection behavior undergoes discrete transitions, and reveals structural conditions under which evaluator alignment or bias mitigation are most effective. Finally, we show how this framework and results enable interventions for fairness-aware design in decentralized selection systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23628v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.CY</category>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amit Kumar, Nisheeth K. Vishnoi</dc:creator>
    </item>
  </channel>
</rss>
