<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 21 May 2025 01:49:31 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Accelerating Natural Gradient Descent for PINNs with Randomized Numerical Linear Algebra</title>
      <link>https://arxiv.org/abs/2505.11638</link>
      <description>arXiv:2505.11638v2 Announce Type: new 
Abstract: Natural Gradient Descent (NGD) has emerged as a promising optimization algorithm for training neural network-based solvers for partial differential equations (PDEs), such as Physics-Informed Neural Networks (PINNs). However, its practical use is often limited by the high computational cost of solving linear systems involving the Gramian matrix. While matrix-free NGD methods based on the conjugate gradient (CG) method avoid explicit matrix inversion, the ill-conditioning of the Gramian significantly slows the convergence of CG. In this work, we extend matrix-free NGD to broader classes of problems than previously considered and propose the use of Randomized Nystr\"om preconditioning to accelerate convergence of the inner CG solver. The resulting algorithm demonstrates substantial performance improvements over existing NGD-based methods on a range of PDE problems discretized using neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11638v2</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ivan Bioli, Carlo Marcati, Giancarlo Sangalli</dc:creator>
    </item>
    <item>
      <title>A parameterized Wasserstein Hamiltonian flow approach for solving the Schr\"odinger equation</title>
      <link>https://arxiv.org/abs/2505.11762</link>
      <description>arXiv:2505.11762v1 Announce Type: new 
Abstract: In this paper, we propose a new method to compute the solution of time-dependent Schr\"odinger equation (TDSE). Using push-forward maps and Wasserstein Hamiltonian flow, we reformulate the TDSE as a Hamiltonian system in terms of push-forward maps. The new formulation can be viewed as a generative model in the Wasserstein space, which is a manifold of probability density functions. Then we parameterize the push-forward maps by reduce-order models such as neural networks. This induces a new metric in the parameter space by pulling back the Wasserstein metric on density manifold, which further results in a system of ordinary differential equations (ODEs) for the parameters of the reduce-order model. Leveraging the computational techniques from deep learning, such as Neural ODE, we design an algorithm to solve the TDSE in the parameterized push-forward map space, which provides an alternative approach with the potential to scale up to high-dimensional problems. Several numerical examples are presented to demonstrate the performance of this algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11762v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Wu, Shu Liu, Xiaojing Ye, Haomin Zhou</dc:creator>
    </item>
    <item>
      <title>Identifying convex obstacles from backscattering far field data</title>
      <link>https://arxiv.org/abs/2505.11850</link>
      <description>arXiv:2505.11850v1 Announce Type: new 
Abstract: The recovery of anomalies from backscattering far field data is a long-standing open problem in inverse scattering theory. We make a first step in this direction by establishing the unique identifiability of convex impenetrable obstacles from backscattering far field measurements. Specifically, we prove that both the boundary and the boundary conditions of the convex obstacle are uniquely determined by the far field pattern measured in backscattering directions for all frequencies. The key tool is Majda's asymptotic estimate of the far field patterns in the high-frequency regime. Furthermore, we introduce a fast and stable numerical algorithm for reconstructing the boundary and computing the boundary condition. A key feature of the algorithm is that the boundary condition can be computed even if the boundary is not known, and vice versa. Numerical experiments demonstrate the validity and robustness of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11850v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jialei Li, Xiaodong Liu, Qingxiang Shi</dc:creator>
    </item>
    <item>
      <title>Numerical reconstructions of a source term in a mobile-immobile diffusion model from the partial interior observation</title>
      <link>https://arxiv.org/abs/2505.11869</link>
      <description>arXiv:2505.11869v1 Announce Type: new 
Abstract: We consider an inverse source problem in the two-time-scale mobile-immobile fractional diffusion model from partial interior observation. Theoretically, we combine the fractional Duhamel's principle with the weak vanishing property to establish the uniqueness of this inverse problem. Numerically, we adopt an optimal control approach for determining the source term. A coupled forward-backward system of equations is derived using the first-order optimality condition. Finally, we construct a finite element conjugate gradient algorithm for the numerical inversion of the source term. Several experiments are presented to show the utility of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11869v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiwei Yang, Yikan Liu</dc:creator>
    </item>
    <item>
      <title>Stable Nonlinear Dynamical Approximation with Dynamical Sampling</title>
      <link>https://arxiv.org/abs/2505.11938</link>
      <description>arXiv:2505.11938v1 Announce Type: new 
Abstract: We present a nonlinear dynamical approximation method for time-dependent Partial Differential Equations (PDEs). The approach makes use of parametrized decoder functions, and provides a general, and principled way of understanding and analyzing stability and accuracy of nonlinear dynamical approximations. The parameters of these functions are evolved in time by means of projections on finite dimensional subspaces of an ambient Hilbert space related to the PDE evolution. For practical computations of these projections, one usually needs to sample. We propose a dynamical sampling strategy which comes with stability guarantees, while keeping a low numerical complexity. We show the effectiveness of the method on several examples in moderate spatial dimension.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11938v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daan Bon, Benjamin Caris, Olga Mula</dc:creator>
    </item>
    <item>
      <title>An Immersed Finite Element Method for Anisotropic Elliptic Interface Problems with Nonhomogeneous Jump Conditions</title>
      <link>https://arxiv.org/abs/2505.11961</link>
      <description>arXiv:2505.11961v1 Announce Type: new 
Abstract: A new finite element method (FEM) using meshes that do not necessarily align with the interface is developed for two- and three-dimensional anisotropic elliptic interface problems with nonhomogeneous jump conditions. The degrees of freedom of the proposed method are the same as those of traditional nonconforming FEMs, while the function space is modified to account for the jump conditions of the solution. The modified function space on an interface element is shown to exist uniquely, independent of the element's shape and the manner in which the interface intersects it. Optimal error estimates for the method, along with the usual bound on the condition number of the stiffness matrix, are proven, with the error constant independent of the interface's location relative to the mesh. To solve the resulting linear system, a preconditioner is proposed in which a Gauss-Seidel smoother with the interface correction is employed to ensure robustness against large jumps in the diffusion matrix. Numerical experiments are provided to demonstrate the optimal convergence of the proposed method and the efficiency of the preconditioner.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11961v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haifeng Ji, Zhilin Li</dc:creator>
    </item>
    <item>
      <title>Numerical Integrators for Mechanical Systems on Lie Groups</title>
      <link>https://arxiv.org/abs/2505.12103</link>
      <description>arXiv:2505.12103v1 Announce Type: new 
Abstract: Retraction maps are known to be the seed for all numerical integrators. These retraction maps-based integrators can be further lifted to tangent and cotangent bundles, giving rise to structure-preserving integrators for mechanical systems. We explore the particular case where the configuration space of our mechanical system is a Lie group with certain symmetries. Here, the integrator simplifies based on the property that the tangent and cotangent bundles of Lie groups are trivializable. Finally, we present a framework for designing numerical integrators for Euler- Poincare and Lie-Poisson type equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12103v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.DG</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Viyom Vivek, David Martin de Diego, Ravi N Banavar</dc:creator>
    </item>
    <item>
      <title>Propagation of chaos and approximation error of random batch particle system in the mean field regime</title>
      <link>https://arxiv.org/abs/2505.12172</link>
      <description>arXiv:2505.12172v1 Announce Type: new 
Abstract: The random batch method [J. Comput. Phys. 400 (2020) 108877] is not only an efficient algorithm for simulation of classical $N$-particle systems and their mean-field limit, but also a new model for interacting particle system that could be more physical in some applications. In this work, we establish the propagation of chaos for the random batch particle system and at the same time obtain its sharp approximation error to the classical mean field limit of $N$-particle systems. The proof leverages the BBGKY hierarchy and achieves a sharp bound both in the particle number $N$ and the time step $\tau$. In particular, by introducing a coupling of the division of the random batches to resolve the $N$-dependence, we derive an $\mathcal{O}(k^2/N^2 + k\tau^2)$ bound on the $k$-particle relative entropy between the law of the system and the tensorized law of the mean-field limit. This result provides a useful understanding of the convergence properties of the random batch system in the mean field regime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12172v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Li, Yuelin Wang, Shi Jin</dc:creator>
    </item>
    <item>
      <title>Kernel Interpolation on Sparse Grids</title>
      <link>https://arxiv.org/abs/2505.12282</link>
      <description>arXiv:2505.12282v1 Announce Type: new 
Abstract: We consider scattered data approximation on product regions of equal and different dimensionality. On each of these regions, we assume quasi-uniform but unstructured data sites and construct optimal sparse grids for scattered data interpolation on the product region. For this, we derive new improved error estimates for the respective kernel interpolation error by invoking duality arguments. An efficient algorithm to solve the underlying linear system of equations is proposed. The algorithm is based on the sparse grid combination technique, where a sparse direct solver is used for the elementary anisotropic tensor product kernel interpolation problems. The application of the sparse direct solver is facilitated by applying a samplet matrix compression to each univariate kernel matrix, resulting in an essentially sparse representation of the latter. In this way, we obtain a method that is able to deal with large problems up to billions of interpolation points, especially in case of reproducing kernels of nonlocal nature. Numerical results are presented to qualify and quantify the approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12282v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Griebel, Helmut Harbrecht, Michael Multerer</dc:creator>
    </item>
    <item>
      <title>BOLT: Block-Orthonormal Lanczos for Trace estimation of matrix functions</title>
      <link>https://arxiv.org/abs/2505.12289</link>
      <description>arXiv:2505.12289v1 Announce Type: new 
Abstract: Efficient matrix trace estimation is essential for scalable computation of log-determinants, matrix norms, and distributional divergences. In many large-scale applications, the matrices involved are too large to store or access in full, making even a single matrix-vector (mat-vec) product infeasible. Instead, one often has access only to small subblocks of the matrix or localized matrix-vector products on restricted index sets. Hutch++ achieves optimal convergence rate but relies on randomized SVD and assumes full mat-vec access, making it difficult to apply in these constrained settings. We propose the Block-Orthonormal Stochastic Lanczos Quadrature (BOLT), which matches Hutch++ accuracy with a simpler implementation based on orthonormal block probes and Lanczos iterations. BOLT builds on the Stochastic Lanczos Quadrature (SLQ) framework, which combines random probing with Krylov subspace methods to efficiently approximate traces of matrix functions, and performs better than Hutch++ in near flat-spectrum regimes. To address memory limitations and partial access constraints, we introduce Subblock SLQ, a variant of BOLT that operates only on small principal submatrices. As a result, this framework yields a proxy KL divergence estimator and an efficient method for computing the Wasserstein-2 distance between Gaussians - both compatible with low-memory and partial-access regimes. We provide theoretical guarantees and demonstrate strong empirical performance across a range of high-dimensional settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12289v1</guid>
      <category>math.NA</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kingsley Yeon, Promit Ghosal, Mihai Anitescu</dc:creator>
    </item>
    <item>
      <title>Stability and convergence of multi-product expansion splitting methods with negative weights for semilinear parabolic equations</title>
      <link>https://arxiv.org/abs/2505.12481</link>
      <description>arXiv:2505.12481v1 Announce Type: new 
Abstract: The operator splitting method has been widely used to solve differential equations by splitting the equation into more manageable parts. In this work, we resolves a long-standing problem -- how to establish the stability of multi-product expansion (MPE) splitting methods with negative weights. The difficulty occurs because negative weights in high-order MPE method cause the sum of the absolute values of weights larger than one, making standard stability proofs fail. In particular, we take the semilinear parabolic equation as a typical model and establish the stability of arbitrarily high-order MPE splitting methods with positive time steps but possibly negative weights. Rigorous convergence analysis is subsequently obtained from the stability result. Extensive numerical experiments validate the stability and accuracy of various high-order MPE splitting methods, highlighting their efficiency and robustness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12481v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xianglong Duan, Chaoyu Quan, Jiang Yang, Zijing Zhu</dc:creator>
    </item>
    <item>
      <title>Identifiability of Nonnegative Tucker Decompositions -- Part I: Theory</title>
      <link>https://arxiv.org/abs/2505.12713</link>
      <description>arXiv:2505.12713v1 Announce Type: new 
Abstract: Tensor decompositions have become a central tool in data science, with applications in areas such as data analysis, signal processing, and machine learning. A key property of many tensor decompositions, such as the canonical polyadic decomposition, is identifiability: the factors are unique, up to trivial scaling and permutation ambiguities. This allows one to recover the groundtruth sources that generated the data. The Tucker decomposition (TD) is a central and widely used tensor decomposition model. However, it is in general not identifiable. In this paper, we study the identifiability of the nonnegative TD (nTD). By adapting and extending identifiability results of nonnegative matrix factorization (NMF), we provide uniqueness results for nTD. Our results require the nonnegative matrix factors to have some degree of sparsity (namely, satisfy the separability condition, or the sufficiently scattered condition), while the core tensor only needs to have some slices (or linear combinations of them) or unfoldings with full column rank (but does not need to be nonnegative). Under such conditions, we derive several procedures, using either unfoldings or slices of the input tensor, to obtain identifiable nTDs by minimizing the volume of unfoldings or slices of the core tensor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12713v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>eess.SP</category>
      <category>stat.ML</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Subhayan Saha, Giovanni Barbarino, Nicolas Gillis</dc:creator>
    </item>
    <item>
      <title>Implicit numerical approximation for stochastic delay differential equations with the nonlinear diffusion term in the infinite horizon</title>
      <link>https://arxiv.org/abs/2505.12883</link>
      <description>arXiv:2505.12883v1 Announce Type: new 
Abstract: This paper investigates the approximation of stochastic delay differential equations (SDDEs) via the backward Euler-Maruyama (BEM) method under generalized monotonicity and Khasminskii-type conditions in the infinite horizon. First, by establishing the uniform moment boundedness and finite-time strong convergence of the BEM method, we prove that for sufficiently small step sizes, the numerical approximations strongly converge to the underlying solution in the infinite horizon with a rate of $1/2$, which coincides with the optimal finite-time strong convergence rate.
  Next, we establish the uniform boundedness and convergence in probability for the segment processes associated with the BEM method. This analysis further demonstrates that the probability measures of the numerical segment processes converge to the underlying invariant measure of the SDDEs. Finally, a numerical example and simulations are provided to illustrate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12883v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yudong Wang, Hongjiong Tian</dc:creator>
    </item>
    <item>
      <title>An implicit regularized enthalpy Lattice Boltzmann Method for the Stefan problem</title>
      <link>https://arxiv.org/abs/2505.13097</link>
      <description>arXiv:2505.13097v1 Announce Type: new 
Abstract: Solving the Stefan problem, also referred as the heat conduction problem with phase change, is a necessary step to solve phase change problems with convection. In this article, we are interested in using the Lattice Boltzmann Method (LBM) to solve the Stefan problem using a regularized total enthalpy model. The liquid fraction is treated as a nonlinear source/sink term, that involves the time derivative of the solution. The resulting non-linear system is solved using a Newton algorithm. By conserving the locality of the problem, this method is highly scalable, while keeping a high accuracy. The newly developed scheme is analyzed theoretically through a Chapman-Enskog expansion and illustrated numerically with 1D and 2D benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13097v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francky Luddens (LMRS), Corentin Lothod\'e (LAREMA), Ionut Danaila (LMRS)</dc:creator>
    </item>
    <item>
      <title>Ocean wave spectrum reconstruction from HF radar data and its application to wave height estimation</title>
      <link>https://arxiv.org/abs/2505.13132</link>
      <description>arXiv:2505.13132v1 Announce Type: new 
Abstract: Real-time estimation of ocean wave heights using high-frequency (HF) radar has attracted great attention. This method offers the benefit of easy maintenance by virtue of its ground-based installation. However, it is adversely affected by issues such as low estimation accuracy. As described herein, we propose an algorithm based on the nonnegative sparse regularization method to estimate the energy distribution of the component waves, known as the ocean wave spectrum, from HF radar data. After proving a stability estimate of this algorithm, we perform numerical simulations to verify the proposed method's effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13132v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaede Watanabe, Toshiaki Yachimura, Tsubasa Terada, Hiroshi Kameda, Ryuhei Takahashi, Hiroshi Suito</dc:creator>
    </item>
    <item>
      <title>A parametric finite element method for a degenerate multi-phase Stefan problem with triple junctions</title>
      <link>https://arxiv.org/abs/2505.13165</link>
      <description>arXiv:2505.13165v1 Announce Type: new 
Abstract: In this study, we propose a parametric finite element method for a degenerate multi-phase Stefan problem with triple junctions. This model describes the energy-driven motion of a surface cluster whose distributional solution was studied by Garcke and Sturzenhecker. We approximate the weak formulation of this sharp interface model by an unfitted finite element method that uses parametric elements for the representation of the moving interfaces. We establish existence and uniqueness of the discrete solution and prove unconditional stability of the proposed scheme. Moreover, a modification of the original scheme leads to a structure-preserving variant, in that it conserves the discrete analogue of a quantity that is preserved by the classical solution. Some numerical results demonstrate the applicability of our introduced schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13165v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tokuhiro Eto, Harald Garcke, Robert N\"urnberg</dc:creator>
    </item>
    <item>
      <title>Structure-preserving schemes conserving entropy and kinetic energy</title>
      <link>https://arxiv.org/abs/2505.13374</link>
      <description>arXiv:2505.13374v1 Announce Type: new 
Abstract: This paper presents a novel structure-preserving scheme for Euler equations, focusing on the numerical conservation of entropy and kinetic energy. Explicit flux functions engineered to conserve entropy are introduced within the finite-volume framework. Further, discrete kinetic energy conservation too is introduced. A systematic inquiry is presented, commencing with an overview of numerical entropy conservation and formulation of entropy-conserving and kinetic energy-preserving fluxes, followed by the study of their properties and efficacy. A novelty introduced is to associate numerical entropy conservation to the discretization of the energy conservation equation. Furthermore, an entropy-stable shock-capturing diffusion method and a hybrid approach utilizing the entropy distance to manage smooth regions effectively are also introduced. The addition of artificial viscosity in appropriate regions ensures entropy generation sufficient to prevent numerical instabilities. Various test cases, showcasing the efficacy and stability of the proposed methodology, are presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13374v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Kunal Bahuguna, Ramesh Kolluru, S. V. Raghurama Rao</dc:creator>
    </item>
    <item>
      <title>CASL-HJX: A Comprehensive Guide to Solving Deterministic and Stochastic Hamilton-Jacobi Equations</title>
      <link>https://arxiv.org/abs/2505.11527</link>
      <description>arXiv:2505.11527v2 Announce Type: cross 
Abstract: CASL-HJX is a computational framework designed for solving deterministic and stochastic Hamilton-Jacobi equations in two spatial dimensions. It provides a flexible and efficient approach to modeling front propagation problems, optimal control problems, and stochastic Hamilton-Jacobi Bellman equations. The framework integrates numerical methods for hyperbolic PDEs with operator splitting techniques and implements implicit methods for second-order derivative terms, ensuring convergence to viscosity solutions while achieving global rather than local optimization. Built with a high-performance C++ core, CASL-HJX efficiently handles mixed-order derivative systems with time-varying dynamics, making it suitable for real-world applications across multiple domains. We demonstrate the solver's versatility through tutorial examples covering various PDEs and through applications in neuroscience, where it enables the design of energy-efficient controllers for regulating neural populations to mitigate pathological synchrony. While our examples focus on these applications, the mathematical foundation of the solver makes it applicable to problems in finance, engineering, and machine learning. The modular architecture allows researchers to define computational domains, configure problems, and execute simulations with high numerical accuracy. CASL-HJX bridges the gap between deterministic control methods and stochastic models, providing a robust tool for managing uncertainty in complex dynamical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11527v2</guid>
      <category>math.OC</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Faranak Rajabi, Jacob Fingerman, Andrew Wang, Jeff Moehlis, Frederic Gibou</dc:creator>
    </item>
    <item>
      <title>Policy Gradient with Second Order Momentum</title>
      <link>https://arxiv.org/abs/2505.11561</link>
      <description>arXiv:2505.11561v1 Announce Type: cross 
Abstract: We develop Policy Gradient with Second-Order Momentum (PG-SOM), a lightweight second-order optimisation scheme for reinforcement-learning policies. PG-SOM augments the classical REINFORCE update with two exponentially weighted statistics: a first-order gradient average and a diagonal approximation of the Hessian. By preconditioning the gradient with this curvature estimate, the method adaptively rescales each parameter, yielding faster and more stable ascent of the expected return. We provide a concise derivation, establish that the diagonal Hessian estimator is unbiased and positive-definite under mild regularity assumptions, and prove that the resulting update is a descent direction in expectation. Numerical experiments on standard control benchmarks show up to a 2.1x increase in sample efficiency and a substantial reduction in variance compared to first-order and Fisher-matrix baselines. These results indicate that even coarse second-order information can deliver significant practical gains while incurring only D memory overhead for a D-parameter policy. All code and reproducibility scripts will be made publicly available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11561v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianyu Sun</dc:creator>
    </item>
    <item>
      <title>A preconditioned difference of convex functions algorithm with extrapolation and line search</title>
      <link>https://arxiv.org/abs/2505.11914</link>
      <description>arXiv:2505.11914v1 Announce Type: cross 
Abstract: This paper proposes a novel proximal difference-of-convex (DC) algorithm enhanced with extrapolation and aggressive non-monotone line search for solving non-convex optimization problems. We introduce an adaptive conservative update strategy of the extrapolation parameter determined by a computationally efficient non-monotone line search. The core of our algorithm is to unite the update of the extrapolation parameter with the step size of the non-monotone line search interactively. The global convergence of the two proposed algorithms is established through the Kurdyka-{\L}ojasiewicz properties, ensuring convergence within a preconditioned framework for linear equations. Numerical experiments on two general non-convex problems: SCAD-penalized binary classification and graph-based Ginzburg-Landau image segmentation models, demonstrate the proposed method's high efficiency compared to existing DC algorithms both in convergence rate and solution accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11914v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ran Zhang, Hongpeng Sun</dc:creator>
    </item>
    <item>
      <title>XiSort: Deterministic Sorting via IEEE-754 Total Ordering and Entropy Minimization</title>
      <link>https://arxiv.org/abs/2505.11927</link>
      <description>arXiv:2505.11927v1 Announce Type: cross 
Abstract: We introduce XiSort, a deterministic and reproducible sorting algorithm for floating-point sequences based on IEEE-754 total ordering and entropy minimization. XiSort guarantees bit-for-bit stability across runs and platforms by resolving tie-breaking via information-theoretic and symbolic methods. The algorithm supports both in-memory and external (out-of-core) operation, offering consistent performance on large datasets. We formalize a curved variant of the sorting metric that integrates into the Alpay Algebra framework, treating XiSort as a recursive operator with provable convergence and symbolic idempotence. This model preserves state-space closure while minimizing local disorder, interpretable as symbolic entropy. Empirical benchmarks demonstrate that XiSort achieves competitive throughput (e.g., sorting 10^8 doubles in approximately 12 seconds in-memory, and 100 GB at around 100 MB/s on SSDs), with applications in scientific computing, high-frequency finance, and reproducible numerical workflows. The results position XiSort as a principled tool for stable data alignment, symbolic preprocessing, and cross-platform float ordering.
  Keywords: deterministic sorting, IEEE-754, entropy minimization, symbolic algebra, reproducibility, external memory, Alpay Algebra, data pipelines</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11927v1</guid>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>cs.NA</category>
      <category>math.IT</category>
      <category>math.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Faruk Alpay</dc:creator>
    </item>
    <item>
      <title>Approximation theory for 1-Lipschitz ResNets</title>
      <link>https://arxiv.org/abs/2505.12003</link>
      <description>arXiv:2505.12003v1 Announce Type: cross 
Abstract: 1-Lipschitz neural networks are fundamental for generative modelling, inverse problems, and robust classifiers. In this paper, we focus on 1-Lipschitz residual networks (ResNets) based on explicit Euler steps of negative gradient flows and study their approximation capabilities. Leveraging the Restricted Stone-Weierstrass Theorem, we first show that these 1-Lipschitz ResNets are dense in the set of scalar 1-Lipschitz functions on any compact domain when width and depth are allowed to grow. We also show that these networks can exactly represent scalar piecewise affine 1-Lipschitz functions. We then prove a stronger statement: by inserting norm-constrained linear maps between the residual blocks, the same density holds when the hidden width is fixed. Because every layer obeys simple norm constraints, the resulting models can be trained with off-the-shelf optimisers. This paper provides the first universal approximation guarantees for 1-Lipschitz ResNets, laying a rigorous foundation for their practical use.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12003v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Davide Murari, Takashi Furuya, Carola-Bibiane Sch\"onlieb</dc:creator>
    </item>
    <item>
      <title>High-dimensional Optimization with Low Rank Tensor Sampling and Local Search</title>
      <link>https://arxiv.org/abs/2505.12383</link>
      <description>arXiv:2505.12383v1 Announce Type: cross 
Abstract: We present a novel method called TESALOCS (TEnsor SAmpling and LOCal Search) for multidimensional optimization, combining the strengths of gradient-free discrete methods and gradient-based approaches. The discrete optimization in our method is based on low-rank tensor techniques, which, thanks to their low-parameter representation, enable efficient optimization of high-dimensional problems. For the second part, i.e., local search, any effective gradient-based method can be used, whether existing (such as quasi-Newton methods) or any other developed in the future. Our approach addresses the limitations of gradient-based methods, such as getting stuck in local optima; the limitations of discrete methods, which cannot be directly applied to continuous functions; and limitations of gradient-free methods that require large computational budgets. Note that we are not limited to a single type of low-rank tensor decomposition for discrete optimization, but for illustrative purposes, we consider a specific efficient low-rank tensor train decomposition. For 20 challenging 100-dimensional functions, we demonstrate that our method can significantly outperform results obtained with gradient-based methods like Conjugate Gradient, BFGS, SLSQP, and other methods, improving them by orders of magnitude with the same computing budget.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12383v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Konstantin Sozykin, Andrei Chertkov, Anh-Huy Phan, Ivan Oseledets, Gleb Ryzhakov</dc:creator>
    </item>
    <item>
      <title>RGNMR: A Gauss-Newton method for robust matrix completion with theoretical guarantees</title>
      <link>https://arxiv.org/abs/2505.12919</link>
      <description>arXiv:2505.12919v1 Announce Type: cross 
Abstract: Recovering a low rank matrix from a subset of its entries, some of which may be corrupted, is known as the robust matrix completion (RMC) problem. Existing RMC methods have several limitations: they require a relatively large number of observed entries; they may fail under overparametrization, when their assumed rank is higher than the correct one; and many of them fail to recover even mildly ill-conditioned matrices. In this paper we propose a novel RMC method, denoted $\texttt{RGNMR}$, which overcomes these limitations. $\texttt{RGNMR}$ is a simple factorization-based iterative algorithm, which combines a Gauss-Newton linearization with removal of entries suspected to be outliers. On the theoretical front, we prove that under suitable assumptions, $\texttt{RGNMR}$ is guaranteed exact recovery of the underlying low rank matrix. Our theoretical results improve upon the best currently known for factorization-based methods. On the empirical front, we show via several simulations the advantages of $\texttt{RGNMR}$ over existing RMC methods, and in particular its ability to handle a small number of observed entries, overparameterization of the rank and ill-conditioned matrices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12919v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eilon Vaknin Laufer, Boaz Nadler</dc:creator>
    </item>
    <item>
      <title>Multi-Level Monte Carlo Training of Neural Operators</title>
      <link>https://arxiv.org/abs/2505.12940</link>
      <description>arXiv:2505.12940v1 Announce Type: cross 
Abstract: Operator learning is a rapidly growing field that aims to approximate nonlinear operators related to partial differential equations (PDEs) using neural operators. These rely on discretization of input and output functions and are, usually, expensive to train for large-scale problems at high-resolution. Motivated by this, we present a Multi-Level Monte Carlo (MLMC) approach to train neural operators by leveraging a hierarchy of resolutions of function dicretization. Our framework relies on using gradient corrections from fewer samples of fine-resolution data to decrease the computational cost of training while maintaining a high level accuracy. The proposed MLMC training procedure can be applied to any architecture accepting multi-resolution data. Our numerical experiments on a range of state-of-the-art models and test-cases demonstrate improved computational efficiency compared to traditional single-resolution training approaches, and highlight the existence of a Pareto curve between accuracy and computational time, related to the number of samples per resolution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12940v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>James Rowbottom, Stefania Fresca, Pietro Lio, Carola-Bibiane Sch\"onlieb, Nicolas Boull\'e</dc:creator>
    </item>
    <item>
      <title>Revisiting the Slip Boundary Condition: Surface Roughness as a Hidden Tuning Parameter</title>
      <link>https://arxiv.org/abs/2505.13068</link>
      <description>arXiv:2505.13068v1 Announce Type: cross 
Abstract: In this paper, we investigate the effect of boundary surface roughness on numerical simulations of incompressible fluid flow past a cylinder in two and three spatial dimensions furnished with slip boundary conditions. The governing equations are approximated using a continuous finite element method, stabilized with a Galerkin least-squares approach.
  Through a series of numerical experiments, we demonstrate that: $(i)$ the introduction of surface roughness through numerical discretization error, or mesh distortion, makes the potential flow solution unstable; $(ii)$ when numerical surface roughness and mesh distortion are minimized by using high-order isoparametric geometry mappings, a stable potential flow is obtained in both two and three dimensions; $(iii)$ numerical surface roughness, mesh distortion and refinement level can be used as control parameters to manipulate drag and lift forces resulting in numerical values spanning more than an order of magnitude.
  Our results cast some doubt on the predictive capability of the slip boundary condition for wall modeling in turbulent simulations of incompressible flow.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13068v1</guid>
      <category>physics.flu-dyn</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthias Maier, Peter Munch, Murtazo Nazarov</dc:creator>
    </item>
    <item>
      <title>Quantum Hardware-in-the-Loop for Optimal Power Flow in Renewable-Integrated Power Systems</title>
      <link>https://arxiv.org/abs/2505.13356</link>
      <description>arXiv:2505.13356v1 Announce Type: cross 
Abstract: This paper presents a proof-of-concept for integrating quantum hardware with real-time digital simulator (RTDS) to model and control modern power systems, including renewable energy resources. Power flow (PF) analysis and optimal power flow (OPF) studies are conducted using RTDS coupled with Fujitsu's CMOS Digital Annealer and D-Wave's Advantage quantum processors. The adiabatic quantum power flow (AQPF) and adiabatic quantum optimal power flow (AQOPF) algorithms are used to perform PF and OPF, respectively, on quantum and quantum-inspired hardware. The experiments are performed on the IEEE 9-bus test system and a modified version that includes solar and wind farms. The findings demonstrate that the AQPF and AQOPF algorithms can accurately perform PF and OPF, yielding results that closely match those of classical Newton-Raphson (NR) solvers while also exhibiting robust convergence. Furthermore, the integration of renewable energy sources (RES) within the AQOPF framework proves effective in maintaining system stability and performance, even under variable generation conditions. These findings highlight the potential of quantum computing to significantly enhance the modeling and control of future power grids, particularly in systems with high renewable energy penetration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13356v1</guid>
      <category>eess.SY</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>math.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zeynab Kaseb, Rahul Rane, Aleksandra Lekic, Matthias Moller, Amin Khodaei, Peter Palensky, Pedro P. Vergara</dc:creator>
    </item>
    <item>
      <title>Learning by solving differential equations</title>
      <link>https://arxiv.org/abs/2505.13397</link>
      <description>arXiv:2505.13397v1 Announce Type: cross 
Abstract: Modern deep learning algorithms use variations of gradient descent as their main learning methods. Gradient descent can be understood as the simplest Ordinary Differential Equation (ODE) solver; namely, the Euler method applied to the gradient flow differential equation. Since Euler, many ODE solvers have been devised that follow the gradient flow equation more precisely and more stably. Runge-Kutta (RK) methods provide a family of very powerful explicit and implicit high-order ODE solvers. However, these higher-order solvers have not found wide application in deep learning so far. In this work, we evaluate the performance of higher-order RK solvers when applied in deep learning, study their limitations, and propose ways to overcome these drawbacks. In particular, we explore how to improve their performance by naturally incorporating key ingredients of modern neural network optimizers such as preconditioning, adaptive learning rates, and momentum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13397v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benoit Dherin, Michael Munn, Hanna Mazzawi, Michael Wunder, Sourabh Medapati, Javier Gonzalvo</dc:creator>
    </item>
    <item>
      <title>Spectral ACMS: A robust localized Approximated Component Mode Synthesis Method</title>
      <link>https://arxiv.org/abs/1709.04044</link>
      <description>arXiv:1709.04044v3 Announce Type: replace 
Abstract: We consider finite element methods of multiscale type to approximate solutions for two-dimensional symmetric elliptic partial differential equations with heterogeneous $L^\infty$ coefficients. The methods are of Galerkin type and follow the Variational Multiscale and Localized Orthogonal Decomposition--LOD approaches in the sense that it decouples spaces into \emph{multiscale} and \emph{fine} subspaces. In a first method, the multiscale basis functions are obtained by mapping coarse basis functions, based on corners used on primal iterative substructuring methods, to functions of global minimal energy. This approach delivers quasi-optimal a priori error energy approximation with respect to the mesh size, but it is not robust with respect to high-contrast coefficients. In a second method, edge modes based on local generalized eigenvalue problems are added to the corner modes. As a result, optimal a priori error energy estimate is achieved which is mesh and contrast independent. The methods converge at optimal rate even if the solution has minimum regularity, belonging only to the Sobolev space $H^1$.</description>
      <guid isPermaLink="false">oai:arXiv.org:1709.04044v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexandre L. Madureira, Marcus Sarkis</dc:creator>
    </item>
    <item>
      <title>Convergence and Near-optimal Sampling for Multivariate Function Approximations in Irregular Domains via Vandermonde with Arnoldi</title>
      <link>https://arxiv.org/abs/2301.12241</link>
      <description>arXiv:2301.12241v2 Announce Type: replace 
Abstract: Vandermonde matrices are usually exponentially ill-conditioned and often result in unstable approximations. In this paper, we introduce and analyze the \textit{multivariate Vandermonde with Arnoldi (V+A) method}, which is based on least-squares approximation together with a Stieltjes orthogonalization process, for approximating continuous, multivariate functions on $d$-dimensional irregular domains. The V+A method addresses the ill-conditioning of the Vandermonde approximation by creating a set of discrete orthogonal bases with respect to a discrete measure. The V+A method is simple and general, relying only on the domain's sample points. This paper analyzes the sample complexity of {the least-squares approximation that uses the V+A method}. We show that, for a large class of domains, this approximation gives a well-conditioned and near-optimal $N$-dimensional least-squares approximation using $M=O(N^2)$ equispaced sample points or $M=O(N^2\log N)$ random sample points, independently of $d$. We provide a comprehensive analysis of the error estimates and the rate of convergence of the least-squares approximation that uses the V+A method. Based on the multivariate V+A techniques, we propose a new variant of the weighted V+A least-squares algorithm that uses only $M=O(N\log N)$ sample points to achieve a near-optimal approximation. {Our initial numerical results validate that the V+A least-squares approximation method provides well-conditioned and near-optimal approximations for multivariate functions on (irregular) domains. Additionally, the (weighted) least-squares approximation that uses the V+A method performs competitively with state-of-the-art orthogonalization techniques and can serve as a practical tool for selecting near-optimal distributions of sample points in irregular domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.12241v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Wenqi Zhu, Yuji Nakatsukasa</dc:creator>
    </item>
    <item>
      <title>Average conditioning of underdetermined polynomial systems</title>
      <link>https://arxiv.org/abs/2305.05965</link>
      <description>arXiv:2305.05965v3 Announce Type: replace 
Abstract: This article study the average conditioning for a random underdetermined polynomial system. The expected value of the moments of the condition number are compared to the moments of the condition number of random matrices. An expression for these moments is given by studying the kernel finding problem for random matrices. Furthermore, the second moment of the Frobenius condition number is computed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.05965v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Federico Carrasco</dc:creator>
    </item>
    <item>
      <title>Convergence analysis and parameter estimation for the iterated Arnoldi-Tikhonov method</title>
      <link>https://arxiv.org/abs/2311.11823</link>
      <description>arXiv:2311.11823v2 Announce Type: replace 
Abstract: The Arnoldi-Tikhonov method is a well-established regularization technique for solving large-scale ill-posed linear inverse problems. This method leverages the Arnoldi decomposition to reduce computational complexity by projecting the discretized problem into a lower-dimensional Krylov subspace, in which it is solved. This paper explores the iterated Arnoldi-Tikhonov method, conducting a comprehensive analysis that addresses all approximation errors. Additionally, it introduces a novel strategy for choosing the regularization parameter, leading to more accurate approximate solutions compared to the standard Arnoldi-Tikhonov method. Moreover, the proposed method demonstrates robustness with respect to the regularization parameter, as confirmed by the numerical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.11823v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s00211-025-01472-9</arxiv:DOI>
      <arxiv:journal_reference>Numerische Mathematik (2025)</arxiv:journal_reference>
      <dc:creator>Davide Bianchi, Marco Donatelli, Davide Furch\`i, Lothar Reichel</dc:creator>
    </item>
    <item>
      <title>Training PINNs with Hard Constraints and Adaptive Weights: An Ablation Study</title>
      <link>https://arxiv.org/abs/2404.16189</link>
      <description>arXiv:2404.16189v2 Announce Type: replace 
Abstract: Training Physics-Informed Neural Networks (PINNs) to solve stiff time-dependent partial differential equations (PDEs) remains a significant challenge. The main difficulties lie in precisely enforcing initial conditions and balancing the various loss components. In stiff PDEs, where solutions show rapid transitions or sharp gradients, this balance becomes especially difficult. The wide range of scales in the dynamics can cause certain losses to dominate, leading to unstable or inefficient training. This paper presents a comprehensive ablation study focused on two pivotal training schemes: the enforcement of hard constraints for initial and boundary conditions, and the implementation of adaptive weights. We specifically examine their impact on the performance of PINNs when applied to stiff time-dependent PDEs from materials science and mathematical biology applications. We conduct extensive numerical experiments across a diverse range of time-dependent PDEs from Allen-Cahn, Cahn-Hillard, to Gray-Scott systems. We further discuss the implications of our findings for improving the robustness and efficiency of PINN training, particularly in settings where accurate representation of initial conditions and balanced loss contributions are paramount.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16189v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Baoli Hao, Ulisses Braga-Neto, Chun Liu, Lifan Wang, Ming Zhong</dc:creator>
    </item>
    <item>
      <title>A Priori Estimation of the Approximation, Optimization and Generalization Errors of Random Neural Networks for Solving Partial Differential Equations</title>
      <link>https://arxiv.org/abs/2406.03080</link>
      <description>arXiv:2406.03080v3 Announce Type: replace 
Abstract: In recent years, neural networks have achieved remarkable progress in various fields and have also drawn much attention in applying them on scientific problems. A line of methods involving neural networks for solving partial differential equations (PDEs), such as Physics-Informed Neural Networks (PINNs) and the Deep Ritz Method (DRM), has emerged. Although these methods outperform classical numerical methods in certain cases, the optimization problems involving neural networks are typically non-convex and non-smooth, which can result in unsatisfactory solutions for PDEs. In contrast to deterministic neural networks, the hidden weights of random neural networks are sampled from some prior distribution and only the output weights participate in training. This makes training much simpler, but it remains unclear how to select the prior distribution. In this paper, we focus on Barron type functions and approximate them under Sobolev norms by random neural networks with clear prior distribution. In addition to the approximation error, we also derive bounds for the optimization and generalization errors of random neural networks for solving PDEs when the solutions are Barron type functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03080v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xianliang Xu, Ye Li, Zhongyi Huang</dc:creator>
    </item>
    <item>
      <title>An approach to discrete operator learning based on sparse high-dimensional approximation</title>
      <link>https://arxiv.org/abs/2406.03973</link>
      <description>arXiv:2406.03973v2 Announce Type: replace 
Abstract: We present a dimension-incremental method for function approximation in bounded orthonormal product bases to learn the solutions of various differential equations. Therefore, we decompose the source function of the differential equation into parameters like Fourier or Spline coefficients and treat the solution of the differential equation as a high-dimensional function w.r.t. the spatial variables, these parameters and also further possible parameters from the differential equation itself. Finally, we learn this function in the sense of sparse approximation in a suitable function space by detecting coefficients of the basis expansion with the largest absolute values. Investigating the corresponding indices of the basis coefficients yields further insights on the structure of the solution as well as its dependency on the parameters and their interactions and allows for a reasonable generalization to even higher dimensions and therefore better resolutions of the decomposed source function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03973v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Potts, Fabian Taubert</dc:creator>
    </item>
    <item>
      <title>Efficient Shallow Ritz Method For 1D Diffusion-Reaction Problems</title>
      <link>https://arxiv.org/abs/2407.01496</link>
      <description>arXiv:2407.01496v2 Announce Type: replace 
Abstract: This paper studies the shallow Ritz method for solving one-dimensional diffusion-reaction problems. The method is capable of improving the order of approximation for non-smooth problems. By following a similar approach to the one presented in [9], we present a damped block Newton (dBN) method to achieve nearly optimal order of approximation. The dBN method optimizes the Ritz functional by alternating between the linear and non-linear parameters of the shallow ReLU neural network (NN). For diffusion-reaction problems, new difficulties arise: (1) for the linear parameters, the mass matrix is dense and even more ill-conditioned than the stiffness matrix, and (2) for the non-linear parameters, the Hessian matrix is dense and may be singular. This paper addresses these challenges, resulting in a dBN method with computational cost of ${\cal O}(n)$.
  The ideas presented for diffusion-reaction problems can also be applied to least-squares approximation problems. For both applications, starting with the non-linear parameters as a uniform partition, numerical experiments show that the dBN method moves the mesh points to nearly optimal locations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01496v2</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zhiqiang Cai, Anastassia Doktorova, Robert D. Falgout, C\'esar Herrera</dc:creator>
    </item>
    <item>
      <title>A boundary integral equation formulation for transient electromagnetic transmission problems on Lipschitz domains</title>
      <link>https://arxiv.org/abs/2407.05823</link>
      <description>arXiv:2407.05823v3 Announce Type: replace 
Abstract: We propose a boundary integral formulation for the dynamic problem of electromagnetic scattering and transmission by homogeneous dielectric obstacles. In the spirit of Costabel and Stephan, we use the transmission conditions to reduce the number of unknown densities and to formulate a system of coupled boundary integral equations describing the scattered and transmitted waves. The system is transformed into the Laplace domain where it is proven to be stable and uniquely solvable. The Laplace domain stability estimates are then used to establish the stability and unique solvability of the original time domain problem. Finally, we show how the bounds obtained in both Laplace and time domains can be used to derive error estimates for semi discrete Galerkin discretizations in space and for fully discrete numerical schemes that use Convolution Quadrature for time discretization and a conforming Galerkin method for discretization of the space variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05823v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1051/m2an/2025036</arxiv:DOI>
      <dc:creator>Tonatiuh S\'anchez-Vizuet</dc:creator>
    </item>
    <item>
      <title>Row-aware Randomized SVD with applications</title>
      <link>https://arxiv.org/abs/2408.04503</link>
      <description>arXiv:2408.04503v3 Announce Type: replace 
Abstract: The randomized singular value decomposition proposed in [25] has certainly become one of the most well-established randomization-based algorithms in numerical linear algebra. The key ingredient of the entire procedure is the computation of a subspace which is close to the column space of the target matrix $\mathbf{A}$ up to a certain probabilistic confidence. In this paper we employ a modification to the standard randomized SVD procedure which leads, in general, to better approximations to $\text{Range}(\mathbf{A})$ at the same computational cost. To this end, we explicitly construct information from the row space of $\mathbf{A}$ enhancing the quality of the approximation. We derive novel error bounds which improve over existing results for $\mathbf{A}$ having important gaps in its singular values. We also observe that very few pieces of information from $\text{Range}(\mathbf{A}^T)$ may be necessary. We thus design a variant of this algorithm equipped with a subsampling step which largely increases the efficiency of the procedure while attaining competitive accuracy records. Our findings are supported by both theoretical analysis and numerical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04503v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Davide Palitta, Sascha Portaro</dc:creator>
    </item>
    <item>
      <title>Uniform Approximation of Eigenproblems of a Large-Scale Parameter-Dependent Hermitian Matrix</title>
      <link>https://arxiv.org/abs/2409.05791</link>
      <description>arXiv:2409.05791v3 Announce Type: replace 
Abstract: We consider the uniform approximation of the smallest eigenvalue of a large parameter-dependent Hermitian matrix by that of a smaller counterpart obtained through projections. The projection subspaces are constructed iteratively by means of a greedy strategy; at each iteration the parameter where a surrogate error is maximal is computed and the eigenvectors associated with the smallest eigenvalues at the maximizing parameter value are added to the subspace. Unlike the classical approaches, such as the successive constraint method, that maximize such surrogate errors over a discrete and finite set, we maximize the surrogate error over the continuum of all permissible parameter values globally. We formally prove that the projected eigenvalue function converges to the actual eigenvalue function uniformly. In the second part, we focus on the uniform approximation of the smallest singular value of a large parameter-dependent matrix, in case it is non-Hermitian. The proposed frameworks on numerical examples, including those arising from discretizations of parametric PDEs, reduce the size of the large matrix-valued function drastically, while retaining a high accuracy over all permissible parameter values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.05791v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mattia Manucci, Emre Mengi, Nicola Guglielmi</dc:creator>
    </item>
    <item>
      <title>An Immersed Interface Method for Incompressible Flows and Geometries with Sharp Features</title>
      <link>https://arxiv.org/abs/2410.16466</link>
      <description>arXiv:2410.16466v3 Announce Type: replace 
Abstract: The immersed interface method (IIM) for models of fluid flow and fluid-structure interaction imposes jump conditions that capture stress discontinuities generated by forces that are concentrated along immersed boundaries. Most prior work using the IIM for fluid dynamic applications has focused on smooth interfaces, but boundaries with sharp features such as corners and edges can appear in practical analyses, particularly on engineered structures. The present study builds on our work to integrate finite element-type representations of interface geometries with the IIM. Initial realizations of this approach used a continuous Galerkin (CG) finite element discretization for the boundary, but as we show herein, these approaches generate large errors near sharp geometrical features. To overcome this difficulty, this study introduces an IIM approach using discontinuous Galerkin (DG) representation of the jump conditions. Numerical examples explore the impacts of different interface representations on accuracy for both smooth and sharp boundaries, particularly flows interacting with fixed interface configurations. We demonstrate that using a DG approach provides accuracy that is comparable to the CG method for smooth cases. Further, we identify a time step size restriction for the CG representation that is directly related to the sharpness of the geometry. In contrast, time step size restrictions imposed by DG representations are demonstrated to be insensitive to the presence of sharp features.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16466v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Michael J. Facci, Ebrahim M. Kolahdouz, Boyce E. Griffith</dc:creator>
    </item>
    <item>
      <title>Decoupled structure-preserving discretization of incompressible MHD equations with general boundary conditions</title>
      <link>https://arxiv.org/abs/2410.23973</link>
      <description>arXiv:2410.23973v2 Announce Type: replace 
Abstract: In the framework of a mixed finite element method, a structure-preserving formulation for incompressible magnetohydrodynamic (MHD) equations with general boundary conditions is proposed. A leapfrog-type temporal scheme fully decouples the fluid part from the Maxwell part by means of staggered discrete time sequences and, in doing so, partially linearizes the system. Conservation and dissipation properties of the formulation before and after the decoupling are analyzed. We demonstrate optimal spatial and second-order temporal accuracy, as well as conservation and dissipation properties, of the proposed method using manufactured solutions, and apply it to the benchmark Orszag-Tang and lid-driven cavity cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23973v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi Zhang, Artur Palha, Andrea Brugnoli, Deepesh Toshniwal, Marc Gerritsma</dc:creator>
    </item>
    <item>
      <title>A Micro-Macro Decomposition-Based Asymptotic-Preserving Random Feature Method for Multiscale Radiative Transfer Equations</title>
      <link>https://arxiv.org/abs/2411.04643</link>
      <description>arXiv:2411.04643v2 Announce Type: replace 
Abstract: This paper introduces the Asymptotic-Preserving Random Feature Method (APRFM) for the efficient resolution of multiscale radiative transfer equations. The APRFM effectively addresses the challenges posed by stiffness and multiscale characteristics inherent in radiative transfer equations through the application of a micro-macro decomposition strategy. This approach decomposes the distribution function into equilibrium and non-equilibrium components, allowing for the approximation of both parts through the random feature method (RFM) within a least squares minimization framework. The proposed method exhibits remarkable robustness across different scales and achieves high accuracy with fewer degrees of freedom and collocation points than the vanilla RFM. Additionally, compared to the deep neural network-based method, our approach offers significant advantages in terms of parameter efficiency and computational speed. These benefits have been substantiated through numerous numerical experiments conducted on both one- and two-dimensional problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04643v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingrun Chen, Zheng Ma, Keke Wu</dc:creator>
    </item>
    <item>
      <title>A bound-preserving Runge--Kutta discontinuous Galerkin method with compact stencils for hyperbolic conservation laws</title>
      <link>https://arxiv.org/abs/2412.16002</link>
      <description>arXiv:2412.16002v2 Announce Type: replace 
Abstract: In this paper, we develop bound-preserving techniques for the Runge--Kutta (RK) discontinuous Galerkin (DG) method with compact stencils (cRKDG method) for hyperbolic conservation laws. The cRKDG method was recently introduced in [Q. Chen, Z. Sun, and Y. Xing, SIAM J. Sci. Comput., 46: A1327--A1351, 2024]. It enhances the compactness of the standard RKDG method, resulting in reduced data communication, simplified boundary treatments, and improved suitability for local time marching. This work improves the robustness of the cRKDG method by enforcing desirable physical bounds while preserving its compactness, local conservation, and high-order accuracy. Our method is extended from the seminal work of [X. Zhang and C.-W. Shu, J. Comput. Phys., 229: 3091--3120, 2010]. We prove that the cell average of the cRKDG method at each RK stage preserves the physical bounds by expressing it as a convex combination of three types of forward-Euler solutions. A scaling limiter is then applied after each RK stage to enforce pointwise bounds. Additionally, we explore RK methods with less restrictive time step sizes. Because the cRKDG method does not rely on strong-stability-preserving RK time discretization, it avoids its order barriers, allowing us to construct a four-stage, fourth-order bound-preserving cRKDG method. Numerical tests on challenging benchmarks are provided to demonstrate the performance of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16002v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chen Liu, Zheng Sun, Xiangxiong Zhang</dc:creator>
    </item>
    <item>
      <title>Complexity of Tensor Product Functions in Representing Antisymmetry</title>
      <link>https://arxiv.org/abs/2501.05958</link>
      <description>arXiv:2501.05958v2 Announce Type: replace 
Abstract: Tensor product function (TPF) approximations have been widely adopted in solving high-dimensional problems, such as partial differential equations and eigenvalue problems, achieving desirable accuracy with computational overhead that scales linearly with problem dimensions. However, recent studies have underscored the extraordinarily high computational cost of TPFs on quantum many-body problems, even for systems with as few as three particles. A key distinction in these problems is the antisymmetry requirement on the unknown functions. In the present work, we rigorously establish that the minimum number of involved terms for a class of TPFs to be exactly antisymmetric increases exponentially fast with the problem dimension. This class encompasses both traditionally discretized TPFs and the recent ones parameterized by neural networks. Our proof exploits the link between the antisymmetric TPFs in this class and the corresponding antisymmetric tensors and focuses on the Canonical Polyadic rank of the latter. As a result, our findings uncover a fundamental incompatibility between antisymmetry and low-rank TPFs in high-dimensional contexts and offer new insights for further developments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05958v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuyang Wang, Yukuan Hu, Xin Liu</dc:creator>
    </item>
    <item>
      <title>Control, Optimal Transport and Neural Differential Equations in Supervised Learning</title>
      <link>https://arxiv.org/abs/2503.15105</link>
      <description>arXiv:2503.15105v3 Announce Type: replace 
Abstract: We study the fundamental computational problem of approximating optimal transport (OT) equations using neural differential equations (Neural ODEs). More specifically, we develop a novel framework for approximating unbalanced optimal transport (UOT) in the continuum using Neural ODEs. By generalizing a discrete UOT problem with Pearson divergence, we constructively design vector fields for Neural ODEs that converge to the true UOT dynamics, thereby advancing the mathematical foundations of computational transport and machine learning. To this end, we design a numerical scheme inspired by the Sinkhorn algorithm to solve the corresponding minimization problem and rigorously prove its convergence, providing explicit error estimates. From the obtained numerical solutions, we derive vector fields defining the transport dynamics and construct the corresponding transport equation.
  Finally, from the numerically obtained transport equation, we construct a neural differential equation whose flow converges to the true transport dynamics in an appropriate limiting regime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15105v3</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minh-Nhat Phung, Minh-Binh Tran</dc:creator>
    </item>
    <item>
      <title>Error analysis of a Euler finite element scheme for Natural convection model with variable density</title>
      <link>https://arxiv.org/abs/2504.04381</link>
      <description>arXiv:2504.04381v2 Announce Type: replace 
Abstract: In this paper, we derive first-order Euler finite element discretization schemes for a time-dependent natural convection model with variable density (NCVD). The model is governed by the variable density Navier-Stokes equations coupled with a parabolic partial differential equation that describes the evolution of temperature. Stability and error estimate for the velocity, pressure, density and temperature in $L^2$-norm are proved by using finite element approximations in space and finite differences in time. Finally, the numerical results are showed to support the theoretical analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04381v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Li Hang, Chenyang Li</dc:creator>
    </item>
    <item>
      <title>Stochastic Multigrid Minimization for Ptychographic Phase Retrieval</title>
      <link>https://arxiv.org/abs/2504.10118</link>
      <description>arXiv:2504.10118v2 Announce Type: replace 
Abstract: We propose a novel stochastic multigrid minimization method for ptychographic phase retrieval. In our formulation, the challenging nonconvex and ill-posed inverse problem is recast as the iterative minimization of a quadratic surrogate model that majorizes the original objective function. Our general framework encompasses the Ptychographic Iterative Engine (PIE) family of algorithms. By efficiently solving the surrogate problem using a multigrid method, our approach delivers significant improvements in both convergence speed and reconstruction quality compared with conventional PIE techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10118v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Borong Zhang, Qin Li, Zichao Wendy Di</dc:creator>
    </item>
    <item>
      <title>Numerical Derivatives, Projection Coefficients, and Truncation Errors in Analytic Hilbert Space With Gaussian Measure</title>
      <link>https://arxiv.org/abs/2504.16246</link>
      <description>arXiv:2504.16246v2 Announce Type: replace 
Abstract: We introduce the projection coefficients algorithm, a novel method for determining the leading terms of the Taylor series expansion of a given holomorphic function from a graph perspective, while also analyzing the associated truncation errors. Let $ f(z) $ be a holomorphic function, and let $\langle \cdot, \cdot \rangle$ denote the inner product defined over an analytic Hilbert space equipped with a Gaussian measure. The derivatives $ f^{(n)}(z) $ at a point $ z_0 $ can be computed theoretically by evaluating an inner product of the form $
f^{(n)}(z_0) = \frac{\langle z^n, f(z) \rangle}{C}, $
where $ C $ is a normalization constant. Specifically, in the Bargmann space (the analytic Hilbert space with a Gaussian weight and orthogonal monomials), this constant is $ \pi $. This result assumes that $ f(z) $ is a holomorphic function of a single complex variable. The accuracy of the computed derivative values depends on the precision and reliability of the numerical routines used to evaluate these inner products.
  The projection coefficients offer valuable insights into certain properties of analytic functions, such as whether they are odd or even, and whether the $ n $-th derivatives exist at a given point $ z_0 $. Due to its relevance to quantum theory, our approach establishes a correspondence between quantum circuits derived from quantum systems and the theory of analytic functions. This study lays the groundwork for further applications in numerical analysis and approximation theory within Hilbert spaces equipped with Gaussian measures. Additionally, it holds potential for advancing fields such as quantum computing, reproducing kernel Hilbert space (RKHS) methods -- which are widely used in support vector machines (SVM) and other areas of machine learning -- and probabilistic numerics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16246v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>M. W. AlMasri</dc:creator>
    </item>
    <item>
      <title>On Runge-Kutta methods of order 10</title>
      <link>https://arxiv.org/abs/2504.17329</link>
      <description>arXiv:2504.17329v3 Announce Type: replace 
Abstract: A family of explicit 15-stage Runge-Kutta methods of order 10 is derived.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17329v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Misha Stepanov</dc:creator>
    </item>
    <item>
      <title>Virtual Element Method Applied to Two Dimensional Axisymmetric Elastic Problems</title>
      <link>https://arxiv.org/abs/2504.21305</link>
      <description>arXiv:2504.21305v2 Announce Type: replace 
Abstract: This work presents a Virtual Element Method (VEM) formulation tailored for two-dimensional axisymmetric problems in linear elasticity. By exploiting the rotational symmetry of the geometry and loading conditions, the problem is reduced to a meridional cross-section, where all fields depend only on the radial and axial coordinates. The method incorporates the radial weight $r$ in both the weak formulation and the interpolation estimates to remain consistent with the physical volume measure of cylindrical coordinates. A projection operator onto constant strain fields is constructed via boundary integrals, and a volumetric correction term is introduced to account for the divergence of the stress field arising from axisymmetry. The stabilization term is designed to act only on the kernel of the projection and is implemented using a boundary-based formulation that guarantees stability without affecting polynomial consistency. Furthermore, an a priori interpolation error estimate is established in a weighted Sobolev space, showing optimal convergence rates. The implementation is validated through patch tests that demonstrate the accuracy, consistency, and robustness of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.21305v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paulo Akira F. Enabe, Rodrigo Provasi</dc:creator>
    </item>
    <item>
      <title>Quasi-3D beam theory based on equilibrium stress definition and mixed element model for accurate analysis of functionally graded beams</title>
      <link>https://arxiv.org/abs/2505.09127</link>
      <description>arXiv:2505.09127v3 Announce Type: replace 
Abstract: This paper presents a novel quasi-3D theory and the corresponding mixed beam element model to achieve accurate solutions for functionally graded beams. The key innovations include the development of equilibrium-based stress expressions, the modified cross-sectional stiffness matrix, and the mixed beam element model based on semi-analytical definition of internal force fields. In contrast to the conventional quasi-3D theory where stress expressions are derived from constitutive equations and geometric relations, the stress expressions in this study are derived from the differential equilibrium equations among stresses, ensuring strict adherence of stress solutions to equilibrium conditions. To incorporate the influence of equilibrium-derived stress distributions, the modified cross-sectional stiffness matrix is derived, enhancing the theoretical and practical feasibility of the beam model. For beam element construction, the mixed variational principle of two-field variables is employed, with generalized internal forces and generalized displacements regarded as two independent fields. Especially, semi-analytical internal force fields, which partially satisfy the differential equilibrium equations, are introduced to improve the element performance. Numerical examples are conducted to verify the accuracy and effectiveness of the proposed theory and beam element.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09127v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenxiong Li, Zhiwei Liu, Suiyin Chen, Gengying Li</dc:creator>
    </item>
    <item>
      <title>On the Well-Posedness of Green's Function Reconstruction via the Kirchhoff-Helmholtz Equation for One-Speed Neutron Diffusion</title>
      <link>https://arxiv.org/abs/2505.09766</link>
      <description>arXiv:2505.09766v2 Announce Type: replace 
Abstract: This work presents a methodology for reconstructing the spatial distribution of the neutron flux in a nuclear reactor, leveraging real-time measurements obtained from ex-core detectors. The Kirchhoff-Helmholtz (K-H) equation inherently defines the problem of estimating a scalar field within a domain based on boundary data, making it a natural mathematical framework for this task. The main challenge lies in deriving the Green's function specific to the domain and the neutron diffusion process. While analytical solutions for Green's functions exist for simplified geometries, their derivation of complex, heterogeneous domains-such as a nuclear reactor-requires a numerical approach. The objective of this work is to demonstrate the well-posedness of the data-driven Green's function approximation by formulating and solving the K-H equation as an inverse problem. After establishing the symmetry properties that the Green's function must satisfy, the K-H equation is derived from the one-speed neutron diffusion model. This is followed by a comprehensive description of the procedure for interpreting sensor readings and implementing the neutron flux reconstruction algorithm. Finally, the existence and uniqueness of the Green's function inferred from the sampled data are demonstrated, ensuring the reliability of the proposed method and its predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09766v2</guid>
      <category>math.NA</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roberto Ponciroli</dc:creator>
    </item>
    <item>
      <title>A Symplectic Analysis of Alternating Mirror Descent</title>
      <link>https://arxiv.org/abs/2405.03472</link>
      <description>arXiv:2405.03472v3 Announce Type: replace-cross 
Abstract: Motivated by understanding the behavior of the Alternating Mirror Descent (AMD) algorithm for bilinear zero-sum games, we study the discretization of continuous-time Hamiltonian flow via the symplectic Euler method. We provide a framework for analysis using results from Hamiltonian dynamics, Lie algebra, and symplectic numerical integrators, with an emphasis on the existence and properties of a conserved quantity, the modified Hamiltonian (MH), for the symplectic Euler method. We compute the MH in closed-form when the original Hamiltonian is a quadratic function, and show that it generally differs from the other conserved quantity known previously in that case. We derive new error bounds on the MH when truncated at orders in the stepsize in terms of the number of iterations, $K$, and use these bounds to show an improved $\mathcal{O}(K^{1/5})$ total regret bound and an $\mathcal{O}(K^{-4/5})$ duality gap of the average iterates for AMD. Finally, we propose a conjecture which, if true, would imply that the total regret for AMD scales as $\mathcal{O}\left(K^{\varepsilon}\right)$ and the duality gap of the average iterates as $\mathcal{O}\left(K^{-1+\varepsilon}\right)$ for any $\varepsilon&gt;0$, and we can take $\varepsilon=0$ upon certain convergence conditions for the MH.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03472v3</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonas Katona, Xiuyuan Wang, Andre Wibisono</dc:creator>
    </item>
    <item>
      <title>Back-Projection Diffusion: Solving the Wideband Inverse Scattering Problem with Diffusion Models</title>
      <link>https://arxiv.org/abs/2408.02866</link>
      <description>arXiv:2408.02866v4 Announce Type: replace-cross 
Abstract: We present Wideband Back-Projection Diffusion, an end-to-end probabilistic framework for approximating the posterior distribution induced by the inverse scattering map from wideband scattering data. This framework produces highly accurate reconstructions, leveraging conditional diffusion models to draw samples, and also honors the symmetries of the underlying physics of wave-propagation. The procedure is factored into two steps: the first step, inspired by the filtered back-propagation formula, transforms data into a physics-based latent representation, while the second step learns a conditional score function conditioned on this latent representation. These two steps individually obey their associated symmetries and are amenable to compression by imposing the rank structure found in the filtered back-projection formula. Empirically, our framework has both low sample and computational complexity, with its number of parameters scaling only sub-linearly with the target resolution, and has stable training dynamics. It provides sharp reconstructions effortlessly and is capable of recovering even sub-Nyquist features in the multiple-scattering regime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02866v4</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cma.2025.118036</arxiv:DOI>
      <arxiv:journal_reference>Computer Methods in Applied Mechanics and Engineering 443 (2025) 118036 Computer Methods in Applied Mechanics and Engineering 443 (2025) 118036</arxiv:journal_reference>
      <dc:creator>Borong Zhang, Mart\'in Guerra, Qin Li, Leonardo Zepeda-N\'u\~nez</dc:creator>
    </item>
    <item>
      <title>VICON: Vision In-Context Operator Networks for Multi-Physics Fluid Dynamics Prediction</title>
      <link>https://arxiv.org/abs/2411.16063</link>
      <description>arXiv:2411.16063v3 Announce Type: replace-cross 
Abstract: In-Context Operator Networks (ICONs) have demonstrated the ability to learn operators across diverse partial differential equations using few-shot, in-context learning. However, existing ICONs process each spatial point as an individual token, severely limiting computational efficiency when handling dense data in higher spatial dimensions. We propose Vision In-Context Operator Networks (VICON), which integrates vision transformer architectures to efficiently process 2D data through patch-wise operations while preserving ICON's adaptability to multiphysics systems and varying timesteps. Evaluated across three fluid dynamics benchmarks, VICON significantly outperforms state-of-the-art baselines: DPOT and MPP, reducing the averaged last-step rollout error by 37.9% compared to DPOT and 44.7% compared to MPP, while requiring only 72.5% and 34.8% of their respective inference times. VICON naturally supports flexible rollout strategies with varying timestep strides, enabling immediate deployment in imperfect measurement systems where sampling frequencies may differ or frames might be dropped - common challenges in real-world settings - without requiring retraining or interpolation. In these realistic scenarios, VICON exhibits remarkable robustness, experiencing only 24.41% relative performance degradation compared to 71.37%-74.49% degradation in baseline methods, demonstrating its versatility for deploying in realistic applications. Our scripts for processing datasets and code are publicly available at https://github.com/Eydcao/VICON.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16063v3</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.flu-dyn</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yadi Cao, Yuxuan Liu, Liu Yang, Rose Yu, Hayden Schaeffer, Stanley Osher</dc:creator>
    </item>
    <item>
      <title>Adaptive Extrapolated Proximal Gradient Methods with Variance Reduction for Composite Nonconvex Finite-Sum Minimization</title>
      <link>https://arxiv.org/abs/2502.21099</link>
      <description>arXiv:2502.21099v2 Announce Type: replace-cross 
Abstract: This paper proposes {\sf AEPG-SPIDER}, an Adaptive Extrapolated Proximal Gradient (AEPG) method with variance reduction for minimizing composite nonconvex finite-sum functions. It integrates three acceleration techniques: adaptive stepsizes, Nesterov's extrapolation, and the recursive stochastic path-integrated estimator SPIDER. Unlike existing methods that adjust the stepsize factor using historical gradients, {\sf AEPG-SPIDER} relies on past iterate differences for its update. While targeting stochastic finite-sum problems, {\sf AEPG-SPIDER} simplifies to {\sf AEPG} in the full-batch, non-stochastic setting, which is also of independent interest. To our knowledge, {\sf AEPG-SPIDER} and {\sf AEPG} are the first Lipschitz-free methods to achieve optimal iteration complexity for this class of \textit{composite} minimization problems. Specifically, {\sf AEPG} achieves the optimal iteration complexity of $\mathcal{O}(N \epsilon^{-2})$, while {\sf AEPG-SPIDER} achieves $\mathcal{O}(N + \sqrt{N} \epsilon^{-2})$ for finding $\epsilon$-approximate stationary points, where $N$ is the number of component functions. Under the Kurdyka-Lojasiewicz (KL) assumption, we establish non-ergodic convergence rates for both methods. Preliminary experiments on sparse phase retrieval and linear eigenvalue problems demonstrate the superior performance of {\sf AEPG-SPIDER} and {\sf AEPG} compared to existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.21099v2</guid>
      <category>math.OC</category>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ganzhao Yuan</dc:creator>
    </item>
    <item>
      <title>Boundary value problem of magnetically insulated diode: existence of solutions and complex bifurcation</title>
      <link>https://arxiv.org/abs/2505.02155</link>
      <description>arXiv:2505.02155v2 Announce Type: replace-cross 
Abstract: The paper focuses on the stationary self-consistent problem of magnetic insulation for a vacuum diode with space-charge limitation, described by a singularly perturbed Vlasov-Maxwell system of dimension 1.5. The case of insulated diode when the electrons are deflected back towards the cathode at the point $x^{*}$ is considered. First, the initial VM system is reduced to the nonlinear singular limit system of ODEs for the potentials of electric and magnetic fields. The second step deals with the limit system's reduction to the new nonlinear singular ODE equation for effective potential $\theta(x)$. The existence of non-negative solutions is proved for the last equation on the interval $[0, x^{*})$ where $\theta(x)&gt;0$. The most interesting and unexplored case is when $\theta(x)&lt;0$ on the interval $(x^{*}, 1]$ and corresponds to the case of an insulated diode. For the first time, a numerical analysis of complex bifurcation of solutions in insulated diode is considered for $\theta(x)&lt;0$ depending on parameters and boundary conditions. Bifurcation diagrams of the dependence of solution $\theta(x)$ on a free point (free boundary) $x^{*}$ were constructed. Insulated diode spacing is found.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02155v2</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.DS</category>
      <category>math.MP</category>
      <category>math.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Denis Sidorov, Alexander Sinitsyn, David Leguizamon, Liguo Wang</dc:creator>
    </item>
    <item>
      <title>Dual-Balancing for Physics-Informed Neural Networks</title>
      <link>https://arxiv.org/abs/2505.11117</link>
      <description>arXiv:2505.11117v3 Announce Type: replace-cross 
Abstract: Physics-informed neural networks (PINNs) have emerged as a new learning paradigm for solving partial differential equations (PDEs) by enforcing the constraints of physical equations, boundary conditions (BCs), and initial conditions (ICs) into the loss function. Despite their successes, vanilla PINNs still suffer from poor accuracy and slow convergence due to the intractable multi-objective optimization issue. In this paper, we propose a novel Dual-Balanced PINN (DB-PINN), which dynamically adjusts loss weights by integrating inter-balancing and intra-balancing to alleviate two imbalance issues in PINNs. Inter-balancing aims to mitigate the gradient imbalance between PDE residual loss and condition-fitting losses by determining an aggregated weight that offsets their gradient distribution discrepancies. Intra-balancing acts on condition-fitting losses to tackle the imbalance in fitting difficulty across diverse conditions. By evaluating the fitting difficulty based on the loss records, intra-balancing can allocate the aggregated weight proportionally to each condition loss according to its fitting difficulty level. We further introduce a robust weight update strategy to prevent abrupt spikes and arithmetic overflow in instantaneous weight values caused by large loss variances, enabling smooth weight updating and stable training. Extensive experiments demonstrate that DB-PINN achieves significantly superior performance than those popular gradient-based weighting methods in terms of convergence speed and prediction accuracy. Our code and supplementary material are available at https://github.com/chenhong-zhou/DualBalanced-PINNs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11117v3</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenhong Zhou, Jie Chen, Zaifeng Yang, Ching Eng Png</dc:creator>
    </item>
  </channel>
</rss>
