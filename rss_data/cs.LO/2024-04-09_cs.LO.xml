<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 10 Apr 2024 04:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 10 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Syndicate: Synergistic Synthesis of Ranking Function and Invariants for Termination Analysis</title>
      <link>https://arxiv.org/abs/2404.05951</link>
      <description>arXiv:2404.05951v1 Announce Type: new 
Abstract: Several techniques have been developed to prove the termination of programs. Finding ranking functions is one of the common approaches to do so. A ranking function must be bounded and must reduce at every iteration for all the reachable program states. Since the set of reachable states is often unknown, invariants serve as an over-approximation. Further, in the case of nested loops, the initial set of program states for the nested loop can be determined by the invariant of the outer loop. So, invariants play an important role in proving the validity of a ranking function in the absence of the exact reachable states. However, in the existing techniques, either the invariants are synthesized independently, or combined with ranking function synthesis into a single query, both of which are inefficient.
  We observe that a guided search for invariants and ranking functions can have benefits in terms of the number of programs that can be proved to terminate and the time needed to identify a proof of termination. So, in this work, we develop Syndicate, a novel framework that synergistically guides the search for both the ranking function and an invariant that together constitute a proof of termination. Owing to our synergistic approach, Syndicate can not only prove the termination of more benchmarks but also achieves a reduction ranging from 17% to 70% in the average runtime as compared to existing state-of-the-art termination analysis tools. We also prove that Syndicate is relatively complete, i.e., if there exists a ranking function and an invariant in their respective templates that can be used to prove the termination of a program, then Syndicate will always find it if there exist complete procedures for the template-specific functions in our framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05951v1</guid>
      <category>cs.LO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yasmin Sarita, Avaljot Singh, Shaurya Gomber, Gagandeep Singh, Mahesh Vishwanathan</dc:creator>
    </item>
    <item>
      <title>Weak Simplicial Bisimilarity for Polyhedral Models and SLCS_eta -- Extended Version</title>
      <link>https://arxiv.org/abs/2404.06131</link>
      <description>arXiv:2404.06131v1 Announce Type: new 
Abstract: In the context of spatial logics and spatial model checking for polyhedral models - mathematical basis for visualisations in continuous space - we propose a weakening of simplicial bisimilarity. We additionally propose a corresponding weak notion of +/--bisimilarity on cell-poset models, a discrete representation of polyhedral models. We show that two points are weakly simplicial bisimilar iff their repesentations are weakly +/--bisimilar. The advantage of this weaker notion is that it leads to a stronger reduction of models than its counterpart that was introduced in our previous work. This is important, since real-world polyhedral models, such as those found in domains exploiting mesh processing, typically consist of large numbers of cells. We also propose SLCS_eta, a weaker version of the Spatial Logic for Closure Spaces (SLCS) on polyhedral models, and we show that the proposed bisimilarities enjoy the Hennessy-Milner property: two points are weakly simplicial bisimilar iff they are logically equivalent for SLCS_eta. Similarly, two cells are weakly +/--bisimilar iff they are logically equivalent in the poset-model interpretation of SLCS_eta. This work is performed in the context of the geometric spatial model checker PolyLogicA and the polyhedral semantics of SLCS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06131v1</guid>
      <category>cs.LO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nick Bezhanishvili, Vincenzo Ciancia, David Gabelaia, Mamuka Jibladze, Diego Latella, Mieke Massink, Erik P. de Vink</dc:creator>
    </item>
    <item>
      <title>A Semantic Proof of Generalised Cut Elimination for Deep Inference</title>
      <link>https://arxiv.org/abs/2404.06233</link>
      <description>arXiv:2404.06233v1 Announce Type: new 
Abstract: Multiplicative-Additive System Virtual (MAV) is a logic that extends Multiplicative-Additive Linear Logic with a self-dual non-commutative operator expressing the concept of "before" or "sequencing". MAV is also an extenson of the the logic Basic System Virtual (BV) with additives. Formulas in BV have an appealing reading as processes with parallel and sequential composition. MAV adds internal and external choice operators. BV and MAV are also closely related to Concurrent sKleene Algebras.
  Proof systems for MAV and BV are Deep Inference systems, which allow inference rules to be applied anywhere inside a structure. As with any proof system, a key question is whether proofs in MAV can be reduced to a normal form, removing detours and the introduction of structures not present in the original goal. In Sequent Calcluli systems, this property is referred to as Cut Elimination. Deep Inference systems have an analogous Cut rule and other rules that are not present in normalised proofs. Cut Elimination for Deep Inference systems has the same metatheoretic benefits as for Sequent Calculi systems, including consistency and decidability.
  Proofs of Cut Elimination for BV, MAV, and other Deep Inference systems present in the literature have relied on intrincate syntactic reasoning and complex termination measures.
  We present a concise semantic proof that all MAV proofs can be reduced to a normal form avoiding the Cut rule and other "non analytic" rules. We also develop soundness and completeness proofs of MAV (and BV) with respect to a class of models. We have mechanised all our proofs in the Agda proof assistant, which provides both assurance of their correctness as well as yielding an executable normalisation procedure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06233v1</guid>
      <category>cs.LO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert Atkey, Wen Kokke</dc:creator>
    </item>
    <item>
      <title>Meaningfulness and Genericity in a Subsuming Framework</title>
      <link>https://arxiv.org/abs/2404.06361</link>
      <description>arXiv:2404.06361v1 Announce Type: new 
Abstract: This paper studies the notion of meaningfulness for a unifying framework called dBang-calculus, which subsumes both call-by-name (dCbN) and call-by-value (dCbV). We first characterize meaningfulness in dBang by means of typability and inhabitation in an associated non-idempotent intersection type system previously proposed in the literature. We validate the proposed notion of meaningfulness by showing two properties (1) consistency of the theory $\mathcal{H}$ equating meaningless terms and (2) genericity, stating that meaningless subterms have no bearing on the significance of meaningful terms. The theory $\mathcal{H}$ is also shown to have a unique consistent and maximal extension. Last but not least, we show that the notions of meaningfulness and genericity in the literature for dCbN and dCbV are subsumed by the respectively ones proposed here for the dBang-calculus.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06361v1</guid>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Delia Kesner, Victor Arrial, Giulio Guerrieri</dc:creator>
    </item>
    <item>
      <title>Verification of Recursively Defined Quantum Circuits</title>
      <link>https://arxiv.org/abs/2404.05934</link>
      <description>arXiv:2404.05934v1 Announce Type: cross 
Abstract: Recursive techniques have recently been introduced into quantum programming so that a variety of large quantum circuits and algorithms can be elegantly and economically programmed. In this paper, we present a proof system for formal verification of the correctness of recursively defined quantum circuits. The soundness and (relative) completeness of the proof system are established. To demonstrating its effectiveness, a series of application examples of the proof system are given, including (multi-qubit) controlled gates, a quantum circuit generating (multi-qubit) GHZ (Greenberger-Horne-Zeilinger) states, recursive definition of quantum Fourier transform, quantum state preparation, and quantum random-access memories (QRAM).</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05934v1</guid>
      <category>quant-ph</category>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mingsheng Ying, Zhicheng Zhang</dc:creator>
    </item>
    <item>
      <title>Monoidal Context Theory</title>
      <link>https://arxiv.org/abs/2404.06192</link>
      <description>arXiv:2404.06192v1 Announce Type: cross 
Abstract: We universally characterize the produoidal category of monoidal lenses over a monoidal category. In the same way that each category induces a cofree promonoidal category of spliced arrows, each monoidal category induces a cofree produoidal category of monoidal spliced arrows; monoidal lenses are the free normalization of the cofree produoidal category of monoidal spliced arrows. We apply the characterization of symmetric monoidal lenses to the analysis of multi-party message-passing protocols. We introduce a minimalistic axiomatization of message passing -- message theories -- and we construct combinatorially the free message theory over a set. Symmetric monoidal lenses are the derivations of the free message theory over a symmetric monoidal category.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06192v1</guid>
      <category>math.CT</category>
      <category>cs.LO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Mario Rom\'an</dc:creator>
    </item>
    <item>
      <title>Mechanised Hypersafety Proofs about Structured Data: Extended Version</title>
      <link>https://arxiv.org/abs/2404.06477</link>
      <description>arXiv:2404.06477v1 Announce Type: cross 
Abstract: Arrays are a fundamental abstraction to represent collections of data. It is often possible to exploit structural properties of the data stored in an array (e.g., repetition or sparsity) to develop a specialised representation optimised for space efficiency. Formally reasoning about correctness of manipulations with such structured data is challenging, as they are often composed of multiple loops with non-trivial invariants.
  In this work, we observe that specifications for structured data manipulations can be phrased as hypersafety properties, i.e., predicates that relate traces of $k$ programs. To turn this observation into an effective verification methodology, we developed the Logic for Graceful Tensor Manipulation (LGTM), a new Hoare-style relational separation logic for specifying and verifying computations over structured data. The key enabling idea of LGTM is that of parametrised hypersafety specifications that allow the number $k$ of the program components to depend on the program variables. We implemented LGTM as a foundational embedding into Coq, mechanising its rules, meta-theory, and the proof of soundness. Furthermore, we developed a library of domain-specific tactics that automate computer-aided hypersafety reasoning, resulting in pleasantly short proof scripts that enjoy a high degree of reuse. We argue for the effectiveness of relational reasoning about structured data in LGTM by specifying and mechanically proving correctness of 13 case studies including computations on compressed arrays and efficient operations over multiple kinds of sparse tensors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06477v1</guid>
      <category>cs.PL</category>
      <category>cs.LO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3656403</arxiv:DOI>
      <dc:creator>Vladimir Gladshtein, Qiyuan Zhao, Willow Ahrens, Saman Amarasinghe, Ilya Sergey</dc:creator>
    </item>
    <item>
      <title>Inapproximability of Unique Games in Fixed-Point Logic with Counting</title>
      <link>https://arxiv.org/abs/2104.04566</link>
      <description>arXiv:2104.04566v5 Announce Type: replace 
Abstract: We study the extent to which it is possible to approximate the optimal value of a Unique Games instance in Fixed-Point Logic with Counting (FPC). Formally, we prove lower bounds against the accuracy of FPC-interpretations that map Unique Games instances (encoded as relational structures) to rational numbers giving the approximate fraction of constraints that can be satisfied. We prove two new FPC-inexpressibility results for Unique Games: the existence of a $(1/2, 1/3 + \delta)$-inapproximability gap, and inapproximability to within any constant factor. Previous recent work has established similar FPC-inapproximability results for a small handful of other problems. Our construction builds upon some of these ideas, but contains a novel technique. While most FPC-inexpressibility results are based on variants of the CFI-construction, ours is significantly different. We start with a graph of very large girth and label the edges with random affine vector spaces over $\mathbb{F}_2$ that determine the constraints in the two structures. Duplicator's strategy involves maintaining a partial isomorphism over a minimal tree that spans the pebbled vertices of the graph.</description>
      <guid isPermaLink="false">oai:arXiv.org:2104.04566v5</guid>
      <category>cs.LO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jamie Tucker-Foltz</dc:creator>
    </item>
    <item>
      <title>On the Metric Temporal Logic for Continuous Stochastic Processes</title>
      <link>https://arxiv.org/abs/2308.00984</link>
      <description>arXiv:2308.00984v5 Announce Type: replace 
Abstract: In this paper, we prove measurability of event for which a general continuous-time stochastic process satisfies continuous-time Metric Temporal Logic (MTL) formula. Continuous-time MTL can define temporal constrains for physical system in natural way. Then there are several researches that deal with probability of continuous MTL semantics for stochastic processes. However, proving measurability for such events is by no means an obvious task, even though it is essential. The difficulty comes from the semantics of "until operator", which is defined by logical sum of uncountably many propositions. Given the difficulty involved in proving the measurability of such an event using classical measure-theoretic methods, we employ a theorem from stochastic analysis. This theorem is utilized to prove the measurability of hitting times for stochastic processes, and it stands as a profound result within the theory of capacity. Next, we provide an example that illustrates the failure of probability approximation when discretizing the continuous semantics of MTL formulas with respect to time. Additionally, we prove that the probability of the discretized semantics converges to that of the continuous semantics when we impose restrictions on diamond operators to prevent nesting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.00984v5</guid>
      <category>cs.LO</category>
      <category>math.LO</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mitsumasa Ikeda, Yoriyuki Yamagata, Takayuki Kihara</dc:creator>
    </item>
    <item>
      <title>Taking Complete Finite Prefixes To High Level, Symbolically</title>
      <link>https://arxiv.org/abs/2311.11443</link>
      <description>arXiv:2311.11443v3 Announce Type: replace 
Abstract: Unfoldings are a well known partial-order semantics of P/T Petri nets that can be applied to various model checking or verification problems. For high-level Petri nets, the so-called symbolic unfolding generalizes this notion. A complete finite prefix of a P/T Petri net's unfolding contains all information to verify, e.g., reachability of markings. We unite these two concepts and define complete finite prefixes of the symbolic unfolding of high-level Petri nets. For a class of safe high-level Petri nets, we generalize the well-known algorithm by Esparza et al. for constructing small such prefixes. We evaluate this extended algorithm through a prototype implementation on four novel benchmark families. Additionally, we identify a more general class of nets with infinitely many reachable markings, for which an approach with an adapted cut-off criterion extends the complete prefix methodology, in the sense that the original algorithm cannot be applied to the P/T net represented by a high-level net.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.11443v3</guid>
      <category>cs.LO</category>
      <category>cs.FL</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nick W\"urdemann, Thomas Chatain, Stefan Haar, Lukas Panneke</dc:creator>
    </item>
    <item>
      <title>Inferentialist Resource Semantics</title>
      <link>https://arxiv.org/abs/2402.09217</link>
      <description>arXiv:2402.09217v3 Announce Type: replace 
Abstract: In systems modelling, a system typically comprises located resources relative to which processes execute. One important use of logic in informatics is in modelling such systems for the purpose of reasoning (perhaps automated) about their behaviour and properties. To this end, one requires an interpretation of logical formulae in terms of the resources and states of the system; such an interpretation is called a resource semantics of the logic. This paper shows how inferentialism -- the view that meaning is given in terms of inferential behaviour -- enables a versatile and expressive framework for resource semantics. Specifically, how inferentialism seamlessly incorporates the assertion-based approach of the logic of Bunched Implications, foundational in program verification (e.g., as the basis of Separation Logic), and the renowned number-of-uses reading of Linear Logic. This integration enables reasoning about shared and separated resources in intuitive and familiar ways, as well as about the composition and interfacing of system components.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.09217v3</guid>
      <category>cs.LO</category>
      <category>cs.CR</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.LO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander V. Gheorghiu, Tao Gu, David J. Pym</dc:creator>
    </item>
    <item>
      <title>Definitional Functoriality for Dependent (Sub)Types -- Extended version</title>
      <link>https://arxiv.org/abs/2310.14929</link>
      <description>arXiv:2310.14929v2 Announce Type: replace-cross 
Abstract: Dependently typed proof assistant rely crucially on definitional equality, which relates types and terms that are automatically identified in the underlying type theory. This paper extends type theory with definitional functor laws, equations satisfied propositionally by a large class of container-like type constructors $F : \mathrm{Type} \to \mathrm{Type}$, equipped with a $\mathrm{map}_{F} : (A \to B) \to F\,A \to F\,B$, such as lists or trees. Promoting these equations to definitional ones strengthens the theory, enabling slicker proofs and more automation for functorial type constructors. This extension is used to modularly justify a structural form of coercive subtyping, propagating subtyping through type formers in a map-like fashion. We show that the resulting notion of coercive subtyping, thanks to the extra definitional equations, is equivalent to a natural and implicit form of subsumptive subtyping. The key result of decidability of type-checking in a dependent type system with functor laws for lists has been entirely mechanized in Coq. This is the extended version of the work with the same name published at ESOP'24.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.14929v2</guid>
      <category>cs.PL</category>
      <category>cs.LO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Th\'eo Laurent, Meven Lennon-Bertrand, Kenji Maillard</dc:creator>
    </item>
  </channel>
</rss>
