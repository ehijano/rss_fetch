<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 17 May 2024 04:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 17 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>The Best Radar Ranging Pulse to Resolve Two Reflectors</title>
      <link>https://arxiv.org/abs/2405.09571</link>
      <description>arXiv:2405.09571v1 Announce Type: cross 
Abstract: Previous work established fundamental bounds on subwavelength resolution for the radar range resolution problem, called superradar [Phys. Rev. Appl. 20, 064046 (2023)]. In this work, we identify the optimal waveforms for distinguishing the range resolution between two reflectors of identical strength. We discuss both the unnormalized optimal waveform as well as the best square-integrable pulse, and their variants. Using orthogonal function theory, we give an explicit algorithm to optimize the wave pulse in finite time to have the best performance. We also explore range resolution estimation with unnormalized waveforms with multi-parameter methods to also independently estimate loss and time of arrival. These results are consistent with the earlier single parameter approach of range resolution only and give deeper insight into the ranging estimation problem. Experimental results are presented using radio pulse reflections inside coaxial cables, showing robust range resolution smaller than a tenth of the inverse bandedge, with uncertainties close to the derived Cram\'er-Rao bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09571v1</guid>
      <category>eess.SP</category>
      <category>physics.data-an</category>
      <category>physics.optics</category>
      <category>quant-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrew N. Jordan, John C. Howell, Achim Kempf, Shunxing Zhang, Derek White</dc:creator>
    </item>
    <item>
      <title>Scalable Sparse Regression for Model Discovery: The Fast Lane to Insight</title>
      <link>https://arxiv.org/abs/2405.09579</link>
      <description>arXiv:2405.09579v1 Announce Type: cross 
Abstract: There exist endless examples of dynamical systems with vast available data and unsatisfying mathematical descriptions. Sparse regression applied to symbolic libraries has quickly emerged as a powerful tool for learning governing equations directly from data; these learned equations balance quantitative accuracy with qualitative simplicity and human interpretability. Here, I present a general purpose, model agnostic sparse regression algorithm that extends a recently proposed exhaustive search leveraging iterative Singular Value Decompositions (SVD). This accelerated scheme, Scalable Pruning for Rapid Identification of Null vecTors (SPRINT), uses bisection with analytic bounds to quickly identify optimal rank-1 modifications to null vectors. It is intended to maintain sensitivity to small coefficients and be of reasonable computational cost for large symbolic libraries. A calculation that would take the age of the universe with an exhaustive search but can be achieved in a day with SPRINT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09579v1</guid>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthew Golden</dc:creator>
    </item>
    <item>
      <title>Holevo Cram\'er-Rao bound: How close can we get without entangling measurements?</title>
      <link>https://arxiv.org/abs/2405.09622</link>
      <description>arXiv:2405.09622v1 Announce Type: cross 
Abstract: In multi-parameter quantum metrology, the resource of entanglement can lead to an increase in efficiency of the estimation process. Entanglement can be used in the state preparation stage, or the measurement stage, or both, to harness this advantage; here we focus on the role of entangling measurements. Specifically, entangling or collective measurements over multiple identical copies of a probe state are known to be superior to measuring each probe individually, but the extent of this improvement is an open problem. It is also known that such entangling measurements, though resource-intensive, are required to attain the ultimate limits in multi-parameter quantum metrology and quantum information processing tasks. In this work we investigate the maximum precision improvement that collective quantum measurements can offer over individual measurements for estimating parameters of qudit states, calling this the 'collective quantum enhancement'. We show that, whereas the maximum enhancement can, in principle, be a factor of $n$ for estimating $n$ parameters, this bound is not tight for large $n$. Instead, our results prove an enhancement linear in dimension of the qudit is possible using collective measurements and lead us to conjecture that this is the maximum collective quantum enhancement in any local estimation scenario.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09622v1</guid>
      <category>quant-ph</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aritra Das, Lorc\'an O. Conlon, Jun Suzuki, Simon K. Yung, Ping K. Lam, Syed M. Assad</dc:creator>
    </item>
    <item>
      <title>Active Learning with Fully Bayesian Neural Networks for Discontinuous and Nonstationary Data</title>
      <link>https://arxiv.org/abs/2405.09817</link>
      <description>arXiv:2405.09817v1 Announce Type: cross 
Abstract: Active learning optimizes the exploration of large parameter spaces by strategically selecting which experiments or simulations to conduct, thus reducing resource consumption and potentially accelerating scientific discovery. A key component of this approach is a probabilistic surrogate model, typically a Gaussian Process (GP), which approximates an unknown functional relationship between control parameters and a target property. However, conventional GPs often struggle when applied to systems with discontinuities and non-stationarities, prompting the exploration of alternative models. This limitation becomes particularly relevant in physical science problems, which are often characterized by abrupt transitions between different system states and rapid changes in physical property behavior. Fully Bayesian Neural Networks (FBNNs) serve as a promising substitute, treating all neural network weights probabilistically and leveraging advanced Markov Chain Monte Carlo techniques for direct sampling from the posterior distribution. This approach enables FBNNs to provide reliable predictive distributions, crucial for making informed decisions under uncertainty in the active learning setting. Although traditionally considered too computationally expensive for 'big data' applications, many physical sciences problems involve small amounts of data in relatively low-dimensional parameter spaces. Here, we assess the suitability and performance of FBNNs with the No-U-Turn Sampler for active learning tasks in the 'small data' regime, highlighting their potential to enhance predictive accuracy and reliability on test functions relevant to problems in physical sciences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09817v1</guid>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maxim Ziatdinov</dc:creator>
    </item>
    <item>
      <title>Novel Data Models for Inter-operable LCA Frameworks</title>
      <link>https://arxiv.org/abs/2405.10235</link>
      <description>arXiv:2405.10235v1 Announce Type: cross 
Abstract: Life cycle assessment (LCA) plays a critical role in assessing the environmental impacts of a product, technology, or service throughout its entire life cycle. Nonetheless, many existing LCA tools and methods lack adequate metadata management, which can hinder their further development and wide adoption. In the example of LCA for clean energy technologies, metadata helps monitor data and the environment that holds the integrity of the energy assets and sustainability of the materials sources across their entire value chains. Ontologizing metadata, i.e. a common vocabulary and language to connect multiple data sources, as well as implementing AI-aware data management, can have long-lasting, positive, and accelerating effects along with collecting and utilizing quality data from different sources and across the entire data lifecycle. The integration of ontologies in life cycle assessments has garnered significant attention in recent years. We synthesized the existing literature on ontologies for LCAs, providing insights into this interdisciplinary field's evolution, current state, and future directions. We also proposed the framework for a suitable data model and the workflow thereof to warrant the alignment with existing ontologies, practical frameworks, and industry standards.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10235v1</guid>
      <category>cs.DB</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kourosh Malek, Max Dreger, Zirui Tang, Qingshi Tu</dc:creator>
    </item>
    <item>
      <title>CaloFlow for CaloChallenge Dataset 1</title>
      <link>https://arxiv.org/abs/2210.14245</link>
      <description>arXiv:2210.14245v3 Announce Type: replace-cross 
Abstract: CaloFlow is a new and promising approach to fast calorimeter simulation based on normalizing flows. Applying CaloFlow to the photon and charged pion Geant4 showers of Dataset 1 of the Fast Calorimeter Simulation Challenge 2022, we show how it can produce high-fidelity samples with a sampling time that is several orders of magnitude faster than Geant4. We demonstrate the fidelity of the samples using calorimeter shower images, histograms of high-level features, and aggregate metrics such as a classifier trained to distinguish CaloFlow from Geant4 samples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.14245v3</guid>
      <category>physics.ins-det</category>
      <category>cs.LG</category>
      <category>hep-ex</category>
      <category>hep-ph</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.21468/SciPostPhys.16.5.126</arxiv:DOI>
      <arxiv:journal_reference>SciPost Phys. 16, 126 (2024)</arxiv:journal_reference>
      <dc:creator>Claudius Krause, Ian Pang, David Shih</dc:creator>
    </item>
    <item>
      <title>Calorimeter shower superresolution</title>
      <link>https://arxiv.org/abs/2308.11700</link>
      <description>arXiv:2308.11700v3 Announce Type: replace-cross 
Abstract: Calorimeter shower simulation is a major bottleneck in the Large Hadron Collider computational pipeline. There have been recent efforts to employ deep-generative surrogate models to overcome this challenge. However, many of best performing models have training and generation times that do not scale well to high-dimensional calorimeter showers. In this work, we introduce SuperCalo, a flow-based superresolution model, and demonstrate that high-dimensional fine-grained calorimeter showers can be quickly upsampled from coarse-grained showers. This novel approach presents a way to reduce computational cost, memory requirements and generation time associated with fast calorimeter simulation models. Additionally, we show that the showers upsampled by SuperCalo possess a high degree of variation. This allows a large number of high-dimensional calorimeter showers to be upsampled from much fewer coarse showers with high-fidelity, which results in additional reduction in generation time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.11700v3</guid>
      <category>physics.ins-det</category>
      <category>cs.LG</category>
      <category>hep-ex</category>
      <category>hep-ph</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1103/PhysRevD.109.092009</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. D 109, 092009 (2024)</arxiv:journal_reference>
      <dc:creator>Ian Pang, John Andrew Raine, David Shih</dc:creator>
    </item>
  </channel>
</rss>
