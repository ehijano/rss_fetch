<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 06 Nov 2024 05:00:45 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Rate of convergence of a semi-implicit time Euler scheme for a 2D B\'enard-Boussinesq model</title>
      <link>https://arxiv.org/abs/2411.02590</link>
      <description>arXiv:2411.02590v1 Announce Type: new 
Abstract: We prove that a semi-implicit time Euler scheme for the two-dimensional B\'enard-Boussinesq model on the torus D converges. The rate of convergence in probability is almost 1/2 for a multiplicative noise; this relies on moment estimates in various norms for the processes and the scheme.
  In case of an additive noise, due to the coupling of the equations, provided that the difference on temperature between the top and bottom parts of the torus is not too big compared to the viscosity and thermal diffusivity, a strong polynomial rate of convergence (almost 1/2) is proven in $(L^2(D))^2$ for the velocity and in $L^2(D)$ for the temperature.
  It depends on exponential moments of the scheme; due to linear terms involving the other quantity in both evolution equations, the proof has to be done simultaneaously for both the velocity and the temperature. These rates in both cases are similar to that obtained for the Navier-Stokes equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02590v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Hakima Bessaih, Annie Millet</dc:creator>
    </item>
    <item>
      <title>A Discontinuous Galerkin Method for the Extracellular Membrane Intracellular Model</title>
      <link>https://arxiv.org/abs/2411.02646</link>
      <description>arXiv:2411.02646v1 Announce Type: new 
Abstract: We formulate and analyze interior penalty discontinuous Galerkin methods for coupled elliptic PDEs modeling excitable tissue, represented by intracellular and extracellular domains sharing a common interface. The PDEs are coupled through a dynamic boundary condition, posed on the interface, that relates the normal gradients of the solutions to the time derivative of their jump. This system is referred to as the Extracellular Membrane Intracellular model or the cell-by-cell model. Due to the dynamic nature of the interface condition and to the presence of corner singularities, the analysis of discontinuous Galerkin methods is non-standard. We prove the existence and uniqueness of solutions by a reformulation of the problem to one posed on the membrane. Convergence is shown by utilizing face-to-element lifting operators and notions of weak consistency suitable for solutions with low spatial regularity. Further, we present parameter-robust preconditioned iterative solvers. Numerical examples in idealized geometries demonstrate our theoretical findings, and simulations in multiple cells portray the robustness of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02646v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rami Masri, Keegan L. A. Kirk, Eirill Hauge, Miroslav Kuchta</dc:creator>
    </item>
    <item>
      <title>The shift-and-invert Arnoldi method for singular matrix pencils</title>
      <link>https://arxiv.org/abs/2411.02895</link>
      <description>arXiv:2411.02895v1 Announce Type: new 
Abstract: The numerical solution of singular generalized eigenvalue problems is still challenging. In Hochstenbach, Mehl, and Plestenjak, Solving Singular Generalized Eigenvalue Problems by a Rank-Completing Perturbation, SIMAX 2019, a rank-completing perturbation was proposed and a related bordering of the singular pencil. For large sparse pencils, we propose an LU factorization that determines a rank completing perturbation that regularizes the pencil and that is then used in the shift-and-invert Arnoldi method to obtain eigenvalues nearest a shift. Numerical examples illustrate the theory and the algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02895v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karl Meerbergen, Zhijun Wang</dc:creator>
    </item>
    <item>
      <title>A stabilized nonconforming finite element method for the surface biharmonic problem</title>
      <link>https://arxiv.org/abs/2411.02952</link>
      <description>arXiv:2411.02952v1 Announce Type: new 
Abstract: This paper presents a novel stabilized nonconforming finite element method for solving the surface biharmonic problem. The method extends the New-Zienkiewicz-type (NZT) element to polyhedral (approximated) surfaces by employing the Piola transform to establish the connection of vertex gradients across adjacent elements. Key features of the surface NZT finite element space include its $H^1$-relative conformity and weak $H({\rm div})$ conformity, allowing for stabilization without the use of artificial parameters. Under the assumption that the exact solution and the dual problem possess only $H^3$ regularity, we establish optimal error estimates in the energy norm and provide, for the first time, a comprehensive analysis yielding optimal second-order convergence in the broken $H^1$ norm. Numerical experiments are provided to support the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02952v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuonan Wu, Hao Zhou</dc:creator>
    </item>
    <item>
      <title>A Linear-complexity Tensor Butterfly Algorithm for Compressing High-dimensional Oscillatory Integral Operators</title>
      <link>https://arxiv.org/abs/2411.03029</link>
      <description>arXiv:2411.03029v1 Announce Type: new 
Abstract: This paper presents a multilevel tensor compression algorithm called tensor butterfly algorithm for efficiently representing large-scale and high-dimensional oscillatory integral operators, including Green's functions for wave equations and integral transforms such as Radon transforms and Fourier transforms. The proposed algorithm leverages a tensor extension of the so-called complementary low-rank property of existing matrix butterfly algorithms. The algorithm partitions the discretized integral operator tensor into subtensors of multiple levels, and factorizes each subtensor at the middle level as a Tucker-like interpolative decomposition, whose factor matrices are formed in a multilevel fashion. For a $d$-dimensional integral operator discretized into a $2d$-mode tensor with $n^{2d}$ entries, the overall CPU time and memory requirement scale as $O(n^d)$, in stark contrast to the $O(n^d\log n)$ requirement of existing matrix algorithms such as matrix butterfly algorithm and fast Fourier transforms (FFT), where $n$ is the number of points per direction. When comparing with other tensor algorithms such as quantized tensor train (QTT), the proposed algorithm also shows superior CPU and memory performance for tensor contraction. Remarkably, the tensor butterfly algorithm can efficiently model high-frequency Green's function interactions between two unit cubes, each spanning 512 wavelengths per direction, which represents over $512\times$ larger problem sizes than existing algorithms. On the other hand, for a problem representing 64 wavelengths per direction, which is the largest size existing algorithms can handle, our tensor butterfly algorithm exhibits 200x speedups and $30\times$ memory reduction comparing with existing ones. Moreover, the tensor butterfly algorithm also permits $O(n^d)$-complexity FFTs and Radon transforms up to $d=6$ dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03029v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>P. Michael Kielstra, Tianyi Shi, Hengrui Luo, Jianliang Qian, Yang Liu</dc:creator>
    </item>
    <item>
      <title>Adjoint lattice kinetic scheme for topology optimization in fluid problems</title>
      <link>https://arxiv.org/abs/2411.03090</link>
      <description>arXiv:2411.03090v1 Announce Type: new 
Abstract: This paper proposes a topology optimization method for non-thermal and thermal fluid problems using the Lattice Kinetic Scheme (LKS).LKS, which is derived from the Lattice Boltzmann Method (LBM), requires only macroscopic values, such as fluid velocity and pressure, whereas LBM requires velocity distribution functions, thereby reducing memory requirements. The proposed method computes design sensitivities based on the adjoint variable method, and the adjoint equation is solved in the same manner as LKS; thus, we refer to it as the Adjoint Lattice Kinetic Scheme (ALKS). A key contribution of this method is the proposed approximate treatment of boundary conditions for the adjoint equation, which is challenging to apply directly due to the characteristics of LKS boundary conditions. We demonstrate numerical examples for steady and unsteady problems involving non-thermal and thermal fluids, and the results are physically meaningful and consistent with previous research, exhibiting similar trends in parameter dependencies, such as the Reynolds number. Furthermore, the proposed method reduces memory usage by up to 75% compared to the conventional LBM in an unsteady thermal fluid problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03090v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuta Tanabe, Kentaro Yaji, Kuniharu Ushijima</dc:creator>
    </item>
    <item>
      <title>A priori and a posteriori error estimates of a DG-CG method for the wave equation in second order formulation</title>
      <link>https://arxiv.org/abs/2411.03264</link>
      <description>arXiv:2411.03264v1 Announce Type: new 
Abstract: We establish fully-discrete a priori and semi-discrete in time a posteriori error estimates for a discontinuous-continuous Galerkin discretization of the wave equation in second order formulation; the resulting method is a Petrov-Galerkin scheme based on piecewise and piecewise continuous polynomial in time test and trial spaces, respectively. Crucial tools in the a priori analysis for the fully-discrete formulation are the design of suitable projection and interpolation operators extending those used in the parabolic setting, and stability estimates based on a nonstandard choice of the test function; a priori estimates are shown, which are measured in $L^\infty$-type norms in time. For the semi-discrete in time formulation, we exhibit constant-free, reliable a posteriori error estimates for the error measured in the $L^\infty(L^2)$ norm; to this aim, we design a reconstruction operator into $\mathcal C^1$ piecewise polynomials over the time grid with optimal approximation properties in terms of the polynomial degree distribution and the time steps. Numerical examples illustrate the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03264v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhaonan Dong, Lorenzo Mascotto, Zuodong Wang</dc:creator>
    </item>
    <item>
      <title>Optimal bounds for POD approximations of infinite horizon control problems based on time derivatives</title>
      <link>https://arxiv.org/abs/2310.10552</link>
      <description>arXiv:2310.10552v3 Announce Type: replace 
Abstract: In this paper we consider the numerical approximation of infinite horizon problems via the dynamic programming approach. The value function of the problem solves a Hamilton-Jacobi-Bellman (HJB) equation that is approximated by a fully discrete method. It is known that the numerical problem is difficult to handle by the so called curse of dimensionality. To mitigate this issue we apply a reduction of the order by means of a new proper orthogonal decomposition (POD) method based on time derivatives. We carry out the error analysis of the method using recently proved optimal bounds for the fully discrete approximations. Moreover, the use of snapshots based on time derivatives allow us to bound some terms of the error that could not be bounded in a standard POD approach. Some numerical experiments show the good performance of the method in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.10552v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Javier de Frutos, Bosco Garcia-Archilla, Julia Novo</dc:creator>
    </item>
    <item>
      <title>Augmented physics informed extreme learning machine to solve the biharmonic equations via Fourier expansions</title>
      <link>https://arxiv.org/abs/2310.13947</link>
      <description>arXiv:2310.13947v4 Announce Type: replace 
Abstract: To address the sensitivity of parameters and limited precision for physics-informed extreme learning machines (PIELM) with common activation functions, such as sigmoid, tangent, and Gaussian, in solving high-order partial differential equations (PDEs) relevant to scientific computation and engineering applications, this work develops a Fourier-induced PIELM (FPIELM) method. This approach aims to approximate solutions for a class of fourth-order biharmonic equations with two boundary conditions on both unitized and non-unitized domains. By carefully calculating the differential and boundary operators of the biharmonic equation on discretized collections, the solution for this high-order equation is reformulated as a linear least squares minimization problem. We further evaluate the FPIELM with varying hidden nodes and scaling factors for uniform distribution initialization, and then determine the optimal range for these two hyperparameters. Numerical experiments and comparative analyses demonstrate that the proposed FPIELM method is more stable, robust, precise, and efficient than other PIELM approaches in solving biharmonic equations across both regular and irregular domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.13947v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Xi'an Li, Jinran Wu, Yujia Huang, Zhe Ding, Xin Tai, Liang Liu, You-Gan Wang</dc:creator>
    </item>
    <item>
      <title>Bidirectional conformal mapping for over-break and under-break tunnelling and its application in complex variable method</title>
      <link>https://arxiv.org/abs/2406.12148</link>
      <description>arXiv:2406.12148v2 Announce Type: replace 
Abstract: Over-break and under-break excavation is very common in practical tunnel engineering with asymmetrical cavity contour, while existing conformal mapping schemes of complex variable method generally focus on tunnelling with theoretical and symmetrical cavity contour. Besides, the solution strategies of existing conformal mapping schemes for noncircular tunnel generally apply optimization theory, and are thereby mathematically complicated. This paper proposes a new bidirectional conformal mapping for over-break and under-break tunnels of asymmetrical contours by incorporating Charge Simulation Method, which only involves a pair of forward and backward linear systems, and is therefore logically straight-forward, computationally efficient, and practically easy in coding. New numerical strategies are developed to deal with possible sharp corners of cavity by small arc simulation and densified collocation points. Several numerical examples are presented to illustrate the geometrical usage of the new bidirectional conformal mapping. Furthermore, the new bidirectional conformal mapping is embedded into two complex variable solutions of under-break shallow tunnelling in gravitational geomaterial with reasonable far-field displacement. The respective result comparisons with finite element solution and existing analytical solution show good agreements, indicating that the new bidirectional conformal mapping would extend the mechanical application range of the complex variable method in practical over-break and under-break tunnelling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12148v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.CV</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luobin Lin, Fuquan Chen, Changjie Zheng, Shangshun Lin</dc:creator>
    </item>
    <item>
      <title>Convolution tensor decomposition for efficient high-resolution solutions to the Allen-Cahn equation</title>
      <link>https://arxiv.org/abs/2410.15519</link>
      <description>arXiv:2410.15519v2 Announce Type: replace 
Abstract: This paper presents a convolution tensor decomposition based model reduction method for solving the Allen-Cahn equation. The Allen-Cahn equation is usually used to characterize phase separation or the motion of anti-phase boundaries in materials. Its solution is time-consuming when high-resolution meshes and large time scale integration are involved. To resolve these issues, the convolution tensor decomposition method is developed, in conjunction with a stabilized semi-implicit scheme for time integration. The development enables a powerful computational framework for high-resolution solutions of Allen-Cahn problems, and allows the use of relatively large time increments for time integration without violating the discrete energy law. To further improve the efficiency and robustness of the method, an adaptive algorithm is also proposed. Numerical examples have confirmed the efficiency of the method in both 2D and 3D problems. Orders-of-magnitude speedups were obtained with the method for high-resolution problems, compared to the finite element method. The proposed computational framework opens numerous opportunities for simulating complex microstructure formation in materials on large-volume high-resolution meshes at a deeply reduced computational cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15519v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ye Lu, Chaoqian Yuan, Han Guo</dc:creator>
    </item>
    <item>
      <title>Hierarchical Network Partitioning for Solution of Potential-Driven, Steady-State Nonlinear Network Flow Equations</title>
      <link>https://arxiv.org/abs/2410.19850</link>
      <description>arXiv:2410.19850v2 Announce Type: replace 
Abstract: Potential-driven steady-state flow in networks is an abstract problem which manifests in various engineering applications, such as transport of natural gas, water, electric power through infrastructure networks or flow through fractured rocks modeled as discrete fracture networks. The relevance of steady-state network flow to control systems and optimization, as well as the question of the existence of a solution for a particular class of flows, has been established in a prior article (IEEE Control Systems Letters (2024), doi:10.1109/LCSYS.2024.3394317). Building on that foundation, this article concerns itself with computation of such a solution for a large network since the problem while simple when restricted to a single edge of a network, ceases to be so for a large network. The resultant system of nonlinear equations depends on the network topology and in general there is no numerical algorithm that offers guaranteed convergence to the solution (assuming a solution exists). Some methods offer guarantees in cases where the network topology satisfies certain assumptions, but these methods fail for larger networks. On the other hand, the Newton-Raphson algorithm offers a convergence guarantee if the starting point lies close to the (unknown) solution. It would be advantageous to compute the solution of the large nonlinear system through the solution of smaller nonlinear sub-systems wherein the solution algorithms (Newton-Raphson or otherwise) are more likely to succeed. This article proposes and describes such a procedure, an hierarchical network partitioning algorithm that enables the solution of large nonlinear systems corresponding to potential-driven steady-state network flow equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19850v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shriram Srinivasan, Kaarthik Sundar</dc:creator>
    </item>
    <item>
      <title>Losing momentum in continuous-time stochastic optimisation</title>
      <link>https://arxiv.org/abs/2209.03705</link>
      <description>arXiv:2209.03705v2 Announce Type: replace-cross 
Abstract: The training of modern machine learning models often consists in solving high-dimensional non-convex optimisation problems that are subject to large-scale data. In this context, momentum-based stochastic optimisation algorithms have become particularly widespread. The stochasticity arises from data subsampling which reduces computational cost. Both, momentum and stochasticity help the algorithm to converge globally. In this work, we propose and analyse a continuous-time model for stochastic gradient descent with momentum. This model is a piecewise-deterministic Markov process that represents the optimiser by an underdamped dynamical system and the data subsampling through a stochastic switching. We investigate longtime limits, the subsampling-to-no-subsampling limit, and the momentum-to-no-momentum limit. We are particularly interested in the case of reducing the momentum over time. Under convexity assumptions, we show convergence of our dynamical system to the global minimiser when reducing momentum over time and letting the subsampling rate go to infinity. We then propose a stable, symplectic discretisation scheme to construct an algorithm from our continuous-time dynamical system. In experiments, we study our scheme in convex and non-convex test problems. Additionally, we train a convolutional neural network in an image classification problem. Our algorithm {attains} competitive results compared to stochastic gradient descent with momentum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.03705v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kexin Jin, Jonas Latz, Chenguang Liu, Alessandro Scagliotti</dc:creator>
    </item>
    <item>
      <title>Fast Empirical Scenarios</title>
      <link>https://arxiv.org/abs/2307.03927</link>
      <description>arXiv:2307.03927v3 Announce Type: replace-cross 
Abstract: We seek to extract a small number of representative scenarios from large panel data that are consistent with sample moments. Among two novel algorithms, the first identifies scenarios that have not been observed before, and comes with a scenario-based representation of covariance matrices. The second proposal selects important data points from states of the world that have already realized, and are consistent with higher-order sample moment information. Both algorithms are efficient to compute and lend themselves to consistent scenario-based modeling and multi-dimensional numerical integration that can be used for interpretable decision-making under uncertainty. Extensive numerical benchmarking studies and an application in portfolio optimization favor the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.03927v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>q-fin.RM</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jcmds.2024.100099</arxiv:DOI>
      <arxiv:journal_reference>Journal of Computational Mathematics and Data Science, 12, 2024, 100099</arxiv:journal_reference>
      <dc:creator>Michael Multerer, Paul Schneider, Rohan Sen</dc:creator>
    </item>
    <item>
      <title>Convolution finite element based digital image correlation for displacement and strain measurements</title>
      <link>https://arxiv.org/abs/2311.03504</link>
      <description>arXiv:2311.03504v2 Announce Type: replace-cross 
Abstract: This work presents a novel global digital image correlation (DIC) method, based on a newly developed convolution finite element (C-FE) approximation. The convolution approximation can rely on the mesh of linear finite elements and enables arbitrarily high order approximations without adding more degrees of freedom. Therefore, the C-FE based DIC can be more accurate than {the} usual FE based DIC by providing highly smooth and accurate displacement and strain results with the same element size. The detailed formulation and implementation of the method have been discussed in this work. The controlling parameters in the method include the polynomial order, patch size, and dilation. A general choice of the parameters and their potential adaptivity have been discussed. The proposed DIC method has been tested by several representative examples, including the DIC challenge 2.0 benchmark problems, with comparison to the usual FE based DIC. C-FE outperformed FE in all the DIC results for the tested examples. This work demonstrates the potential of C-FE and opens a new avenue to enable highly smooth, accurate, and robust DIC analysis for full-field displacement and strain measurements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.03504v2</guid>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cma.2023.116597</arxiv:DOI>
      <dc:creator>Ye Lu, Weidong Zhu</dc:creator>
    </item>
    <item>
      <title>MicroAdam: Accurate Adaptive Optimization with Low Space Overhead and Provable Convergence</title>
      <link>https://arxiv.org/abs/2405.15593</link>
      <description>arXiv:2405.15593v2 Announce Type: replace-cross 
Abstract: We propose a new variant of the Adam optimizer called MicroAdam that specifically minimizes memory overheads, while maintaining theoretical convergence guarantees. We achieve this by compressing the gradient information before it is fed into the optimizer state, thereby reducing its memory footprint significantly. We control the resulting compression error via a novel instance of the classical \emph{error feedback} mechanism from distributed optimization in which *the error correction information is itself compressed* to allow for practical memory gains. We prove that the resulting approach maintains theoretical convergence guarantees competitive to those of AMSGrad, while providing good practical performance. Specifically, we show that MicroAdam can be implemented efficiently on GPUs: on both million-scale (BERT) and billion-scale (LLaMA) models, MicroAdam provides practical convergence competitive to that of the uncompressed Adam baseline, with lower memory usage and similar running time. Our code is available at https://github.com/IST-DASLab/MicroAdam.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15593v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ionut-Vlad Modoranu, Mher Safaryan, Grigory Malinovsky, Eldar Kurtic, Thomas Robert, Peter Richtarik, Dan Alistarh</dc:creator>
    </item>
    <item>
      <title>Families of lattices with an unbounded number of unit vectors</title>
      <link>https://arxiv.org/abs/2410.16172</link>
      <description>arXiv:2410.16172v2 Announce Type: replace-cross 
Abstract: 3 families of 4-dimensional lattices $L_k, M_k, M_k / 2 \subset \mathbb{R}^2$ are defined. Each lattice is defined by 2 quadratic extensions and has a \emph{finite} number of unit vectors, but the number of unit vectors in each of the 3 familes is \emph{unbounded}. $L_3$ is the Moser lattice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16172v2</guid>
      <category>math.MG</category>
      <category>cs.NA</category>
      <category>math.CO</category>
      <category>math.NA</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Helmut Ruhland</dc:creator>
    </item>
    <item>
      <title>Simulating incompressible flows over complex geometries using the shifted boundary method with incomplete adaptive octree meshes</title>
      <link>https://arxiv.org/abs/2411.00272</link>
      <description>arXiv:2411.00272v2 Announce Type: replace-cross 
Abstract: We extend the shifted boundary method (SBM) to the simulation of incompressible fluid flow using immersed octree meshes. Previous work on SBM for fluid flow primarily utilized two- or three-dimensional unstructured tetrahedral grids. Recently, octree grids have become an essential component of immersed CFD solvers, and this work addresses this gap and the associated computational challenges. We leverage an optimal (approximate) surrogate boundary constructed efficiently on incomplete and adaptive octree meshes. The resulting framework enables the simulation of the incompressible Navier-Stokes equations in complex geometries without requiring boundary-fitted grids. Simulations of benchmark tests in two and three dimensions demonstrate that the Octree-SBM framework is a robust, accurate, and efficient approach to simulating fluid dynamics problems with complex geometries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00272v2</guid>
      <category>physics.flu-dyn</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cheng-Hau Yang, Guglielmo Scovazzi, Adarsh Krishnamurthy, Baskar Ganapathysubramanian</dc:creator>
    </item>
  </channel>
</rss>
