<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 12 Jul 2024 04:00:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 12 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>GeNet: A Multimodal LLM-Based Co-Pilot for Network Topology and Configuration</title>
      <link>https://arxiv.org/abs/2407.08249</link>
      <description>arXiv:2407.08249v1 Announce Type: new 
Abstract: Communication network engineering in enterprise environments is traditionally a complex, time-consuming, and error-prone manual process. Most research on network engineering automation has concentrated on configuration synthesis, often overlooking changes in the physical network topology. This paper introduces GeNet, a multimodal co-pilot for enterprise network engineers. GeNet is a novel framework that leverages a large language model (LLM) to streamline network design workflows. It uses visual and textual modalities to interpret and update network topologies and device configurations based on user intents. GeNet was evaluated on enterprise network scenarios adapted from Cisco certification exercises. Our results demonstrate GeNet's ability to interpret network topology images accurately, potentially reducing network engineers' efforts and accelerating network design processes in enterprise environments. Furthermore, we show the importance of precise topology understanding when handling intents that require modifications to the network's topology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08249v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Beni Ifland, Elad Duani, Rubin Krief, Miro Ohana, Aviram Zilberman, Andres Murillo, Ofir Manor, Ortal Lavi, Hikichi Kenji, Asaf Shabtai, Yuval Elovici, Rami Puzis</dc:creator>
    </item>
    <item>
      <title>BriDe Arbitrager: Enhancing Arbitrage in Ethereum 2.0 via Bribery-enabled Delayed Block Production</title>
      <link>https://arxiv.org/abs/2407.08537</link>
      <description>arXiv:2407.08537v1 Announce Type: new 
Abstract: The advent of Ethereum 2.0 has introduced significant changes, particularly the shift to Proof-of-Stake consensus. This change presents new opportunities and challenges for arbitrage. Amidst these changes, we introduce BriDe Arbitrager, a novel tool designed for Ethereum 2.0 that leverages Bribery-driven attacks to Delay block production and increase arbitrage gains. The main idea is to allow malicious proposers to delay block production by bribing validators/proposers, thereby gaining more time to identify arbitrage opportunities. Through analysing the bribery process, we design an adaptive bribery strategy. Additionally, we propose a Delayed Transaction Ordering Algorithm to leverage the delayed time to amplify arbitrage profits for malicious proposers. To ensure fairness and automate the bribery process, we design and implement a bribery smart contract and a bribery client. As a result, BriDe Arbitrager enables adversaries controlling a limited (&lt; 1/4) fraction of the voting powers to delay block production via bribery and arbitrage more profit. Extensive experimental results based on Ethereum historical transactions demonstrate that BriDe Arbitrager yields an average of 8.66 ETH (16,442.23 USD) daily profits. Furthermore, our approach does not trigger any slashing mechanisms and remains effective even under Proposer Builder Separation and other potential mechanisms will be adopted by Ethereum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08537v1</guid>
      <category>cs.NI</category>
      <category>cs.CR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hulin Yang, Mingzhe Li, Jin Zhang, Alia Asheralieva, Qingsong Wei, Siow Mong Rick Goh</dc:creator>
    </item>
    <item>
      <title>FlexCross: High-Speed and Flexible Packet Processing via a Crosspoint-Queued Crossbar</title>
      <link>https://arxiv.org/abs/2407.08621</link>
      <description>arXiv:2407.08621v1 Announce Type: new 
Abstract: The fast pace at which new online services emerge leads to a rapid surge in the volume of network traffic. A recent approach that the research community has proposed to tackle this issue is in-network computing, which means that network devices perform more computations than before. As a result, processing demands become more varied, creating the need for flexible packet-processing architectures. State-of-the-art approaches provide a high degree of flexibility at the expense of performance for complex applications, or they ensure high performance but only for specific use cases. In order to address these limitations, we propose FlexCross. This flexible packet-processing design can process network traffic with diverse processing requirements at over 100 Gbit/s on FPGAs. Our design contains a crosspoint-queued crossbar that enables the execution of complex applications by forwarding incoming packets to the required processing engines in the specified sequence. The crossbar consists of distributed logic blocks that route incoming packets to the specified targets and resolve contentions for shared resources, as well as memory blocks for packet buffering. We implemented a prototype of FlexCross in Verilog and evaluated it via cycle-accurate register-transfer level simulations. We also conducted test runs with real-world network traffic on an FPGA. The evaluation results demonstrate that FlexCross outperforms state-of-the-art flexible packet-processing designs for different traffic loads and scenarios. The synthesis results show that our prototype consumes roughly 21% of the resources on a Virtex XCU55 UltraScale+ FPGA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08621v1</guid>
      <category>cs.NI</category>
      <category>cs.AR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Klajd Zyla, Marco Liess, Thomas Wild, Andreas Herkersdorf</dc:creator>
    </item>
    <item>
      <title>End-to-End Orchestration of NextG Media Services over the Distributed Compute Continuum</title>
      <link>https://arxiv.org/abs/2407.08710</link>
      <description>arXiv:2407.08710v1 Announce Type: new 
Abstract: NextG (5G and beyond) networks, through the increasing integration of cloud/edge computing technologies, are becoming highly distributed compute platforms ideally suited to host emerging resource-intensive and latency-sensitive applications (e.g., industrial automation, extended reality, distributed AI). The end-to-end orchestration of such demanding applications, which involves function/data placement, flow routing, and joint communication/computation/storage resource allocation, requires new models and algorithms able to capture: (i) their disaggregated microservice-based architecture, (ii) their complex processing graph structures, including multiple-input multiple-output processing stages, and (iii) the opportunities for efficiently sharing and replicating data streams that may be useful for multiple functions and/or end users. To this end, we first identify the technical gaps in existing literature that prevent efficiently addressing the optimal orchestration of emerging applications described by information-aware directed acyclic graphs (DAGs). We then leverage the recently proposed Cloud Network Flow optimization framework and a novel functionally-equivalent DAG-to-Forest graph transformation procedure to design IDAGO (Information-Aware DAG Orchestration), a polynomial-time multi-criteria approximation algorithm for the optimal orchestration of NextG media services over NextG compute-integrated networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08710v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alessandro Mauro, Antonia Maria Tulino, Jaime Llorca</dc:creator>
    </item>
    <item>
      <title>Automatic Generation of Web Censorship Probe Lists</title>
      <link>https://arxiv.org/abs/2407.08185</link>
      <description>arXiv:2407.08185v1 Announce Type: cross 
Abstract: Domain probe lists--used to determine which URLs to probe for Web censorship--play a critical role in Internet censorship measurement studies. Indeed, the size and accuracy of the domain probe list limits the set of censored pages that can be detected; inaccurate lists can lead to an incomplete view of the censorship landscape or biased results. Previous efforts to generate domain probe lists have been mostly manual or crowdsourced. This approach is time-consuming, prone to errors, and does not scale well to the ever-changing censorship landscape.
  In this paper, we explore methods for automatically generating probe lists that are both comprehensive and up-to-date for Web censorship measurement. We start from an initial set of 139,957 unique URLs from various existing test lists consisting of pages from a variety of languages to generate new candidate pages. By analyzing content from these URLs (i.e., performing topic and keyword extraction), expanding these topics, and using them as a feed to search engines, our method produces 119,255 new URLs across 35,147 domains. We then test the new candidate pages by attempting to access each URL from servers in eleven different global locations over a span of four months to check for their connectivity and potential signs of censorship. Our measurements reveal that our method discovered over 1,400 domains--not present in the original dataset--we suspect to be blocked. In short, automatically updating probe lists is possible, and can help further automate censorship measurements at scale.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08185v1</guid>
      <category>cs.CR</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.NI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.56553/popets-2024-0106</arxiv:DOI>
      <dc:creator>Jenny Tang, Leo Alvarez, Arjun Brar, Nguyen Phong Hoang, Nicolas Christin</dc:creator>
    </item>
    <item>
      <title>Joint Optimization of Age of Information and Energy Consumption in NR-V2X System based on Deep Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2407.08458</link>
      <description>arXiv:2407.08458v1 Announce Type: cross 
Abstract: Autonomous driving may be the most important application scenario of next generation, the development of wireless access technologies enabling reliable and low-latency vehicle communication becomes crucial. To address this, 3GPP has developed Vehicle-to-Everything (V2X) specifications based on 5G New Radio (NR) technology, where Mode 2 Side-Link (SL) communication resembles Mode 4 in LTE-V2X, allowing direct communication between vehicles. This supplements SL communication in LTE-V2X and represents the latest advancement in cellular V2X (C-V2X) with improved performance of NR-V2X. However, in NR-V2X Mode 2, resource collisions still occur, and thus degrade the age of information (AOI). Therefore, a interference cancellation method is employed to mitigate this impact by combining NR-V2X with Non-Orthogonal multiple access (NOMA) technology. In NR-V2X, when vehicles select smaller resource reservation interval (RRI), higher-frequency transmissions take ore energy to reduce AoI. Hence, it is important to jointly consider AoI and communication energy consumption based on NR-V2X communication. Then, we formulate such an optimization problem and employ the Deep Reinforcement Learning (DRL) algorithm to compute the optimal transmission RRI and transmission power for each transmitting vehicle to reduce the energy consumption of each transmitting vehicle and the AoI of each receiving vehicle. Extensive simulations have demonstrated the performance of our proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08458v1</guid>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shulin Song, Zheng Zhang, Qiong Wu, Qiang Fan, Pingyi Fan</dc:creator>
    </item>
    <item>
      <title>Distributed Deep Reinforcement Learning Based Gradient Quantization for Federated Learning Enabled Vehicle Edge Computing</title>
      <link>https://arxiv.org/abs/2407.08462</link>
      <description>arXiv:2407.08462v1 Announce Type: cross 
Abstract: Federated Learning (FL) can protect the privacy of the vehicles in vehicle edge computing (VEC) to a certain extent through sharing the gradients of vehicles' local models instead of local data. The gradients of vehicles' local models are usually large for the vehicular artificial intelligence (AI) applications, thus transmitting such large gradients would cause large per-round latency. Gradient quantization has been proposed as one effective approach to reduce the per-round latency in FL enabled VEC through compressing gradients and reducing the number of bits, i.e., the quantization level, to transmit gradients. The selection of quantization level and thresholds determines the quantization error, which further affects the model accuracy and training time. To do so, the total training time and quantization error (QE) become two key metrics for the FL enabled VEC. It is critical to jointly optimize the total training time and QE for the FL enabled VEC. However, the time-varying channel condition causes more challenges to solve this problem. In this paper, we propose a distributed deep reinforcement learning (DRL)-based quantization level allocation scheme to optimize the long-term reward in terms of the total training time and QE. Extensive simulations identify the optimal weighted factors between the total training time and QE, and demonstrate the feasibility and effectiveness of the proposed scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08462v1</guid>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cui Zhang, Wenjun Zhang, Qiong Wu, Pingyi Fan, Qiang Fan, Jiangzhou Wang, Khaled B. Letaief</dc:creator>
    </item>
    <item>
      <title>Robust Generalization of Graph Neural Networks for Carrier Scheduling</title>
      <link>https://arxiv.org/abs/2407.08479</link>
      <description>arXiv:2407.08479v1 Announce Type: cross 
Abstract: Battery-free sensor tags are devices that leverage backscatter techniques to communicate with standard IoT devices, thereby augmenting a network's sensing capabilities in a scalable way. For communicating, a sensor tag relies on an unmodulated carrier provided by a neighboring IoT device, with a schedule coordinating this provisioning across the network. Carrier scheduling--computing schedules to interrogate all sensor tags while minimizing energy, spectrum utilization, and latency--is an NP-Hard optimization problem. Recent work introduces learning-based schedulers that achieve resource savings over a carefully-crafted heuristic, generalizing to networks of up to 60 nodes. However, we find that their advantage diminishes in networks with hundreds of nodes, and degrades further in larger setups. This paper introduces RobustGANTT, a GNN-based scheduler that improves generalization (without re-training) to networks up to 1000 nodes (100x training topology sizes). RobustGANTT not only achieves better and more consistent generalization, but also computes schedules requiring up to 2x less resources than existing systems. Our scheduler exhibits average runtimes of hundreds of milliseconds, allowing it to react fast to changing network conditions. Our work not only improves resource utilization in large-scale backscatter networks, but also offers valuable insights in learning-based scheduling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08479v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel F. Perez-Ramirez, Carlos P\'erez-Penichet, Nicolas Tsiftes, Dejan Kostic, Magnus Boman, Thiemo Voigt</dc:creator>
    </item>
    <item>
      <title>Semantics-Aware Status Updates with Energy Harvesting Devices: Query Version Age of Information</title>
      <link>https://arxiv.org/abs/2407.08587</link>
      <description>arXiv:2407.08587v1 Announce Type: cross 
Abstract: In this work, we study the freshness and significance of information in an IoT status update system where an Energy Harvesting (EH) device samples an information source and forwards the update packets to a destination node through a direct channel. We introduce and optimize a semantics-aware metric, Query Version Age of Information (QVAoI), in the system along with other semantic metrics: Query Age of Information (QAoI), Version Age of Information (VAoI), and Age of Information (AoI). By employing the MDP framework, we formulate the optimization problem and determine the optimal transmission policies at the device, which involve deciding the time slots for updating, subject to the energy limitations imposed by the device's battery and energy arrivals. Through analytical and numerical results, we compare the performance of the semantics-aware QVAoI-Optimal, QAoI-Optimal, VoI-Optimal, and AoI-Optimal policies with a baseline greedy policy. All semantics-aware policies show significantly improved performance compared to the greedy policy. The QVAoI-Optimal policy, in particular, demonstrates a significant performance improvement by either providing fresher, more relevant, and valuable updates with the same amount of energy arrivals or reducing the number of transmissions in the system to maintain the same level of freshness and significance of information compared to the QAoI-Optimal and other policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08587v1</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erfan Delfani, Nikolaos Pappas</dc:creator>
    </item>
    <item>
      <title>Multi-Threshold AoII-Optimum Sampling Policies for CTMC Information Sources</title>
      <link>https://arxiv.org/abs/2407.08592</link>
      <description>arXiv:2407.08592v1 Announce Type: cross 
Abstract: We study push-based sampling and transmission policies for a status update system consisting of a general finite-state continuous-time Markov chain (CTMC) information source with known dynamics, with the goal of minimizing the average age of incorrect information (AoII). The problem setting we investigate involves an exponentially distributed delay channel for transmissions and a constraint on the average sampling rate. We first show that the optimum sampling and transmission policy is a 'multi-threshold policy', where the thresholds depend on both the estimation value and the state of the original process, and sampling and transmission need to be initiated when the instantaneous AoII exceeds the corresponding threshold, called the estimation- and state-aware transmission (ESAT) policy. Subsequently, we formulate the problem of finding the thresholds as a constrained semi-Markov decision process (CSMDP) and the Lagrangian approach. Additionally, we propose two lower complexity sub-optimum policies, namely the estimation-aware transmission (EAT) policy, and the single-threshold (ST) policy, for which it is possible to obtain these thresholds for CTMCs with relatively larger number of states. The underlying CSMDP formulation relies on the 'multi-regime phase-type' (MRPH) distribution which is a generalization of the well-known phase-type distribution, which allows us to obtain the distribution of time until absorption in a CTMC whose transition rates change with respect to time in a piece-wise manner. The effectiveness of the proposed ESAT, EAT and ST sampling and transmission policies are shown through numerical examples, along with comparisons with a baseline scheme that transmits packets according to a Poisson process in out-of-sync periods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08592v1</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ismail Cosandal, Nail Akar, Sennur Ulukus</dc:creator>
    </item>
    <item>
      <title>Multi-sided Matching for the Association of Space-Air-Ground Integrated Systems</title>
      <link>https://arxiv.org/abs/2111.09411</link>
      <description>arXiv:2111.09411v2 Announce Type: replace 
Abstract: Space-air-ground integrated networks (SAGINs) will play a pivotal role in 6G communication systems. They are considered a promising technology for enhancing network capacity in densely populated urban areas and extending connectivity to rural regions. However, the complex, multi-layered, and heterogeneous nature of SAGINs demands an innovative approach to designing their multi-tier associations. In this context, we propose a modeling of the SAGINs association problem using multi-sided matching theory. Our objective is to devise a reliable, asynchronous, and fully distributed approach that associates nodes across the layers to maximize the total end-to-end rate of the assigned agents. To achieve this, our problem is formulated as a multi-sided many-to-one matching game. We introduce a randomized matching algorithm with minimal information exchange. The algorithm is shown to reach an efficient and stable association between nodes in adjacent layers. Simulation results show that our proposed approach yields significant gains compared to both greedy and distance-based algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2111.09411v2</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abdoul Karim A. H. Saliah, Doha Hamza, Hajar El Hammouti, Jeff S Shamma, Mohamed-Slim Alouini</dc:creator>
    </item>
    <item>
      <title>Differentiated Federated Reinforcement Learning Based Traffic Offloading on Space-Air-Ground Integrated Networks</title>
      <link>https://arxiv.org/abs/2212.02075</link>
      <description>arXiv:2212.02075v3 Announce Type: replace 
Abstract: The Space-Air-Ground Integrated Network (SAGIN) plays a pivotal role as a comprehensive foundational network communication infrastructure, presenting opportunities for highly efficient global data transmission. Nonetheless, given SAGIN's unique characteristics as a dynamically heterogeneous network, conventional network optimization methodologies encounter challenges in satisfying the stringent requirements for network latency and stability inherent to data transmission within this network environment. Therefore, this paper proposes the use of differentiated federated reinforcement learning (DFRL) to solve the traffic offloading problem in SAGIN, i.e., using multiple agents to generate differentiated traffic offloading policies. Considering the differentiated characteristics of each region of SAGIN, DFRL models the traffic offloading policy optimization process as the process of solving the Decentralized Partially Observable Markov Decision Process (DEC-POMDP) problem. The paper proposes a novel Differentiated Federated Soft Actor-Critic (DFSAC) algorithm to solve the problem. The DFSAC algorithm takes the network packet delay as the joint reward value and introduces the global trend model as the joint target action-value function of each agent to guide the update of each agent's policy. The simulation results demonstrate that the traffic offloading policy based on the DFSAC algorithm achieves better performance in terms of network throughput, packet loss rate, and packet delay compared to the traditional federated reinforcement learning approach and other baseline approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.02075v3</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yeguang Qin, Yilin Yang, Fengxiao Tang, Xin Yao, Ming Zhao, Nei Kato</dc:creator>
    </item>
    <item>
      <title>Green Operations of SWIPT Networks: The Role of End-User Devices</title>
      <link>https://arxiv.org/abs/2312.08232</link>
      <description>arXiv:2312.08232v2 Announce Type: replace 
Abstract: Internet of Things (IoT) devices often come with batteries of limited capacity that are not easily replaceable or rechargeable, and that constrain significantly the sensing, computing, and communication tasks that they can perform. The Simultaneous Wireless Information and Power Transfer (SWIPT) paradigm addresses this issue by delivering power wirelessly to energy-harvesting IoT devices with the same signal used for information transfer. For their peculiarity, these networks require specific energy-efficient planning and management approaches. However, to date, it is not clear what are the most effective strategies for managing a SWIPT network for energy efficiency. In this paper, we address this issue by developing an analytical model based on stochastic geometry, accounting for the statistics of user-perceived performance and base station scheduling. We formulate an optimization problem for deriving the energy optimal configuration as a function of the main system parameters, and we propose a genetic algorithm approach to solve it. Our results enable a first-order evaluation of the most effective strategies for energy-efficient provisioning of power and communications in a SWIPT network. We show that the service capacity brought about by users brings energy-efficient dynamic network provisioning strategies that radically differ from those of networks with no wireless power transfer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.08232v2</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gianluca Rizzo, Marco Ajmone Marsan, Christian Esposito, Biagio Boi</dc:creator>
    </item>
    <item>
      <title>Emergence of Metcalfe's Law: Mechanism and Model</title>
      <link>https://arxiv.org/abs/2312.11110</link>
      <description>arXiv:2312.11110v2 Announce Type: replace 
Abstract: Metcalfe's Law captures the relationship between the value of a network and its scale, asserting that a network's value is directly proportional to the square of its size. Over the past four decades, various researchers have proposed different scaling laws on this subject. Remarkably, these seemingly conflicting conclusions have all been substantiated by robust data validation, raising the question of which law holds greater representativeness. Consequently, there remains a need for inherent mechanism to underpin these laws. This study aims to bridge this disparity by offering a theoretical interpretation of Metcalfe's Law and its variations. Based on a certain degree of consensus that "traffic is value", network effects are gauged using network traffic load. A general analytical boundary for network traffic load is deduced by balancing practicality and analytical feasibility through the establishment of a comprehensive network model. From this foundation, the mechanism behind Metcalfe's Law and its variants is elucidated, aligning the theoretical derivations with the previously validated empirical evidence for Metcalfe's Law.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.11110v2</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cheng Wang, Yi Wang, Changjun Jiang</dc:creator>
    </item>
    <item>
      <title>SIRD: A Sender-Informed, Receiver-Driven Datacenter Transport Protocol</title>
      <link>https://arxiv.org/abs/2312.15403</link>
      <description>arXiv:2312.15403v4 Announce Type: replace 
Abstract: Datacenter congestion management protocols must navigate the throughput-latency buffering trade-off in the presence of growing constraints due to switching hardware trends, oversubscribed topologies, and varying network configurability and features. In this context, receiver-driven protocols, which schedule packet transmissions instead of reacting to congestion, have shown great promise and work exceptionally well when the bottleneck lies at the ToR-to-receiver link. However, independent receiver schedules may collide if a shared link is the bottleneck instead.
  We present SIRD, a receiver-driven congestion control protocol designed around the simple insight that single-owner links should be scheduled while shared links should be managed through traditional congestion control algorithms. The approach achieves the best of both worlds by allowing precise control of the most common bottleneck and robust bandwidth sharing for shared bottlenecks. SIRD is implemented by end hosts and does not depend on Ethernet priorities or extensive network configuration.
  We compare SIRD to state-of-the-art receiver-driven protocols (Homa, dcPIM, and ExpressPass) and production-grade reactive protocols (Swift and DCTCP) and show that SIRD is the only one that can consistently maximize link utilization, minimize queuing, and obtain near-optimal latency across a wide set of workloads and traffic patterns. SIRD causes 12x less peak buffering than Homa and achieves competitive latency and utilization without requiring Ethernet priorities. Unlike dcPIM, SIRD operates without latency-inducing message exchange rounds and outperforms it in utilization, buffering, and tail latency by 9%, 43%, and 46% respectively. Finally, SIRD achieves 10x lower tail latency and 26% higher utilization than ExpressPass.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.15403v4</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Konstantinos Prasopoulos, Edouard Bugnion, Marios Kogias</dc:creator>
    </item>
  </channel>
</rss>
