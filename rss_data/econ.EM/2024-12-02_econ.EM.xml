<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 02 Dec 2024 05:01:41 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Contrasting the optimal resource allocation to cybersecurity and cyber insurance using prospect theory versus expected utility theory</title>
      <link>https://arxiv.org/abs/2411.18838</link>
      <description>arXiv:2411.18838v1 Announce Type: new 
Abstract: Protecting against cyber-threats is vital for every organization and can be done by investing in cybersecurity controls and purchasing cyber insurance. However, these are interlinked since insurance premiums could be reduced by investing more in cybersecurity controls. The expected utility theory and the prospect theory are two alternative theories explaining decision-making under risk and uncertainty, which can inform strategies for optimizing resource allocation. While the former is considered a rational approach, research has shown that most people make decisions consistent with the latter, including on insurance uptakes. We compare and contrast these two approaches to provide important insights into how the two approaches could lead to different optimal allocations resulting in differing risk exposure as well as financial costs. We introduce the concept of a risk curve and show that identifying the nature of the risk curve is a key step in deriving the optimal resource allocation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18838v1</guid>
      <category>econ.EM</category>
      <category>math.OC</category>
      <category>stat.OT</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Chaitanya Joshi, Jinming Yang, Sergeja Slapnicar, Ryan K L Ko</dc:creator>
    </item>
    <item>
      <title>Warfare Ignited Price Contagion Dynamics in Early Modern Europe</title>
      <link>https://arxiv.org/abs/2411.18978</link>
      <description>arXiv:2411.18978v1 Announce Type: new 
Abstract: Economic historians have long studied market integration and contagion dynamics during periods of warfare and global stress, but there is a lack of model-based evidence on these phenomena. This paper uses an econometric contagion model, the Diebold-Yilmaz framework, to examine the dynamics of economic shocks across European markets in the early modern period. Our findings suggest that violent conflicts, especially the Thirty Years' War, significantly increased food price spillover across cities, causing widespread disruptions across Europe. We also demonstrate the ability of this framework to capture relevant historical dynamics between the main trade centers of the period.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18978v1</guid>
      <category>econ.EM</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emile Esmaili, Michael J. Puma, Francis Ludlow, Eva Jobbova</dc:creator>
    </item>
    <item>
      <title>Canonical correlation analysis of stochastic trends via functional approximation</title>
      <link>https://arxiv.org/abs/2411.19572</link>
      <description>arXiv:2411.19572v1 Announce Type: new 
Abstract: This paper proposes a novel canonical correlation analysis for semiparametric inference in $I(1)/I(0)$ systems via functional approximation. The approach can be applied coherently to panels of $p$ variables with a generic number $s$ of stochastic trends, as well as to subsets or aggregations of variables. This study discusses inferential tools on $s$ and on the loading matrix $\psi$ of the stochastic trends (and on their duals $r$ and $\beta$, the cointegration rank and the cointegrating matrix): asymptotically pivotal test sequences and consistent estimators of $s$ and $r$, $T$-consistent, mixed Gaussian and efficient estimators of $\psi$ and $\beta$, Wald tests thereof, and misspecification tests for checking model assumptions. Monte Carlo simulations show that these tools have reliable performance uniformly in $s$ for small, medium and large-dimensional systems, with $p$ ranging from 10 to 300. An empirical analysis of 20 exchange rates illustrates the methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19572v1</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Massimo Franchi, Iliyan Georgiev, Paolo Paruolo</dc:creator>
    </item>
    <item>
      <title>Difference-in-differences Design with Outcomes Missing Not at Random</title>
      <link>https://arxiv.org/abs/2411.18772</link>
      <description>arXiv:2411.18772v1 Announce Type: cross 
Abstract: This paper addresses one of the most prevalent problems encountered by political scientists working with difference-in-differences (DID) design: missingness in panel data. A common practice for handling missing data, known as complete case analysis, is to drop cases with any missing values over time. A more principled approach involves using nonparametric bounds on causal effects or applying inverse probability weighting based on baseline covariates. Yet, these methods are general remedies that often under-utilize the assumptions already imposed on panel structure for causal identification. In this paper, I outline the pitfalls of complete case analysis and propose an alternative identification strategy based on principal strata. To be specific, I impose parallel trends assumption within each latent group that shares the same missingness pattern (e.g., always-respondents, if-treated-respondents) and leverage missingness rates over time to estimate the proportions of these groups. Building on this, I tailor Lee bounds, a well-known nonparametric bounds under selection bias, to partially identify the causal effect within the DID design. Unlike complete case analysis, the proposed method does not require independence between treatment selection and missingness patterns, nor does it assume homogeneous effects across these patterns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18772v1</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sooahn Shin</dc:creator>
    </item>
    <item>
      <title>Estimation and Inference in High-Dimensional Panel Data Models with Interactive Fixed Effects</title>
      <link>https://arxiv.org/abs/2206.12152</link>
      <description>arXiv:2206.12152v2 Announce Type: replace 
Abstract: We develop new econometric methods for estimation and inference in high-dimensional panel data models with interactive fixed effects. Our approach can be regarded as a non-trivial extension of the very popular common correlated effects (CCE) approach. Roughly speaking, we proceed as follows: We first construct a projection device to eliminate the unobserved factors from the model by applying a dimensionality reduction transform to the matrix of cross-sectionally averaged covariates. The unknown parameters are then estimated by applying lasso techniques to the projected model. For inference purposes, we derive a desparsified version of our lasso-type estimator. While the original CCE approach is restricted to the low-dimensional case where the number of regressors is small and fixed, our methods can deal with both low- and high-dimensional situations where the number of regressors is large and may even exceed the overall sample size. We derive theory for our estimation and inference methods both in the large-T-case, where the time series length T tends to infinity, and in the small-T-case, where T is a fixed natural number. Specifically, we derive the convergence rate of our estimator and show that its desparsified version is asymptotically normal under suitable regularity conditions. The theoretical analysis of the paper is complemented by a simulation study and an empirical application to characteristic based asset pricing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.12152v2</guid>
      <category>econ.EM</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Oliver Linton, Maximilian Ruecker, Michael Vogt, Christopher Walsh</dc:creator>
    </item>
    <item>
      <title>The Transmission of Monetary Policy via Common Cycles in the Euro Area</title>
      <link>https://arxiv.org/abs/2410.05741</link>
      <description>arXiv:2410.05741v3 Announce Type: replace 
Abstract: We use a FAVAR model with proxy variables and sign restrictions to investigate the role of the euro area's common output and inflation cycles in the transmission of monetary policy shocks. Our findings indicate that common cycles explain most of the variation in output and inflation across member countries. However, Southern European economies exhibit a notable divergence from these cycles in the aftermath of the financial crisis. Building on this evidence, we demonstrate that monetary policy is homogeneously propagated to member countries via the common cycles. In contrast, country-specific transmission channels lead to heterogeneous country responses to monetary policy shocks. Consequently, our empirical results suggest that the divergent effects of ECB monetary policy are attributable to heterogeneous country-specific exposures to financial markets, rather than to dis-synchronized economies within the euro area.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05741v3</guid>
      <category>econ.EM</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Lukas Berend, Jan Pr\"user</dc:creator>
    </item>
    <item>
      <title>Doubly Robust Regression Discontinuity Designs</title>
      <link>https://arxiv.org/abs/2411.07978</link>
      <description>arXiv:2411.07978v2 Announce Type: replace 
Abstract: This study introduces a doubly robust (DR) estimator for regression discontinuity (RD) designs. In RD designs, treatment effects are estimated in a quasi-experimental setting where treatment assignment depends on whether a running variable surpasses a predefined cutoff. A common approach in RD estimation is to apply nonparametric regression methods, such as local linear regression. In such an approach, the validity relies heavily on the consistency of nonparametric estimators and is limited by the nonparametric convergence rate, thereby preventing $\sqrt{n}$-consistency. To address these issues, we propose the DR-RD estimator, which combines two distinct estimators for the conditional expected outcomes. If either of these estimators is consistent, the treatment effect estimator remains consistent. Furthermore, due to the debiasing effect, our proposed estimator achieves $\sqrt{n}$-consistency if both regression estimators satisfy certain mild conditions, which also simplifies statistical inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07978v2</guid>
      <category>econ.EM</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Masahiro Kato</dc:creator>
    </item>
    <item>
      <title>Measuring the Quality of Answers in Political Q&amp;As with Large Language Models</title>
      <link>https://arxiv.org/abs/2404.08816</link>
      <description>arXiv:2404.08816v3 Announce Type: replace-cross 
Abstract: This paper proposes a novel methodology for assessing the quality of answers in political question-and-answer sessions. Our approach consists of measuring the quality of an answer based on how accurately it can be identified among all observed answers given the question. This reflects the relevance and depth of engagement of the answer to the question. Similarly to semantic search, this measurement approach can be implemented by training a language model on the corpus of observed questions and answers without additional labeled data. We showcase and validate our methodology using data from the Question Period in the Canadian House of Commons. Our analysis reveals that while some answers have a weak semantic connection with questions, hinting at some evasion or obfuscation, answers are generally relevant, far surpassing what would be expected from random replies. Besides, our findings provide valuable insights into the correlates of answer quality. We find significant variations based on the party affiliation of the members of Parliament posing the questions. Finally, we uncover a meaningful correlation between the quality of answers and the topic of the questions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08816v3</guid>
      <category>cs.CL</category>
      <category>econ.EM</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>R. Michael Alvarez, Jacob Morrier</dc:creator>
    </item>
  </channel>
</rss>
