<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 03 Jul 2025 04:00:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Faster Algorithm for Second (s,t)-mincut and Breaking Quadratic barrier for Dual Edge Sensitivity for (s,t)-mincut</title>
      <link>https://arxiv.org/abs/2507.01366</link>
      <description>arXiv:2507.01366v1 Announce Type: new 
Abstract: We study (s,t)-cuts of second minimum capacity and present the following algorithmic and graph-theoretic results.
  1. Vazirani and Yannakakis [ICALP 1992] designed the first algorithm for computing an (s,t)-cut of second minimum capacity using $O(n^2)$ maximum (s,t)-flow computations. For directed integer-weighted graphs, we significantly improve this bound by designing an algorithm that computes an $(s,t)$-cut of second minimum capacity using $O(\sqrt{n})$ maximum (s,t)-flow computations w.h.p. To achieve this result, a close relationship of independent interest is established between $(s,t)$-cuts of second minimum capacity and global mincuts in directed weighted graphs.
  2. Minimum+1 (s,t)-cuts have been studied quite well recently [Baswana, Bhanja, and Pandey, ICALP 2022], which is a special case of second (s,t)-mincut.
  (a) For directed multi-graphs, we design an algorithm that, given any maximum (s,t)-flow, computes a minimum+1 (s,t)-cut, if it exists, in $O(m)$ time.
  (b) The existing structures for storing and characterizing all minimum+1 (s,t)-cuts occupy $O(mn)$ space. For undirected multi-graphs, we design a DAG occupying only $O(m)$ space that stores and characterizes all minimum+1 (s,t)-cuts.
  3. The study of minimum+1 (s,t)-cuts often turns out to be useful in designing dual edge sensitivity oracles -- a compact data structure for efficiently reporting an (s,t)-mincut after insertion/failure of any given pair of query edges. It has been shown recently [Bhanja, ICALP 2025] that any dual edge sensitivity oracle for (s,t)-mincut in undirected multi-graphs must occupy ${\Omega}(n^2)$ space in the worst-case, irrespective of the query time. For simple graphs, we break this quadratic barrier while achieving a non-trivial query time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01366v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Surender Baswana, Koustav Bhanja, Anupam Roy</dc:creator>
    </item>
    <item>
      <title>Dynamic Similarity Graph Construction with Kernel Density Estimation</title>
      <link>https://arxiv.org/abs/2507.01696</link>
      <description>arXiv:2507.01696v1 Announce Type: new 
Abstract: In the kernel density estimation (KDE) problem, we are given a set $X$ of data points in $\mathbb{R}^d$, a kernel function $k: \mathbb{R}^d \times \mathbb{R}^d \rightarrow \mathbb{R}$, and a query point $\mathbf{q} \in \mathbb{R}^d$, and the objective is to quickly output an estimate of $\sum_{\mathbf{x} \in X} k(\mathbf{q}, \mathbf{x})$. In this paper, we consider $\textsf{KDE}$ in the dynamic setting, and introduce a data structure that efficiently maintains the estimates for a set of query points as data points are added to $X$ over time. Based on this, we design a dynamic data structure that maintains a sparse approximation of the fully connected similarity graph on $X$, and develop a fast dynamic spectral clustering algorithm. We further evaluate the effectiveness of our algorithms on both synthetic and real-world datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01696v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Steinar Laenen, Peter Macgregor, He Sun</dc:creator>
    </item>
    <item>
      <title>SPARSE-PIVOT: Dynamic correlation clustering for node insertions</title>
      <link>https://arxiv.org/abs/2507.01830</link>
      <description>arXiv:2507.01830v1 Announce Type: new 
Abstract: We present a new Correlation Clustering algorithm for a dynamic setting where nodes are added one at a time. In this model, proposed by Cohen-Addad, Lattanzi, Maggiori, and Parotsidis (ICML 2024), the algorithm uses database queries to access the input graph and updates the clustering as each new node is added. Our algorithm has the amortized update time of $O_{\epsilon}(\log^{O(1)}(n))$. Its approximation factor is $20+\varepsilon$, which is a substantial improvement over the approximation factor of the algorithm by Cohen-Addad et al. We complement our theoretical findings by empirically evaluating the approximation guarantee of our algorithm. The results show that it outperforms the algorithm by Cohen-Addad et al.~in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01830v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mina Dalirrooyfard, Konstantin Makarychev, Slobodan Mitrovi\'c</dc:creator>
    </item>
    <item>
      <title>Breaking the $n^{1.5}$ Additive Error Barrier for Private and Efficient Graph Sparsification via Private Expander Decomposition</title>
      <link>https://arxiv.org/abs/2507.01873</link>
      <description>arXiv:2507.01873v1 Announce Type: new 
Abstract: We study differentially private algorithms for graph cut sparsification, a fundamental problem in algorithms, privacy, and machine learning. While significant progress has been made, the best-known private and efficient cut sparsifiers on $n$-node graphs approximate each cut within $\widetilde{O}(n^{1.5})$ additive error and $1+\gamma$ multiplicative error for any $\gamma &gt; 0$ [Gupta, Roth, Ullman TCC'12]. In contrast, "inefficient" algorithms, i.e., those requiring exponential time, can achieve an $\widetilde{O}(n)$ additive error and $1+\gamma$ multiplicative error [Eli{\'a}{\v{s}}, Kapralov, Kulkarni, Lee SODA'20]. In this work, we break the $n^{1.5}$ additive error barrier for private and efficient cut sparsification. We present an $(\varepsilon,\delta)$-DP polynomial time algorithm that, given a non-negative weighted graph, outputs a private synthetic graph approximating all cuts with multiplicative error $1+\gamma$ and additive error $n^{1.25 + o(1)}$ (ignoring dependencies on $\varepsilon, \delta, \gamma$).
  At the heart of our approach lies a private algorithm for expander decomposition, a popular and powerful technique in (non-private) graph algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01873v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anders Aamand, Justin Y. Chen, Mina Dalirrooyfard, Slobodan Mitrovi\'c, Yuriy Nevmyvaka, Sandeep Silwal, Yinzhan Xu</dc:creator>
    </item>
    <item>
      <title>Optimal Dispersion Under Asynchrony</title>
      <link>https://arxiv.org/abs/2507.01298</link>
      <description>arXiv:2507.01298v1 Announce Type: cross 
Abstract: We study the dispersion problem in anonymous port-labeled graphs: $k \leq n$ mobile agents, each with a unique ID and initially located arbitrarily on the nodes of an $n$-node graph with maximum degree $\Delta$, must autonomously relocate so that no node hosts more than one agent. Dispersion serves as a fundamental task in distributed computing of mobile agents, and its complexity stems from key challenges in local coordination under anonymity and limited memory.
  The goal is to minimize both the time to achieve dispersion and the memory required per agent. It is known that any algorithm requires $\Omega(k)$ time in the worst case, and $\Omega(\log k)$ bits of memory per agent. A recent result [SPAA'25] gives an optimal $O(k)$-time algorithm in the synchronous setting and an $O(k \log k)$-time algorithm in the asynchronous setting, both using $O(\log(k+\Delta))$ bits.
  In this paper, we close the complexity gap in the asynchronous setting by presenting the first dispersion algorithm that runs in optimal $O(k)$ time using $O(\log(k+\Delta))$ bits of memory per agent. Our solution is based on a novel technique we develop in this paper that constructs a port-one tree in anonymous graphs, which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01298v1</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <category>cs.MA</category>
      <category>cs.RO</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Debasish Pattanayak, Ajay D. Kshemkalyani, Manish Kumar, Anisur Rahaman Molla, Gokarna Sharma</dc:creator>
    </item>
    <item>
      <title>A Deterministic Partition Tree and Applications</title>
      <link>https://arxiv.org/abs/2507.01775</link>
      <description>arXiv:2507.01775v1 Announce Type: cross 
Abstract: In this paper, we present a deterministic variant of Chan's randomized partition tree [Discret. Comput. Geom., 2012]. This result leads to numerous applications. In particular, for $d$-dimensional simplex range counting (for any constant $d \ge 2$), we construct a data structure using $O(n)$ space and $O(n^{1+\epsilon})$ preprocessing time, such that each query can be answered in $o(n^{1-1/d})$ time (specifically, $O(n^{1-1/d} / \log^{\Omega(1)} n)$ time), thereby breaking an $\Omega(n^{1-1/d})$ lower bound known for the semigroup setting. Notably, our approach does not rely on any bit-packing techniques. We also obtain deterministic improvements for several other classical problems, including simplex range stabbing counting and reporting, segment intersection detection, counting and reporting, ray-shooting among segments, and more. Similar to Chan's original randomized partition tree, we expect that additional applications will emerge in the future, especially in situations where deterministic results are preferred.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01775v1</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haitao Wang</dc:creator>
    </item>
    <item>
      <title>Collision-Free Robot Scheduling</title>
      <link>https://arxiv.org/abs/2402.12019</link>
      <description>arXiv:2402.12019v3 Announce Type: replace 
Abstract: Robots are becoming an increasingly common part of scientific work within laboratory environments. In this paper, we investigate the problem of designing \emph{schedules} for completing a set of tasks at fixed locations with multiple robots in a laboratory. We represent the laboratory as a graph with tasks placed on fixed vertices and robots represented as agents, with the constraint that no two robots may occupy the same vertex at any given timestep. Each schedule is partitioned into a set of timesteps, corresponding to a walk through the graph (allowing for a robot to wait at a vertex to complete a task), with each timestep taking time equal to the time for a robot to move from one vertex to another and each task taking some given number of timesteps during the completion of which a robot must stay at the vertex containing the task. The goal is to determine a set of schedules, with one schedule for each robot, minimising the number of timesteps taken by the schedule taking the greatest number of timesteps within the set of schedules.
  We show that this problem is NP-complete for many simple classes of graphs, the problem of determining the fastest schedule, defined by the number of time steps required for a robot to visit every vertex in the schedule and complete every task assigned in its assigned schedule. Explicitly, we provide this result for complete graphs, bipartite graphs, star graphs, and planar graphs. Finally, we provide positive results for line graphs, showing that we can find an optimal set of schedules for $k$ robots completing $m$ tasks of equal length of a path of length $n$ in $O(kmn)$ time, and a $k$-approximation when the length of the tasks is unbounded.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.12019v3</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ic.2025.105294</arxiv:DOI>
      <arxiv:journal_reference>Information and Computation, Volume 304, 2025, 105294</arxiv:journal_reference>
      <dc:creator>Duncan Adamson, Nathan Flaherty, Igor Potapov, Paul Spirakis</dc:creator>
    </item>
    <item>
      <title>Dynamic Matching with Post-allocation Service and its Application to Refugee Resettlement</title>
      <link>https://arxiv.org/abs/2410.22992</link>
      <description>arXiv:2410.22992v2 Announce Type: replace 
Abstract: Motivated by our collaboration with a major refugee resettlement agency in the U.S., we study a dynamic matching problem where each new arrival (a refugee case) must be matched immediately and irrevocably to one of the static resources (a location with a fixed annual quota). In addition to consuming the static resource, each case requires post-allocation services from a server, such as a translator. Given the uncertainty in service time, a server may not be available at a given time, thus we refer to it as a dynamic resource. Upon matching, the case will wait to avail service in a first-come-first-serve manner. Bursty matching to a location may result in undesirable congestion at its corresponding server. Consequently, the central planner (the agency) faces a dynamic matching problem with an objective that combines the matching reward (captured by pair-specific employment outcomes) with the cost for congestion for dynamic resources and over-allocation for the static ones. Motivated by the observed fluctuations in the composition of refugee pools across the years, we aim to design algorithms that do not rely on distributional knowledge. We develop learning-based algorithms that are asymptotically optimal in certain regimes, easy to interpret, and computationally fast. Our design is based on learning the dual variables of the underlying optimization problem; however, the main challenge lies in the time-varying nature of the dual variables associated with dynamic resources. Our theoretical development brings together techniques from Lyapunov analysis, adversarial online learning, and stochastic optimization. On the application side, when tested on real data from our partner agency and incorporating practical considerations, our method outperforms existing ones making it a viable candidate for replacing the current practice upon experimentation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22992v2</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kirk Bansak, Soonbong Lee, Vahideh Manshadi, Rad Niazadeh, Elisabeth Paulson</dc:creator>
    </item>
    <item>
      <title>Combined Search and Encoding for Seeds, with an Application to Minimal Perfect Hashing</title>
      <link>https://arxiv.org/abs/2502.05613</link>
      <description>arXiv:2502.05613v2 Announce Type: replace 
Abstract: Randomised algorithms often employ methods that can fail and that are retried with independent randomness until they succeed. Randomised data structures therefore often store indices of successful attempts, called seeds. If $n$ such seeds are required (e.g., for independent substructures) the standard approach is to compute for each $i \in [n]$ the smallest successful seed $S_i$ and store $\vec{S} = (S_1, \ldots, S_n)$.
  The central observation of this paper is that this is not space-optimal. We present a different algorithm that computes a sequence $\vec{S}' = (S_1', \ldots, S_n')$ of successful seeds such that the entropy of $\vec{S'}$ undercuts the entropy of $\vec{S}$ by $\Omega(n)$ bits in most cases. To achieve a memory consumption of $\mathrm{OPT}+\varepsilon n$, the expected number of inspected seeds increases by a factor of $O(1/\varepsilon)$.
  We demonstrate the usefulness of our findings with a novel construction for minimal perfect hash functions that, for $n$ keys and any $\varepsilon \in [n^{-3/7}, 1]$, has space requirement $(1+\varepsilon)\mathrm{OPT}$ and construction time $O(n/\varepsilon)$. All previous approaches only support $\varepsilon = \omega(1 / \log n)$ or have construction times that increase exponentially with $1/\varepsilon$. Our implementation beats the construction throughput of the state of the art by more than two orders of magnitude for $\varepsilon \leq 3\%$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05613v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hans-Peter Lehmann, Peter Sanders, Stefan Walzer, Jonatan Ziegler</dc:creator>
    </item>
    <item>
      <title>MOMENTI: Scalable Motif Mining in Multidimensional Time Series</title>
      <link>https://arxiv.org/abs/2502.14446</link>
      <description>arXiv:2502.14446v2 Announce Type: replace 
Abstract: Time series play a fundamental role in many domains, capturing a plethora of information about the underlying data-generating processes. When a process generates multiple synchronized signals we are faced with multidimensional time series. In this context a fundamental problem is that of motif mining, where we seek patterns repeating twice with minor variations, spanning some of the dimensions. State of the art exact solutions for this problem run in time quadratic in the length of the input time series.
  We provide a scalable method to find the top-k motifs in multidimensional time series with probabilistic guarantees on the quality of the results. Our algorithm runs in time subquadratic in the length of the input, and returns the exact solution with probability at least $1-\delta$, where $\delta$ is a user-defined parameter. The algorithm is designed to be adaptive to the input distribution, self-tuning its parameters while respecting user-defined limits on the memory to use.
  Our theoretical analysis is complemented by an extensive experimental evaluation, showing that our algorithm is orders of magnitude faster than the state of the art.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14446v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matteo Ceccarello, Francesco Pio Monaco, Francesco Silvestri</dc:creator>
    </item>
    <item>
      <title>On the time complexity of finding a well-spread perfect matching in bridgeless cubic graphs</title>
      <link>https://arxiv.org/abs/2503.00263</link>
      <description>arXiv:2503.00263v2 Announce Type: replace 
Abstract: We present an algorithm for finding a perfect matching in a $3$-edge-connected cubic graph that intersects every $3$-edge cut in exactly one edge. Specifically, we propose an algorithm with a time complexity of $O(n \log^4 n)$, which significantly improves upon the previously known $O(n^3)$-time algorithms for the same problem. The technique we use for the improvement is efficient use of cactus model of 3-edge cuts. As an application, we use our algorithm to compute embeddings of $3$-edge-connected cubic graphs with limited number of singular edges (i.e., edges that are twice in the boundary of one face) in $O(n \log^4 n)$ time; this application contributes to the study of the well-known Cycle Double Cover conjecture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00263v2</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Babak Ghanbari, Robert \v{S}\'amal</dc:creator>
    </item>
    <item>
      <title>MorphisHash: Improving Space Efficiency of ShockHash for Minimal Perfect Hashing</title>
      <link>https://arxiv.org/abs/2503.10161</link>
      <description>arXiv:2503.10161v2 Announce Type: replace 
Abstract: A minimal perfect hash function (MPHF) maps a set of n keys to unique positions {1, ..., n}. Representing an MPHF requires at least 1.44 bits per key. ShockHash is a technique to construct an MPHF and requires just slightly more space. It gives each key two pseudo random candidate positions. If each key can be mapped to one of its two candidate positions such that there is exactly one key mapped to each position, then an MPHF is found. If not, ShockHash repeats the process with a new set of random candidate positions. ShockHash has to store how many repetitions were required and for each key to which of the two candidate positions it is mapped. However, when a given set of candidate positions can be used as MPHF then there is not only one but multiple ways of mapping the keys to one of their candidate positions such that the mapping results in an MPHF. This redundancy makes up for the majority of the remaining space overhead in ShockHash. In this paper, we present MorphisHash which is a technique that almost completely eliminates this redundancy. Our theoretical result is that MorphisHash saves {\Theta}(ln(n)) bits compared to ShockHash. This corresponds to a factor of 20 less space overhead in practice. The technique to accomplish this might be of a more general interest to compress data structures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10161v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefan Hermann</dc:creator>
    </item>
    <item>
      <title>From Theory to Practice: Engineering Approximation Algorithms for Dynamic Orientation</title>
      <link>https://arxiv.org/abs/2504.16720</link>
      <description>arXiv:2504.16720v2 Announce Type: replace 
Abstract: Dynamic graph algorithms have seen significant theoretical advancements, but practical evaluations often lag behind. This work bridges the gap between theory and practice by engineering and empirically evaluating recently developed approximation algorithms for dynamically maintaining graph orientations. We comprehensively describe the underlying data structures, including efficient bucketing techniques and round-robin updates. Our implementation has a natural parameter $\lambda$, which allows for a trade-off between algorithmic efficiency and the quality of the solution. In the extensive experimental evaluation, we demonstrate that our implementation offers a considerable speedup. Using different quality metrics, we show that our implementations are very competitive and can outperform previous methods. Overall, our approach solves more instances than other methods while being up to 112 times faster on instances that are solvable by all methods compared.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16720v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ernestine Gro{\ss}mann, Ivor van der Hoog, Henrik Reinst\"adtler, Eva Rotenberg, Christian Schulz, Juliette Vlieghe</dc:creator>
    </item>
    <item>
      <title>Engineering Minimal k-Perfect Hash Functions</title>
      <link>https://arxiv.org/abs/2504.20001</link>
      <description>arXiv:2504.20001v2 Announce Type: replace 
Abstract: Given a set S of n keys, a k-perfect hash function (kPHF) is a data structure that maps the keys to the first m integers, where each output integer can be hit by at most k input keys. When m=n/k, the resulting function is called a minimal k-perfect hash function (MkPHF). Applications of kPHFs can be found in external memory data structures or to create efficient 1-perfect hash functions, which in turn have a wide range of applications from databases to bioinformatics. Several papers from the 1980s look at external memory data structures with small internal memory indexes. However, actual k-perfect hash functions are surprisingly rare, and the area has not seen a lot of research recently. At the same time, recent research in 1-perfect hashing shows that there is a lack of efficient kPHFs. In this paper, we revive the area of k-perfect hashing, presenting four new constructions. Our implementations simultaneously dominate older approaches in space consumption, construction time, and query time. We see this paper as a possible starting point of an active line of research, similar to the area of 1-perfect hashing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20001v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefan Hermann, Sebastian Kirmayer, Hans-Peter Lehmann, Peter Sanders, Stefan Walzer</dc:creator>
    </item>
    <item>
      <title>Reweighted Spectral Partitioning Works: Bounds for Special Graph Classes</title>
      <link>https://arxiv.org/abs/2506.01228</link>
      <description>arXiv:2506.01228v2 Announce Type: replace 
Abstract: Spectral partitioning is a method that can be used to compute small sparse cuts or small edge-separators in a wide variety of graph classes, by computing the second-smallest eigenvalue (and eigenvector) of the Laplacian matrix. Upper bounds on this eigenvalue for certain graph classes imply that the method obtains small edge-separators for these classes, usually with a sub-optimal dependence on the maximum degree. In this work, we show that a related method, called reweighted spectral partitioning, guarantees near-optimal sparse vertex-cuts and vertex-separators in a wide variety of graph classes. In many cases, this involves little-to-no necessary dependence on maximum degree.
  We also obtain a new proof of the planar separator theorem, a strengthened eigenvalue bound for bounded-genus graphs, and a refined form of the recent Cheeger-style inequality for vertex expansion via a specialized dimension-reduction step.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01228v2</guid>
      <category>cs.DS</category>
      <category>cs.CG</category>
      <category>cs.DM</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jack Spalding-Jamieson</dc:creator>
    </item>
    <item>
      <title>Practical colinear chaining on sequences revisited</title>
      <link>https://arxiv.org/abs/2506.11750</link>
      <description>arXiv:2506.11750v3 Announce Type: replace 
Abstract: Colinear chaining is a classical heuristic for sequence alignment and is widely used in modern practical aligners. Jain et al. (J. Comput. Biol. 2022) proposed an $O(n \log^3 n)$ time algorithm to chain a set of $n$ anchors so that the chaining cost matches the edit distance of the input sequences, when anchors are all the maximal exact matches. Moreover, assuming a uniform and sparse distribution of anchors, they provided a practical solution ($\mathtt{ChainX}$) working in $O(n \cdot \mathrm{SOL} + n \log n)$ average-case time, where $\mathrm{SOL}$ is the cost of the output chain. This practical solution is not guaranteed to be optimal: we study the failing cases, introduce the anchor diagonal distance, and find and implement an optimal algorithm working in $O(n \cdot \mathrm{OPT} + n \log n)$ average-case time, where $\mathrm{OPT}$ $\le \mathrm{SOL}$ is the optimal chaining cost. We validate the results by Jain et al., show that $\mathtt{ChainX}$ can be suboptimal with a realistic long read dataset, and show minimal computational slowdown for our solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11750v3</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicola Rizzo, Manuel C\'aceres, Veli M\"akinen</dc:creator>
    </item>
    <item>
      <title>A polynomial delay algorithm generating all potential maximal cliques in triconnected planar graphs</title>
      <link>https://arxiv.org/abs/2506.12635</link>
      <description>arXiv:2506.12635v2 Announce Type: replace 
Abstract: We develop a new characterization of potential maximal cliques of a triconnected planar graph and, using this characterization, give a polynomial delay algorithm generating all potential maximal cliques of a given triconnected planar graph. Combined with the dynamic programming algorithms due to Bouchitt{\'e} and Todinca, this algorithm leads to a treewidth algorithm for general planar graphs that runs in time linear in the number of potential maximal cliques and polynomial in the number of vertices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.12635v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Grigoriev, Yasuaki Kobayashi, Hisao Tamaki, Tom C. van der Zanden</dc:creator>
    </item>
    <item>
      <title>Approximating Submodular Matroid-Constrained Partitioning</title>
      <link>https://arxiv.org/abs/2506.19507</link>
      <description>arXiv:2506.19507v2 Announce Type: replace 
Abstract: The submodular partitioning problem asks to minimize, over all partitions $P$ of a ground set $V$, the sum of a given submodular function $f$ over the parts of $P$. The problem has seen considerable work in approximability, as it encompasses multiterminal cuts on graphs, $k$-cuts on hypergraphs, and elementary linear algebra problems such as matrix multiway partitioning. This research has been divided between the fixed terminal setting, where we are given a set of terminals that must be separated by $P$, and the global setting, where the only constraint is the size of the partition. We investigate a generalization that unifies these two settings: minimum submodular matroid-constrained partition. In this problem, we are additionally given a matroid over the ground set and seek to find a partition $P$ in which there exists some basis that is separated by $P$. We explore the approximability of this problem and its variants, reaching the state of the art for the special case of symmetric submodular functions, and provide results for monotone and general submodular functions as well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19507v2</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Krist\'of B\'erczi, Karthekeyan Chandrasekaran, Tam\'as Kir\'aly, Daniel P. Szabo</dc:creator>
    </item>
    <item>
      <title>Inverse matroid optimization under subset constraints</title>
      <link>https://arxiv.org/abs/2507.00930</link>
      <description>arXiv:2507.00930v2 Announce Type: replace 
Abstract: In the Inverse Matroid problem, we are given a matroid, a fixed basis $B$, and an initial weight function, and the goal is to minimally modify the weights -- measured by some function -- so that $B$ becomes a maximum-weight basis. The problem arises naturally in settings where one wishes to explain or enforce a given solution by minimally perturbing the input.
  We extend this classical problem by replacing the fixed basis with a subset $S_0$ of the ground set and imposing various structural constraints on the set of maximum-weight bases relative to $S_0$. Specifically, we study six variants: (A) Inverse Matroid Exists, where $S_0$ must contain at least one maximum-weight basis; (B) Inverse Matroid All, where all bases contained in $S_0$ are maximum-weight; and (C) Inverse Matroid Only, where $S_0$ contains exactly the maximum-weight bases, along with their natural negated counterparts.
  For all variants, we develop combinatorial polynomial-time algorithms under the $\ell_\infty$-norm. A key ingredient is a refined min-max theorem for Inverse Matroid under the $\ell_\infty$-norm, which enables simpler and faster algorithms than previous approaches and may be of independent combinatorial interest. Our work significantly broadens the range of inverse optimization problems on matroids that can be solved efficiently, especially those that constrain the structure of optimal solutions through subset inclusion or exclusion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.00930v2</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Krist\'of B\'erczi, Lydia Mirabel Mendoza-Cadena, Jos\'e Soto</dc:creator>
    </item>
    <item>
      <title>Classical Simulation of High Temperature Quantum Ising Models</title>
      <link>https://arxiv.org/abs/2002.02232</link>
      <description>arXiv:2002.02232v2 Announce Type: replace-cross 
Abstract: We consider generalized quantum Ising models, including those which could describe disordered materials or quantum annealers, and we prove that for all temperatures above a system-size independent threshold the path integral Monte Carlo method based on worldline heat-bath updates always mixes to stationarity in time $\mathcal{O}(n \log n)$ for an $n$ qubit system, and therefore provides a fully polynomial-time approximation scheme for the partition function. This result holds whenever the temperature is greater than four plus twice the maximum interaction degree (valence) over all qubits, measured in units of the local coupling strength. For example, this implies that the classical simulation of the thermal state of a superconducting device modeling a frustrated quantum Ising model with maximum valence of 6 and coupling strengths of 1 GHz is always possible at temperatures above 800 mK. Despite the quantum system being at high temperature, the classical spin system resulting from the quantum-to-classical mapping contains strong couplings which cause the single-site Glauber dynamics to mix slowly, therefore this result depends on the use of worldline updates (which are a form of cluster updates that can be implemented efficiently). This result places definite constraints on the temperatures required for a quantum advantage in analog quantum simulation with various NISQ devices based on equilibrium states of quantum Ising models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2002.02232v2</guid>
      <category>quant-ph</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.DS</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elizabeth Crosson, Samuel Slezak</dc:creator>
    </item>
    <item>
      <title>Criteria for toroidal embedding of one-vertex ribbon graphs</title>
      <link>https://arxiv.org/abs/2208.08692</link>
      <description>arXiv:2208.08692v5 Announce Type: replace-cross 
Abstract: The work provides a brief intuitive overview theory of graph on surfaces. We considers graphs with an additional structure, wich we call discs with ribbons, also known as one-vertex ribbon graphs. And solves the problem (Skopenkov's) about criteria for toroidal embedding of one-vertex ribbon graph.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.08692v5</guid>
      <category>math.CO</category>
      <category>cs.DS</category>
      <category>math.GT</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tim Berezin</dc:creator>
    </item>
    <item>
      <title>Dynamic Indexing Through Learned Indices with Worst-case Guarantees</title>
      <link>https://arxiv.org/abs/2503.05007</link>
      <description>arXiv:2503.05007v2 Announce Type: replace-cross 
Abstract: Indexing data is a fundamental problem in computer science. Recently, various papers apply machine learning to this problem.
  For a fixed integer $\varepsilon$, a \emph{learned index} is a function $h : \mathcal{U} \rightarrow [0, n]$ where $\forall q \in \mathcal{U}$, $h(q) \in [\text{rank}(q) - \varepsilon, \text{rank}(q) + \varepsilon]$. These works use machine learning to compute $h$. Then, they store $S$ in a sorted array $A$ and access $A[\lfloor h(q) \rfloor]$ to answer queries in $O(k + \varepsilon + \log |h|)$ time. Here, $k$ denotes the output size and $|h|$ the complexity of $h$. Ferragina and Vinciguerra (VLDB 2020) observe that creating a learned index is a geometric problem. They define the PGM index by restricting $h$ to a piecewise linear function and show a linear-time algorithm to compute a PGM index of approximate minimum complexity.
  Since indexing queries are decomposable, the PGM index may be made dynamic through the logarithmic method. When allowing deletions, range query times deteriorate to worst-case $O(N + \sum\limits_i^{\lceil \log n \rceil } (\varepsilon + \log |h_i|))$ time (where $N$ is the largest size of $S$ seen so far).
  This paper offers a combination of theoretical insights and experiments as we apply techniques from computational geometry to dynamically maintain an approximately minimum-complexity learned index $h : \mathcal{U} \rightarrow [0, n]$ with $O(\log^2 n)$ update time.
  We also prove that if we restrict $h$ to lie in a specific subclass of piecewise-linear functions, then we can combine $h$ and hash maps to support queries in $O(k + \varepsilon + \log |h|)$ time (at the cost of increasing $|h|$). We implement our algorithm and compare it to the existing implementation. Our empirical analysis shows that our solution supports more efficient range queries in the special case where the update sequence contains many deletions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05007v2</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emil Toftegaard G{\ae}de, Ivor van der Hoog, Eva Rotenberg, Tord Stordalen</dc:creator>
    </item>
    <item>
      <title>Dynamic Membership for Regular Tree Languages</title>
      <link>https://arxiv.org/abs/2504.17536</link>
      <description>arXiv:2504.17536v2 Announce Type: replace-cross 
Abstract: We study the dynamic membership problem for regular tree languages under relabeling updates: we fix an alphabet $\Sigma$ and a regular tree language $L$ over $\Sigma$ (expressed, e.g., as a tree automaton), we are given a tree $T$ with labels in $\Sigma$, and we must maintain the information of whether the tree $T$ belongs to $L$ while handling relabeling updates that change the labels of individual nodes in $T$.
  Our first contribution is to show that this problem admits an $O(\log n / \log \log n)$ algorithm for any fixed regular tree language, improving over known $O(\log n)$ algorithms. This generalizes the known $O(\log n / \log \log n)$ upper bound over words, and it matches the lower bound of $\Omega(\log n / \log \log n)$ from dynamic membership to some word languages and from the existential marked ancestor problem.
  Our second contribution is to introduce a class of regular languages, dubbed almost-commutative tree languages, and show that dynamic membership to such languages under relabeling updates can be decided in constant time per update. Almost-commutative languages generalize both commutative languages and finite languages: they are the analogue for trees of the ZG languages enjoying constant-time dynamic membership over words. Our main technical contribution is to show that this class is conditionally optimal when we assume that the alphabet features a neutral letter, i.e., a letter that has no effect on membership to the language. More precisely, we show that any regular tree language with a neutral letter which is not almost-commutative cannot be maintained in constant time under the assumption that the prefix-U1 problem from (Amarilli, Jachiet, Paperman, ICALP'21) also does not admit a constant-time algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17536v2</guid>
      <category>cs.FL</category>
      <category>cs.DS</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antoine Amarilli, Corentin Barloy, Louis Jachiet, Charles Paperman</dc:creator>
    </item>
    <item>
      <title>Efficient Matching of Some Fundamental Regular Expressions with Backreferences</title>
      <link>https://arxiv.org/abs/2504.18247</link>
      <description>arXiv:2504.18247v2 Announce Type: replace-cross 
Abstract: Regular expression matching is of practical importance due to its widespread use in real-world applications. In practical use, regular expressions are often used with real-world extensions. Accordingly, the matching problem of regular expressions with real-world extensions has been actively studied in recent years, yielding steady progress. However, backreference, a popular extension supported by most modern programming languages such as Java, Python, JavaScript and others in their standard libraries for string processing, is an exception to this positive trend. In fact, it is known that the matching problem of regular expressions with backreferences (rewbs) is theoretically hard and the existence of an asymptotically fast matching algorithm for arbitrary rewbs seems unlikely. Even among currently known partial solutions, the balance between efficiency and generality remains unsatisfactory. To bridge this gap, we present an efficient matching algorithm for rewbs of the form $e_0 (e)_1 e_1 \backslash 1 e_2$ where $e_0, e, e_1, e_2$ are pure regular expressions, which are fundamental and frequently used in practical applications. It runs in quadratic time with respect to the input string length, substantially improving the best-known cubic time complexity for these rewbs. Our algorithm combines ideas from both stringology and automata theory in a novel way. We leverage two techniques from automata theory, injection and summarization, to simultaneously examine matches whose backreferenced substrings are either a fixed right-maximal repeat or its extendable prefixes, which are concepts from stringology. By further utilizing a subtle property of extendable prefixes, our algorithm correctly decides the matching problem while achieving the quadratic-time complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18247v2</guid>
      <category>cs.FL</category>
      <category>cs.DS</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Taisei Nogami, Tachio Terauchi</dc:creator>
    </item>
  </channel>
</rss>
